diff --git a/docs/dev/python/index.md b/docs/dev/python/index.md
index a8ffee46ebf..b299d3347c6 100644
--- a/docs/dev/python/index.md
+++ b/docs/dev/python/index.md
@@ -26,16 +26,15 @@ under the License.
 
 <img src="{% link /fig/pyflink.svg %}" alt="PyFlink" class="offset" width="50%" />
 
-PyFlink is a language for building unified batch and streaming workloads.
-This means real-time streaming pipelines, performing exploratory data
-analysis at scale, building machine learning pipelines, and creating ETLs for a data platform.
-If you're already familiar with Python and libraries such as Pandas, then PyFlink makes it simple
-to leverage the full capabilities of the Apache Flink ecosystem.
+PyFlink is a Python API for Apache Flink that allows you to build scalable batch and streaming 
+workloads, such as real-time data processing pipelines, large-scale exploratory data analysis,
+Machine Learning (ML) pipelines and ETL processes.
+If you're already familiar with Python and libraries such as Pandas, then PyFlink makes it simpler
+to leverage the full capabilities of the Flink ecosystem. Depending on the level of abstraction you
+need, there are two different APIs that can be used in PyFlink:
 
-The PyFlink Table API makes it simple to write powerful relational queries for building reports and
-ETL pipelines.
-At the same time, the PyFlink DataStream API gives developers access to low-level control over
-state and time, unlocking the full power of stream processing.
+* The **PyFlink Table API** allows you to write powerful relational queries in a way that is similar to using SQL or working with tabular data in Python.
+* At the same time, the **PyFlink DataStream API** gives you lower-level control over the core building blocks of Flink, [state]({% link concepts/stateful-stream-processing.md %}) and [time]({% link concepts/timely-stream-processing.md %}), to build more complex stream processing use cases.
 
 <div class="row">
 <div class="col-sm-6" markdown="1">
@@ -44,8 +43,8 @@ state and time, unlocking the full power of stream processing.
 
 If you’re interested in playing around with Flink, try one of our tutorials:
 
-* [Intro to PyFlink Table API]({% link dev/python/table_api_tutorial.md %})
 * [Intro to PyFlink DataStream API]({% link dev/python/datastream_tutorial.md %})
+* [Intro to PyFlink Table API]({% link dev/python/table_api_tutorial.md %})
 
 </div>
 <div class="col-sm-6" markdown="1">
diff --git a/docs/dev/python/index.zh.md b/docs/dev/python/index.zh.md
index a8ffee46ebf..87f0fe54cc9 100644
--- a/docs/dev/python/index.zh.md
+++ b/docs/dev/python/index.zh.md
@@ -26,16 +26,15 @@ under the License.
 
 <img src="{% link /fig/pyflink.svg %}" alt="PyFlink" class="offset" width="50%" />
 
-PyFlink is a language for building unified batch and streaming workloads.
-This means real-time streaming pipelines, performing exploratory data
-analysis at scale, building machine learning pipelines, and creating ETLs for a data platform.
-If you're already familiar with Python and libraries such as Pandas, then PyFlink makes it simple
-to leverage the full capabilities of the Apache Flink ecosystem.
+PyFlink is a Python API for Apache Flink that allows you to build scalable batch and streaming 
+workloads, such as real-time data processing pipelines, large-scale exploratory data analysis,
+Machine Learning (ML) pipelines and ETL processes.
+If you're already familiar with Python and libraries such as Pandas, then PyFlink makes it simpler
+to leverage the full capabilities of the Flink ecosystem. Depending on the level of abstraction you
+need, there are two different APIs that can be used in PyFlink:
 
-The PyFlink Table API makes it simple to write powerful relational queries for building reports and
-ETL pipelines.
-At the same time, the PyFlink DataStream API gives developers access to low-level control over
-state and time, unlocking the full power of stream processing.
+* The **PyFlink Table API** allows you to write powerful relational queries in a way that is similar to using SQL or working with tabular data in Python.
+* At the same time, the **PyFlink DataStream API** gives you lower-level control over the core building blocks of Flink, [state]({% link concepts/stateful-stream-processing.zh.md %}) and [time]({% link concepts/timely-stream-processing.zh.md %}), to build more complex stream processing use cases.
 
 <div class="row">
 <div class="col-sm-6" markdown="1">
@@ -44,8 +43,8 @@ state and time, unlocking the full power of stream processing.
 
 If you’re interested in playing around with Flink, try one of our tutorials:
 
-* [Intro to PyFlink Table API]({% link dev/python/table_api_tutorial.md %})
-* [Intro to PyFlink DataStream API]({% link dev/python/datastream_tutorial.md %})
+* [Intro to PyFlink Table API]({% link dev/python/table_api_tutorial.zh.md %})
+* [Intro to PyFlink DataStream API]({% link dev/python/datastream_tutorial.zh.md %})
 
 </div>
 <div class="col-sm-6" markdown="1">
@@ -54,8 +53,8 @@ If you’re interested in playing around with Flink, try one of our tutorials:
 
 The reference documentation covers all the details. Some starting points:
 
-* [PyFlink DataStream API]({% link dev/python/table-api-users-guide/index.md %})
-* [PyFlink Table API &amp; SQL]({% link dev/python/datastream-api-users-guide/index.md %})
+* [PyFlink DataStream API]({% link dev/python/table-api-users-guide/index.zh.md %})
+* [PyFlink Table API &amp; SQL]({% link dev/python/datastream-api-users-guide/index.zh.md %})
 
 </div>
 </div>
diff --git a/docs/dev/python/table-api-users-guide/conversion_of_pandas.md b/docs/dev/python/table-api-users-guide/conversion_of_pandas.md
index d904e7f7ff9..5ae98b80b40 100644
--- a/docs/dev/python/table-api-users-guide/conversion_of_pandas.md
+++ b/docs/dev/python/table-api-users-guide/conversion_of_pandas.md
@@ -29,11 +29,11 @@ PyFlink Table API supports conversion to and from Pandas DataFrame.
 
 ## Convert Pandas DataFrame to PyFlink Table
 
-Pandas DataFrames can be converted into a PyFlink TAble.
+Pandas DataFrames can be converted into a PyFlink Table.
 Internally, PyFlink will serialize the Pandas DataFrame using Arrow columnar format on the client. 
 The serialized data will be processed and deserialized in Arrow source during execution. 
 The Arrow source can also be used in streaming jobs, and is integrated with checkpointing to
-and provide the exactly once guarantees.
+provide exactly-once guarantees.
 
 The following example shows how to create a PyFlink Table from a Pandas DataFrame:
 
@@ -62,7 +62,7 @@ table = t_env.from_pandas(pdf,
 ## Convert PyFlink Table to Pandas DataFrame
 
 PyFlink Tables can additionally be converted into a Pandas DataFrame.
-The resulting rows will materialized into multiple Arrow batches of Arrow columnar format on the client. 
+The resulting rows will be serialized as multiple Arrow batches of Arrow columnar format on the client. 
 The maximum Arrow batch size is configured via the option [python.fn-execution.arrow.batch.size]({% link dev/python/table-api-users-guide/python_config.md %}#python-fn-execution-arrow-batch-size).
 The serialized data will then be converted to a Pandas DataFrame. 
 Because the contents of the table will be collected on the client, please ensure that the results of the table can fit in memory before calling this method.
diff --git a/docs/dev/python/table-api-users-guide/index.md b/docs/dev/python/table-api-users-guide/index.md
index 5cc8d864048..786b4dc637b 100644
--- a/docs/dev/python/table-api-users-guide/index.md
+++ b/docs/dev/python/table-api-users-guide/index.md
@@ -23,8 +23,7 @@ specific language governing permissions and limitations
 under the License.
 -->
 
-Python Table API allows users to develop [Table API]({% link dev/table/tableApi.md %}) programs using the Python language.
-Apache Flink has provided Python Table API support since 1.9.0.
+The Python Table API allows users to develop [Table API]({% link dev/table/tableApi.md %}) programs using the Python language.
 
 ## Where to go next?
 
diff --git a/docs/dev/python/table-api-users-guide/index.zh.md b/docs/dev/python/table-api-users-guide/index.zh.md
index 57c6d477966..49f31079a27 100644
--- a/docs/dev/python/table-api-users-guide/index.zh.md
+++ b/docs/dev/python/table-api-users-guide/index.zh.md
@@ -25,8 +25,6 @@ under the License.
 
 Python Table API允许用户使用Python语言开发[Table API]({% link dev/table/tableApi.zh.md %})程序。
 
-自1.9.0起，Apache Flink就提供了Python Table API支持。
-
 ## Where to go next?
 
 - [环境安装]({% link dev/python/installation.zh.md %}): 介绍了如何设置Python Table API的执行环境。
diff --git a/docs/fig/pyflink.svg b/docs/fig/pyflink.svg
index bf60695253f..777956c024f 100644
--- a/docs/fig/pyflink.svg
+++ b/docs/fig/pyflink.svg
@@ -1,4 +1,22 @@
 <?xml version="1.0" encoding="UTF-8" standalone="no"?>
+<!--
+Licensed to the Apache Software Foundation (ASF) under one
+or more contributor license agreements.  See the NOTICE file
+distributed with this work for additional information
+regarding copyright ownership.  The ASF licenses this file
+to you under the Apache License, Version 2.0 (the
+"License"); you may not use this file except in compliance
+with the License.  You may obtain a copy of the License at
+
+http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing,
+software distributed under the License is distributed on an
+"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+KIND, either express or implied.  See the License for the
+specific language governing permissions and limitations
+under the License.
+-->
 <svg
    xmlns:dc="http://purl.org/dc/elements/1.1/"
    xmlns:cc="http://creativecommons.org/ns#"
