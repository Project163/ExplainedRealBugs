diff --git a/flink-core/src/main/java/org/apache/flink/configuration/ConfigConstants.java b/flink-core/src/main/java/org/apache/flink/configuration/ConfigConstants.java
index a0bf3656a46..42a3c9a76c3 100644
--- a/flink-core/src/main/java/org/apache/flink/configuration/ConfigConstants.java
+++ b/flink-core/src/main/java/org/apache/flink/configuration/ConfigConstants.java
@@ -42,17 +42,6 @@ public final class ConfigConstants {
 	public static final String DEFAULT_EXECUTION_RETRIES_KEY = "execution-retries.default";
 	
 	// -------------------------------- Runtime -------------------------------
-
-	/**
-	 * The config parameter defining the storage directory to be used by the blob server.
-	 */
-	public static final String BLOB_STORAGE_DIRECTORY_KEY = "blob.storage.directory";
-
-	/**
-	 * The config parameter defining the cleanup interval of the library cache manager.
-	 */
-	public static final String LIBRARY_CACHE_MANAGER_CLEANUP_INTERVAL = "library-cache-manager" +
-			".cleanup.interval";
 	
 	/**
 	 * The config parameter defining the network address to connect to
@@ -71,7 +60,32 @@ public final class ConfigConstants {
 	 * marked as failed.
 	 */
 	public static final String JOB_MANAGER_DEAD_TASKMANAGER_TIMEOUT_KEY = "jobmanager.max-heartbeat-delay-before-failure.msecs";
-	
+
+	/**
+	 * The config parameter defining the storage directory to be used by the blob server.
+	 */
+	public static final String BLOB_STORAGE_DIRECTORY_KEY = "blob.storage.directory";
+
+	/**
+	 * The config parameter defining number of retires for failed BLOB fetches.
+	 */
+	public static final String BLOB_FETCH_RETRIES_KEY = "blob.fetch.retries";
+
+	/**
+	 * The config parameter defining the maximum number of concurrent BLOB fetches that the JobManager serves.
+	 */
+	public static final String BLOB_FETCH_CONCURRENT_KEY = "blob.fetch.num-concurrent";
+
+	/**
+	 * The config parameter defining the backlog of BLOB fetches on the JobManager
+	 */
+	public static final String BLOB_FETCH_BACKLOG_KEY = "blob.fetch.backlog";
+
+	/**
+	 * The config parameter defining the cleanup interval of the library cache manager.
+	 */
+	public static final String LIBRARY_CACHE_MANAGER_CLEANUP_INTERVAL = "library-cache-manager.cleanup.interval";
+
 	/**
 	 * The config parameter defining the task manager's IPC port from the configuration.
 	 */
@@ -405,7 +419,22 @@ public final class ConfigConstants {
 	 */
 	// 30 seconds (its enough to get to mars, should be enough to detect failure)
 	public static final int DEFAULT_JOB_MANAGER_DEAD_TASKMANAGER_TIMEOUT = 30*1000;
-	
+
+	/**
+	 * Default number of retries for failed BLOB fetches.
+	 */
+	public static final int DEFAULT_BLOB_FETCH_RETRIES = 5;
+
+	/**
+	 * Default number of concurrent BLOB fetch operations.
+	 */
+	public static final int DEFAULT_BLOB_FETCH_CONCURRENT = 50;
+
+	/**
+	 * Default BLOB fetch connection backlog.
+	 */
+	public static final int DEFAULT_BLOB_FETCH_BACKLOG = 1000;
+
 	/**
 	 * The default network port the task manager expects incoming IPC connections. The {@code 0} means that
 	 * the TaskManager searches for a free port.
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/AbstractID.java b/flink-runtime/src/main/java/org/apache/flink/runtime/AbstractID.java
index 130e3eb42b2..247a05205f5 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/AbstractID.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/AbstractID.java
@@ -16,11 +16,9 @@
  * limitations under the License.
  */
 
-
 package org.apache.flink.runtime;
 
 import java.io.IOException;
-import java.nio.ByteBuffer;
 import java.util.Random;
 
 import org.apache.flink.core.io.IOReadableWritable;
@@ -103,48 +101,39 @@ public class AbstractID implements IOReadableWritable, Comparable<AbstractID>, j
 	}
 	
 	// --------------------------------------------------------------------------------------------
-	
+
+	/**
+	 * Gets the lower 64 bits of the ID.
+	 *
+	 * @return The lower 64 bits of the ID.
+	 */
 	public long getLowerPart() {
 		return lowerPart;
 	}
-	
-	public long getUpperPart() {
-		return upperPart;
-	}
-
-	// --------------------------------------------------------------------------------------------
 
 	/**
-	 * Converts the given byte array to a long.
+	 * Gets the upper 64 bits of the ID.
 	 *
-	 * @param ba the byte array to be converted
-	 * @param offset the offset indicating at which byte inside the array the conversion shall begin
-	 * @return the long variable
+	 * @return The upper 64 bits of the ID.
 	 */
-	private static long byteArrayToLong(byte[] ba, int offset) {
-		long l = 0;
-
-		for (int i = 0; i < SIZE_OF_LONG; ++i) {
-			l |= (ba[offset + SIZE_OF_LONG - 1 - i] & 0xffL) << (i << 3);
-		}
-
-		return l;
+	public long getUpperPart() {
+		return upperPart;
 	}
 
 	/**
-	 * Converts a long to a byte array.
+	 * Gets the bytes underlying this ID.
 	 *
-	 * @param l the long variable to be converted
-	 * @param ba the byte array to store the result the of the conversion
-	 * @param offset offset indicating at what position inside the byte array the result of the conversion shall be stored
+	 * @return The bytes underlying this ID.
 	 */
-	private static void longToByteArray(final long l, final byte[] ba, final int offset) {
-		for (int i = 0; i < SIZE_OF_LONG; ++i) {
-			final int shift = i << 3; // i * 8
-			ba[offset + SIZE_OF_LONG - 1 - i] = (byte) ((l & (0xffL << shift)) >>> shift);
-		}
+	public byte[] getBytes() {
+		byte[] bytes = new byte[SIZE];
+		longToByteArray(lowerPart, bytes, 0);
+		longToByteArray(upperPart, bytes, SIZE_OF_LONG);
+		return bytes;
 	}
-	
+
+	// --------------------------------------------------------------------------------------------
+	//  Serialization
 	// --------------------------------------------------------------------------------------------
 
 	@Override
@@ -159,16 +148,13 @@ public class AbstractID implements IOReadableWritable, Comparable<AbstractID>, j
 		out.writeLong(this.upperPart);
 	}
 
-	public void write(ByteBuffer buffer) {
-		buffer.putLong(this.lowerPart);
-		buffer.putLong(this.upperPart);
-	}
-
 	public void writeTo(ByteBuf buf) {
 		buf.writeLong(this.lowerPart);
 		buf.writeLong(this.upperPart);
 	}
 
+	// --------------------------------------------------------------------------------------------
+	//  Standard Utilities
 	// --------------------------------------------------------------------------------------------
 	
 	@Override
@@ -203,4 +189,39 @@ public class AbstractID implements IOReadableWritable, Comparable<AbstractID>, j
 		int diff2 = (this.lowerPart < o.lowerPart) ? -1 : ((this.lowerPart == o.lowerPart) ? 0 : 1);
 		return diff1 == 0 ? diff2 : diff1;
 	}
+
+	// --------------------------------------------------------------------------------------------
+	//  Conversion Utilities
+	// --------------------------------------------------------------------------------------------
+
+	/**
+	 * Converts the given byte array to a long.
+	 *
+	 * @param ba the byte array to be converted
+	 * @param offset the offset indicating at which byte inside the array the conversion shall begin
+	 * @return the long variable
+	 */
+	private static long byteArrayToLong(byte[] ba, int offset) {
+		long l = 0;
+
+		for (int i = 0; i < SIZE_OF_LONG; ++i) {
+			l |= (ba[offset + SIZE_OF_LONG - 1 - i] & 0xffL) << (i << 3);
+		}
+
+		return l;
+	}
+
+	/**
+	 * Converts a long to a byte array.
+	 *
+	 * @param l the long variable to be converted
+	 * @param ba the byte array to store the result the of the conversion
+	 * @param offset offset indicating at what position inside the byte array the result of the conversion shall be stored
+	 */
+	private static void longToByteArray(long l, byte[] ba, int offset) {
+		for (int i = 0; i < SIZE_OF_LONG; ++i) {
+			final int shift = i << 3; // i * 8
+			ba[offset + SIZE_OF_LONG - 1 - i] = (byte) ((l & (0xffL << shift)) >>> shift);
+		}
+	}
 }
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobCache.java b/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobCache.java
index 40ec4e3876f..0d1b29c31e2 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobCache.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobCache.java
@@ -24,6 +24,7 @@ import org.apache.flink.configuration.Configuration;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import java.io.Closeable;
 import java.io.File;
 import java.io.FileOutputStream;
 import java.io.IOException;
@@ -40,9 +41,7 @@ import java.util.concurrent.atomic.AtomicBoolean;
  */
 public final class BlobCache implements BlobService {
 
-	/**
-	 * The log object used for debugging.
-	 */
+	/** The log object used for debugging. */
 	private static final Logger LOG = LoggerFactory.getLogger(BlobCache.class);
 
 	private final InetSocketAddress serverAddress;
@@ -54,6 +53,9 @@ public final class BlobCache implements BlobService {
 	/** Shutdown hook thread to ensure deletion of the storage directory. */
 	private final Thread shutdownHook;
 
+	/** The number of retries when the transfer fails */
+	private final int numFetchRetries;
+
 
 	public BlobCache(InetSocketAddress serverAddress, Configuration configuration) {
 		if (serverAddress == null || configuration == null) {
@@ -62,80 +64,122 @@ public final class BlobCache implements BlobService {
 
 		this.serverAddress = serverAddress;
 
+		// configure and create the storage directory
 		String storageDirectory = configuration.getString(ConfigConstants.BLOB_STORAGE_DIRECTORY_KEY, null);
 		this.storageDir = BlobUtils.initStorageDirectory(storageDirectory);
 		LOG.info("Created BLOB cache storage directory " + storageDir);
 
+		// configure the number of fetch retries
+		final int fetchRetries = configuration.getInteger(
+				ConfigConstants.BLOB_FETCH_RETRIES_KEY, ConfigConstants.DEFAULT_BLOB_FETCH_RETRIES);
+		if (fetchRetries >= 0) {
+			this.numFetchRetries = fetchRetries;
+		}
+		else {
+			LOG.warn("Invalid value for {}. System will attempt no retires on failed fetches of BLOBs.",
+					ConfigConstants.BLOB_FETCH_RETRIES_KEY);
+			this.numFetchRetries = 0;
+		}
+
 		// Add shutdown hook to delete storage directory
 		shutdownHook = BlobUtils.addShutdownHook(this, LOG);
 	}
 
 	/**
-	 * Returns the URL for the content-addressable BLOB with the given key. The method will first attempt to serve
-	 * the BLOB from its local cache. If one or more BLOB are not in the cache, the method will try to download them
-	 * from the BLOB server with the given address.
+	 * Returns the URL for the BLOB with the given key. The method will first attempt to serve
+	 * the BLOB from its local cache. If the BLOB is not in the cache, the method will try to download it
+	 * from this cache's BLOB server.
 	 * 
-	 * @param requiredBlob
-	 *        the key of the desired content-addressable BLOB
-	 * @return URL referring to the local storage location of the BLOB
-	 * @throws IOException
-	 *         thrown if an I/O error occurs while downloading the BLOBs from the BLOB server
+	 * @param requiredBlob The key of the desired BLOB.
+	 * @return URL referring to the local storage location of the BLOB.
+	 * @throws IOException Thrown if an I/O error occurs while downloading the BLOBs from the BLOB server.
 	 */
 	public URL getURL(final BlobKey requiredBlob) throws IOException {
 		if (requiredBlob == null) {
-			throw new IllegalArgumentException("Required BLOB cannot be null.");
+			throw new IllegalArgumentException("BLOB key cannot be null.");
 		}
 
-		BlobClient bc = null;
-		byte[] buf = null;
-		URL url = null;
+		final File localJarFile = BlobUtils.getStorageLocation(storageDir, requiredBlob);
 
-		try {
-			final File localJarFile = BlobUtils.getStorageLocation(storageDir, requiredBlob);
+		if (!localJarFile.exists()) {
 
-			if (!localJarFile.exists()) {
+			final byte[] buf = new byte[BlobServerProtocol.BUFFER_SIZE];
 
-				if (LOG.isDebugEnabled()) {
-					LOG.debug("Trying to download " + requiredBlob + " from " + serverAddress);
-				}
+			// loop over retries
+			int attempt = 0;
+			while (true) {
 
-				bc = new BlobClient(serverAddress);
-				buf = new byte[BlobServer.BUFFER_SIZE];
+				if (attempt == 0) {
+					LOG.info("Downloading {} from {}", requiredBlob, serverAddress);
+				} else {
+					LOG.info("Downloading {} from {} (retry {})", requiredBlob, serverAddress, attempt);
+				}
 
-				InputStream is = null;
-				OutputStream os = null;
 				try {
-					is = bc.get(requiredBlob);
-					os = new FileOutputStream(localJarFile);
+					BlobClient bc = null;
+					InputStream is = null;
+					OutputStream os = null;
+
+					try {
+						bc = new BlobClient(serverAddress);
+						is = bc.get(requiredBlob);
+						os = new FileOutputStream(localJarFile);
+
+						while (true) {
+							final int read = is.read(buf);
+							if (read < 0) {
+								break;
+							}
+							os.write(buf, 0, read);
+						}
 
-					while (true) {
+						// we do explicitly not use a finally block, because we want the closing
+						// in the regular case to throw exceptions and cause the writing to fail.
+						// But, the closing on exception should not throw further exceptions and
+						// let us keep the root exception
+						os.close();
+						os = null;
+						is.close();
+						is = null;
+						bc.close();
+						bc = null;
 
-						final int read = is.read(buf);
-						if (read < 0) {
-							break;
+						// success, we finished
+						break;
+					}
+					catch (Throwable t) {
+						// we use "catch (Throwable)" to keep the root exception. Otherwise that exception
+						// it would be replaced by any exception thrown in the finally block
+						closeSilently(os);
+						closeSilently(is);
+						closeSilently(bc);
+
+						if (t instanceof IOException) {
+							throw (IOException) t;
+						} else {
+							throw new IOException(t.getMessage(), t);
 						}
-
-						os.write(buf, 0, read);
 					}
-				} finally {
-					if (is != null) {
-						is.close();
+				}
+				catch (IOException e) {
+					String message = "Failed to fetch BLOB " + requiredBlob + "  from " + serverAddress + '.';
+					if (attempt < numFetchRetries) {
+						attempt++;
+						if (LOG.isDebugEnabled()) {
+							LOG.debug(message + " Retrying...", e);
+						} else {
+							LOG.error(message + " Retrying...");
+						}
 					}
-					if (os != null) {
-						os.close();
+					else {
+						LOG.error(message + " No retries left.", e);
+						throw new IOException(message, e);
 					}
 				}
-			}
-			url = localJarFile.toURI().toURL();
-
-
-		} finally {
-			if (bc != null) {
-				bc.close();
-			}
+			} // end loop over retries
 		}
 
-		return url;
+		return localJarFile.toURI().toURL();
 	}
 
 	/**
@@ -145,8 +189,10 @@ public final class BlobCache implements BlobService {
 	public void delete(BlobKey key) throws IOException{
 		final File localFile = BlobUtils.getStorageLocation(storageDir, key);
 
-		if(localFile.exists()) {
-			localFile.delete();
+		if (localFile.exists()) {
+			if (!localFile.delete()) {
+				LOG.warn("Failed to delete locally cached BLOB " + key + " at " + localFile.getAbsolutePath());
+			}
 		}
 	}
 
@@ -180,4 +226,24 @@ public final class BlobCache implements BlobService {
 			}
 		}
 	}
+
+	public File getStorageDir() {
+		return this.storageDir;
+	}
+
+	// ------------------------------------------------------------------------
+	//  Miscellaneous
+	// ------------------------------------------------------------------------
+
+	private void closeSilently(Closeable closeable) {
+		if (closeable != null) {
+			try {
+				closeable.close();
+			} catch (Throwable t) {
+				if (LOG.isDebugEnabled()) {
+					LOG.debug("Error while closing resource after BLOB transfer.", t);
+				}
+			}
+		}
+	}
 }
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobClient.java b/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobClient.java
index 9a0479f07a7..cb799c4a70d 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobClient.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobClient.java
@@ -19,30 +19,45 @@
 package org.apache.flink.runtime.blob;
 
 import java.io.Closeable;
+import java.io.EOFException;
 import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.OutputStream;
 import java.net.InetSocketAddress;
 import java.net.Socket;
-import java.nio.ByteBuffer;
 import java.security.MessageDigest;
 
-import org.apache.flink.runtime.AbstractID;
+import org.apache.flink.util.InstantiationUtil;
+import org.slf4j.LoggerFactory;
+import org.slf4j.Logger;
+
 import org.apache.flink.runtime.jobgraph.JobID;
 
+import static org.apache.flink.runtime.blob.BlobServerProtocol.CONTENT_ADDRESSABLE;
+import static org.apache.flink.runtime.blob.BlobServerProtocol.JOB_ID_SCOPE;
+import static org.apache.flink.runtime.blob.BlobServerProtocol.NAME_ADDRESSABLE;
+import static org.apache.flink.runtime.blob.BlobUtils.readFully;
+import static org.apache.flink.runtime.blob.BlobUtils.readLength;
+import static org.apache.flink.runtime.blob.BlobUtils.writeLength;
+import static org.apache.flink.runtime.blob.BlobServerProtocol.BUFFER_SIZE;
+import static org.apache.flink.runtime.blob.BlobServerProtocol.DELETE_OPERATION;
+import static org.apache.flink.runtime.blob.BlobServerProtocol.GET_OPERATION;
+import static org.apache.flink.runtime.blob.BlobServerProtocol.PUT_OPERATION;
+import static org.apache.flink.runtime.blob.BlobServerProtocol.MAX_KEY_LENGTH;
+import static org.apache.flink.runtime.blob.BlobServerProtocol.RETURN_OKAY;
+import static org.apache.flink.runtime.blob.BlobServerProtocol.RETURN_ERROR;
+
 /**
- * The BLOB client can communicate with the BLOB server and either upload (PUT), download (GET), or delete (DELETE)
- * BLOBs.
- * <p>
- * This class is not thread-safe.
+ * The BLOB client can communicate with the BLOB server and either upload (PUT), download (GET),
+ * or delete (DELETE) BLOBs.
  */
 public final class BlobClient implements Closeable {
 
-	/**
-	 * The socket connection to the BLOB server.
-	 */
-	private Socket socket;
+	private static final Logger LOG = LoggerFactory.getLogger(BlobClient.class);
+
+	/** The socket connection to the BLOB server. */
+	private final Socket socket;
 
 	/**
 	 * Instantiates a new BLOB client.
@@ -52,71 +67,177 @@ public final class BlobClient implements Closeable {
 	 * @throws IOException
 	 *         thrown if the connection to the BLOB server could not be established
 	 */
-	public BlobClient(final InetSocketAddress serverAddress) throws IOException {
-
+	public BlobClient(InetSocketAddress serverAddress) throws IOException {
 		this.socket = new Socket();
 		try {
 			this.socket.connect(serverAddress);
-		}catch(IOException e){
+		}
+		catch(IOException e) {
+			BlobUtils.closeSilently(socket, LOG);
 			throw new IOException("Could not connect to BlobServer at address " + serverAddress, e);
 		}
 	}
 
+	@Override
+	public void close() throws IOException {
+		this.socket.close();
+	}
+
+	public boolean isClosed() {
+		return this.socket.isClosed();
+	}
+
+	// --------------------------------------------------------------------------------------------
+	//  GET
+	// --------------------------------------------------------------------------------------------
+
 	/**
-	 * Constructs and writes the header data for a PUT request to the given output stream.
+	 * Downloads the BLOB identified by the given job ID and key from the BLOB server. If no such BLOB exists on the
+	 * server, a {@link FileNotFoundException} is thrown.
+	 * 
+	 * @param jobID
+	 *        the job ID identifying the BLOB to download
+	 * @param key
+	 *        the key identifying the BLOB to download
+	 * @return an input stream to read the retrieved data from
+	 * @throws IOException
+	 *         thrown if an I/O error occurs during the download
+	 */
+	public InputStream get(JobID jobID, String key) throws IOException {
+		if (key.length() > MAX_KEY_LENGTH) {
+			throw new IllegalArgumentException("Keys must not be longer than " + MAX_KEY_LENGTH);
+		}
+
+		if (this.socket.isClosed()) {
+			throw new IllegalStateException("BLOB Client is not connected. " +
+					"Client has been shut down or encountered an error before.");
+		}
+		if (LOG.isDebugEnabled()) {
+			LOG.debug(String.format("GET BLOB %s / \"%s\" from %s", jobID, key, socket.getLocalSocketAddress()));
+		}
+
+		try {
+			OutputStream os = this.socket.getOutputStream();
+			InputStream is = this.socket.getInputStream();
+
+			sendGetHeader(os, jobID, key, null);
+			receiveAndCheckResponse(is);
+
+			return new BlobInputStream(is, null);
+		}
+		catch (Throwable t) {
+			BlobUtils.closeSilently(socket, LOG);
+			throw new IOException("GET operation failed: " + t.getMessage(), t);
+		}
+	}
+
+	/**
+	 * Downloads the BLOB identified by the given BLOB key from the BLOB server. If no such BLOB exists on the server, a
+	 * {@link FileNotFoundException} is thrown.
 	 * 
+	 * @param blobKey
+	 *        the BLOB key identifying the BLOB to download
+	 * @return an input stream to read the retrieved data from
+	 * @throws IOException
+	 *         thrown if an I/O error occurs during the download
+	 */
+	public InputStream get(BlobKey blobKey) throws IOException {
+		if (this.socket.isClosed()) {
+			throw new IllegalStateException("BLOB Client is not connected. " +
+					"Client has been shut down or encountered an error before.");
+		}
+		if (LOG.isDebugEnabled()) {
+			LOG.debug(String.format("GET content addressable BLOB %s from %s", blobKey, socket.getLocalSocketAddress()));
+		}
+
+		try {
+			OutputStream os = this.socket.getOutputStream();
+			InputStream is = this.socket.getInputStream();
+
+			// Send GET header
+			sendGetHeader(os, null, null, blobKey);
+			receiveAndCheckResponse(is);
+
+			return new BlobInputStream(is, blobKey);
+		}
+		catch (Throwable t) {
+			BlobUtils.closeSilently(socket, LOG);
+			throw new IOException("GET operation failed: " + t.getMessage(), t);
+		}
+	}
+
+	/**
+	 * Constructs and writes the header data for a GET operation to the given output stream.
+	 *
 	 * @param outputStream
-	 *        the output stream to write the PUT header data to
+	 *        the output stream to write the header data to
 	 * @param jobID
-	 *        the ID of job the BLOB belongs to or <code>null</code> to indicate the upload of a
-	 *        content-addressable BLOB
+	 *        the job ID identifying the BLOB to download or <code>null</code> to indicate the BLOB key should be used
+	 *        to identify the BLOB on the server instead
 	 * @param key
-	 *        the key of the BLOB to upload or <code>null</code> to indicate the upload of a content-addressable BLOB
-	 * @param buf
-	 *        an auxiliary buffer used for data serialization
+	 *        the key identifying the BLOB to download or <code>null</code> to indicate the BLOB key should be used to
+	 *        identify the BLOB on the server instead
+	 * @param blobKey
+	 *        the BLOB key to identify the BLOB to download if either the job ID or the regular key are
+	 *        <code>null</code>
 	 * @throws IOException
 	 *         thrown if an I/O error occurs while writing the header data to the output stream
 	 */
-	private void sendPutHeader(final OutputStream outputStream, final JobID jobID, final String key, final byte[] buf)
-			throws IOException {
+	private void sendGetHeader(OutputStream outputStream, JobID jobID, String key, BlobKey blobKey) throws IOException {
 
 		// Signal type of operation
-		outputStream.write(BlobServer.PUT_OPERATION);
+		outputStream.write(GET_OPERATION);
 
-		// Check if PUT should be done in content-addressable manner
+		// Check if GET should be done in content-addressable manner
 		if (jobID == null || key == null) {
-			outputStream.write(1);
-		} else {
-			outputStream.write(0);
-			// Send job ID
-			final ByteBuffer bb = ByteBuffer.wrap(buf);
-			jobID.write(bb);
-			outputStream.write(buf);
-
-			// Send the key
+			outputStream.write(CONTENT_ADDRESSABLE);
+			blobKey.writeToOutputStream(outputStream);
+		}
+		else {
+			outputStream.write(NAME_ADDRESSABLE);
+			// Send job ID and key
+			outputStream.write(jobID.getBytes());
 			byte[] keyBytes = key.getBytes(BlobUtils.DEFAULT_CHARSET);
-			BlobServer.writeLength(keyBytes.length, buf, outputStream);
+			writeLength(keyBytes.length, outputStream);
 			outputStream.write(keyBytes);
 		}
 	}
 
+	private void receiveAndCheckResponse(InputStream is) throws IOException {
+		int response = is.read();
+		if (response < 0) {
+			throw new EOFException("Premature end of response");
+		}
+		if (response == RETURN_ERROR) {
+			Throwable cause = readExceptionFromStream(is);
+			throw new IOException("Server side error: " + cause.getMessage(), cause);
+		}
+		else if (response != RETURN_OKAY) {
+			throw new IOException("Unrecognized response");
+		}
+	}
+
+
+	// --------------------------------------------------------------------------------------------
+	//  PUT
+	// --------------------------------------------------------------------------------------------
+
 	/**
 	 * Uploads the data of the given byte array to the BLOB server in a content-addressable manner.
-	 * 
+	 *
 	 * @param value
 	 *        the buffer to upload
 	 * @return the computed BLOB key identifying the BLOB on the server
 	 * @throws IOException
 	 *         thrown if an I/O error occurs while uploading the data to the BLOB server
 	 */
-	public BlobKey put(final byte[] value) throws IOException {
-
+	public BlobKey put(byte[] value) throws IOException {
 		return put(value, 0, value.length);
 	}
 
 	/**
 	 * Uploads data from the given byte array to the BLOB server in a content-addressable manner.
-	 * 
+	 *
 	 * @param value
 	 *        the buffer to upload data from
 	 * @param offset
@@ -127,14 +248,13 @@ public final class BlobClient implements Closeable {
 	 * @throws IOException
 	 *         thrown if an I/O error occurs while uploading the data to the BLOB server
 	 */
-	public BlobKey put(final byte[] value, final int offset, final int len) throws IOException {
-
+	public BlobKey put(byte[] value, int offset, int len) throws IOException {
 		return putBuffer(null, null, value, offset, len);
 	}
 
 	/**
 	 * Uploads the data of the given byte array to the BLOB server and stores it under the given job ID and key.
-	 * 
+	 *
 	 * @param jobId
 	 *        the job ID to identify the uploaded data
 	 * @param key
@@ -144,14 +264,13 @@ public final class BlobClient implements Closeable {
 	 * @throws IOException
 	 *         thrown if an I/O error occurs while uploading the data to the BLOB server
 	 */
-	public void put(final JobID jobId, final String key, final byte[] value) throws IOException {
-
+	public void put(JobID jobId, String key, byte[] value) throws IOException {
 		put(jobId, key, value, 0, value.length);
 	}
 
 	/**
 	 * Uploads data from the given byte array to the BLOB server and stores it under the given job ID and key.
-	 * 
+	 *
 	 * @param jobId
 	 *        the job ID to identify the uploaded data
 	 * @param key
@@ -165,11 +284,9 @@ public final class BlobClient implements Closeable {
 	 * @throws IOException
 	 *         thrown if an I/O error occurs while uploading the data to the BLOB server
 	 */
-	public void put(final JobID jobId, final String key, final byte[] value, final int offset, final int len)
-			throws IOException {
-
-		if (key.length() > BlobServer.MAX_KEY_LENGTH) {
-			throw new IllegalArgumentException("Keys must not be longer than " + BlobServer.MAX_KEY_LENGTH);
+	public void put(JobID jobId, String key, byte[] value, int offset, int len) throws IOException {
+		if (key.length() > MAX_KEY_LENGTH) {
+			throw new IllegalArgumentException("Keys must not be longer than " + MAX_KEY_LENGTH);
 		}
 
 		putBuffer(jobId, key, value, offset, len);
@@ -177,7 +294,7 @@ public final class BlobClient implements Closeable {
 
 	/**
 	 * Uploads data from the given input stream to the BLOB server and stores it under the given job ID and key.
-	 * 
+	 *
 	 * @param jobId
 	 *        the job ID to identify the uploaded data
 	 * @param key
@@ -188,10 +305,9 @@ public final class BlobClient implements Closeable {
 	 *         thrown if an I/O error occurs while reading the data from the input stream or uploading the data to the
 	 *         BLOB server
 	 */
-	public void put(final JobID jobId, final String key, final InputStream inputStream) throws IOException {
-
-		if (key.length() > BlobServer.MAX_KEY_LENGTH) {
-			throw new IllegalArgumentException("Keys must not be longer than " + BlobServer.MAX_KEY_LENGTH);
+	public void put(JobID jobId, String key, InputStream inputStream) throws IOException {
+		if (key.length() > MAX_KEY_LENGTH) {
+			throw new IllegalArgumentException("Keys must not be longer than " + MAX_KEY_LENGTH);
 		}
 
 		putInputStream(jobId, key, inputStream);
@@ -199,7 +315,7 @@ public final class BlobClient implements Closeable {
 
 	/**
 	 * Uploads the data from the given input stream to the BLOB server in a content-addressable manner.
-	 * 
+	 *
 	 * @param inputStream
 	 *        the input stream to read the data from
 	 * @return the computed BLOB key identifying the BLOB on the server
@@ -207,93 +323,13 @@ public final class BlobClient implements Closeable {
 	 *         thrown if an I/O error occurs while reading the data from the input stream or uploading the data to the
 	 *         BLOB server
 	 */
-	public BlobKey put(final InputStream inputStream) throws IOException {
-
+	public BlobKey put(InputStream inputStream) throws IOException {
 		return putInputStream(null, null, inputStream);
 	}
 
-	/**
-	 * Deletes the BLOB identified by the given job ID and key from the BLOB server.
-	 * 
-	 * @param jobId
-	 *        the job ID to identify the BLOB
-	 * @param key
-	 *        the key to identify the BLOB
-	 * @throws IOException
-	 *         thrown if an I/O error occurs while transferring the request to the BLOB server
-	 */
-	public void delete(final JobID jobId, final String key) throws IOException {
-
-		if (jobId == null) {
-			throw new IllegalArgumentException("Argument jobID must not be null");
-		}
-
-		if (key == null) {
-			throw new IllegalArgumentException("Argument key must not be null");
-		}
-
-		if (key.length() > BlobServer.MAX_KEY_LENGTH) {
-			throw new IllegalArgumentException("Keys must not be longer than " + BlobServer.MAX_KEY_LENGTH);
-		}
-
-		deleteInternal(jobId, key);
-	}
-
-	/**
-	 * Deletes all BLOBs belonging to the job with the given ID from the BLOB server
-	 * 
-	 * @param jobId
-	 *        the job ID to identify the BLOBs to be deleted
-	 * @throws IOException
-	 *         thrown if an I/O error occurs while transferring the request to the BLOB server
-	 */
-	public void deleteAll(final JobID jobId) throws IOException {
-
-		if (jobId == null) {
-			throw new IllegalArgumentException("Argument jobID must not be null");
-		}
-
-		deleteInternal(jobId, null);
-	}
-
-	/**
-	 * Delete one or multiple BLOBs from the BLOB server.
-	 * 
-	 * @param jobId
-	 *        the job ID to identify the BLOB(s) to be deleted
-	 * @param key
-	 *        the key to identify the specific BLOB to delete or <code>null</code> to delete all BLOBs associated with
-	 *        the job
-	 * @throws IOException
-	 *         thrown if an I/O error occurs while transferring the request to the BLOB server
-	 */
-	private void deleteInternal(final JobID jobId, final String key) throws IOException {
-
-		final OutputStream os = this.socket.getOutputStream();
-		final byte[] buf = new byte[AbstractID.SIZE];
-
-		// Signal type of operation
-		os.write(BlobServer.DELETE_OPERATION);
-
-		// Send job ID
-		final ByteBuffer bb = ByteBuffer.wrap(buf);
-		jobId.write(bb);
-		os.write(buf);
-
-		if (key == null) {
-			os.write(0);
-		} else {
-			os.write(1);
-			// Send the key
-			byte[] keyBytes = key.getBytes(BlobUtils.DEFAULT_CHARSET);
-			BlobServer.writeLength(keyBytes.length, buf, os);
-			os.write(keyBytes);
-		}
-	}
-
 	/**
 	 * Uploads data from the given byte buffer to the BLOB server.
-	 * 
+	 *
 	 * @param jobId
 	 *        the ID of the job the BLOB belongs to or <code>null</code> to store the BLOB in a content-addressable
 	 *        manner
@@ -311,56 +347,62 @@ public final class BlobClient implements Closeable {
 	 * @throws IOException
 	 *         thrown if an I/O error occurs while uploading the data to the BLOB server
 	 */
-	private BlobKey putBuffer(final JobID jobId, final String key, final byte[] value, final int offset, final int len)
-			throws IOException {
+	private BlobKey putBuffer(JobID jobId, String key, byte[] value, int offset, int len) throws IOException {
+		if (this.socket.isClosed()) {
+			throw new IllegalStateException("BLOB Client is not connected. " +
+					"Client has been shut down or encountered an error before.");
+		}
 
-		final OutputStream os = this.socket.getOutputStream();
-		final MessageDigest md = (jobId == null || key == null) ? BlobUtils.createMessageDigest() :
-				null;
-		final byte[] buf = new byte[AbstractID.SIZE];
+		if (LOG.isDebugEnabled()) {
+			if (jobId == null) {
+				LOG.debug(String.format("PUT content addressable BLOB buffer (%d bytes) to %s",
+						len, socket.getLocalSocketAddress()));
+			} else {
+				LOG.debug(String.format("PUT BLOB buffer (%d bytes) under %s / \"%s\" to %s",
+						len, jobId, key, socket.getLocalSocketAddress()));
+			}
+		}
 
-		// Send the PUT header
-		sendPutHeader(os, jobId, key, buf);
+		try {
+			final OutputStream os = this.socket.getOutputStream();
+			final MessageDigest md = jobId == null ? BlobUtils.createMessageDigest() : null;
 
-		// Send the value in iterations of BUFFER_SIZE
-		int remainingBytes = value.length;
-		int bytesSent = 0;
+			// Send the PUT header
+			sendPutHeader(os, jobId, key);
 
-		while (remainingBytes > 0) {
+			// Send the value in iterations of BUFFER_SIZE
+			int remainingBytes = len;
 
-			final int bytesToSend = Math.min(BlobServer.BUFFER_SIZE, remainingBytes);
-			BlobServer.writeLength(bytesToSend, buf, os);
+			while (remainingBytes > 0) {
+				final int bytesToSend = Math.min(BUFFER_SIZE, remainingBytes);
+				writeLength(bytesToSend, os);
 
-			os.write(value, offset + bytesSent, bytesToSend);
+				os.write(value, offset, bytesToSend);
 
-			// Update the message digest if necessary
-			if (md != null) {
-				md.update(value, offset + bytesSent, bytesToSend);
-			}
+				// Update the message digest if necessary
+				if (md != null) {
+					md.update(value, offset, bytesToSend);
+				}
 
-			remainingBytes -= bytesToSend;
-			bytesSent += bytesToSend;
-		}
+				remainingBytes -= bytesToSend;
+				offset += bytesToSend;
+			}
+			// send -1 as the stream end
+			writeLength(-1, os);
 
-		if (md == null) {
-			return null;
+			// Receive blob key and compare
+			final InputStream is = this.socket.getInputStream();
+			return receivePutResponseAndCompare(is, md);
 		}
-
-		// Receive blob key and compare
-		final InputStream is = this.socket.getInputStream();
-		final BlobKey localKey = new BlobKey(md.digest());
-		final BlobKey remoteKey = BlobKey.readFromInputStream(is);
-
-		if (!localKey.equals(remoteKey)) {
-			throw new IOException("Detected data corruption during transfer");
+		catch (Throwable t) {
+			BlobUtils.closeSilently(socket, LOG);
+			throw new IOException("PUT operation failed: " + t.getMessage(), t);
 		}
-
-		return localKey;
 	}
 
 	/**
 	 * Uploads data from the given input stream to the BLOB server.
-	 * 
+	 *
 	 * @param jobId
 	 *        the ID of the job the BLOB belongs to or <code>null</code> to store the BLOB in a content-addressable
 	 *        manner
@@ -374,143 +416,261 @@ public final class BlobClient implements Closeable {
 	 * @throws IOException
 	 *         thrown if an I/O error occurs while uploading the data to the BLOB server
 	 */
-	private BlobKey putInputStream(final JobID jobId, final String key, final InputStream inputStream)
-			throws IOException {
-
-		final OutputStream os = this.socket.getOutputStream();
-		final MessageDigest md = (jobId == null || key == null) ? BlobUtils.createMessageDigest
-				() : null;
-		final byte[] buf = new byte[AbstractID.SIZE];
-		final byte[] xferBuf = new byte[BlobServer.BUFFER_SIZE];
-
-		// Send the PUT header
-		sendPutHeader(os, jobId, key, buf);
-
-		while (true) {
+	private BlobKey putInputStream(JobID jobId, String key, InputStream inputStream) throws IOException {
+		if (this.socket.isClosed()) {
+			throw new IllegalStateException("BLOB Client is not connected. " +
+					"Client has been shut down or encountered an error before.");
+		}
 
-			final int read = inputStream.read(xferBuf);
-			if (read < 0) {
-				break;
+		if (LOG.isDebugEnabled()) {
+			if (jobId == null) {
+				LOG.debug(String.format("PUT content addressable BLOB stream to %s",
+						socket.getLocalSocketAddress()));
+			} else {
+				LOG.debug(String.format("PUT BLOB stream under %s / \"%s\" to %s",
+						jobId, key, socket.getLocalSocketAddress()));
 			}
-			if (read > 0) {
-				BlobServer.writeLength(read, buf, os);
-				os.write(xferBuf, 0, read);
-				if (md != null) {
-					md.update(xferBuf, 0, read);
+		}
+
+		try {
+			final OutputStream os = this.socket.getOutputStream();
+			final MessageDigest md = jobId == null ? BlobUtils.createMessageDigest() : null;
+			final byte[] xferBuf = new byte[BUFFER_SIZE];
+
+			// Send the PUT header
+			sendPutHeader(os, jobId, key);
+
+			while (true) {
+				final int read = inputStream.read(xferBuf);
+				if (read < 0) {
+					// we are done. send a -1 and be done
+					writeLength(-1, os);
+					break;
+				}
+				if (read > 0) {
+					writeLength(read, os);
+					os.write(xferBuf, 0, read);
+					if (md != null) {
+						md.update(xferBuf, 0, read);
+					}
 				}
 			}
+
+			// Receive blob key and compare
+			final InputStream is = this.socket.getInputStream();
+			return receivePutResponseAndCompare(is, md);
+		}
+		catch (Throwable t) {
+			BlobUtils.closeSilently(socket, LOG);
+			throw new IOException("PUT operation failed: " + t.getMessage(), t);
 		}
+	}
 
-		if (md == null) {
-			return null;
+	private BlobKey receivePutResponseAndCompare(InputStream is, MessageDigest md) throws IOException {
+		int response = is.read();
+		if (response < 0) {
+			throw new EOFException("Premature end of response");
 		}
+		else if (response == RETURN_OKAY) {
+			if (md == null) {
+				// not content addressable
+				return null;
+			}
 
-		// Receive blob key and compare
-		final InputStream is = this.socket.getInputStream();
-		final BlobKey localKey = new BlobKey(md.digest());
-		final BlobKey remoteKey = BlobKey.readFromInputStream(is);
+			BlobKey remoteKey = BlobKey.readFromInputStream(is);
+			BlobKey localKey = new BlobKey(md.digest());
 
-		if (!localKey.equals(remoteKey)) {
-			throw new IOException("Detected data corruption during transfer");
-		}
+			if (!localKey.equals(remoteKey)) {
+				throw new IOException("Detected data corruption during transfer");
+			}
 
-		return localKey;
+			return localKey;
+		}
+		else if (response == RETURN_ERROR) {
+			Throwable cause = readExceptionFromStream(is);
+			throw new IOException("Server side error: " + cause.getMessage(), cause);
+		}
+		else {
+			throw new IOException("Unrecognized response");
+		}
 	}
 
 	/**
-	 * Downloads the BLOB identified by the given job ID and key from the BLOB server. If no such BLOB exists on the
-	 * server, a {@link FileNotFoundException} is thrown.
-	 * 
+	 * Constructs and writes the header data for a PUT request to the given output stream.
+	 * NOTE: If the jobId and key are null, we send the data to the content addressable section.
+	 *
+	 * @param outputStream
+	 *        the output stream to write the PUT header data to
 	 * @param jobID
-	 *        the job ID identifying the BLOB to download
+	 *        the ID of job the BLOB belongs to or <code>null</code> to indicate the upload of a
+	 *        content-addressable BLOB
 	 * @param key
-	 *        the key identifying the BLOB to download
-	 * @return an input stream to read the retrieved data from
+	 *        the key of the BLOB to upload or <code>null</code> to indicate the upload of a content-addressable BLOB
 	 * @throws IOException
-	 *         thrown if an I/O error occurs during the download
+	 *         thrown if an I/O error occurs while writing the header data to the output stream
 	 */
-	public InputStream get(final JobID jobID, final String key) throws IOException {
+	private void sendPutHeader(OutputStream outputStream, JobID jobID, String key) throws IOException {
+		// sanity check that either both are null or both are not null
+		if ((jobID != null || key != null) && !(jobID != null && key != null)) {
+			throw new IllegalArgumentException();
+		}
 
-		if (key.length() > BlobServer.MAX_KEY_LENGTH) {
-			throw new IllegalArgumentException("Keys must not be longer than " + BlobServer.MAX_KEY_LENGTH);
+		// Signal type of operation
+		outputStream.write(PUT_OPERATION);
+
+		// Check if PUT should be done in content-addressable manner
+		if (jobID == null) {
+			outputStream.write(CONTENT_ADDRESSABLE);
 		}
+		else {
+			outputStream.write(NAME_ADDRESSABLE);
+			// Send job ID and the key
+			byte[] idBytes = jobID.getBytes();
+			byte[] keyBytes = key.getBytes(BlobUtils.DEFAULT_CHARSET);
+			outputStream.write(idBytes);
+			writeLength(keyBytes.length, outputStream);
+			outputStream.write(keyBytes);
+		}
+	}
 
-		final OutputStream os = this.socket.getOutputStream();
-		final byte[] buf = new byte[AbstractID.SIZE];
+	// --------------------------------------------------------------------------------------------
+	//  DELETE
+	// --------------------------------------------------------------------------------------------
 
-		// Send GET header
-		sendGetHeader(os, jobID, key, null, buf);
+	/**
+	 * Deletes the BLOB identified by the given BLOB key from the BLOB server.
+	 *
+	 * @param key
+	 *        the key to identify the BLOB
+	 * @throws IOException
+	 *         thrown if an I/O error occurs while transferring the request to the BLOB server
+	 */
+	public void delete(BlobKey key) throws IOException {
+		if (key == null) {
+			throw new IllegalArgumentException("BLOB key must not be null");
+		}
 
-		return new BlobInputStream(this.socket.getInputStream(), null, buf);
+		deleteInternal(null, null, key);
 	}
 
 	/**
-	 * Downloads the BLOB identified by the given BLOB key from the BLOB server. If no such BLOB exists on the server, a
-	 * {@link FileNotFoundException} is thrown.
-	 * 
-	 * @param blobKey
-	 *        the BLOB key identifying the BLOB to download
-	 * @return an input stream to read the retrieved data from
+	 * Deletes the BLOB identified by the given job ID and key from the BLOB server.
+	 *
+	 * @param jobId
+	 *        the job ID to identify the BLOB
+	 * @param key
+	 *        the key to identify the BLOB
 	 * @throws IOException
-	 *         thrown if an I/O error occurs during the download
+	 *         thrown if an I/O error occurs while transferring the request to the BLOB server
 	 */
-	public InputStream get(final BlobKey blobKey) throws IOException {
+	public void delete(JobID jobId, String key) throws IOException {
+		if (jobId == null) {
+			throw new IllegalArgumentException("JobID must not be null");
+		}
+		if (key == null) {
+			throw new IllegalArgumentException("Key must not be null");
+		}
+		if (key.length() > MAX_KEY_LENGTH) {
+			throw new IllegalArgumentException("Keys must not be longer than " + MAX_KEY_LENGTH);
+		}
 
-		final OutputStream os = this.socket.getOutputStream();
-		final byte[] buf = new byte[AbstractID.SIZE];
+		deleteInternal(jobId, key, null);
+	}
 
-		// Send GET header
-		sendGetHeader(os, null, null, blobKey, buf);
+	/**
+	 * Deletes all BLOBs belonging to the job with the given ID from the BLOB server
+	 *
+	 * @param jobId
+	 *        the job ID to identify the BLOBs to be deleted
+	 * @throws IOException
+	 *         thrown if an I/O error occurs while transferring the request to the BLOB server
+	 */
+	public void deleteAll(JobID jobId) throws IOException {
+		if (jobId == null) {
+			throw new IllegalArgumentException("Argument jobID must not be null");
+		}
 
-		return new BlobInputStream(this.socket.getInputStream(), blobKey, buf);
+		deleteInternal(jobId, null, null);
 	}
 
 	/**
-	 * Constructs and writes the header data for a GET operation to the given output stream.
-	 * 
-	 * @param outputStream
-	 *        the output stream to write the header data to
-	 * @param jobID
-	 *        the job ID identifying the BLOB to download or <code>null</code> to indicate the BLOB key should be used
-	 *        to identify the BLOB on the server instead
-	 * @param key
-	 *        the key identifying the BLOB to download or <code>null</code> to indicate the BLOB key should be used to
-	 *        identify the BLOB on the server instead
-	 * @param key2
-	 *        the BLOB key to identify the BLOB to download if either the job ID or the regular key are
-	 *        <code>null</code>
-	 * @param buf
-	 *        auxiliary buffer used for data serialization
-	 * @throws IOException
-	 *         thrown if an I/O error occurs while writing the header data to the output stream
+	 * Delete one or multiple BLOBs from the BLOB server.
+	 *
+	 * @param jobId The job ID to identify the BLOB(s) to be deleted.
+	 * @param key The key to identify the specific BLOB to delete or <code>null</code> to delete
+	 *            all BLOBs associated with the job id.
+	 * @param bKey The blob key to identify a specific content addressable BLOB. This parameter
+	 *             is exclusive with jobId and key.
+	 * @throws IOException Thrown if an I/O error occurs while transferring the request to the BLOB server.
 	 */
-	private void sendGetHeader(final OutputStream outputStream, final JobID jobID, final String key,
-			final BlobKey key2, final byte[] buf) throws IOException {
+	private void deleteInternal(JobID jobId, String key, BlobKey bKey) throws IOException {
+		if ((jobId != null && bKey != null) || (jobId == null && bKey == null)) {
+			throw new IllegalArgumentException();
+		}
 
-		// Signal type of operation
-		outputStream.write(BlobServer.GET_OPERATION);
+		try {
+			final OutputStream outputStream = this.socket.getOutputStream();
+			final InputStream inputStream = this.socket.getInputStream();
 
-		// Check if GET should be done in content-addressable manner
-		if (jobID == null || key == null) {
-			outputStream.write(1);
-			key2.writeToOutputStream(outputStream);
-		} else {
-			outputStream.write(0);
-			// Send job ID
-			final ByteBuffer bb = ByteBuffer.wrap(buf);
-			jobID.write(bb);
-			outputStream.write(buf);
-
-			// Send the key
-			byte[] keyBytes = key.getBytes(BlobUtils.DEFAULT_CHARSET);
-			BlobServer.writeLength(keyBytes.length, buf, outputStream);
-			outputStream.write(keyBytes);
+			// Signal type of operation
+			outputStream.write(DELETE_OPERATION);
+
+			// Check if DELETE should be done in content-addressable manner
+			if (jobId == null) {
+				// delete blob key
+				outputStream.write(CONTENT_ADDRESSABLE);
+				bKey.writeToOutputStream(outputStream);
+			}
+			else if (key != null) {
+				// delete BLOB for jobID and name key
+				outputStream.write(NAME_ADDRESSABLE);
+				// Send job ID and the key
+				byte[] idBytes = jobId.getBytes();
+				byte[] keyBytes = key.getBytes(BlobUtils.DEFAULT_CHARSET);
+				outputStream.write(idBytes);
+				writeLength(keyBytes.length, outputStream);
+				outputStream.write(keyBytes);
+			}
+			else {
+				// delete all blobs for JobID
+				outputStream.write(JOB_ID_SCOPE);
+				byte[] idBytes = jobId.getBytes();
+				outputStream.write(idBytes);
+			}
+
+			int response = inputStream.read();
+			if (response < 0) {
+				throw new EOFException("Premature end of response");
+			}
+			if (response == RETURN_ERROR) {
+				Throwable cause = readExceptionFromStream(inputStream);
+				throw new IOException("Server side error: " + cause.getMessage(), cause);
+			}
+			else if (response != RETURN_OKAY) {
+				throw new IOException("Unrecognized response");
+			}
+		}
+		catch (Throwable t) {
+			BlobUtils.closeSilently(socket, LOG);
+			throw new IOException("DELETE operation failed: " + t.getMessage(), t);
 		}
 	}
 
-	@Override
-	public void close() throws IOException {
+	// --------------------------------------------------------------------------------------------
+	//  Miscellaneous
+	// --------------------------------------------------------------------------------------------
 
-		this.socket.close();
+	private static Throwable readExceptionFromStream(InputStream in) throws IOException {
+		int len = readLength(in);
+		byte[] bytes = new byte[len];
+		readFully(in, bytes, 0, len, "Error message");
+
+		try {
+			return (Throwable) InstantiationUtil.deserializeObject(bytes, ClassLoader.getSystemClassLoader());
+		}
+		catch (ClassNotFoundException e) {
+			// should never occur
+			throw new IOException("Could not transfer error message", e);
+		}
 	}
 }
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobConnection.java b/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobConnection.java
deleted file mode 100644
index 3b7a31baa73..00000000000
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobConnection.java
+++ /dev/null
@@ -1,337 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.flink.runtime.blob;
-
-import java.io.EOFException;
-import java.io.File;
-import java.io.FileInputStream;
-import java.io.FileOutputStream;
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.OutputStream;
-import java.net.Socket;
-import java.nio.ByteBuffer;
-import java.security.MessageDigest;
-
-import org.apache.flink.runtime.jobgraph.JobID;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * A BLOB connection handles a series of requests from a particular BLOB client.
- * <p>
- * This class it thread-safe.
- */
-class BlobConnection extends Thread {
-
-	/**
-	 * The log object used for debugging.
-	 */
-	private static final Logger LOG = LoggerFactory.getLogger(BlobConnection.class);
-
-	/**
-	 * The socket to communicate with the client.
-	 */
-	private final Socket clientSocket;
-
-	/**
-	 * The BLOB server.
-	 */
-	private final BlobServer blobServer;
-
-	/**
-	 * Creates a new BLOB connection for a client request
-	 * 
-	 * @param clientSocket
-	 *        the socket to read/write data
-	 * @param blobServer
-	 *        the BLOB server
-	 */
-	BlobConnection(final Socket clientSocket, final BlobServer blobServer) {
-		super("BLOB connection for " + clientSocket.getRemoteSocketAddress().toString());
-
-		this.clientSocket = clientSocket;
-		this.blobServer = blobServer;
-	}
-
-	@Override
-	public void run() {
-
-		try {
-
-			final InputStream inputStream = this.clientSocket.getInputStream();
-			final OutputStream outputStream = this.clientSocket.getOutputStream();
-			final byte[] buffer = new byte[BlobServer.BUFFER_SIZE];
-
-			while (true) {
-
-				// Read the requested operation
-				final int operation = inputStream.read();
-				if (operation < 0) {
-					return;
-				}
-
-				switch (operation) {
-				case BlobServer.PUT_OPERATION:
-					put(inputStream, outputStream, buffer);
-					break;
-				case BlobServer.GET_OPERATION:
-					get(inputStream, outputStream, buffer);
-					break;
-				case BlobServer.DELETE_OPERATION:
-					delete(inputStream, buffer);
-					break;
-				default:
-					throw new IOException("Unknown operation " + operation);
-				}
-			}
-
-		} catch (IOException ioe) {
-			if (LOG.isErrorEnabled()) {
-				LOG.error("Error while executing BLOB connection.", ioe);
-			}
-		} finally {
-			closeSilently(this.clientSocket);
-		}
-	}
-
-	/**
-	 * Handles an incoming GET request from a BLOB client.
-	 * 
-	 * @param inputStream
-	 *        the input stream to read incoming data from
-	 * @param outputStream
-	 *        the output stream to send data back to the client
-	 * @param buf
-	 *        an auxiliary buffer for data serialization/deserialization
-	 * @throws IOException
-	 *         thrown if an I/O error occurs while reading/writing data from/to the respective streams
-	 */
-	private void get(final InputStream inputStream, final OutputStream outputStream, final byte[] buf)
-			throws IOException {
-
-		File blob = null;
-
-		final int contentAdressable = inputStream.read();
-		if (contentAdressable < 0) {
-			throw new EOFException("Expected GET header");
-		}
-
-		if (contentAdressable == 0) {
-			// Receive the job ID
-			BlobServer.readFully(inputStream, buf, 0, JobID.SIZE);
-			final ByteBuffer bb = ByteBuffer.wrap(buf);
-			final JobID jobID = JobID.fromByteBuffer(bb);
-			// Receive the key
-			final String key = readKey(buf, inputStream);
-			blob = this.blobServer.getStorageLocation(jobID, key);
-		} else {
-			final BlobKey key = BlobKey.readFromInputStream(inputStream);
-			blob = blobServer.getStorageLocation(key);
-		}
-
-		// Check if BLOB exists
-		if (!blob.exists()) {
-			BlobServer.writeLength(-1, buf, outputStream);
-			return;
-		}
-
-		BlobServer.writeLength((int) blob.length(), buf, outputStream);
-		FileInputStream fis = null;
-		try {
-			fis = new FileInputStream(blob);
-
-			while (true) {
-
-				final int read = fis.read(buf);
-				if (read < 0) {
-					break;
-				}
-				outputStream.write(buf, 0, read);
-			}
-
-		} finally {
-			if (fis != null) {
-				fis.close();
-			}
-		}
-	}
-
-	/**
-	 * Handles an incoming PUT request from a BLOB client.
-	 * 
-	 * @param inputStream
-	 *        the input stream to read incoming data from
-	 * @param outputStream
-	 *        the output stream to send data back to the client
-	 * @param buf
-	 *        an auxiliary buffer for data serialization/deserialization
-	 * @throws IOException
-	 *         thrown if an I/O error occurs while reading/writing data from/to the respective streams
-	 */
-	private void put(final InputStream inputStream, final OutputStream outputStream, final byte[] buf)
-			throws IOException {
-
-		JobID jobID = null;
-		String key = null;
-		MessageDigest md = null;
-		final int contentAdressable = inputStream.read();
-		if (contentAdressable < 0) {
-			throw new EOFException("Expected PUT header");
-		}
-
-		if (contentAdressable == 0) {
-			// Receive the job ID
-			BlobServer.readFully(inputStream, buf, 0, JobID.SIZE);
-			final ByteBuffer bb = ByteBuffer.wrap(buf);
-			jobID = JobID.fromByteBuffer(bb);
-			// Receive the key
-			key = readKey(buf, inputStream);
-		} else {
-			md = BlobUtils.createMessageDigest();
-		}
-
-		File incomingFile = null;
-		FileOutputStream fos = null;
-
-		try {
-			incomingFile = blobServer.getTemporaryFilename();
-			fos = new FileOutputStream(incomingFile);
-
-			while (true) {
-
-				final int bytesExpected = BlobServer.readLength(buf, inputStream);
-				if (bytesExpected > BlobServer.BUFFER_SIZE) {
-					throw new IOException("Unexpected number of incoming bytes: " + bytesExpected);
-				}
-
-				BlobServer.readFully(inputStream, buf, 0, bytesExpected);
-				fos.write(buf, 0, bytesExpected);
-
-				if (md != null) {
-					md.update(buf, 0, bytesExpected);
-				}
-
-				if (bytesExpected < BlobServer.BUFFER_SIZE) {
-					break;
-				}
-			}
-
-			fos.close();
-			fos = null;
-
-			if (contentAdressable == 0) {
-				final File storageFile = this.blobServer.getStorageLocation(jobID, key);
-				incomingFile.renameTo(storageFile);
-				incomingFile = null;
-			} else {
-				final BlobKey blobKey = new BlobKey(md.digest());
-				final File storageFile = blobServer.getStorageLocation(blobKey);
-				incomingFile.renameTo(storageFile);
-				incomingFile = null;
-
-				// Return computed key to client for validation
-				blobKey.writeToOutputStream(outputStream);
-			}
-		} finally {
-			if (fos != null) {
-				fos.close();
-			}
-			if (incomingFile != null) {
-				incomingFile.delete();
-			}
-		}
-	}
-
-	/**
-	 * Handles an incoming DELETE request from a BLOB client.
-	 * 
-	 * @param inputStream
-	 *        the input stream to read the request from.
-	 * @param buf
-	 *        an auxiliary buffer for data deserialization
-	 * @throws IOException
-	 *         thrown if an I/O error occurs while reading the request data from the input stream
-	 */
-	private void delete(final InputStream inputStream, final byte[] buf) throws IOException {
-
-		// Receive the job ID
-		BlobServer.readFully(inputStream, buf, 0, JobID.SIZE);
-		final ByteBuffer bb = ByteBuffer.wrap(buf);
-		final JobID jobID = JobID.fromByteBuffer(bb);
-		String key = null;
-
-		final int r = inputStream.read();
-		if (r < 0) {
-			throw new EOFException();
-		}
-		if (r > 0) {
-			// Delete individual BLOB
-			// Receive the key
-			key = readKey(buf, inputStream);
-
-			final File blob = this.blobServer.getStorageLocation(jobID, key);
-			blob.delete();
-
-		} else {
-			// Delete all BLOBs for this job
-			blobServer.deleteJobDirectory(jobID);
-		}
-	}
-
-	/**
-	 * Auxiliary method to silently close a {@link Socket}.
-	 * 
-	 * @param socket
-	 *        the socket to close
-	 */
-	static void closeSilently(final Socket socket) {
-
-		try {
-			if (socket != null) {
-				socket.close();
-			}
-		} catch (IOException ioe) {
-		}
-	}
-
-	/**
-	 * Reads the key of a BLOB from the given input stream.
-	 * 
-	 * @param buf
-	 *        auxiliary buffer to data deserialization
-	 * @param inputStream
-	 *        the input stream to read the key from
-	 * @return the key of a BLOB
-	 * @throws IOException
-	 *         thrown if an I/O error occurs while reading the key data from the input stream
-	 */
-	private static String readKey(final byte[] buf,
-			final InputStream inputStream) throws IOException {
-
-		final int keyLength = BlobServer.readLength(buf, inputStream);
-		if (keyLength > BlobServer.MAX_KEY_LENGTH) {
-			throw new IOException("Unexpected key length " + keyLength);
-		}
-
-		BlobServer.readFully(inputStream, buf, 0, keyLength);
-
-		return new String(buf, 0, keyLength, BlobUtils.DEFAULT_CHARSET);
-	}
-}
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobInputStream.java b/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobInputStream.java
index 3654f8f972e..a89a4610e6f 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobInputStream.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobInputStream.java
@@ -24,6 +24,8 @@ import java.io.IOException;
 import java.io.InputStream;
 import java.security.MessageDigest;
 
+import static org.apache.flink.runtime.blob.BlobUtils.readLength;
+
 /**
  * The BLOB input stream is a special implementation of an {@link InputStream} to read the results of a GET operation
  * from the BLOB server.
@@ -63,15 +65,13 @@ final class BlobInputStream extends InputStream {
 	 *        the underlying input stream to read from
 	 * @param blobKey
 	 *        the expected BLOB key for content-addressable BLOBs, <code>null</code> for non-content-addressable BLOBs.
-	 * @param buf
-	 *        auxiliary buffer to read the meta data from the BLOB server
 	 * @throws IOException
 	 *         throws if an I/O error occurs while reading the BLOB data from the BLOB server
 	 */
-	BlobInputStream(final InputStream wrappedInputStream, final BlobKey blobKey, final byte[] buf) throws IOException {
+	BlobInputStream(final InputStream wrappedInputStream, final BlobKey blobKey) throws IOException {
 		this.wrappedInputStream = wrappedInputStream;
 		this.blobKey = blobKey;
-		this.bytesToReceive = BlobServer.readLength(buf, wrappedInputStream);
+		this.bytesToReceive = readLength(wrappedInputStream);
 		if (this.bytesToReceive < 0) {
 			throw new FileNotFoundException();
 		}
@@ -157,7 +157,7 @@ final class BlobInputStream extends InputStream {
 
 	@Override
 	public int available() throws IOException {
-		return 0;
+		return this.bytesToReceive - this.bytesReceived;
 	}
 
 	@Override
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobKey.java b/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobKey.java
index e3d237d6a27..bd254dd9d97 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobKey.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobKey.java
@@ -16,7 +16,6 @@
  * limitations under the License.
  */
 
-
 package org.apache.flink.runtime.blob;
 
 import java.io.EOFException;
@@ -142,7 +141,7 @@ public final class BlobKey implements Serializable, Comparable<BlobKey> {
 		while (bytesRead < BlobKey.SIZE) {
 			final int read = inputStream.read(key, bytesRead, BlobKey.SIZE - bytesRead);
 			if (read < 0) {
-				throw new EOFException();
+				throw new EOFException("Read an incomplete BLOB key");
 			}
 			bytesRead += read;
 		}
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobServer.java b/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobServer.java
index b27af039a2e..c0e81f1e78e 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobServer.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobServer.java
@@ -18,14 +18,15 @@
 
 package org.apache.flink.runtime.blob;
 
-import java.io.EOFException;
 import java.io.File;
 import java.io.FileNotFoundException;
 import java.io.IOException;
-import java.io.InputStream;
-import java.io.OutputStream;
 import java.net.ServerSocket;
 import java.net.URL;
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
 
@@ -42,61 +43,32 @@ import org.slf4j.LoggerFactory;
  * spawning threads to handle these requests. Furthermore, it takes care of creating the directory structure to store
  * the BLOBs or temporarily cache them.
  */
-public final class BlobServer extends Thread implements BlobService {
+public class BlobServer extends Thread implements BlobService {
 
-	/**
-	 * The log object used for debugging.
-	 */
+	/** The log object used for debugging. */
 	private static final Logger LOG = LoggerFactory.getLogger(BlobServer.class);
 
-	/**
-	 * The buffer size in bytes for network transfers.
-	 */
-	static final int BUFFER_SIZE = 4096;
-
-	/**
-	 * The maximum key length allowed for storing BLOBs.
-	 */
-	static final int MAX_KEY_LENGTH = 64;
-
-	/**
-	 * Internal code to identify a PUT operation.
-	 */
-	static final byte PUT_OPERATION = 0;
-
-	/**
-	 * Internal code to identify a GET operation.
-	 */
-	static final byte GET_OPERATION = 1;
-
-	/**
-	 * Internal code to identify a DELETE operation.
-	 */
-	static final byte DELETE_OPERATION = 2;
-
-	/**
-	 * Counter to generate unique names for temporary files.
-	 */
+	/** Counter to generate unique names for temporary files. */
 	private final AtomicInteger tempFileCounter = new AtomicInteger(0);
 
-	/**
-	 * The server socket listening for incoming connections.
-	 */
+	/** The server socket listening for incoming connections. */
 	private final ServerSocket serverSocket;
 
-	/**
-	 * Indicates whether a shutdown of server component has been requested.
-	 */
-	private AtomicBoolean shutdownRequested = new AtomicBoolean();
+	/** Indicates whether a shutdown of server component has been requested. */
+	private final AtomicBoolean shutdownRequested = new AtomicBoolean();
 
 	/** Shutdown hook thread to ensure deletion of the storage directory. */
 	private final Thread shutdownHook;
 
-	/**
-	 * Is the root directory for file storage
-	 */
+	/** Is the root directory for file storage */
 	private final File storageDir;
 
+	/** Set of currently running threads */
+	private final Set<BlobServerConnection> activeConnections = new HashSet<BlobServerConnection>();
+
+	/** The maximum number of concurrent connections */
+	private final int maxConnections;
+
 	/**
 	 * Instantiates a new BLOB server and binds it to a free network port.
 	 * 
@@ -105,38 +77,57 @@ public final class BlobServer extends Thread implements BlobService {
 	 */
 	public BlobServer(Configuration config) throws IOException {
 
+		// configure and create the storage directory
 		String storageDirectory = config.getString(ConfigConstants.BLOB_STORAGE_DIRECTORY_KEY, null);
 		this.storageDir = BlobUtils.initStorageDirectory(storageDirectory);
 		LOG.info("Created BLOB server storage directory {}", storageDir);
 
+		// configure the maximum number of concurrent connections
+		final int maxConnections = config.getInteger(
+				ConfigConstants.BLOB_FETCH_CONCURRENT_KEY, ConfigConstants.DEFAULT_BLOB_FETCH_CONCURRENT);
+		if (maxConnections >= 1) {
+			this.maxConnections = maxConnections;
+		}
+		else {
+			LOG.warn("Invalid value for maximum connections in BLOB server: {}. Using default value of {}",
+					maxConnections, ConfigConstants.DEFAULT_BLOB_FETCH_CONCURRENT);
+			this.maxConnections = ConfigConstants.DEFAULT_BLOB_FETCH_CONCURRENT;
+		}
+
+		// configure the backlog of connections
+		int backlog = config.getInteger(ConfigConstants.BLOB_FETCH_BACKLOG_KEY, ConfigConstants.DEFAULT_BLOB_FETCH_BACKLOG);
+		if (backlog < 1) {
+			LOG.warn("Invalid value for BLOB connection backlog: {}. Using default value of {}",
+					backlog, ConfigConstants.DEFAULT_BLOB_FETCH_BACKLOG);
+			backlog = ConfigConstants.DEFAULT_BLOB_FETCH_BACKLOG;
+		}
+
 		// Add shutdown hook to delete storage directory
 		this.shutdownHook = BlobUtils.addShutdownHook(this, LOG);
 
+		// start the server
 		try {
-			this.serverSocket = new ServerSocket(0);
-
-			start();
-
-			if (LOG.isInfoEnabled()) {
-				LOG.info(String.format("Started BLOB server on port %d",
-						this.serverSocket.getLocalPort()));
-			}
+			this.serverSocket = new ServerSocket(0, backlog);
 		}
 		catch (IOException e) {
-			throw new IOException("Could not create BlobServer with random port.", e);
+			throw new IOException("Could not create BlobServer with automatic port choice.", e);
 		}
-	}
 
-	/**
-	 * Returns the network port the BLOB server is bound to. The return value of this method is undefined after the BLOB
-	 * server has been shut down.
-	 * 
-	 * @return the network port the BLOB server is bound to
-	 */
-	public int getServerPort() {
-		return this.serverSocket.getLocalPort();
+		// start the server thread
+		setName("BLOB Server listener at " + getPort());
+		setDaemon(true);
+		start();
+
+		if (LOG.isInfoEnabled()) {
+			LOG.info("Started BLOB server at {}:{} - max concurrent requests: {} - max backlog: {}",
+					serverSocket.getInetAddress().getHostAddress(), getPort(), maxConnections, backlog);
+		}
 	}
 
+	// --------------------------------------------------------------------------------------------
+	//  Path Accessors
+	// --------------------------------------------------------------------------------------------
+
 	/**
 	 * Returns a file handle to the file associated with the given blob key on the blob
 	 * server.
@@ -174,7 +165,7 @@ public final class BlobServer extends Thread implements BlobService {
 	 * 
 	 * @return a temporary file inside the BLOB server's incoming directory
 	 */
-	File getTemporaryFilename() {
+	File createTemporaryFilename() {
 		return new File(BlobUtils.getIncomingDirectory(storageDir),
 				String.format("temp-%08d", tempFileCounter.getAndIncrement()));
 	}
@@ -183,7 +174,26 @@ public final class BlobServer extends Thread implements BlobService {
 	public void run() {
 		try {
 			while (!this.shutdownRequested.get()) {
-				new BlobConnection(this.serverSocket.accept(), this).start();
+				BlobServerConnection conn = new BlobServerConnection(serverSocket.accept(), this);
+				try {
+					synchronized (activeConnections) {
+						while (activeConnections.size() >= maxConnections) {
+							activeConnections.wait(2000);
+						}
+						activeConnections.add(conn);
+					}
+
+					conn.start();
+					conn = null;
+				}
+				finally {
+					if (conn != null) {
+						conn.close();
+						synchronized (activeConnections) {
+							activeConnections.remove(conn);
+						}
+					}
+				}
 			}
 		}
 		catch (Throwable t) {
@@ -206,6 +216,10 @@ public final class BlobServer extends Thread implements BlobService {
 			catch (IOException ioe) {
 				LOG.debug("Error while closing the server socket.", ioe);
 			}
+
+			// wake the thread up, in case it is waiting on some operation
+			interrupt();
+
 			try {
 				join();
 			}
@@ -213,6 +227,16 @@ public final class BlobServer extends Thread implements BlobService {
 				LOG.debug("Error while waiting for this thread to die.", ie);
 			}
 
+			synchronized (activeConnections) {
+				if (!activeConnections.isEmpty()) {
+					for (BlobServerConnection conn : activeConnections) {
+						LOG.debug("Shutting down connection " + conn.getName());
+						conn.close();
+					}
+					activeConnections.clear();
+				}
+			}
+
 			// Clean up the storage directory
 			try {
 				FileUtils.deleteDirectory(storageDir);
@@ -255,8 +279,7 @@ public final class BlobServer extends Thread implements BlobService {
 		final File localFile = BlobUtils.getStorageLocation(storageDir, requiredBlob);
 
 		if (!localFile.exists()) {
-			throw new FileNotFoundException("File " + localFile.getCanonicalPath() + " does " +
-					"not exist.");
+			throw new FileNotFoundException("File " + localFile.getCanonicalPath() + " does not exist.");
 		} else {
 			return localFile.toURI().toURL();
 		}
@@ -266,15 +289,17 @@ public final class BlobServer extends Thread implements BlobService {
 	 * This method deletes the file associated to the blob key if it exists in the local storage
 	 * of the blob server.
 	 *
-	 * @param blobKey associated with the file to be deleted
+	 * @param key associated with the file to be deleted
 	 * @throws IOException
 	 */
 	@Override
-	public void delete(BlobKey blobKey) throws IOException {
-		final File localFile = BlobUtils.getStorageLocation(storageDir, blobKey);
+	public void delete(BlobKey key) throws IOException {
+		final File localFile = BlobUtils.getStorageLocation(storageDir, key);
 
 		if (localFile.exists()) {
-			localFile.delete();
+			if (!localFile.delete()) {
+				LOG.warn("Failed to delete locally BLOB " + key + " at " + localFile.getAbsolutePath());
+			}
 		}
 	}
 
@@ -285,95 +310,35 @@ public final class BlobServer extends Thread implements BlobService {
 	 */
 	@Override
 	public int getPort() {
-		return getServerPort();
+		return this.serverSocket.getLocalPort();
 	}
 
 	/**
-	 * Auxiliary method to write the length of an upcoming data chunk to an
-	 * output stream.
+	 * Tests whether the BLOB server has been requested to shut down.
 	 *
-	 * @param length
-	 *        the length of the upcoming data chunk in bytes
-	 * @param buf
-	 *        the byte buffer to use for the integer serialization
-	 * @param outputStream
-	 *        the output stream to write the length to
-	 * @throws IOException
-	 *         thrown if an I/O error occurs while writing to the output
-	 *         stream
+	 * @return True, if the server has been requested to shut down, false otherwise.
 	 */
-	static void writeLength(final int length, final byte[] buf,
-							final OutputStream outputStream) throws IOException {
-
-		buf[0] = (byte) (length & 0xff);
-		buf[1] = (byte) ((length >> 8) & 0xff);
-		buf[2] = (byte) ((length >> 16) & 0xff);
-		buf[3] = (byte) ((length >> 24) & 0xff);
-
-		outputStream.write(buf, 0, 4);
+	public boolean isShutdown() {
+		return this.shutdownRequested.get();
 	}
 
 	/**
-	 * Auxiliary method to read the length of an upcoming data chunk from an
-	 * input stream.
-	 *
-	 * @param buf
-	 *        the byte buffer to use for the integer deserialization
-	 * @param inputStream
-	 *        the input stream to read the length from
-	 * @return the length of the upcoming data chunk in bytes
-	 * @throws IOException
-	 *         thrown if an I/O error occurs while reading from the input
-	 *         stream
+	 * Access to the server socket, for testing
 	 */
-	static int readLength(final byte[] buf, final InputStream inputStream)
-			throws IOException {
-
-		int bytesRead = 0;
-		while (bytesRead < 4) {
-			final int read = inputStream.read(buf, bytesRead, 4 - bytesRead);
-			if (read < 0) {
-				throw new EOFException();
-			}
-			bytesRead += read;
-		}
-
-		bytesRead = buf[0] & 0xff;
-		bytesRead |= (buf[1] & 0xff) << 8;
-		bytesRead |= (buf[2] & 0xff) << 16;
-		bytesRead |= (buf[3] & 0xff) << 24;
-
-		return bytesRead;
+	ServerSocket getServerSocket() {
+		return this.serverSocket;
 	}
 
-	/**
-	 * Auxiliary method to read a particular number of bytes from an input stream. This method blocks until the
-	 * requested number of bytes have been read from the stream. If the stream cannot offer enough data, an
-	 * {@link EOFException} is thrown.
-	 *
-	 * @param inputStream
-	 *        the input stream to read the data from
-	 * @param buf
-	 *        the buffer to store the read data
-	 * @param off
-	 *        the offset inside the buffer
-	 * @param len
-	 *        the number of bytes to read from the stream
-	 * @throws IOException
-	 *         thrown if I/O error occurs while reading from the stream or the stream cannot offer enough data
-	 */
-	static void readFully(final InputStream inputStream,
-						final byte[] buf, final int off, final int len) throws IOException {
-
-		int bytesRead = 0;
-		while (bytesRead < len) {
+	void unregisterConnection(BlobServerConnection conn) {
+		synchronized (activeConnections) {
+			activeConnections.remove(conn);
+			activeConnections.notifyAll();
+		}
+	}
 
-			final int read = inputStream.read(buf, off + bytesRead, len
-					- bytesRead);
-			if (read < 0) {
-				throw new EOFException();
-			}
-			bytesRead += read;
+	List<BlobServerConnection> getCurrentyActiveConnections() {
+		synchronized (activeConnections) {
+			return new ArrayList<BlobServerConnection>(activeConnections);
 		}
 	}
 }
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobServerConnection.java b/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobServerConnection.java
new file mode 100644
index 00000000000..0946d9803ad
--- /dev/null
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobServerConnection.java
@@ -0,0 +1,466 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.runtime.blob;
+
+import java.io.EOFException;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.OutputStream;
+import java.net.Socket;
+import java.net.SocketException;
+import java.security.MessageDigest;
+
+import org.apache.flink.runtime.jobgraph.JobID;
+import org.apache.flink.util.InstantiationUtil;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import static org.apache.flink.runtime.blob.BlobServerProtocol.CONTENT_ADDRESSABLE;
+import static org.apache.flink.runtime.blob.BlobServerProtocol.JOB_ID_SCOPE;
+import static org.apache.flink.runtime.blob.BlobServerProtocol.NAME_ADDRESSABLE;
+import static org.apache.flink.runtime.blob.BlobUtils.closeSilently;
+import static org.apache.flink.runtime.blob.BlobUtils.readFully;
+import static org.apache.flink.runtime.blob.BlobUtils.readLength;
+import static org.apache.flink.runtime.blob.BlobUtils.writeLength;
+
+import static org.apache.flink.runtime.blob.BlobServerProtocol.BUFFER_SIZE;
+import static org.apache.flink.runtime.blob.BlobServerProtocol.DELETE_OPERATION;
+import static org.apache.flink.runtime.blob.BlobServerProtocol.GET_OPERATION;
+import static org.apache.flink.runtime.blob.BlobServerProtocol.PUT_OPERATION;
+import static org.apache.flink.runtime.blob.BlobServerProtocol.MAX_KEY_LENGTH;
+import static org.apache.flink.runtime.blob.BlobServerProtocol.RETURN_OKAY;
+import static org.apache.flink.runtime.blob.BlobServerProtocol.RETURN_ERROR;
+
+/**
+ * A BLOB connection handles a series of requests from a particular BLOB client.
+ */
+class BlobServerConnection extends Thread {
+
+	/** The log object used for debugging. */
+	private static final Logger LOG = LoggerFactory.getLogger(BlobServer.class);
+
+	/** The socket to communicate with the client. */
+	private final Socket clientSocket;
+
+	/** The BLOB server. */
+	private final BlobServer blobServer;
+
+	/**
+	 * Creates a new BLOB connection for a client request
+	 * 
+	 * @param clientSocket The socket to read/write data.
+	 * @param blobServer The BLOB server.
+	 */
+	BlobServerConnection(Socket clientSocket, BlobServer blobServer) {
+		super("BLOB connection for " + clientSocket.getRemoteSocketAddress().toString());
+		setDaemon(true);
+
+		if (blobServer == null) {
+			throw new NullPointerException();
+		}
+
+		this.clientSocket = clientSocket;
+		this.blobServer = blobServer;
+	}
+
+	// --------------------------------------------------------------------------------------------
+	//  Connection / Thread methods
+	// --------------------------------------------------------------------------------------------
+
+	/**
+	 * Main connection work method. Accepts requests until the other side closes the connection.
+	 */
+	@Override
+	public void run() {
+		try {
+			final InputStream inputStream = this.clientSocket.getInputStream();
+			final OutputStream outputStream = this.clientSocket.getOutputStream();
+			final byte[] buffer = new byte[BUFFER_SIZE];
+
+			while (true) {
+				// Read the requested operation
+				final int operation = inputStream.read();
+				if (operation < 0) {
+					// done, no one is asking anything from us
+					return;
+				}
+
+				switch (operation) {
+				case PUT_OPERATION:
+					put(inputStream, outputStream, buffer);
+					break;
+				case GET_OPERATION:
+					get(inputStream, outputStream, buffer);
+					break;
+				case DELETE_OPERATION:
+					delete(inputStream, outputStream, buffer);
+					break;
+				default:
+					throw new IOException("Unknown operation " + operation);
+				}
+			}
+		}
+		catch (SocketException e) {
+			// this happens when the remote site closes the connection
+			LOG.debug("Socket connection closed", e);
+		}
+		catch (Throwable t) {
+			LOG.error("Error while executing BLOB connection.", t);
+		}
+		finally {
+			try {
+				if (clientSocket != null) {
+					clientSocket.close();
+				}
+			} catch (Throwable t) {
+				LOG.debug("Exception while closing BLOB server connection socket.", t);
+			}
+
+			blobServer.unregisterConnection(this);
+		}
+	}
+
+	/**
+	 * Closes the connection socket and lets the thread exit.
+	 */
+	public void close() {
+		closeSilently(clientSocket, LOG);
+		interrupt();
+	}
+
+	// --------------------------------------------------------------------------------------------
+	//  Actions
+	// --------------------------------------------------------------------------------------------
+
+	/**
+	 * Handles an incoming GET request from a BLOB client.
+	 * 
+	 * @param inputStream
+	 *        the input stream to read incoming data from
+	 * @param outputStream
+	 *        the output stream to send data back to the client
+	 * @param buf
+	 *        an auxiliary buffer for data serialization/deserialization
+	 * @throws IOException
+	 *         thrown if an I/O error occurs while reading/writing data from/to the respective streams
+	 */
+	private void get(InputStream inputStream, OutputStream outputStream, byte[] buf) throws IOException {
+
+		File blobFile;
+		try {
+			final int contentAdressable = inputStream.read();
+
+			if (contentAdressable < 0) {
+				throw new EOFException("Premature end of GET request");
+			}
+			if (contentAdressable == NAME_ADDRESSABLE) {
+				// Receive the job ID and key
+				byte[] jidBytes = new byte[JobID.SIZE];
+				readFully(inputStream, jidBytes, 0, JobID.SIZE, "JobID");
+
+				JobID jobID = JobID.fromByteArray(jidBytes);
+				String key = readKey(buf, inputStream);
+				blobFile = this.blobServer.getStorageLocation(jobID, key);
+			}
+			else if (contentAdressable == CONTENT_ADDRESSABLE) {
+				final BlobKey key = BlobKey.readFromInputStream(inputStream);
+				blobFile = blobServer.getStorageLocation(key);
+			}
+			else {
+				throw new IOException("Unknown type of BLOB addressing.");
+			}
+
+			// Check if BLOB exists
+			if (!blobFile.exists()) {
+				throw new IOException("Cannot find required BLOB at " + blobFile.getAbsolutePath());
+			}
+			if (blobFile.length() > Integer.MAX_VALUE) {
+				throw new IOException("BLOB size exceeds the maximum size (2 GB).");
+			}
+
+			outputStream.write(RETURN_OKAY);
+
+			// up to here, an error can give a good message
+		}
+		catch (Throwable t) {
+			LOG.error("GET operation failed", t);
+			try {
+				writeErrorToStream(outputStream, t);
+			}
+			catch (IOException e) {
+				// since we are in an exception case, it means not much that we could not send the error
+				// ignore this
+			}
+			clientSocket.close();
+			return;
+		}
+
+		// from here on, we started sending data, so all we can do is close the connection when something happens
+		try {
+			int blobLen = (int) blobFile.length();
+			writeLength(blobLen, outputStream);
+
+			FileInputStream fis = new FileInputStream(blobFile);
+			try {
+				int bytesRemaining = blobLen;
+				while (bytesRemaining > 0) {
+					int read = fis.read(buf);
+					if (read < 0) {
+						throw new IOException("Premature end of BLOB file stream for " + blobFile.getAbsolutePath());
+					}
+					outputStream.write(buf, 0, read);
+					bytesRemaining -= read;
+				}
+			} finally {
+				fis.close();
+			}
+		}
+		catch (SocketException e) {
+			// happens when the other side disconnects
+			LOG.debug("Socket connection closed", e);
+		}
+		catch (Throwable t) {
+			LOG.error("GET operation failed", t);
+			clientSocket.close();
+		}
+	}
+
+	/**
+	 * Handles an incoming PUT request from a BLOB client.
+	 * 
+	 * @param inputStream The input stream to read incoming data from.
+	 * @param outputStream The output stream to send data back to the client.
+	 * @param buf An auxiliary buffer for data serialization/deserialization.
+	 */
+	private void put(InputStream inputStream, OutputStream outputStream, byte[] buf) throws IOException {
+		JobID jobID = null;
+		String key = null;
+		MessageDigest md = null;
+
+		File incomingFile = null;
+		FileOutputStream fos = null;
+
+		try {
+			final int contentAdressable = inputStream.read();
+			if (contentAdressable < 0) {
+				throw new EOFException("Premature end of PUT request");
+			}
+
+			if (contentAdressable == NAME_ADDRESSABLE) {
+				// Receive the job ID and key
+				byte[] jidBytes = new byte[JobID.SIZE];
+				readFully(inputStream, jidBytes, 0, JobID.SIZE, "JobID");
+				jobID = JobID.fromByteArray(jidBytes);
+				key = readKey(buf, inputStream);
+			}
+			else if (contentAdressable == CONTENT_ADDRESSABLE) {
+				md = BlobUtils.createMessageDigest();
+			}
+			else {
+				throw new IOException("Unknown type of BLOB addressing.");
+			}
+
+			if (LOG.isDebugEnabled()) {
+				if (contentAdressable == NAME_ADDRESSABLE) {
+					LOG.debug(String.format("Received PUT request for BLOB under %s / \"%s\"", jobID, key));
+				} else {
+					LOG.debug("Received PUT request for content addressable BLOB");
+				}
+			}
+
+			incomingFile = blobServer.createTemporaryFilename();
+			fos = new FileOutputStream(incomingFile);
+
+			while (true) {
+				final int bytesExpected = readLength(inputStream);
+				if (bytesExpected == -1) {
+					// done
+					break;
+				}
+				if (bytesExpected > BUFFER_SIZE) {
+					throw new IOException("Unexpected number of incoming bytes: " + bytesExpected);
+				}
+
+				readFully(inputStream, buf, 0, bytesExpected, "buffer");
+				fos.write(buf, 0, bytesExpected);
+
+				if (md != null) {
+					md.update(buf, 0, bytesExpected);
+				}
+			}
+
+			fos.close();
+			fos = null;
+
+			if (contentAdressable == NAME_ADDRESSABLE) {
+				File storageFile = this.blobServer.getStorageLocation(jobID, key);
+				if (!incomingFile.renameTo(storageFile)) {
+					throw new IOException(String.format("Cannot move staging file %s to BLOB file %s",
+							incomingFile.getAbsolutePath(), storageFile.getAbsolutePath()));
+				}
+				incomingFile = null;
+				outputStream.write(RETURN_OKAY);
+			}
+			else {
+				BlobKey blobKey = new BlobKey(md.digest());
+				File storageFile = blobServer.getStorageLocation(blobKey);
+				if (!incomingFile.renameTo(storageFile)) {
+					throw new IOException(String.format("Cannot move staging file %s to BLOB file %s",
+							incomingFile.getAbsolutePath(), storageFile.getAbsolutePath()));
+				}
+				incomingFile = null;
+
+				// Return computed key to client for validation
+				outputStream.write(RETURN_OKAY);
+				blobKey.writeToOutputStream(outputStream);
+			}
+		}
+		catch (SocketException e) {
+			// happens when the other side disconnects
+			LOG.debug("Socket connection closed", e);
+		}
+		catch (Throwable t) {
+			LOG.error("PUT operation failed", t);
+			try {
+				writeErrorToStream(outputStream, t);
+			}
+			catch (IOException e) {
+				// since we are in an exception case, it means not much that we could not send the error
+				// ignore this
+			}
+			clientSocket.close();
+		}
+		finally {
+			if (fos != null) {
+				try {
+					fos.close();
+				} catch (Throwable t) {
+					LOG.warn("Cannot close stream to BLOB staging file", t);
+				}
+			}
+			if (incomingFile != null) {
+				if (!incomingFile.delete()) {
+					LOG.warn("Cannot delete BLOB server staging file " + incomingFile.getAbsolutePath());
+				}
+			}
+		}
+	}
+
+	/**
+	 * Handles an incoming DELETE request from a BLOB client.
+	 * 
+	 * @param inputStream The input stream to read the request from.
+	 * @param outputStream The output stream to write the response to.
+	 * @throws java.io.IOException Thrown if an I/O error occurs while reading the request data from the input stream.
+	 */
+	private void delete(InputStream inputStream, OutputStream outputStream, byte[] buf) throws IOException {
+
+		try {
+			int type = inputStream.read();
+			if (type < 0) {
+				throw new EOFException("Premature end of DELETE request");
+			}
+
+			if (type == CONTENT_ADDRESSABLE) {
+				BlobKey key = BlobKey.readFromInputStream(inputStream);
+				File blobFile = this.blobServer.getStorageLocation(key);
+				if (blobFile.exists() && !blobFile.delete()) {
+					throw new IOException("Cannot delete BLOB file " + blobFile.getAbsolutePath());
+				}
+			}
+			else if (type == NAME_ADDRESSABLE) {
+				byte[] jidBytes = new byte[JobID.SIZE];
+				readFully(inputStream, jidBytes, 0, JobID.SIZE, "JobID");
+				JobID jobID = JobID.fromByteArray(jidBytes);
+
+				String key = readKey(buf, inputStream);
+
+				File blobFile = this.blobServer.getStorageLocation(jobID, key);
+				if (blobFile.exists() && !blobFile.delete()) {
+					throw new IOException("Cannot delete BLOB file " + blobFile.getAbsolutePath());
+				}
+			}
+			else if (type == JOB_ID_SCOPE) {
+				byte[] jidBytes = new byte[JobID.SIZE];
+				readFully(inputStream, jidBytes, 0, JobID.SIZE, "JobID");
+				JobID jobID = JobID.fromByteArray(jidBytes);
+
+				blobServer.deleteJobDirectory(jobID);
+			}
+			else {
+				throw new IOException("Unrecognized addressing type: " + type);
+			}
+
+			outputStream.write(RETURN_OKAY);
+		}
+		catch (Throwable t) {
+			LOG.error("DELETE operation failed", t);
+			try {
+				writeErrorToStream(outputStream, t);
+			}
+			catch (IOException e) {
+				// since we are in an exception case, it means not much that we could not send the error
+				// ignore this
+			}
+			clientSocket.close();
+		}
+	}
+
+	// --------------------------------------------------------------------------------------------
+	//  Utilities
+	// --------------------------------------------------------------------------------------------
+
+	/**
+	 * Reads the key of a BLOB from the given input stream.
+	 * 
+	 * @param buf
+	 *        auxiliary buffer to data deserialization
+	 * @param inputStream
+	 *        the input stream to read the key from
+	 * @return the key of a BLOB
+	 * @throws IOException
+	 *         thrown if an I/O error occurs while reading the key data from the input stream
+	 */
+	private static String readKey(byte[] buf, InputStream inputStream) throws IOException {
+		final int keyLength = readLength(inputStream);
+		if (keyLength > MAX_KEY_LENGTH) {
+			throw new IOException("Unexpected key length " + keyLength);
+		}
+
+		readFully(inputStream, buf, 0, keyLength, "BlobKey");
+		return new String(buf, 0, keyLength, BlobUtils.DEFAULT_CHARSET);
+	}
+
+	/**
+	 * Writes to the output stream the error return code, and the given exception in serialized form.
+	 *
+	 * @param out Thr output stream to write to.
+	 * @param t The exception to send.
+	 * @throws IOException Thrown, if the output stream could not be written to.
+	 */
+	private static void writeErrorToStream(OutputStream out, Throwable t) throws IOException {
+		byte[] bytes = InstantiationUtil.serializeObject(t);
+		out.write(RETURN_ERROR);
+		writeLength(bytes.length, out);
+		out.write(bytes);
+	}
+}
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobServerProtocol.java b/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobServerProtocol.java
new file mode 100644
index 00000000000..6df78110b9a
--- /dev/null
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobServerProtocol.java
@@ -0,0 +1,59 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.flink.runtime.blob;
+
+public class BlobServerProtocol {
+
+	// --------------------------------------------------------------------------------------------
+	//  Constants used in the protocol of the BLOB store
+	// --------------------------------------------------------------------------------------------
+
+	/** The buffer size in bytes for network transfers. */
+	static final int BUFFER_SIZE = 65536; // 64 K
+
+	/** The maximum key length allowed for storing BLOBs. */
+	static final int MAX_KEY_LENGTH = 64;
+
+	/** Internal code to identify a PUT operation. */
+	static final byte PUT_OPERATION = 0;
+
+	/** Internal code to identify a GET operation. */
+	static final byte GET_OPERATION = 1;
+
+	/** Internal code to identify a DELETE operation. */
+	static final byte DELETE_OPERATION = 2;
+
+	/** Internal code to identify a successful operation. */
+	static final byte RETURN_OKAY = 0;
+
+	/** Internal code to identify an erroneous operation. */
+	static final byte RETURN_ERROR = 1;
+
+	/** Internal code to identify a reference via content hash as the key */
+	static final byte CONTENT_ADDRESSABLE = 0;
+
+	/** Internal code to identify a reference via jobId and name as the key */
+	static final byte NAME_ADDRESSABLE = 1;
+
+	/** Internal code to identify a reference via jobId as the key */
+	static final byte JOB_ID_SCOPE = 2;
+
+	// --------------------------------------------------------------------------------------------
+
+	private BlobServerProtocol() {}
+}
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobService.java b/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobService.java
index 148476f53c1..a2400b5579c 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobService.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobService.java
@@ -21,27 +21,32 @@ package org.apache.flink.runtime.blob;
 import java.io.IOException;
 import java.net.URL;
 
+/**
+ * A simple store and retrieve binary large objects (BLOBs).
+ */
 public interface BlobService {
+
 	/**
 	 * This method returns the URL of the file associated with the provided blob key.
 	 *
-	 * @param requiredBlob blob key associated with the requested file
-	 * @return URL of the file
+	 * @param key blob key associated with the requested file
+	 * @return The URL to the file.
 	 * @throws IOException
 	 */
-	URL getURL(final BlobKey requiredBlob) throws IOException;
+	URL getURL(BlobKey key) throws IOException;
+
 
 	/**
 	 * This method deletes the file associated with the provided blob key.
 	 *
-	 * @param blobKey associated with the file to be deleted
+	 * @param key associated with the file to be deleted
 	 * @throws IOException
 	 */
-	void delete(final BlobKey blobKey) throws IOException;
+	void delete(BlobKey key) throws IOException;
 
 	/**
-	 * Returns the port of the blob service
-	 * @return the port of the blob service
+	 * Returns the port of the blob service.
+	 * @return the port of the blob service.
 	 */
 	int getPort();
 
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobUtils.java b/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobUtils.java
index 53cab1ccaed..5db5ef6ff92 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobUtils.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/blob/BlobUtils.java
@@ -23,8 +23,12 @@ import org.apache.commons.io.FileUtils;
 import org.apache.flink.runtime.jobgraph.JobID;
 import org.slf4j.Logger;
 
+import java.io.EOFException;
 import java.io.File;
 import java.io.IOException;
+import java.io.InputStream;
+import java.io.OutputStream;
+import java.net.Socket;
 import java.nio.charset.Charset;
 import java.security.MessageDigest;
 import java.security.NoSuchAlgorithmException;
@@ -90,10 +94,13 @@ public class BlobUtils {
 	 * @return the BLOB server's directory for incoming files
 	 */
 	static File getIncomingDirectory(File storageDir) {
-		final File incomingDirectory = new File(storageDir, "incoming");
-		incomingDirectory.mkdir();
+		final File incomingDir = new File(storageDir, "incoming");
 
-		return incomingDirectory;
+		if (!incomingDir.exists() && !incomingDir.mkdir()) {
+			throw new RuntimeException("Cannot create directory for incoming files " + incomingDir.getAbsolutePath());
+		}
+
+		return incomingDir;
 	}
 
 	/**
@@ -106,7 +113,7 @@ public class BlobUtils {
 		final File cacheDirectory = new File(storageDir, "cache");
 
 		if (!cacheDirectory.exists() && !cacheDirectory.mkdir()) {
-			throw new RuntimeException("Could not create cache directory '" + cacheDirectory + "'.");
+			throw new RuntimeException("Could not create cache directory '" + cacheDirectory.getAbsolutePath() + "'.");
 		}
 
 		return cacheDirectory;
@@ -119,7 +126,7 @@ public class BlobUtils {
 	 *        the key identifying the BLOB
 	 * @return the (designated) physical storage location of the BLOB
 	 */
-	static File getStorageLocation(final File storageDir,  final BlobKey key) {
+	static File getStorageLocation(File storageDir, BlobKey key) {
 		return new File(getCacheDirectory(storageDir), BLOB_FILE_PREFIX + key.toString());
 	}
 
@@ -132,7 +139,7 @@ public class BlobUtils {
 	 *        the key of the BLOB
 	 * @return the (designated) physical storage location of the BLOB with the given job ID and key
 	 */
-	static File getStorageLocation(final File storageDir, final JobID jobID, final String key) {
+	static File getStorageLocation(File storageDir, JobID jobID, String key) {
 		return new File(getJobDirectory(storageDir, jobID), BLOB_FILE_PREFIX + encodeKey(key));
 	}
 
@@ -143,9 +150,12 @@ public class BlobUtils {
 	 *        the ID of the job to return the storage directory for
 	 * @return the storage directory for BLOBs belonging to the job with the given ID
 	 */
-	private static File getJobDirectory(final File storageDir, final JobID jobID){
+	private static File getJobDirectory(File storageDir, JobID jobID) {
 		final File jobDirectory = new File(storageDir, JOB_DIR_PREFIX + jobID.toString());
-		jobDirectory.mkdirs();
+
+		if (!jobDirectory.exists() && !jobDirectory.mkdirs()) {
+			throw new RuntimeException("Could not create jobId directory '" + jobDirectory.getAbsolutePath() + "'.");
+		}
 
 		return jobDirectory;
 	}
@@ -157,8 +167,7 @@ public class BlobUtils {
 	 *        the user's key for a BLOB
 	 * @return the internal name for the BLOB as used by the BLOB server
 	 */
-	private static String encodeKey(final String key) {
-
+	private static String encodeKey(String key) {
 		return BaseEncoding.base64().encode(key.getBytes(DEFAULT_CHARSET));
 	}
 
@@ -168,9 +177,8 @@ public class BlobUtils {
 	 * @param jobID
 	 *			jobID whose directory shall be deleted
 	 */
-	static void deleteJobDirectory(final File storageDir, final JobID jobID) throws IOException {
+	static void deleteJobDirectory(File storageDir, JobID jobID) throws IOException {
 		File directory = getJobDirectory(storageDir, jobID);
-
 		FileUtils.deleteDirectory(directory);
 	}
 
@@ -220,4 +228,94 @@ public class BlobUtils {
 			return null;
 		}
 	}
+
+	/**
+	 * Auxiliary method to write the length of an upcoming data chunk to an
+	 * output stream.
+	 *
+	 * @param length
+	 *        the length of the upcoming data chunk in bytes
+	 * @param outputStream
+	 *        the output stream to write the length to
+	 * @throws IOException
+	 *         thrown if an I/O error occurs while writing to the output
+	 *         stream
+	 */
+	static void writeLength(int length, OutputStream outputStream) throws IOException {
+		byte[] buf = new byte[4];
+		buf[0] = (byte) (length & 0xff);
+		buf[1] = (byte) ((length >> 8) & 0xff);
+		buf[2] = (byte) ((length >> 16) & 0xff);
+		buf[3] = (byte) ((length >> 24) & 0xff);
+		outputStream.write(buf, 0, 4);
+	}
+
+	/**
+	 * Auxiliary method to read the length of an upcoming data chunk from an
+	 * input stream.
+	 *
+	 * @param inputStream
+	 *        the input stream to read the length from
+	 * @return the length of the upcoming data chunk in bytes
+	 * @throws IOException
+	 *         thrown if an I/O error occurs while reading from the input
+	 *         stream
+	 */
+	static int readLength(InputStream inputStream) throws IOException {
+		byte[] buf = new byte[4];
+		int bytesRead = 0;
+		while (bytesRead < 4) {
+			final int read = inputStream.read(buf, bytesRead, 4 - bytesRead);
+			if (read < 0) {
+				throw new EOFException("Read an incomplete length");
+			}
+			bytesRead += read;
+		}
+
+		bytesRead = buf[0] & 0xff;
+		bytesRead |= (buf[1] & 0xff) << 8;
+		bytesRead |= (buf[2] & 0xff) << 16;
+		bytesRead |= (buf[3] & 0xff) << 24;
+
+		return bytesRead;
+	}
+
+	/**
+	 * Auxiliary method to read a particular number of bytes from an input stream. This method blocks until the
+	 * requested number of bytes have been read from the stream. If the stream cannot offer enough data, an
+	 * {@link EOFException} is thrown.
+	 *
+	 * @param inputStream The input stream to read the data from.
+	 * @param buf The buffer to store the read data.
+	 * @param off The offset inside the buffer.
+	 * @param len The number of bytes to read from the stream.
+	 * @param type The name of the type, to throw a good error message in case of not enough data.
+	 * @throws IOException
+	 *         Thrown if I/O error occurs while reading from the stream or the stream cannot offer enough data.
+	 */
+	static void readFully(InputStream inputStream, byte[] buf, int off, int len, String type) throws IOException {
+
+		int bytesRead = 0;
+		while (bytesRead < len) {
+
+			final int read = inputStream.read(buf, off + bytesRead, len
+					- bytesRead);
+			if (read < 0) {
+				throw new EOFException("Received an incomplete " + type);
+			}
+			bytesRead += read;
+		}
+	}
+
+	static void closeSilently(Socket socket, Logger LOG) {
+		if (socket != null) {
+			try {
+				socket.close();
+			} catch (Throwable t) {
+				if (LOG.isDebugEnabled()) {
+					LOG.debug("Error while closing resource after BLOB transfer.", t);
+				}
+			}
+		}
+	}
 }
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/AbstractIDTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/AbstractIDTest.java
index 7f7575b8b26..ba9add588f5 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/AbstractIDTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/AbstractIDTest.java
@@ -22,10 +22,13 @@ import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
+import org.apache.flink.runtime.jobgraph.JobID;
 import org.junit.Test;
 
 import org.apache.flink.runtime.testutils.CommonTestUtils;
 
+import java.nio.ByteBuffer;
+
 /**
  * This class contains tests for the {@link org.apache.flink.runtime.AbstractID} class.
  */
@@ -48,6 +51,45 @@ public class AbstractIDTest {
 			fail(e.getMessage());
 		}
 	}
+
+	@Test
+	public void testConvertToBytes() {
+		try {
+			AbstractID origID = new AbstractID();
+
+			AbstractID copy1 = new AbstractID(origID);
+			AbstractID copy2 = new AbstractID(origID.getBytes());
+			AbstractID copy3 = new AbstractID(origID.getLowerPart(), origID.getUpperPart());
+
+			assertEquals(origID, copy1);
+			assertEquals(origID, copy2);
+			assertEquals(origID, copy3);
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+	}
+
+	@Test
+	public void testConvertToByteBuffer() {
+		try {
+			JobID origID = new JobID();
+
+			byte[] bytes = origID.getBytes();
+			ByteBuffer buffer = ByteBuffer.wrap(bytes);
+
+			JobID copy1 = JobID.fromByteBuffer(buffer);
+			JobID copy2 = JobID.fromByteArray(bytes);
+
+			assertEquals(origID, copy1);
+			assertEquals(origID, copy2);
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+	}
 	
 	@Test
 	public void testCompare() {
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobCacheRetriesTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobCacheRetriesTest.java
new file mode 100644
index 00000000000..aba0afffb85
--- /dev/null
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobCacheRetriesTest.java
@@ -0,0 +1,150 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.runtime.blob;
+
+import org.apache.flink.configuration.Configuration;
+import org.junit.Test;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.net.InetSocketAddress;
+import java.net.URL;
+
+import static org.junit.Assert.*;
+
+/**
+ * Unit tests for the blob cache retrying the connection to the server.
+ */
+public class BlobCacheRetriesTest {
+
+	/**
+	 * A test where the connection fails twice and then the get operation succeeds.
+	 */
+	@Test
+	public void testBlobFetchRetries() {
+
+		final byte[] data = new byte[] {1, 2, 3, 4, 5, 6, 7, 8, 9, 0};
+
+		BlobServer server = null;
+		BlobCache cache = null;
+		try {
+			final Configuration config = new Configuration();
+
+			server = new TestingFailingBlobServer(config, 2);
+
+			final InetSocketAddress serverAddress = new InetSocketAddress("localhost", server.getPort());
+
+			// upload some blob
+			BlobClient blobClient = null;
+			BlobKey key;
+			try {
+				blobClient = new BlobClient(serverAddress);
+
+				key = blobClient.put(data);
+			}
+			finally {
+				if (blobClient != null) {
+					blobClient.close();
+				}
+			}
+
+			cache = new BlobCache(serverAddress, config);
+
+			// trigger a download - it should fail on the first time, but retry, and succeed at the second time
+			URL url = cache.getURL(key);
+			InputStream is = url.openStream();
+			try {
+				byte[] received = new byte[data.length];
+				assertEquals(data.length, is.read(received));
+				assertArrayEquals(data, received);
+			}
+			finally {
+				is.close();
+			}
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+		finally {
+			if (cache != null) {
+				cache.shutdown();
+			}
+			if (server != null) {
+				server.shutdown();
+			}
+		}
+	}
+
+	/**
+	 * A test where the connection fails too often and eventually fails the GET request.
+	 */
+	@Test
+	public void testBlobFetchWithTooManyFailures() {
+
+		final byte[] data = new byte[] { 1, 2, 3, 4, 5, 6, 7, 8, 9, 0 };
+
+		BlobServer server = null;
+		BlobCache cache = null;
+		try {
+			final Configuration config = new Configuration();
+
+			server = new TestingFailingBlobServer(config, 10);
+
+			final InetSocketAddress serverAddress = new InetSocketAddress("localhost", server.getPort());
+
+			// upload some blob
+			BlobClient blobClient = null;
+			BlobKey key;
+			try {
+				blobClient = new BlobClient(serverAddress);
+
+				key = blobClient.put(data);
+			}
+			finally {
+				if (blobClient != null) {
+					blobClient.close();
+				}
+			}
+
+			cache = new BlobCache(serverAddress, config);
+
+			// trigger a download - it should fail eventually
+			try {
+				cache.getURL(key);
+				fail("This should fail");
+			}
+			catch (IOException e) {
+				// as we expected
+			}
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+		finally {
+			if (cache != null) {
+				cache.shutdown();
+			}
+			if (server != null) {
+				server.shutdown();
+			}
+		}
+	}
+}
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobCacheTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobCacheSuccessTest.java
similarity index 94%
rename from flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobCacheTest.java
rename to flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobCacheSuccessTest.java
index 32c8c3a2c41..4b92b717352 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobCacheTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobCacheSuccessTest.java
@@ -24,7 +24,6 @@ import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 import java.io.File;
-import java.io.IOException;
 import java.net.InetSocketAddress;
 import java.net.URISyntaxException;
 import java.net.URL;
@@ -37,7 +36,7 @@ import org.junit.Test;
 /**
  * This class contains unit tests for the {@link BlobCache}.
  */
-public class BlobCacheTest {
+public class BlobCacheSuccessTest {
 
 	@Test
 	public void testBlobCache() {
@@ -52,7 +51,7 @@ public class BlobCacheTest {
 
 			// Start the BLOB server
 			blobServer = new BlobServer(new Configuration());
-			final InetSocketAddress serverAddress = new InetSocketAddress(blobServer.getServerPort());
+			final InetSocketAddress serverAddress = new InetSocketAddress(blobServer.getPort());
 
 			// Upload BLOBs
 			BlobClient blobClient = null;
@@ -103,12 +102,13 @@ public class BlobCacheTest {
 				} catch (URISyntaxException e) {
 					fail(e.getMessage());
 				}
-
 			}
-
-		} catch (IOException ioe) {
-			fail(ioe.getMessage());
-		} finally {
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+		finally {
 			if (blobServer != null) {
 				blobServer.shutdown();
 			}
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobClientTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobClientTest.java
index 146577772a9..2254d7c0594 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobClientTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobClientTest.java
@@ -24,7 +24,6 @@ import static org.junit.Assert.fail;
 import java.io.EOFException;
 import java.io.File;
 import java.io.FileInputStream;
-import java.io.FileNotFoundException;
 import java.io.FileOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
@@ -33,7 +32,6 @@ import java.security.MessageDigest;
 
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.runtime.jobgraph.JobID;
-import org.apache.flink.util.StringUtils;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 import org.junit.Test;
@@ -43,14 +41,10 @@ import org.junit.Test;
  */
 public class BlobClientTest {
 
-	/**
-	 * The buffer size used during the tests in bytes.
-	 */
+	/** The buffer size used during the tests in bytes. */
 	private static final int TEST_BUFFER_SIZE = 17 * 1000;
 
-	/**
-	 * The instance of the BLOB server used during the tests.
-	 */
+	/** The instance of the BLOB server used during the tests. */
 	private static BlobServer BLOB_SERVER;
 
 	/**
@@ -60,10 +54,11 @@ public class BlobClientTest {
 	public static void startServer() {
 		try {
 			BLOB_SERVER = new BlobServer(new Configuration());
-		} catch (IOException ioe) {
-			fail(StringUtils.stringifyException(ioe));
 		}
-
+		catch (IOException e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
 	}
 
 	/**
@@ -82,13 +77,10 @@ public class BlobClientTest {
 	 * @return a test buffer filled with a specific byte pattern
 	 */
 	private static byte[] createTestBuffer() {
-
 		final byte[] buf = new byte[TEST_BUFFER_SIZE];
-
 		for (int i = 0; i < buf.length; ++i) {
 			buf[i] = (byte) (i % 128);
 		}
-
 		return buf;
 	}
 
@@ -102,7 +94,7 @@ public class BlobClientTest {
 	 * @throws IOException
 	 *         thrown if an I/O error occurs while writing to the test file
 	 */
-	private static BlobKey prepareTestFile(final File file) throws IOException {
+	private static BlobKey prepareTestFile(File file) throws IOException {
 
 		MessageDigest md = BlobUtils.createMessageDigest();
 
@@ -203,44 +195,44 @@ public class BlobClientTest {
 	@Test
 	public void testContentAddressableBuffer() {
 
-		final byte[] testBuffer = createTestBuffer();
-		final MessageDigest md = BlobUtils.createMessageDigest();
-		md.update(testBuffer);
-		final BlobKey origKey = new BlobKey(md.digest());
+		BlobClient client = null;
 
 		try {
+			byte[] testBuffer = createTestBuffer();
+			MessageDigest md = BlobUtils.createMessageDigest();
+			md.update(testBuffer);
+			BlobKey origKey = new BlobKey(md.digest());
 
-			BlobClient client = null;
-			try {
+			InetSocketAddress serverAddress = new InetSocketAddress("localhost", BLOB_SERVER.getPort());
+			client = new BlobClient(serverAddress);
 
-				final InetSocketAddress serverAddress = new InetSocketAddress("localhost", BLOB_SERVER.getServerPort());
-				client = new BlobClient(serverAddress);
+			// Store the data
+			BlobKey receivedKey = client.put(testBuffer);
+			assertEquals(origKey, receivedKey);
 
-				// Store the data
-				final BlobKey receivedKey = client.put(testBuffer);
-				assertEquals(origKey, receivedKey);
+			// Retrieve the data
+			InputStream is = client.get(receivedKey);
+			validateGet(is, testBuffer);
 
-				// Retrieve the data
-				final InputStream is = client.get(receivedKey);
-				validateGet(is, testBuffer);
-
-				// Check reaction to invalid keys
+			// Check reaction to invalid keys
+			try {
+				client.get(new BlobKey());
+				fail("Expected IOException did not occur");
+			}
+			catch (IOException fnfe) {
+				// expected
+			}
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+		finally {
+			if (client != null) {
 				try {
-					client.get(new BlobKey());
-				} catch (FileNotFoundException fnfe) {
-					return;
-				}
-
-				fail("Expected FileNotFoundException did not occur");
-
-			} finally {
-				if (client != null) {
 					client.close();
-				}
+				} catch (Throwable t) {}
 			}
-
-		} catch (IOException ioe) {
-			fail(StringUtils.stringifyException(ioe));
 		}
 	}
 
@@ -250,42 +242,45 @@ public class BlobClientTest {
 	@Test
 	public void testContentAddressableStream() {
 
-		try {
+		BlobClient client = null;
+		InputStream is = null;
 
-			final File testFile = File.createTempFile("testfile", ".dat");
+		try {
+			File testFile = File.createTempFile("testfile", ".dat");
 			testFile.deleteOnExit();
-			final BlobKey origKey = prepareTestFile(testFile);
 
-			BlobClient client = null;
-			InputStream is = null;
-			try {
-
-				final InetSocketAddress serverAddress = new InetSocketAddress("localhost", BLOB_SERVER.getServerPort());
-				client = new BlobClient(serverAddress);
+			BlobKey origKey = prepareTestFile(testFile);
 
-				// Store the data
-				is = new FileInputStream(testFile);
-				final BlobKey receivedKey = client.put(is);
-				assertEquals(origKey, receivedKey);
+			InetSocketAddress serverAddress = new InetSocketAddress("localhost", BLOB_SERVER.getPort());
+			client = new BlobClient(serverAddress);
 
-				is.close();
-				is = null;
+			// Store the data
+			is = new FileInputStream(testFile);
+			BlobKey receivedKey = client.put(is);
+			assertEquals(origKey, receivedKey);
 
-				// Retrieve the data
-				is = client.get(receivedKey);
-				validateGet(is, testFile);
+			is.close();
+			is = null;
 
-			} finally {
-				if (is != null) {
+			// Retrieve the data
+			is = client.get(receivedKey);
+			validateGet(is, testFile);
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+		finally {
+			if (is != null) {
+				try {
 					is.close();
-				}
-				if (client != null) {
+				} catch (Throwable t) {}
+			}
+			if (client != null) {
+				try {
 					client.close();
-				}
+				} catch (Throwable t) {}
 			}
-
-		} catch (IOException ioe) {
-			fail(StringUtils.stringifyException(ioe));
 		}
 	}
 
@@ -300,11 +295,9 @@ public class BlobClientTest {
 		final String key = "testkey";
 
 		try {
-
 			BlobClient client = null;
 			try {
-
-				final InetSocketAddress serverAddress = new InetSocketAddress("localhost", BLOB_SERVER.getServerPort());
+				final InetSocketAddress serverAddress = new InetSocketAddress("localhost", BLOB_SERVER.getPort());
 				client = new BlobClient(serverAddress);
 
 				// Store the data
@@ -320,20 +313,21 @@ public class BlobClientTest {
 				// Check if the BLOB is still available
 				try {
 					client.get(jobID, key);
-				} catch (FileNotFoundException fnfe) {
-					return;
+					fail("Expected IOException did not occur");
 				}
-
-				fail("Expected FileNotFoundException did not occur");
-
-			} finally {
+				catch (IOException e) {
+					// expected
+				}
+			}
+			finally {
 				if (client != null) {
 					client.close();
 				}
 			}
-
-		} catch (IOException ioe) {
-			fail(StringUtils.stringifyException(ioe));
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
 		}
 	}
 
@@ -355,7 +349,7 @@ public class BlobClientTest {
 			InputStream is = null;
 			try {
 
-				final InetSocketAddress serverAddress = new InetSocketAddress("localhost", BLOB_SERVER.getServerPort());
+				final InetSocketAddress serverAddress = new InetSocketAddress("localhost", BLOB_SERVER.getPort());
 				client = new BlobClient(serverAddress);
 
 				// Store the data
@@ -369,7 +363,8 @@ public class BlobClientTest {
 				is = client.get(jobID, key);
 				validateGet(is, testFile);
 
-			} finally {
+			}
+			finally {
 				if (is != null) {
 					is.close();
 				}
@@ -378,8 +373,10 @@ public class BlobClientTest {
 				}
 			}
 
-		} catch (IOException ioe) {
-			fail(StringUtils.stringifyException(ioe));
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
 		}
 	}
 }
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobServerDeleteTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobServerDeleteTest.java
new file mode 100644
index 00000000000..adb3bfc710f
--- /dev/null
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobServerDeleteTest.java
@@ -0,0 +1,323 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.runtime.blob;
+
+import org.apache.flink.configuration.Configuration;
+import org.apache.flink.runtime.jobgraph.JobID;
+import org.junit.Test;
+
+import java.io.File;
+import java.io.IOException;
+import java.net.InetSocketAddress;
+import java.util.Random;
+
+import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.fail;
+
+/**
+ * Tests how DELETE requests behave.
+ */
+public class BlobServerDeleteTest {
+
+	private final Random rnd = new Random();
+
+	@Test
+	public void testDeleteSingle() {
+		BlobServer server = null;
+		BlobClient client = null;
+
+		try {
+			Configuration config = new Configuration();
+			server = new BlobServer(config);
+
+			InetSocketAddress serverAddress = new InetSocketAddress("localhost", server.getPort());
+			client = new BlobClient(serverAddress);
+
+			byte[] data = new byte[2000000];
+			rnd.nextBytes(data);
+
+			// put content addressable (like libraries)
+			BlobKey key = client.put(data);
+			assertNotNull(key);
+
+			// issue a DELETE request
+			client.delete(key);
+			client.close();
+
+			client = new BlobClient(serverAddress);
+			try {
+				client.get(key);
+				fail("BLOB should have been deleted");
+			}
+			catch (IOException e) {
+				// expected
+			}
+
+			try {
+				client.put(new byte[1]);
+				fail("client should be closed after erroneous operation");
+			}
+			catch (IllegalStateException e) {
+				// expected
+			}
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+		finally {
+			if (client != null) {
+				try {
+					client.close();
+				} catch (Throwable t) {
+					t.printStackTrace();
+				}
+			}
+			if (server != null) {
+				server.shutdown();
+			}
+		}
+	}
+
+	@Test
+	public void testDeleteAll() {
+		BlobServer server = null;
+		BlobClient client = null;
+
+		try {
+			Configuration config = new Configuration();
+			server = new BlobServer(config);
+
+			InetSocketAddress serverAddress = new InetSocketAddress("localhost", server.getPort());
+			client = new BlobClient(serverAddress);
+
+			byte[] data = new byte[2000000];
+			rnd.nextBytes(data);
+
+			JobID jobID = new JobID();
+			String name1 = "random name";
+			String name2 = "any nyme";
+
+			// put content addressable (like libraries)
+			client.put(jobID, name1, data);
+			client.put(jobID, name2, new byte[712]);
+
+
+			// issue a DELETE ALL request
+			client.deleteAll(jobID);
+			client.close();
+
+			client = new BlobClient(serverAddress);
+			try {
+				client.get(jobID, name1);
+				fail("BLOB should have been deleted");
+			}
+			catch (IOException e) {
+				// expected
+			}
+
+			try {
+				client.put(new byte[1]);
+				fail("client should be closed after erroneous operation");
+			}
+			catch (IllegalStateException e) {
+				// expected
+			}
+
+			client = new BlobClient(serverAddress);
+			try {
+				client.get(jobID, name2);
+				fail("BLOB should have been deleted");
+			}
+			catch (IOException e) {
+				// expected
+			}
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+		finally {
+			if (client != null) {
+				try {
+					client.close();
+				} catch (Throwable t) {
+					t.printStackTrace();
+				}
+			}
+			if (server != null) {
+				server.shutdown();
+			}
+		}
+	}
+
+	@Test
+	public void testDeleteAlreadyDeletedByBlobKey() {
+		BlobServer server = null;
+		BlobClient client = null;
+
+		try {
+			Configuration config = new Configuration();
+			server = new BlobServer(config);
+
+			InetSocketAddress serverAddress = new InetSocketAddress("localhost", server.getPort());
+			client = new BlobClient(serverAddress);
+
+			byte[] data = new byte[2000000];
+			rnd.nextBytes(data);
+
+			// put content addressable (like libraries)
+			BlobKey key = client.put(data);
+			assertNotNull(key);
+
+			File blobFile = server.getStorageLocation(key);
+			assertTrue(blobFile.delete());
+
+			// issue a DELETE request
+			try {
+				client.delete(key);
+			}
+			catch (IOException e) {
+				fail("DELETE operation should not fail if file is already deleted");
+			}
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+		finally {
+			if (client != null) {
+				try {
+					client.close();
+				} catch (Throwable t) {
+					t.printStackTrace();
+				}
+			}
+			if (server != null) {
+				server.shutdown();
+			}
+		}
+	}
+
+	@Test
+	public void testDeleteAlreadyDeletedByName() {
+		BlobServer server = null;
+		BlobClient client = null;
+
+		try {
+			Configuration config = new Configuration();
+			server = new BlobServer(config);
+
+			InetSocketAddress serverAddress = new InetSocketAddress("localhost", server.getPort());
+			client = new BlobClient(serverAddress);
+
+			byte[] data = new byte[2000000];
+			rnd.nextBytes(data);
+
+			JobID jid = new JobID();
+			String name = "------------fdghljEgRJHF+##4U789Q345";
+
+			client.put(jid, name, data);
+
+			File blobFile = server.getStorageLocation(jid, name);
+			assertTrue(blobFile.delete());
+
+			// issue a DELETE request
+			try {
+				client.delete(jid, name);
+			}
+			catch (IOException e) {
+				fail("DELETE operation should not fail if file is already deleted");
+			}
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+		finally {
+			if (client != null) {
+				try {
+					client.close();
+				} catch (Throwable t) {
+					t.printStackTrace();
+				}
+			}
+			if (server != null) {
+				server.shutdown();
+			}
+		}
+	}
+
+	@Test
+	public void testDeleteFails() {
+		BlobServer server = null;
+		BlobClient client = null;
+
+		try {
+			Configuration config = new Configuration();
+			server = new BlobServer(config);
+
+			InetSocketAddress serverAddress = new InetSocketAddress("localhost", server.getPort());
+			client = new BlobClient(serverAddress);
+
+			byte[] data = new byte[2000000];
+			rnd.nextBytes(data);
+
+			// put content addressable (like libraries)
+			BlobKey key = client.put(data);
+			assertNotNull(key);
+
+			File blobFile = server.getStorageLocation(key);
+			File directory = blobFile.getParentFile();
+
+			assertTrue(blobFile.setWritable(false, false));
+			assertTrue(directory.setWritable(false, false));
+
+			// issue a DELETE request
+			try {
+				client.delete(key);
+				fail("DELETE operation should fail if file cannot be deleted");
+			}
+			catch (IOException e) {
+				// expected
+			}
+			finally {
+				blobFile.setWritable(true, false);
+				directory.setWritable(true, false);
+			}
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+		finally {
+			if (client != null) {
+				try {
+					client.close();
+				} catch (Throwable t) {
+					t.printStackTrace();
+				}
+			}
+			if (server != null) {
+				server.shutdown();
+			}
+		}
+	}
+}
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobServerGetTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobServerGetTest.java
new file mode 100644
index 00000000000..c564670cec0
--- /dev/null
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobServerGetTest.java
@@ -0,0 +1,149 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.runtime.blob;
+
+import org.apache.flink.configuration.Configuration;
+import org.junit.Test;
+
+import java.io.File;
+import java.io.IOException;
+
+import java.io.InputStream;
+import java.net.InetSocketAddress;
+import java.util.Random;
+
+import static org.junit.Assert.*;
+
+/**
+ * Tests how failing GET requests behave in the presence of failures.
+ * Successful GET requests are tested in conjunction wit the PUT
+ * requests.
+ */
+public class BlobServerGetTest {
+
+	private final Random rnd = new Random();
+
+	@Test
+	public void testGetFailsDuringLookup() {
+		BlobServer server = null;
+		BlobClient client = null;
+
+		try {
+			Configuration config = new Configuration();
+			server = new BlobServer(config);
+
+			InetSocketAddress serverAddress = new InetSocketAddress("localhost", server.getPort());
+			client = new BlobClient(serverAddress);
+
+			byte[] data = new byte[2000000];
+			rnd.nextBytes(data);
+
+			// put content addressable (like libraries)
+			BlobKey key = client.put(data);
+			assertNotNull(key);
+
+			// delete all files to make sure that GET requests fail
+			File blobFile = server.getStorageLocation(key);
+			assertTrue(blobFile.delete());
+
+			// issue a GET request that fails
+			try {
+				client.get(key);
+				fail("This should not succeed.");
+			}
+			catch (IOException e) {
+				// expected
+			}
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+		finally {
+			if (client != null) {
+				try {
+					client.close();
+				} catch (Throwable t) {
+					t.printStackTrace();
+				}
+			}
+			if (server != null) {
+				server.shutdown();
+			}
+		}
+	}
+
+	@Test
+	public void testGetFailsDuringStreaming() {
+		BlobServer server = null;
+		BlobClient client = null;
+
+		try {
+			Configuration config = new Configuration();
+			server = new BlobServer(config);
+
+			InetSocketAddress serverAddress = new InetSocketAddress("localhost", server.getPort());
+			client = new BlobClient(serverAddress);
+
+			byte[] data = new byte[5000000];
+			rnd.nextBytes(data);
+
+			// put content addressable (like libraries)
+			BlobKey key = client.put(data);
+			assertNotNull(key);
+
+			// issue a GET request that succeeds
+			InputStream is = client.get(key);
+
+			byte[] receiveBuffer = new byte[50000];
+			BlobUtils.readFully(is, receiveBuffer, 0, receiveBuffer.length, null);
+			BlobUtils.readFully(is, receiveBuffer, 0, receiveBuffer.length, null);
+
+			// shut down the server
+			for (BlobServerConnection conn : server.getCurrentyActiveConnections()) {
+				conn.close();
+			}
+
+			try {
+				byte[] remainder = new byte[data.length - 2*receiveBuffer.length];
+				BlobUtils.readFully(is, remainder, 0, remainder.length, null);
+				fail();
+			}
+			catch (IOException e) {
+				// expected
+			}
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+		finally {
+			if (client != null) {
+				try {
+					client.close();
+				} catch (Throwable t) {
+					t.printStackTrace();
+				}
+			}
+			if (server != null) {
+				server.shutdown();
+			}
+		}
+	}
+}
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobServerPutTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobServerPutTest.java
new file mode 100644
index 00000000000..1f8d29bc66a
--- /dev/null
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/blob/BlobServerPutTest.java
@@ -0,0 +1,402 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.runtime.blob;
+
+import org.apache.flink.configuration.Configuration;
+import org.apache.flink.runtime.jobgraph.JobID;
+import org.junit.Test;
+
+import java.io.ByteArrayInputStream;
+import java.io.File;
+import java.io.IOException;
+import java.io.InputStream;
+import java.net.InetSocketAddress;
+import java.util.Random;
+
+import static org.junit.Assert.*;
+
+/**
+ * Tests for successful and failing PUT operations against the BLOB server,
+ * and successful GET operations.
+ */
+public class BlobServerPutTest {
+
+	private final Random rnd = new Random();
+
+	@Test
+	public void testPutBufferSuccessful() {
+		BlobServer server = null;
+		BlobClient client = null;
+
+		try {
+			Configuration config = new Configuration();
+			server = new BlobServer(config);
+
+			InetSocketAddress serverAddress = new InetSocketAddress("localhost", server.getPort());
+			client = new BlobClient(serverAddress);
+
+			byte[] data = new byte[2000000];
+			rnd.nextBytes(data);
+
+			// put content addressable (like libraries)
+			BlobKey key1 = client.put(data);
+			assertNotNull(key1);
+
+			BlobKey key2 = client.put(data, 10, 44);
+			assertNotNull(key2);
+
+			// put under job and name scope
+			JobID jid = new JobID();
+			String stringKey = "my test key";
+			client.put(jid, stringKey, data);
+
+			// --- GET the data and check that it is equal ---
+
+			// one get request on the same client
+			InputStream is1 = client.get(key2);
+			byte[] result1 = new byte[44];
+			BlobUtils.readFully(is1, result1, 0, result1.length, null);
+			is1.close();
+
+			for (int i = 0, j = 10; i < result1.length; i++, j++) {
+				assertEquals(data[j], result1[i]);
+			}
+
+			// close the client and create a new one for the remaining requests
+			client.close();
+			client = new BlobClient(serverAddress);
+
+			InputStream is2 = client.get(key1);
+			byte[] result2 = new byte[data.length];
+			BlobUtils.readFully(is2, result2, 0, result2.length, null);
+			is2.close();
+			assertArrayEquals(data, result2);
+
+			InputStream is3 = client.get(jid, stringKey);
+			byte[] result3 = new byte[data.length];
+			BlobUtils.readFully(is3, result3, 0, result3.length, null);
+			is3.close();
+			assertArrayEquals(data, result3);
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+		finally {
+			if (client != null) {
+				try {
+					client.close();
+				} catch (Throwable t) {
+					t.printStackTrace();
+				}
+			}
+			if (server != null) {
+				server.shutdown();
+			}
+		}
+	}
+
+
+	@Test
+	public void testPutStreamSuccessful() {
+		BlobServer server = null;
+		BlobClient client = null;
+
+		try {
+			Configuration config = new Configuration();
+			server = new BlobServer(config);
+
+			InetSocketAddress serverAddress = new InetSocketAddress("localhost", server.getPort());
+			client = new BlobClient(serverAddress);
+
+			byte[] data = new byte[2000000];
+			rnd.nextBytes(data);
+
+			// put content addressable (like libraries)
+			{
+				BlobKey key1 = client.put(new ByteArrayInputStream(data));
+				assertNotNull(key1);
+
+			}
+
+			// put under job and name scope
+			{
+				JobID jid = new JobID();
+				String stringKey = "my test key";
+				client.put(jid, stringKey, new ByteArrayInputStream(data));
+			}
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+		finally {
+			if (client != null) {
+				try {
+					client.close();
+				} catch (Throwable t) {
+					t.printStackTrace();
+				}
+			}
+			if (server != null) {
+				server.shutdown();
+			}
+		}
+	}
+
+	@Test
+	public void testPutChunkedStreamSuccessful() {
+		BlobServer server = null;
+		BlobClient client = null;
+
+		try {
+			Configuration config = new Configuration();
+			server = new BlobServer(config);
+
+			InetSocketAddress serverAddress = new InetSocketAddress("localhost", server.getPort());
+			client = new BlobClient(serverAddress);
+
+			byte[] data = new byte[2000000];
+			rnd.nextBytes(data);
+
+			// put content addressable (like libraries)
+			{
+				BlobKey key1 = client.put(new ChunkedInputStream(data, 19));
+				assertNotNull(key1);
+
+			}
+
+			// put under job and name scope
+			{
+				JobID jid = new JobID();
+				String stringKey = "my test key";
+				client.put(jid, stringKey, new ChunkedInputStream(data, 17));
+			}
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+		finally {
+			if (client != null) {
+				try {
+					client.close();
+				} catch (Throwable t) {
+					t.printStackTrace();
+				}
+			}
+			if (server != null) {
+				server.shutdown();
+			}
+		}
+	}
+
+	@Test
+	public void testPutBufferFails() {
+		BlobServer server = null;
+		BlobClient client = null;
+
+		File tempFileDir = null;
+		try {
+			Configuration config = new Configuration();
+			server = new BlobServer(config);
+
+			// make sure the blob server cannot create any files in its storage dir
+			tempFileDir = server.createTemporaryFilename().getParentFile().getParentFile();
+			assertTrue(tempFileDir.setExecutable(true, false));
+			assertTrue(tempFileDir.setReadable(true, false));
+			assertTrue(tempFileDir.setWritable(false, false));
+
+			InetSocketAddress serverAddress = new InetSocketAddress("localhost", server.getPort());
+			client = new BlobClient(serverAddress);
+
+			byte[] data = new byte[2000000];
+			rnd.nextBytes(data);
+
+			// put content addressable (like libraries)
+			try {
+				client.put(data);
+				fail("This should fail.");
+			}
+			catch (IOException e) {
+				assertTrue(e.getMessage(), e.getMessage().contains("Server side error"));
+			}
+
+			try {
+				client.put(data);
+				fail("Client should be closed");
+			}
+			catch (IllegalStateException e) {
+				// expected
+			}
+
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+		finally {
+			// set writable again to make sure we can remove the directory
+			if (tempFileDir != null) {
+				tempFileDir.setWritable(true, false);
+			}
+			if (client != null) {
+				try {
+					client.close();
+				} catch (Throwable t) {
+					t.printStackTrace();
+				}
+			}
+			if (server != null) {
+				server.shutdown();
+			}
+		}
+	}
+
+	@Test
+	public void testPutNamedBufferFails() {
+		BlobServer server = null;
+		BlobClient client = null;
+
+		File tempFileDir = null;
+		try {
+			Configuration config = new Configuration();
+			server = new BlobServer(config);
+
+			// make sure the blob server cannot create any files in its storage dir
+			tempFileDir = server.createTemporaryFilename().getParentFile().getParentFile();
+			assertTrue(tempFileDir.setExecutable(true, false));
+			assertTrue(tempFileDir.setReadable(true, false));
+			assertTrue(tempFileDir.setWritable(false, false));
+
+			InetSocketAddress serverAddress = new InetSocketAddress("localhost", server.getPort());
+			client = new BlobClient(serverAddress);
+
+			byte[] data = new byte[2000000];
+			rnd.nextBytes(data);
+
+			// put under job and name scope
+			try {
+				JobID jid = new JobID();
+				String stringKey = "my test key";
+				client.put(jid, stringKey, data);
+				fail("This should fail.");
+			}
+			catch (IOException e) {
+				assertTrue(e.getMessage(), e.getMessage().contains("Server side error"));
+			}
+
+			try {
+				JobID jid = new JobID();
+				String stringKey = "another key";
+				client.put(jid, stringKey, data);
+				fail("Client should be closed");
+			}
+			catch (IllegalStateException e) {
+				// expected
+			}
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+		finally {
+			// set writable again to make sure we can remove the directory
+			if (tempFileDir != null) {
+				tempFileDir.setWritable(true, false);
+			}
+			if (client != null) {
+				try {
+					client.close();
+				} catch (Throwable t) {
+					t.printStackTrace();
+				}
+			}
+			if (server != null) {
+				server.shutdown();
+			}
+		}
+	}
+
+	// --------------------------------------------------------------------------------------------
+
+	private static final class ChunkedInputStream extends InputStream {
+
+		private final byte[][] data;
+
+		private int x = 0, y = 0;
+
+
+		private ChunkedInputStream(byte[] data, int numChunks) {
+			this.data = new byte[numChunks][];
+
+			int bytesPerChunk = data.length / numChunks;
+			int bytesTaken = 0;
+			for (int i = 0; i < numChunks - 1; i++, bytesTaken += bytesPerChunk) {
+				this.data[i] = new byte[bytesPerChunk];
+				System.arraycopy(data, bytesTaken, this.data[i], 0, bytesPerChunk);
+			}
+
+			this.data[numChunks -  1] = new byte[data.length - bytesTaken];
+			System.arraycopy(data, bytesTaken, this.data[numChunks -  1], 0, this.data[numChunks -  1].length);
+		}
+
+		@Override
+		public int read() {
+			if (x < data.length) {
+				byte[] curr = data[x];
+				if (y < curr.length) {
+					byte next = curr[y];
+					y++;
+					return next;
+				}
+				else {
+					y = 0;
+					x++;
+					return read();
+				}
+			} else {
+				return -1;
+			}
+		}
+
+		@Override
+		public int read(byte[] b, int off, int len) throws IOException {
+			if (len == 0) {
+				return 0;
+			}
+			if (x < data.length) {
+				byte[] curr = data[x];
+				if (y < curr.length) {
+					int toCopy = Math.min(len, curr.length - y);
+					System.arraycopy(curr, y, b, off, toCopy);
+					y += toCopy;
+					return toCopy;
+				} else {
+					y = 0;
+					x++;
+					return read(b, off, len);
+				}
+			}
+			else {
+				return -1;
+			}
+		}
+	}
+}
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/blob/TestingFailingBlobServer.java b/flink-runtime/src/test/java/org/apache/flink/runtime/blob/TestingFailingBlobServer.java
new file mode 100644
index 00000000000..93f9b7331db
--- /dev/null
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/blob/TestingFailingBlobServer.java
@@ -0,0 +1,74 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.flink.runtime.blob;
+
+import org.apache.flink.configuration.Configuration;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.OutputStream;
+import java.net.Socket;
+
+public class TestingFailingBlobServer extends BlobServer {
+
+	private int numFailures;
+
+	public TestingFailingBlobServer(Configuration config, int numFailures) throws IOException {
+		super(config);
+		this.numFailures = numFailures;
+	}
+
+	@Override
+	public void run() {
+
+		// we do properly the first operation (PUT)
+		try {
+			new BlobServerConnection(getServerSocket().accept(), this).start();
+		}
+		catch (Throwable t) {
+			t.printStackTrace();
+		}
+
+		// do some failing operations
+		for (int num = 0; num < numFailures && !isShutdown(); num++) {
+			Socket socket = null;
+			try {
+				socket = getServerSocket().accept();
+				InputStream is = socket.getInputStream();
+				OutputStream os = socket.getOutputStream();
+
+				// just abort everything
+				is.close();
+				os.close();
+				socket.close();
+			}
+			catch (IOException e) {
+			}
+			finally {
+				if (socket != null) {
+					try {
+						socket.close();
+					} catch(Throwable t) {}
+				}
+			}
+		}
+
+		// regular runs
+		super.run();
+	}
+}
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/execution/librarycache/BlobLibraryCacheManagerTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/execution/librarycache/BlobLibraryCacheManagerTest.java
index 2675346db00..4c24b1eae52 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/execution/librarycache/BlobLibraryCacheManagerTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/execution/librarycache/BlobLibraryCacheManagerTest.java
@@ -52,7 +52,7 @@ public class BlobLibraryCacheManagerTest {
 
 		try {
 			server = new BlobServer(new Configuration());
-			InetSocketAddress blobSocketAddress = new InetSocketAddress(server.getServerPort());
+			InetSocketAddress blobSocketAddress = new InetSocketAddress(server.getPort());
 			BlobClient bc = new BlobClient(blobSocketAddress);
 
 			keys.add(bc.put(buf));
