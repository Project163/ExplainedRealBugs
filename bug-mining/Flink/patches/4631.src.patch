diff --git a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveDynamicTableFactory.java b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveDynamicTableFactory.java
index 98ae3e77671..79d2f3766b1 100644
--- a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveDynamicTableFactory.java
+++ b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveDynamicTableFactory.java
@@ -56,14 +56,15 @@ public class HiveDynamicTableFactory implements
 		throw new UnsupportedOperationException("Hive factory is only work for catalog.");
 	}
 
-	private static CatalogTable removeIsGenericFlag(CatalogTable table) {
-		Map<String, String> newOptions = new HashMap<>(table.getOptions());
+	private static CatalogTable removeIsGenericFlag(Context context) {
+		Map<String, String> newOptions = new HashMap<>(context.getCatalogTable().getOptions());
 		boolean isGeneric = Boolean.parseBoolean(newOptions.remove(IS_GENERIC));
-		if (!isGeneric) {
+		// temporary table doesn't have the IS_GENERIC flag but we still consider it generic
+		if (!isGeneric && !context.isTemporary()) {
 			throw new ValidationException(
 					"Hive dynamic table factory now only work for generic table.");
 		}
-		return table.copy(newOptions);
+		return context.getCatalogTable().copy(newOptions);
 	}
 
 	@Override
@@ -71,7 +72,7 @@ public class HiveDynamicTableFactory implements
 		return FactoryUtil.createTableSink(
 				null, // we already in the factory of catalog
 				context.getObjectIdentifier(),
-				removeIsGenericFlag(context.getCatalogTable()),
+				removeIsGenericFlag(context),
 				context.getConfiguration(),
 				context.getClassLoader(),
 				false);
@@ -82,7 +83,7 @@ public class HiveDynamicTableFactory implements
 		return FactoryUtil.createTableSource(
 				null, // we already in the factory of catalog
 				context.getObjectIdentifier(),
-				removeIsGenericFlag(context.getCatalogTable()),
+				removeIsGenericFlag(context),
 				context.getConfiguration(),
 				context.getClassLoader(),
 				false);
diff --git a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableFactory.java b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableFactory.java
index 0bb78b86535..eec97d09997 100644
--- a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableFactory.java
+++ b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableFactory.java
@@ -66,7 +66,8 @@ public class HiveTableFactory
 
 		boolean isGeneric = Boolean.parseBoolean(table.getProperties().get(CatalogConfig.IS_GENERIC));
 
-		if (!isGeneric) {
+		// temporary table doesn't have the IS_GENERIC flag but we still consider it generic
+		if (!isGeneric && !context.isTemporary()) {
 			return new HiveTableSource(
 					new JobConf(hiveConf),
 					context.getConfiguration(),
@@ -84,7 +85,8 @@ public class HiveTableFactory
 
 		boolean isGeneric = Boolean.parseBoolean(table.getProperties().get(CatalogConfig.IS_GENERIC));
 
-		if (!isGeneric) {
+		// temporary table doesn't have the IS_GENERIC flag but we still consider it generic
+		if (!isGeneric && !context.isTemporary()) {
 			return new HiveTableSink(
 					context.getConfiguration().get(
 							HiveOptions.TABLE_EXEC_HIVE_FALLBACK_MAPRED_WRITER),
diff --git a/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveLookupJoinITCase.java b/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveLookupJoinITCase.java
index 3654462b997..a636a5936d2 100644
--- a/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveLookupJoinITCase.java
+++ b/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveLookupJoinITCase.java
@@ -79,7 +79,7 @@ public class HiveLookupJoinITCase {
 		ObjectIdentifier tableIdentifier = ObjectIdentifier.of(hiveCatalog.getName(), "default", "build");
 		CatalogTable catalogTable = (CatalogTable) hiveCatalog.getTable(tableIdentifier.toObjectPath());
 		HiveTableSource hiveTableSource = (HiveTableSource) ((HiveTableFactory) hiveCatalog.getTableFactory().get()).createTableSource(
-				new TableSourceFactoryContextImpl(tableIdentifier, catalogTable, tableEnv.getConfig().getConfiguration()));
+				new TableSourceFactoryContextImpl(tableIdentifier, catalogTable, tableEnv.getConfig().getConfiguration(), false));
 		FileSystemLookupFunction lookupFunction = (FileSystemLookupFunction) hiveTableSource.getLookupFunction(new String[]{"x"});
 		assertEquals(Duration.ofMinutes(5), lookupFunction.getCacheTTL());
 
diff --git a/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableFactoryTest.java b/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableFactoryTest.java
index 80bf25fe2cd..1ae8ab88a3c 100644
--- a/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableFactoryTest.java
+++ b/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableFactoryTest.java
@@ -83,13 +83,13 @@ public class HiveTableFactoryTest {
 		assertTrue(opt.isPresent());
 		HiveTableFactory tableFactory = (HiveTableFactory) opt.get();
 		TableSource tableSource = tableFactory.createTableSource(new TableSourceFactoryContextImpl(
-				ObjectIdentifier.of("mycatalog", "mydb", "mytable"), table, new Configuration()));
+				ObjectIdentifier.of("mycatalog", "mydb", "mytable"), table, new Configuration(), false));
 		assertTrue(tableSource instanceof StreamTableSource);
 		TableSink tableSink = tableFactory.createTableSink(new TableSinkFactoryContextImpl(
 				ObjectIdentifier.of("mycatalog", "mydb", "mytable"),
 				table,
 				new Configuration(),
-				true));
+				true, false));
 		assertTrue(tableSink instanceof StreamTableSink);
 	}
 
@@ -114,10 +114,10 @@ public class HiveTableFactoryTest {
 				ObjectIdentifier.of("mycatalog", "mydb", "mytable"),
 				table,
 				new Configuration(),
-				true));
+				true, false));
 		assertTrue(tableSink instanceof HiveTableSink);
 		TableSource tableSource = tableFactory.createTableSource(new TableSourceFactoryContextImpl(
-				ObjectIdentifier.of("mycatalog", "mydb", "mytable"), table, new Configuration()));
+				ObjectIdentifier.of("mycatalog", "mydb", "mytable"), table, new Configuration(), false));
 		assertTrue(tableSource instanceof HiveTableSource);
 	}
 
diff --git a/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogITCase.java b/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogITCase.java
index 7aaf27c7f37..f7eaeec2166 100644
--- a/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogITCase.java
+++ b/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogITCase.java
@@ -35,6 +35,7 @@ import org.apache.flink.table.catalog.exceptions.TableNotExistException;
 import org.apache.flink.table.descriptors.FileSystem;
 import org.apache.flink.table.descriptors.FormatDescriptor;
 import org.apache.flink.table.descriptors.OldCsv;
+import org.apache.flink.table.planner.factories.utils.TestCollectionTableFactory;
 import org.apache.flink.types.Row;
 import org.apache.flink.util.CollectionUtil;
 import org.apache.flink.util.FileUtils;
@@ -56,6 +57,7 @@ import java.io.File;
 import java.io.FileReader;
 import java.io.PrintStream;
 import java.net.URI;
+import java.nio.file.Files;
 import java.nio.file.Path;
 import java.nio.file.Paths;
 import java.util.ArrayList;
@@ -433,4 +435,32 @@ public class HiveCatalogITCase {
 			future.get(5, TimeUnit.SECONDS);
 		}
 	}
+
+	@Test
+	public void testTemporaryGenericTable() throws Exception {
+		EnvironmentSettings settings = EnvironmentSettings.newInstance().useBlinkPlanner().inStreamingMode().build();
+		TableEnvironment tableEnv = TableEnvironment.create(settings);
+		tableEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);
+		tableEnv.useCatalog(hiveCatalog.getName());
+
+		TestCollectionTableFactory.reset();
+		TestCollectionTableFactory.initData(Arrays.asList(Row.of(1), Row.of(2)));
+		tableEnv.executeSql("create temporary table src(x int) with ('connector'='COLLECTION','is-bounded' = 'false')");
+		File tempDir = Files.createTempDirectory("dest-").toFile();
+		Runtime.getRuntime().addShutdownHook(new Thread(() -> org.apache.commons.io.FileUtils.deleteQuietly(tempDir)));
+		tableEnv.executeSql("create temporary table dest(x int) with (" +
+				"'connector' = 'filesystem'," +
+				String.format("'path' = 'file://%s/1.csv',", tempDir.getAbsolutePath()) +
+				"'format' = 'csv')");
+		tableEnv.executeSql("insert into dest select * from src").await();
+
+		tableEnv.executeSql("create temporary table datagen(i int) with (" +
+				"'connector'='datagen'," +
+				"'rows-per-second'='5'," +
+				"'fields.i.kind'='sequence'," +
+				"'fields.i.start'='1'," +
+				"'fields.i.end'='10')");
+		tableEnv.executeSql("create temporary table blackhole(i int) with ('connector'='blackhole')");
+		tableEnv.executeSql("insert into blackhole select * from datagen").await();
+	}
 }
