diff --git a/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/reader/KafkaSourceReaderTest.java b/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/reader/KafkaSourceReaderTest.java
index 58b3fddf683..f4e3fbd7bc1 100644
--- a/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/reader/KafkaSourceReaderTest.java
+++ b/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/reader/KafkaSourceReaderTest.java
@@ -76,6 +76,7 @@ import static org.apache.flink.connector.kafka.source.metrics.KafkaSourceReaderM
 import static org.apache.flink.connector.kafka.source.metrics.KafkaSourceReaderMetrics.KAFKA_SOURCE_READER_METRIC_GROUP;
 import static org.apache.flink.connector.kafka.source.metrics.KafkaSourceReaderMetrics.PARTITION_GROUP;
 import static org.apache.flink.connector.kafka.source.metrics.KafkaSourceReaderMetrics.TOPIC_GROUP;
+import static org.apache.flink.connector.kafka.source.testutils.KafkaSourceTestEnv.NUM_PARTITIONS;
 import static org.apache.flink.core.testutils.CommonTestUtils.waitUtil;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
@@ -89,7 +90,7 @@ public class KafkaSourceReaderTest extends SourceReaderTestBase<KafkaPartitionSp
         KafkaSourceTestEnv.setup();
         try (AdminClient adminClient = KafkaSourceTestEnv.getAdminClient()) {
             adminClient.createTopics(
-                    Collections.singleton(new NewTopic(TOPIC, NUM_SPLITS, (short) 1)));
+                    Collections.singleton(new NewTopic(TOPIC, NUM_PARTITIONS, (short) 1)));
             // Use the admin client to trigger the creation of internal __consumer_offsets topic.
             // This makes sure that we won't see unavailable coordinator in the tests.
             waitUtil(
@@ -116,6 +117,10 @@ public class KafkaSourceReaderTest extends SourceReaderTestBase<KafkaPartitionSp
         KafkaSourceTestEnv.tearDown();
     }
 
+    protected int getNumSplits() {
+        return NUM_PARTITIONS;
+    }
+
     // -----------------------------------------
 
     @Test
@@ -196,7 +201,7 @@ public class KafkaSourceReaderTest extends SourceReaderTestBase<KafkaPartitionSp
                 (KafkaSourceReader<Integer>)
                         createReader(Boundedness.CONTINUOUS_UNBOUNDED, groupId)) {
             reader.addSplits(
-                    getSplits(NUM_SPLITS, NUM_RECORDS_PER_SPLIT, Boundedness.CONTINUOUS_UNBOUNDED));
+                    getSplits(numSplits, NUM_RECORDS_PER_SPLIT, Boundedness.CONTINUOUS_UNBOUNDED));
             ValidatingSourceOutput output = new ValidatingSourceOutput();
             long checkpointId = 0;
             do {
@@ -204,7 +209,7 @@ public class KafkaSourceReaderTest extends SourceReaderTestBase<KafkaPartitionSp
                 reader.pollNext(output);
                 // Create a checkpoint for each message consumption, but not complete them.
                 reader.snapshotState(checkpointId);
-            } while (output.count() < TOTAL_NUM_RECORDS);
+            } while (output.count() < totalNumRecords);
 
             // The completion of the last checkpoint should subsume all the previous checkpoitns.
             assertEquals(checkpointId, reader.getOffsetsToCommit().size());
@@ -223,7 +228,7 @@ public class KafkaSourceReaderTest extends SourceReaderTestBase<KafkaPartitionSp
                             .listConsumerGroupOffsets(groupId)
                             .partitionsToOffsetAndMetadata()
                             .get();
-            assertEquals(NUM_SPLITS, committedOffsets.size());
+            assertEquals(numSplits, committedOffsets.size());
             committedOffsets.forEach(
                     (tp, offsetAndMetadata) ->
                             assertEquals(NUM_RECORDS_PER_SPLIT, offsetAndMetadata.offset()));
@@ -480,7 +485,7 @@ public class KafkaSourceReaderTest extends SourceReaderTestBase<KafkaPartitionSp
 
     private static List<ProducerRecord<String, Integer>> getRecords() {
         List<ProducerRecord<String, Integer>> records = new ArrayList<>();
-        for (int part = 0; part < NUM_SPLITS; part++) {
+        for (int part = 0; part < NUM_PARTITIONS; part++) {
             for (int i = 0; i < NUM_RECORDS_PER_SPLIT; i++) {
                 records.add(
                         new ProducerRecord<>(
diff --git a/flink-test-utils-parent/flink-connector-test-utils/src/main/java/org/apache/flink/connector/testutils/source/reader/SourceReaderTestBase.java b/flink-test-utils-parent/flink-connector-test-utils/src/main/java/org/apache/flink/connector/testutils/source/reader/SourceReaderTestBase.java
index c109aae11d7..462c5b2ba03 100644
--- a/flink-test-utils-parent/flink-connector-test-utils/src/main/java/org/apache/flink/connector/testutils/source/reader/SourceReaderTestBase.java
+++ b/flink-test-utils-parent/flink-connector-test-utils/src/main/java/org/apache/flink/connector/testutils/source/reader/SourceReaderTestBase.java
@@ -49,9 +49,18 @@ import static org.junit.Assert.assertFalse;
  */
 public abstract class SourceReaderTestBase<SplitT extends SourceSplit> extends TestLogger {
 
-    protected static final int NUM_SPLITS = 10;
+    protected final int numSplits;
+    protected final int totalNumRecords;
     protected static final int NUM_RECORDS_PER_SPLIT = 10;
-    protected static final int TOTAL_NUM_RECORDS = NUM_RECORDS_PER_SPLIT * NUM_SPLITS;
+
+    public SourceReaderTestBase() {
+        this.numSplits = getNumSplits();
+        this.totalNumRecords = this.numSplits * NUM_RECORDS_PER_SPLIT;
+    }
+
+    protected int getNumSplits() {
+        return 10;
+    }
 
     @Rule public ExpectedException expectedException = ExpectedException.none();
 
@@ -68,9 +77,9 @@ public abstract class SourceReaderTestBase<SplitT extends SourceSplit> extends T
     @Test
     public void testRead() throws Exception {
         try (SourceReader<Integer, SplitT> reader = createReader()) {
-            reader.addSplits(getSplits(NUM_SPLITS, NUM_RECORDS_PER_SPLIT, Boundedness.BOUNDED));
+            reader.addSplits(getSplits(numSplits, NUM_RECORDS_PER_SPLIT, Boundedness.BOUNDED));
             ValidatingSourceOutput output = new ValidatingSourceOutput();
-            while (output.count < TOTAL_NUM_RECORDS) {
+            while (output.count < totalNumRecords) {
                 reader.pollNext(output);
             }
             output.validate();
@@ -87,12 +96,12 @@ public abstract class SourceReaderTestBase<SplitT extends SourceSplit> extends T
         // Poll 5 records and let it block on the element queue which only have capacity of 1;
         try (SourceReader<Integer, SplitT> reader = consumeRecords(splits, output, 5)) {
             List<SplitT> newSplits = new ArrayList<>();
-            for (int i = 1; i < NUM_SPLITS; i++) {
+            for (int i = 1; i < numSplits; i++) {
                 newSplits.add(getSplit(i, NUM_RECORDS_PER_SPLIT, Boundedness.BOUNDED));
             }
             reader.addSplits(newSplits);
 
-            while (output.count() < NUM_RECORDS_PER_SPLIT * NUM_SPLITS) {
+            while (output.count() < NUM_RECORDS_PER_SPLIT * numSplits) {
                 reader.pollNext(output);
             }
             output.validate();
@@ -136,12 +145,12 @@ public abstract class SourceReaderTestBase<SplitT extends SourceSplit> extends T
         ValidatingSourceOutput output = new ValidatingSourceOutput();
         // Add a split to start the fetcher.
         List<SplitT> splits =
-                getSplits(NUM_SPLITS, NUM_RECORDS_PER_SPLIT, Boundedness.CONTINUOUS_UNBOUNDED);
+                getSplits(numSplits, NUM_RECORDS_PER_SPLIT, Boundedness.CONTINUOUS_UNBOUNDED);
         try (SourceReader<Integer, SplitT> reader =
-                consumeRecords(splits, output, NUM_SPLITS * NUM_RECORDS_PER_SPLIT)) {
+                consumeRecords(splits, output, totalNumRecords)) {
             List<SplitT> state = reader.snapshotState(1L);
-            assertEquals("The snapshot should only have 10 splits. ", NUM_SPLITS, state.size());
-            for (int i = 0; i < NUM_SPLITS; i++) {
+            assertEquals("The snapshot should only have 10 splits. ", numSplits, state.size());
+            for (int i = 0; i < numSplits; i++) {
                 assertEquals(
                         "The first four splits should have been fully consumed.",
                         NUM_RECORDS_PER_SPLIT,
@@ -176,7 +185,7 @@ public abstract class SourceReaderTestBase<SplitT extends SourceSplit> extends T
     // ---------------- helper classes -----------------
 
     /** A source output that validates the output. */
-    public static class ValidatingSourceOutput implements ReaderOutput<Integer> {
+    public class ValidatingSourceOutput implements ReaderOutput<Integer> {
         private Set<Integer> consumedValues = new HashSet<>();
         private int max = Integer.MIN_VALUE;
         private int min = Integer.MAX_VALUE;
@@ -199,17 +208,17 @@ public abstract class SourceReaderTestBase<SplitT extends SourceSplit> extends T
         public void validate() {
 
             assertEquals(
-                    String.format("Should be %d distinct elements in total", TOTAL_NUM_RECORDS),
-                    TOTAL_NUM_RECORDS,
+                    String.format("Should be %d distinct elements in total", totalNumRecords),
+                    totalNumRecords,
                     consumedValues.size());
             assertEquals(
-                    String.format("Should be %d elements in total", TOTAL_NUM_RECORDS),
-                    TOTAL_NUM_RECORDS,
+                    String.format("Should be %d elements in total", totalNumRecords),
+                    totalNumRecords,
                     count);
             assertEquals("The min value should be 0", 0, min);
             assertEquals(
-                    "The max value should be " + (TOTAL_NUM_RECORDS - 1),
-                    TOTAL_NUM_RECORDS - 1,
+                    String.format("The max value should be %d", totalNumRecords - 1),
+                    totalNumRecords - 1,
                     max);
         }
 
