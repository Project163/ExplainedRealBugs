diff --git a/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/sink/KafkaCommitter.java b/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/sink/KafkaCommitter.java
index 705ae2f5039..f4c852a0d6d 100644
--- a/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/sink/KafkaCommitter.java
+++ b/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/sink/KafkaCommitter.java
@@ -26,7 +26,7 @@ import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import java.io.IOException;
-import java.util.Collections;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Properties;
 
@@ -37,39 +37,41 @@ import java.util.Properties;
  */
 class KafkaCommitter implements Committer<KafkaCommittable> {
 
+    private static final Logger LOG = LoggerFactory.getLogger(KafkaCommitter.class);
+
     private final Properties kafkaProducerConfig;
 
     KafkaCommitter(Properties kafkaProducerConfig) {
         this.kafkaProducerConfig = kafkaProducerConfig;
     }
 
-    private static final Logger LOG = LoggerFactory.getLogger(KafkaCommitter.class);
-
     @Override
     public List<KafkaCommittable> commit(List<KafkaCommittable> committables) throws IOException {
-        committables.forEach(this::commitTransaction);
-        return Collections.emptyList();
+        List<KafkaCommittable> retryableCommittables = new ArrayList<>();
+        for (KafkaCommittable committable : committables) {
+            final String transactionalId = committable.getTransactionalId();
+            LOG.debug("Committing Kafka transaction {}", transactionalId);
+            try (FlinkKafkaInternalProducer<?, ?> producer =
+                    committable.getProducer().orElseGet(() -> createProducer(committable))) {
+                producer.commitTransaction();
+            } catch (ProducerFencedException | InvalidTxnStateException e) {
+                // That means we have committed this transaction before.
+                LOG.warn(
+                        "Encountered error {} while recovering transaction {}. "
+                                + "Presumably this transaction has been already committed before",
+                        e,
+                        committable);
+            } catch (Throwable e) {
+                LOG.warn("Cannot commit Kafka transaction, retrying.", e);
+                retryableCommittables.add(committable);
+            }
+        }
+        return retryableCommittables;
     }
 
     @Override
     public void close() throws Exception {}
 
-    private void commitTransaction(KafkaCommittable committable) {
-        final String transactionalId = committable.getTransactionalId();
-        LOG.debug("Committing Kafka transaction {}", transactionalId);
-        try (FlinkKafkaInternalProducer<?, ?> producer =
-                committable.getProducer().orElseGet(() -> createProducer(committable))) {
-            producer.commitTransaction();
-        } catch (InvalidTxnStateException | ProducerFencedException e) {
-            // That means we have committed this transaction before.
-            LOG.warn(
-                    "Encountered error {} while recovering transaction {}. "
-                            + "Presumably this transaction has been already committed before",
-                    e,
-                    committable);
-        }
-    }
-
     /**
      * Creates a producer that can commit into the same transaction as the upstream producer that
      * was serialized into {@link KafkaCommittable}.
diff --git a/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/sink/KafkaCommitterTest.java b/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/sink/KafkaCommitterTest.java
new file mode 100644
index 00000000000..62f0cec3e70
--- /dev/null
+++ b/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/sink/KafkaCommitterTest.java
@@ -0,0 +1,42 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.connector.kafka.sink;
+
+import org.apache.flink.util.TestLogger;
+
+import org.junit.Test;
+
+import java.io.IOException;
+import java.util.Collections;
+import java.util.List;
+import java.util.Properties;
+
+import static org.junit.Assert.assertEquals;
+
+/** Tests for {@link KafkaCommitter}. */
+public class KafkaCommitterTest extends TestLogger {
+
+    @Test
+    public void testRetryCommittableOnFailure() throws IOException {
+        final KafkaCommitter committer = new KafkaCommitter(new Properties());
+        final short epoch = 0;
+        final List<KafkaCommittable> committables =
+                Collections.singletonList(new KafkaCommittable(0, epoch, "transactionalId", null));
+        assertEquals(committables, committer.commit(committables));
+    }
+}
