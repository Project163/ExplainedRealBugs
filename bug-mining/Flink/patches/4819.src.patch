diff --git a/flink-connectors/flink-connector-elasticsearch-base/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkTestBase.java b/flink-connectors/flink-connector-elasticsearch-base/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkTestBase.java
index 540f4316a00..034161ec696 100644
--- a/flink-connectors/flink-connector-elasticsearch-base/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkTestBase.java
+++ b/flink-connectors/flink-connector-elasticsearch-base/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkTestBase.java
@@ -21,12 +21,10 @@ import org.apache.flink.api.java.tuple.Tuple2;
 import org.apache.flink.runtime.client.JobExecutionException;
 import org.apache.flink.streaming.api.datastream.DataStreamSource;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
-import org.apache.flink.streaming.connectors.elasticsearch.testutils.ElasticsearchResource;
 import org.apache.flink.streaming.connectors.elasticsearch.testutils.SourceSinkDataTestKit;
 import org.apache.flink.test.util.AbstractTestBase;
 
 import org.elasticsearch.client.Client;
-import org.junit.ClassRule;
 
 import java.util.Collections;
 import java.util.HashMap;
@@ -44,10 +42,11 @@ import static org.junit.Assert.fail;
  */
 public abstract class ElasticsearchSinkTestBase<C extends AutoCloseable, A> extends AbstractTestBase {
 
-	protected static final String CLUSTER_NAME = "test-cluster";
+	// It's not good that we're using a Client here instead of a Rest Client but we need this
+	// for compatibility with ES 5.3.x. As soon as we drop that we can use RestClient here.
+	protected abstract Client getClient();
 
-	@ClassRule
-	public static ElasticsearchResource elasticsearchResource = new ElasticsearchResource(CLUSTER_NAME);
+	protected abstract String getClusterName();
 
 	/**
 	 * Tests that the Elasticsearch sink works properly with json.
@@ -84,13 +83,14 @@ public abstract class ElasticsearchSinkTestBase<C extends AutoCloseable, A> exte
 
 		source.addSink(createElasticsearchSinkForEmbeddedNode(
 				1,
-				CLUSTER_NAME,
+				getClusterName(),
 				functionFactory.apply(index)));
 
 		env.execute("Elasticsearch Sink Test");
 
 		// verify the results
-		Client client = elasticsearchResource.getClient();
+		Client client = getClient();
+
 		SourceSinkDataTestKit.verifyProducedSinkData(client, index);
 
 		client.close();
@@ -99,11 +99,11 @@ public abstract class ElasticsearchSinkTestBase<C extends AutoCloseable, A> exte
 	/**
 	 * Tests that the Elasticsearch sink fails eagerly if the provided list of addresses is {@code null}.
 	 */
-	public void runNullAddressesTest() throws Exception {
+	public void runNullAddressesTest() {
 		try {
 			createElasticsearchSink(
 					1,
-					CLUSTER_NAME,
+					getClusterName(),
 					null,
 					SourceSinkDataTestKit.getJsonSinkFunction("test"));
 		} catch (IllegalArgumentException | NullPointerException expectedException) {
@@ -117,11 +117,11 @@ public abstract class ElasticsearchSinkTestBase<C extends AutoCloseable, A> exte
 	/**
 	 * Tests that the Elasticsearch sink fails eagerly if the provided list of addresses is empty.
 	 */
-	public void runEmptyAddressesTest() throws Exception {
+	public void runEmptyAddressesTest() {
 		try {
 			createElasticsearchSink(
 					1,
-					CLUSTER_NAME,
+					getClusterName(),
 					Collections.emptyList(),
 					SourceSinkDataTestKit.getJsonSinkFunction("test"));
 		} catch (IllegalArgumentException expectedException) {
diff --git a/flink-connectors/flink-connector-elasticsearch5/src/test/java/org/apache/flink/streaming/connectors/elasticsearch5/ElasticsearchSinkITCase.java b/flink-connectors/flink-connector-elasticsearch5/src/test/java/org/apache/flink/streaming/connectors/elasticsearch5/ElasticsearchSinkITCase.java
index 0d4103f31d3..f22147d8c06 100644
--- a/flink-connectors/flink-connector-elasticsearch5/src/test/java/org/apache/flink/streaming/connectors/elasticsearch5/ElasticsearchSinkITCase.java
+++ b/flink-connectors/flink-connector-elasticsearch5/src/test/java/org/apache/flink/streaming/connectors/elasticsearch5/ElasticsearchSinkITCase.java
@@ -22,8 +22,11 @@ import org.apache.flink.api.java.tuple.Tuple2;
 import org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkBase;
 import org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkFunction;
 import org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkTestBase;
+import org.apache.flink.streaming.connectors.elasticsearch.testutils.ElasticsearchResource;
 
+import org.elasticsearch.client.Client;
 import org.elasticsearch.client.transport.TransportClient;
+import org.junit.ClassRule;
 import org.junit.Test;
 
 import java.net.InetAddress;
@@ -37,6 +40,21 @@ import java.util.List;
  */
 public class ElasticsearchSinkITCase extends ElasticsearchSinkTestBase<TransportClient, InetSocketAddress> {
 
+	protected static final String CLUSTER_NAME = "test-cluster";
+
+	@ClassRule
+	public static ElasticsearchResource elasticsearchResource = new ElasticsearchResource(CLUSTER_NAME);
+
+	@Override
+	protected String getClusterName() {
+		return CLUSTER_NAME;
+	}
+
+	@Override
+	protected final Client getClient() {
+		return elasticsearchResource.getClient();
+	}
+
 	@Test
 	public void testElasticsearchSink() throws Exception {
 		runElasticsearchSinkTest();
diff --git a/flink-connectors/flink-connector-elasticsearch6/pom.xml b/flink-connectors/flink-connector-elasticsearch6/pom.xml
index e796af833c4..f6a534775a7 100644
--- a/flink-connectors/flink-connector-elasticsearch6/pom.xml
+++ b/flink-connectors/flink-connector-elasticsearch6/pom.xml
@@ -83,6 +83,13 @@ under the License.
 
 		<!-- test dependencies -->
 
+		<dependency>
+			<groupId>org.testcontainers</groupId>
+			<artifactId>elasticsearch</artifactId>
+			<version>1.15.0</version>
+			<scope>test</scope>
+		</dependency>
+
 		<dependency>
 			<groupId>org.apache.flink</groupId>
 			<artifactId>flink-test-utils_${scala.binary.version}</artifactId>
diff --git a/flink-connectors/flink-connector-elasticsearch6/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/EmbeddedElasticsearchNodeEnvironmentImpl.java b/flink-connectors/flink-connector-elasticsearch6/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/EmbeddedElasticsearchNodeEnvironmentImpl.java
deleted file mode 100644
index 8dc62168049..00000000000
--- a/flink-connectors/flink-connector-elasticsearch6/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/EmbeddedElasticsearchNodeEnvironmentImpl.java
+++ /dev/null
@@ -1,79 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.flink.streaming.connectors.elasticsearch;
-
-import org.apache.flink.streaming.connectors.elasticsearch6.ElasticsearchSinkITCase;
-
-import org.elasticsearch.client.Client;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.node.InternalSettingsPreparer;
-import org.elasticsearch.node.Node;
-import org.elasticsearch.plugins.Plugin;
-import org.elasticsearch.transport.Netty4Plugin;
-
-import java.io.File;
-import java.util.Collections;
-
-/**
- * Implementation of {@link EmbeddedElasticsearchNodeEnvironment} for Elasticsearch 6.
- * Will be dynamically loaded in {@link ElasticsearchSinkITCase} for integration tests.
- */
-public class EmbeddedElasticsearchNodeEnvironmentImpl implements EmbeddedElasticsearchNodeEnvironment {
-
-	private Node node;
-
-	@Override
-	public void start(File tmpDataFolder, String clusterName) throws Exception {
-		if (node == null) {
-			Settings settings = Settings.builder()
-				.put("cluster.name", clusterName)
-				.put("http.enabled", true)
-				.put("path.home", tmpDataFolder.getParent())
-				.put("path.data", tmpDataFolder.getAbsolutePath())
-				.build();
-
-			node = new PluginNode(settings);
-			node.start();
-		}
-	}
-
-	@Override
-	public void close() throws Exception {
-		if (node != null && !node.isClosed()) {
-			node.close();
-			node = null;
-		}
-	}
-
-	@Override
-	public Client getClient() {
-		if (node != null && !node.isClosed()) {
-			return node.client();
-		} else {
-			return null;
-		}
-	}
-
-	private static class PluginNode extends Node {
-		public PluginNode(Settings settings) {
-			super(InternalSettingsPreparer.prepareEnvironment(settings, null), Collections.<Class<? extends Plugin>>singletonList(Netty4Plugin.class));
-		}
-	}
-
-}
diff --git a/flink-connectors/flink-connector-elasticsearch6/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch6DynamicSinkITCase.java b/flink-connectors/flink-connector-elasticsearch6/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch6DynamicSinkITCase.java
index ce57fadbf0e..f1604d0d501 100644
--- a/flink-connectors/flink-connector-elasticsearch6/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch6DynamicSinkITCase.java
+++ b/flink-connectors/flink-connector-elasticsearch6/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch6DynamicSinkITCase.java
@@ -22,7 +22,6 @@ import org.apache.flink.api.common.time.Deadline;
 import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.api.functions.sink.SinkFunction;
-import org.apache.flink.streaming.connectors.elasticsearch.testutils.ElasticsearchResource;
 import org.apache.flink.table.api.DataTypes;
 import org.apache.flink.table.api.EnvironmentSettings;
 import org.apache.flink.table.api.TableEnvironment;
@@ -38,9 +37,14 @@ import org.apache.flink.types.RowKind;
 
 import org.elasticsearch.action.get.GetRequest;
 import org.elasticsearch.client.Client;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.transport.TransportAddress;
 import org.elasticsearch.search.SearchHits;
+import org.elasticsearch.transport.client.PreBuiltTransportClient;
 import org.junit.ClassRule;
 import org.junit.Test;
+import org.testcontainers.elasticsearch.ElasticsearchContainer;
+import org.testcontainers.utility.DockerImageName;
 
 import java.time.Duration;
 import java.time.LocalDate;
@@ -61,7 +65,20 @@ import static org.junit.Assert.assertThat;
 public class Elasticsearch6DynamicSinkITCase {
 
 	@ClassRule
-	public static ElasticsearchResource elasticsearchResource = new ElasticsearchResource("es-6-dynamic-sink-tests");
+	public static ElasticsearchContainer elasticsearchContainer =
+			new ElasticsearchContainer(
+					DockerImageName
+							.parse("docker.elastic.co/elasticsearch/elasticsearch-oss")
+							.withTag("6.3.1"));
+
+	@SuppressWarnings("deprecation")
+	protected final Client getClient() {
+		TransportAddress transportAddress = new TransportAddress(elasticsearchContainer.getTcpHost());
+		String expectedClusterName = "docker-cluster";
+		Settings settings = Settings.builder().put("cluster.name", expectedClusterName).build();
+		return new PreBuiltTransportClient(settings)
+				.addTransportAddress(transportAddress);
+	}
 
 	@Test
 	public void testWritingDocuments() throws Exception {
@@ -93,7 +110,7 @@ public class Elasticsearch6DynamicSinkITCase {
 				.withSchema(schema)
 				.withOption(ElasticsearchOptions.INDEX_OPTION.key(), index)
 				.withOption(ElasticsearchOptions.DOCUMENT_TYPE_OPTION.key(), myType)
-				.withOption(ElasticsearchOptions.HOSTS_OPTION.key(), "http://127.0.0.1:9200")
+				.withOption(ElasticsearchOptions.HOSTS_OPTION.key(), elasticsearchContainer.getHttpHostAddress())
 				.withOption(ElasticsearchOptions.FLUSH_ON_CHECKPOINT_OPTION.key(), "false")
 				.build()
 		).getSinkRuntimeProvider(new MockContext());
@@ -104,7 +121,7 @@ public class Elasticsearch6DynamicSinkITCase {
 		environment.<RowData>fromElements(rowData).addSink(sinkFunction);
 		environment.execute();
 
-		Client client = elasticsearchResource.getClient();
+		Client client = getClient();
 		Map<String, Object> response = client.get(new GetRequest(index, myType, "1_2012-12-12T12:12:12")).actionGet().getSource();
 		Map<Object, Object> expectedMap = new HashMap<>();
 		expectedMap.put("a", 1);
@@ -141,7 +158,7 @@ public class Elasticsearch6DynamicSinkITCase {
 			String.format("'%s'='%s',\n", "connector", "elasticsearch-6") +
 			String.format("'%s'='%s',\n", ElasticsearchOptions.INDEX_OPTION.key(), index) +
 			String.format("'%s'='%s',\n", ElasticsearchOptions.DOCUMENT_TYPE_OPTION.key(), myType) +
-			String.format("'%s'='%s',\n", ElasticsearchOptions.HOSTS_OPTION.key(), "http://127.0.0.1:9200") +
+			String.format("'%s'='%s',\n", ElasticsearchOptions.HOSTS_OPTION.key(), elasticsearchContainer.getHttpHostAddress()) +
 			String.format("'%s'='%s'\n", ElasticsearchOptions.FLUSH_ON_CHECKPOINT_OPTION.key(), "false") +
 			")");
 
@@ -156,7 +173,7 @@ public class Elasticsearch6DynamicSinkITCase {
 				LocalDateTime.parse("2012-12-12T12:12:12"))
 		).executeInsert("esTable").await();
 
-		Client client = elasticsearchResource.getClient();
+		Client client = getClient();
 		Map<String, Object> response = client.get(new GetRequest(index, myType, "1_2012-12-12T12:12:12"))
 			.actionGet()
 			.getSource();
@@ -193,7 +210,7 @@ public class Elasticsearch6DynamicSinkITCase {
 			String.format("'%s'='%s',\n", "connector", "elasticsearch-6") +
 			String.format("'%s'='%s',\n", ElasticsearchOptions.INDEX_OPTION.key(), index) +
 			String.format("'%s'='%s',\n", ElasticsearchOptions.DOCUMENT_TYPE_OPTION.key(), myType) +
-			String.format("'%s'='%s',\n", ElasticsearchOptions.HOSTS_OPTION.key(), "http://127.0.0.1:9200") +
+			String.format("'%s'='%s',\n", ElasticsearchOptions.HOSTS_OPTION.key(), elasticsearchContainer.getHttpHostAddress()) +
 			String.format("'%s'='%s'\n", ElasticsearchOptions.FLUSH_ON_CHECKPOINT_OPTION.key(), "false") +
 			")");
 
@@ -216,7 +233,7 @@ public class Elasticsearch6DynamicSinkITCase {
 				LocalDateTime.parse("2013-12-12T13:13:13"))
 		).executeInsert("esTable").await();
 
-		Client client = elasticsearchResource.getClient();
+		Client client = getClient();
 
 		// search API does not return documents that were not indexed, we might need to query
 		// the index a few times
@@ -279,14 +296,14 @@ public class Elasticsearch6DynamicSinkITCase {
 			String.format("'%s'='%s',\n", "connector", "elasticsearch-6") +
 			String.format("'%s'='%s',\n", ElasticsearchOptions.INDEX_OPTION.key(), index) +
 			String.format("'%s'='%s',\n", ElasticsearchOptions.DOCUMENT_TYPE_OPTION.key(), myType) +
-			String.format("'%s'='%s',\n", ElasticsearchOptions.HOSTS_OPTION.key(), "http://127.0.0.1:9200") +
+			String.format("'%s'='%s',\n", ElasticsearchOptions.HOSTS_OPTION.key(), elasticsearchContainer.getHttpHostAddress()) +
 			String.format("'%s'='%s'\n", ElasticsearchOptions.FLUSH_ON_CHECKPOINT_OPTION.key(), "false") +
 			")");
 
 		tableEnvironment.fromValues(row(1L, LocalDateTime.parse("2012-12-12T12:12:12")))
 			.executeInsert("esTable").await();
 
-		Client client = elasticsearchResource.getClient();
+		Client client = getClient();
 		Map<String, Object> response = client.get(new GetRequest("dynamic-index-2012-12-12", myType, "1")).actionGet().getSource();
 		Map<Object, Object> expectedMap = new HashMap<>();
 		expectedMap.put("a", 1);
diff --git a/flink-connectors/flink-connector-elasticsearch6/src/test/java/org/apache/flink/streaming/connectors/elasticsearch6/ElasticsearchSinkITCase.java b/flink-connectors/flink-connector-elasticsearch6/src/test/java/org/apache/flink/streaming/connectors/elasticsearch6/ElasticsearchSinkITCase.java
index 4a1d7e82dcb..5663aab0132 100644
--- a/flink-connectors/flink-connector-elasticsearch6/src/test/java/org/apache/flink/streaming/connectors/elasticsearch6/ElasticsearchSinkITCase.java
+++ b/flink-connectors/flink-connector-elasticsearch6/src/test/java/org/apache/flink/streaming/connectors/elasticsearch6/ElasticsearchSinkITCase.java
@@ -24,13 +24,16 @@ import org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkFunc
 import org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkTestBase;
 
 import org.apache.http.HttpHost;
-import org.elasticsearch.client.RestClient;
-import org.elasticsearch.client.RestClientBuilder;
+import org.elasticsearch.client.Client;
 import org.elasticsearch.client.RestHighLevelClient;
-import org.junit.Before;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.transport.TransportAddress;
+import org.elasticsearch.transport.client.PreBuiltTransportClient;
+import org.junit.ClassRule;
 import org.junit.Test;
+import org.testcontainers.elasticsearch.ElasticsearchContainer;
+import org.testcontainers.utility.DockerImageName;
 
-import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
 
@@ -39,13 +42,26 @@ import java.util.List;
  */
 public class ElasticsearchSinkITCase extends ElasticsearchSinkTestBase<RestHighLevelClient, HttpHost> {
 
-	@Before
-	public void ensureClusterIsUp() throws IOException {
-		RestClientBuilder builder = RestClient.builder(HttpHost.create("http://127.0.0.1:9200"));
-		RestHighLevelClient client = new RestHighLevelClient(builder);
-		if (!client.ping()) {
-			throw new RuntimeException("Cannot ping cluster!");
-		}
+	@ClassRule
+	public static ElasticsearchContainer elasticsearchContainer =
+			new ElasticsearchContainer(
+					DockerImageName
+							.parse("docker.elastic.co/elasticsearch/elasticsearch-oss")
+							.withTag("6.3.1"));
+
+	@Override
+	protected String getClusterName() {
+		return "docker-cluster";
+	}
+
+	@Override
+	@SuppressWarnings("deprecation")
+	protected final Client getClient() {
+		TransportAddress transportAddress = new TransportAddress(elasticsearchContainer.getTcpHost());
+		String expectedClusterName = getClusterName();
+		Settings settings = Settings.builder().put("cluster.name", expectedClusterName).build();
+		return new PreBuiltTransportClient(settings)
+				.addTransportAddress(transportAddress);
 	}
 
 	@Test
@@ -59,12 +75,12 @@ public class ElasticsearchSinkITCase extends ElasticsearchSinkTestBase<RestHighL
 	}
 
 	@Test
-	public void testNullAddresses() throws Exception {
+	public void testNullAddresses() {
 		runNullAddressesTest();
 	}
 
 	@Test
-	public void testEmptyAddresses() throws Exception {
+	public void testEmptyAddresses() {
 		runEmptyAddressesTest();
 	}
 
@@ -90,10 +106,10 @@ public class ElasticsearchSinkITCase extends ElasticsearchSinkTestBase<RestHighL
 	protected ElasticsearchSinkBase<Tuple2<Integer, String>, RestHighLevelClient> createElasticsearchSinkForEmbeddedNode(
 			int bulkFlushMaxActions,
 			String clusterName,
-			ElasticsearchSinkFunction<Tuple2<Integer, String>> elasticsearchSinkFunction) throws Exception {
+			ElasticsearchSinkFunction<Tuple2<Integer, String>> elasticsearchSinkFunction) {
 
 		return createElasticsearchSinkForNode(
-				bulkFlushMaxActions, clusterName, elasticsearchSinkFunction, "127.0.0.1");
+				bulkFlushMaxActions, clusterName, elasticsearchSinkFunction, elasticsearchContainer.getHttpHostAddress());
 	}
 
 	@Override
@@ -101,10 +117,10 @@ public class ElasticsearchSinkITCase extends ElasticsearchSinkTestBase<RestHighL
 			int bulkFlushMaxActions,
 			String clusterName,
 			ElasticsearchSinkFunction<Tuple2<Integer, String>> elasticsearchSinkFunction,
-			String ipAddress) throws Exception {
+			String hostAddress) {
 
 		ArrayList<HttpHost> httpHosts = new ArrayList<>();
-		httpHosts.add(new HttpHost(ipAddress, 9200, "http"));
+		httpHosts.add(HttpHost.create(hostAddress));
 
 		ElasticsearchSink.Builder<Tuple2<Integer, String>> builder = new ElasticsearchSink.Builder<>(httpHosts, elasticsearchSinkFunction);
 		builder.setBulkFlushMaxActions(bulkFlushMaxActions);
diff --git a/flink-connectors/flink-connector-elasticsearch7/pom.xml b/flink-connectors/flink-connector-elasticsearch7/pom.xml
index f1b9e822719..e4393215b22 100644
--- a/flink-connectors/flink-connector-elasticsearch7/pom.xml
+++ b/flink-connectors/flink-connector-elasticsearch7/pom.xml
@@ -83,6 +83,13 @@ under the License.
 
 		<!-- test dependencies -->
 
+		<dependency>
+			<groupId>org.testcontainers</groupId>
+			<artifactId>elasticsearch</artifactId>
+			<version>1.15.0</version>
+			<scope>test</scope>
+		</dependency>
+
 		<dependency>
 			<groupId>org.apache.flink</groupId>
 			<artifactId>flink-test-utils_${scala.binary.version}</artifactId>
diff --git a/flink-connectors/flink-connector-elasticsearch7/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/EmbeddedElasticsearchNodeEnvironmentImpl.java b/flink-connectors/flink-connector-elasticsearch7/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/EmbeddedElasticsearchNodeEnvironmentImpl.java
deleted file mode 100644
index 6f051a383bb..00000000000
--- a/flink-connectors/flink-connector-elasticsearch7/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/EmbeddedElasticsearchNodeEnvironmentImpl.java
+++ /dev/null
@@ -1,79 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.flink.streaming.connectors.elasticsearch;
-
-import org.apache.flink.streaming.connectors.elasticsearch7.ElasticsearchSinkITCase;
-
-import org.elasticsearch.client.Client;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.node.InternalSettingsPreparer;
-import org.elasticsearch.node.Node;
-import org.elasticsearch.plugins.Plugin;
-import org.elasticsearch.transport.Netty4Plugin;
-
-import java.io.File;
-import java.util.Collections;
-
-/**
- * Implementation of {@link EmbeddedElasticsearchNodeEnvironment} for Elasticsearch 7.
- * Will be dynamically loaded in {@link ElasticsearchSinkITCase} for integration tests.
- */
-public class EmbeddedElasticsearchNodeEnvironmentImpl implements EmbeddedElasticsearchNodeEnvironment {
-
-	private Node node;
-
-	@Override
-	public void start(File tmpDataFolder, String clusterName) throws Exception {
-		if (node == null) {
-			Settings settings = Settings.builder()
-				.put("cluster.name", clusterName)
-				.put("http.cors.enabled", true)
-				.put("path.home", tmpDataFolder.getParent())
-				.put("path.data", tmpDataFolder.getAbsolutePath())
-				.build();
-
-			node = new PluginNode(settings);
-			node.start();
-		}
-	}
-
-	@Override
-	public void close() throws Exception {
-		if (node != null && !node.isClosed()) {
-			node.close();
-			node = null;
-		}
-	}
-
-	@Override
-	public Client getClient() {
-		if (node != null && !node.isClosed()) {
-			return node.client();
-		} else {
-			return null;
-		}
-	}
-
-	private static class PluginNode extends Node {
-		public PluginNode(Settings settings) {
-			super(InternalSettingsPreparer.prepareEnvironment(settings, Collections.emptyMap(), null, () -> "node1"), Collections.<Class<? extends Plugin>>singletonList(Netty4Plugin.class), true);
-		}
-	}
-
-}
diff --git a/flink-connectors/flink-connector-elasticsearch7/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch7DynamicSinkITCase.java b/flink-connectors/flink-connector-elasticsearch7/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch7DynamicSinkITCase.java
index d2964f55ac9..c8bb4e8ccde 100644
--- a/flink-connectors/flink-connector-elasticsearch7/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch7DynamicSinkITCase.java
+++ b/flink-connectors/flink-connector-elasticsearch7/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch7DynamicSinkITCase.java
@@ -22,7 +22,6 @@ import org.apache.flink.api.common.time.Deadline;
 import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.api.functions.sink.SinkFunction;
-import org.apache.flink.streaming.connectors.elasticsearch.testutils.ElasticsearchResource;
 import org.apache.flink.table.api.DataTypes;
 import org.apache.flink.table.api.EnvironmentSettings;
 import org.apache.flink.table.api.TableEnvironment;
@@ -38,9 +37,14 @@ import org.apache.flink.types.RowKind;
 
 import org.elasticsearch.action.get.GetRequest;
 import org.elasticsearch.client.Client;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.transport.TransportAddress;
 import org.elasticsearch.search.SearchHits;
+import org.elasticsearch.transport.client.PreBuiltTransportClient;
 import org.junit.ClassRule;
 import org.junit.Test;
+import org.testcontainers.elasticsearch.ElasticsearchContainer;
+import org.testcontainers.utility.DockerImageName;
 
 import java.time.Duration;
 import java.time.LocalDate;
@@ -61,7 +65,20 @@ import static org.junit.Assert.assertThat;
 public class Elasticsearch7DynamicSinkITCase {
 
 	@ClassRule
-	public static ElasticsearchResource elasticsearchResource = new ElasticsearchResource("es-dynamic-sink-it-test");
+	public static ElasticsearchContainer elasticsearchContainer =
+			new ElasticsearchContainer(
+					DockerImageName
+							.parse("docker.elastic.co/elasticsearch/elasticsearch-oss")
+							.withTag("7.5.1"));
+
+	@SuppressWarnings("deprecation")
+	protected final Client getClient() {
+		TransportAddress transportAddress = new TransportAddress(elasticsearchContainer.getTcpHost());
+		String expectedClusterName = "docker-cluster";
+		Settings settings = Settings.builder().put("cluster.name", expectedClusterName).build();
+		return new PreBuiltTransportClient(settings)
+				.addTransportAddress(transportAddress);
+	}
 
 	@Test
 	public void testWritingDocuments() throws Exception {
@@ -91,7 +108,7 @@ public class Elasticsearch7DynamicSinkITCase {
 			context()
 				.withSchema(schema)
 				.withOption(ElasticsearchOptions.INDEX_OPTION.key(), index)
-				.withOption(ElasticsearchOptions.HOSTS_OPTION.key(), "http://127.0.0.1:9200")
+				.withOption(ElasticsearchOptions.HOSTS_OPTION.key(), elasticsearchContainer.getHttpHostAddress())
 				.withOption(ElasticsearchOptions.FLUSH_ON_CHECKPOINT_OPTION.key(), "false")
 				.build()
 		).getSinkRuntimeProvider(new MockContext());
@@ -102,7 +119,7 @@ public class Elasticsearch7DynamicSinkITCase {
 		environment.<RowData>fromElements(rowData).addSink(sinkFunction);
 		environment.execute();
 
-		Client client = elasticsearchResource.getClient();
+		Client client = getClient();
 		Map<String, Object> response = client.get(new GetRequest(index, "1_2012-12-12T12:12:12")).actionGet().getSource();
 		Map<Object, Object> expectedMap = new HashMap<>();
 		expectedMap.put("a", 1);
@@ -137,7 +154,7 @@ public class Elasticsearch7DynamicSinkITCase {
 			"WITH (\n" +
 			String.format("'%s'='%s',\n", "connector", "elasticsearch-7") +
 			String.format("'%s'='%s',\n", ElasticsearchOptions.INDEX_OPTION.key(), index) +
-			String.format("'%s'='%s',\n", ElasticsearchOptions.HOSTS_OPTION.key(), "http://127.0.0.1:9200") +
+			String.format("'%s'='%s',\n", ElasticsearchOptions.HOSTS_OPTION.key(), elasticsearchContainer.getHttpHostAddress()) +
 			String.format("'%s'='%s'\n", ElasticsearchOptions.FLUSH_ON_CHECKPOINT_OPTION.key(), "false") +
 			")");
 
@@ -152,7 +169,7 @@ public class Elasticsearch7DynamicSinkITCase {
 				LocalDateTime.parse("2012-12-12T12:12:12"))
 		).executeInsert("esTable").await();
 
-		Client client = elasticsearchResource.getClient();
+		Client client = getClient();
 		Map<String, Object> response = client.get(new GetRequest(index, "1_2012-12-12T12:12:12")).actionGet().getSource();
 		Map<Object, Object> expectedMap = new HashMap<>();
 		expectedMap.put("a", 1);
@@ -185,7 +202,7 @@ public class Elasticsearch7DynamicSinkITCase {
 			"WITH (\n" +
 			String.format("'%s'='%s',\n", "connector", "elasticsearch-7") +
 			String.format("'%s'='%s',\n", ElasticsearchOptions.INDEX_OPTION.key(), index) +
-			String.format("'%s'='%s',\n", ElasticsearchOptions.HOSTS_OPTION.key(), "http://127.0.0.1:9200") +
+			String.format("'%s'='%s',\n", ElasticsearchOptions.HOSTS_OPTION.key(), elasticsearchContainer.getHttpHostAddress()) +
 			String.format("'%s'='%s'\n", ElasticsearchOptions.FLUSH_ON_CHECKPOINT_OPTION.key(), "false") +
 			")");
 
@@ -208,7 +225,7 @@ public class Elasticsearch7DynamicSinkITCase {
 				LocalDateTime.parse("2013-12-12T13:13:13"))
 		).executeInsert("esTable").await();
 
-		Client client = elasticsearchResource.getClient();
+		Client client = getClient();
 
 		// search API does not return documents that were not indexed, we might need to query
 		// the index a few times
@@ -269,14 +286,14 @@ public class Elasticsearch7DynamicSinkITCase {
 			"WITH (\n" +
 			String.format("'%s'='%s',\n", "connector", "elasticsearch-7") +
 			String.format("'%s'='%s',\n", ElasticsearchOptions.INDEX_OPTION.key(), index) +
-			String.format("'%s'='%s',\n", ElasticsearchOptions.HOSTS_OPTION.key(), "http://127.0.0.1:9200") +
+			String.format("'%s'='%s',\n", ElasticsearchOptions.HOSTS_OPTION.key(), elasticsearchContainer.getHttpHostAddress()) +
 			String.format("'%s'='%s'\n", ElasticsearchOptions.FLUSH_ON_CHECKPOINT_OPTION.key(), "false") +
 			")");
 
 		tableEnvironment.fromValues(row(1L, LocalDateTime.parse("2012-12-12T12:12:12")))
 			.executeInsert("esTable").await();
 
-		Client client = elasticsearchResource.getClient();
+		Client client = getClient();
 		Map<String, Object> response = client.get(new GetRequest("dynamic-index-2012-12-12", "1"))
 			.actionGet()
 			.getSource();
diff --git a/flink-connectors/flink-connector-elasticsearch7/src/test/java/org/apache/flink/streaming/connectors/elasticsearch7/ElasticsearchSinkITCase.java b/flink-connectors/flink-connector-elasticsearch7/src/test/java/org/apache/flink/streaming/connectors/elasticsearch7/ElasticsearchSinkITCase.java
index 66f1eabcc88..3ba3a8b80f3 100644
--- a/flink-connectors/flink-connector-elasticsearch7/src/test/java/org/apache/flink/streaming/connectors/elasticsearch7/ElasticsearchSinkITCase.java
+++ b/flink-connectors/flink-connector-elasticsearch7/src/test/java/org/apache/flink/streaming/connectors/elasticsearch7/ElasticsearchSinkITCase.java
@@ -24,8 +24,15 @@ import org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkFunc
 import org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkTestBase;
 
 import org.apache.http.HttpHost;
+import org.elasticsearch.client.Client;
 import org.elasticsearch.client.RestHighLevelClient;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.transport.TransportAddress;
+import org.elasticsearch.transport.client.PreBuiltTransportClient;
+import org.junit.ClassRule;
 import org.junit.Test;
+import org.testcontainers.elasticsearch.ElasticsearchContainer;
+import org.testcontainers.utility.DockerImageName;
 
 import java.util.ArrayList;
 import java.util.List;
@@ -35,6 +42,28 @@ import java.util.List;
  */
 public class ElasticsearchSinkITCase extends ElasticsearchSinkTestBase<RestHighLevelClient, HttpHost> {
 
+	@ClassRule
+	public static ElasticsearchContainer elasticsearchContainer =
+			new ElasticsearchContainer(
+					DockerImageName
+							.parse("docker.elastic.co/elasticsearch/elasticsearch-oss")
+							.withTag("7.5.1"));
+
+	@Override
+	protected String getClusterName() {
+		return "docker-cluster";
+	}
+
+	@Override
+	@SuppressWarnings("deprecation")
+	protected final Client getClient() {
+		TransportAddress transportAddress = new TransportAddress(elasticsearchContainer.getTcpHost());
+		String expectedClusterName = getClusterName();
+		Settings settings = Settings.builder().put("cluster.name", expectedClusterName).build();
+		return new PreBuiltTransportClient(settings)
+				.addTransportAddress(transportAddress);
+	}
+
 	@Test
 	public void testElasticsearchSink() throws Exception {
 		runElasticsearchSinkTest();
@@ -46,12 +75,12 @@ public class ElasticsearchSinkITCase extends ElasticsearchSinkTestBase<RestHighL
 	}
 
 	@Test
-	public void testNullAddresses() throws Exception {
+	public void testNullAddresses() {
 		runNullAddressesTest();
 	}
 
 	@Test
-	public void testEmptyAddresses() throws Exception {
+	public void testEmptyAddresses() {
 		runEmptyAddressesTest();
 	}
 
@@ -77,10 +106,10 @@ public class ElasticsearchSinkITCase extends ElasticsearchSinkTestBase<RestHighL
 	protected ElasticsearchSinkBase<Tuple2<Integer, String>, RestHighLevelClient> createElasticsearchSinkForEmbeddedNode(
 			int bulkFlushMaxActions,
 			String clusterName,
-			ElasticsearchSinkFunction<Tuple2<Integer, String>> elasticsearchSinkFunction) throws Exception {
+			ElasticsearchSinkFunction<Tuple2<Integer, String>> elasticsearchSinkFunction) {
 
 		return createElasticsearchSinkForNode(
-				bulkFlushMaxActions, clusterName, elasticsearchSinkFunction, "127.0.0.1");
+				bulkFlushMaxActions, clusterName, elasticsearchSinkFunction, elasticsearchContainer.getHttpHostAddress());
 	}
 
 	@Override
@@ -88,10 +117,10 @@ public class ElasticsearchSinkITCase extends ElasticsearchSinkTestBase<RestHighL
 			int bulkFlushMaxActions,
 			String clusterName,
 			ElasticsearchSinkFunction<Tuple2<Integer, String>> elasticsearchSinkFunction,
-			String ipAddress) throws Exception {
+			String hostAddress) {
 
 		ArrayList<HttpHost> httpHosts = new ArrayList<>();
-		httpHosts.add(new HttpHost(ipAddress, 9200, "http"));
+		httpHosts.add(HttpHost.create(hostAddress));
 
 		ElasticsearchSink.Builder<Tuple2<Integer, String>> builder = new ElasticsearchSink.Builder<>(httpHosts, elasticsearchSinkFunction);
 		builder.setBulkFlushMaxActions(bulkFlushMaxActions);
