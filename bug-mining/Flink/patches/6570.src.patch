diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsMemoryDataManager.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsMemoryDataManager.java
index d7f0e2b346d..2fc63646c03 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsMemoryDataManager.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsMemoryDataManager.java
@@ -150,6 +150,14 @@ public class HsMemoryDataManager implements HsSpillingInfoProvider, HsMemoryData
         spiller.release();
     }
 
+    public void setOutputMetrics(HsOutputMetrics metrics) {
+        // HsOutputMetrics is not thread-safe. It can be shared by all the subpartitions because it
+        // is expected always updated from the producer task's mailbox thread.
+        for (int i = 0; i < numSubpartitions; i++) {
+            getSubpartitionMemoryDataManager(i).setOutputMetrics(metrics);
+        }
+    }
+
     // ------------------------------------
     //        For Spilling Strategy
     // ------------------------------------
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsOutputMetrics.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsOutputMetrics.java
new file mode 100644
index 00000000000..6ffb1f03d01
--- /dev/null
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsOutputMetrics.java
@@ -0,0 +1,40 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.runtime.io.network.partition.hybrid;
+
+import org.apache.flink.metrics.Counter;
+
+/** All metrics that {@link HsResultPartition} needs to count, except numBytesProduced. */
+public class HsOutputMetrics {
+    private final Counter numBytesOut;
+    private final Counter numBuffersOut;
+
+    public HsOutputMetrics(Counter numBytesOut, Counter numBuffersOut) {
+        this.numBytesOut = numBytesOut;
+        this.numBuffersOut = numBuffersOut;
+    }
+
+    public Counter getNumBytesOut() {
+        return numBytesOut;
+    }
+
+    public Counter getNumBuffersOut() {
+        return numBuffersOut;
+    }
+}
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsResultPartition.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsResultPartition.java
index 31e257db8f5..15242440ad1 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsResultPartition.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsResultPartition.java
@@ -35,6 +35,7 @@ import org.apache.flink.runtime.io.network.partition.ResultPartitionID;
 import org.apache.flink.runtime.io.network.partition.ResultPartitionManager;
 import org.apache.flink.runtime.io.network.partition.ResultPartitionType;
 import org.apache.flink.runtime.io.network.partition.ResultSubpartitionView;
+import org.apache.flink.runtime.metrics.groups.TaskIOMetricGroup;
 import org.apache.flink.util.function.SupplierWithException;
 
 import javax.annotation.Nullable;
@@ -127,8 +128,16 @@ public class HsResultPartition extends ResultPartition {
                         bufferCompressor);
     }
 
+    @Override
+    public void setMetricGroup(TaskIOMetricGroup metrics) {
+        super.setMetricGroup(metrics);
+        checkNotNull(memoryDataManager)
+                .setOutputMetrics(new HsOutputMetrics(numBytesOut, numBuffersOut));
+    }
+
     @Override
     public void emitRecord(ByteBuffer record, int targetSubpartition) throws IOException {
+        numBytesProduced.inc(record.remaining());
         emit(record, targetSubpartition, Buffer.DataType.DATA_BUFFER);
     }
 
@@ -149,6 +158,7 @@ public class HsResultPartition extends ResultPartition {
     }
 
     private void broadcast(ByteBuffer record, Buffer.DataType dataType) throws IOException {
+        numBytesProduced.inc(record.remaining());
         for (int i = 0; i < numSubpartitions; i++) {
             emit(record.duplicate(), i, dataType);
         }
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionMemoryDataManager.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionMemoryDataManager.java
index 17b7e833e29..7d7b529d5af 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionMemoryDataManager.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionMemoryDataManager.java
@@ -33,6 +33,7 @@ import org.apache.flink.runtime.io.network.partition.hybrid.HsSpillingInfoProvid
 import org.apache.flink.util.function.SupplierWithException;
 import org.apache.flink.util.function.ThrowingRunnable;
 
+import javax.annotation.Nullable;
 import javax.annotation.concurrent.GuardedBy;
 
 import java.nio.ByteBuffer;
@@ -83,6 +84,8 @@ public class HsSubpartitionMemoryDataManager implements HsDataView {
     /** DO NOT USE DIRECTLY. Use {@link #runWithLock} or {@link #callWithLock} instead. */
     private final Object subpartitionLock = new Object();
 
+    @Nullable private HsOutputMetrics outputMetrics;
+
     HsSubpartitionMemoryDataManager(
             int targetChannel,
             int bufferSize,
@@ -266,6 +269,10 @@ public class HsSubpartitionMemoryDataManager implements HsDataView {
                                 }));
     }
 
+    public void setOutputMetrics(HsOutputMetrics outputMetrics) {
+        this.outputMetrics = checkNotNull(outputMetrics);
+    }
+
     // ------------------------------------------------------------------------
     //  Internal Methods
     // ------------------------------------------------------------------------
@@ -368,6 +375,7 @@ public class HsSubpartitionMemoryDataManager implements HsDataView {
                                     bufferContext.getBufferIndexAndChannel().getBufferIndex(),
                                     bufferContext);
                             trimHeadingReleasedBuffers(unConsumedBuffers);
+                            updateStatistics(bufferContext.getBuffer());
                             return unConsumedBuffers.size() <= 1;
                         });
         if (needNotify) {
@@ -472,6 +480,11 @@ public class HsSubpartitionMemoryDataManager implements HsDataView {
         return match;
     }
 
+    private void updateStatistics(Buffer buffer) {
+        checkNotNull(outputMetrics).getNumBuffersOut().inc();
+        checkNotNull(outputMetrics).getNumBytesOut().inc(buffer.readableBytes());
+    }
+
     private <E extends Exception> void runWithLock(ThrowingRunnable<E> runnable) throws E {
         try {
             resultPartitionLock.lock();
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsMemoryDataManagerTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsMemoryDataManagerTest.java
index 0bb65f3f15e..4cf1bc88c94 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsMemoryDataManagerTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsMemoryDataManagerTest.java
@@ -39,6 +39,7 @@ import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicInteger;
 
+import static org.apache.flink.runtime.io.network.partition.hybrid.HybridShuffleTestUtils.createTestingOutputMetrics;
 import static org.assertj.core.api.Assertions.assertThat;
 
 /** Tests for {@link HsMemoryDataManager}. */
@@ -193,30 +194,24 @@ class HsMemoryDataManagerTest {
 
     private HsMemoryDataManager createMemoryDataManager(HsSpillingStrategy spillStrategy)
             throws Exception {
-        NetworkBufferPool networkBufferPool = new NetworkBufferPool(NUM_BUFFERS, bufferSize);
-        BufferPool bufferPool = networkBufferPool.createBufferPool(poolSize, poolSize);
-        return new HsMemoryDataManager(
-                NUM_SUBPARTITIONS,
-                bufferSize,
-                bufferPool,
-                spillStrategy,
-                new HsFileDataIndexImpl(NUM_SUBPARTITIONS),
-                dataFilePath,
-                null);
+        return createMemoryDataManager(spillStrategy, new HsFileDataIndexImpl(NUM_SUBPARTITIONS));
     }
 
     private HsMemoryDataManager createMemoryDataManager(
             HsSpillingStrategy spillStrategy, HsFileDataIndex fileDataIndex) throws Exception {
         NetworkBufferPool networkBufferPool = new NetworkBufferPool(NUM_BUFFERS, bufferSize);
         BufferPool bufferPool = networkBufferPool.createBufferPool(poolSize, poolSize);
-        return new HsMemoryDataManager(
-                NUM_SUBPARTITIONS,
-                bufferSize,
-                bufferPool,
-                spillStrategy,
-                fileDataIndex,
-                dataFilePath,
-                null);
+        HsMemoryDataManager memoryDataManager =
+                new HsMemoryDataManager(
+                        NUM_SUBPARTITIONS,
+                        bufferSize,
+                        bufferPool,
+                        spillStrategy,
+                        fileDataIndex,
+                        dataFilePath,
+                        null);
+        memoryDataManager.setOutputMetrics(createTestingOutputMetrics());
+        return memoryDataManager;
     }
 
     private static ByteBuffer createRecord(int value) {
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsResultPartitionTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsResultPartitionTest.java
index 0973fa5052a..73826440553 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsResultPartitionTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsResultPartitionTest.java
@@ -23,6 +23,7 @@ import org.apache.flink.core.memory.MemorySegment;
 import org.apache.flink.core.memory.MemorySegmentFactory;
 import org.apache.flink.core.testutils.CheckedThread;
 import org.apache.flink.runtime.event.AbstractEvent;
+import org.apache.flink.runtime.executiongraph.IOMetrics;
 import org.apache.flink.runtime.io.disk.BatchShuffleReadBufferPool;
 import org.apache.flink.runtime.io.disk.FileChannelManager;
 import org.apache.flink.runtime.io.disk.FileChannelManagerImpl;
@@ -40,6 +41,8 @@ import org.apache.flink.runtime.io.network.partition.ResultPartitionType;
 import org.apache.flink.runtime.io.network.partition.ResultSubpartition;
 import org.apache.flink.runtime.io.network.partition.ResultSubpartitionView;
 import org.apache.flink.runtime.io.network.partition.hybrid.HybridShuffleConfiguration.SpillingStrategyType;
+import org.apache.flink.runtime.metrics.groups.TaskIOMetricGroup;
+import org.apache.flink.runtime.metrics.groups.UnregisteredMetricGroups;
 
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
@@ -84,6 +87,8 @@ class HsResultPartitionTest {
 
     private ExecutorService readIOExecutor;
 
+    private TaskIOMetricGroup taskIOMetricGroup;
+
     @TempDir public Path tempDataPath;
 
     @BeforeEach
@@ -280,6 +285,22 @@ class HsResultPartitionTest {
         assertThat(partition.isAvailable()).isTrue();
     }
 
+    @Test
+    void testMetricsUpdate() throws Exception {
+        BufferPool bufferPool = globalPool.createBufferPool(3, 3);
+        try (HsResultPartition partition = createHsResultPartition(2, bufferPool)) {
+            partition.emitRecord(ByteBuffer.allocate(bufferSize), 0);
+            partition.broadcastRecord(ByteBuffer.allocate(bufferSize));
+            assertThat(taskIOMetricGroup.getNumBuffersOutCounter().getCount()).isEqualTo(3);
+            assertThat(taskIOMetricGroup.getNumBytesOutCounter().getCount())
+                    .isEqualTo(3 * bufferSize);
+            IOMetrics ioMetrics = taskIOMetricGroup.createSnapshot();
+            assertThat(ioMetrics.getNumBytesProducedOfPartitions())
+                    .hasSize(1)
+                    .containsValue((long) 2 * bufferSize);
+        }
+    }
+
     private static void recordDataWritten(
             ByteBuffer record,
             Queue<Tuple2<ByteBuffer, Buffer.DataType>>[] dataWritten,
@@ -391,7 +412,10 @@ class HsResultPartitionTest {
                                 .build(),
                         null,
                         () -> bufferPool);
+        taskIOMetricGroup =
+                UnregisteredMetricGroups.createUnregisteredTaskMetricGroup().getIOMetricGroup();
         hsResultPartition.setup();
+        hsResultPartition.setMetricGroup(taskIOMetricGroup);
         return hsResultPartition;
     }
 
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionMemoryDataManagerTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionMemoryDataManagerTest.java
index f1b16d0d231..3edf397cfcb 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionMemoryDataManagerTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionMemoryDataManagerTest.java
@@ -21,6 +21,8 @@ package org.apache.flink.runtime.io.network.partition.hybrid;
 import org.apache.flink.api.java.tuple.Tuple2;
 import org.apache.flink.core.memory.MemorySegment;
 import org.apache.flink.core.memory.MemorySegmentFactory;
+import org.apache.flink.runtime.io.network.api.EndOfPartitionEvent;
+import org.apache.flink.runtime.io.network.api.serialization.EventSerializer;
 import org.apache.flink.runtime.io.network.buffer.Buffer;
 import org.apache.flink.runtime.io.network.buffer.Buffer.DataType;
 import org.apache.flink.runtime.io.network.buffer.BufferBuilder;
@@ -44,6 +46,7 @@ import java.util.concurrent.locks.ReentrantReadWriteLock;
 import java.util.stream.Collectors;
 
 import static org.apache.flink.runtime.io.network.partition.hybrid.HybridShuffleTestUtils.createBufferBuilder;
+import static org.apache.flink.runtime.io.network.partition.hybrid.HybridShuffleTestUtils.createTestingOutputMetrics;
 import static org.apache.flink.util.Preconditions.checkArgument;
 import static org.assertj.core.api.Assertions.assertThat;
 
@@ -354,6 +357,29 @@ class HsSubpartitionMemoryDataManagerTest {
         checkMemorySegmentValue(recycledBuffers, Arrays.asList(0, 1, 2));
     }
 
+    @Test
+    void testMetricsUpdate() throws Exception {
+        final int recordSize = bufferSize / 2;
+        TestingMemoryDataManagerOperation memoryDataManagerOperation =
+                TestingMemoryDataManagerOperation.builder()
+                        .setRequestBufferFromPoolSupplier(() -> createBufferBuilder(bufferSize))
+                        .build();
+
+        HsOutputMetrics metrics = createTestingOutputMetrics();
+        HsSubpartitionMemoryDataManager subpartitionMemoryDataManager =
+                createSubpartitionMemoryDataManager(memoryDataManagerOperation);
+        subpartitionMemoryDataManager.setOutputMetrics(metrics);
+
+        subpartitionMemoryDataManager.append(ByteBuffer.allocate(recordSize), DataType.DATA_BUFFER);
+        ByteBuffer eventBuffer = EventSerializer.toSerializedEvent(EndOfPartitionEvent.INSTANCE);
+        final int eventSize = eventBuffer.remaining();
+        subpartitionMemoryDataManager.append(
+                EventSerializer.toSerializedEvent(EndOfPartitionEvent.INSTANCE),
+                DataType.EVENT_BUFFER);
+        assertThat(metrics.getNumBuffersOut().getCount()).isEqualTo(2);
+        assertThat(metrics.getNumBytesOut().getCount()).isEqualTo(recordSize + eventSize);
+    }
+
     private static void checkBufferIndex(
             Deque<BufferIndexAndChannel> bufferWithIdentities, List<Integer> expectedIndexes) {
         List<Integer> bufferIndexes =
@@ -413,8 +439,11 @@ class HsSubpartitionMemoryDataManagerTest {
 
     private HsSubpartitionMemoryDataManager createSubpartitionMemoryDataManager(
             HsMemoryDataManagerOperation memoryDataManagerOperation) {
-        return new HsSubpartitionMemoryDataManager(
-                SUBPARTITION_ID, bufferSize, lock.readLock(), memoryDataManagerOperation);
+        HsSubpartitionMemoryDataManager subpartitionMemoryDataManager =
+                new HsSubpartitionMemoryDataManager(
+                        SUBPARTITION_ID, bufferSize, lock.readLock(), memoryDataManagerOperation);
+        subpartitionMemoryDataManager.setOutputMetrics(createTestingOutputMetrics());
+        return subpartitionMemoryDataManager;
     }
 
     private static ByteBuffer createRecord(int value) {
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionViewTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionViewTest.java
index b81373ac11e..aedb0602c83 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionViewTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HsSubpartitionViewTest.java
@@ -38,6 +38,7 @@ import java.util.Optional;
 import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.atomic.AtomicInteger;
 
+import static org.apache.flink.runtime.io.network.partition.hybrid.HybridShuffleTestUtils.createTestingOutputMetrics;
 import static org.assertj.core.api.Assertions.assertThat;
 import static org.assertj.core.api.Assertions.assertThatThrownBy;
 
@@ -114,6 +115,7 @@ class HsSubpartitionViewTest {
                         new HsFileDataIndexImpl(1),
                         dataFilePath.resolve(".data"),
                         null);
+        memoryDataManager.setOutputMetrics(createTestingOutputMetrics());
         HsDataView hsDataView = memoryDataManager.registerSubpartitionView(0, subpartitionView);
         subpartitionView.setMemoryDataView(hsDataView);
         subpartitionView.setDiskDataView(TestingHsDataView.NO_OP);
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HybridShuffleTestUtils.java b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HybridShuffleTestUtils.java
index 0d7ec874ba9..f32e3179563 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HybridShuffleTestUtils.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/HybridShuffleTestUtils.java
@@ -20,6 +20,7 @@ package org.apache.flink.runtime.io.network.partition.hybrid;
 
 import org.apache.flink.core.memory.MemorySegment;
 import org.apache.flink.core.memory.MemorySegmentFactory;
+import org.apache.flink.metrics.util.TestCounter;
 import org.apache.flink.runtime.io.network.buffer.Buffer;
 import org.apache.flink.runtime.io.network.buffer.BufferBuilder;
 import org.apache.flink.runtime.io.network.buffer.FreeingBufferRecycler;
@@ -68,4 +69,8 @@ public class HybridShuffleTestUtils {
                 MemorySegmentFactory.allocateUnpooledSegment(bufferSize),
                 FreeingBufferRecycler.INSTANCE);
     }
+
+    public static HsOutputMetrics createTestingOutputMetrics() {
+        return new HsOutputMetrics(new TestCounter(), new TestCounter());
+    }
 }
