diff --git a/docs/content.zh/docs/dev/table/hive-compatibility/hiveserver2.md b/docs/content.zh/docs/dev/table/hive-compatibility/hiveserver2.md
index 0fdf6025495..3d414e7eda1 100644
--- a/docs/content.zh/docs/dev/table/hive-compatibility/hiveserver2.md
+++ b/docs/content.zh/docs/dev/table/hive-compatibility/hiveserver2.md
@@ -287,7 +287,7 @@ to the Flink SQL Gateway like Hive. Please refer to the [guidance](https://super
 the following JDBC URL to connect to the Apache Superset:
 
 ```bash
-jdbc:hive2://{host}:{port}/{database}?auth=NOSASL
+hive://hive@{host}:{port}/{database}?auth=NOSASL
 ```
 
 Streaming SQL
diff --git a/docs/content/docs/dev/table/hive-compatibility/hiveserver2.md b/docs/content/docs/dev/table/hive-compatibility/hiveserver2.md
index 4320cdc965e..9d6dc46d143 100644
--- a/docs/content/docs/dev/table/hive-compatibility/hiveserver2.md
+++ b/docs/content/docs/dev/table/hive-compatibility/hiveserver2.md
@@ -287,7 +287,7 @@ to the Flink SQL Gateway like Hive. Please refer to the [guidance](https://super
 the following JDBC URL to connect to the Apache Superset:
 
 ```bash
-jdbc:hive2://{host}:{port}/{database}?auth=NOSASL
+hive://hive@{host}:{port}/{database}?auth=NOSASL
 ```
 
 Streaming SQL
diff --git a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/endpoint/hive/HiveServer2Endpoint.java b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/endpoint/hive/HiveServer2Endpoint.java
index 1bc38b09dfb..0260503368b 100644
--- a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/endpoint/hive/HiveServer2Endpoint.java
+++ b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/endpoint/hive/HiveServer2Endpoint.java
@@ -183,7 +183,7 @@ public class HiveServer2Endpoint implements TCLIService.Iface, SqlGatewayEndpoin
 
     private final String catalogName;
     @Nullable private final String defaultDatabase;
-    @Nullable private final String hiveConfPath;
+    private final HiveConf hiveConf;
     private final boolean allowEmbedded;
 
     // --------------------------------------------------------------------------------------------
@@ -202,7 +202,7 @@ public class HiveServer2Endpoint implements TCLIService.Iface, SqlGatewayEndpoin
             int maxWorkerThreads,
             Duration workerKeepAliveTime,
             String catalogName,
-            @Nullable String hiveConfPath,
+            HiveConf hiveConf,
             @Nullable String defaultDatabase,
             String moduleName) {
         this(
@@ -215,7 +215,7 @@ public class HiveServer2Endpoint implements TCLIService.Iface, SqlGatewayEndpoin
                 maxWorkerThreads,
                 workerKeepAliveTime,
                 catalogName,
-                hiveConfPath,
+                hiveConf,
                 defaultDatabase,
                 moduleName,
                 false,
@@ -233,7 +233,7 @@ public class HiveServer2Endpoint implements TCLIService.Iface, SqlGatewayEndpoin
             int maxWorkerThreads,
             Duration workerKeepAliveTime,
             String catalogName,
-            @Nullable String hiveConfPath,
+            HiveConf hiveConf,
             @Nullable String defaultDatabase,
             String moduleName,
             boolean allowEmbedded,
@@ -250,7 +250,7 @@ public class HiveServer2Endpoint implements TCLIService.Iface, SqlGatewayEndpoin
         this.isVerbose = isVerbose;
 
         this.catalogName = checkNotNull(catalogName);
-        this.hiveConfPath = hiveConfPath;
+        this.hiveConf = hiveConf;
         this.defaultDatabase = defaultDatabase;
 
         this.moduleName = moduleName;
@@ -296,14 +296,8 @@ public class HiveServer2Endpoint implements TCLIService.Iface, SqlGatewayEndpoin
                     tOpenSessionReq.getConfiguration() == null
                             ? Collections.emptyMap()
                             : tOpenSessionReq.getConfiguration();
-            Map<String, String> sessionConfig = new HashMap<>();
-            sessionConfig.put(TABLE_SQL_DIALECT.key(), SqlDialect.HIVE.name());
-            sessionConfig.put(RUNTIME_MODE.key(), RuntimeExecutionMode.BATCH.name());
-            sessionConfig.put(TABLE_DML_SYNC.key(), "true");
-            HiveConf conf = HiveCatalog.createHiveConf(hiveConfPath, null);
-            // set variables to HiveConf or Session's conf
-            setVariables(conf, sessionConfig, originSessionConf);
 
+            HiveConf conf = new HiveConf(hiveConf);
             Catalog hiveCatalog =
                     new HiveCatalog(
                             catalogName,
@@ -311,7 +305,18 @@ public class HiveServer2Endpoint implements TCLIService.Iface, SqlGatewayEndpoin
                             conf,
                             HiveShimLoader.getHiveVersion(),
                             allowEmbedded);
+            // Trigger the creation of the HiveMetaStoreClient to use the same HiveConf. If the
+            // initial HiveConf is different, it will trigger the PersistenceManagerFactory to close
+            // all the alive PersistenceManager in the ObjectStore, which may get error like
+            // "Persistence Manager has been closed" in the later connection.
+            hiveCatalog.open();
             Module hiveModule = new HiveModule();
+            // set variables to HiveConf and Session's conf
+            Map<String, String> sessionConfig = new HashMap<>();
+            sessionConfig.put(TABLE_SQL_DIALECT.key(), SqlDialect.HIVE.name());
+            sessionConfig.put(RUNTIME_MODE.key(), RuntimeExecutionMode.BATCH.name());
+            sessionConfig.put(TABLE_DML_SYNC.key(), "true");
+            setVariables(conf, sessionConfig, originSessionConf);
             SessionHandle sessionHandle =
                     service.openSession(
                             SessionEnvironment.newBuilder()
@@ -801,7 +806,6 @@ public class HiveServer2Endpoint implements TCLIService.Iface, SqlGatewayEndpoin
                 && Objects.equals(workerKeepAliveTime, that.workerKeepAliveTime)
                 && Objects.equals(catalogName, that.catalogName)
                 && Objects.equals(defaultDatabase, that.defaultDatabase)
-                && Objects.equals(hiveConfPath, that.hiveConfPath)
                 && Objects.equals(allowEmbedded, that.allowEmbedded)
                 && Objects.equals(isVerbose, that.isVerbose)
                 && Objects.equals(moduleName, that.moduleName);
@@ -819,7 +823,6 @@ public class HiveServer2Endpoint implements TCLIService.Iface, SqlGatewayEndpoin
                 maxMessageSize,
                 catalogName,
                 defaultDatabase,
-                hiveConfPath,
                 allowEmbedded,
                 isVerbose,
                 moduleName);
diff --git a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/endpoint/hive/HiveServer2EndpointFactory.java b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/endpoint/hive/HiveServer2EndpointFactory.java
index 553e3f909eb..7517d8b573d 100644
--- a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/endpoint/hive/HiveServer2EndpointFactory.java
+++ b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/endpoint/hive/HiveServer2EndpointFactory.java
@@ -21,6 +21,7 @@ package org.apache.flink.table.endpoint.hive;
 import org.apache.flink.configuration.ConfigOption;
 import org.apache.flink.configuration.ReadableConfig;
 import org.apache.flink.table.api.ValidationException;
+import org.apache.flink.table.catalog.hive.HiveCatalog;
 import org.apache.flink.table.gateway.api.endpoint.SqlGatewayEndpoint;
 import org.apache.flink.table.gateway.api.endpoint.SqlGatewayEndpointFactory;
 import org.apache.flink.table.gateway.api.endpoint.SqlGatewayEndpointFactoryUtils;
@@ -67,7 +68,7 @@ public class HiveServer2EndpointFactory implements SqlGatewayEndpointFactory {
                 configuration.get(THRIFT_WORKER_THREADS_MAX),
                 configuration.get(THRIFT_WORKER_KEEPALIVE_TIME),
                 configuration.get(CATALOG_NAME),
-                configuration.get(CATALOG_HIVE_CONF_DIR),
+                HiveCatalog.createHiveConf(configuration.get(CATALOG_HIVE_CONF_DIR), null),
                 configuration.get(CATALOG_DEFAULT_DATABASE),
                 configuration.get(MODULE_NAME));
     }
diff --git a/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveTestUtils.java b/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveTestUtils.java
index 278a9f57764..65bd028c349 100644
--- a/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveTestUtils.java
+++ b/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveTestUtils.java
@@ -44,10 +44,8 @@ import org.junit.rules.TemporaryFolder;
 
 import java.io.BufferedWriter;
 import java.io.File;
-import java.io.FileOutputStream;
 import java.io.FileWriter;
 import java.io.IOException;
-import java.io.OutputStream;
 import java.net.BindException;
 import java.net.InetSocketAddress;
 import java.net.ServerSocket;
@@ -131,15 +129,6 @@ public class HiveTestUtils {
         }
     }
 
-    public static File createHiveSite() throws Exception {
-        HiveConf conf = createHiveConf();
-        File site = TEMPORARY_FOLDER.newFile("hive-site.xml");
-        try (OutputStream out = new FileOutputStream(site)) {
-            conf.writeXml(out);
-        }
-        return site;
-    }
-
     // Gets a free port of localhost. Note that this method suffers the "time of check to time of
     // use" race condition.
     // Use it as best efforts to avoid port conflicts.
diff --git a/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/endpoint/hive/HiveServer2EndpointFactoryTest.java b/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/endpoint/hive/HiveServer2EndpointFactoryTest.java
index bfa1270d546..1382a2e9f1b 100644
--- a/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/endpoint/hive/HiveServer2EndpointFactoryTest.java
+++ b/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/endpoint/hive/HiveServer2EndpointFactoryTest.java
@@ -21,6 +21,8 @@ package org.apache.flink.table.endpoint.hive;
 import org.apache.flink.configuration.ConfigOption;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.core.testutils.FlinkAssertions;
+import org.apache.flink.table.catalog.hive.HiveCatalog;
+import org.apache.flink.table.catalog.hive.HiveTestUtils;
 import org.apache.flink.table.gateway.api.endpoint.SqlGatewayEndpointFactoryUtils;
 import org.apache.flink.table.gateway.api.utils.MockedSqlGatewayService;
 
@@ -29,6 +31,7 @@ import org.junit.jupiter.params.ParameterizedTest;
 import org.junit.jupiter.params.provider.MethodSource;
 
 import java.net.InetSocketAddress;
+import java.nio.file.Paths;
 import java.time.Duration;
 import java.util.Arrays;
 import java.util.Collections;
@@ -52,6 +55,7 @@ import static org.apache.flink.table.endpoint.hive.HiveServer2EndpointConfigOpti
 import static org.apache.flink.table.endpoint.hive.HiveServer2EndpointFactory.IDENTIFIER;
 import static org.apache.flink.table.factories.FactoryUtil.SQL_GATEWAY_ENDPOINT_TYPE;
 import static org.apache.flink.table.gateway.api.endpoint.SqlGatewayEndpointFactoryUtils.GATEWAY_ENDPOINT_PREFIX;
+import static org.apache.flink.util.Preconditions.checkNotNull;
 import static org.assertj.core.api.Assertions.assertThat;
 import static org.assertj.core.api.Assertions.assertThatThrownBy;
 
@@ -69,7 +73,6 @@ class HiveServer2EndpointFactoryTest {
     private final Duration backOffSlotLength = Duration.ofMillis(300);
 
     private final String catalogName = "test-hive";
-    private final String hiveConfPath = "/path/to/conf";
     private final String defaultDatabase = "test-db";
     private final String moduleName = "test-module";
 
@@ -90,7 +93,7 @@ class HiveServer2EndpointFactoryTest {
                                         maxWorkerThreads,
                                         workerAliveDuration,
                                         catalogName,
-                                        hiveConfPath,
+                                        HiveTestUtils.createHiveConf(),
                                         defaultDatabase,
                                         moduleName)));
     }
@@ -179,7 +182,17 @@ class HiveServer2EndpointFactoryTest {
         setEndpointOption(config, THRIFT_LOGIN_TIMEOUT, "10s");
 
         setEndpointOption(config, CATALOG_NAME, catalogName);
-        setEndpointOption(config, CATALOG_HIVE_CONF_DIR, hiveConfPath);
+        setEndpointOption(
+                config,
+                CATALOG_HIVE_CONF_DIR,
+                Paths.get(
+                                checkNotNull(
+                                                HiveTestUtils.class
+                                                        .getClassLoader()
+                                                        .getResource(HiveCatalog.HIVE_SITE_FILE))
+                                        .toString())
+                        .toFile()
+                        .getParent());
         setEndpointOption(config, CATALOG_DEFAULT_DATABASE, defaultDatabase);
 
         setEndpointOption(config, MODULE_NAME, moduleName);
diff --git a/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/endpoint/hive/util/HiveServer2EndpointExtension.java b/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/endpoint/hive/util/HiveServer2EndpointExtension.java
index 634f5152f38..fb6d48c7db1 100644
--- a/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/endpoint/hive/util/HiveServer2EndpointExtension.java
+++ b/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/endpoint/hive/util/HiveServer2EndpointExtension.java
@@ -79,7 +79,7 @@ public class HiveServer2EndpointExtension implements BeforeAllCallback, AfterAll
                         endpointConfig.get(THRIFT_WORKER_THREADS_MAX),
                         endpointConfig.get(THRIFT_WORKER_KEEPALIVE_TIME),
                         endpointConfig.get(CATALOG_NAME),
-                        HiveTestUtils.createHiveSite().getParent(),
+                        HiveTestUtils.createHiveConf(),
                         endpointConfig.get(CATALOG_DEFAULT_DATABASE),
                         endpointConfig.get(MODULE_NAME),
                         true,
@@ -112,7 +112,7 @@ public class HiveServer2EndpointExtension implements BeforeAllCallback, AfterAll
         // Please cc FLINK-27999 for more details
         return DriverManager.getConnection(
                 String.format(
-                        "jdbc:hive2://%s:%s/default;auth=noSasl?datanucleus.schema.autoCreateAll=true",
+                        "jdbc:hive2://%s:%s/default;auth=noSasl",
                         InetAddress.getLocalHost().getHostAddress(), getPort()));
     }
 }
