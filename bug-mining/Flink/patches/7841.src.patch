diff --git a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/CodeGenUtils.scala b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/CodeGenUtils.scala
index 5da8128a21a..0f946b173dc 100644
--- a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/CodeGenUtils.scala
+++ b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/CodeGenUtils.scala
@@ -123,6 +123,8 @@ object CodeGenUtils {
 
   val RUNTIME_CONTEXT: String = className[RuntimeContext]
 
+  val FILTER_CONTEXT: String = className[FilterCondition.Context]
+
   // ----------------------------------------------------------------------------------------
 
   private val nameCounter = new AtomicLong
diff --git a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/FunctionCodeGenerator.scala b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/FunctionCodeGenerator.scala
index 3b5943d6ab6..817d399bacc 100644
--- a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/FunctionCodeGenerator.scala
+++ b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/planner/codegen/FunctionCodeGenerator.scala
@@ -195,6 +195,8 @@ object FunctionCodeGenerator {
    *   the first input term
    * @param input2Term
    *   the second input term.
+   * @param contextTerm
+   *   the term used for a context for retrieving time service
    * @return
    *   the generated condition function name and code
    */
@@ -204,14 +206,15 @@ object FunctionCodeGenerator {
       clazz: Class[F],
       bodyCode: String,
       input1Term: String = CodeGenUtils.DEFAULT_INPUT1_TERM,
-      input2Term: String = CodeGenUtils.DEFAULT_INPUT2_TERM): (String, String) = {
+      input2Term: String = CodeGenUtils.DEFAULT_INPUT2_TERM,
+      contextTerm: String = CodeGenUtils.DEFAULT_CONTEXT_TERM): (String, String) = {
     val funcName = newName(ctx, name)
 
     val methodHeader = {
       if (clazz == classOf[JoinCondition]) {
         s"apply($ROW_DATA $input1Term, $ROW_DATA $input2Term)"
       } else if (clazz == classOf[FilterCondition]) {
-        s"apply($ROW_DATA $input1Term)"
+        s"apply($FILTER_CONTEXT $contextTerm, $ROW_DATA $input1Term)"
       } else {
         throw new CodeGenException(s"Unsupported Condition Function $clazz.")
       }
diff --git a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/stream/ChangelogNormalizeRestoreTest.java b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/stream/ChangelogNormalizeRestoreTest.java
index 03fbd5db543..b903fde8081 100644
--- a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/stream/ChangelogNormalizeRestoreTest.java
+++ b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/stream/ChangelogNormalizeRestoreTest.java
@@ -40,6 +40,7 @@ public class ChangelogNormalizeRestoreTest extends RestoreTestBase {
                 ChangelogNormalizeTestPrograms.CHANGELOG_SOURCE,
                 ChangelogNormalizeTestPrograms.CHANGELOG_SOURCE_MINI_BATCH,
                 ChangelogNormalizeTestPrograms.UPSERT_SOURCE,
-                ChangelogNormalizeTestPrograms.UPSERT_SOURCE_WITH_FILTER);
+                ChangelogNormalizeTestPrograms.UPSERT_SOURCE_WITH_FILTER,
+                ChangelogNormalizeTestPrograms.UPSERT_SOURCE_WITH_FILTER_ON_WATERMARK);
     }
 }
diff --git a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/stream/ChangelogNormalizeTestPrograms.java b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/stream/ChangelogNormalizeTestPrograms.java
index e92fe2839a4..786b4f57bb0 100644
--- a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/stream/ChangelogNormalizeTestPrograms.java
+++ b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/stream/ChangelogNormalizeTestPrograms.java
@@ -26,6 +26,7 @@ import org.apache.flink.types.Row;
 import org.apache.flink.types.RowKind;
 
 import java.time.Duration;
+import java.time.Instant;
 
 /** {@link TableTestProgram} definitions for testing {@link StreamExecChangelogNormalize}. */
 public class ChangelogNormalizeTestPrograms {
@@ -199,4 +200,88 @@ public class ChangelogNormalizeTestPrograms {
                                     .build())
                     .runSql("INSERT INTO sink_t SELECT a, b, c FROM source_t WHERE b < 10")
                     .build();
+
+    static final TableTestProgram UPSERT_SOURCE_WITH_FILTER_ON_WATERMARK =
+            TableTestProgram.of(
+                            "changelog-normalize-upsert-filter-watermark",
+                            "validates changelog normalize upsert with filter using current_watermark")
+                    .setupConfig(
+                            ExecutionConfigOptions.TABLE_EXEC_SOURCE_CDC_EVENTS_DUPLICATE, true)
+                    .setupTableSource(
+                            SourceTestStep.newBuilder("source_t")
+                                    .addOption("changelog-mode", "I,UA,D")
+                                    .addSchema(
+                                            "a VARCHAR",
+                                            "b INT NOT NULL",
+                                            "c VARCHAR",
+                                            "d TIMESTAMP_LTZ(3)",
+                                            "WATERMARK FOR d AS d",
+                                            "PRIMARY KEY(a) NOT ENFORCED")
+                                    .producedBeforeRestore(
+                                            Row.ofKind(
+                                                    RowKind.UPDATE_AFTER,
+                                                    "one",
+                                                    1,
+                                                    "a",
+                                                    Instant.ofEpochMilli(1L)),
+                                            Row.ofKind(
+                                                    RowKind.UPDATE_AFTER,
+                                                    "one",
+                                                    2,
+                                                    "b",
+                                                    Instant.ofEpochMilli(2L)),
+                                            Row.ofKind(
+                                                    RowKind.UPDATE_AFTER,
+                                                    "one",
+                                                    12,
+                                                    "b",
+                                                    Instant.ofEpochMilli(3L)),
+                                            Row.ofKind(
+                                                    RowKind.UPDATE_AFTER,
+                                                    "one",
+                                                    13,
+                                                    "b",
+                                                    Instant.ofEpochMilli(4L)),
+                                            Row.ofKind(
+                                                    RowKind.UPDATE_AFTER,
+                                                    "three",
+                                                    3,
+                                                    "cc",
+                                                    Instant.ofEpochMilli(5L)))
+                                    .producedAfterRestore(
+                                            Row.ofKind(
+                                                    RowKind.UPDATE_AFTER,
+                                                    "one",
+                                                    15,
+                                                    "aa",
+                                                    Instant.ofEpochMilli(6L)),
+                                            Row.ofKind(
+                                                    RowKind.DELETE,
+                                                    "one",
+                                                    15,
+                                                    "c",
+                                                    Instant.ofEpochMilli(7L)),
+                                            Row.ofKind(
+                                                    RowKind.DELETE,
+                                                    "three",
+                                                    3,
+                                                    "cc",
+                                                    Instant.ofEpochMilli(8L)))
+                                    .build())
+                    .setupTableSink(
+                            SinkTestStep.newBuilder("sink_t")
+                                    .addSchema(SINK_SCHEMA)
+                                    .consumedBeforeRestore(
+                                            "+I[one, 1, a]",
+                                            "-U[one, 1, a]",
+                                            "+U[one, 2, b]",
+                                            "-D[one, 2, b]",
+                                            "+I[three, 3, cc]")
+                                    .consumedAfterRestore("-D[three, 3, cc]")
+                                    .build())
+                    .runSql(
+                            "INSERT INTO sink_t SELECT a, b, c FROM source_t WHERE b < 10 AND "
+                                    + "CURRENT_WATERMARK(d) IS NULL OR "
+                                    + "CURRENT_WATERMARK(d) >= TIMESTAMP '1970-01-01 00:00:00'")
+                    .build();
 }
diff --git a/flink-table/flink-table-planner/src/test/resources/restore-tests/stream-exec-changelog-normalize_1/changelog-normalize-upsert-filter-watermark/plan/changelog-normalize-upsert-filter-watermark.json b/flink-table/flink-table-planner/src/test/resources/restore-tests/stream-exec-changelog-normalize_1/changelog-normalize-upsert-filter-watermark/plan/changelog-normalize-upsert-filter-watermark.json
new file mode 100644
index 00000000000..d819eee915a
--- /dev/null
+++ b/flink-table/flink-table-planner/src/test/resources/restore-tests/stream-exec-changelog-normalize_1/changelog-normalize-upsert-filter-watermark/plan/changelog-normalize-upsert-filter-watermark.json
@@ -0,0 +1,384 @@
+{
+  "flinkVersion" : "2.1",
+  "nodes" : [ {
+    "id" : 19,
+    "type" : "stream-exec-table-source-scan_1",
+    "scanTableSource" : {
+      "table" : {
+        "identifier" : "`default_catalog`.`default_database`.`source_t`",
+        "resolvedTable" : {
+          "schema" : {
+            "columns" : [ {
+              "name" : "a",
+              "dataType" : "VARCHAR(2147483647) NOT NULL"
+            }, {
+              "name" : "b",
+              "dataType" : "INT NOT NULL"
+            }, {
+              "name" : "c",
+              "dataType" : "VARCHAR(2147483647)"
+            }, {
+              "name" : "d",
+              "dataType" : {
+                "type" : "TIMESTAMP_WITH_LOCAL_TIME_ZONE",
+                "precision" : 3,
+                "kind" : "ROWTIME"
+              }
+            } ],
+            "watermarkSpecs" : [ {
+              "rowtimeAttribute" : "d",
+              "expression" : {
+                "rexNode" : {
+                  "kind" : "INPUT_REF",
+                  "inputIndex" : 3,
+                  "type" : "TIMESTAMP(3) WITH LOCAL TIME ZONE"
+                },
+                "serializableString" : "`d`"
+              }
+            } ],
+            "primaryKey" : {
+              "name" : "PK_a",
+              "type" : "PRIMARY_KEY",
+              "columns" : [ "a" ]
+            }
+          },
+          "partitionKeys" : [ ]
+        }
+      }
+    },
+    "outputType" : "ROW<`a` VARCHAR(2147483647) NOT NULL, `b` INT NOT NULL, `c` VARCHAR(2147483647), `d` TIMESTAMP(3) WITH LOCAL TIME ZONE>",
+    "description" : "TableSourceScan(table=[[default_catalog, default_database, source_t]], fields=[a, b, c, d])",
+    "inputProperties" : [ ]
+  }, {
+    "id" : 20,
+    "type" : "stream-exec-watermark-assigner_1",
+    "watermarkExpr" : {
+      "kind" : "INPUT_REF",
+      "inputIndex" : 3,
+      "type" : "TIMESTAMP(3) WITH LOCAL TIME ZONE"
+    },
+    "rowtimeFieldIndex" : 3,
+    "inputProperties" : [ {
+      "requiredDistribution" : {
+        "type" : "UNKNOWN"
+      },
+      "damBehavior" : "PIPELINED",
+      "priority" : 0
+    } ],
+    "outputType" : {
+      "type" : "ROW",
+      "fields" : [ {
+        "name" : "a",
+        "fieldType" : "VARCHAR(2147483647) NOT NULL"
+      }, {
+        "name" : "b",
+        "fieldType" : "INT NOT NULL"
+      }, {
+        "name" : "c",
+        "fieldType" : "VARCHAR(2147483647)"
+      }, {
+        "name" : "d",
+        "fieldType" : {
+          "type" : "TIMESTAMP_WITH_LOCAL_TIME_ZONE",
+          "precision" : 3,
+          "kind" : "ROWTIME"
+        }
+      } ]
+    },
+    "description" : "WatermarkAssigner(rowtime=[d], watermark=[d])"
+  }, {
+    "id" : 21,
+    "type" : "stream-exec-exchange_1",
+    "inputProperties" : [ {
+      "requiredDistribution" : {
+        "type" : "HASH",
+        "keys" : [ 0 ]
+      },
+      "damBehavior" : "PIPELINED",
+      "priority" : 0
+    } ],
+    "outputType" : {
+      "type" : "ROW",
+      "fields" : [ {
+        "name" : "a",
+        "fieldType" : "VARCHAR(2147483647) NOT NULL"
+      }, {
+        "name" : "b",
+        "fieldType" : "INT NOT NULL"
+      }, {
+        "name" : "c",
+        "fieldType" : "VARCHAR(2147483647)"
+      }, {
+        "name" : "d",
+        "fieldType" : {
+          "type" : "TIMESTAMP_WITH_LOCAL_TIME_ZONE",
+          "precision" : 3,
+          "kind" : "ROWTIME"
+        }
+      } ]
+    },
+    "description" : "Exchange(distribution=[hash[a]])"
+  }, {
+    "id" : 22,
+    "type" : "stream-exec-changelog-normalize_1",
+    "configuration" : {
+      "table.exec.mini-batch.enabled" : "false",
+      "table.exec.mini-batch.size" : "-1"
+    },
+    "uniqueKeys" : [ 0 ],
+    "generateUpdateBefore" : true,
+    "state" : [ {
+      "index" : 0,
+      "ttl" : "0 ms",
+      "name" : "changelogNormalizeState"
+    } ],
+    "inputProperties" : [ {
+      "requiredDistribution" : {
+        "type" : "UNKNOWN"
+      },
+      "damBehavior" : "PIPELINED",
+      "priority" : 0
+    } ],
+    "outputType" : {
+      "type" : "ROW",
+      "fields" : [ {
+        "name" : "a",
+        "fieldType" : "VARCHAR(2147483647) NOT NULL"
+      }, {
+        "name" : "b",
+        "fieldType" : "INT NOT NULL"
+      }, {
+        "name" : "c",
+        "fieldType" : "VARCHAR(2147483647)"
+      }, {
+        "name" : "d",
+        "fieldType" : {
+          "type" : "TIMESTAMP_WITH_LOCAL_TIME_ZONE",
+          "precision" : 3,
+          "kind" : "ROWTIME"
+        }
+      } ]
+    },
+    "description" : "ChangelogNormalize(key=[a], condition=[(((b < 10) OR (CURRENT_WATERMARK(CAST(d AS TIMESTAMP_WITH_LOCAL_TIME_ZONE(3))) >= 1970-01-01 00:00:00)) AND (CURRENT_WATERMARK(CAST(d AS TIMESTAMP_WITH_LOCAL_TIME_ZONE(3))) IS NULL OR (CURRENT_WATERMARK(CAST(d AS TIMESTAMP_WITH_LOCAL_TIME_ZONE(3))) >= 1970-01-01 00:00:00)))])",
+    "filterCondition" : {
+      "kind" : "CALL",
+      "syntax" : "BINARY",
+      "internalName" : "$AND$1",
+      "operands" : [ {
+        "kind" : "CALL",
+        "syntax" : "BINARY",
+        "internalName" : "$OR$1",
+        "operands" : [ {
+          "kind" : "CALL",
+          "syntax" : "BINARY",
+          "internalName" : "$<$1",
+          "operands" : [ {
+            "kind" : "INPUT_REF",
+            "inputIndex" : 1,
+            "type" : "INT NOT NULL"
+          }, {
+            "kind" : "LITERAL",
+            "value" : 10,
+            "type" : "INT NOT NULL"
+          } ],
+          "type" : "BOOLEAN NOT NULL"
+        }, {
+          "kind" : "CALL",
+          "syntax" : "BINARY",
+          "internalName" : "$>=$1",
+          "operands" : [ {
+            "kind" : "CALL",
+            "internalName" : "$CURRENT_WATERMARK$1",
+            "operands" : [ {
+              "kind" : "CALL",
+              "syntax" : "SPECIAL",
+              "internalName" : "$CAST$1",
+              "operands" : [ {
+                "kind" : "INPUT_REF",
+                "inputIndex" : 3,
+                "type" : {
+                  "type" : "TIMESTAMP_WITH_LOCAL_TIME_ZONE",
+                  "precision" : 3,
+                  "kind" : "ROWTIME"
+                }
+              } ],
+              "type" : "TIMESTAMP(3) WITH LOCAL TIME ZONE"
+            } ],
+            "type" : "TIMESTAMP(3) WITH LOCAL TIME ZONE"
+          }, {
+            "kind" : "LITERAL",
+            "value" : "1970-01-01 00:00:00",
+            "type" : "TIMESTAMP(0) NOT NULL"
+          } ],
+          "type" : "BOOLEAN"
+        } ],
+        "type" : "BOOLEAN"
+      }, {
+        "kind" : "CALL",
+        "syntax" : "BINARY",
+        "internalName" : "$OR$1",
+        "operands" : [ {
+          "kind" : "CALL",
+          "syntax" : "POSTFIX",
+          "internalName" : "$IS NULL$1",
+          "operands" : [ {
+            "kind" : "CALL",
+            "internalName" : "$CURRENT_WATERMARK$1",
+            "operands" : [ {
+              "kind" : "CALL",
+              "syntax" : "SPECIAL",
+              "internalName" : "$CAST$1",
+              "operands" : [ {
+                "kind" : "INPUT_REF",
+                "inputIndex" : 3,
+                "type" : {
+                  "type" : "TIMESTAMP_WITH_LOCAL_TIME_ZONE",
+                  "precision" : 3,
+                  "kind" : "ROWTIME"
+                }
+              } ],
+              "type" : "TIMESTAMP(3) WITH LOCAL TIME ZONE"
+            } ],
+            "type" : "TIMESTAMP(3) WITH LOCAL TIME ZONE"
+          } ],
+          "type" : "BOOLEAN NOT NULL"
+        }, {
+          "kind" : "CALL",
+          "syntax" : "BINARY",
+          "internalName" : "$>=$1",
+          "operands" : [ {
+            "kind" : "CALL",
+            "internalName" : "$CURRENT_WATERMARK$1",
+            "operands" : [ {
+              "kind" : "CALL",
+              "syntax" : "SPECIAL",
+              "internalName" : "$CAST$1",
+              "operands" : [ {
+                "kind" : "INPUT_REF",
+                "inputIndex" : 3,
+                "type" : {
+                  "type" : "TIMESTAMP_WITH_LOCAL_TIME_ZONE",
+                  "precision" : 3,
+                  "kind" : "ROWTIME"
+                }
+              } ],
+              "type" : "TIMESTAMP(3) WITH LOCAL TIME ZONE"
+            } ],
+            "type" : "TIMESTAMP(3) WITH LOCAL TIME ZONE"
+          }, {
+            "kind" : "LITERAL",
+            "value" : "1970-01-01 00:00:00",
+            "type" : "TIMESTAMP(0) NOT NULL"
+          } ],
+          "type" : "BOOLEAN"
+        } ],
+        "type" : "BOOLEAN"
+      } ],
+      "type" : "BOOLEAN"
+    }
+  }, {
+    "id" : 23,
+    "type" : "stream-exec-calc_1",
+    "projection" : [ {
+      "kind" : "INPUT_REF",
+      "inputIndex" : 0,
+      "type" : "VARCHAR(2147483647) NOT NULL"
+    }, {
+      "kind" : "INPUT_REF",
+      "inputIndex" : 1,
+      "type" : "INT NOT NULL"
+    }, {
+      "kind" : "INPUT_REF",
+      "inputIndex" : 2,
+      "type" : "VARCHAR(2147483647)"
+    } ],
+    "condition" : null,
+    "inputProperties" : [ {
+      "requiredDistribution" : {
+        "type" : "UNKNOWN"
+      },
+      "damBehavior" : "PIPELINED",
+      "priority" : 0
+    } ],
+    "outputType" : "ROW<`a` VARCHAR(2147483647) NOT NULL, `b` INT NOT NULL, `c` VARCHAR(2147483647)>",
+    "description" : "Calc(select=[a, b, c])"
+  }, {
+    "id" : 24,
+    "type" : "stream-exec-sink_1",
+    "configuration" : {
+      "table.exec.sink.keyed-shuffle" : "AUTO",
+      "table.exec.sink.not-null-enforcer" : "ERROR",
+      "table.exec.sink.rowtime-inserter" : "ENABLED",
+      "table.exec.sink.type-length-enforcer" : "IGNORE",
+      "table.exec.sink.upsert-materialize" : "AUTO"
+    },
+    "dynamicTableSink" : {
+      "table" : {
+        "identifier" : "`default_catalog`.`default_database`.`sink_t`",
+        "resolvedTable" : {
+          "schema" : {
+            "columns" : [ {
+              "name" : "a",
+              "dataType" : "VARCHAR(2147483647)"
+            }, {
+              "name" : "b",
+              "dataType" : "INT"
+            }, {
+              "name" : "c",
+              "dataType" : "VARCHAR(2147483647)"
+            } ],
+            "watermarkSpecs" : [ ]
+          },
+          "partitionKeys" : [ ]
+        }
+      }
+    },
+    "inputChangelogMode" : [ "INSERT", "UPDATE_BEFORE", "UPDATE_AFTER", "DELETE" ],
+    "inputUpsertKey" : [ 0 ],
+    "inputProperties" : [ {
+      "requiredDistribution" : {
+        "type" : "UNKNOWN"
+      },
+      "damBehavior" : "PIPELINED",
+      "priority" : 0
+    } ],
+    "outputType" : "ROW<`a` VARCHAR(2147483647) NOT NULL, `b` INT NOT NULL, `c` VARCHAR(2147483647)>",
+    "description" : "Sink(table=[default_catalog.default_database.sink_t], fields=[a, b, c])"
+  } ],
+  "edges" : [ {
+    "source" : 19,
+    "target" : 20,
+    "shuffle" : {
+      "type" : "FORWARD"
+    },
+    "shuffleMode" : "PIPELINED"
+  }, {
+    "source" : 20,
+    "target" : 21,
+    "shuffle" : {
+      "type" : "FORWARD"
+    },
+    "shuffleMode" : "PIPELINED"
+  }, {
+    "source" : 21,
+    "target" : 22,
+    "shuffle" : {
+      "type" : "FORWARD"
+    },
+    "shuffleMode" : "PIPELINED"
+  }, {
+    "source" : 22,
+    "target" : 23,
+    "shuffle" : {
+      "type" : "FORWARD"
+    },
+    "shuffleMode" : "PIPELINED"
+  }, {
+    "source" : 23,
+    "target" : 24,
+    "shuffle" : {
+      "type" : "FORWARD"
+    },
+    "shuffleMode" : "PIPELINED"
+  } ]
+}
\ No newline at end of file
diff --git a/flink-table/flink-table-planner/src/test/resources/restore-tests/stream-exec-changelog-normalize_1/changelog-normalize-upsert-filter-watermark/savepoint/_metadata b/flink-table/flink-table-planner/src/test/resources/restore-tests/stream-exec-changelog-normalize_1/changelog-normalize-upsert-filter-watermark/savepoint/_metadata
new file mode 100644
index 00000000000..9cff5cce221
Binary files /dev/null and b/flink-table/flink-table-planner/src/test/resources/restore-tests/stream-exec-changelog-normalize_1/changelog-normalize-upsert-filter-watermark/savepoint/_metadata differ
diff --git a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/generated/FilterCondition.java b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/generated/FilterCondition.java
index 52f670512c6..ad0a7c7d1a5 100644
--- a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/generated/FilterCondition.java
+++ b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/generated/FilterCondition.java
@@ -19,6 +19,10 @@
 package org.apache.flink.table.runtime.generated;
 
 import org.apache.flink.api.common.functions.RichFunction;
+import org.apache.flink.streaming.api.TimerService;
+import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
+import org.apache.flink.streaming.api.functions.ProcessFunction;
+import org.apache.flink.table.api.TableRuntimeException;
 import org.apache.flink.table.data.RowData;
 
 /** Interface for code generated filter condition function on single RowData. */
@@ -27,5 +31,66 @@ public interface FilterCondition extends RichFunction {
     /**
      * @return true if the filter condition stays true for the input row
      */
-    boolean apply(RowData in);
+    boolean apply(Context ctx, RowData in);
+
+    /**
+     * Context for generating expressions such as e.g. {@code CURRENT_WATERMARK} or {@code
+     * STREAMRECORD_TIMESTAMP}.
+     *
+     * @see ProcessFunction.Context
+     */
+    interface Context {
+        /**
+         * Timestamp of the element currently being processed or timestamp of a firing timer.
+         *
+         * <p>This might be {@code null}, depending on the stream's watermark strategy.
+         */
+        Long timestamp();
+
+        /** A {@link TimerService} for querying time and registering timers. */
+        TimerService timerService();
+
+        static Context of(KeyedProcessFunction<?, ?, ?>.Context context) {
+            return new Context() {
+                @Override
+                public Long timestamp() {
+                    return context.timestamp();
+                }
+
+                @Override
+                public TimerService timerService() {
+                    return context.timerService();
+                }
+            };
+        }
+
+        static Context of(ProcessFunction<?, ?>.Context context) {
+            return new Context() {
+                @Override
+                public Long timestamp() {
+                    return context.timestamp();
+                }
+
+                @Override
+                public TimerService timerService() {
+                    return context.timerService();
+                }
+            };
+        }
+
+        Context INVALID_CONTEXT =
+                new Context() {
+                    @Override
+                    public Long timestamp() {
+                        throw new TableRuntimeException(
+                                "Access to timestamp is not supported in this context.");
+                    }
+
+                    @Override
+                    public TimerService timerService() {
+                        throw new TableRuntimeException(
+                                "Access to timerService is not supported in this context.");
+                    }
+                };
+    }
 }
diff --git a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/ProcTimeDeduplicateKeepLastRowFunction.java b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/ProcTimeDeduplicateKeepLastRowFunction.java
index efac322c782..aabd3829b14 100644
--- a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/ProcTimeDeduplicateKeepLastRowFunction.java
+++ b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/ProcTimeDeduplicateKeepLastRowFunction.java
@@ -95,6 +95,7 @@ public class ProcTimeDeduplicateKeepLastRowFunction
                     equaliser);
         } else if (filterCondition != null) {
             processLastRowOnChangelogWithFilter(
+                    FilterCondition.Context.of(ctx),
                     input,
                     generateUpdateBefore,
                     state,
diff --git a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/ProcTimeMiniBatchDeduplicateKeepLastRowFunction.java b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/ProcTimeMiniBatchDeduplicateKeepLastRowFunction.java
index f081ca0e0a3..23f102b9e82 100644
--- a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/ProcTimeMiniBatchDeduplicateKeepLastRowFunction.java
+++ b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/ProcTimeMiniBatchDeduplicateKeepLastRowFunction.java
@@ -112,6 +112,7 @@ public class ProcTimeMiniBatchDeduplicateKeepLastRowFunction
                         equaliser);
             } else if (filterCondition != null) {
                 processLastRowOnChangelogWithFilter(
+                        FilterCondition.Context.INVALID_CONTEXT,
                         currentRow,
                         generateUpdateBefore,
                         state,
diff --git a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/utils/DeduplicateFunctionHelper.java b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/utils/DeduplicateFunctionHelper.java
index 957d2dbcd95..a9b79fc9f7b 100644
--- a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/utils/DeduplicateFunctionHelper.java
+++ b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/deduplicate/utils/DeduplicateFunctionHelper.java
@@ -154,6 +154,7 @@ public class DeduplicateFunctionHelper {
     }
 
     public static void processLastRowOnChangelogWithFilter(
+            FilterCondition.Context context,
             RowData currentRow,
             boolean generateUpdateBefore,
             ValueState<RowData> state,
@@ -166,7 +167,7 @@ public class DeduplicateFunctionHelper {
         RowKind currentKind = currentRow.getRowKind();
         if (currentKind == RowKind.INSERT || currentKind == RowKind.UPDATE_AFTER) {
             if (preRow == null) {
-                if (filterCondition.apply(currentRow)) {
+                if (filterCondition.apply(context, currentRow)) {
                     // the first row, send INSERT message
                     currentRow.setRowKind(RowKind.INSERT);
                     out.collect(currentRow);
@@ -182,7 +183,7 @@ public class DeduplicateFunctionHelper {
                     // state eviction of downstream operators.
                     return;
                 } else {
-                    if (filterCondition.apply(currentRow)) {
+                    if (filterCondition.apply(context, currentRow)) {
                         if (generateUpdateBefore) {
                             preRow.setRowKind(RowKind.UPDATE_BEFORE);
                             out.collect(preRow);
diff --git a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/AsyncLookupJoinRunner.java b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/AsyncLookupJoinRunner.java
index 73f9575971b..310f38d5489 100644
--- a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/AsyncLookupJoinRunner.java
+++ b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/AsyncLookupJoinRunner.java
@@ -132,7 +132,7 @@ public class AsyncLookupJoinRunner extends RichAsyncFunction<RowData, RowData> {
         // the input row is copied when object reuse in AsyncWaitOperator
         outResultFuture.reset(input, resultFuture);
 
-        if (preFilterCondition.apply(input)) {
+        if (preFilterCondition.apply(FilterCondition.Context.INVALID_CONTEXT, input)) {
             // fetcher has copied the input field when object reuse is enabled
             fetcher.asyncInvoke(input, outResultFuture);
         } else {
diff --git a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/KeyedLookupJoinWrapper.java b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/KeyedLookupJoinWrapper.java
index 8c718658116..1164651973c 100644
--- a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/KeyedLookupJoinWrapper.java
+++ b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/KeyedLookupJoinWrapper.java
@@ -31,6 +31,7 @@ import org.apache.flink.table.data.RowData;
 import org.apache.flink.table.data.binary.BinaryRowData;
 import org.apache.flink.table.data.util.RowDataUtil;
 import org.apache.flink.table.runtime.collector.ListenableCollector;
+import org.apache.flink.table.runtime.generated.FilterCondition;
 import org.apache.flink.types.RowKind;
 import org.apache.flink.util.Collector;
 
@@ -129,7 +130,7 @@ public class KeyedLookupJoinWrapper extends KeyedProcessFunction<RowData, RowDat
 
         // do lookup for acc msg
         if (RowDataUtil.isAccumulateMsg(in)) {
-            if (lookupJoinRunner.preFilter(in)) {
+            if (lookupJoinRunner.preFilter(FilterCondition.Context.of(ctx), in)) {
                 // clear local state first
                 deleteState();
 
@@ -144,7 +145,7 @@ public class KeyedLookupJoinWrapper extends KeyedProcessFunction<RowData, RowDat
             lookupJoinRunner.padNullForLeftJoin(in, out);
         } else {
             boolean collected = false;
-            if (lookupJoinRunner.preFilter(in)) {
+            if (lookupJoinRunner.preFilter(FilterCondition.Context.of(ctx), in)) {
                 // do state access for non-acc msg
                 if (lookupKeyContainsPrimaryKey) {
                     RowData rightRow = uniqueState.value();
diff --git a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/LookupJoinRunner.java b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/LookupJoinRunner.java
index 718962c5c8b..c91a9feb7bf 100644
--- a/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/LookupJoinRunner.java
+++ b/flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/join/lookup/LookupJoinRunner.java
@@ -88,7 +88,7 @@ public class LookupJoinRunner extends ProcessFunction<RowData, RowData> {
         prepareCollector(in, out);
 
         // apply local filter first
-        if (preFilter(in)) {
+        if (preFilter(FilterCondition.Context.of(ctx), in)) {
             doFetch(in);
         }
 
@@ -101,8 +101,8 @@ public class LookupJoinRunner extends ProcessFunction<RowData, RowData> {
         collector.reset();
     }
 
-    public boolean preFilter(RowData in) throws Exception {
-        return preFilterCondition.apply(in);
+    public boolean preFilter(FilterCondition.Context ctx, RowData in) throws Exception {
+        return preFilterCondition.apply(ctx, in);
     }
 
     public void doFetch(RowData in) throws Exception {
diff --git a/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/ProcTimeDeduplicateFunctionTestBase.java b/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/ProcTimeDeduplicateFunctionTestBase.java
index 07f3aa1d585..25bf35865cb 100644
--- a/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/ProcTimeDeduplicateFunctionTestBase.java
+++ b/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/runtime/operators/deduplicate/ProcTimeDeduplicateFunctionTestBase.java
@@ -77,7 +77,7 @@ abstract class ProcTimeDeduplicateFunctionTestBase {
 
     private static class TestingFilter implements FilterCondition {
         @Override
-        public boolean apply(RowData input) {
+        public boolean apply(Context ctx, RowData input) {
             return input.getInt(2) > 10;
         }
 
diff --git a/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/runtime/operators/join/LookupJoinHarnessTest.java b/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/runtime/operators/join/LookupJoinHarnessTest.java
index 2851a100cd3..6b318fe2655 100644
--- a/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/runtime/operators/join/LookupJoinHarnessTest.java
+++ b/flink-table/flink-table-runtime/src/test/java/org/apache/flink/table/runtime/operators/join/LookupJoinHarnessTest.java
@@ -342,7 +342,7 @@ class LookupJoinHarnessTest {
         }
 
         @Override
-        public boolean apply(RowData in) {
+        public boolean apply(Context ctx, RowData in) {
             // a pre-filter that will not affect the final result
             return !in.isNullAt(1);
         }
