diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategy.java b/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategy.java
index 359f957c249..b939ba1df19 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategy.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategy.java
@@ -131,13 +131,19 @@ public class PipelinedRegionSchedulingStrategy implements SchedulingStrategy {
                                                     .stream())
                             .collect(Collectors.toSet());
 
+            // for POINTWISE consumers of a BLOCKING partition, it's possible that some of the
+            // consumers are not affected by the restarting of sibling vertices so they are still in
+            // SCHEDULED/DEPLOYING/RUNNING/FINISHED. We should skip rescheduling these vertices.
             final Set<SchedulingPipelinedRegion> consumerRegions =
                     finishedPartitions.stream()
                             .flatMap(
                                     partition ->
                                             partitionConsumerRegions.get(partition.getId())
                                                     .stream())
+                            .distinct()
+                            .filter(region -> areRegionVerticesAllInCreatedState(region))
                             .collect(Collectors.toSet());
+
             maybeScheduleRegions(consumerRegions);
         }
     }
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategyTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategyTest.java
index 21852a3e9a0..ff667470860 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategyTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategyTest.java
@@ -28,6 +28,7 @@ import org.junit.Test;
 
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collections;
 import java.util.List;
 import java.util.Set;
 import java.util.stream.Collectors;
@@ -147,6 +148,36 @@ public class PipelinedRegionSchedulingStrategyTest extends TestLogger {
         assertLatestScheduledVerticesAreEqualTo(expectedScheduledVertices);
     }
 
+    @Test
+    public void testFinishedBlockingResultPartitionProducerDoNotScheduleNonCreatedRegions() {
+        final TestingSchedulingTopology topology = new TestingSchedulingTopology();
+
+        final List<TestingSchedulingExecutionVertex> producer =
+                topology.addExecutionVertices().withParallelism(2).finish();
+        final List<TestingSchedulingExecutionVertex> consumer =
+                topology.addExecutionVertices().withParallelism(2).finish();
+
+        topology.connectPointwise(producer, consumer)
+                .withResultPartitionState(ResultPartitionState.CONSUMABLE)
+                .withResultPartitionType(ResultPartitionType.BLOCKING)
+                .finish();
+
+        final PipelinedRegionSchedulingStrategy schedulingStrategy = startScheduling(topology);
+
+        consumer.get(0).setState(ExecutionState.SCHEDULED);
+        schedulingStrategy.onExecutionStateChange(producer.get(0).getId(), ExecutionState.FINISHED);
+
+        // non-CREATED regions should not be re-scheduled
+        assertThat(testingSchedulerOperation.getScheduledVertices(), hasSize(3));
+
+        final List<List<TestingSchedulingExecutionVertex>> expectedScheduledVertices =
+                new ArrayList<>();
+        expectedScheduledVertices.add(Collections.singletonList(producer.get(0)));
+        expectedScheduledVertices.add(Collections.singletonList(producer.get(1)));
+        expectedScheduledVertices.add(Collections.singletonList(consumer.get(1)));
+        assertLatestScheduledVerticesAreEqualTo(expectedScheduledVertices);
+    }
+
     @Test
     public void testSchedulingTopologyWithPersistentBlockingEdges() {
         final TestingSchedulingTopology topology = new TestingSchedulingTopology();
diff --git a/flink-tests/src/test/java/org/apache/flink/test/scheduling/PipelinedRegionSchedulingITCase.java b/flink-tests/src/test/java/org/apache/flink/test/scheduling/PipelinedRegionSchedulingITCase.java
index d39ac8b48d7..959a5dfeb86 100644
--- a/flink-tests/src/test/java/org/apache/flink/test/scheduling/PipelinedRegionSchedulingITCase.java
+++ b/flink-tests/src/test/java/org/apache/flink/test/scheduling/PipelinedRegionSchedulingITCase.java
@@ -23,10 +23,13 @@ import org.apache.flink.client.program.MiniClusterClient;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.configuration.JobManagerOptions;
 import org.apache.flink.configuration.RestOptions;
+import org.apache.flink.configuration.RestartStrategyOptions;
 import org.apache.flink.runtime.execution.Environment;
 import org.apache.flink.runtime.io.network.api.reader.RecordReader;
 import org.apache.flink.runtime.io.network.api.writer.RecordWriter;
 import org.apache.flink.runtime.io.network.api.writer.RecordWriterBuilder;
+import org.apache.flink.runtime.io.network.partition.PartitionException;
+import org.apache.flink.runtime.io.network.partition.PartitionNotFoundException;
 import org.apache.flink.runtime.io.network.partition.ResultPartitionType;
 import org.apache.flink.runtime.jobgraph.DistributionPattern;
 import org.apache.flink.runtime.jobgraph.JobGraph;
@@ -49,6 +52,7 @@ import java.util.Arrays;
 import java.util.List;
 import java.util.Optional;
 import java.util.concurrent.CompletableFuture;
+import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.stream.Collectors;
 
 import static org.hamcrest.CoreMatchers.containsString;
@@ -82,8 +86,25 @@ public class PipelinedRegionSchedulingITCase extends TestLogger {
                 cause.get().getMessage(), containsString("Slot request bulk is not fulfillable!"));
     }
 
-    private JobResult executeSchedulingTest(int numSlots) throws Exception {
+    @Test(timeout = 120000)
+    public void testRecoverFromPartitionException() throws Exception {
         final Configuration configuration = new Configuration();
+        configuration.setString(RestartStrategyOptions.RESTART_STRATEGY, "fixed-delay");
+        configuration.set(RestartStrategyOptions.RESTART_STRATEGY_FIXED_DELAY_ATTEMPTS, 1);
+
+        OneTimeFailingReceiverWithPartitionException.hasFailed.set(false);
+
+        final JobResult jobResult =
+                executeSchedulingTest(createJobGraphWithThreeStages(2), 2, configuration);
+        assertThat(jobResult.getSerializedThrowable().isPresent(), is(false));
+    }
+
+    private JobResult executeSchedulingTest(int numSlots) throws Exception {
+        return executeSchedulingTest(createJobGraph(2), numSlots, new Configuration());
+    }
+
+    private JobResult executeSchedulingTest(
+            JobGraph jobGraph, int numSlots, Configuration configuration) throws Exception {
         configuration.setString(RestOptions.BIND_PORT, "0");
         configuration.setLong(JobManagerOptions.SLOT_REQUEST_TIMEOUT, 5000L);
 
@@ -100,8 +121,6 @@ public class PipelinedRegionSchedulingITCase extends TestLogger {
             final MiniClusterClient miniClusterClient =
                     new MiniClusterClient(configuration, miniCluster);
 
-            final JobGraph jobGraph = createJobGraph(10);
-
             // wait for the submission to succeed
             final JobID jobID = miniClusterClient.submitJob(jobGraph).get();
 
@@ -140,6 +159,33 @@ public class PipelinedRegionSchedulingITCase extends TestLogger {
         return JobGraphTestUtils.batchJobGraph(source1, source2, sink);
     }
 
+    private JobGraph createJobGraphWithThreeStages(final int parallelism) {
+        final SlotSharingGroup group1 = new SlotSharingGroup();
+        final JobVertex source = new JobVertex("source");
+        source.setInvokableClass(NoOpInvokable.class);
+        source.setParallelism(parallelism);
+        source.setSlotSharingGroup(group1);
+
+        final SlotSharingGroup group2 = new SlotSharingGroup();
+        final JobVertex map = new JobVertex("map");
+        map.setInvokableClass(NoOpInvokable.class);
+        map.setParallelism(parallelism);
+        map.setSlotSharingGroup(group2);
+
+        final SlotSharingGroup group3 = new SlotSharingGroup();
+        final JobVertex sink = new JobVertex("sink");
+        sink.setInvokableClass(OneTimeFailingReceiverWithPartitionException.class);
+        sink.setParallelism(parallelism);
+        sink.setSlotSharingGroup(group3);
+
+        map.connectNewDataSetAsInput(
+                source, DistributionPattern.POINTWISE, ResultPartitionType.BLOCKING);
+        sink.connectNewDataSetAsInput(
+                map, DistributionPattern.ALL_TO_ALL, ResultPartitionType.BLOCKING);
+
+        return JobGraphTestUtils.batchJobGraph(source, map, sink);
+    }
+
     /**
      * This invokable is used by source1. It sends data to trigger the scheduling of the sink task.
      * It will also wait for a bit time before finishing itself, so that the scheduled sink task can
@@ -204,4 +250,22 @@ public class PipelinedRegionSchedulingITCase extends TestLogger {
             }
         }
     }
+
+    /** Invokable which fails exactly once with a {@link PartitionException}. */
+    public static class OneTimeFailingReceiverWithPartitionException extends AbstractInvokable {
+
+        private static final AtomicBoolean hasFailed = new AtomicBoolean(false);
+
+        public OneTimeFailingReceiverWithPartitionException(Environment environment) {
+            super(environment);
+        }
+
+        @Override
+        public void invoke() throws Exception {
+            if (hasFailed.compareAndSet(false, true)) {
+                throw new PartitionNotFoundException(
+                        getEnvironment().getInputGate(0).getChannel(1).getPartitionId());
+            }
+        }
+    }
 }
