diff --git a/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/source/split/KafkaPartitionSplit.java b/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/source/split/KafkaPartitionSplit.java
index 20e468240e3..baf028fa88d 100644
--- a/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/source/split/KafkaPartitionSplit.java
+++ b/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/source/split/KafkaPartitionSplit.java
@@ -32,9 +32,9 @@ import java.util.Set;
 /** A {@link SourceSplit} for a Kafka partition. */
 public class KafkaPartitionSplit implements SourceSplit {
     public static final long NO_STOPPING_OFFSET = Long.MIN_VALUE;
-    // Indicating the split should consume from the earliest.
-    public static final long LATEST_OFFSET = -1;
     // Indicating the split should consume from the latest.
+    public static final long LATEST_OFFSET = -1;
+    // Indicating the split should consume from the earliest.
     public static final long EARLIEST_OFFSET = -2;
     // Indicating the split should consume from the last committed offset.
     public static final long COMMITTED_OFFSET = -3;
diff --git a/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/KafkaSourceITCase.java b/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/KafkaSourceITCase.java
index 5c2107acf11..5cb70743dc7 100644
--- a/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/KafkaSourceITCase.java
+++ b/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/KafkaSourceITCase.java
@@ -81,8 +81,10 @@ public class KafkaSourceITCase {
         @BeforeAll
         public void setup() throws Throwable {
             KafkaSourceTestEnv.setup();
-            KafkaSourceTestEnv.setupTopic(TOPIC1, true, true);
-            KafkaSourceTestEnv.setupTopic(TOPIC2, true, true);
+            KafkaSourceTestEnv.setupTopic(
+                    TOPIC1, true, true, KafkaSourceTestEnv::getRecordsForTopicWithoutTimestamp);
+            KafkaSourceTestEnv.setupTopic(
+                    TOPIC2, true, true, KafkaSourceTestEnv::getRecordsForTopicWithoutTimestamp);
         }
 
         @AfterAll
@@ -93,12 +95,13 @@ public class KafkaSourceITCase {
         @Test
         public void testTimestamp() throws Throwable {
             final String topic = "testTimestamp";
+            final long currentTimestamp = System.currentTimeMillis();
             KafkaSourceTestEnv.createTestTopic(topic, 1, 1);
             KafkaSourceTestEnv.produceToKafka(
                     Arrays.asList(
-                            new ProducerRecord<>(topic, 0, 1L, "key0", 0),
-                            new ProducerRecord<>(topic, 0, 2L, "key1", 1),
-                            new ProducerRecord<>(topic, 0, 3L, "key2", 2)));
+                            new ProducerRecord<>(topic, 0, currentTimestamp + 1L, "key0", 0),
+                            new ProducerRecord<>(topic, 0, currentTimestamp + 2L, "key1", 1),
+                            new ProducerRecord<>(topic, 0, currentTimestamp + 3L, "key2", 2)));
 
             KafkaSource<PartitionAndValue> source =
                     KafkaSource.<PartitionAndValue>builder()
@@ -123,7 +126,10 @@ public class KafkaSourceITCase {
             stream.addSink(new DiscardingSink<>());
             JobExecutionResult result = env.execute();
 
-            assertEquals(Arrays.asList(1L, 2L, 3L), result.getAccumulatorResult("timestamp"));
+            assertEquals(
+                    Arrays.asList(
+                            currentTimestamp + 1L, currentTimestamp + 2L, currentTimestamp + 3L),
+                    result.getAccumulatorResult("timestamp"));
         }
 
         @Test
diff --git a/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/enumerator/KafkaEnumeratorTest.java b/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/enumerator/KafkaEnumeratorTest.java
index 423584f3388..fdab5f14dcf 100644
--- a/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/enumerator/KafkaEnumeratorTest.java
+++ b/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/enumerator/KafkaEnumeratorTest.java
@@ -77,8 +77,8 @@ public class KafkaEnumeratorTest {
     @BeforeClass
     public static void setup() throws Throwable {
         KafkaSourceTestEnv.setup();
-        KafkaSourceTestEnv.setupTopic(TOPIC1, true, true);
-        KafkaSourceTestEnv.setupTopic(TOPIC2, true, true);
+        KafkaSourceTestEnv.setupTopic(TOPIC1, true, true, KafkaSourceTestEnv::getRecordsForTopic);
+        KafkaSourceTestEnv.setupTopic(TOPIC2, true, true, KafkaSourceTestEnv::getRecordsForTopic);
     }
 
     @AfterClass
diff --git a/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/enumerator/initializer/OffsetsInitializerTest.java b/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/enumerator/initializer/OffsetsInitializerTest.java
index 4bc9769165c..618a3632b47 100644
--- a/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/enumerator/initializer/OffsetsInitializerTest.java
+++ b/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/enumerator/initializer/OffsetsInitializerTest.java
@@ -47,8 +47,8 @@ public class OffsetsInitializerTest {
     @BeforeClass
     public static void setup() throws Throwable {
         KafkaSourceTestEnv.setup();
-        KafkaSourceTestEnv.setupTopic(TOPIC, true, true);
-        KafkaSourceTestEnv.setupTopic(TOPIC2, false, false);
+        KafkaSourceTestEnv.setupTopic(TOPIC, true, true, KafkaSourceTestEnv::getRecordsForTopic);
+        KafkaSourceTestEnv.setupTopic(TOPIC2, false, false, KafkaSourceTestEnv::getRecordsForTopic);
         retriever =
                 new KafkaSourceEnumerator.PartitionOffsetsRetrieverImpl(
                         KafkaSourceTestEnv.getConsumer(),
diff --git a/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/reader/KafkaPartitionSplitReaderTest.java b/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/reader/KafkaPartitionSplitReaderTest.java
index 97f29bad0f3..b537b9ee2ab 100644
--- a/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/reader/KafkaPartitionSplitReaderTest.java
+++ b/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/reader/KafkaPartitionSplitReaderTest.java
@@ -82,8 +82,8 @@ public class KafkaPartitionSplitReaderTest {
     @BeforeClass
     public static void setup() throws Throwable {
         KafkaSourceTestEnv.setup();
-        KafkaSourceTestEnv.setupTopic(TOPIC1, true, true);
-        KafkaSourceTestEnv.setupTopic(TOPIC2, true, true);
+        KafkaSourceTestEnv.setupTopic(TOPIC1, true, true, KafkaSourceTestEnv::getRecordsForTopic);
+        KafkaSourceTestEnv.setupTopic(TOPIC2, true, true, KafkaSourceTestEnv::getRecordsForTopic);
         splitsByOwners =
                 KafkaSourceTestEnv.getSplitsByOwners(Arrays.asList(TOPIC1, TOPIC2), NUM_SUBTASKS);
         earliestOffsets =
diff --git a/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/testutils/KafkaSourceTestEnv.java b/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/testutils/KafkaSourceTestEnv.java
index df5d8eac30c..286934b1e95 100644
--- a/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/testutils/KafkaSourceTestEnv.java
+++ b/flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/connector/kafka/source/testutils/KafkaSourceTestEnv.java
@@ -41,6 +41,7 @@ import java.util.List;
 import java.util.Map;
 import java.util.Properties;
 import java.util.concurrent.ExecutionException;
+import java.util.function.Function;
 import java.util.stream.Collectors;
 
 import static org.junit.Assert.assertEquals;
@@ -140,6 +141,26 @@ public class KafkaSourceTestEnv extends KafkaTestBase {
         return records;
     }
 
+    /**
+     * For a given partition {@code TOPIC-PARTITION} the {@code i}-th records looks like following.
+     *
+     * <pre>{@code
+     * topic: TOPIC
+     * partition: PARTITION
+     * timestamp: null
+     * key: TOPIC-PARTITION
+     * value: i
+     * }</pre>
+     */
+    public static List<ProducerRecord<String, Integer>> getRecordsForPartitionWithoutTimestamp(
+            TopicPartition tp) {
+        List<ProducerRecord<String, Integer>> records = new ArrayList<>();
+        for (int i = 0; i < NUM_RECORDS_PER_PARTITION; i++) {
+            records.add(new ProducerRecord<>(tp.topic(), tp.partition(), null, tp.toString(), i));
+        }
+        return records;
+    }
+
     public static List<ProducerRecord<String, Integer>> getRecordsForTopic(String topic) {
         List<ProducerRecord<String, Integer>> records = new ArrayList<>();
         for (TopicPartition tp : getPartitionsForTopic(topic)) {
@@ -148,6 +169,15 @@ public class KafkaSourceTestEnv extends KafkaTestBase {
         return records;
     }
 
+    public static List<ProducerRecord<String, Integer>> getRecordsForTopicWithoutTimestamp(
+            String topic) {
+        List<ProducerRecord<String, Integer>> records = new ArrayList<>();
+        for (TopicPartition tp : getPartitionsForTopic(topic)) {
+            records.addAll(getRecordsForPartitionWithoutTimestamp(tp));
+        }
+        return records;
+    }
+
     public static List<TopicPartition> getPartitionsForTopics(Collection<String> topics) {
         List<TopicPartition> partitions = new ArrayList<>();
         topics.forEach(t -> partitions.addAll(getPartitionsForTopic(t)));
@@ -219,10 +249,13 @@ public class KafkaSourceTestEnv extends KafkaTestBase {
     }
 
     public static void setupTopic(
-            String topic, boolean setupEarliestOffsets, boolean setupCommittedOffsets)
+            String topic,
+            boolean setupEarliestOffsets,
+            boolean setupCommittedOffsets,
+            Function<String, List<ProducerRecord<String, Integer>>> testDataGenerator)
             throws Throwable {
         createTestTopic(topic);
-        produceToKafka(getRecordsForTopic(topic));
+        produceToKafka(testDataGenerator.apply(topic));
         if (setupEarliestOffsets) {
             setupEarliestOffsets(topic);
         }
