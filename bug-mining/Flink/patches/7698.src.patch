diff --git a/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/catalog/SqlCatalogViewTable.java b/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/catalog/SqlCatalogViewTable.java
index f4c60563d8c..37004ade8ea 100644
--- a/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/catalog/SqlCatalogViewTable.java
+++ b/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/catalog/SqlCatalogViewTable.java
@@ -20,15 +20,19 @@ package org.apache.flink.table.planner.catalog;
 
 import org.apache.flink.table.catalog.CatalogView;
 import org.apache.flink.table.planner.plan.schema.ExpandingPreparingTable;
+import org.apache.flink.table.planner.plan.schema.TimeIndicatorRelDataType;
 import org.apache.flink.table.planner.plan.stats.FlinkStatistic;
 
 import org.apache.calcite.plan.RelOptSchema;
 import org.apache.calcite.plan.RelOptUtil;
 import org.apache.calcite.rel.RelNode;
 import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeFactory;
+import org.apache.calcite.rel.type.RelRecordType;
 
 import javax.annotation.Nullable;
 
+import java.util.AbstractList;
 import java.util.List;
 
 /**
@@ -56,6 +60,62 @@ public class SqlCatalogViewTable extends ExpandingPreparingTable {
     public RelNode convertToRel(ToRelContext context) {
         RelNode original =
                 context.expandView(rowType, view.getExpandedQuery(), viewPath, names).project();
-        return RelOptUtil.createCastRel(original, rowType, true);
+        RelDataType castTargetType =
+                adaptTimeAttributes(
+                        original.getRowType(), rowType, context.getCluster().getTypeFactory());
+        return RelOptUtil.createCastRel(original, castTargetType, true);
+    }
+
+    private static RelDataType adaptTimeAttributes(
+            RelDataType queryType, RelDataType targetType, RelDataTypeFactory typeFactory) {
+        if (queryType instanceof RelRecordType) {
+            if (RelOptUtil.areRowTypesEqual(queryType, targetType, true)) {
+                return targetType;
+            } else if (targetType.getFieldCount() != queryType.getFieldCount()) {
+                throw new IllegalArgumentException(
+                        "Field counts are not equal: queryType ["
+                                + queryType
+                                + "]"
+                                + " castRowType ["
+                                + targetType
+                                + "]");
+            } else {
+                return adaptTimeAttributeInRecord(
+                        (RelRecordType) queryType, (RelRecordType) targetType, typeFactory);
+            }
+        } else {
+            return adaptTimeAttributeInSimpleType(queryType, targetType, typeFactory);
+        }
+    }
+
+    private static RelDataType adaptTimeAttributeInRecord(
+            RelRecordType queryType, RelRecordType targetType, RelDataTypeFactory typeFactory) {
+        RelDataType structType =
+                typeFactory.createStructType(
+                        targetType.getStructKind(),
+                        new AbstractList<>() {
+                            public RelDataType get(int index) {
+                                RelDataType targetFieldType =
+                                        (targetType.getFieldList().get(index)).getType();
+                                RelDataType queryFieldType =
+                                        (queryType.getFieldList().get(index)).getType();
+                                return adaptTimeAttributes(
+                                        queryFieldType, targetFieldType, typeFactory);
+                            }
+
+                            public int size() {
+                                return targetType.getFieldCount();
+                            }
+                        },
+                        targetType.getFieldNames());
+        return typeFactory.createTypeWithNullability(structType, targetType.isNullable());
+    }
+
+    private static RelDataType adaptTimeAttributeInSimpleType(
+            RelDataType queryType, RelDataType targetType, RelDataTypeFactory typeFactory) {
+        if (queryType instanceof TimeIndicatorRelDataType) {
+            return typeFactory.createTypeWithNullability(queryType, targetType.isNullable());
+        }
+        return targetType;
     }
 }
diff --git a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/catalog/JavaCatalogTableTest.java b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/catalog/JavaCatalogTableTest.java
index bd1fecb3294..ea36fe66fea 100644
--- a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/catalog/JavaCatalogTableTest.java
+++ b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/catalog/JavaCatalogTableTest.java
@@ -19,17 +19,22 @@
 package org.apache.flink.table.planner.catalog;
 
 import org.apache.flink.table.api.DataTypes;
+import org.apache.flink.table.api.Schema;
+import org.apache.flink.table.api.Schema.UnresolvedPhysicalColumn;
 import org.apache.flink.table.api.Table;
 import org.apache.flink.table.api.TableConfig;
 import org.apache.flink.table.api.TableEnvironment;
 import org.apache.flink.table.api.Tumble;
 import org.apache.flink.table.catalog.CatalogBaseTable;
 import org.apache.flink.table.catalog.CatalogTable;
+import org.apache.flink.table.catalog.CatalogView;
 import org.apache.flink.table.catalog.GenericInMemoryCatalog;
 import org.apache.flink.table.catalog.ObjectPath;
+import org.apache.flink.table.catalog.exceptions.TableNotExistException;
 import org.apache.flink.table.legacy.api.TableSchema;
 import org.apache.flink.table.planner.utils.TableTestBase;
 import org.apache.flink.table.planner.utils.TableTestUtil;
+import org.apache.flink.table.types.DataType;
 import org.apache.flink.testutils.junit.extensions.parameterized.Parameter;
 import org.apache.flink.testutils.junit.extensions.parameterized.ParameterizedTestExtension;
 import org.apache.flink.testutils.junit.extensions.parameterized.Parameters;
@@ -44,6 +49,7 @@ import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Optional;
+import java.util.stream.Collectors;
 
 import static org.apache.flink.table.api.Expressions.$;
 import static org.apache.flink.table.api.Expressions.lit;
@@ -58,10 +64,10 @@ class JavaCatalogTableTest extends TableTestBase {
         return Arrays.asList(true, false);
     }
 
-    @Parameter private boolean isStreamingMode;
+    @Parameter private boolean streamingMode;
 
     private TableTestUtil getTestUtil() {
-        if (isStreamingMode) {
+        if (streamingMode) {
             return streamTestUtil(TableConfig.getDefault());
         } else {
             return batchTestUtil(TableConfig.getDefault());
@@ -75,7 +81,7 @@ class JavaCatalogTableTest extends TableTestBase {
         GenericInMemoryCatalog genericInMemoryCatalog = new GenericInMemoryCatalog("in-memory");
         genericInMemoryCatalog.createTable(
                 new ObjectPath("default", "testTable"),
-                new CustomCatalogTable(isStreamingMode),
+                new CustomCatalogTable(streamingMode),
                 false);
         tableEnvironment.registerCatalog("testCatalog", genericInMemoryCatalog);
         tableEnvironment.executeSql(
@@ -92,7 +98,7 @@ class JavaCatalogTableTest extends TableTestBase {
         GenericInMemoryCatalog genericInMemoryCatalog = new GenericInMemoryCatalog("in-memory");
         genericInMemoryCatalog.createTable(
                 new ObjectPath("default", "testTable"),
-                new CustomCatalogTable(isStreamingMode),
+                new CustomCatalogTable(streamingMode),
                 false);
         tableEnvironment.registerCatalog("testCatalog", genericInMemoryCatalog);
 
@@ -107,7 +113,7 @@ class JavaCatalogTableTest extends TableTestBase {
 
     @TestTemplate
     void testResolvingProctimeOfCustomTableSql() throws Exception {
-        if (!isStreamingMode) {
+        if (!streamingMode) {
             // proctime not supported in batch
             return;
         }
@@ -116,7 +122,7 @@ class JavaCatalogTableTest extends TableTestBase {
         GenericInMemoryCatalog genericInMemoryCatalog = new GenericInMemoryCatalog("in-memory");
         genericInMemoryCatalog.createTable(
                 new ObjectPath("default", "testTable"),
-                new CustomCatalogTable(isStreamingMode),
+                new CustomCatalogTable(streamingMode),
                 false);
         tableEnvironment.registerCatalog("testCatalog", genericInMemoryCatalog);
 
@@ -127,7 +133,7 @@ class JavaCatalogTableTest extends TableTestBase {
 
     @TestTemplate
     void testResolvingProctimeOfCustomTableTableApi() throws Exception {
-        if (!isStreamingMode) {
+        if (!streamingMode) {
             // proctime not supported in batch
             return;
         }
@@ -136,7 +142,7 @@ class JavaCatalogTableTest extends TableTestBase {
         GenericInMemoryCatalog genericInMemoryCatalog = new GenericInMemoryCatalog("in-memory");
         genericInMemoryCatalog.createTable(
                 new ObjectPath("default", "testTable"),
-                new CustomCatalogTable(isStreamingMode),
+                new CustomCatalogTable(streamingMode),
                 false);
         tableEnvironment.registerCatalog("testCatalog", genericInMemoryCatalog);
 
@@ -149,12 +155,119 @@ class JavaCatalogTableTest extends TableTestBase {
         testUtil.verifyExecPlan(table);
     }
 
+    @TestTemplate
+    void testTimeAttributeOfView() {
+        if (!streamingMode) {
+            // time attributes not supported in batch
+            return;
+        }
+        TableTestUtil testUtil = getTestUtil();
+        TableEnvironment tableEnvironment = testUtil.getTableEnv();
+        tableEnvironment.registerCatalog("cat", new CustomCatalog("cat"));
+        tableEnvironment.executeSql(
+                "CREATE TABLE t(i INT, ts TIMESTAMP_LTZ(3), WATERMARK FOR "
+                        + "ts AS ts) WITH ('connector' = 'datagen')");
+        tableEnvironment.executeSql("CREATE VIEW `cat`.`default`.v AS SELECT * FROM t");
+        testUtil.verifyExecPlan(
+                "SELECT sum(i), window_start "
+                        + "FROM TUMBLE(\n"
+                        + "     DATA => TABLE `cat`.`default`.v,\n"
+                        + "     TIMECOL => DESCRIPTOR(ts),\n"
+                        + "     SIZE => INTERVAL '10' MINUTES)\n"
+                        + "GROUP BY window_start, window_end");
+    }
+
+    private static class CustomCatalog extends GenericInMemoryCatalog {
+        public CustomCatalog(String name) {
+            super(name);
+        }
+
+        @Override
+        public CatalogBaseTable getTable(ObjectPath tablePath) throws TableNotExistException {
+            CatalogBaseTable table = super.getTable(tablePath);
+            if (table.getTableKind() == CatalogBaseTable.TableKind.VIEW) {
+                return new CustomView((CatalogView) table);
+            }
+            return table;
+        }
+    }
+
+    private static class CustomView implements CatalogView {
+
+        private final CatalogView origin;
+
+        public CustomView(CatalogView table) {
+            this.origin = table;
+        }
+
+        @Override
+        public String getOriginalQuery() {
+            return origin.getOriginalQuery();
+        }
+
+        @Override
+        public String getExpandedQuery() {
+            return origin.getExpandedQuery();
+        }
+
+        @Override
+        public Map<String, String> getOptions() {
+            return origin.getOptions();
+        }
+
+        @Override
+        public Schema getUnresolvedSchema() {
+            Schema originalSchema = origin.getUnresolvedSchema();
+            return Schema.newBuilder()
+                    .fromColumns(
+                            originalSchema.getColumns().stream()
+                                    .map(
+                                            c -> {
+                                                if (c instanceof UnresolvedPhysicalColumn) {
+                                                    DataType dataType =
+                                                            (DataType)
+                                                                    ((UnresolvedPhysicalColumn) c)
+                                                                            .getDataType();
+                                                    String stringType =
+                                                            dataType.getLogicalType()
+                                                                    .asSerializableString();
+                                                    return new UnresolvedPhysicalColumn(
+                                                            c.getName(), DataTypes.of(stringType));
+                                                }
+                                                throw new UnsupportedOperationException(
+                                                        "Unexpected column type");
+                                            })
+                                    .collect(Collectors.toList()))
+                    .build();
+        }
+
+        @Override
+        public String getComment() {
+            return origin.getComment();
+        }
+
+        @Override
+        public CatalogBaseTable copy() {
+            return new CustomView((CatalogView) origin.copy());
+        }
+
+        @Override
+        public Optional<String> getDescription() {
+            return origin.getDescription();
+        }
+
+        @Override
+        public Optional<String> getDetailedDescription() {
+            return origin.getDetailedDescription();
+        }
+    }
+
     private static class CustomCatalogTable implements CatalogTable {
 
-        private final boolean isStreamingMode;
+        private final boolean streamingMode;
 
-        private CustomCatalogTable(boolean isStreamingMode) {
-            this.isStreamingMode = isStreamingMode;
+        private CustomCatalogTable(boolean streamingMode) {
+            this.streamingMode = streamingMode;
         }
 
         @Override
@@ -181,7 +294,7 @@ class JavaCatalogTableTest extends TableTestBase {
         public Map<String, String> getOptions() {
             Map<String, String> map = new HashMap<>();
             map.put("connector", "values");
-            map.put("bounded", Boolean.toString(!isStreamingMode));
+            map.put("bounded", Boolean.toString(!streamingMode));
             return map;
         }
 
diff --git a/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/catalog/JavaCatalogTableTest.xml b/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/catalog/JavaCatalogTableTest.xml
index 22f82b06a25..fdfd779cf81 100644
--- a/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/catalog/JavaCatalogTableTest.xml
+++ b/flink-table/flink-table-planner/src/test/resources/org/apache/flink/table/planner/catalog/JavaCatalogTableTest.xml
@@ -38,27 +38,6 @@ GroupWindowAggregate(window=[TumblingGroupWindow('w$, proctime, 600000)], select
       +- WatermarkAssigner(rowtime=[rowtime], watermark=[(rowtime - 5000:INTERVAL SECOND)])
          +- Calc(select=[PROCTIME() AS proctime, rowtime])
             +- TableSourceScan(table=[[testCatalog, default, testTable, project=[rowtime], metadata=[]]], fields=[rowtime])
-]]>
-    </Resource>
-  </TestCase>
-  <TestCase name="testResolvingSchemaOfCustomCatalogTableTableApi[streamingMode = true]">
-    <Resource name="ast">
-      <![CDATA[
-LogicalProject(EXPR$0=[$0])
-+- LogicalWindowAggregate(group=[{}], EXPR$0=[COUNT()], window=[TumblingGroupWindow('w, rowtime, 600000)], properties=[])
-   +- LogicalProject(count=[$0], rowtime=[$1], proctime=[$2], $f3=[1])
-      +- LogicalWatermarkAssigner(rowtime=[rowtime], watermark=[-($1, 5000:INTERVAL SECOND)])
-         +- LogicalProject(count=[$0], rowtime=[$1], proctime=[PROCTIME()])
-            +- LogicalTableScan(table=[[testCatalog, default, testTable]])
-]]>
-    </Resource>
-    <Resource name="optimized exec plan">
-      <![CDATA[
-GroupWindowAggregate(window=[TumblingGroupWindow('w, rowtime, 600000)], select=[COUNT(*) AS EXPR$0])
-+- Exchange(distribution=[single])
-   +- WatermarkAssigner(rowtime=[rowtime], watermark=[(rowtime - 5000:INTERVAL SECOND)])
-      +- Calc(select=[count, rowtime, PROCTIME() AS proctime])
-         +- TableSourceScan(table=[[testCatalog, default, testTable]], fields=[count, rowtime])
 ]]>
     </Resource>
   </TestCase>
@@ -127,6 +106,27 @@ GroupWindowAggregate(window=[TumblingGroupWindow('w$, rowtime, 600000)], select=
 +- Exchange(distribution=[single])
    +- WatermarkAssigner(rowtime=[rowtime], watermark=[(rowtime - 5000:INTERVAL SECOND)])
       +- TableSourceScan(table=[[testCatalog, default, testTable, project=[rowtime], metadata=[]]], fields=[rowtime])
+]]>
+    </Resource>
+  </TestCase>
+  <TestCase name="testResolvingSchemaOfCustomCatalogTableTableApi[streamingMode = true]">
+    <Resource name="ast">
+      <![CDATA[
+LogicalProject(EXPR$0=[$0])
++- LogicalWindowAggregate(group=[{}], EXPR$0=[COUNT()], window=[TumblingGroupWindow('w, rowtime, 600000)], properties=[])
+   +- LogicalProject(count=[$0], rowtime=[$1], proctime=[$2], $f3=[1])
+      +- LogicalWatermarkAssigner(rowtime=[rowtime], watermark=[-($1, 5000:INTERVAL SECOND)])
+         +- LogicalProject(count=[$0], rowtime=[$1], proctime=[PROCTIME()])
+            +- LogicalTableScan(table=[[testCatalog, default, testTable]])
+]]>
+    </Resource>
+    <Resource name="optimized exec plan">
+      <![CDATA[
+GroupWindowAggregate(window=[TumblingGroupWindow('w, rowtime, 600000)], select=[COUNT(*) AS EXPR$0])
++- Exchange(distribution=[single])
+   +- WatermarkAssigner(rowtime=[rowtime], watermark=[(rowtime - 5000:INTERVAL SECOND)])
+      +- Calc(select=[count, rowtime, PROCTIME() AS proctime])
+         +- TableSourceScan(table=[[testCatalog, default, testTable]], fields=[count, rowtime])
 ]]>
     </Resource>
   </TestCase>
@@ -145,6 +145,37 @@ HashWindowAggregate(window=[TumblingGroupWindow('w, rowtime, 600000)], select=[F
 +- Exchange(distribution=[single])
    +- LocalHashWindowAggregate(window=[TumblingGroupWindow('w, rowtime, 600000)], select=[Partial_COUNT(*) AS count1$0])
       +- TableSourceScan(table=[[testCatalog, default, testTable]], fields=[count, rowtime])
+]]>
+    </Resource>
+  </TestCase>
+  <TestCase name="testTimeAttributeOfView[streamingMode = true]">
+    <Resource name="sql">
+      <![CDATA[SELECT sum(i), window_start FROM TUMBLE(
+     DATA => TABLE `cat`.`default`.v,
+     TIMECOL => DESCRIPTOR(ts),
+     SIZE => INTERVAL '10' MINUTES)
+GROUP BY window_start, window_end]]>
+    </Resource>
+    <Resource name="ast">
+      <![CDATA[
+LogicalProject(EXPR$0=[$2], window_start=[$0])
++- LogicalAggregate(group=[{0, 1}], EXPR$0=[SUM($2)])
+   +- LogicalProject(window_start=[$2], window_end=[$3], i=[$0])
+      +- LogicalTableFunctionScan(invocation=[TUMBLE(DESCRIPTOR($1), 600000:INTERVAL MINUTE)], rowType=[RecordType(INTEGER i, TIMESTAMP_WITH_LOCAL_TIME_ZONE(3) ts, TIMESTAMP(3) window_start, TIMESTAMP(3) window_end, TIMESTAMP_WITH_LOCAL_TIME_ZONE(3) window_time)])
+         +- LogicalProject(i=[$0], ts=[$1])
+            +- LogicalProject(i=[$0], ts=[$1])
+               +- LogicalWatermarkAssigner(rowtime=[ts], watermark=[$1])
+                  +- LogicalTableScan(table=[[default_catalog, default_database, t]])
+]]>
+    </Resource>
+    <Resource name="optimized exec plan">
+      <![CDATA[
+Calc(select=[EXPR$0, window_start])
++- GlobalWindowAggregate(window=[TUMBLE(slice_end=[$slice_end], size=[10 min])], select=[SUM(sum$0) AS EXPR$0, start('w$) AS window_start, end('w$) AS window_end])
+   +- Exchange(distribution=[single])
+      +- LocalWindowAggregate(window=[TUMBLE(time_col=[ts], size=[10 min])], select=[SUM(i) AS sum$0, slice_end('w$) AS $slice_end])
+         +- WatermarkAssigner(rowtime=[ts], watermark=[ts])
+            +- TableSourceScan(table=[[default_catalog, default_database, t]], fields=[i, ts])
 ]]>
     </Resource>
   </TestCase>
