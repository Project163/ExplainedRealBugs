diff --git a/flink-table/flink-table-api-java/src/test/java/org/apache/flink/table/operations/utils/ValuesOperationTreeBuilderTest.java b/flink-table/flink-table-api-java/src/test/java/org/apache/flink/table/operations/utils/ValuesOperationTreeBuilderTest.java
index f48935e9df7..559344c6dcf 100644
--- a/flink-table/flink-table-api-java/src/test/java/org/apache/flink/table/operations/utils/ValuesOperationTreeBuilderTest.java
+++ b/flink-table/flink-table-api-java/src/test/java/org/apache/flink/table/operations/utils/ValuesOperationTreeBuilderTest.java
@@ -171,7 +171,7 @@ public class ValuesOperationTreeBuilderTest {
 						.build()
 				)),
 
-			TestSpec.test("Finding common type for nested rows")
+			TestSpec.test("Finding a common type for nested rows")
 				.values(
 					row(1L, row(1L, "ABC")),
 					row(3.1f, row(3.1f, "DEFG"))
@@ -184,7 +184,7 @@ public class ValuesOperationTreeBuilderTest {
 								rowCtor(
 									DataTypes.ROW(
 										DataTypes.FIELD("f0", DataTypes.FLOAT().notNull()),
-										DataTypes.FIELD("f1", DataTypes.VARCHAR(4).notNull())),
+										DataTypes.FIELD("f1", DataTypes.VARCHAR(4).notNull())).notNull(),
 									cast(valueLiteral(1L), DataTypes.FLOAT().notNull()),
 									valueLiteral("ABC", DataTypes.VARCHAR(4).notNull())
 								)
@@ -194,7 +194,7 @@ public class ValuesOperationTreeBuilderTest {
 								rowCtor(
 									DataTypes.ROW(
 										DataTypes.FIELD("f0", DataTypes.FLOAT().notNull()),
-										DataTypes.FIELD("f1", DataTypes.VARCHAR(4).notNull())),
+										DataTypes.FIELD("f1", DataTypes.VARCHAR(4).notNull())).notNull(),
 									valueLiteral(3.1f, DataTypes.FLOAT().notNull()),
 									valueLiteral("DEFG", DataTypes.VARCHAR(4).notNull())
 								)
@@ -206,7 +206,7 @@ public class ValuesOperationTreeBuilderTest {
 								"f1",
 								DataTypes.ROW(
 									DataTypes.FIELD("f0", DataTypes.FLOAT().notNull()),
-									DataTypes.FIELD("f1", DataTypes.VARCHAR(4).notNull())))
+									DataTypes.FIELD("f1", DataTypes.VARCHAR(4).notNull())).notNull())
 							.build()
 					)),
 
@@ -263,8 +263,8 @@ public class ValuesOperationTreeBuilderTest {
 					"Types in fromValues(...) must have a common super type. Could not find a common type" +
 						" for all rows at column 1.\n" +
 						"Could not find a common super type for types: " +
-						"[ROW<`f0` INT NOT NULL, `f1` TIME(0) NOT NULL>," +
-						" ROW<`f0` DOUBLE NOT NULL, `f1` DATE NOT NULL>]"),
+						"[ROW<`f0` INT NOT NULL, `f1` TIME(0) NOT NULL> NOT NULL," +
+						" ROW<`f0` DOUBLE NOT NULL, `f1` DATE NOT NULL> NOT NULL]"),
 
 			TestSpec.test("Cannot cast to the requested type")
 				.values(
diff --git a/flink-table/flink-table-common/src/main/java/org/apache/flink/table/types/inference/TypeStrategies.java b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/types/inference/TypeStrategies.java
index 6ed7071a72f..6b96a652c91 100644
--- a/flink-table/flink-table-common/src/main/java/org/apache/flink/table/types/inference/TypeStrategies.java
+++ b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/types/inference/TypeStrategies.java
@@ -79,7 +79,7 @@ public final class TypeStrategies {
 			.mapToObj(idx -> DataTypes.FIELD("f" + idx, argumentDataTypes.get(idx)))
 			.toArray(DataTypes.Field[]::new);
 
-		return Optional.of(DataTypes.ROW(fields));
+		return Optional.of(DataTypes.ROW(fields).notNull());
 	};
 
 	/**
@@ -91,7 +91,7 @@ public final class TypeStrategies {
 		if (argumentDataTypes.size() < 2) {
 			return Optional.empty();
 		}
-		return Optional.of(DataTypes.MAP(argumentDataTypes.get(0), argumentDataTypes.get(1)));
+		return Optional.of(DataTypes.MAP(argumentDataTypes.get(0), argumentDataTypes.get(1)).notNull());
 	};
 
 	/**
@@ -103,7 +103,7 @@ public final class TypeStrategies {
 		if (argumentDataTypes.size() < 1) {
 			return Optional.empty();
 		}
-		return Optional.of(DataTypes.ARRAY(argumentDataTypes.get(0)));
+		return Optional.of(DataTypes.ARRAY(argumentDataTypes.get(0)).notNull());
 	};
 
 	// --------------------------------------------------------------------------------------------
diff --git a/flink-table/flink-table-common/src/test/java/org/apache/flink/table/types/inference/TypeStrategiesTest.java b/flink-table/flink-table-common/src/test/java/org/apache/flink/table/types/inference/TypeStrategiesTest.java
index 13183173ee6..c9153908f54 100644
--- a/flink-table/flink-table-common/src/test/java/org/apache/flink/table/types/inference/TypeStrategiesTest.java
+++ b/flink-table/flink-table-common/src/test/java/org/apache/flink/table/types/inference/TypeStrategiesTest.java
@@ -118,19 +118,20 @@ public class TypeStrategiesTest {
 				.inputTypes(DataTypes.BIGINT(), DataTypes.STRING())
 				.expectDataType(DataTypes.ROW(
 					DataTypes.FIELD("f0", DataTypes.BIGINT()),
-					DataTypes.FIELD("f1", DataTypes.STRING()))),
+					DataTypes.FIELD("f1", DataTypes.STRING())).notNull()
+				),
 
 			TestSpec.forStrategy(
 				"Infer an array type",
 				TypeStrategies.ARRAY)
 				.inputTypes(DataTypes.BIGINT(), DataTypes.BIGINT())
-				.expectDataType(DataTypes.ARRAY(DataTypes.BIGINT())),
+				.expectDataType(DataTypes.ARRAY(DataTypes.BIGINT()).notNull()),
 
 			TestSpec.forStrategy(
 				"Infer a map type",
 				TypeStrategies.MAP)
 				.inputTypes(DataTypes.BIGINT(), DataTypes.STRING().notNull())
-				.expectDataType(DataTypes.MAP(DataTypes.BIGINT(), DataTypes.STRING().notNull()))
+				.expectDataType(DataTypes.MAP(DataTypes.BIGINT(), DataTypes.STRING().notNull()).notNull())
 		);
 	}
 
diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/expressions/converter/CustomizedConvertRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/expressions/converter/CustomizedConvertRule.java
index 981a7f04163..0916ea3235a 100644
--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/expressions/converter/CustomizedConvertRule.java
+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/expressions/converter/CustomizedConvertRule.java
@@ -34,9 +34,6 @@ import org.apache.flink.table.planner.functions.InternalFunctionDefinitions;
 import org.apache.flink.table.planner.functions.sql.FlinkSqlOperatorTable;
 import org.apache.flink.table.planner.functions.sql.SqlThrowExceptionFunction;
 import org.apache.flink.table.types.DataType;
-import org.apache.flink.table.types.logical.ArrayType;
-import org.apache.flink.table.types.logical.LogicalType;
-import org.apache.flink.table.types.logical.RowType;
 
 import com.google.common.collect.ImmutableList;
 import org.apache.calcite.rel.type.RelDataType;
@@ -166,31 +163,29 @@ public class CustomizedConvertRule implements CallExpressionConvertRule {
 	}
 
 	private static RexNode convertArray(CallExpression call, ConvertContext context) {
-		// TODO get type from CallExpression directly until introduce type inference on Expression
 		List<RexNode> childrenRexNode = toRexNodes(context, call.getChildren());
-		ArrayType arrayType = new ArrayType(toLogicalType(childrenRexNode.get(0).getType()));
-		RelDataType relDataType = context.getTypeFactory().createFieldTypeFromLogicalType(arrayType);
-		return context.getRelBuilder().getRexBuilder().makeCall(relDataType, FlinkSqlOperatorTable.ARRAY_VALUE_CONSTRUCTOR, childrenRexNode);
+		RelDataType relDataType = context.getTypeFactory()
+			.createFieldTypeFromLogicalType(call.getOutputDataType().getLogicalType());
+		return context.getRelBuilder()
+			.getRexBuilder()
+			.makeCall(relDataType, FlinkSqlOperatorTable.ARRAY_VALUE_CONSTRUCTOR, childrenRexNode);
 	}
 
 	private static RexNode convertMap(CallExpression call, ConvertContext context) {
-		// TODO get type from CallExpression directly until introduce type inference on Expression
 		List<Expression> children = call.getChildren();
 		checkArgument(call, !children.isEmpty() && children.size() % 2 == 0);
 		List<RexNode> childrenRexNode = toRexNodes(context, children);
-		RelDataType keyType = childrenRexNode.get(0).getType();
-		RelDataType valueType = childrenRexNode.get(childrenRexNode.size() - 1).getType();
-		RelDataType mapType = context.getTypeFactory().createMapType(keyType, valueType);
-		return context.getRelBuilder().getRexBuilder().makeCall(mapType, FlinkSqlOperatorTable.MAP_VALUE_CONSTRUCTOR, childrenRexNode);
+		RelDataType mapType = context.getTypeFactory()
+			.createFieldTypeFromLogicalType(call.getOutputDataType().getLogicalType());
+		return context.getRelBuilder()
+			.getRexBuilder()
+			.makeCall(mapType, FlinkSqlOperatorTable.MAP_VALUE_CONSTRUCTOR, childrenRexNode);
 	}
 
 	private static RexNode convertRow(CallExpression call, ConvertContext context) {
-		// TODO get type from CallExpression directly until introduce type inference on Expression
 		List<RexNode> childrenRexNode = toRexNodes(context, call.getChildren());
-		LogicalType[] childTypes = childrenRexNode.stream().map(rexNode -> toLogicalType(rexNode.getType()))
-			.toArray(LogicalType[]::new);
-		RowType rowType = RowType.of(childTypes);
-		RelDataType relDataType = context.getTypeFactory().createFieldTypeFromLogicalType(rowType);
+		RelDataType relDataType = context.getTypeFactory()
+			.createFieldTypeFromLogicalType(call.getOutputDataType().getLogicalType());
 		return context.getRelBuilder().getRexBuilder().makeCall(relDataType, FlinkSqlOperatorTable.ROW, childrenRexNode);
 	}
 
diff --git a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/calcite/FlinkTypeFactory.scala b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/calcite/FlinkTypeFactory.scala
index d41a631732d..61a0d0e8f5b 100644
--- a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/calcite/FlinkTypeFactory.scala
+++ b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/calcite/FlinkTypeFactory.scala
@@ -20,7 +20,6 @@ package org.apache.flink.table.planner.calcite
 
 import java.nio.charset.Charset
 import java.util
-
 import org.apache.calcite.avatica.util.TimeUnit
 import org.apache.calcite.jdbc.JavaTypeFactoryImpl
 import org.apache.calcite.rel.RelNode
@@ -36,7 +35,7 @@ import org.apache.flink.table.api.{DataTypes, TableException, TableSchema, Valid
 import org.apache.flink.table.calcite.ExtendedRelTypeFactory
 import org.apache.flink.table.planner.calcite.FlinkTypeFactory.toLogicalType
 import org.apache.flink.table.planner.plan.schema.{GenericRelDataType, _}
-import org.apache.flink.table.runtime.types.LogicalTypeDataTypeConverter
+import org.apache.flink.table.runtime.types.{LogicalTypeDataTypeConverter, PlannerTypeUtils}
 import org.apache.flink.table.types.inference.TypeInferenceUtil
 import org.apache.flink.table.types.logical._
 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo
@@ -128,6 +127,8 @@ class FlinkTypeFactory(typeSystem: RelDataTypeSystem)
             new RawRelDataType(rawType)
           case genericType: TypeInformationRawType[_] =>
             new GenericRelDataType(genericType, true, getTypeSystem)
+          case legacyType: LegacyTypeInformationType[_] =>
+            createFieldTypeFromLogicalType(PlannerTypeUtils.removeLegacyTypes(legacyType))
         }
 
       case LogicalTypeRoot.SYMBOL =>
diff --git a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/runtime/stream/table/ValuesITCase.java b/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/runtime/stream/table/ValuesITCase.java
index 66b894a79fc..3c7ca8ce0dd 100644
--- a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/runtime/stream/table/ValuesITCase.java
+++ b/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/runtime/stream/table/ValuesITCase.java
@@ -37,9 +37,12 @@ import java.time.Instant;
 import java.time.LocalDate;
 import java.time.LocalDateTime;
 import java.time.LocalTime;
+import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
+import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.stream.Collectors;
@@ -316,6 +319,22 @@ public class ValuesITCase extends StreamingTestBase {
 			equalTo(new HashSet<>(expected)));
 	}
 
+	@Test
+	public void testRegisteringValuesWithComplexTypes() {
+		Map<Integer, Integer> mapData = new HashMap<>();
+		mapData.put(1, 1);
+		mapData.put(2, 2);
+
+		Row row = Row.of(mapData, Row.of(1, 2, 3), new Integer[]{1, 2});
+		Table values = tEnv().fromValues(Collections.singletonList(row));
+		tEnv().createTemporaryView("values_t", values);
+		Iterator<Row> iter = tEnv().executeSql("select * from values_t").collect();
+
+		List<Row> results = new ArrayList<>();
+		iter.forEachRemaining(results::add);
+		assertThat(results, equalTo(Collections.singletonList(row)));
+	}
+
 	/**
 	 * A {@link ScalarFunction} that takes all supported types as parameters and
 	 * converts them to String.
diff --git a/flink-table/flink-table-planner-blink/src/test/resources/org/apache/flink/table/planner/plan/stream/table/ValuesTest.xml b/flink-table/flink-table-planner-blink/src/test/resources/org/apache/flink/table/planner/plan/stream/table/ValuesTest.xml
index 465b8d7f9ec..4abdd1a06b8 100644
--- a/flink-table/flink-table-planner-blink/src/test/resources/org/apache/flink/table/planner/plan/stream/table/ValuesTest.xml
+++ b/flink-table/flink-table-planner-blink/src/test/resources/org/apache/flink/table/planner/plan/stream/table/ValuesTest.xml
@@ -127,15 +127,15 @@ LogicalUnion(all=[true])
     <Resource name="planAfter">
       <![CDATA[
 Union(all=[true], union=[f0, f1, f2])
-:- Calc(select=[4E0:DOUBLE AS f0, _UTF-16LE'ABC':VARCHAR(4) CHARACTER SET "UTF-16LE" AS f1, CAST(MAP(_UTF-16LE'a':VARCHAR(4) CHARACTER SET "UTF-16LE", 3.0E0:DOUBLE)) AS f2])
+:- Calc(select=[4E0:DOUBLE AS f0, _UTF-16LE'ABC':VARCHAR(4) CHARACTER SET "UTF-16LE" AS f1, MAP(_UTF-16LE'a':VARCHAR(4) CHARACTER SET "UTF-16LE", 3.0E0:DOUBLE) AS f2])
 :  +- Values(tuples=[[{ 0 }]], reuse_id=[1])
-:- Calc(select=[3E0:DOUBLE AS f0, _UTF-16LE'ABC':VARCHAR(4) CHARACTER SET "UTF-16LE" AS f1, CAST(MAP(_UTF-16LE'a':VARCHAR(4) CHARACTER SET "UTF-16LE", CAST(+(ABS(-5), -5)))) AS f2])
+:- Calc(select=[3E0:DOUBLE AS f0, _UTF-16LE'ABC':VARCHAR(4) CHARACTER SET "UTF-16LE" AS f1, MAP(_UTF-16LE'a':VARCHAR(4) CHARACTER SET "UTF-16LE", CAST(+(ABS(-5), -5))) AS f2])
 :  +- Reused(reference_id=[1])
-:- Calc(select=[3.1415926535897931159E0:DOUBLE AS f0, _UTF-16LE'ABC':VARCHAR(4) CHARACTER SET "UTF-16LE" AS f1, CAST(MAP(_UTF-16LE'abc':VARCHAR(4) CHARACTER SET "UTF-16LE", 3.0E0:DOUBLE)) AS f2])
+:- Calc(select=[3.1415926535897931159E0:DOUBLE AS f0, _UTF-16LE'ABC':VARCHAR(4) CHARACTER SET "UTF-16LE" AS f1, MAP(_UTF-16LE'abc':VARCHAR(4) CHARACTER SET "UTF-16LE", 3.0E0:DOUBLE) AS f2])
 :  +- Reused(reference_id=[1])
-:- Calc(select=[3.1000000000000000888E0:DOUBLE AS f0, _UTF-16LE'DEF':VARCHAR(4) CHARACTER SET "UTF-16LE" AS f1, CAST(MAP(_UTF-16LE'abcd':VARCHAR(4) CHARACTER SET "UTF-16LE", 3:DOUBLE)) AS f2])
+:- Calc(select=[3.1E0:DOUBLE AS f0, _UTF-16LE'DEF':VARCHAR(4) CHARACTER SET "UTF-16LE" AS f1, MAP(_UTF-16LE'abcd':VARCHAR(4) CHARACTER SET "UTF-16LE", 3:DOUBLE) AS f2])
 :  +- Reused(reference_id=[1])
-:- Calc(select=[9.9E1:DOUBLE AS f0, _UTF-16LE'DEFG':VARCHAR(4) CHARACTER SET "UTF-16LE" AS f1, CAST(MAP(_UTF-16LE'a':VARCHAR(4) CHARACTER SET "UTF-16LE", 1:DOUBLE)) AS f2])
+:- Calc(select=[99:DOUBLE AS f0, _UTF-16LE'DEFG':VARCHAR(4) CHARACTER SET "UTF-16LE" AS f1, MAP(_UTF-16LE'a':VARCHAR(4) CHARACTER SET "UTF-16LE", 1:DOUBLE) AS f2])
 :  +- Reused(reference_id=[1])
 +- Calc(select=[0E-1:DOUBLE AS f0, _UTF-16LE'D':VARCHAR(4) CHARACTER SET "UTF-16LE" AS f1, null:(VARCHAR(4) CHARACTER SET "UTF-16LE", DOUBLE) MAP AS f2])
    +- Reused(reference_id=[1])
diff --git a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/types/LogicalTypeDataTypeConverter.java b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/types/LogicalTypeDataTypeConverter.java
index 18d00806995..fde61b88079 100644
--- a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/types/LogicalTypeDataTypeConverter.java
+++ b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/types/LogicalTypeDataTypeConverter.java
@@ -18,39 +18,11 @@
 
 package org.apache.flink.table.runtime.types;
 
-import org.apache.flink.api.common.typeinfo.BasicArrayTypeInfo;
-import org.apache.flink.api.common.typeinfo.BasicTypeInfo;
-import org.apache.flink.api.common.typeinfo.TypeInformation;
-import org.apache.flink.api.common.typeutils.CompositeType;
-import org.apache.flink.table.api.DataTypes;
-import org.apache.flink.table.data.DecimalDataUtils;
-import org.apache.flink.table.runtime.typeutils.BigDecimalTypeInfo;
-import org.apache.flink.table.runtime.typeutils.DecimalDataTypeInfo;
-import org.apache.flink.table.runtime.typeutils.LegacyInstantTypeInfo;
-import org.apache.flink.table.runtime.typeutils.LegacyLocalDateTimeTypeInfo;
-import org.apache.flink.table.runtime.typeutils.LegacyTimestampTypeInfo;
-import org.apache.flink.table.runtime.typeutils.StringDataTypeInfo;
-import org.apache.flink.table.runtime.typeutils.TimestampDataTypeInfo;
 import org.apache.flink.table.types.DataType;
-import org.apache.flink.table.types.logical.ArrayType;
-import org.apache.flink.table.types.logical.DecimalType;
 import org.apache.flink.table.types.logical.LegacyTypeInformationType;
-import org.apache.flink.table.types.logical.LocalZonedTimestampType;
 import org.apache.flink.table.types.logical.LogicalType;
-import org.apache.flink.table.types.logical.MapType;
-import org.apache.flink.table.types.logical.MultisetType;
-import org.apache.flink.table.types.logical.RowType;
-import org.apache.flink.table.types.logical.TimestampType;
-import org.apache.flink.table.types.logical.TypeInformationRawType;
-import org.apache.flink.table.types.logical.utils.LogicalTypeDefaultVisitor;
 import org.apache.flink.table.types.utils.TypeConversions;
 
-import java.util.function.Function;
-import java.util.stream.Collectors;
-import java.util.stream.Stream;
-
-import static org.apache.flink.table.runtime.types.TypeInfoLogicalTypeConverter.fromTypeInfoToLogicalType;
-
 /**
  * Converter between {@link DataType} and {@link LogicalType}.
  *
@@ -70,91 +42,6 @@ public class LogicalTypeDataTypeConverter {
 	 * It convert {@link LegacyTypeInformationType} to planner types.
 	 */
 	public static LogicalType fromDataTypeToLogicalType(DataType dataType) {
-		return dataType.getLogicalType().accept(new LegacyTypeToPlannerTypeConverter());
-	}
-
-	private static class LegacyTypeToPlannerTypeConverter extends LogicalTypeDefaultVisitor<LogicalType> {
-
-		@Override
-		protected LogicalType defaultMethod(LogicalType logicalType) {
-			if (logicalType instanceof LegacyTypeInformationType) {
-				TypeInformation typeInfo = ((LegacyTypeInformationType) logicalType).getTypeInformation();
-				if (typeInfo.equals(BasicTypeInfo.BIG_DEC_TYPE_INFO)) {
-					// BigDecimal have infinity precision and scale, but we converted it into a limited
-					// Decimal(38, 18). If the user's BigDecimal is more precision than this, we will
-					// throw Exception to remind user to use GenericType in real data conversion.
-					return DecimalDataUtils.DECIMAL_SYSTEM_DEFAULT;
-				} else if (typeInfo.equals(StringDataTypeInfo.INSTANCE)) {
-					return DataTypes.STRING().getLogicalType();
-				} else if (typeInfo instanceof BasicArrayTypeInfo) {
-					return new ArrayType(
-							fromTypeInfoToLogicalType(((BasicArrayTypeInfo) typeInfo).getComponentInfo()));
-				} else if (typeInfo instanceof CompositeType) {
-					CompositeType compositeType = (CompositeType) typeInfo;
-					return RowType.of(
-							Stream.iterate(0, x -> x + 1).limit(compositeType.getArity())
-									.map((Function<Integer, TypeInformation>) compositeType::getTypeAt)
-									.map(TypeInfoLogicalTypeConverter::fromTypeInfoToLogicalType)
-									.toArray(LogicalType[]::new),
-							compositeType.getFieldNames()
-					);
-				} else if (typeInfo instanceof DecimalDataTypeInfo) {
-					DecimalDataTypeInfo decimalType = (DecimalDataTypeInfo) typeInfo;
-					return new DecimalType(decimalType.precision(), decimalType.scale());
-				} else if (typeInfo instanceof BigDecimalTypeInfo) {
-					BigDecimalTypeInfo decimalType = (BigDecimalTypeInfo) typeInfo;
-					return new DecimalType(decimalType.precision(), decimalType.scale());
-				} else if (typeInfo instanceof TimestampDataTypeInfo) {
-					TimestampDataTypeInfo timestampDataTypeInfo = (TimestampDataTypeInfo) typeInfo;
-					return new TimestampType(timestampDataTypeInfo.getPrecision());
-				} else if (typeInfo instanceof LegacyLocalDateTimeTypeInfo) {
-					LegacyLocalDateTimeTypeInfo dateTimeType = (LegacyLocalDateTimeTypeInfo) typeInfo;
-					return new TimestampType(dateTimeType.getPrecision());
-				} else if (typeInfo instanceof LegacyTimestampTypeInfo) {
-					LegacyTimestampTypeInfo timstampType = (LegacyTimestampTypeInfo) typeInfo;
-					return new TimestampType(timstampType.getPrecision());
-				} else if (typeInfo instanceof LegacyInstantTypeInfo) {
-					LegacyInstantTypeInfo instantTypeInfo = (LegacyInstantTypeInfo) typeInfo;
-					return new LocalZonedTimestampType(instantTypeInfo.getPrecision());
-				} else {
-					return new TypeInformationRawType<>(typeInfo);
-				}
-			} else {
-				return logicalType;
-			}
-		}
-
-		@Override
-		public LogicalType visit(ArrayType arrayType) {
-			return new ArrayType(
-					arrayType.isNullable(),
-					arrayType.getElementType().accept(this));
-		}
-
-		@Override
-		public LogicalType visit(MultisetType multisetType) {
-			return new MultisetType(
-					multisetType.isNullable(),
-					multisetType.getElementType().accept(this));
-		}
-
-		@Override
-		public LogicalType visit(MapType mapType) {
-			return new MapType(
-					mapType.isNullable(),
-					mapType.getKeyType().accept(this),
-					mapType.getValueType().accept(this));
-		}
-
-		@Override
-		public LogicalType visit(RowType rowType) {
-			return new RowType(
-					rowType.isNullable(),
-					rowType.getFields().stream().map(field ->
-							new RowType.RowField(
-									field.getName(),
-									field.getType().accept(LegacyTypeToPlannerTypeConverter.this)))
-							.collect(Collectors.toList()));
-		}
+		return PlannerTypeUtils.removeLegacyTypes(dataType.getLogicalType());
 	}
 }
diff --git a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/types/PlannerTypeUtils.java b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/types/PlannerTypeUtils.java
index 724828ee8da..6f433ebc5d7 100644
--- a/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/types/PlannerTypeUtils.java
+++ b/flink-table/flink-table-runtime-blink/src/main/java/org/apache/flink/table/runtime/types/PlannerTypeUtils.java
@@ -18,13 +18,39 @@
 
 package org.apache.flink.table.runtime.types;
 
+import org.apache.flink.api.common.typeinfo.BasicArrayTypeInfo;
+import org.apache.flink.api.common.typeinfo.BasicTypeInfo;
+import org.apache.flink.api.common.typeinfo.TypeInformation;
+import org.apache.flink.api.common.typeutils.CompositeType;
+import org.apache.flink.table.api.DataTypes;
+import org.apache.flink.table.data.DecimalDataUtils;
+import org.apache.flink.table.runtime.typeutils.BigDecimalTypeInfo;
+import org.apache.flink.table.runtime.typeutils.DecimalDataTypeInfo;
+import org.apache.flink.table.runtime.typeutils.LegacyInstantTypeInfo;
+import org.apache.flink.table.runtime.typeutils.LegacyLocalDateTimeTypeInfo;
+import org.apache.flink.table.runtime.typeutils.LegacyTimestampTypeInfo;
+import org.apache.flink.table.runtime.typeutils.StringDataTypeInfo;
+import org.apache.flink.table.runtime.typeutils.TimestampDataTypeInfo;
 import org.apache.flink.table.types.DataType;
+import org.apache.flink.table.types.logical.ArrayType;
+import org.apache.flink.table.types.logical.DecimalType;
+import org.apache.flink.table.types.logical.LegacyTypeInformationType;
+import org.apache.flink.table.types.logical.LocalZonedTimestampType;
 import org.apache.flink.table.types.logical.LogicalType;
 import org.apache.flink.table.types.logical.LogicalTypeRoot;
+import org.apache.flink.table.types.logical.MapType;
+import org.apache.flink.table.types.logical.MultisetType;
 import org.apache.flink.table.types.logical.RowType;
+import org.apache.flink.table.types.logical.TimestampType;
+import org.apache.flink.table.types.logical.TypeInformationRawType;
+import org.apache.flink.table.types.logical.utils.LogicalTypeDefaultVisitor;
 
 import java.util.List;
+import java.util.function.Function;
+import java.util.stream.Collectors;
+import java.util.stream.Stream;
 
+import static org.apache.flink.table.runtime.types.TypeInfoLogicalTypeConverter.fromTypeInfoToLogicalType;
 import static org.apache.flink.table.types.logical.LogicalTypeFamily.BINARY_STRING;
 import static org.apache.flink.table.types.logical.LogicalTypeFamily.CHARACTER_STRING;
 
@@ -52,6 +78,13 @@ public class PlannerTypeUtils {
 		}
 	}
 
+	/**
+	 * A conversion that removes all {@link LegacyTypeInformationType}s by mapping to corresponding new types.
+	 */
+	public static LogicalType removeLegacyTypes(LogicalType t) {
+		return t.accept(new LegacyTypeToPlannerTypeConverter());
+	}
+
 	public static boolean isPrimitive(LogicalType type) {
 		return isPrimitive(type.getTypeRoot());
 	}
@@ -157,4 +190,88 @@ public class PlannerTypeUtils {
 				}
 		}
 	}
+
+	private static class LegacyTypeToPlannerTypeConverter extends LogicalTypeDefaultVisitor<LogicalType> {
+		@Override
+		protected LogicalType defaultMethod(LogicalType logicalType) {
+			if (logicalType instanceof LegacyTypeInformationType) {
+				TypeInformation<?> typeInfo = ((LegacyTypeInformationType<?>) logicalType).getTypeInformation();
+				if (typeInfo.equals(BasicTypeInfo.BIG_DEC_TYPE_INFO)) {
+					// BigDecimal have infinity precision and scale, but we converted it into a limited
+					// Decimal(38, 18). If the user's BigDecimal is more precision than this, we will
+					// throw Exception to remind user to use GenericType in real data conversion.
+					return DecimalDataUtils.DECIMAL_SYSTEM_DEFAULT;
+				} else if (typeInfo.equals(StringDataTypeInfo.INSTANCE)) {
+					return DataTypes.STRING().getLogicalType();
+				} else if (typeInfo instanceof BasicArrayTypeInfo) {
+					return new ArrayType(
+						fromTypeInfoToLogicalType(((BasicArrayTypeInfo<?, ?>) typeInfo).getComponentInfo()));
+				} else if (typeInfo instanceof CompositeType) {
+					CompositeType<?> compositeType = (CompositeType<?>) typeInfo;
+					return RowType.of(
+						Stream.iterate(0, x -> x + 1).limit(compositeType.getArity())
+							.map((Function<Integer, TypeInformation<?>>) compositeType::getTypeAt)
+							.map(TypeInfoLogicalTypeConverter::fromTypeInfoToLogicalType)
+							.toArray(LogicalType[]::new),
+						compositeType.getFieldNames()
+					);
+				} else if (typeInfo instanceof DecimalDataTypeInfo) {
+					DecimalDataTypeInfo decimalType = (DecimalDataTypeInfo) typeInfo;
+					return new DecimalType(decimalType.precision(), decimalType.scale());
+				} else if (typeInfo instanceof BigDecimalTypeInfo) {
+					BigDecimalTypeInfo decimalType = (BigDecimalTypeInfo) typeInfo;
+					return new DecimalType(decimalType.precision(), decimalType.scale());
+				} else if (typeInfo instanceof TimestampDataTypeInfo) {
+					TimestampDataTypeInfo timestampDataTypeInfo = (TimestampDataTypeInfo) typeInfo;
+					return new TimestampType(timestampDataTypeInfo.getPrecision());
+				} else if (typeInfo instanceof LegacyLocalDateTimeTypeInfo) {
+					LegacyLocalDateTimeTypeInfo dateTimeType = (LegacyLocalDateTimeTypeInfo) typeInfo;
+					return new TimestampType(dateTimeType.getPrecision());
+				} else if (typeInfo instanceof LegacyTimestampTypeInfo) {
+					LegacyTimestampTypeInfo timstampType = (LegacyTimestampTypeInfo) typeInfo;
+					return new TimestampType(timstampType.getPrecision());
+				} else if (typeInfo instanceof LegacyInstantTypeInfo) {
+					LegacyInstantTypeInfo instantTypeInfo = (LegacyInstantTypeInfo) typeInfo;
+					return new LocalZonedTimestampType(instantTypeInfo.getPrecision());
+				} else {
+					return new TypeInformationRawType<>(typeInfo);
+				}
+			} else {
+				return logicalType;
+			}
+		}
+
+		@Override
+		public LogicalType visit(ArrayType arrayType) {
+			return new ArrayType(
+				arrayType.isNullable(),
+				arrayType.getElementType().accept(this));
+		}
+
+		@Override
+		public LogicalType visit(MultisetType multisetType) {
+			return new MultisetType(
+				multisetType.isNullable(),
+				multisetType.getElementType().accept(this));
+		}
+
+		@Override
+		public LogicalType visit(MapType mapType) {
+			return new MapType(
+				mapType.isNullable(),
+				mapType.getKeyType().accept(this),
+				mapType.getValueType().accept(this));
+		}
+
+		@Override
+		public LogicalType visit(RowType rowType) {
+			return new RowType(
+				rowType.isNullable(),
+				rowType.getFields().stream().map(field ->
+					new RowType.RowField(
+						field.getName(),
+						field.getType().accept(LegacyTypeToPlannerTypeConverter.this)))
+					.collect(Collectors.toList()));
+		}
+	}
 }
