diff --git a/flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaProducerTestBase.java b/flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaProducerTestBase.java
index 99a19d2fc98..10e4f552e73 100644
--- a/flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaProducerTestBase.java
+++ b/flink-connectors/flink-connector-kafka-base/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaProducerTestBase.java
@@ -255,7 +255,7 @@ public abstract class KafkaProducerTestBase extends KafkaTestBaseWithFlink {
 
 		// process exactly failAfterElements number of elements and then shutdown Kafka broker and fail application
 		DataStream<Integer> inputStream = env
-			.fromCollection(getIntegersSequence(numElements))
+			.addSource(new InfiniteIntegerSource())
 			.map(new BrokerRestartingMapper<>(failAfterElements));
 
 		StreamSink<Integer> kafkaSink = kafkaServer.getProducerSink(topic, keyedSerializationSchema, properties, new FlinkKafkaPartitioner<Integer>() {
@@ -538,4 +538,22 @@ public abstract class KafkaProducerTestBase extends KafkaTestBaseWithFlink {
 		public void initializeState(FunctionInitializationContext context) throws Exception {
 		}
 	}
+
+	private static final class InfiniteIntegerSource implements SourceFunction<Integer> {
+
+		private volatile boolean running = true;
+		private int counter = 0;
+
+		@Override
+		public void run(SourceContext<Integer> ctx) throws Exception {
+			while (running) {
+				ctx.collect(counter++);
+			}
+		}
+
+		@Override
+		public void cancel() {
+			running = false;
+		}
+	}
 }
