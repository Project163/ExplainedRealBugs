diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/connector/sink2/GlobalCommittableWrapper.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/connector/sink2/GlobalCommittableWrapper.java
new file mode 100644
index 00000000000..c9f6d081510
--- /dev/null
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/connector/sink2/GlobalCommittableWrapper.java
@@ -0,0 +1,46 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.streaming.api.connector.sink2;
+
+import org.apache.flink.annotation.Internal;
+import org.apache.flink.streaming.runtime.operators.sink.committables.CommittableCollector;
+
+import java.util.Collection;
+
+@Internal
+class GlobalCommittableWrapper<CommT, GlobalCommT> {
+
+    private final CommittableCollector<CommT> committableCollector;
+    private final Collection<GlobalCommT> globalCommittables;
+
+    public GlobalCommittableWrapper(
+            CommittableCollector<CommT> committableCollector,
+            Collection<GlobalCommT> globalCommittables) {
+        this.committableCollector = committableCollector;
+        this.globalCommittables = globalCommittables;
+    }
+
+    public Collection<GlobalCommT> getGlobalCommittables() {
+        return globalCommittables;
+    }
+
+    public CommittableCollector<CommT> getCommittableCollector() {
+        return committableCollector;
+    }
+}
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/connector/sink2/GlobalCommitterOperator.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/connector/sink2/GlobalCommitterOperator.java
index 6ad3ec4aae7..a57371e17eb 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/connector/sink2/GlobalCommitterOperator.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/connector/sink2/GlobalCommitterOperator.java
@@ -21,6 +21,7 @@ package org.apache.flink.streaming.api.connector.sink2;
 import org.apache.flink.api.common.state.ListState;
 import org.apache.flink.api.common.state.ListStateDescriptor;
 import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;
+import org.apache.flink.api.connector.sink.GlobalCommitter;
 import org.apache.flink.api.connector.sink2.Committer;
 import org.apache.flink.core.io.SimpleVersionedSerializer;
 import org.apache.flink.runtime.state.StateInitializationContext;
@@ -31,6 +32,7 @@ import org.apache.flink.streaming.api.operators.BoundedOneInput;
 import org.apache.flink.streaming.api.operators.OneInputStreamOperator;
 import org.apache.flink.streaming.api.operators.Output;
 import org.apache.flink.streaming.api.operators.util.SimpleVersionedListState;
+import org.apache.flink.streaming.api.transformations.SinkV1Adapter;
 import org.apache.flink.streaming.runtime.operators.sink.committables.CheckpointCommittableManager;
 import org.apache.flink.streaming.runtime.operators.sink.committables.CommittableCollector;
 import org.apache.flink.streaming.runtime.operators.sink.committables.CommittableCollectorSerializer;
@@ -39,30 +41,39 @@ import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
 import org.apache.flink.streaming.runtime.tasks.StreamTask;
 import org.apache.flink.util.function.SerializableSupplier;
 
+import javax.annotation.Nullable;
+
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
+import java.util.List;
 
 import static org.apache.flink.util.Preconditions.checkNotNull;
+import static org.apache.flink.util.Preconditions.checkState;
 
-class GlobalCommitterOperator<CommT> extends AbstractStreamOperator<Void>
+class GlobalCommitterOperator<CommT, GlobalCommT> extends AbstractStreamOperator<Void>
         implements OneInputStreamOperator<CommittableMessage<CommT>, Void>, BoundedOneInput {
 
     /** The operator's state descriptor. */
     private static final ListStateDescriptor<byte[]> GLOBAL_COMMITTER_OPERATOR_RAW_STATES_DESC =
             new ListStateDescriptor<>(
-                    "global_committer_raw_states", BytePrimitiveArraySerializer.INSTANCE);
+                    "streaming_committer_raw_states", BytePrimitiveArraySerializer.INSTANCE);
 
     private final SerializableSupplier<Committer<CommT>> committerFactory;
     private final SerializableSupplier<SimpleVersionedSerializer<CommT>>
             committableSerializerFactory;
 
-    private ListState<CommittableCollector<CommT>> committableCollectorState;
+    private ListState<GlobalCommittableWrapper<CommT, GlobalCommT>> globalCommitterState;
     private Committer<CommT> committer;
     private CommittableCollector<CommT> committableCollector;
     private long lastCompletedCheckpointId = -1;
     private SimpleVersionedSerializer<CommT> committableSerializer;
 
+    @Nullable private GlobalCommitter<CommT, GlobalCommT> globalCommitter;
+    @Nullable private SimpleVersionedSerializer<GlobalCommT> globalCommittableSerializer;
+    private List<GlobalCommT> sinkV1State = new ArrayList<>();
+
     GlobalCommitterOperator(
             SerializableSupplier<Committer<CommT>> committerFactory,
             SerializableSupplier<SimpleVersionedSerializer<CommT>> committableSerializerFactory) {
@@ -79,29 +90,55 @@ class GlobalCommitterOperator<CommT> extends AbstractStreamOperator<Void>
         committer = committerFactory.get();
         committableCollector = CommittableCollector.of(getRuntimeContext());
         committableSerializer = committableSerializerFactory.get();
+        if (committer instanceof SinkV1Adapter.GlobalCommitterAdapter) {
+            final SinkV1Adapter<?, CommT, ?, GlobalCommT>.GlobalCommitterAdapter gc =
+                    ((SinkV1Adapter<?, CommT, ?, GlobalCommT>.GlobalCommitterAdapter) committer);
+            globalCommitter = gc.getGlobalCommitter();
+            globalCommittableSerializer = gc.getGlobalCommittableSerializer();
+        }
     }
 
     @Override
     public void snapshotState(StateSnapshotContext context) throws Exception {
         super.snapshotState(context);
         // It is important to copy the collector to not mutate the state.
-        committableCollectorState.update(Collections.singletonList(committableCollector.copy()));
+        globalCommitterState.update(
+                Collections.singletonList(
+                        new GlobalCommittableWrapper<>(
+                                committableCollector.copy(), new ArrayList<>(sinkV1State))));
     }
 
     @Override
     public void initializeState(StateInitializationContext context) throws Exception {
         super.initializeState(context);
-        committableCollectorState =
+        final CommittableCollectorSerializer<CommT> committableCollectorSerializer =
+                new CommittableCollectorSerializer<>(
+                        committableSerializer,
+                        getRuntimeContext().getIndexOfThisSubtask(),
+                        getRuntimeContext().getMaxNumberOfParallelSubtasks());
+        final SimpleVersionedSerializer<GlobalCommittableWrapper<CommT, GlobalCommT>> serializer =
+                new GlobalCommitterSerializer<>(
+                        committableCollectorSerializer,
+                        globalCommittableSerializer,
+                        getRuntimeContext().getIndexOfThisSubtask(),
+                        getRuntimeContext().getMaxNumberOfParallelSubtasks());
+        globalCommitterState =
                 new SimpleVersionedListState<>(
                         context.getOperatorStateStore()
                                 .getListState(GLOBAL_COMMITTER_OPERATOR_RAW_STATES_DESC),
-                        new CommittableCollectorSerializer<>(
-                                committableSerializer,
-                                getRuntimeContext().getIndexOfThisSubtask(),
-                                getRuntimeContext().getMaxNumberOfParallelSubtasks()));
+                        serializer);
         if (context.isRestored()) {
-            committableCollectorState.get().forEach(cc -> committableCollector.merge(cc));
+            globalCommitterState
+                    .get()
+                    .forEach(
+                            cc -> {
+                                sinkV1State.addAll(cc.getGlobalCommittables());
+                                committableCollector.merge(cc.getCommittableCollector());
+                            });
             lastCompletedCheckpointId = context.getRestoredCheckpointId().getAsLong();
+            if (globalCommitter != null) {
+                sinkV1State = globalCommitter.filterRecoveredCommittables(sinkV1State);
+            }
             // try to re-commit recovered transactions as quickly as possible
             commit(lastCompletedCheckpointId);
         }
@@ -110,6 +147,9 @@ class GlobalCommitterOperator<CommT> extends AbstractStreamOperator<Void>
     @Override
     public void notifyCheckpointComplete(long checkpointId) throws Exception {
         super.notifyCheckpointComplete(checkpointId);
+        checkState(
+                globalCommitter != null || sinkV1State.isEmpty(),
+                "GlobalCommitter is required to commit SinkV1 state.");
         lastCompletedCheckpointId = Math.max(lastCompletedCheckpointId, checkpointId);
         commit(lastCompletedCheckpointId);
     }
@@ -125,6 +165,9 @@ class GlobalCommitterOperator<CommT> extends AbstractStreamOperator<Void>
     }
 
     private void commit(long checkpointId) throws IOException, InterruptedException {
+        if (globalCommitter != null && !sinkV1State.isEmpty()) {
+            sinkV1State = globalCommitter.commit(sinkV1State);
+        }
         for (CheckpointCommittableManager<CommT> committable : getCommittables(checkpointId)) {
             boolean fullyReceived = committable.getCheckpointId() == lastCompletedCheckpointId;
             committable.commit(fullyReceived, committer);
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/connector/sink2/GlobalCommitterSerializer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/connector/sink2/GlobalCommitterSerializer.java
new file mode 100644
index 00000000000..3c140f2fe33
--- /dev/null
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/connector/sink2/GlobalCommitterSerializer.java
@@ -0,0 +1,140 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.streaming.api.connector.sink2;
+
+import org.apache.flink.annotation.Internal;
+import org.apache.flink.core.io.SimpleVersionedSerialization;
+import org.apache.flink.core.io.SimpleVersionedSerializer;
+import org.apache.flink.core.memory.DataInputDeserializer;
+import org.apache.flink.core.memory.DataInputView;
+import org.apache.flink.core.memory.DataOutputSerializer;
+import org.apache.flink.streaming.runtime.operators.sink.committables.CommittableCollector;
+import org.apache.flink.streaming.runtime.operators.sink.committables.CommittableCollectorSerializer;
+import org.apache.flink.streaming.runtime.operators.sink.committables.SinkV1CommittableDeserializer;
+
+import javax.annotation.Nullable;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.List;
+
+import static org.apache.flink.util.Preconditions.checkNotNull;
+import static org.apache.flink.util.Preconditions.checkState;
+
+@Internal
+class GlobalCommitterSerializer<CommT, GlobalCommT>
+        implements SimpleVersionedSerializer<GlobalCommittableWrapper<CommT, GlobalCommT>> {
+
+    private static final int MAGIC_NUMBER = 0xb91f252b;
+
+    private final CommittableCollectorSerializer<CommT> committableCollectorSerializer;
+    @Nullable private final SimpleVersionedSerializer<GlobalCommT> globalCommittableSerializer;
+    private final int subtaskId;
+    private final int numberOfSubtasks;
+
+    GlobalCommitterSerializer(
+            CommittableCollectorSerializer<CommT> committableCollectorSerializer,
+            @Nullable SimpleVersionedSerializer<GlobalCommT> globalCommittableSerializer,
+            int subtaskId,
+            int numberOfSubtasks) {
+        this.committableCollectorSerializer = checkNotNull(committableCollectorSerializer);
+        this.globalCommittableSerializer = globalCommittableSerializer;
+        this.subtaskId = subtaskId;
+        this.numberOfSubtasks = numberOfSubtasks;
+    }
+
+    @Override
+    public int getVersion() {
+        return 2;
+    }
+
+    @Override
+    public byte[] serialize(GlobalCommittableWrapper<CommT, GlobalCommT> obj) throws IOException {
+        final DataOutputSerializer out = new DataOutputSerializer(256);
+        out.writeInt(MAGIC_NUMBER);
+        if (globalCommittableSerializer != null) {
+            out.writeBoolean(true);
+            final Collection<GlobalCommT> globalCommittables = obj.getGlobalCommittables();
+            SimpleVersionedSerialization.writeVersionAndSerializeList(
+                    globalCommittableSerializer, new ArrayList<>(globalCommittables), out);
+        } else {
+            out.writeBoolean(false);
+        }
+        SimpleVersionedSerialization.writeVersionAndSerialize(
+                committableCollectorSerializer, obj.getCommittableCollector(), out);
+        return out.getCopyOfBuffer();
+    }
+
+    @Override
+    public GlobalCommittableWrapper<CommT, GlobalCommT> deserialize(int version, byte[] serialized)
+            throws IOException {
+        final DataInputDeserializer in = new DataInputDeserializer(serialized);
+        if (version == 1) {
+            if (globalCommittableSerializer == null) {
+                throw new IllegalStateException(
+                        "Tried to deserialize Sink V1 state without a GlobalCommittable serializer.");
+            }
+            return deserializeV1(in);
+        }
+        if (version == 2) {
+            validateMagicNumber(in);
+            return deserializeV2(in);
+        }
+        throw new IllegalStateException("Unrecognized version or corrupt state: " + version);
+    }
+
+    private GlobalCommittableWrapper<CommT, GlobalCommT> deserializeV1(DataInputView in)
+            throws IOException {
+        final List<GlobalCommT> globalCommittables =
+                SinkV1CommittableDeserializer.readVersionAndDeserializeList(
+                        globalCommittableSerializer, in);
+        return new GlobalCommittableWrapper<>(
+                new CommittableCollector<>(subtaskId, numberOfSubtasks), globalCommittables);
+    }
+
+    private GlobalCommittableWrapper<CommT, GlobalCommT> deserializeV2(DataInputView in)
+            throws IOException {
+        final boolean withGlobalCommittableSerializer = in.readBoolean();
+        List<GlobalCommT> globalCommittables;
+        if (globalCommittableSerializer == null) {
+            checkState(
+                    !withGlobalCommittableSerializer,
+                    "Trying to recover state from a GlobalCommittable serializer without specifying one.");
+            globalCommittables = Collections.emptyList();
+        } else {
+            globalCommittables =
+                    SimpleVersionedSerialization.readVersionAndDeserializeList(
+                            globalCommittableSerializer, in);
+        }
+        return new GlobalCommittableWrapper<>(
+                SimpleVersionedSerialization.readVersionAndDeSerialize(
+                        committableCollectorSerializer, in),
+                globalCommittables);
+    }
+
+    private static void validateMagicNumber(DataInputView in) throws IOException {
+        final int magicNumber = in.readInt();
+        if (magicNumber != MAGIC_NUMBER) {
+            throw new IllegalStateException(
+                    String.format("Corrupt data: Unexpected magic number %08X", magicNumber));
+        }
+    }
+}
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/transformations/SinkV1Adapter.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/transformations/SinkV1Adapter.java
index e4e2c51d674..ddd421f4309 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/transformations/SinkV1Adapter.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/transformations/SinkV1Adapter.java
@@ -417,12 +417,16 @@ public class SinkV1Adapter<InputT, CommT, WriterStateT, GlobalCommT> implements
         public void close() throws Exception {}
     }
 
-    private class GlobalCommitterAdapter implements Committer<CommT> {
-        GlobalCommitter<CommT, GlobalCommT> globalCommitter;
+    /** Simulate the global committer behaviour with a committer. */
+    @Internal
+    public class GlobalCommitterAdapter implements Committer<CommT> {
+        final GlobalCommitter<CommT, GlobalCommT> globalCommitter;
+        final SimpleVersionedSerializer<GlobalCommT> globalCommittableSerializer;
 
         GlobalCommitterAdapter() {
             try {
                 globalCommitter = sink.createGlobalCommitter().get();
+                globalCommittableSerializer = sink.getGlobalCommittableSerializer().get();
             } catch (IOException e) {
                 throw new UncheckedIOException("Cannot create global committer", e);
             }
@@ -436,6 +440,10 @@ public class SinkV1Adapter<InputT, CommT, WriterStateT, GlobalCommT> implements
         @Override
         public void commit(Collection<CommitRequest<CommT>> committables)
                 throws IOException, InterruptedException {
+            if (committables.isEmpty()) {
+                return;
+            }
+
             List<CommT> rawCommittables =
                     committables.stream()
                             .map(CommitRequest::getCommittable)
@@ -443,9 +451,21 @@ public class SinkV1Adapter<InputT, CommT, WriterStateT, GlobalCommT> implements
             List<GlobalCommT> globalCommittables =
                     Collections.singletonList(globalCommitter.combine(rawCommittables));
             List<GlobalCommT> failures = globalCommitter.commit(globalCommittables);
+            // Only committables are retriable so the complete batch of committables is retried
+            // because we cannot trace back the committable to which global committable it belongs.
+            // This might lead to committing the same global committable twice, but we assume that
+            // the GlobalCommitter commit call is idempotent.
             if (!failures.isEmpty()) {
                 committables.forEach(CommitRequest::retryLater);
             }
         }
+
+        public GlobalCommitter<CommT, GlobalCommT> getGlobalCommitter() {
+            return globalCommitter;
+        }
+
+        public SimpleVersionedSerializer<GlobalCommT> getGlobalCommittableSerializer() {
+            return globalCommittableSerializer;
+        }
     }
 }
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/SinkV1WriterCommittableSerializer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/SinkV1WriterCommittableSerializer.java
new file mode 100644
index 00000000000..06194d802f5
--- /dev/null
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/SinkV1WriterCommittableSerializer.java
@@ -0,0 +1,57 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.streaming.runtime.operators.sink;
+
+import org.apache.flink.annotation.Internal;
+import org.apache.flink.core.io.SimpleVersionedSerializer;
+import org.apache.flink.core.memory.DataInputDeserializer;
+import org.apache.flink.streaming.runtime.operators.sink.committables.SinkV1CommittableDeserializer;
+
+import java.io.IOException;
+import java.util.List;
+
+import static org.apache.flink.util.Preconditions.checkNotNull;
+
+@Internal
+class SinkV1WriterCommittableSerializer<CommT> implements SimpleVersionedSerializer<List<CommT>> {
+
+    private final SimpleVersionedSerializer<CommT> committableSerializer;
+
+    public SinkV1WriterCommittableSerializer(
+            SimpleVersionedSerializer<CommT> committableSerializer) {
+        this.committableSerializer = checkNotNull(committableSerializer);
+    }
+
+    @Override
+    public int getVersion() {
+        return 1;
+    }
+
+    @Override
+    public byte[] serialize(List<CommT> obj) throws IOException {
+        throw new UnsupportedOperationException(
+                "This serializer should only be used to deserialize legacy committable state.");
+    }
+
+    @Override
+    public List<CommT> deserialize(int version, byte[] serialized) throws IOException {
+        return SinkV1CommittableDeserializer.readVersionAndDeserializeList(
+                committableSerializer, new DataInputDeserializer(serialized));
+    }
+}
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/SinkWriterOperator.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/SinkWriterOperator.java
index 564f0aad191..e593616abf7 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/SinkWriterOperator.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/SinkWriterOperator.java
@@ -20,12 +20,16 @@ package org.apache.flink.streaming.runtime.operators.sink;
 import org.apache.flink.api.common.eventtime.TimestampAssigner;
 import org.apache.flink.api.common.operators.MailboxExecutor;
 import org.apache.flink.api.common.serialization.SerializationSchema.InitializationContext;
+import org.apache.flink.api.common.state.ListState;
+import org.apache.flink.api.common.state.ListStateDescriptor;
+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;
 import org.apache.flink.api.connector.sink2.Sink;
 import org.apache.flink.api.connector.sink2.Sink.InitContext;
 import org.apache.flink.api.connector.sink2.SinkWriter;
 import org.apache.flink.api.connector.sink2.StatefulSink;
 import org.apache.flink.api.connector.sink2.TwoPhaseCommittingSink;
 import org.apache.flink.api.connector.sink2.TwoPhaseCommittingSink.PrecommittingSinkWriter;
+import org.apache.flink.core.io.SimpleVersionedSerializer;
 import org.apache.flink.metrics.groups.SinkWriterMetricGroup;
 import org.apache.flink.runtime.metrics.groups.InternalSinkWriterMetricGroup;
 import org.apache.flink.runtime.state.StateInitializationContext;
@@ -38,6 +42,7 @@ import org.apache.flink.streaming.api.operators.BoundedOneInput;
 import org.apache.flink.streaming.api.operators.InternalTimerService;
 import org.apache.flink.streaming.api.operators.OneInputStreamOperator;
 import org.apache.flink.streaming.api.operators.StreamingRuntimeContext;
+import org.apache.flink.streaming.api.operators.util.SimpleVersionedListState;
 import org.apache.flink.streaming.api.watermark.Watermark;
 import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
 import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;
@@ -46,11 +51,14 @@ import org.apache.flink.util.UserCodeClassLoader;
 import javax.annotation.Nullable;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Collection;
+import java.util.List;
 import java.util.OptionalLong;
 
 import static org.apache.flink.util.IOUtils.closeAll;
 import static org.apache.flink.util.Preconditions.checkNotNull;
+import static org.apache.flink.util.Preconditions.checkState;
 
 /**
  * An operator that processes records to be written into a {@link
@@ -66,6 +74,17 @@ import static org.apache.flink.util.Preconditions.checkNotNull;
 class SinkWriterOperator<InputT, CommT> extends AbstractStreamOperator<CommittableMessage<CommT>>
         implements OneInputStreamOperator<InputT, CommittableMessage<CommT>>, BoundedOneInput {
 
+    /**
+     * To support state migrations from 1.14 where the sinkWriter and committer where part of the
+     * same operator.
+     */
+    private static final ListStateDescriptor<byte[]> STREAMING_COMMITTER_RAW_STATES_DESC =
+            new ListStateDescriptor<>(
+                    "streaming_committer_raw_states", BytePrimitiveArraySerializer.INSTANCE);
+
+    @Nullable private final SimpleVersionedSerializer<CommT> committableSerializer;
+    private final List<CommT> legacyCommittables = new ArrayList<>();
+
     /** The runtime information of the input element. */
     private final Context<InputT> context;
 
@@ -99,6 +118,13 @@ class SinkWriterOperator<InputT, CommT> extends AbstractStreamOperator<Committab
         } else {
             writerStateHandler = new StatelessSinkWriterStateHandler<>(sink);
         }
+
+        if (sink instanceof TwoPhaseCommittingSink) {
+            committableSerializer =
+                    ((TwoPhaseCommittingSink<InputT, CommT>) sink).getCommittableSerializer();
+        } else {
+            committableSerializer = null;
+        }
     }
 
     @Override
@@ -107,7 +133,16 @@ class SinkWriterOperator<InputT, CommT> extends AbstractStreamOperator<Committab
         OptionalLong checkpointId = context.getRestoredCheckpointId();
         InitContext initContext =
                 createInitContext(checkpointId.isPresent() ? checkpointId.getAsLong() : null);
-
+        if (context.isRestored()) {
+            if (committableSerializer != null) {
+                final ListState<List<CommT>> legacyCommitterState =
+                        new SimpleVersionedListState<>(
+                                context.getOperatorStateStore()
+                                        .getListState(STREAMING_COMMITTER_RAW_STATES_DESC),
+                                new SinkV1WriterCommittableSerializer<>(committableSerializer));
+                legacyCommitterState.get().forEach(legacyCommittables::addAll);
+            }
+        }
         sinkWriter = writerStateHandler.createWriter(initContext, context);
     }
 
@@ -160,12 +195,37 @@ class SinkWriterOperator<InputT, CommT> extends AbstractStreamOperator<Committab
         Collection<CommT> committables =
                 ((PrecommittingSinkWriter<?, CommT>) sinkWriter).prepareCommit();
         StreamingRuntimeContext runtimeContext = getRuntimeContext();
-        int indexOfThisSubtask = runtimeContext.getIndexOfThisSubtask();
+        final int indexOfThisSubtask = runtimeContext.getIndexOfThisSubtask();
+        final int numberOfParallelSubtasks = runtimeContext.getNumberOfParallelSubtasks();
+
+        // Emit only committable summary if there are legacy committables
+        if (!legacyCommittables.isEmpty()) {
+            checkState(checkpointId > InitContext.INITIAL_CHECKPOINT_ID);
+            emit(
+                    indexOfThisSubtask,
+                    numberOfParallelSubtasks,
+                    InitContext.INITIAL_CHECKPOINT_ID,
+                    legacyCommittables);
+            legacyCommittables.clear();
+        }
+        emit(indexOfThisSubtask, numberOfParallelSubtasks, checkpointId, committables);
+    }
+
+    @Override
+    public void close() throws Exception {
+        closeAll(sinkWriter, super::close);
+    }
+
+    private void emit(
+            int indexOfThisSubtask,
+            int numberOfParallelSubtasks,
+            long checkpointId,
+            Collection<CommT> committables) {
         output.collect(
                 new StreamRecord<>(
                         new CommittableSummary<>(
                                 indexOfThisSubtask,
-                                runtimeContext.getNumberOfParallelSubtasks(),
+                                numberOfParallelSubtasks,
                                 checkpointId,
                                 committables.size(),
                                 committables.size(),
@@ -178,11 +238,6 @@ class SinkWriterOperator<InputT, CommT> extends AbstractStreamOperator<Committab
         }
     }
 
-    @Override
-    public void close() throws Exception {
-        closeAll(sinkWriter, super::close);
-    }
-
     private Sink.InitContext createInitContext(@Nullable Long restoredCheckpointId) {
         return new InitContextImpl(
                 getRuntimeContext(),
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/committables/CommittableCollector.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/committables/CommittableCollector.java
index 94c5654ee94..efb2ff1404c 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/committables/CommittableCollector.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/committables/CommittableCollector.java
@@ -55,7 +55,7 @@ public class CommittableCollector<CommT> {
 
     private final int numberOfSubtasks;
 
-    CommittableCollector(int subtaskId, int numberOfSubtasks) {
+    public CommittableCollector(int subtaskId, int numberOfSubtasks) {
         this.subtaskId = subtaskId;
         this.numberOfSubtasks = numberOfSubtasks;
         this.checkpointCommittables = new TreeMap<>();
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/committables/CommittableCollectorSerializer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/committables/CommittableCollectorSerializer.java
index 6a8d6f6cd48..07947b98a06 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/committables/CommittableCollectorSerializer.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/committables/CommittableCollectorSerializer.java
@@ -42,7 +42,6 @@ public final class CommittableCollectorSerializer<CommT>
         implements SimpleVersionedSerializer<CommittableCollector<CommT>> {
 
     private static final int MAGIC_NUMBER = 0xb91f252c;
-    private static final long EOI = Long.MAX_VALUE;
 
     private final SimpleVersionedSerializer<CommT> committableSerializer;
     private final int subtaskId;
@@ -85,19 +84,9 @@ public final class CommittableCollectorSerializer<CommT>
     }
 
     private CommittableCollector<CommT> deserializeV1(DataInputView in) throws IOException {
-        final List<CommT> r = new ArrayList<>();
-        final int committableSerializerVersion = in.readInt();
-        final int numOfCommittable = in.readInt();
-
-        for (int i = 0; i < numOfCommittable; i++) {
-            final byte[] bytes = new byte[in.readInt()];
-            in.readFully(bytes);
-            final CommT committable =
-                    committableSerializer.deserialize(committableSerializerVersion, bytes);
-            r.add(committable);
-        }
-
-        return CommittableCollector.ofLegacy(r);
+        return CommittableCollector.ofLegacy(
+                SinkV1CommittableDeserializer.readVersionAndDeserializeList(
+                        committableSerializer, in));
     }
 
     private void serializeV2(
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/committables/SinkV1CommittableDeserializer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/committables/SinkV1CommittableDeserializer.java
new file mode 100644
index 00000000000..c7372ca6397
--- /dev/null
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/committables/SinkV1CommittableDeserializer.java
@@ -0,0 +1,55 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.streaming.runtime.operators.sink.committables;
+
+import org.apache.flink.annotation.Internal;
+import org.apache.flink.annotation.VisibleForTesting;
+import org.apache.flink.core.io.SimpleVersionedSerialization;
+import org.apache.flink.core.io.SimpleVersionedSerializer;
+import org.apache.flink.core.memory.DataInputView;
+
+import java.io.IOException;
+import java.util.List;
+
+/**
+ * This class offers the possibility to deserialize committables that have been written with older
+ * Flink releases (i.e. 1.13, 1.14).
+ */
+@Internal
+public class SinkV1CommittableDeserializer {
+    /**
+     * It is important to keep this number consistent with the number used by the {@code
+     * StreamingCommitterStateSerializer} in Flink 1.13 and 1.14.
+     */
+    @VisibleForTesting public static final int MAGIC_NUMBER = 0xb91f252c;
+
+    public static <T> List<T> readVersionAndDeserializeList(
+            SimpleVersionedSerializer<T> serializer, DataInputView in) throws IOException {
+        validateMagicNumber(in);
+        return SimpleVersionedSerialization.readVersionAndDeserializeList(serializer, in);
+    }
+
+    private static void validateMagicNumber(DataInputView in) throws IOException {
+        final int magicNumber = in.readInt();
+        if (magicNumber != MAGIC_NUMBER) {
+            throw new IllegalStateException(
+                    String.format("Corrupt data: Unexpected magic number %08X", magicNumber));
+        }
+    }
+}
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/translators/SinkTransformationTranslator.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/translators/SinkTransformationTranslator.java
index 09240c00252..cb1486488a5 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/translators/SinkTransformationTranslator.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/translators/SinkTransformationTranslator.java
@@ -27,6 +27,7 @@ import org.apache.flink.api.connector.sink2.TwoPhaseCommittingSink;
 import org.apache.flink.api.dag.Transformation;
 import org.apache.flink.streaming.api.connector.sink2.CommittableMessage;
 import org.apache.flink.streaming.api.connector.sink2.CommittableMessageTypeInfo;
+import org.apache.flink.streaming.api.connector.sink2.StandardSinkTopologies;
 import org.apache.flink.streaming.api.connector.sink2.WithPostCommitTopology;
 import org.apache.flink.streaming.api.connector.sink2.WithPreCommitTopology;
 import org.apache.flink.streaming.api.connector.sink2.WithPreWriteTopology;
@@ -307,10 +308,12 @@ public class SinkTransformationTranslator<Input, Output>
                 BiConsumer<Transformation<?>, String> setter,
                 @Nullable String transformationName) {
             if (transformationName != null && getter.apply(transformation) != null) {
+                // Use the same uid pattern than for Sink V1
                 if (transformationName.equals(COMMITTER_NAME)) {
+                    final String committerFormat = "Sink %s Committer";
                     setter.accept(
                             subTransformation,
-                            getter.apply(transformation) + ": " + COMMITTER_NAME);
+                            String.format(committerFormat, getter.apply(transformation)));
                     return;
                 }
                 // Set the writer operator uid to the sinks uid to support state migrations
@@ -318,6 +321,16 @@ public class SinkTransformationTranslator<Input, Output>
                     setter.accept(subTransformation, getter.apply(transformation));
                     return;
                 }
+
+                // Use the same uid pattern than for Sink V1
+                if (transformationName.equals(
+                        StandardSinkTopologies.GLOBAL_COMMITTER_TRANSFORMATION_NAME)) {
+                    final String committerFormat = "Sink %s Global Committer";
+                    setter.accept(
+                            subTransformation,
+                            String.format(committerFormat, getter.apply(transformation)));
+                    return;
+                }
             }
             concatProperty(subTransformation, getter, setter);
         }
diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/connector/sink2/GlobalCommitterSerializerTest.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/connector/sink2/GlobalCommitterSerializerTest.java
new file mode 100644
index 00000000000..b21abebce4a
--- /dev/null
+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/connector/sink2/GlobalCommitterSerializerTest.java
@@ -0,0 +1,123 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.streaming.api.connector.sink2;
+
+import org.apache.flink.core.io.SimpleVersionedSerializer;
+import org.apache.flink.core.memory.DataInputDeserializer;
+import org.apache.flink.core.memory.DataOutputSerializer;
+import org.apache.flink.streaming.runtime.operators.sink.committables.CommittableCollector;
+import org.apache.flink.streaming.runtime.operators.sink.committables.CommittableCollectorSerializer;
+import org.apache.flink.streaming.runtime.operators.sink.committables.SinkV1CommittableDeserializer;
+
+import org.junit.jupiter.api.Test;
+import org.junit.jupiter.params.ParameterizedTest;
+import org.junit.jupiter.params.provider.ValueSource;
+
+import java.io.IOException;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.List;
+
+import static org.assertj.core.api.Assertions.assertThat;
+
+class GlobalCommitterSerializerTest {
+
+    private static final int SUBTASK_ID = 0;
+    private static final int NUMBER_OF_SUBTASKS = 1;
+    private static final CommittableCollectorSerializer<Integer> COMMITTABLE_COLLECTOR_SERIALIZER =
+            new CommittableCollectorSerializer<>(
+                    new IntegerSerializer(), SUBTASK_ID, NUMBER_OF_SUBTASKS);
+    private static final GlobalCommitterSerializer<Integer, String> SERIALIZER =
+            new GlobalCommitterSerializer<>(
+                    COMMITTABLE_COLLECTOR_SERIALIZER,
+                    new StringSerializer(),
+                    SUBTASK_ID,
+                    NUMBER_OF_SUBTASKS);
+
+    @ParameterizedTest
+    @ValueSource(booleans = {true, false})
+    void testSerDe(boolean withSinkV1State) throws IOException {
+        final GlobalCommitterSerializer<Integer, String> serializer =
+                new GlobalCommitterSerializer<>(
+                        COMMITTABLE_COLLECTOR_SERIALIZER,
+                        withSinkV1State ? new StringSerializer() : null,
+                        SUBTASK_ID,
+                        NUMBER_OF_SUBTASKS);
+        final CommittableCollector<Integer> collector =
+                new CommittableCollector<>(SUBTASK_ID, NUMBER_OF_SUBTASKS);
+        collector.addMessage(new CommittableSummary<>(2, 3, 1L, 1, 1, 0));
+        collector.addMessage(new CommittableWithLineage<>(1, 1L, 2));
+        final List<String> v1State =
+                withSinkV1State ? Arrays.asList("first", "second") : Collections.emptyList();
+        final GlobalCommittableWrapper<Integer, String> wrapper =
+                new GlobalCommittableWrapper<>(collector, v1State);
+        final GlobalCommittableWrapper<Integer, String> copy =
+                serializer.deserialize(2, serializer.serialize(wrapper));
+        assertThat(copy.getGlobalCommittables()).containsExactlyInAnyOrderElementsOf(v1State);
+        assertThat(collector.getNumberOfSubtasks()).isEqualTo(1);
+        assertThat(collector.isFinished()).isFalse();
+        assertThat(collector.getSubtaskId()).isEqualTo(0);
+        assertThat(collector.getCheckpointCommittablesUpTo(2)).hasSize(1);
+    }
+
+    @Test
+    void testDeserializationV1() throws IOException {
+        final DataOutputSerializer out = new DataOutputSerializer(256);
+        final SimpleVersionedSerializer<String> stringSerializer = new StringSerializer();
+        out.writeInt(SinkV1CommittableDeserializer.MAGIC_NUMBER);
+        out.writeInt(1);
+        out.writeInt(2);
+        String state1 = "legacy1";
+        out.writeInt(stringSerializer.serialize(state1).length);
+        out.writeUTF(state1);
+        String state2 = "legacy2";
+        out.writeInt(stringSerializer.serialize(state2).length);
+        out.writeUTF(state2);
+        final byte[] serialized = out.getCopyOfBuffer();
+        final GlobalCommittableWrapper<Integer, String> wrapper =
+                SERIALIZER.deserialize(1, serialized);
+
+        assertThat(wrapper.getGlobalCommittables()).containsExactlyInAnyOrder(state1, state2);
+        final CommittableCollector<Integer> collector = wrapper.getCommittableCollector();
+        assertThat(collector.getNumberOfSubtasks()).isEqualTo(1);
+        assertThat(collector.getSubtaskId()).isEqualTo(0);
+        assertThat(collector.getCheckpointCommittablesUpTo(Long.MAX_VALUE)).isEmpty();
+    }
+
+    private static class StringSerializer implements SimpleVersionedSerializer<String> {
+
+        @Override
+        public int getVersion() {
+            return 1;
+        }
+
+        @Override
+        public byte[] serialize(String obj) throws IOException {
+            final DataOutputSerializer out = new DataOutputSerializer(256);
+            out.writeUTF(obj);
+            return out.getCopyOfBuffer();
+        }
+
+        @Override
+        public String deserialize(int version, byte[] serialized) throws IOException {
+            final DataInputDeserializer in = new DataInputDeserializer(serialized);
+            return in.readUTF();
+        }
+    }
+}
diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/sink/SinkWriterOperatorTest.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/sink/SinkWriterOperatorTest.java
index d71becfe492..b1674fdf510 100644
--- a/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/sink/SinkWriterOperatorTest.java
+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/sink/SinkWriterOperatorTest.java
@@ -24,8 +24,12 @@ import org.apache.flink.api.common.typeutils.base.StringSerializer;
 import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;
 import org.apache.flink.api.connector.sink.Sink;
 import org.apache.flink.api.java.tuple.Tuple3;
+import org.apache.flink.core.io.SimpleVersionedSerialization;
+import org.apache.flink.core.io.SimpleVersionedSerializer;
+import org.apache.flink.core.memory.DataOutputSerializer;
 import org.apache.flink.runtime.checkpoint.OperatorSubtaskState;
 import org.apache.flink.runtime.state.StateInitializationContext;
+import org.apache.flink.runtime.state.StateSnapshotContext;
 import org.apache.flink.streaming.api.connector.sink2.CommittableMessage;
 import org.apache.flink.streaming.api.connector.sink2.CommittableSummary;
 import org.apache.flink.streaming.api.connector.sink2.CommittableWithLineage;
@@ -34,6 +38,7 @@ import org.apache.flink.streaming.api.operators.AbstractStreamOperator;
 import org.apache.flink.streaming.api.operators.OneInputStreamOperator;
 import org.apache.flink.streaming.api.operators.util.SimpleVersionedListState;
 import org.apache.flink.streaming.api.watermark.Watermark;
+import org.apache.flink.streaming.runtime.operators.sink.committables.SinkV1CommittableDeserializer;
 import org.apache.flink.streaming.runtime.streamrecord.StreamElement;
 import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
 import org.apache.flink.streaming.util.OneInputStreamOperatorTestHarness;
@@ -45,6 +50,7 @@ import org.junit.jupiter.params.provider.ValueSource;
 
 import javax.annotation.Nullable;
 
+import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
@@ -291,6 +297,62 @@ class SinkWriterOperatorTest {
         restoredSinkOperator.close();
     }
 
+    @Test
+    void testRestoreCommitterState() throws Exception {
+        final List<String> committables = Arrays.asList("state1", "state2");
+
+        final OneInputStreamOperatorTestHarness<String, String> committer =
+                new OneInputStreamOperatorTestHarness<>(
+                        new TestCommitterOperator(), StringSerializer.INSTANCE);
+
+        final OperatorSubtaskState committerState =
+                TestHarnessUtil.buildSubtaskState(committer, committables);
+
+        final TestSink.DefaultSinkWriter<Integer> sinkWriter = new TestSink.DefaultSinkWriter<>();
+        final OneInputStreamOperatorTestHarness<Integer, CommittableMessage<Integer>> testHarness =
+                new OneInputStreamOperatorTestHarness<>(
+                        new SinkWriterOperatorFactory<>(
+                                TestSink.newBuilder()
+                                        .setDefaultCommitter()
+                                        .setWriter(sinkWriter)
+                                        .build()
+                                        .asV2()));
+
+        testHarness.initializeState(committerState);
+
+        testHarness.open();
+
+        testHarness.prepareSnapshotPreBarrier(2);
+
+        final List<StreamElement> output = fromOutput(testHarness.getOutput());
+        assertThat(output).hasSize(4);
+
+        assertThat(output.get(0).asRecord().getValue())
+                .isInstanceOf(CommittableSummary.class)
+                .satisfies(
+                        cs ->
+                                SinkV2Assertions.assertThat(((CommittableSummary<?>) cs))
+                                        .hasPendingCommittables(committables.size())
+                                        .hasCheckpointId(
+                                                org.apache.flink.api.connector.sink2.Sink
+                                                        .InitContext.INITIAL_CHECKPOINT_ID)
+                                        .hasOverallCommittables(committables.size())
+                                        .hasFailedCommittables(0));
+        assertRestoredCommitterCommittable(
+                output.get(1).asRecord().getValue(), committables.get(0));
+        assertRestoredCommitterCommittable(
+                output.get(2).asRecord().getValue(), committables.get(1));
+        assertThat(output.get(3).asRecord().getValue())
+                .isInstanceOf(CommittableSummary.class)
+                .satisfies(
+                        cs ->
+                                SinkV2Assertions.assertThat(((CommittableSummary<?>) cs))
+                                        .hasPendingCommittables(0)
+                                        .hasCheckpointId(2L)
+                                        .hasOverallCommittables(0)
+                                        .hasFailedCommittables(0));
+    }
+
     @ParameterizedTest
     @ValueSource(booleans = {true, false})
     void testHandleEndInputInStreamingMode(boolean isCheckpointingEnabled) throws Exception {
@@ -322,6 +384,20 @@ class SinkWriterOperatorTest {
         testHarness.close();
     }
 
+    @SuppressWarnings("unchecked")
+    private static void assertRestoredCommitterCommittable(Object record, String committable) {
+        assertThat(record)
+                .isInstanceOf(CommittableWithLineage.class)
+                .satisfies(
+                        cl ->
+                                SinkV2Assertions.assertThat((CommittableWithLineage<String>) cl)
+                                        .hasCommittable(committable)
+                                        .hasCheckpointId(
+                                                org.apache.flink.api.connector.sink2.Sink
+                                                        .InitContext.INITIAL_CHECKPOINT_ID)
+                                        .hasSubtaskId(0));
+    }
+
     @SuppressWarnings("unchecked")
     private static void assertEmitted(List<String> records, Queue<Object> output) {
 
@@ -426,6 +502,38 @@ class SinkWriterOperatorTest {
         }
     }
 
+    private static class TestCommitterOperator extends AbstractStreamOperator<String>
+            implements OneInputStreamOperator<String, String> {
+
+        private static final ListStateDescriptor<byte[]> STREAMING_COMMITTER_RAW_STATES_DESC =
+                new ListStateDescriptor<>(
+                        "streaming_committer_raw_states", BytePrimitiveArraySerializer.INSTANCE);
+        private ListState<List<String>> committerState;
+        private final List<String> buffer = new ArrayList<>();
+
+        @Override
+        public void initializeState(StateInitializationContext context) throws Exception {
+            super.initializeState(context);
+            committerState =
+                    new SimpleVersionedListState<>(
+                            context.getOperatorStateStore()
+                                    .getListState(STREAMING_COMMITTER_RAW_STATES_DESC),
+                            new TestingCommittableSerializer(
+                                    TestSink.StringCommittableSerializer.INSTANCE));
+        }
+
+        @Override
+        public void processElement(StreamRecord<String> element) throws Exception {
+            buffer.add(element.getValue());
+        }
+
+        @Override
+        public void snapshotState(StateSnapshotContext context) throws Exception {
+            super.snapshotState(context);
+            committerState.add(buffer);
+        }
+    }
+
     private static class DummySinkOperator extends AbstractStreamOperator<String>
             implements OneInputStreamOperator<String, String> {
 
@@ -476,4 +584,25 @@ class SinkWriterOperatorTest {
             return result;
         }
     }
+
+    private static class TestingCommittableSerializer
+            extends SinkV1WriterCommittableSerializer<String> {
+
+        private final SimpleVersionedSerializer<String> committableSerializer;
+
+        public TestingCommittableSerializer(
+                SimpleVersionedSerializer<String> committableSerializer) {
+            super(committableSerializer);
+            this.committableSerializer = committableSerializer;
+        }
+
+        @Override
+        public byte[] serialize(List<String> obj) throws IOException {
+            final DataOutputSerializer out = new DataOutputSerializer(256);
+            out.writeInt(SinkV1CommittableDeserializer.MAGIC_NUMBER);
+            SimpleVersionedSerialization.writeVersionAndSerializeList(
+                    committableSerializer, obj, out);
+            return out.getCopyOfBuffer();
+        }
+    }
 }
diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/sink/committables/CommittableCollectorSerializerTest.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/sink/committables/CommittableCollectorSerializerTest.java
index e6599bddba9..b12fed07b75 100644
--- a/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/sink/committables/CommittableCollectorSerializerTest.java
+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/sink/committables/CommittableCollectorSerializerTest.java
@@ -18,13 +18,13 @@
 
 package org.apache.flink.streaming.runtime.operators.sink.committables;
 
+import org.apache.flink.core.io.SimpleVersionedSerialization;
 import org.apache.flink.core.io.SimpleVersionedSerializer;
+import org.apache.flink.core.memory.DataOutputSerializer;
 import org.apache.flink.streaming.api.connector.sink2.CommittableSummary;
 import org.apache.flink.streaming.api.connector.sink2.CommittableWithLineage;
 import org.apache.flink.streaming.api.connector.sink2.IntegerSerializer;
 
-import org.apache.flink.shaded.guava30.com.google.common.primitives.Bytes;
-
 import org.junit.jupiter.api.Test;
 
 import java.io.IOException;
@@ -46,31 +46,12 @@ class CommittableCollectorSerializerTest {
 
     @Test
     void testCommittableCollectorV1SerDe() throws IOException {
-        final int committableSerializerVersion = 1;
-        final int numCommittables = 3;
-        final int committableSize = 4;
-        final List<Integer> legacyState =
-                Arrays.asList(
-                        committableSerializerVersion,
-                        numCommittables,
-                        committableSize,
-                        1,
-                        committableSize,
-                        2,
-                        committableSize,
-                        3);
-        final List<byte[]> bytes =
-                legacyState.stream()
-                        .map(
-                                i -> {
-                                    try {
-                                        return COMMITTABLE_SERIALIZER.serialize(i);
-                                    } catch (IOException e) {
-                                        throw new RuntimeException(e);
-                                    }
-                                })
-                        .collect(Collectors.toList());
-        final byte[] serialized = Bytes.concat(bytes.toArray(new byte[][] {}));
+        final List<Integer> legacyState = Arrays.asList(1, 2, 3);
+        final DataOutputSerializer out = new DataOutputSerializer(256);
+        out.writeInt(SinkV1CommittableDeserializer.MAGIC_NUMBER);
+        SimpleVersionedSerialization.writeVersionAndSerializeList(
+                COMMITTABLE_SERIALIZER, legacyState, out);
+        final byte[] serialized = out.getCopyOfBuffer();
         final CommittableCollector<Integer> committableCollector =
                 SERIALIZER.deserialize(1, serialized);
         assertThat(committableCollector.getNumberOfSubtasks()).isEqualTo(1);
diff --git a/flink-tests/src/test/java/org/apache/flink/test/streaming/runtime/UnifiedSinkMigrationITCase.java b/flink-tests/src/test/java/org/apache/flink/test/streaming/runtime/UnifiedSinkMigrationITCase.java
new file mode 100644
index 00000000000..2b23936c6bb
--- /dev/null
+++ b/flink-tests/src/test/java/org/apache/flink/test/streaming/runtime/UnifiedSinkMigrationITCase.java
@@ -0,0 +1,382 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.test.streaming.runtime;
+
+import org.apache.flink.api.common.JobStatus;
+import org.apache.flink.api.common.functions.MapFunction;
+import org.apache.flink.api.common.restartstrategy.RestartStrategies;
+import org.apache.flink.api.connector.sink.Committer;
+import org.apache.flink.api.connector.sink.GlobalCommitter;
+import org.apache.flink.api.connector.sink.Sink;
+import org.apache.flink.api.connector.sink.SinkWriter;
+import org.apache.flink.configuration.Configuration;
+import org.apache.flink.core.execution.JobClient;
+import org.apache.flink.core.execution.SavepointFormatType;
+import org.apache.flink.core.io.SimpleVersionedSerializer;
+import org.apache.flink.core.memory.DataInputDeserializer;
+import org.apache.flink.core.memory.DataOutputSerializer;
+import org.apache.flink.core.testutils.OneShotLatch;
+import org.apache.flink.runtime.jobgraph.SavepointConfigOptions;
+import org.apache.flink.runtime.testutils.MiniClusterResourceConfiguration;
+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
+import org.apache.flink.test.junit5.MiniClusterExtension;
+import org.apache.flink.testutils.junit.SharedObjectsExtension;
+import org.apache.flink.testutils.junit.SharedReference;
+import org.apache.flink.util.TestLoggerExtension;
+
+import org.junit.jupiter.api.Disabled;
+import org.junit.jupiter.api.Test;
+import org.junit.jupiter.api.extension.ExtendWith;
+import org.junit.jupiter.api.extension.RegisterExtension;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.io.File;
+import java.io.IOException;
+import java.net.URISyntaxException;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.List;
+import java.util.Optional;
+import java.util.concurrent.CompletableFuture;
+import java.util.concurrent.CountDownLatch;
+
+import static org.assertj.core.api.Assertions.assertThat;
+
+@ExtendWith(TestLoggerExtension.class)
+class UnifiedSinkMigrationITCase {
+
+    private static final Logger LOG = LoggerFactory.getLogger(UnifiedSinkMigrationITCase.class);
+
+    private static final String SAVEPOINT_FOLDER_NAME = "unified-sink-migration-test";
+
+    @RegisterExtension
+    private static final MiniClusterExtension miniClusterExtension =
+            new MiniClusterExtension(new MiniClusterResourceConfiguration.Builder().build());
+
+    @RegisterExtension
+    private final SharedObjectsExtension sharedObjects = SharedObjectsExtension.create();
+
+    private static final int WRITER_STATE = 1;
+    private static final int COMMITTER_STATE = 2;
+    private static final int GLOBAL_COMMITTER_STATE = 3;
+    private static final String SINK_UUID = "1c4ec0f9-2d96-46e9-99ea-45e8c3df5202";
+
+    /**
+     * You can enable this test to update the taken savepoint.
+     *
+     * <p>Be aware that the current savepoint points to snapshot taken before the introduction of
+     * Sink V2 to test the migration.
+     */
+    @Disabled
+    @Test
+    void prepareSinkSavepoint() throws Exception {
+        LOG.warn("Deleting the previous savepoints.");
+        final Path basePath = Paths.get("src/test/resources/").resolve(SAVEPOINT_FOLDER_NAME);
+
+        Files.walk(basePath)
+                .skip(1)
+                .sorted(Comparator.reverseOrder())
+                .map(Path::toFile)
+                .forEach(File::delete);
+
+        final JobClient jobClient = executeJob(false);
+
+        final CompletableFuture<String> savepointFuture =
+                jobClient.stopWithSavepoint(
+                        false, basePath.toString(), SavepointFormatType.CANONICAL);
+        final String savepointPath = savepointFuture.get();
+        LOG.info("Savepoint path: {}", savepointPath);
+        assertThat(savepointPath).contains(basePath.toString());
+    }
+
+    /**
+     * This test tries to restore a job with a complete Sink V1 sink
+     * writer->committer->global-committer to ensure the state compatibility.
+     */
+    @Test
+    void testRestoreSinkState() throws Exception {
+        // Restore job and wait for one successful commit
+        final JobClient jobClient = executeJob(true);
+
+        // Await shutdown
+        jobClient.cancel();
+    }
+
+    private JobClient executeJob(boolean restore) throws Exception {
+        final Configuration conf = new Configuration();
+        if (restore) {
+            conf.set(SavepointConfigOptions.SAVEPOINT_PATH, findSavepointPath());
+        }
+        final StreamExecutionEnvironment env =
+                StreamExecutionEnvironment.getExecutionEnvironment(conf);
+        final SharedReference<OneShotLatch> latch = sharedObjects.add(new OneShotLatch());
+        final SharedReference<CountDownLatch> commitLatch =
+                sharedObjects.add(new CountDownLatch(2));
+
+        env.enableCheckpointing(100);
+        env.setParallelism(1);
+        env.setRestartStrategy(RestartStrategies.noRestart());
+        env.fromSequence(1, Long.MAX_VALUE)
+                .map(
+                        (MapFunction<Long, Long>)
+                                value -> {
+                                    // Throttle the execution to prevent writing to many records
+                                    Thread.sleep(10);
+                                    return value;
+                                })
+                .sinkTo(new StateFulSinkV1(restore, latch, commitLatch))
+                // Until FLINK-26358 is fixed
+                .disableChaining()
+                .uid(SINK_UUID);
+        final JobClient jobClient = env.executeAsync();
+
+        // Wait until a fist checkpoint has been taken successful
+        latch.get().await();
+        assertThat(jobClient.getJobStatus().get()).isEqualTo(JobStatus.RUNNING);
+        return jobClient;
+    }
+
+    private File buildSavepointPath() throws URISyntaxException {
+        return new File(getClass().getResource("/" + SAVEPOINT_FOLDER_NAME).toURI());
+    }
+
+    private String findSavepointPath() throws URISyntaxException {
+        final File basePath = buildSavepointPath();
+        LOG.info("Base path: {}", basePath.getAbsolutePath());
+        final File[] savepointDirectories = basePath.listFiles(File::isDirectory);
+        assertThat(savepointDirectories).isNotNull().hasSize(1);
+        final File[] stateFiles = savepointDirectories[0].listFiles();
+        assertThat(stateFiles).isNotNull().hasSize(1);
+        return stateFiles[0].getAbsolutePath();
+    }
+
+    private static class StateFulSinkV1 implements Sink<Long, Integer, Integer, String> {
+
+        private final boolean recovered;
+        private final SharedReference<OneShotLatch> latch;
+        private final SharedReference<CountDownLatch> commitLatch;
+
+        StateFulSinkV1(
+                boolean recovered,
+                SharedReference<OneShotLatch> latch,
+                SharedReference<CountDownLatch> commitLatch) {
+            this.recovered = recovered;
+            this.latch = latch;
+            this.commitLatch = commitLatch;
+        }
+
+        @Override
+        public SinkWriter<Long, Integer, Integer> createWriter(
+                InitContext context, List<Integer> states) throws IOException {
+            return new TestWriter(recovered, states);
+        }
+
+        @Override
+        public Optional<SimpleVersionedSerializer<Integer>> getWriterStateSerializer() {
+            return Optional.of(new IntegerSerializer());
+        }
+
+        @Override
+        public Optional<Committer<Integer>> createCommitter() throws IOException {
+            return Optional.of(new TestCommitter(recovered, commitLatch));
+        }
+
+        @Override
+        public Optional<GlobalCommitter<Integer, String>> createGlobalCommitter()
+                throws IOException {
+            return Optional.of(new TestGlobalCommitter(recovered, latch, commitLatch));
+        }
+
+        @Override
+        public Optional<SimpleVersionedSerializer<Integer>> getCommittableSerializer() {
+            return Optional.of(new IntegerSerializer());
+        }
+
+        @Override
+        public Optional<SimpleVersionedSerializer<String>> getGlobalCommittableSerializer() {
+            return Optional.of(new StringSerializer());
+        }
+    }
+
+    private static class TestWriter implements SinkWriter<Long, Integer, Integer> {
+
+        private final boolean recovered;
+        private boolean emitted = false;
+
+        TestWriter(boolean recovered, List<Integer> recoveredState) {
+            this.recovered = recovered;
+            if (recovered) {
+                assertThat(recoveredState).containsExactly(WRITER_STATE);
+            } else {
+                assertThat(recoveredState).isEmpty();
+            }
+        }
+
+        @Override
+        public void write(Long element, Context context) throws IOException, InterruptedException {}
+
+        @Override
+        public List<Integer> prepareCommit(boolean flush) throws IOException, InterruptedException {
+            if (emitted || recovered) {
+                return Collections.emptyList();
+            }
+            emitted = true;
+            return Arrays.asList(COMMITTER_STATE, GLOBAL_COMMITTER_STATE);
+        }
+
+        @Override
+        public List<Integer> snapshotState(long checkpointId) throws IOException {
+            return Collections.singletonList(WRITER_STATE);
+        }
+
+        @Override
+        public void close() throws Exception {}
+    }
+
+    private static class TestCommitter implements Committer<Integer> {
+
+        private final boolean recovered;
+        private final SharedReference<CountDownLatch> commitLatch;
+        boolean firstCommit = true;
+
+        TestCommitter(boolean recovered, SharedReference<CountDownLatch> commitLatch) {
+            this.recovered = recovered;
+            this.commitLatch = commitLatch;
+        }
+
+        @Override
+        public List<Integer> commit(List<Integer> committables)
+                throws IOException, InterruptedException {
+            if (firstCommit && !recovered) {
+                assertThat(committables).containsExactly(COMMITTER_STATE, GLOBAL_COMMITTER_STATE);
+            } else {
+                assertThat(committables).containsExactly(COMMITTER_STATE);
+            }
+            LOG.info("Committing {}", committables);
+            commitLatch.get().countDown();
+            firstCommit = false;
+            // Always retry to keep the state
+            return Collections.singletonList(COMMITTER_STATE);
+        }
+
+        @Override
+        public void close() throws Exception {}
+    }
+
+    private static class TestGlobalCommitter implements GlobalCommitter<Integer, String> {
+
+        private final boolean recover;
+        private final SharedReference<OneShotLatch> latch;
+        private final SharedReference<CountDownLatch> commitLatch;
+        private boolean firstCommitAfterRecover;
+
+        TestGlobalCommitter(
+                boolean recover,
+                SharedReference<OneShotLatch> latch,
+                SharedReference<CountDownLatch> commitLatch) {
+            this.recover = recover;
+            this.firstCommitAfterRecover = recover;
+            this.latch = latch;
+            this.commitLatch = commitLatch;
+        }
+
+        @Override
+        public List<String> filterRecoveredCommittables(List<String> globalCommittables)
+                throws IOException {
+            if (recover) {
+                assertThat(globalCommittables)
+                        .containsExactly(String.valueOf(GLOBAL_COMMITTER_STATE));
+            }
+            return globalCommittables;
+        }
+
+        @Override
+        public String combine(List<Integer> committables) throws IOException {
+            assertThat(committables).hasSize(1);
+            return String.valueOf(committables.get(0));
+        }
+
+        @Override
+        public List<String> commit(List<String> globalCommittables)
+                throws IOException, InterruptedException {
+            LOG.info("Global committing {}", globalCommittables);
+            LOG.info("Latch count: {}", commitLatch.get().getCount());
+            if (!firstCommitAfterRecover && commitLatch.get().getCount() <= 0) {
+                latch.get().trigger();
+                // Always retry to keep the state
+                assertThat(globalCommittables)
+                        .containsExactly(String.valueOf(GLOBAL_COMMITTER_STATE));
+            }
+            firstCommitAfterRecover = false;
+            return globalCommittables;
+        }
+
+        @Override
+        public void endOfInput() throws IOException, InterruptedException {}
+
+        @Override
+        public void close() throws Exception {}
+    }
+
+    private static class StringSerializer implements SimpleVersionedSerializer<String> {
+
+        @Override
+        public int getVersion() {
+            return 0;
+        }
+
+        @Override
+        public byte[] serialize(String obj) throws IOException {
+            DataOutputSerializer out = new DataOutputSerializer(8);
+            out.writeUTF(obj);
+            return out.getCopyOfBuffer();
+        }
+
+        @Override
+        public String deserialize(int version, byte[] serialized) throws IOException {
+            final DataInputDeserializer in = new DataInputDeserializer(serialized);
+            return in.readUTF();
+        }
+    }
+
+    private static class IntegerSerializer implements SimpleVersionedSerializer<Integer> {
+        @Override
+        public int getVersion() {
+            return 0;
+        }
+
+        @Override
+        public byte[] serialize(Integer obj) throws IOException {
+            DataOutputSerializer out = new DataOutputSerializer(8);
+            out.writeInt(obj);
+            return out.getCopyOfBuffer();
+        }
+
+        @Override
+        public Integer deserialize(int version, byte[] serialized) throws IOException {
+            final DataInputDeserializer in = new DataInputDeserializer(serialized);
+            return in.readInt();
+        }
+    }
+}
diff --git a/flink-tests/src/test/resources/unified-sink-migration-test/savepoint-7bd90b-3a2cda6957cb/_metadata b/flink-tests/src/test/resources/unified-sink-migration-test/savepoint-7bd90b-3a2cda6957cb/_metadata
new file mode 100644
index 00000000000..fc296fdeea1
Binary files /dev/null and b/flink-tests/src/test/resources/unified-sink-migration-test/savepoint-7bd90b-3a2cda6957cb/_metadata differ
