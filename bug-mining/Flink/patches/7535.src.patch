diff --git a/flink-table/flink-table-planner/src/main/java/org/apache/calcite/sql/validate/ProcedureNamespace.java b/flink-table/flink-table-planner/src/main/java/org/apache/calcite/sql/validate/ProcedureNamespace.java
index 9bd055f75d2..ee811aafbf9 100644
--- a/flink-table/flink-table-planner/src/main/java/org/apache/calcite/sql/validate/ProcedureNamespace.java
+++ b/flink-table/flink-table-planner/src/main/java/org/apache/calcite/sql/validate/ProcedureNamespace.java
@@ -25,6 +25,7 @@ import org.apache.calcite.sql.SqlCallBinding;
 import org.apache.calcite.sql.SqlNode;
 import org.apache.calcite.sql.SqlOperator;
 import org.apache.calcite.sql.SqlTableFunction;
+import org.apache.calcite.sql.SqlWindowTableFunction;
 import org.apache.calcite.sql.type.SqlReturnTypeInference;
 
 import static java.util.Objects.requireNonNull;
@@ -56,14 +57,17 @@ public final class ProcedureNamespace extends AbstractNamespace {
 
     public RelDataType validateImpl(RelDataType targetRowType) {
         validator.inferUnknownTypes(validator.unknownType, scope, call);
-        // The result is ignored but the type is derived to trigger the validation
+        final SqlOperator operator = call.getOperator();
         final SqlCallBinding callBinding = new FlinkSqlCallBinding(validator, scope, call);
+        // The result is ignored but the type is derived to trigger the function resolution
         validator.deriveTypeImpl(scope, callBinding.permutedCall());
-        final SqlOperator operator = call.getOperator();
         if (!(operator instanceof SqlTableFunction)) {
             throw new IllegalArgumentException(
                     "Argument must be a table function: " + operator.getNameAsId());
         }
+        if (operator instanceof SqlWindowTableFunction) {
+            callBinding.permutedCall().validate(validator, scope);
+        }
         final SqlTableFunction tableFunction = (SqlTableFunction) operator;
         final SqlReturnTypeInference rowTypeInference = tableFunction.getRowTypeInference();
         final RelDataType rowRelDataType =
diff --git a/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/functions/sql/SqlWindowTableFunction.java b/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/functions/sql/SqlWindowTableFunction.java
index 3f22bed1907..4a33380839b 100644
--- a/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/functions/sql/SqlWindowTableFunction.java
+++ b/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/functions/sql/SqlWindowTableFunction.java
@@ -42,6 +42,7 @@ import org.apache.calcite.sql.type.SqlTypeName;
 import org.apache.calcite.sql.type.SqlTypeUtil;
 import org.apache.calcite.sql.validate.SqlNameMatcher;
 import org.apache.calcite.sql.validate.SqlValidator;
+import org.apache.calcite.sql.validate.SqlValidatorScope;
 
 import java.util.Collections;
 import java.util.List;
@@ -96,6 +97,27 @@ public class SqlWindowTableFunction extends org.apache.calcite.sql.SqlWindowTabl
         return ARG0_TABLE_FUNCTION_WINDOWING;
     }
 
+    @Override
+    public void validateCall(
+            SqlCall call,
+            SqlValidator validator,
+            SqlValidatorScope scope,
+            SqlValidatorScope operandScope) {
+        assert call.getOperator() == this;
+        final List<SqlNode> operandList = call.getOperandList();
+        // Validation for DESCRIPTOR or PARTITION BY of SESSION window is broken, and we
+        // make assumptions at different locations those are not validated and not properly scoped.
+        // Theoretically, we should scope identifiers of the above to the result of the subquery
+        // from the first argument. Unfortunately this breaks at other locations which do not expect
+        // it. We run additional validations while deriving the return type, therefore we can skip
+        // it here.
+        SqlNode selectQuery = operandList.get(0);
+        if (selectQuery.getKind().equals(SqlKind.SET_SEMANTICS_TABLE)) {
+            selectQuery = ((SqlCall) selectQuery).getOperandList().get(0);
+        }
+        selectQuery.validate(validator, scope);
+    }
+
     /**
      * {@inheritDoc}
      *
diff --git a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/stream/MiscTests.java b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/stream/MiscTests.java
new file mode 100644
index 00000000000..9d894718711
--- /dev/null
+++ b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/stream/MiscTests.java
@@ -0,0 +1,116 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.table.planner.plan.nodes.exec.stream;
+
+import org.apache.flink.table.api.EnvironmentSettings;
+import org.apache.flink.table.api.TableEnvironment;
+import org.apache.flink.table.planner.factories.TestValuesTableFactory;
+import org.apache.flink.table.planner.plan.nodes.exec.testutils.RestoreTestBase;
+import org.apache.flink.table.test.program.SinkTestStep;
+import org.apache.flink.table.test.program.SourceTestStep;
+import org.apache.flink.table.test.program.TableTestProgram;
+import org.apache.flink.table.test.program.TableTestProgramRunner;
+import org.apache.flink.table.test.program.TestStep;
+import org.apache.flink.test.junit5.MiniClusterExtension;
+
+import org.junit.jupiter.api.AfterEach;
+import org.junit.jupiter.api.TestInstance;
+import org.junit.jupiter.api.extension.ExtendWith;
+import org.junit.jupiter.params.ParameterizedTest;
+import org.junit.jupiter.params.provider.MethodSource;
+
+import java.util.Collections;
+import java.util.EnumSet;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+import static org.assertj.core.api.Assertions.assertThat;
+
+/**
+ * Miscellaneous tests that do not fall into {@link RestoreTestBase} category, but use the {@link
+ * TableTestProgram} infrastructure.
+ */
+@ExtendWith(MiniClusterExtension.class)
+@TestInstance(TestInstance.Lifecycle.PER_CLASS)
+class MiscTests implements TableTestProgramRunner {
+    @Override
+    public List<TableTestProgram> programs() {
+        return Collections.singletonList(
+                WindowRankTestPrograms.WINDOW_RANK_HOP_TVF_NAMED_MIN_TOP_1);
+    }
+
+    @Override
+    public EnumSet<TestStep.TestKind> supportedSetupSteps() {
+        return EnumSet.of(
+                TestStep.TestKind.CONFIG,
+                TestStep.TestKind.SOURCE_WITH_DATA,
+                TestStep.TestKind.SINK_WITH_DATA);
+    }
+
+    @Override
+    public EnumSet<TestStep.TestKind> supportedRunSteps() {
+        return EnumSet.of(TestStep.TestKind.SQL);
+    }
+
+    @AfterEach
+    public void clearData() {
+        TestValuesTableFactory.clearAllData();
+    }
+
+    @ParameterizedTest
+    @MethodSource("supportedPrograms")
+    void runTests(TableTestProgram program) throws Exception {
+        final TableEnvironment tEnv =
+                TableEnvironment.create(EnvironmentSettings.inStreamingMode());
+        program.getSetupConfigOptionTestSteps().forEach(s -> s.apply(tEnv));
+
+        for (SourceTestStep sourceTestStep : program.getSetupSourceTestSteps()) {
+            final String id = TestValuesTableFactory.registerData(sourceTestStep.dataBeforeRestore);
+            final Map<String, String> options = new HashMap<>();
+            options.put("connector", "values");
+            options.put("data-id", id);
+            options.put("runtime-source", "NewSource");
+            sourceTestStep.apply(tEnv, options);
+        }
+
+        for (SinkTestStep sinkTestStep : program.getSetupSinkTestSteps()) {
+            final Map<String, String> options = new HashMap<>();
+            options.put("connector", "values");
+            options.put("sink-insert-only", "false");
+            sinkTestStep.apply(tEnv, options);
+        }
+
+        program.getRunSqlTestStep().apply(tEnv).await();
+        for (SinkTestStep sinkTestStep : program.getSetupSinkTestSteps()) {
+            List<String> expectedResults = getExpectedResults(sinkTestStep, sinkTestStep.name);
+            assertThat(expectedResults)
+                    .containsExactlyInAnyOrder(
+                            sinkTestStep.getExpectedAsStrings().toArray(new String[0]));
+        }
+    }
+
+    private static List<String> getExpectedResults(SinkTestStep sinkTestStep, String tableName) {
+        if (sinkTestStep.getTestChangelogData()) {
+            return TestValuesTableFactory.getRawResultsAsStrings(tableName);
+        } else {
+            return TestValuesTableFactory.getResultsAsStrings(tableName);
+        }
+    }
+}
diff --git a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/stream/WindowRankTestPrograms.java b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/stream/WindowRankTestPrograms.java
index bacbe648a9d..f2b10e0c2d2 100644
--- a/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/stream/WindowRankTestPrograms.java
+++ b/flink-table/flink-table-planner/src/test/java/org/apache/flink/table/planner/plan/nodes/exec/stream/WindowRankTestPrograms.java
@@ -237,6 +237,47 @@ public class WindowRankTestPrograms {
                     .runSql(String.format(QUERY_TVF_TOP_N, "ASC", HOP_TVF))
                     .build();
 
+    static final TableTestProgram WINDOW_RANK_HOP_TVF_NAMED_MIN_TOP_1 =
+            TableTestProgram.of(
+                            "window-rank-hop-tvf-named-min-top-n",
+                            "validates window min top-n follows after hop window")
+                    .setupTableSource(
+                            SourceTestStep.newBuilder("bid_t")
+                                    .addSchema(
+                                            "ts STRING",
+                                            "price DECIMAL(10,2)",
+                                            "supplier_id STRING",
+                                            "`bid_time` AS TO_TIMESTAMP(`ts`)",
+                                            "WATERMARK for `bid_time` AS `bid_time` - INTERVAL '1' SECOND")
+                                    .producedValues(
+                                            Row.of(
+                                                    "2020-04-15 08:00:05",
+                                                    new BigDecimal(4.00),
+                                                    "supplier1"))
+                                    .build())
+                    .setupTableSink(
+                            SinkTestStep.newBuilder("sink_t")
+                                    .addSchema("bid_time TIMESTAMP(3)", "supplier_id STRING")
+                                    .consumedValues(
+                                            "+I[2020-04-15T08:00:05, supplier1]",
+                                            "+I[2020-04-15T08:00:05, supplier1]")
+                                    .build())
+                    .runSql(
+                            "INSERT INTO sink_t(bid_time, supplier_id) "
+                                    + "SELECT bid_time, supplier_id\n"
+                                    + "  FROM (\n"
+                                    + "    SELECT\n"
+                                    + "         bid_time,\n"
+                                    + "         supplier_id,\n"
+                                    + "         ROW_NUMBER() OVER (PARTITION BY window_start, window_end ORDER BY price ASC) AS row_num\n"
+                                    + "    FROM TABLE(HOP(\n"
+                                    + "      DATA => TABLE bid_t,\n"
+                                    + "      TIMECOL => DESCRIPTOR(`bid_time`),\n"
+                                    + "      SLIDE => INTERVAL '5' SECOND,\n"
+                                    + "      SIZE => INTERVAL '10' SECOND))\n"
+                                    + "  ) WHERE row_num <= 3")
+                    .build();
+
     static final TableTestProgram WINDOW_RANK_CUMULATE_TVF_MIN_TOP_N =
             TableTestProgram.of(
                             "window-rank-cumulate-tvf-min-top-n",
