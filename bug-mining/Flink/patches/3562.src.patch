diff --git a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/calcite/PreValidateReWriter.scala b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/calcite/PreValidateReWriter.scala
index 229e6b3b2fd..307f580c9a4 100644
--- a/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/calcite/PreValidateReWriter.scala
+++ b/flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/calcite/PreValidateReWriter.scala
@@ -20,6 +20,7 @@ package org.apache.flink.table.planner.calcite
 
 import org.apache.flink.sql.parser.SqlProperty
 import org.apache.flink.sql.parser.dml.RichSqlInsert
+import org.apache.flink.table.api.ValidationException
 import org.apache.flink.table.planner.calcite.PreValidateReWriter.appendPartitionProjects
 
 import org.apache.calcite.plan.RelOptTable
@@ -45,10 +46,14 @@ class PreValidateReWriter(
     val typeFactory: RelDataTypeFactory) extends SqlBasicVisitor[Unit] {
   override def visit(call: SqlCall): Unit = {
     call match {
-      case r: RichSqlInsert if r.getStaticPartitions.nonEmpty
-        && r.getSource.isInstanceOf[SqlSelect] =>
-        appendPartitionProjects(r, catalogReader, typeFactory,
-          r.getSource.asInstanceOf[SqlSelect], r.getStaticPartitions)
+      case r: RichSqlInsert if r.getStaticPartitions.nonEmpty => r.getSource match {
+        case select: SqlSelect =>
+          appendPartitionProjects(r, catalogReader, typeFactory, select, r.getStaticPartitions)
+        case source =>
+          throw new ValidationException(
+            s"INSERT INTO <table> PARTITION statement only support SELECT clause for now," +
+                s" '$source' is not supported yet.")
+      }
       case _ =>
     }
   }
diff --git a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/plan/batch/sql/PartitionableSinkTest.scala b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/plan/batch/sql/PartitionableSinkTest.scala
index 84d56597d4f..b7d1f67dfef 100644
--- a/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/plan/batch/sql/PartitionableSinkTest.scala
+++ b/flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/plan/batch/sql/PartitionableSinkTest.scala
@@ -65,4 +65,13 @@ class PartitionableSinkTest extends TableTestBase {
   def testWrongFields(): Unit = {
     util.verifySqlUpdate("INSERT INTO sink PARTITION (b=1) SELECT a, b, c FROM MyTable")
   }
+
+  @Test
+  def testStaticWithValues(): Unit = {
+    thrown.expect(classOf[ValidationException])
+    thrown.expectMessage(
+      "INSERT INTO <table> PARTITION statement only support SELECT clause for now," +
+          " 'VALUES ROW(5)' is not supported yet")
+    util.verifySqlUpdate("INSERT INTO sink PARTITION (b=1, c=1) VALUES (5)")
+  }
 }
