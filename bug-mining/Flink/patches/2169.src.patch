diff --git a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/codegen/AggregationCodeGenerator.scala b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/codegen/AggregationCodeGenerator.scala
index 32cbde2390c..a9ec112e3b4 100644
--- a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/codegen/AggregationCodeGenerator.scala
+++ b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/codegen/AggregationCodeGenerator.scala
@@ -121,7 +121,7 @@ class AggregationCodeGenerator(
 
     // get parameter lists for aggregation functions
     val parametersCode = aggFields.map { inFields =>
-      val fields = inFields.map { f =>
+      val fields = inFields.filter(_ > -1).map { f =>
         // index to constant
         if (f >= physicalInputTypes.length) {
           constantFields(f - physicalInputTypes.length)
@@ -139,7 +139,7 @@ class AggregationCodeGenerator(
     val classes = UserDefinedFunctionUtils.typeInfoToClass(physicalInputTypes)
     val constantClasses = UserDefinedFunctionUtils.typeInfoToClass(constantTypes)
     val methodSignaturesList = aggFields.map { inFields =>
-      inFields.map { f =>
+      inFields.filter(_ > -1).map { f =>
         // index to constant
         if (f >= physicalInputTypes.length) {
           constantClasses(f - physicalInputTypes.length)
@@ -363,8 +363,8 @@ class AggregationCodeGenerator(
              |    ${accTypes(i)} acc$i = (${accTypes(i)}) accs.getField($i);
              |    ${genDataViewFieldSetter(s"acc$i", i)}
              |    ${aggs(i)}.accumulate(
-             |      acc$i,
-             |      ${parametersCode(i)});""".stripMargin
+             |      acc$i ${if (!parametersCode(i).isEmpty) "," else "" } ${parametersCode(i)});
+           """.stripMargin
         }
       }.mkString("\n")
 
@@ -387,8 +387,8 @@ class AggregationCodeGenerator(
              |    ${accTypes(i)} acc$i = (${accTypes(i)}) accs.getField($i);
              |    ${genDataViewFieldSetter(s"acc$i", i)}
              |    ${aggs(i)}.retract(
-             |      acc$i,
-             |      ${parametersCode(i)});""".stripMargin
+             |      acc$i ${if (!parametersCode(i).isEmpty) "," else "" } ${parametersCode(i)});
+           """.stripMargin
         }
       }.mkString("\n")
 
diff --git a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/functions/aggfunctions/CountAggFunction.scala b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/functions/aggfunctions/CountAggFunction.scala
index c94e05396c5..7147e171084 100644
--- a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/functions/aggfunctions/CountAggFunction.scala
+++ b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/functions/aggfunctions/CountAggFunction.scala
@@ -33,7 +33,20 @@ class CountAccumulator extends JTuple1[Long] {
 /**
   * built-in count aggregate function
   */
-class CountAggFunction extends AggregateFunction[JLong, CountAccumulator] {
+class CountAggFunction
+  extends AggregateFunction[JLong, CountAccumulator] {
+
+  // process argument is optimized by Calcite.
+  // For instance count(42) or count(*) will be optimized to count().
+  def accumulate(acc: CountAccumulator): Unit = {
+    acc.f0 += 1L
+  }
+
+  // process argument is optimized by Calcite.
+  // For instance count(42) or count(*) will be optimized to count().
+  def retract(acc: CountAccumulator): Unit = {
+    acc.f0 -= 1L
+  }
 
   def accumulate(acc: CountAccumulator, value: Any): Unit = {
     if (value != null) {
diff --git a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/plan/nodes/datastream/DataStreamOverAggregate.scala b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/plan/nodes/datastream/DataStreamOverAggregate.scala
index c41c1a99dd5..635c7bc2d03 100644
--- a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/plan/nodes/datastream/DataStreamOverAggregate.scala
+++ b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/plan/nodes/datastream/DataStreamOverAggregate.scala
@@ -145,6 +145,14 @@ class DataStreamOverAggregate(
       inputSchema.typeInfo,
       Some(constants))
 
+    val constantTypes = constants.map(_.getType)
+    val fieldTypes = input.getRowType.getFieldList.asScala.map(_.getType)
+    val aggInTypes = fieldTypes ++ constantTypes
+    val aggInNames = aggInTypes.indices.map("f" + _)
+
+    val aggregateInputType =
+      getCluster.getTypeFactory.createStructType(aggInTypes.asJava, aggInNames.asJava)
+
     val timeType = schema.relDataType
       .getFieldList
       .get(orderKey.getFieldIndex)
@@ -167,6 +175,7 @@ class DataStreamOverAggregate(
         generator,
         inputDS,
         rowTimeIdx,
+        aggregateInputType,
         isRowsClause = overWindow.isRows)
     } else if (
       overWindow.lowerBound.isPreceding && !overWindow.lowerBound.isUnbounded &&
@@ -178,6 +187,7 @@ class DataStreamOverAggregate(
         generator,
         inputDS,
         rowTimeIdx,
+        aggregateInputType,
         isRowsClause = overWindow.isRows)
     } else {
       throw new TableException("OVER RANGE FOLLOWING windows are not supported yet.")
@@ -189,6 +199,7 @@ class DataStreamOverAggregate(
     generator: AggregationCodeGenerator,
     inputDS: DataStream[CRow],
     rowTimeIdx: Option[Int],
+    aggregateInputType: RelDataType,
     isRowsClause: Boolean): DataStream[CRow] = {
 
     val overWindow: Group = logicWindow.groups.get(0)
@@ -203,6 +214,7 @@ class DataStreamOverAggregate(
     val processFunction = AggregateUtil.createUnboundedOverProcessFunction(
       generator,
       namedAggregates,
+      aggregateInputType,
       inputSchema.relDataType,
       inputSchema.typeInfo,
       inputSchema.fieldTypeInfos,
@@ -236,6 +248,7 @@ class DataStreamOverAggregate(
     generator: AggregationCodeGenerator,
     inputDS: DataStream[CRow],
     rowTimeIdx: Option[Int],
+    aggregateInputType: RelDataType,
     isRowsClause: Boolean): DataStream[CRow] = {
 
     val overWindow: Group = logicWindow.groups.get(0)
@@ -253,6 +266,7 @@ class DataStreamOverAggregate(
     val processFunction = AggregateUtil.createBoundedOverProcessFunction(
       generator,
       namedAggregates,
+      aggregateInputType,
       inputSchema.relDataType,
       inputSchema.typeInfo,
       inputSchema.fieldTypeInfos,
diff --git a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/aggregate/AggregateUtil.scala b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/aggregate/AggregateUtil.scala
index 0d07153aa20..361a87e2147 100644
--- a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/aggregate/AggregateUtil.scala
+++ b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/aggregate/AggregateUtil.scala
@@ -62,6 +62,7 @@ object AggregateUtil {
     *
     * @param generator       code generator instance
     * @param namedAggregates Physical calls to aggregate functions and their output field names
+    * @param aggregateInputType Physical type of the aggregate functions's input row.
     * @param inputType Physical type of the row.
     * @param inputTypeInfo Physical type information of the row.
     * @param inputFieldTypeInfo Physical type information of the row's fields.
@@ -72,6 +73,7 @@ object AggregateUtil {
   private[flink] def createUnboundedOverProcessFunction(
       generator: AggregationCodeGenerator,
       namedAggregates: Seq[CalcitePair[AggregateCall, String]],
+      aggregateInputType: RelDataType,
       inputType: RelDataType,
       inputTypeInfo: TypeInformation[Row],
       inputFieldTypeInfo: Seq[TypeInformation[_]],
@@ -84,7 +86,7 @@ object AggregateUtil {
     val (aggFields, aggregates, accTypes, accSpecs) =
       transformToAggregateFunctions(
         namedAggregates.map(_.getKey),
-        inputType,
+        aggregateInputType,
         needRetraction = false,
         isStateBackedDataViews = true)
 
@@ -203,6 +205,7 @@ object AggregateUtil {
     *
     * @param generator       code generator instance
     * @param namedAggregates Physical calls to aggregate functions and their output field names
+    * @param aggregateInputType Physical type of the aggregate functions's input row.
     * @param inputType Physical type of the row.
     * @param inputTypeInfo Physical type information of the row.
     * @param inputFieldTypeInfo Physical type information of the row's fields.
@@ -214,6 +217,7 @@ object AggregateUtil {
   private[flink] def createBoundedOverProcessFunction(
       generator: AggregationCodeGenerator,
       namedAggregates: Seq[CalcitePair[AggregateCall, String]],
+      aggregateInputType: RelDataType,
       inputType: RelDataType,
       inputTypeInfo: TypeInformation[Row],
       inputFieldTypeInfo: Seq[TypeInformation[_]],
@@ -227,7 +231,7 @@ object AggregateUtil {
     val (aggFields, aggregates, accTypes, accSpecs) =
       transformToAggregateFunctions(
         namedAggregates.map(_.getKey),
-        inputType,
+        aggregateInputType,
         needRetract,
         isStateBackedDataViews = true)
 
@@ -827,7 +831,8 @@ object AggregateUtil {
       inputType: RelDataType,
       inputFieldTypeInfo: Seq[TypeInformation[_]],
       outputType: RelDataType,
-      groupings: Array[Int]): (Option[DataSetPreAggFunction],
+      groupings: Array[Int]): (
+        Option[DataSetPreAggFunction],
         Option[TypeInformation[Row]],
         Either[DataSetAggFunction, DataSetFinalAggFunction]) = {
 
@@ -1114,7 +1119,7 @@ object AggregateUtil {
 
   private def transformToAggregateFunctions(
       aggregateCalls: Seq[AggregateCall],
-      inputType: RelDataType,
+      aggregateInputType: RelDataType,
       needRetraction: Boolean,
       isStateBackedDataViews: Boolean = false)
   : (Array[Array[Int]],
@@ -1130,259 +1135,263 @@ object AggregateUtil {
     // create aggregate function instances by function type and aggregate field data type.
     aggregateCalls.zipWithIndex.foreach { case (aggregateCall, index) =>
       val argList: util.List[Integer] = aggregateCall.getArgList
-      if (argList.isEmpty) {
-        if (aggregateCall.getAggregation.isInstanceOf[SqlCountAggFunction]) {
-          aggFieldIndexes(index) = Array[Int](0)
+
+      if (aggregateCall.getAggregation.isInstanceOf[SqlCountAggFunction]) {
+        aggregates(index) = new CountAggFunction
+        if (argList.isEmpty) {
+          aggFieldIndexes(index) = Array[Int](-1)
         } else {
-          throw new TableException("Aggregate fields should not be empty.")
+          aggFieldIndexes(index) = argList.asScala.map(i => i.intValue).toArray
         }
       } else {
-        aggFieldIndexes(index) = argList.asScala.map(i => i.intValue).toArray
-      }
-      val relDataType = inputType.getFieldList.get(aggFieldIndexes(index)(0)).getType
-      val sqlTypeName = relDataType.getSqlTypeName
-      aggregateCall.getAggregation match {
-
-        case _: SqlSumAggFunction =>
-          if (needRetraction) {
-            aggregates(index) = sqlTypeName match {
-              case TINYINT =>
-                new ByteSumWithRetractAggFunction
-              case SMALLINT =>
-                new ShortSumWithRetractAggFunction
-              case INTEGER =>
-                new IntSumWithRetractAggFunction
-              case BIGINT =>
-                new LongSumWithRetractAggFunction
-              case FLOAT =>
-                new FloatSumWithRetractAggFunction
-              case DOUBLE =>
-                new DoubleSumWithRetractAggFunction
-              case DECIMAL =>
-                new DecimalSumWithRetractAggFunction
-              case sqlType: SqlTypeName =>
-                throw new TableException(s"Sum aggregate does no support type: '$sqlType'")
-            }
-          } else {
-            aggregates(index) = sqlTypeName match {
-              case TINYINT =>
-                new ByteSumAggFunction
-              case SMALLINT =>
-                new ShortSumAggFunction
-              case INTEGER =>
-                new IntSumAggFunction
-              case BIGINT =>
-                new LongSumAggFunction
-              case FLOAT =>
-                new FloatSumAggFunction
-              case DOUBLE =>
-                new DoubleSumAggFunction
-              case DECIMAL =>
-                new DecimalSumAggFunction
-              case sqlType: SqlTypeName =>
-                throw new TableException(s"Sum aggregate does no support type: '$sqlType'")
-            }
-          }
-
-        case _: SqlSumEmptyIsZeroAggFunction =>
-          if (needRetraction) {
-            aggregates(index) = sqlTypeName match {
-              case TINYINT =>
-                new ByteSum0WithRetractAggFunction
-              case SMALLINT =>
-                new ShortSum0WithRetractAggFunction
-              case INTEGER =>
-                new IntSum0WithRetractAggFunction
-              case BIGINT =>
-                new LongSum0WithRetractAggFunction
-              case FLOAT =>
-                new FloatSum0WithRetractAggFunction
-              case DOUBLE =>
-                new DoubleSum0WithRetractAggFunction
-              case DECIMAL =>
-                new DecimalSum0WithRetractAggFunction
-              case sqlType: SqlTypeName =>
-                throw new TableException(s"Sum0 aggregate does no support type: '$sqlType'")
-            }
-          } else {
-            aggregates(index) = sqlTypeName match {
-              case TINYINT =>
-                new ByteSum0AggFunction
-              case SMALLINT =>
-                new ShortSum0AggFunction
-              case INTEGER =>
-                new IntSum0AggFunction
-              case BIGINT =>
-                new LongSum0AggFunction
-              case FLOAT =>
-                new FloatSum0AggFunction
-              case DOUBLE =>
-                new DoubleSum0AggFunction
-              case DECIMAL =>
-                new DecimalSum0AggFunction
-              case sqlType: SqlTypeName =>
-                throw new TableException(s"Sum0 aggregate does no support type: '$sqlType'")
-            }
-          }
+        if (argList.isEmpty) {
+          throw new TableException("Aggregate fields should not be empty.")
+        } else {
+          aggFieldIndexes(index) = argList.asScala.map(i => i.intValue).toArray
+        }
 
-        case _: SqlAvgAggFunction =>
-          aggregates(index) = sqlTypeName match {
-            case TINYINT =>
-              new ByteAvgAggFunction
-            case SMALLINT =>
-              new ShortAvgAggFunction
-            case INTEGER =>
-              new IntAvgAggFunction
-            case BIGINT =>
-              new LongAvgAggFunction
-            case FLOAT =>
-              new FloatAvgAggFunction
-            case DOUBLE =>
-              new DoubleAvgAggFunction
-            case DECIMAL =>
-              new DecimalAvgAggFunction
-            case sqlType: SqlTypeName =>
-              throw new TableException(s"Avg aggregate does no support type: '$sqlType'")
-          }
+        val relDataType = aggregateInputType.getFieldList.get(aggFieldIndexes(index)(0)).getType
+        val sqlTypeName = relDataType.getSqlTypeName
+        aggregateCall.getAggregation match {
 
-        case sqlMinMaxFunction: SqlMinMaxAggFunction =>
-          aggregates(index) = if (sqlMinMaxFunction.getKind == SqlKind.MIN) {
+          case _: SqlSumAggFunction =>
             if (needRetraction) {
-              sqlTypeName match {
+              aggregates(index) = sqlTypeName match {
                 case TINYINT =>
-                  new ByteMinWithRetractAggFunction
+                  new ByteSumWithRetractAggFunction
                 case SMALLINT =>
-                  new ShortMinWithRetractAggFunction
+                  new ShortSumWithRetractAggFunction
                 case INTEGER =>
-                  new IntMinWithRetractAggFunction
+                  new IntSumWithRetractAggFunction
                 case BIGINT =>
-                  new LongMinWithRetractAggFunction
+                  new LongSumWithRetractAggFunction
                 case FLOAT =>
-                  new FloatMinWithRetractAggFunction
+                  new FloatSumWithRetractAggFunction
                 case DOUBLE =>
-                  new DoubleMinWithRetractAggFunction
+                  new DoubleSumWithRetractAggFunction
                 case DECIMAL =>
-                  new DecimalMinWithRetractAggFunction
-                case BOOLEAN =>
-                  new BooleanMinWithRetractAggFunction
-                case VARCHAR | CHAR =>
-                  new StringMinWithRetractAggFunction
-                case TIMESTAMP =>
-                  new TimestampMinWithRetractAggFunction
-                case DATE =>
-                  new DateMinWithRetractAggFunction
-                case TIME =>
-                  new TimeMinWithRetractAggFunction
+                  new DecimalSumWithRetractAggFunction
                 case sqlType: SqlTypeName =>
-                  throw new TableException(
-                    s"Min with retract aggregate does no support type: '$sqlType'")
+                  throw new TableException(s"Sum aggregate does no support type: '$sqlType'")
               }
             } else {
-              sqlTypeName match {
+              aggregates(index) = sqlTypeName match {
                 case TINYINT =>
-                  new ByteMinAggFunction
+                  new ByteSumAggFunction
                 case SMALLINT =>
-                  new ShortMinAggFunction
+                  new ShortSumAggFunction
                 case INTEGER =>
-                  new IntMinAggFunction
+                  new IntSumAggFunction
                 case BIGINT =>
-                  new LongMinAggFunction
+                  new LongSumAggFunction
                 case FLOAT =>
-                  new FloatMinAggFunction
+                  new FloatSumAggFunction
                 case DOUBLE =>
-                  new DoubleMinAggFunction
+                  new DoubleSumAggFunction
                 case DECIMAL =>
-                  new DecimalMinAggFunction
-                case BOOLEAN =>
-                  new BooleanMinAggFunction
-                case VARCHAR | CHAR =>
-                  new StringMinAggFunction
-                case TIMESTAMP =>
-                  new TimestampMinAggFunction
-                case DATE =>
-                  new DateMinAggFunction
-                case TIME =>
-                  new TimeMinAggFunction
+                  new DecimalSumAggFunction
                 case sqlType: SqlTypeName =>
-                  throw new TableException(s"Min aggregate does no support type: '$sqlType'")
+                  throw new TableException(s"Sum aggregate does no support type: '$sqlType'")
               }
             }
-          } else {
+
+          case _: SqlSumEmptyIsZeroAggFunction =>
             if (needRetraction) {
-              sqlTypeName match {
+              aggregates(index) = sqlTypeName match {
                 case TINYINT =>
-                  new ByteMaxWithRetractAggFunction
+                  new ByteSum0WithRetractAggFunction
                 case SMALLINT =>
-                  new ShortMaxWithRetractAggFunction
+                  new ShortSum0WithRetractAggFunction
                 case INTEGER =>
-                  new IntMaxWithRetractAggFunction
+                  new IntSum0WithRetractAggFunction
                 case BIGINT =>
-                  new LongMaxWithRetractAggFunction
+                  new LongSum0WithRetractAggFunction
                 case FLOAT =>
-                  new FloatMaxWithRetractAggFunction
+                  new FloatSum0WithRetractAggFunction
                 case DOUBLE =>
-                  new DoubleMaxWithRetractAggFunction
+                  new DoubleSum0WithRetractAggFunction
                 case DECIMAL =>
-                  new DecimalMaxWithRetractAggFunction
-                case BOOLEAN =>
-                  new BooleanMaxWithRetractAggFunction
-                case VARCHAR | CHAR =>
-                  new StringMaxWithRetractAggFunction
-                case TIMESTAMP =>
-                  new TimestampMaxWithRetractAggFunction
-                case DATE =>
-                  new DateMaxWithRetractAggFunction
-                case TIME =>
-                  new TimeMaxWithRetractAggFunction
+                  new DecimalSum0WithRetractAggFunction
                 case sqlType: SqlTypeName =>
-                  throw new TableException(
-                    s"Max with retract aggregate does no support type: '$sqlType'")
+                  throw new TableException(s"Sum0 aggregate does no support type: '$sqlType'")
               }
             } else {
-              sqlTypeName match {
+              aggregates(index) = sqlTypeName match {
                 case TINYINT =>
-                  new ByteMaxAggFunction
+                  new ByteSum0AggFunction
                 case SMALLINT =>
-                  new ShortMaxAggFunction
+                  new ShortSum0AggFunction
                 case INTEGER =>
-                  new IntMaxAggFunction
+                  new IntSum0AggFunction
                 case BIGINT =>
-                  new LongMaxAggFunction
+                  new LongSum0AggFunction
                 case FLOAT =>
-                  new FloatMaxAggFunction
+                  new FloatSum0AggFunction
                 case DOUBLE =>
-                  new DoubleMaxAggFunction
+                  new DoubleSum0AggFunction
                 case DECIMAL =>
-                  new DecimalMaxAggFunction
-                case BOOLEAN =>
-                  new BooleanMaxAggFunction
-                case VARCHAR | CHAR =>
-                  new StringMaxAggFunction
-                case TIMESTAMP =>
-                  new TimestampMaxAggFunction
-                case DATE =>
-                  new DateMaxAggFunction
-                case TIME =>
-                  new TimeMaxAggFunction
+                  new DecimalSum0AggFunction
                 case sqlType: SqlTypeName =>
-                  throw new TableException(s"Max aggregate does no support type: '$sqlType'")
+                  throw new TableException(s"Sum0 aggregate does no support type: '$sqlType'")
               }
             }
-          }
 
-        case _: SqlCountAggFunction =>
-          aggregates(index) = new CountAggFunction
+          case _: SqlAvgAggFunction =>
+            aggregates(index) = sqlTypeName match {
+              case TINYINT =>
+                new ByteAvgAggFunction
+              case SMALLINT =>
+                new ShortAvgAggFunction
+              case INTEGER =>
+                new IntAvgAggFunction
+              case BIGINT =>
+                new LongAvgAggFunction
+              case FLOAT =>
+                new FloatAvgAggFunction
+              case DOUBLE =>
+                new DoubleAvgAggFunction
+              case DECIMAL =>
+                new DecimalAvgAggFunction
+              case sqlType: SqlTypeName =>
+                throw new TableException(s"Avg aggregate does no support type: '$sqlType'")
+            }
+
+          case sqlMinMaxFunction: SqlMinMaxAggFunction =>
+            aggregates(index) = if (sqlMinMaxFunction.getKind == SqlKind.MIN) {
+              if (needRetraction) {
+                sqlTypeName match {
+                  case TINYINT =>
+                    new ByteMinWithRetractAggFunction
+                  case SMALLINT =>
+                    new ShortMinWithRetractAggFunction
+                  case INTEGER =>
+                    new IntMinWithRetractAggFunction
+                  case BIGINT =>
+                    new LongMinWithRetractAggFunction
+                  case FLOAT =>
+                    new FloatMinWithRetractAggFunction
+                  case DOUBLE =>
+                    new DoubleMinWithRetractAggFunction
+                  case DECIMAL =>
+                    new DecimalMinWithRetractAggFunction
+                  case BOOLEAN =>
+                    new BooleanMinWithRetractAggFunction
+                  case VARCHAR | CHAR =>
+                    new StringMinWithRetractAggFunction
+                  case TIMESTAMP =>
+                    new TimestampMinWithRetractAggFunction
+                  case DATE =>
+                    new DateMinWithRetractAggFunction
+                  case TIME =>
+                    new TimeMinWithRetractAggFunction
+                  case sqlType: SqlTypeName =>
+                    throw new TableException(
+                      s"Min with retract aggregate does no support type: '$sqlType'")
+                }
+              } else {
+                sqlTypeName match {
+                  case TINYINT =>
+                    new ByteMinAggFunction
+                  case SMALLINT =>
+                    new ShortMinAggFunction
+                  case INTEGER =>
+                    new IntMinAggFunction
+                  case BIGINT =>
+                    new LongMinAggFunction
+                  case FLOAT =>
+                    new FloatMinAggFunction
+                  case DOUBLE =>
+                    new DoubleMinAggFunction
+                  case DECIMAL =>
+                    new DecimalMinAggFunction
+                  case BOOLEAN =>
+                    new BooleanMinAggFunction
+                  case VARCHAR | CHAR =>
+                    new StringMinAggFunction
+                  case TIMESTAMP =>
+                    new TimestampMinAggFunction
+                  case DATE =>
+                    new DateMinAggFunction
+                  case TIME =>
+                    new TimeMinAggFunction
+                  case sqlType: SqlTypeName =>
+                    throw new TableException(s"Min aggregate does no support type: '$sqlType'")
+                }
+              }
+            } else {
+              if (needRetraction) {
+                sqlTypeName match {
+                  case TINYINT =>
+                    new ByteMaxWithRetractAggFunction
+                  case SMALLINT =>
+                    new ShortMaxWithRetractAggFunction
+                  case INTEGER =>
+                    new IntMaxWithRetractAggFunction
+                  case BIGINT =>
+                    new LongMaxWithRetractAggFunction
+                  case FLOAT =>
+                    new FloatMaxWithRetractAggFunction
+                  case DOUBLE =>
+                    new DoubleMaxWithRetractAggFunction
+                  case DECIMAL =>
+                    new DecimalMaxWithRetractAggFunction
+                  case BOOLEAN =>
+                    new BooleanMaxWithRetractAggFunction
+                  case VARCHAR | CHAR =>
+                    new StringMaxWithRetractAggFunction
+                  case TIMESTAMP =>
+                    new TimestampMaxWithRetractAggFunction
+                  case DATE =>
+                    new DateMaxWithRetractAggFunction
+                  case TIME =>
+                    new TimeMaxWithRetractAggFunction
+                  case sqlType: SqlTypeName =>
+                    throw new TableException(
+                      s"Max with retract aggregate does no support type: '$sqlType'")
+                }
+              } else {
+                sqlTypeName match {
+                  case TINYINT =>
+                    new ByteMaxAggFunction
+                  case SMALLINT =>
+                    new ShortMaxAggFunction
+                  case INTEGER =>
+                    new IntMaxAggFunction
+                  case BIGINT =>
+                    new LongMaxAggFunction
+                  case FLOAT =>
+                    new FloatMaxAggFunction
+                  case DOUBLE =>
+                    new DoubleMaxAggFunction
+                  case DECIMAL =>
+                    new DecimalMaxAggFunction
+                  case BOOLEAN =>
+                    new BooleanMaxAggFunction
+                  case VARCHAR | CHAR =>
+                    new StringMaxAggFunction
+                  case TIMESTAMP =>
+                    new TimestampMaxAggFunction
+                  case DATE =>
+                    new DateMaxAggFunction
+                  case TIME =>
+                    new TimeMaxAggFunction
+                  case sqlType: SqlTypeName =>
+                    throw new TableException(s"Max aggregate does no support type: '$sqlType'")
+                }
+              }
+            }
 
-        case collect: SqlAggFunction if collect.getKind == SqlKind.COLLECT =>
-          aggregates(index) = new CollectAggFunction(FlinkTypeFactory.toTypeInfo(relDataType))
-          accTypes(index) = aggregates(index).getAccumulatorType
+          case collect: SqlAggFunction if collect.getKind == SqlKind.COLLECT =>
+            aggregates(index) = new CollectAggFunction(FlinkTypeFactory.toTypeInfo(relDataType))
+            accTypes(index) = aggregates(index).getAccumulatorType
 
-        case udagg: AggSqlFunction =>
-          aggregates(index) = udagg.getFunction
-          accTypes(index) = udagg.accType
+          case udagg: AggSqlFunction =>
+            aggregates(index) = udagg.getFunction
+            accTypes(index) = udagg.accType
 
-        case unSupported: SqlAggFunction =>
-          throw new TableException(s"unsupported Function: '${unSupported.getName}'")
+          case unSupported: SqlAggFunction =>
+            throw new TableException(s"unsupported Function: '${unSupported.getName}'")
+        }
       }
     }
 
diff --git a/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/aggfunctions/CountAggFunctionTest.scala b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/aggfunctions/CountAggFunctionTest.scala
index 87aaff9f143..867435ba9a3 100644
--- a/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/aggfunctions/CountAggFunctionTest.scala
+++ b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/aggfunctions/CountAggFunctionTest.scala
@@ -35,7 +35,7 @@ class CountAggFunctionTest extends AggFunctionTestBase[JLong, CountAccumulator]
 
   override def expectedResults: Seq[JLong] = Seq(6L, 0L)
 
-  override def aggregator: AggregateFunction[JLong, CountAccumulator] = new CountAggFunction()
+  override def aggregator: AggregateFunction[JLong, CountAccumulator] = new CountAggFunction
 
   override def retractFunc = aggregator.getClass.getMethod("retract", accType, classOf[Any])
 }
diff --git a/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/aggfunctions/CountAggFunctionWithNonParamTest.scala b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/aggfunctions/CountAggFunctionWithNonParamTest.scala
new file mode 100644
index 00000000000..da98c57abf9
--- /dev/null
+++ b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/aggfunctions/CountAggFunctionWithNonParamTest.scala
@@ -0,0 +1,44 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.table.runtime.aggfunctions
+
+import java.lang.reflect.Method
+import java.lang.{Long => JLong}
+
+import org.apache.flink.table.functions.AggregateFunction
+import org.apache.flink.table.functions.aggfunctions.{CountAccumulator, CountAggFunction}
+
+/**
+  * Test case for built-in count aggregate function with non-nullable parameter.
+  */
+class CountAggFunctionWithNonParamTest extends AggFunctionTestBase[JLong, CountAccumulator] {
+
+  override def inputValueSets: Seq[Seq[_]] = Seq(
+    Seq("a", "b", null, "c", null, "d", "e", null, "f"),
+    Seq(null, null, null, null, null, null)
+  )
+
+  override def expectedResults: Seq[JLong] = Seq(9L, 6L)
+
+  override def aggregator: AggregateFunction[JLong, CountAccumulator] = new CountAggFunction
+
+  override def retractFunc = aggregator.getClass.getMethod("retract", accType)
+
+  override def accumulateFunc: Method = aggregator.getClass.getMethod("accumulate", accType)
+}
diff --git a/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/stream/sql/OverWindowITCase.scala b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/stream/sql/OverWindowITCase.scala
index 9bfdc4cac2f..411cbb1961a 100644
--- a/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/stream/sql/OverWindowITCase.scala
+++ b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/stream/sql/OverWindowITCase.scala
@@ -152,7 +152,8 @@ class OverWindowITCase extends StreamingWithStateTestBase {
     val sqlQuery = "SELECT " +
       "c, " +
       "count(a) OVER (PARTITION BY c ORDER BY proctime RANGE UNBOUNDED preceding), " +
-      "sum(a) OVER (PARTITION BY c ORDER BY proctime RANGE UNBOUNDED preceding) " +
+      "sum(a) OVER (PARTITION BY c ORDER BY proctime RANGE UNBOUNDED preceding), " +
+      "sum(2) OVER (PARTITION BY c ORDER BY proctime RANGE UNBOUNDED preceding) " +
       "from T1"
 
     val result = tEnv.sqlQuery(sqlQuery).toAppendStream[Row]
@@ -160,8 +161,8 @@ class OverWindowITCase extends StreamingWithStateTestBase {
     env.execute()
 
     val expected = List(
-      "Hello World,1,7", "Hello World,2,15", "Hello World,3,35",
-      "Hello,1,1", "Hello,2,3", "Hello,3,6", "Hello,4,10", "Hello,5,15", "Hello,6,21")
+      "Hello World,1,7,2", "Hello World,2,15,4", "Hello World,3,35,6",
+      "Hello,1,1,2", "Hello,2,3,4", "Hello,3,6,6", "Hello,4,10,8", "Hello,5,15,10", "Hello,6,21,12")
     assertEquals(expected.sorted, StreamITCase.testResults.sorted)
   }
 
@@ -179,7 +180,7 @@ class OverWindowITCase extends StreamingWithStateTestBase {
     val sqlQuery = "SELECT c, cnt1 from " +
       "(SELECT " +
       "c, " +
-      "count(a) " +
+      "count(1) " +
       " OVER (PARTITION BY c ORDER BY proctime ROWS BETWEEN UNBOUNDED preceding AND CURRENT ROW) " +
       "as cnt1 from T1)"
 
@@ -366,7 +367,7 @@ class OverWindowITCase extends StreamingWithStateTestBase {
       " c, a, " +
       "  LTCNT(a, CAST('4' AS BIGINT)) " +
       "    OVER (PARTITION BY c ORDER BY rowtime ROWS BETWEEN 2 PRECEDING AND CURRENT ROW), " +
-      "  COUNT(a) " +
+      "  COUNT(1) " +
       "    OVER (PARTITION BY c ORDER BY rowtime ROWS BETWEEN 2 PRECEDING AND CURRENT ROW), " +
       "  SUM(a) " +
       "    OVER (PARTITION BY c ORDER BY rowtime ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) " +
diff --git a/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/stream/sql/SqlITCase.scala b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/stream/sql/SqlITCase.scala
index 76d01262ac3..0633b712837 100644
--- a/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/stream/sql/SqlITCase.scala
+++ b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/runtime/stream/sql/SqlITCase.scala
@@ -22,21 +22,90 @@ import org.apache.flink.api.common.typeinfo.{BasicTypeInfo, TypeInformation}
 import org.apache.flink.api.java.typeutils.RowTypeInfo
 import org.apache.flink.api.scala._
 import org.apache.flink.streaming.api.TimeCharacteristic
+import org.apache.flink.streaming.api.functions.AssignerWithPunctuatedWatermarks
 import org.apache.flink.streaming.api.scala.StreamExecutionEnvironment
+import org.apache.flink.streaming.api.watermark.Watermark
 import org.apache.flink.table.api.{TableEnvironment, Types}
 import org.apache.flink.table.api.scala._
 import org.apache.flink.table.expressions.utils.SplitUDF
 import org.apache.flink.table.expressions.utils.Func15
+import org.apache.flink.table.runtime.stream.sql.SqlITCase.TimestampAndWatermarkWithOffset
 import org.apache.flink.table.runtime.utils.TimeTestUtil.EventTimeSourceFunction
 import org.apache.flink.table.runtime.utils.{StreamITCase, StreamTestData, StreamingWithStateTestBase}
 import org.apache.flink.types.Row
 import org.apache.flink.table.utils.MemoryTableSinkUtil
-
 import org.junit.Assert._
 import org.junit._
 
+import scala.collection.mutable
+
 class SqlITCase extends StreamingWithStateTestBase {
 
+  val data = List(
+    (1000L, "1", "Hello"),
+    (2000L, "2", "Hello"),
+    (3000L, null.asInstanceOf[String], "Hello"),
+    (4000L, "4", "Hello"),
+    (5000L, null.asInstanceOf[String], "Hello"),
+    (6000L, "6", "Hello"),
+    (7000L, "7", "Hello World"),
+    (8000L, "8", "Hello World"),
+    (20000L, "20", "Hello World"))
+
+  @Test
+  def testRowTimeTumbleWindow(): Unit = {
+
+    val env = StreamExecutionEnvironment.getExecutionEnvironment
+    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
+    val tEnv = TableEnvironment.getTableEnvironment(env)
+    StreamITCase.testResults = mutable.MutableList()
+    StreamITCase.clear
+    env.setParallelism(1)
+
+    val stream = env
+                 .fromCollection(data)
+                 .assignTimestampsAndWatermarks(
+                   new TimestampAndWatermarkWithOffset[(Long, String, String)](0L))
+    val table = stream.toTable(tEnv, 'a, 'b, 'c, 'rowtime.rowtime)
+
+    tEnv.registerTable("T1", table)
+
+    val sqlQuery = "SELECT c, COUNT(*), COUNT(1), COUNT(b) FROM T1 " +
+      "GROUP BY TUMBLE(rowtime, interval '5' SECOND), c"
+
+    val result = tEnv.sqlQuery(sqlQuery).toAppendStream[Row]
+    result.addSink(new StreamITCase.StringSink[Row])
+    env.execute()
+
+    val expected = List("Hello World,2,2,2", "Hello World,1,1,1", "Hello,4,4,3", "Hello,2,2,1")
+    assertEquals(expected.sorted, StreamITCase.testResults.sorted)
+  }
+
+  @Test
+  def testNonWindowedCount(): Unit = {
+
+    val env = StreamExecutionEnvironment.getExecutionEnvironment
+    val tEnv = TableEnvironment.getTableEnvironment(env)
+    StreamITCase.retractedResults = mutable.ArrayBuffer()
+    StreamITCase.clear
+
+    env.setParallelism(1)
+
+    val stream = env.fromCollection(data)
+    val table = stream.toTable(tEnv, 'a, 'b, 'c)
+
+    tEnv.registerTable("T1", table)
+
+    val sqlQuery = "SELECT c, COUNT(*), COUNT(1), COUNT(b) FROM T1 GROUP BY c"
+
+    val result = tEnv.sqlQuery(sqlQuery).toRetractStream[Row]
+    result.addSink(new StreamITCase.RetractingSink)
+    env.execute()
+
+    val expected = List("Hello World,3,3,3", "Hello,6,6,4")
+    assertEquals(expected.sorted, StreamITCase.retractedResults.sorted)
+  }
+
    /** test row stream registered table **/
   @Test
   def testRowRegister(): Unit = {
@@ -544,3 +613,23 @@ class SqlITCase extends StreamingWithStateTestBase {
     assertEquals(expected.sorted, StreamITCase.testResults.sorted)
   }
 }
+
+object SqlITCase {
+
+  class TimestampAndWatermarkWithOffset[T <: Product](
+      offset: Long) extends AssignerWithPunctuatedWatermarks[T] {
+
+    override def checkAndGetNextWatermark(
+        lastElement: T,
+        extractedTimestamp: Long): Watermark = {
+      new Watermark(extractedTimestamp - offset)
+    }
+
+    override def extractTimestamp(
+        element: T,
+        previousElementTimestamp: Long): Long = {
+      element.productElement(0).asInstanceOf[Long]
+    }
+  }
+
+}
