diff --git a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/conversion/HiveInspectors.java b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/conversion/HiveInspectors.java
index 4cdf7a88d6a..8169175dccd 100644
--- a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/conversion/HiveInspectors.java
+++ b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/conversion/HiveInspectors.java
@@ -314,6 +314,9 @@ public class HiveInspectors {
         if (inspector instanceof ListObjectInspector) {
             ListObjectInspector listInspector = (ListObjectInspector) inspector;
             List<?> list = listInspector.getList(data);
+            if (list == null) {
+                return null;
+            }
 
             // flink expects a specific array type (e.g. Integer[] instead of Object[]), so we have
             // to get the element class
@@ -332,6 +335,9 @@ public class HiveInspectors {
         if (inspector instanceof MapObjectInspector) {
             MapObjectInspector mapInspector = (MapObjectInspector) inspector;
             Map<?, ?> map = mapInspector.getMap(data);
+            if (map == null) {
+                return null;
+            }
 
             Map<Object, Object> result = new HashMap<>(map.size());
             for (Map.Entry<?, ?> entry : map.entrySet()) {
diff --git a/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/TableEnvHiveConnectorITCase.java b/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/TableEnvHiveConnectorITCase.java
index 9af50b44ddf..28c3559fe26 100644
--- a/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/TableEnvHiveConnectorITCase.java
+++ b/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/TableEnvHiveConnectorITCase.java
@@ -531,6 +531,32 @@ public class TableEnvHiveConnectorITCase {
         }
     }
 
+    @Test
+    public void testReadEmptyCollectionFromParquet() throws Exception {
+        Assume.assumeTrue(HiveShimLoader.getHiveVersion().equals("2.0.0"));
+        TableEnvironment tableEnv = getTableEnvWithHiveCatalog();
+        try {
+            String format = "parquet";
+            // test.parquet data: hehuiyuan	{}	[]
+            String folderURI = this.getClass().getResource("/parquet").getPath();
+
+            tableEnv.getConfig()
+                    .getConfiguration()
+                    .set(HiveOptions.TABLE_EXEC_HIVE_FALLBACK_MAPRED_READER, true);
+            tableEnv.executeSql(
+                    String.format(
+                            "create external table src_t (a string, b map<string, string>, c array<string>) stored as %s location 'file://%s'",
+                            format, folderURI));
+
+            List<Row> results =
+                    CollectionUtil.iteratorToList(
+                            tableEnv.sqlQuery("select * from src_t").execute().collect());
+            assertEquals("[+I[hehuiyuan, null, null]]", results.toString());
+        } finally {
+            tableEnv.executeSql("drop table if exists src_t");
+        }
+    }
+
     private TableEnvironment getTableEnvWithHiveCatalog() {
         TableEnvironment tableEnv =
                 HiveTestUtils.createTableEnvWithBlinkPlannerBatchMode(SqlDialect.HIVE);
diff --git a/flink-connectors/flink-connector-hive/src/test/resources/parquet/test.parquet b/flink-connectors/flink-connector-hive/src/test/resources/parquet/test.parquet
new file mode 100644
index 00000000000..deb0067b117
Binary files /dev/null and b/flink-connectors/flink-connector-hive/src/test/resources/parquet/test.parquet differ
