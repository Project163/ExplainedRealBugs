diff --git a/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/ExecutionContext.java b/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/ExecutionContext.java
index afac3d83374..26f53220aa7 100644
--- a/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/ExecutionContext.java
+++ b/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/ExecutionContext.java
@@ -232,6 +232,15 @@ public class ExecutionContext<ClusterID> {
 		}
 	}
 
+	/**
+	 * Executes the given Runnable using the execution context's classloader as thread classloader.
+	 */
+	void wrapClassLoader(Runnable runnable) {
+		try (TemporaryClassLoaderContext tmpCl = new TemporaryClassLoaderContext(classLoader)){
+			runnable.run();
+		}
+	}
+
 	public QueryConfig getQueryConfig() {
 		if (streamExecEnv != null) {
 			final StreamQueryConfig config = new StreamQueryConfig();
@@ -523,12 +532,12 @@ public class ExecutionContext<ClusterID> {
 		//--------------------------------------------------------------------------------------------------------------
 		// Step.1 Create catalogs and register them.
 		//--------------------------------------------------------------------------------------------------------------
-		Map<String, Catalog> catalogs = new LinkedHashMap<>();
-		environment.getCatalogs().forEach((name, entry) ->
-				catalogs.put(name, createCatalog(name, entry.asMap(), classLoader))
-		);
-		// register catalogs
-		catalogs.forEach(tableEnv::registerCatalog);
+		wrapClassLoader(() -> {
+			environment.getCatalogs().forEach((name, entry) -> {
+				Catalog catalog = createCatalog(name, entry.asMap(), classLoader);
+				tableEnv.registerCatalog(name, catalog);
+			});
+		});
 
 		//--------------------------------------------------------------------------------------------------------------
 		// Step.2 create table sources & sinks, and register them.
diff --git a/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/LocalExecutor.java b/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/LocalExecutor.java
index 1174b09afbf..573aeaea70f 100644
--- a/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/LocalExecutor.java
+++ b/flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/gateway/local/LocalExecutor.java
@@ -410,7 +410,6 @@ public class LocalExecutor implements Executor {
 			} catch (CatalogException e) {
 				throw new SqlExecutionException("Failed to switch to catalog " + catalogName, e);
 			}
-			return null;
 		});
 	}
 
@@ -426,7 +425,6 @@ public class LocalExecutor implements Executor {
 			} catch (CatalogException e) {
 				throw new SqlExecutionException("Failed to switch to database " + databaseName, e);
 			}
-			return null;
 		});
 	}
 
@@ -629,7 +627,6 @@ public class LocalExecutor implements Executor {
 				table.insertInto(
 						context.getQueryConfig(),
 						tableName);
-				return null;
 			});
 			pipeline = context.createPipeline(jobName, context.getFlinkConfig());
 		} catch (Throwable t) {
@@ -642,7 +639,6 @@ public class LocalExecutor implements Executor {
 			// Remove the temporal table object.
 			context.wrapClassLoader(() -> {
 				context.getTableEnvironment().dropTemporaryTable(tableName);
-				return null;
 			});
 		}
 
@@ -695,7 +691,6 @@ public class LocalExecutor implements Executor {
 				} else {
 					tableEnv.sqlUpdate(updateStatement);
 				}
-				return null;
 			});
 		} catch (Throwable t) {
 			// catch everything such that the statement does not crash the executor
diff --git a/flink-table/flink-sql-client/src/test/java/org/apache/flink/table/client/gateway/local/ExecutionContextTest.java b/flink-table/flink-sql-client/src/test/java/org/apache/flink/table/client/gateway/local/ExecutionContextTest.java
index 85883f19217..3aacc5c3912 100644
--- a/flink-table/flink-sql-client/src/test/java/org/apache/flink/table/client/gateway/local/ExecutionContextTest.java
+++ b/flink-table/flink-sql-client/src/test/java/org/apache/flink/table/client/gateway/local/ExecutionContextTest.java
@@ -23,25 +23,31 @@ import org.apache.flink.api.common.restartstrategy.RestartStrategies;
 import org.apache.flink.client.cli.DefaultCLI;
 import org.apache.flink.client.deployment.DefaultClusterClientServiceLoader;
 import org.apache.flink.configuration.Configuration;
+import org.apache.flink.runtime.execution.librarycache.FlinkUserCodeClassLoaders;
 import org.apache.flink.table.api.TableEnvironment;
 import org.apache.flink.table.api.config.ExecutionConfigOptions;
 import org.apache.flink.table.api.config.OptimizerConfigOptions;
 import org.apache.flink.table.api.java.StreamTableEnvironment;
 import org.apache.flink.table.catalog.Catalog;
+import org.apache.flink.table.catalog.GenericInMemoryCatalog;
 import org.apache.flink.table.catalog.hive.HiveCatalog;
 import org.apache.flink.table.client.config.Environment;
+import org.apache.flink.table.client.config.entries.CatalogEntry;
 import org.apache.flink.table.client.gateway.SessionContext;
 import org.apache.flink.table.client.gateway.utils.DummyTableSourceFactory;
 import org.apache.flink.table.client.gateway.utils.EnvironmentFileUtil;
+import org.apache.flink.table.factories.CatalogFactory;
 import org.apache.flink.util.StringUtils;
 
 import org.apache.commons.cli.Options;
 import org.junit.Test;
 
+import java.net.URL;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
+import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
@@ -244,6 +250,26 @@ public class ExecutionContextTest {
 				OptimizerConfigOptions.TABLE_OPTIMIZER_BROADCAST_JOIN_THRESHOLD));
 	}
 
+	@Test
+	public void testInitCatalogs() throws Exception{
+		final Map<String, String> replaceVars = createDefaultReplaceVars();
+		Environment env = EnvironmentFileUtil.parseModified(DEFAULTS_ENVIRONMENT_FILE, replaceVars);
+
+		Map<String, Object> catalogProps = new HashMap<>();
+		catalogProps.put("name", "test");
+		catalogProps.put("type", "test_cl_catalog");
+		env.getCatalogs().clear();
+		env.getCatalogs().put("test", CatalogEntry.create(catalogProps));
+		Configuration flinkConfig = new Configuration();
+		ExecutionContext.builder(env,
+				new SessionContext("test-session", new Environment()),
+				Collections.emptyList(),
+				flinkConfig,
+				new DefaultClusterClientServiceLoader(),
+				new Options(),
+				Collections.singletonList(new DefaultCLI(flinkConfig))).build();
+	}
+
 	@SuppressWarnings("unchecked")
 	private <T> ExecutionContext<T> createExecutionContext(String file, Map<String, String> replaceVars) throws Exception {
 		final Environment env = EnvironmentFileUtil.parseModified(
@@ -261,14 +287,19 @@ public class ExecutionContextTest {
 				.build();
 	}
 
-	private <T> ExecutionContext<T> createDefaultExecutionContext() throws Exception {
-		final Map<String, String> replaceVars = new HashMap<>();
+	private Map<String, String> createDefaultReplaceVars() {
+		Map<String, String> replaceVars = new HashMap<>();
 		replaceVars.put("$VAR_PLANNER", "old");
 		replaceVars.put("$VAR_EXECUTION_TYPE", "streaming");
 		replaceVars.put("$VAR_RESULT_MODE", "changelog");
 		replaceVars.put("$VAR_UPDATE_MODE", "update-mode: append");
 		replaceVars.put("$VAR_MAX_ROWS", "100");
 		replaceVars.put("$VAR_RESTART_STRATEGY_TYPE", "failure-rate");
+		return replaceVars;
+	}
+
+	private <T> ExecutionContext<T> createDefaultExecutionContext() throws Exception {
+		final Map<String, String> replaceVars = createDefaultReplaceVars();
 		return createExecutionContext(DEFAULTS_ENVIRONMENT_FILE, replaceVars);
 	}
 
@@ -303,4 +334,52 @@ public class ExecutionContextTest {
 	private <T> ExecutionContext<T> createConfigurationExecutionContext() throws Exception {
 		return createExecutionContext(CONFIGURATION_ENVIRONMENT_FILE, new HashMap<>());
 	}
+
+	// a catalog that requires the thread context class loader to be a user code classloader during construction and opening
+	private static class TestClassLoaderCatalog extends GenericInMemoryCatalog {
+
+		private static final Class parentFirstCL = FlinkUserCodeClassLoaders.parentFirst(
+				new URL[0], TestClassLoaderCatalog.class.getClassLoader()).getClass();
+		private static final Class childFirstCL = FlinkUserCodeClassLoaders.childFirst(
+				new URL[0], TestClassLoaderCatalog.class.getClassLoader(), new String[0]).getClass();
+
+		TestClassLoaderCatalog(String name) {
+			super(name);
+			verifyUserClassLoader();
+		}
+
+		@Override
+		public void open() {
+			verifyUserClassLoader();
+			super.open();
+		}
+
+		private void verifyUserClassLoader() {
+			ClassLoader contextLoader = Thread.currentThread().getContextClassLoader();
+			assertTrue(parentFirstCL.isInstance(contextLoader) || childFirstCL.isInstance(contextLoader));
+		}
+	}
+
+	/**
+	 * Factory to create TestClassLoaderCatalog.
+	 */
+	public static class TestClassLoaderCatalogFactory implements CatalogFactory {
+
+		@Override
+		public Catalog createCatalog(String name, Map<String, String> properties) {
+			return new TestClassLoaderCatalog("test_cl");
+		}
+
+		@Override
+		public Map<String, String> requiredContext() {
+			Map<String, String> context = new HashMap<>();
+			context.put("type", "test_cl_catalog");
+			return context;
+		}
+
+		@Override
+		public List<String> supportedProperties() {
+			return Collections.emptyList();
+		}
+	}
 }
diff --git a/flink-table/flink-sql-client/src/test/resources/META-INF/services/org.apache.flink.table.factories.TableFactory b/flink-table/flink-sql-client/src/test/resources/META-INF/services/org.apache.flink.table.factories.TableFactory
index 0b5ae7b26f9..08de07d065d 100644
--- a/flink-table/flink-sql-client/src/test/resources/META-INF/services/org.apache.flink.table.factories.TableFactory
+++ b/flink-table/flink-sql-client/src/test/resources/META-INF/services/org.apache.flink.table.factories.TableFactory
@@ -19,3 +19,4 @@ org.apache.flink.table.client.gateway.utils.SimpleCatalogFactory
 org.apache.flink.table.client.gateway.local.DependencyTest$TestCatalogFactory
 org.apache.flink.table.client.gateway.local.DependencyTest$TestHiveCatalogFactory
 org.apache.flink.table.client.gateway.local.DependencyTest$TestModuleFactory
+org.apache.flink.table.client.gateway.local.ExecutionContextTest$TestClassLoaderCatalogFactory
