diff --git a/flink-core/src/test/java/org/apache/flink/core/fs/FileSystemBehaviorTestSuite.java b/flink-core/src/test/java/org/apache/flink/core/fs/FileSystemBehaviorTestSuite.java
index 566c7b247e8..44ead702584 100644
--- a/flink-core/src/test/java/org/apache/flink/core/fs/FileSystemBehaviorTestSuite.java
+++ b/flink-core/src/test/java/org/apache/flink/core/fs/FileSystemBehaviorTestSuite.java
@@ -30,6 +30,8 @@ import java.io.IOException;
 import java.util.Random;
 
 import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertThrows;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
@@ -97,6 +99,92 @@ public abstract class FileSystemBehaviorTestSuite {
         assertEquals(fs.getUri().getScheme(), fs.getWorkingDirectory().toUri().getScheme());
         assertEquals(fs.getUri().getScheme(), fs.getHomeDirectory().toUri().getScheme());
     }
+    // --- exists
+
+    @Test
+    public void testFileExists() throws IOException {
+        final Path filePath = createRandomFileInDirectory(basePath);
+        assertTrue(fs.exists(filePath));
+    }
+
+    @Test
+    public void testFileDoesNotExist() throws IOException {
+        assertFalse(fs.exists(new Path(basePath, randomName())));
+    }
+
+    // --- delete
+
+    @Test
+    public void testExistingFileDeletion() throws IOException {
+        testSuccessfulDeletion(createRandomFileInDirectory(basePath), false);
+    }
+
+    @Test
+    public void testExistingFileRecursiveDeletion() throws IOException {
+        testSuccessfulDeletion(createRandomFileInDirectory(basePath), true);
+    }
+
+    @Test
+    public void testNotExistingFileDeletion() throws IOException {
+        testSuccessfulDeletion(new Path(basePath, randomName()), false);
+    }
+
+    @Test
+    public void testNotExistingFileRecursiveDeletion() throws IOException {
+        testSuccessfulDeletion(new Path(basePath, randomName()), true);
+    }
+
+    @Test
+    public void testExistingEmptyDirectoryDeletion() throws IOException {
+        final Path path = new Path(basePath, randomName());
+        fs.mkdirs(path);
+        testSuccessfulDeletion(path, false);
+    }
+
+    @Test
+    public void testExistingEmptyDirectoryRecursiveDeletion() throws IOException {
+        final Path path = new Path(basePath, randomName());
+        fs.mkdirs(path);
+        testSuccessfulDeletion(path, true);
+    }
+
+    private void testSuccessfulDeletion(Path path, boolean recursionEnabled) throws IOException {
+        fs.delete(path, recursionEnabled);
+        assertFalse(fs.exists(path));
+    }
+
+    @Test
+    public void testExistingNonEmptyDirectoryDeletion() throws IOException {
+        final Path directoryPath = new Path(basePath, randomName());
+        final Path filePath = createRandomFileInDirectory(directoryPath);
+
+        assertThrows(IOException.class, () -> fs.delete(directoryPath, false));
+        assertTrue(fs.exists(directoryPath));
+        assertTrue(fs.exists(filePath));
+    }
+
+    @Test
+    public void testExistingNonEmptyDirectoryRecursiveDeletion() throws IOException {
+        final Path directoryPath = new Path(basePath, randomName());
+        final Path filePath = createRandomFileInDirectory(directoryPath);
+
+        fs.delete(directoryPath, true);
+        assertFalse(fs.exists(directoryPath));
+        assertFalse(fs.exists(filePath));
+    }
+
+    @Test
+    public void testExistingNonEmptyDirectoryWithSubDirRecursiveDeletion() throws IOException {
+        final Path level1SubDirWithFile = new Path(basePath, randomName());
+        final Path fileInLevel1Subdir = createRandomFileInDirectory(level1SubDirWithFile);
+        final Path level2SubDirWithFile = new Path(level1SubDirWithFile, randomName());
+        final Path fileInLevel2Subdir = createRandomFileInDirectory(level2SubDirWithFile);
+
+        testSuccessfulDeletion(level1SubDirWithFile, true);
+        assertFalse(fs.exists(fileInLevel1Subdir));
+        assertFalse(fs.exists(level2SubDirWithFile));
+        assertFalse(fs.exists(fileInLevel2Subdir));
+    }
 
     // --- mkdirs
 
@@ -189,9 +277,12 @@ public abstract class FileSystemBehaviorTestSuite {
         }
     }
 
-    private void createRandomFileInDirectory(Path directory) throws IOException {
+    private Path createRandomFileInDirectory(Path directory) throws IOException {
         fs.mkdirs(directory);
-        createFile(new Path(directory, randomName()));
+        final Path filePath = new Path(directory, randomName());
+        createFile(filePath);
+
+        return filePath;
     }
 
     private void assumeNotObjectStore() {
diff --git a/flink-filesystems/flink-s3-fs-base/src/main/java/org/apache/flink/fs/s3/common/AbstractS3FileSystemFactory.java b/flink-filesystems/flink-s3-fs-base/src/main/java/org/apache/flink/fs/s3/common/AbstractS3FileSystemFactory.java
index 4818433a81e..024abbdc12d 100644
--- a/flink-filesystems/flink-s3-fs-base/src/main/java/org/apache/flink/fs/s3/common/AbstractS3FileSystemFactory.java
+++ b/flink-filesystems/flink-s3-fs-base/src/main/java/org/apache/flink/fs/s3/common/AbstractS3FileSystemFactory.java
@@ -152,7 +152,7 @@ public abstract class AbstractS3FileSystemFactory implements FileSystemFactory {
             final int maxConcurrentUploads = flinkConfig.getInteger(MAX_CONCURRENT_UPLOADS);
             final S3AccessHelper s3AccessHelper = getS3AccessHelper(fs);
 
-            return new FlinkS3FileSystem(
+            return createFlinkFileSystem(
                     fs,
                     localTmpDirectory,
                     entropyInjectionKey,
@@ -167,6 +167,24 @@ public abstract class AbstractS3FileSystemFactory implements FileSystemFactory {
         }
     }
 
+    protected FileSystem createFlinkFileSystem(
+            org.apache.hadoop.fs.FileSystem fs,
+            String localTmpDirectory,
+            String entropyInjectionKey,
+            int numEntropyChars,
+            S3AccessHelper s3AccessHelper,
+            long s3minPartSize,
+            int maxConcurrentUploads) {
+        return new FlinkS3FileSystem(
+                fs,
+                localTmpDirectory,
+                entropyInjectionKey,
+                numEntropyChars,
+                s3AccessHelper,
+                s3minPartSize,
+                maxConcurrentUploads);
+    }
+
     protected abstract org.apache.hadoop.fs.FileSystem createHadoopFileSystem();
 
     protected abstract URI getInitURI(URI fsUri, org.apache.hadoop.conf.Configuration hadoopConfig);
diff --git a/flink-filesystems/flink-s3-fs-presto/src/main/java/org/apache/flink/fs/s3presto/FlinkS3PrestoFileSystem.java b/flink-filesystems/flink-s3-fs-presto/src/main/java/org/apache/flink/fs/s3presto/FlinkS3PrestoFileSystem.java
new file mode 100644
index 00000000000..c5f2c859af8
--- /dev/null
+++ b/flink-filesystems/flink-s3-fs-presto/src/main/java/org/apache/flink/fs/s3presto/FlinkS3PrestoFileSystem.java
@@ -0,0 +1,140 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.fs.s3presto;
+
+import org.apache.flink.core.fs.FileStatus;
+import org.apache.flink.core.fs.Path;
+import org.apache.flink.fs.s3.common.FlinkS3FileSystem;
+import org.apache.flink.fs.s3.common.writer.S3AccessHelper;
+import org.apache.flink.util.ExceptionUtils;
+import org.apache.flink.util.Preconditions;
+
+import org.apache.hadoop.fs.FileSystem;
+
+import javax.annotation.Nullable;
+
+import java.io.IOException;
+import java.util.Optional;
+
+/**
+ * {@code FlinkS3PrestoFileSystem} provides custom recursive deletion functionality to work around a
+ * bug in the internally used Presto file system.
+ *
+ * <p>https://github.com/prestodb/presto/issues/17416
+ */
+public class FlinkS3PrestoFileSystem extends FlinkS3FileSystem {
+
+    public FlinkS3PrestoFileSystem(
+            FileSystem hadoopS3FileSystem,
+            String localTmpDirectory,
+            @Nullable String entropyInjectionKey,
+            int entropyLength,
+            @Nullable S3AccessHelper s3UploadHelper,
+            long s3uploadPartSize,
+            int maxConcurrentUploadsPerStream) {
+        super(
+                hadoopS3FileSystem,
+                localTmpDirectory,
+                entropyInjectionKey,
+                entropyLength,
+                s3UploadHelper,
+                s3uploadPartSize,
+                maxConcurrentUploadsPerStream);
+    }
+
+    @Override
+    public boolean delete(Path path, boolean recursive) throws IOException {
+        if (recursive) {
+            deleteRecursively(path);
+        } else {
+            deleteObject(path);
+        }
+
+        return true;
+    }
+
+    private void deleteRecursively(Path path) throws IOException {
+        final FileStatus[] containingFiles =
+                Preconditions.checkNotNull(
+                        listStatus(path),
+                        "Hadoop FileSystem.listStatus should never return null based on its contract.");
+
+        if (containingFiles.length == 0) {
+            // This if branch covers objects and empty directories. Both will be handled properly in
+            // the deleteObject method.
+            deleteObject(path);
+            return;
+        }
+
+        IOException exception = null;
+        for (FileStatus fileStatus : containingFiles) {
+            final Path childPath = fileStatus.getPath();
+
+            try {
+                if (fileStatus.isDir()) {
+                    deleteRecursively(childPath);
+                } else {
+                    deleteObject(childPath);
+                }
+            } catch (IOException e) {
+                exception = ExceptionUtils.firstOrSuppressed(e, exception);
+            }
+        }
+
+        // Presto doesn't hold placeholders for directories itself; therefore, we don't need to
+        // call deleteObject on the directory itself if there were objects with the prefix being
+        // deleted in the initial loop above. This saves us from doing some existence checks on
+        // an not-existing object (i.e. the now empty directory)
+        if (exception != null) {
+            throw exception;
+        }
+    }
+
+    /**
+     * Deletes the object referenced by the passed {@code path}. This method is used to work around
+     * the fact that Presto doesn't allow us to differentiate between deleting a non-existing object
+     * and some other errors. Therefore, a final check for existence is necessary in case of an
+     * error or false return value.
+     *
+     * @param path The path referring to the object that shall be deleted.
+     * @throws IOException if an error occurred while deleting the file other than the {@code path}
+     *     referring to a non-empty directory.
+     */
+    private void deleteObject(Path path) throws IOException {
+        boolean success = true;
+        IOException actualException = null;
+        try {
+            // empty directories will cause this method to fail as well - checking for their
+            // existence afterwards is a workaround to cover this use-case
+            success = super.delete(path, false);
+        } catch (IOException e) {
+            actualException = e;
+        }
+
+        if (!success || actualException != null) {
+            if (exists(path)) {
+                throw Optional.ofNullable(actualException)
+                        .orElse(
+                                new IOException(
+                                        path.getPath()
+                                                + " could not be deleted for unknown reasons."));
+            }
+        }
+    }
+}
diff --git a/flink-filesystems/flink-s3-fs-presto/src/main/java/org/apache/flink/fs/s3presto/S3FileSystemFactory.java b/flink-filesystems/flink-s3-fs-presto/src/main/java/org/apache/flink/fs/s3presto/S3FileSystemFactory.java
index 0fa63559584..f5a7172e3f1 100644
--- a/flink-filesystems/flink-s3-fs-presto/src/main/java/org/apache/flink/fs/s3presto/S3FileSystemFactory.java
+++ b/flink-filesystems/flink-s3-fs-presto/src/main/java/org/apache/flink/fs/s3presto/S3FileSystemFactory.java
@@ -64,6 +64,25 @@ public class S3FileSystemFactory extends AbstractS3FileSystemFactory {
                 "");
     }
 
+    @Override
+    protected org.apache.flink.core.fs.FileSystem createFlinkFileSystem(
+            FileSystem fs,
+            String localTmpDirectory,
+            String entropyInjectionKey,
+            int numEntropyChars,
+            S3AccessHelper s3AccessHelper,
+            long s3minPartSize,
+            int maxConcurrentUploads) {
+        return new FlinkS3PrestoFileSystem(
+                fs,
+                localTmpDirectory,
+                entropyInjectionKey,
+                numEntropyChars,
+                s3AccessHelper,
+                s3minPartSize,
+                maxConcurrentUploads);
+    }
+
     @Override
     protected org.apache.hadoop.fs.FileSystem createHadoopFileSystem() {
         return new PrestoS3FileSystem();
