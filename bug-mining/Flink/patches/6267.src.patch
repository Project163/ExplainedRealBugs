diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/JobExceptionsHandler.java b/flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/JobExceptionsHandler.java
index daf281ff66d..c500792c6aa 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/JobExceptionsHandler.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/rest/handler/job/JobExceptionsHandler.java
@@ -119,7 +119,9 @@ public class JobExceptionsHandler
         final ArchivedExecutionGraph executionGraph =
                 executionGraphInfo.getArchivedExecutionGraph();
         if (executionGraph.getFailureInfo() == null) {
-            return new JobExceptionsInfoWithHistory();
+            return new JobExceptionsInfoWithHistory(
+                    createJobExceptionHistory(
+                            executionGraphInfo.getExceptionHistory(), exceptionToReportMaxSize));
         }
 
         List<JobExceptionsInfo.ExecutionExceptionInfo> taskExceptionList = new ArrayList<>();
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/rest/messages/JobExceptionsInfoWithHistory.java b/flink-runtime/src/main/java/org/apache/flink/runtime/rest/messages/JobExceptionsInfoWithHistory.java
index 11f4e472b42..da9e776cfc2 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/rest/messages/JobExceptionsInfoWithHistory.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/rest/messages/JobExceptionsInfoWithHistory.java
@@ -58,13 +58,8 @@ public class JobExceptionsInfoWithHistory extends JobExceptionsInfo implements R
         this.exceptionHistory = exceptionHistory;
     }
 
-    public JobExceptionsInfoWithHistory() {
-        this(
-                null,
-                null,
-                Collections.emptyList(),
-                false,
-                new JobExceptionHistory(Collections.emptyList(), false));
+    public JobExceptionsInfoWithHistory(JobExceptionHistory exceptionHistory) {
+        this(null, null, Collections.emptyList(), false, exceptionHistory);
     }
 
     @JsonIgnore
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/rest/handler/job/JobExceptionsHandlerTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/rest/handler/job/JobExceptionsHandlerTest.java
index 9a80f39f55b..2bfdcf209cd 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/rest/handler/job/JobExceptionsHandlerTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/rest/handler/job/JobExceptionsHandlerTest.java
@@ -130,6 +130,26 @@ public class JobExceptionsHandlerTest extends TestLogger {
                 contains(historyContainsGlobalFailure(rootCause, rootCauseTimestamp)));
     }
 
+    @Test
+    public void testOnlyExceptionHistory() throws HandlerRequestException {
+        final RuntimeException rootThrowable = new RuntimeException("exception #0");
+        final long rootTimestamp = System.currentTimeMillis();
+        final RootExceptionHistoryEntry rootEntry = fromGlobalFailure(rootThrowable, rootTimestamp);
+        final ExecutionGraphInfo executionGraphInfo =
+                createExecutionGraphInfoWithoutFailureCause(rootEntry);
+        final HandlerRequest<EmptyRequestBody> request =
+                createRequest(executionGraphInfo.getJobId(), 10);
+        final JobExceptionsInfoWithHistory response =
+                testInstance.handleRequest(request, executionGraphInfo);
+
+        assertThat(response.getRootException(), is(nullValue()));
+        assertThat(response.getRootTimestamp(), is(nullValue()));
+
+        assertThat(
+                response.getExceptionHistory().getEntries(),
+                contains(historyContainsGlobalFailure(rootThrowable, rootTimestamp)));
+    }
+
     @Test
     public void testWithExceptionHistory() throws HandlerRequestException {
         final RootExceptionHistoryEntry rootCause =
@@ -348,12 +368,22 @@ public class JobExceptionsHandlerTest extends TestLogger {
 
     private static ExecutionGraphInfo createExecutionGraphInfo(
             RootExceptionHistoryEntry... historyEntries) {
+        return createExecutionGraphInfo(true, historyEntries);
+    }
+
+    private static ExecutionGraphInfo createExecutionGraphInfoWithoutFailureCause(
+            RootExceptionHistoryEntry... historyEntries) {
+        return createExecutionGraphInfo(false, historyEntries);
+    }
+
+    private static ExecutionGraphInfo createExecutionGraphInfo(
+            boolean setFailureCause, RootExceptionHistoryEntry... historyEntries) {
         final ArchivedExecutionGraphBuilder executionGraphBuilder =
                 new ArchivedExecutionGraphBuilder();
         final List<RootExceptionHistoryEntry> historyEntryCollection = new ArrayList<>();
 
         for (int i = 0; i < historyEntries.length; i++) {
-            if (i == 0) {
+            if (i == 0 && setFailureCause) {
                 // first entry is root cause
                 executionGraphBuilder.setFailureCause(
                         new ErrorInfo(
diff --git a/flink-tests/src/test/java/org/apache/flink/test/scheduling/AdaptiveSchedulerITCase.java b/flink-tests/src/test/java/org/apache/flink/test/scheduling/AdaptiveSchedulerITCase.java
index f02adf22e7b..3852bd19c98 100644
--- a/flink-tests/src/test/java/org/apache/flink/test/scheduling/AdaptiveSchedulerITCase.java
+++ b/flink-tests/src/test/java/org/apache/flink/test/scheduling/AdaptiveSchedulerITCase.java
@@ -24,16 +24,20 @@ import org.apache.flink.api.common.state.CheckpointListener;
 import org.apache.flink.api.common.state.ListState;
 import org.apache.flink.api.common.state.ListStateDescriptor;
 import org.apache.flink.api.common.time.Deadline;
+import org.apache.flink.client.program.rest.RestClusterClient;
 import org.apache.flink.configuration.ClusterOptions;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.configuration.HeartbeatManagerOptions;
 import org.apache.flink.configuration.JobManagerOptions;
 import org.apache.flink.core.execution.JobClient;
 import org.apache.flink.core.execution.SavepointFormatType;
+import org.apache.flink.runtime.rest.messages.EmptyRequestBody;
+import org.apache.flink.runtime.rest.messages.JobExceptionsHeaders;
+import org.apache.flink.runtime.rest.messages.JobExceptionsInfoWithHistory;
+import org.apache.flink.runtime.rest.messages.job.JobExceptionsMessageParameters;
 import org.apache.flink.runtime.state.FunctionInitializationContext;
 import org.apache.flink.runtime.state.FunctionSnapshotContext;
 import org.apache.flink.runtime.testutils.CommonTestUtils;
-import org.apache.flink.runtime.testutils.MiniClusterResource;
 import org.apache.flink.runtime.testutils.MiniClusterResourceConfiguration;
 import org.apache.flink.streaming.api.CheckpointingMode;
 import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;
@@ -59,6 +63,8 @@ import java.io.File;
 import java.time.Duration;
 import java.time.temporal.ChronoUnit;
 import java.util.Arrays;
+import java.util.Collections;
+import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.ExecutionException;
 import java.util.stream.Collectors;
@@ -90,7 +96,7 @@ public class AdaptiveSchedulerITCase extends TestLogger {
     }
 
     @ClassRule
-    public static final MiniClusterResource MINI_CLUSTER_WITH_CLIENT_RESOURCE =
+    public static final MiniClusterWithClientResource MINI_CLUSTER_WITH_CLIENT_RESOURCE =
             new MiniClusterWithClientResource(
                     new MiniClusterResourceConfiguration.Builder()
                             .setConfiguration(configuration)
@@ -251,6 +257,37 @@ public class AdaptiveSchedulerITCase extends TestLogger {
         assertThat(savepoint, containsString(savepointDirectory.getAbsolutePath()));
     }
 
+    @Test
+    public void testExceptionHistoryIsRetrievableFromTheRestAPI() throws Exception {
+        final Deadline deadline = Deadline.fromNow(Duration.ofMinutes(1));
+        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
+        env.setParallelism(PARALLELISM);
+        env.enableCheckpointing(20L, CheckpointingMode.EXACTLY_ONCE);
+        env.addSource(new FailOnCompletedCheckpointSource()).addSink(new DiscardingSink<>());
+        final JobClient jobClient = env.executeAsync();
+        CommonTestUtils.waitUntilCondition(
+                () -> {
+                    final RestClusterClient<?> restClusterClient =
+                            MINI_CLUSTER_WITH_CLIENT_RESOURCE.getRestClusterClient();
+                    final JobExceptionsMessageParameters params =
+                            new JobExceptionsMessageParameters();
+                    params.jobPathParameter.resolve(jobClient.getJobID());
+                    final CompletableFuture<JobExceptionsInfoWithHistory> exceptionsFuture =
+                            restClusterClient.sendRequest(
+                                    JobExceptionsHeaders.getInstance(),
+                                    params,
+                                    EmptyRequestBody.getInstance());
+                    final JobExceptionsInfoWithHistory jobExceptionsInfoWithHistory =
+                            exceptionsFuture.get();
+                    return jobExceptionsInfoWithHistory.getExceptionHistory().getEntries().size()
+                            > 0;
+                },
+                deadline);
+        jobClient.cancel().get();
+        CommonTestUtils.waitForJobStatus(
+                jobClient, Collections.singletonList(JobStatus.CANCELED), deadline);
+    }
+
     private boolean isDirectoryEmpty(File directory) {
         File[] files = directory.listFiles();
         if (files.length > 0) {
@@ -390,4 +427,31 @@ public class AdaptiveSchedulerITCase extends TestLogger {
             unionListState.add(true);
         }
     }
+
+    /** Simple source which fails every time checkpoint is completed. */
+    public static final class FailOnCompletedCheckpointSource
+            extends RichParallelSourceFunction<Integer> implements CheckpointListener {
+
+        private volatile boolean running = true;
+
+        @Override
+        public void run(SourceContext<Integer> ctx) throws Exception {
+            while (running) {
+                synchronized (ctx.getCheckpointLock()) {
+                    ctx.collect(getRuntimeContext().getIndexOfThisSubtask());
+                    Thread.sleep(5L);
+                }
+            }
+        }
+
+        @Override
+        public void cancel() {
+            running = false;
+        }
+
+        @Override
+        public void notifyCheckpointComplete(long checkpointId) throws Exception {
+            throw new RuntimeException("Test exception.");
+        }
+    }
 }
