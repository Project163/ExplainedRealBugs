diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionGraphBuilder.java b/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionGraphBuilder.java
index fe70bb65fae..cd719bea985 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionGraphBuilder.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionGraphBuilder.java
@@ -43,13 +43,13 @@ import org.apache.flink.runtime.executiongraph.metrics.NumberOfFullRestartsGauge
 import org.apache.flink.runtime.executiongraph.metrics.RestartTimeGauge;
 import org.apache.flink.runtime.executiongraph.metrics.UpTimeGauge;
 import org.apache.flink.runtime.executiongraph.restart.RestartStrategy;
-import org.apache.flink.runtime.jobmaster.slotpool.SlotProvider;
 import org.apache.flink.runtime.jobgraph.JobGraph;
 import org.apache.flink.runtime.jobgraph.JobVertex;
 import org.apache.flink.runtime.jobgraph.JobVertexID;
 import org.apache.flink.runtime.jobgraph.jsonplan.JsonPlanGenerator;
 import org.apache.flink.runtime.jobgraph.tasks.CheckpointCoordinatorConfiguration;
 import org.apache.flink.runtime.jobgraph.tasks.JobCheckpointingSettings;
+import org.apache.flink.runtime.jobmaster.slotpool.SlotProvider;
 import org.apache.flink.runtime.state.StateBackend;
 import org.apache.flink.runtime.state.StateBackendLoader;
 import org.apache.flink.util.DynamicCodeLoadingException;
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionJobVertex.java b/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionJobVertex.java
index bb5ad28a1ea..e07c71ec91c 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionJobVertex.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionJobVertex.java
@@ -35,7 +35,6 @@ import org.apache.flink.runtime.accumulators.StringifiedAccumulatorResult;
 import org.apache.flink.runtime.blob.BlobWriter;
 import org.apache.flink.runtime.blob.PermanentBlobKey;
 import org.apache.flink.runtime.execution.ExecutionState;
-import org.apache.flink.runtime.jobmaster.slotpool.SlotProvider;
 import org.apache.flink.runtime.jobgraph.IntermediateDataSet;
 import org.apache.flink.runtime.jobgraph.IntermediateDataSetID;
 import org.apache.flink.runtime.jobgraph.JobEdge;
@@ -45,6 +44,7 @@ import org.apache.flink.runtime.jobgraph.OperatorID;
 import org.apache.flink.runtime.jobmanager.scheduler.CoLocationGroup;
 import org.apache.flink.runtime.jobmanager.scheduler.LocationPreferenceConstraint;
 import org.apache.flink.runtime.jobmanager.scheduler.SlotSharingGroup;
+import org.apache.flink.runtime.jobmaster.slotpool.SlotProvider;
 import org.apache.flink.runtime.state.KeyGroupRangeAssignment;
 import org.apache.flink.types.Either;
 import org.apache.flink.util.Preconditions;
@@ -73,7 +73,7 @@ import java.util.concurrent.CompletableFuture;
  */
 public class ExecutionJobVertex implements AccessExecutionJobVertex, Archiveable<ArchivedExecutionJobVertex> {
 
-	/** Use the same log for all ExecutionGraph classes */
+	/** Use the same log for all ExecutionGraph classes. */
 	private static final Logger LOG = ExecutionGraph.LOG;
 
 	public static final int VALUE_NOT_SET = -1;
@@ -87,7 +87,7 @@ public class ExecutionJobVertex implements AccessExecutionJobVertex, Archiveable
 	/**
 	 * The IDs of all operators contained in this execution job vertex.
 	 *
-	 * The ID's are stored depth-first post-order; for the forking chain below the ID's would be stored as [D, E, B, C, A].
+	 * <p>The ID's are stored depth-first post-order; for the forking chain below the ID's would be stored as [D, E, B, C, A].
 	 *  A - B - D
 	 *   \    \
 	 *    C    E
@@ -98,7 +98,7 @@ public class ExecutionJobVertex implements AccessExecutionJobVertex, Archiveable
 	/**
 	 * The alternative IDs of all operators contained in this execution job vertex.
 	 *
-	 * The ID's are in the same order as {@link ExecutionJobVertex#operatorIDs}.
+	 * <p>The ID's are in the same order as {@link ExecutionJobVertex#operatorIDs}.
 	 */
 	private final List<OperatorID> userDefinedOperatorIds;
 
@@ -162,22 +162,31 @@ public class ExecutionJobVertex implements AccessExecutionJobVertex, Archiveable
 		if (graph == null || jobVertex == null) {
 			throw new NullPointerException();
 		}
-		
+
 		this.graph = graph;
 		this.jobVertex = jobVertex;
 
 		int vertexParallelism = jobVertex.getParallelism();
 		int numTaskVertices = vertexParallelism > 0 ? vertexParallelism : defaultParallelism;
 
-		this.parallelism = numTaskVertices;
-
 		final int configuredMaxParallelism = jobVertex.getMaxParallelism();
 
 		this.maxParallelismConfigured = (VALUE_NOT_SET != configuredMaxParallelism);
 
 		// if no max parallelism was configured by the user, we calculate and set a default
 		setMaxParallelismInternal(maxParallelismConfigured ?
-				configuredMaxParallelism : KeyGroupRangeAssignment.computeDefaultMaxParallelism(parallelism));
+				configuredMaxParallelism : KeyGroupRangeAssignment.computeDefaultMaxParallelism(numTaskVertices));
+
+		// verify that our parallelism is not higher than the maximum parallelism
+		if (numTaskVertices > maxParallelism) {
+			throw new JobException(
+				String.format("Vertex %s's parallelism (%s) is higher than the max parallelism (%s). Please lower the parallelism or increase the max parallelism.",
+					jobVertex.getName(),
+					numTaskVertices,
+					maxParallelism));
+		}
+
+		this.parallelism = numTaskVertices;
 
 		this.serializedTaskInformation = null;
 
@@ -186,16 +195,16 @@ public class ExecutionJobVertex implements AccessExecutionJobVertex, Archiveable
 		this.userDefinedOperatorIds = Collections.unmodifiableList(jobVertex.getUserDefinedOperatorIDs());
 
 		this.inputs = new ArrayList<>(jobVertex.getInputs().size());
-		
+
 		// take the sharing group
 		this.slotSharingGroup = jobVertex.getSlotSharingGroup();
 		this.coLocationGroup = jobVertex.getCoLocationGroup();
-		
+
 		// setup the coLocation group
 		if (coLocationGroup != null && slotSharingGroup == null) {
 			throw new JobException("Vertex uses a co-location constraint without using slot sharing");
 		}
-		
+
 		// create the intermediate results
 		this.producedDataSets = new IntermediateResult[jobVertex.getNumberOfProducedIntermediateDataSets()];
 
@@ -239,7 +248,7 @@ public class ExecutionJobVertex implements AccessExecutionJobVertex, Archiveable
 		try {
 			@SuppressWarnings("unchecked")
 			InputSplitSource<InputSplit> splitSource = (InputSplitSource<InputSplit>) jobVertex.getInputSplitSource();
-			
+
 			if (splitSource != null) {
 				Thread currentThread = Thread.currentThread();
 				ClassLoader oldContextClassLoader = currentThread.getContextClassLoader();
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/executiongraph/ExecutionGraphRescalingTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/executiongraph/ExecutionGraphRescalingTest.java
index e6cc908d6d7..f4a9f2556fe 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/executiongraph/ExecutionGraphRescalingTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/executiongraph/ExecutionGraphRescalingTest.java
@@ -18,10 +18,11 @@
 
 package org.apache.flink.runtime.executiongraph;
 
-import org.apache.flink.api.common.ExecutionConfig;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.metrics.groups.UnregisteredMetricsGroup;
+import org.apache.flink.runtime.JobException;
 import org.apache.flink.runtime.akka.AkkaUtils;
+import org.apache.flink.runtime.blob.VoidBlobWriter;
 import org.apache.flink.runtime.checkpoint.StandaloneCheckpointRecoveryFactory;
 import org.apache.flink.runtime.executiongraph.restart.NoRestartStrategy;
 import org.apache.flink.runtime.io.network.partition.ResultPartitionType;
@@ -31,8 +32,8 @@ import org.apache.flink.runtime.jobgraph.JobVertex;
 import org.apache.flink.runtime.jobgraph.tasks.AbstractInvokable;
 import org.apache.flink.runtime.jobmanager.scheduler.Scheduler;
 import org.apache.flink.runtime.testingUtils.TestingUtils;
+import org.apache.flink.util.TestLogger;
 
-import org.junit.Ignore;
 import org.junit.Test;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -40,14 +41,15 @@ import org.slf4j.LoggerFactory;
 import java.util.Arrays;
 import java.util.Collections;
 
-import static org.junit.Assert.assertEquals;
+import static org.hamcrest.CoreMatchers.is;
+import static org.junit.Assert.assertThat;
 import static org.junit.Assert.fail;
 
 /**
  * This class contains tests that verify when rescaling a {@link JobGraph},
  * constructed {@link ExecutionGraph}s are correct.
  */
-public class ExecutionGraphRescalingTest {
+public class ExecutionGraphRescalingTest extends TestLogger {
 
 	private static final Logger TEST_LOGGER = LoggerFactory.getLogger(ExecutionGraphRescalingTest.class);
 
@@ -56,72 +58,67 @@ public class ExecutionGraphRescalingTest {
 
 		final Configuration config = new Configuration();
 
-		final JobVertex[] jobVertices = createVerticesForSimpleBipartiteJobGraph();
+		final int initialParallelism = 5;
+		final int maxParallelism = 10;
+		final JobVertex[] jobVertices = createVerticesForSimpleBipartiteJobGraph(initialParallelism, maxParallelism);
 		final JobGraph jobGraph = new JobGraph(jobVertices);
 
-		// TODO rescaling the JobGraph is currently only supported if the
-		// TODO configured parallelism is ExecutionConfig.PARALLELISM_AUTO_MAX.
-		// TODO this limitation should be removed.
-		for (JobVertex jv : jobVertices) {
-			jv.setParallelism(ExecutionConfig.PARALLELISM_AUTO_MAX);
-		}
-
 		ExecutionGraph eg = ExecutionGraphBuilder.buildGraph(
-				null,
-				jobGraph,
-				config,
-				TestingUtils.defaultExecutor(),
-				TestingUtils.defaultExecutor(),
-				new Scheduler(TestingUtils.defaultExecutionContext()),
-				Thread.currentThread().getContextClassLoader(),
-				new StandaloneCheckpointRecoveryFactory(),
-				AkkaUtils.getDefaultTimeout(),
-				new NoRestartStrategy(),
-				new UnregisteredMetricsGroup(),
-				5,
-				TEST_LOGGER);
+			null,
+			jobGraph,
+			config,
+			TestingUtils.defaultExecutor(),
+			TestingUtils.defaultExecutor(),
+			new Scheduler(TestingUtils.defaultExecutionContext()),
+			Thread.currentThread().getContextClassLoader(),
+			new StandaloneCheckpointRecoveryFactory(),
+			AkkaUtils.getDefaultTimeout(),
+			new NoRestartStrategy(),
+			new UnregisteredMetricsGroup(),
+			-1,
+			VoidBlobWriter.getInstance(),
+			TEST_LOGGER);
 
 		for (JobVertex jv : jobVertices) {
-			assertEquals(5, jv.getParallelism());
+			assertThat(jv.getParallelism(), is(initialParallelism));
 		}
 		verifyGeneratedExecutionGraphOfSimpleBitartiteJobGraph(eg, jobVertices);
 
-		// --- verify scaling up works correctly ---
+		// --- verify scaling down works correctly ---
+
+		final int scaleDownParallelism = 1;
 
-		// TODO rescaling the JobGraph is currently only supported if the
-		// TODO configured parallelism is ExecutionConfig.PARALLELISM_AUTO_MAX.
-		// TODO this limitation should be removed.
 		for (JobVertex jv : jobVertices) {
-			jv.setParallelism(ExecutionConfig.PARALLELISM_AUTO_MAX);
+			jv.setParallelism(scaleDownParallelism);
 		}
 
 		eg = ExecutionGraphBuilder.buildGraph(
-				null,
-				jobGraph,
-				config,
-				TestingUtils.defaultExecutor(),
-				TestingUtils.defaultExecutor(),
-				new Scheduler(TestingUtils.defaultExecutionContext()),
-				Thread.currentThread().getContextClassLoader(),
-				new StandaloneCheckpointRecoveryFactory(),
-				AkkaUtils.getDefaultTimeout(),
-				new NoRestartStrategy(),
-				new UnregisteredMetricsGroup(),
-				10,
-				TEST_LOGGER);
+			null,
+			jobGraph,
+			config,
+			TestingUtils.defaultExecutor(),
+			TestingUtils.defaultExecutor(),
+			new Scheduler(TestingUtils.defaultExecutionContext()),
+			Thread.currentThread().getContextClassLoader(),
+			new StandaloneCheckpointRecoveryFactory(),
+			AkkaUtils.getDefaultTimeout(),
+			new NoRestartStrategy(),
+			new UnregisteredMetricsGroup(),
+			-1,
+			VoidBlobWriter.getInstance(),
+			TEST_LOGGER);
 
 		for (JobVertex jv : jobVertices) {
-			assertEquals(10, jv.getParallelism());
+			assertThat(jv.getParallelism(), is(1));
 		}
 		verifyGeneratedExecutionGraphOfSimpleBitartiteJobGraph(eg, jobVertices);
 
-		// --- verify down scaling works correctly ---
+		// --- verify scaling up works correctly ---
+
+		final int scaleUpParallelism = 10;
 
-		// TODO rescaling the JobGraph is currently only supported if the
-		// TODO configured parallelism is ExecutionConfig.PARALLELISM_AUTO_MAX.
-		// TODO this limitation should be removed.
 		for (JobVertex jv : jobVertices) {
-			jv.setParallelism(ExecutionConfig.PARALLELISM_AUTO_MAX);
+			jv.setParallelism(scaleUpParallelism);
 		}
 
 		eg = ExecutionGraphBuilder.buildGraph(
@@ -136,11 +133,12 @@ public class ExecutionGraphRescalingTest {
 			AkkaUtils.getDefaultTimeout(),
 			new NoRestartStrategy(),
 			new UnregisteredMetricsGroup(),
-			2,
+			-1,
+			VoidBlobWriter.getInstance(),
 			TEST_LOGGER);
 
 		for (JobVertex jv : jobVertices) {
-			assertEquals(2, jv.getParallelism());
+			assertThat(jv.getParallelism(), is(scaleUpParallelism));
 		}
 		verifyGeneratedExecutionGraphOfSimpleBitartiteJobGraph(eg, jobVertices);
 	}
@@ -148,24 +146,23 @@ public class ExecutionGraphRescalingTest {
 	/**
 	 * Verifies that building an {@link ExecutionGraph} from a {@link JobGraph} with
 	 * parallelism higher than the maximum parallelism fails.
-	 *
-	 * TODO this test is ignored, since currently the rescale does not properly fail when rescaling to DOP above max.
 	 */
-	@Ignore
 	@Test
 	public void testExecutionGraphConstructionFailsRescaleDopExceedMaxParallelism() throws Exception {
 
 		final Configuration config = new Configuration();
 
-		final JobVertex[] jobVertices = createVerticesForSimpleBipartiteJobGraph();
+		final int initialParallelism = 1;
+		final int maxParallelism = 10;
+		final JobVertex[] jobVertices = createVerticesForSimpleBipartiteJobGraph(initialParallelism,  maxParallelism);
 		final JobGraph jobGraph = new JobGraph(jobVertices);
 
 		for (JobVertex jv : jobVertices) {
-			jv.setParallelism(ExecutionConfig.PARALLELISM_AUTO_MAX);
-			jv.setMaxParallelism(5);
+			jv.setParallelism(maxParallelism + 1);
 		}
 
 		try {
+			// this should fail since we set the parallelism to maxParallelism + 1
 			ExecutionGraphBuilder.buildGraph(
 				null,
 				jobGraph,
@@ -178,16 +175,17 @@ public class ExecutionGraphRescalingTest {
 				AkkaUtils.getDefaultTimeout(),
 				new NoRestartStrategy(),
 				new UnregisteredMetricsGroup(),
-				10, // this should fail because 10 is larger than the max parallelism 5
+				-1,
+				VoidBlobWriter.getInstance(),
 				TEST_LOGGER);
 
 			fail("Building the ExecutionGraph with a parallelism higher than the max parallelism should fail.");
-		} catch (Exception e) {
+		} catch (JobException e) {
 			// expected, ignore
 		}
 	}
 
-	private static JobVertex[] createVerticesForSimpleBipartiteJobGraph() {
+	private static JobVertex[] createVerticesForSimpleBipartiteJobGraph(int parallelism, int maxParallelism) {
 		JobVertex v1 = new JobVertex("vertex1");
 		JobVertex v2 = new JobVertex("vertex2");
 		JobVertex v3 = new JobVertex("vertex3");
@@ -198,6 +196,8 @@ public class ExecutionGraphRescalingTest {
 
 		for (JobVertex jobVertex : jobVertices) {
 			jobVertex.setInvokableClass(AbstractInvokable.class);
+			jobVertex.setParallelism(parallelism);
+			jobVertex.setMaxParallelism(maxParallelism);
 		}
 
 		v2.connectNewDataSetAsInput(v1, DistributionPattern.ALL_TO_ALL, ResultPartitionType.PIPELINED);
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/executiongraph/ExecutionJobVertexTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/executiongraph/ExecutionJobVertexTest.java
index f0f6248eb3d..78c87b7ed99 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/executiongraph/ExecutionJobVertexTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/executiongraph/ExecutionJobVertexTest.java
@@ -23,11 +23,10 @@ import org.apache.flink.runtime.JobException;
 import org.apache.flink.runtime.concurrent.Executors;
 import org.apache.flink.runtime.jobgraph.JobVertex;
 import org.apache.flink.runtime.jobgraph.tasks.AbstractInvokable;
+
 import org.junit.Assert;
 import org.junit.Test;
 
-import java.io.IOException;
-
 import static org.mockito.Mockito.mock;
 import static org.mockito.Mockito.when;
 
@@ -62,9 +61,14 @@ public class ExecutionJobVertexTest {
 		} catch (IllegalArgumentException ignore) {
 		}
 
-		// test configured / trumps computed default
-		executionJobVertex = createExecutionJobVertex(172, 4);
-		Assert.assertEquals(4, executionJobVertex.getMaxParallelism());
+		// parallelism must be smaller than the max parallelism
+		try {
+			createExecutionJobVertex(172, 4);
+			Assert.fail("We should not be able to create an ExecutionJobVertex which " +
+				"has a smaller max parallelism than parallelism.");
+		} catch (JobException ignored) {
+			// expected
+		}
 
 
 		// test configured / trumps computed default
@@ -120,7 +124,7 @@ public class ExecutionJobVertexTest {
 
 	private static ExecutionJobVertex createExecutionJobVertex(
 			int parallelism,
-			int preconfiguredMaxParallelism) throws JobException, IOException {
+			int preconfiguredMaxParallelism) throws JobException {
 
 		JobVertex jobVertex = new JobVertex("testVertex");
 		jobVertex.setInvokableClass(AbstractInvokable.class);
@@ -137,4 +141,4 @@ public class ExecutionJobVertexTest {
 
 		return executionJobVertex;
 	}
-}
\ No newline at end of file
+}
