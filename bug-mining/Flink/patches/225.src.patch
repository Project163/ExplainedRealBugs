diff --git a/flink-clients/src/main/java/org/apache/flink/client/CliFrontend.java b/flink-clients/src/main/java/org/apache/flink/client/CliFrontend.java
index dc14a2f09f6..e438de07581 100644
--- a/flink-clients/src/main/java/org/apache/flink/client/CliFrontend.java
+++ b/flink-clients/src/main/java/org/apache/flink/client/CliFrontend.java
@@ -16,7 +16,6 @@
  * limitations under the License.
  */
 
-
 package org.apache.flink.client;
 
 import java.io.File;
@@ -71,6 +70,7 @@ import org.apache.flink.runtime.messages.JobManagerMessages.RunningJobs;
 import org.apache.flink.runtime.yarn.AbstractFlinkYarnCluster;
 import org.apache.flink.runtime.yarn.FlinkYarnClusterStatus;
 import org.apache.flink.util.StringUtils;
+import scala.Some;
 import scala.concurrent.Await;
 import scala.concurrent.Future;
 import scala.concurrent.duration.FiniteDuration;
@@ -115,9 +115,6 @@ public class CliFrontend {
 		initOptions();
 	}
 	
-	// general options
-	private static final Options GENERAL_OPTIONS = createGeneralOptions();
-	
 	// action options all include the general options
 	private static final Options RUN_OPTIONS = getRunOptions(createGeneralOptions());
 	private static final Options INFO_OPTIONS = getInfoOptions(createGeneralOptions());
@@ -145,7 +142,7 @@ public class CliFrontend {
 	private boolean printHelp;
 	
 	private boolean globalConfigurationLoaded;
-	
+
 	private boolean yarnPropertiesLoaded = false;
 	
 	private Properties yarnProperties;
@@ -516,7 +513,7 @@ public class CliFrontend {
 		}
 		
 		try {
-			ActorRef jobManager = getJobManager(line);
+			ActorRef jobManager = getJobManager(line, getGlobalConfiguration());
 			if (jobManager == null) {
 				return 1;
 			}
@@ -524,16 +521,15 @@ public class CliFrontend {
 			final Future<Object> response = Patterns.ask(jobManager,
 					JobManagerMessages.getRequestRunningJobs(), new Timeout(getAkkaTimeout()));
 
-			Object result = null;
-
-			try{
+			Object result;
+			try {
 				result = Await.result(response, getAkkaTimeout());
 			} catch (Exception exception) {
 				throw new IOException("Could not retrieve running jobs from job manager.",
 						exception);
 			}
 
-			if(!(result instanceof RunningJobs)){
+			if (!(result instanceof RunningJobs)) {
 				throw new RuntimeException("ReqeustRunningJobs requires a response of type " +
 						"RunningJobs. Instead the response is of type " + result.getClass() + ".");
 			} else {
@@ -651,7 +647,7 @@ public class CliFrontend {
 		}
 		
 		try {
-			ActorRef jobManager = getJobManager(line);
+			ActorRef jobManager = getJobManager(line, getGlobalConfiguration());
 
 			if (jobManager == null) {
 				return 1;
@@ -686,7 +682,7 @@ public class CliFrontend {
 				line.getArgs();
 	
 		// take the jar file from the option, or as the first trailing parameter (if available)
-		String jarFilePath = null;
+		String jarFilePath;
 		if (line.hasOption(JAR_OPTION.getOpt())) {
 			jarFilePath = line.getOptionValue(JAR_OPTION.getOpt());
 		}
@@ -775,31 +771,34 @@ public class CliFrontend {
 		}
 	}
 	
-	protected ActorRef getJobManager(CommandLine line) throws IOException {
+	protected ActorRef getJobManager(CommandLine line, Configuration config) throws IOException {
 		//TODO: Get ActorRef from YarnCluster if we are in YARN mode.
 		String jobManagerAddressStr = getJobManagerAddressString(line);
 		if (jobManagerAddressStr == null) {
 			return null;
 		}
 
-		InetSocketAddress address = RemoteExecutor.getInetFromHostport(jobManagerAddressStr);
-
-		Future<ActorRef> jobManagerFuture = JobManager.getJobManager(
-				address,
-				ActorSystem.create("CliFrontendActorSystem", AkkaUtils.getDefaultAkkaConfig()),
-				getAkkaTimeout());
+		final ActorSystem actorSystem;
+		try {
+			scala.Tuple2<String, Object> systemEndpoint = new scala.Tuple2<String, Object>("", 0);
+			actorSystem = AkkaUtils.createActorSystem(config, new Some<scala.Tuple2<String, Object>>(systemEndpoint));
+		}
+		catch (Exception e) {
+			throw new IOException("Could not start actor system to communicate with JobManager", e);
+		}
 
-		try{
-			return Await.result(jobManagerFuture, getAkkaTimeout());
-		} catch (Exception exception) {
-			throw new IOException("Could not find job manager at address " +
-					JobManager.getRemoteAkkaURL(address) + ".");
+		try {
+			InetSocketAddress address = RemoteExecutor.getInetFromHostport(jobManagerAddressStr);
+			return JobManager.getJobManagerRemoteReference(address, actorSystem, config);
+		}
+		finally {
+			actorSystem.shutdown();
 		}
 	}
 	
 
 	public String getConfigurationDirectory() {
-		if(configurationDirectory == null) {
+		if (configurationDirectory == null) {
 			configurationDirectory = getConfigurationDirectoryFromEnv();
 		}
 		return configurationDirectory;
@@ -847,7 +846,7 @@ public class CliFrontend {
 		return GlobalConfiguration.getConfiguration();
 	}
 	public static String getConfigurationDirectoryFromEnv() {
-		String location = null;
+		String location;
 		if (System.getenv(ENV_CONFIG_DIRECTORY) != null) {
 			location = System.getenv(ENV_CONFIG_DIRECTORY);
 		} else if (new File(CONFIG_DIRECTORY_FALLBACK_1).exists()) {
@@ -863,7 +862,6 @@ public class CliFrontend {
 
 	protected FiniteDuration getAkkaTimeout(){
 		Configuration config = getGlobalConfiguration();
-
 		return AkkaUtils.getTimeout(config);
 	}
 	
@@ -897,6 +895,7 @@ public class CliFrontend {
 			} else {
 				yarnProperties = null;
 			}
+			yarnPropertiesLoaded = true;
 		}
 		return yarnProperties;
 	}
diff --git a/flink-clients/src/main/java/org/apache/flink/client/program/Client.java b/flink-clients/src/main/java/org/apache/flink/client/program/Client.java
index 9b95d413110..04e6c4dfb1a 100644
--- a/flink-clients/src/main/java/org/apache/flink/client/program/Client.java
+++ b/flink-clients/src/main/java/org/apache/flink/client/program/Client.java
@@ -25,6 +25,7 @@ import java.io.PrintStream;
 import java.net.InetSocketAddress;
 import java.util.List;
 
+import akka.remote.AssociationErrorEvent;
 import org.apache.flink.runtime.akka.AkkaUtils;
 import org.apache.flink.api.common.JobExecutionResult;
 import org.apache.flink.api.common.Plan;
@@ -86,8 +87,9 @@ public class Client {
 	public Client(InetSocketAddress jobManagerAddress, Configuration config, ClassLoader userCodeClassLoader) {
 		Preconditions.checkNotNull(config, "Configuration is null");
 		this.configuration = config;
-		configuration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY,
-				jobManagerAddress.getHostName());
+		
+		// using the host string instead of the host name saves a reverse name lookup
+		configuration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, jobManagerAddress.getAddress().getHostAddress());
 		configuration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, jobManagerAddress.getPort());
 		
 		this.compiler = new PactCompiler(new DataStatistics(), new DefaultCostEstimator());
@@ -151,7 +153,7 @@ public class Client {
 			}
 			env.setAsContext();
 			
-			// temporarily write syser and sysout to bytearray.
+			// temporarily write syserr and sysout to a byte array.
 			PrintStream originalOut = System.out;
 			PrintStream originalErr = System.err;
 			ByteArrayOutputStream baos = new ByteArrayOutputStream();
@@ -283,16 +285,18 @@ public class Client {
 	}
 	
 	/**
-	 * Runs a program on the nephele system whose job-manager is configured in this client's configuration.
+	 * Runs a program on Flink cluster whose job-manager is configured in this client's configuration.
 	 * This method involves all steps, from compiling, job-graph generation to submission.
 	 * 
 	 * @param prog The program to be executed.
+	 * @param parallelism The default parallelism to use when running the program. The default parallelism is used
+	 *                    when the program does not set a parallelism by itself.
 	 * @param wait A flag that indicates whether this function call should block until the program execution is done.
 	 * @throws CompilerException Thrown, if the compiler encounters an illegal situation.
 	 * @throws ProgramInvocationException Thrown, if the program could not be instantiated from its jar file,
 	 *                                    or if the submission failed. That might be either due to an I/O problem,
-	 *                                    i.e. the job-manager is unreachable, or due to the fact that the execution
-	 *                                    on the nephele system failed.
+	 *                                    i.e. the job-manager is unreachable, or due to the fact that the
+	 *                                    parallel execution failed.
 	 */
 	public JobExecutionResult run(JobWithJars prog, int parallelism, boolean wait) throws CompilerException, ProgramInvocationException {
 		return run((OptimizedPlan) getOptimizedPlan(prog, parallelism), prog.getJarFiles(), wait);
@@ -305,53 +309,85 @@ public class Client {
 	}
 
 	public JobExecutionResult run(JobGraph jobGraph, boolean wait) throws ProgramInvocationException {
-		Tuple2<ActorSystem, ActorRef> pair = JobClient.startActorSystemAndActor(configuration,
-				false);
-
-		ActorRef client = pair._2();
 
-		String hostname = configuration.getString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, null);
+		final String hostname = configuration.getString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, null);
+		if (hostname == null) {
+			throw new ProgramInvocationException("Could not find hostname of job manager.");
+		}
 
 		FiniteDuration timeout = AkkaUtils.getTimeout(configuration);
 
-		if(hostname == null){
-			throw new ProgramInvocationException("Could not find hostname of job manager.");
-		}
+		final ActorSystem actorSystem;
+		final ActorRef client;
 
 		try {
-			JobClient.uploadJarFiles(jobGraph, hostname, client, timeout);
-		}catch(IOException e){
-			throw new ProgramInvocationException("Could not upload blobs.", e);
+			Tuple2<ActorSystem, ActorRef> pair = JobClient.startActorSystemAndActor(configuration, false);
+			actorSystem = pair._1();
+			client = pair._2();
+		}
+		catch (Exception e) {
+			throw new ProgramInvocationException("Could not build up connection to JobManager.", e);
 		}
 
 		try {
+			JobClient.uploadJarFiles(jobGraph, hostname, client, timeout);
+
 			if (wait) {
 				return JobClient.submitJobAndWait(jobGraph, printStatusDuringExecution, client, timeout);
 			}
 			else {
 				SubmissionResponse response = JobClient.submitJobDetached(jobGraph, client, timeout);
-
-				if(response instanceof SubmissionFailure){
+				if (response instanceof SubmissionFailure) {
 					SubmissionFailure failure = (SubmissionFailure) response;
-					throw new ProgramInvocationException("The job was not successfully submitted " +
-							"to the flink job manager", failure.cause());
+					throw new ProgramInvocationException(
+							"Failed to submit the job to the flink JobManager", failure.cause());
 				}
 			}
 		}
-		catch (JobExecutionException jex) {
-			if(jex.isJobCanceledByUser()) {
-				throw new ProgramInvocationException("The program has been canceled");
-			} else {
-				throw new ProgramInvocationException("The program execution failed: " + jex.getMessage());
+		catch (IOException e) {
+			throw new ProgramInvocationException("Could not upload the programs JAR files to the JobManager.", e);
+		}
+		catch (JobExecutionException e) {
+			if (e.isJobCanceledByUser()) {
+				throw new ProgramInvocationException("The program has been canceled.");
 			}
-		}finally{
-			pair._1().shutdown();
-			pair._1().awaitTermination();
+			else if (e.isConnectionTimedOut()) {
+				Throwable ae = null; //getAssociationError(monitoredErrors);
+				String message = ae == null ? "." : ": " + ae.getMessage();
+				throw new ProgramInvocationException("Lost connection to the JobManager" + message);
+			}
+			else {
+				throw new ProgramInvocationException("The program execution failed: " + e.getMessage());
+			}
+		}
+		catch (Exception e) {
+			Throwable ae = null; //getAssociationError(monitoredErrors);
+			String message = ae == null ? "." : ": " + ae.getMessage();
+			throw new ProgramInvocationException("Connection to JobManager failed" + message);
+		}
+		finally {
+			actorSystem.shutdown();
+			actorSystem.awaitTermination();
 		}
 
 		return new JobExecutionResult(-1, null);
 	}
-	
+
+	private Throwable getAssociationError(List<AssociationErrorEvent> eventLog) {
+		int len = eventLog.size();
+		if (len > 0) {
+			AssociationErrorEvent e = eventLog.get(len - 1);
+			Throwable cause = e.getCause();
+			if (cause instanceof akka.remote.InvalidAssociation) {
+				return cause.getCause();
+			} else {
+				return cause;
+			}
+		} else {
+			return null;
+		}
+	}
+
 	// --------------------------------------------------------------------------------------------
 	
 	public static final class OptimizerPlanEnvironment extends ExecutionEnvironment {
@@ -398,7 +434,13 @@ public class Client {
 			this.optimizerPlan = plan;
 		}
 	}
-	
+
+	// --------------------------------------------------------------------------------------------
+
+	/**
+	 * A special exception used to abort programs when the caller is only interested in the
+	 * program plan, rather than in the full execution.
+	 */
 	public static final class ProgramAbortException extends Error {
 		private static final long serialVersionUID = 1L;
 	}
diff --git a/flink-clients/src/main/java/org/apache/flink/client/web/JobsInfoServlet.java b/flink-clients/src/main/java/org/apache/flink/client/web/JobsInfoServlet.java
index b638326720d..381ee33bce7 100644
--- a/flink-clients/src/main/java/org/apache/flink/client/web/JobsInfoServlet.java
+++ b/flink-clients/src/main/java/org/apache/flink/client/web/JobsInfoServlet.java
@@ -73,13 +73,13 @@ public class JobsInfoServlet extends HttpServlet {
 
 		InetSocketAddress address = new InetSocketAddress(jmHost, jmPort);
 
-		Future<ActorRef> jobManagerFuture = JobManager.getJobManager(address, system, timeout);
+		Future<ActorRef> jobManagerFuture = JobManager.getJobManagerRemoteReferenceFuture(address, system, timeout);
 
 		try {
 			this.jobmanager = Await.result(jobManagerFuture, timeout);
 		} catch (Exception ex) {
 			throw new RuntimeException("Could not find job manager at specified address " +
-					JobManager.getRemoteAkkaURL(address) + ".");
+					JobManager.getRemoteJobManagerAkkaURL(address) + ".");
 		}
 	}
 
diff --git a/flink-clients/src/test/java/org/apache/flink/client/CliFrontendListCancelTest.java b/flink-clients/src/test/java/org/apache/flink/client/CliFrontendListCancelTest.java
index 3a09a4b6482..9dc13ba6987 100644
--- a/flink-clients/src/test/java/org/apache/flink/client/CliFrontendListCancelTest.java
+++ b/flink-clients/src/test/java/org/apache/flink/client/CliFrontendListCancelTest.java
@@ -21,6 +21,7 @@ package org.apache.flink.client;
 import akka.actor.*;
 import akka.testkit.JavaTestKit;
 import org.apache.commons.cli.CommandLine;
+import org.apache.flink.configuration.Configuration;
 import org.apache.flink.runtime.jobgraph.JobID;
 import org.apache.flink.runtime.messages.JobManagerMessages;
 import org.junit.AfterClass;
@@ -135,7 +136,7 @@ public class CliFrontendListCancelTest {
 		}
 
 		@Override
-		public ActorRef getJobManager(CommandLine line){
+		public ActorRef getJobManager(CommandLine line, Configuration config) {
 			return jobmanager;
 		}
 	}
@@ -149,15 +150,16 @@ public class CliFrontendListCancelTest {
 
 		@Override
 		public void onReceive(Object message) throws Exception {
-			if(message instanceof JobManagerMessages.RequestTotalNumberOfSlots$){
+			if (message instanceof JobManagerMessages.RequestTotalNumberOfSlots$) {
 				getSender().tell(1, getSelf());
-			}else if(message instanceof JobManagerMessages.CancelJob){
+			}
+			else if (message instanceof JobManagerMessages.CancelJob) {
 				JobManagerMessages.CancelJob cancelJob = (JobManagerMessages.CancelJob) message;
 				assertEquals(jobID, cancelJob.jobID());
 				getSender().tell(new Status.Success(new Object()), getSelf());
-			}else if(message instanceof  JobManagerMessages.RequestRunningJobs$){
-				getSender().tell(new JobManagerMessages.RunningJobs(),
-						getSelf());
+			}
+			else if(message instanceof  JobManagerMessages.RequestRunningJobs$) {
+				getSender().tell(new JobManagerMessages.RunningJobs(), getSelf());
 			}
 		}
 	}
diff --git a/flink-clients/src/test/java/org/apache/flink/client/program/ClientConnectionTest.java b/flink-clients/src/test/java/org/apache/flink/client/program/ClientConnectionTest.java
new file mode 100644
index 00000000000..fd52d5fc568
--- /dev/null
+++ b/flink-clients/src/test/java/org/apache/flink/client/program/ClientConnectionTest.java
@@ -0,0 +1,157 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.client.program;
+
+import org.apache.flink.configuration.ConfigConstants;
+import org.apache.flink.configuration.Configuration;
+import org.apache.flink.runtime.jobgraph.AbstractJobVertex;
+import org.apache.flink.runtime.jobgraph.JobGraph;
+import org.apache.flink.runtime.jobgraph.tasks.AbstractInvokable;
+import org.apache.flink.runtime.net.NetUtils;
+import org.junit.Test;
+
+import java.net.InetAddress;
+import java.net.InetSocketAddress;
+import java.util.concurrent.atomic.AtomicReference;
+
+import static org.junit.Assert.*;
+
+/**
+ * This test starts a job client without the JobManager being reachable. It
+ * tests for a timely error and a meaningful error message.
+ */
+public class ClientConnectionTest {
+
+	private static final long CONNECT_TIMEOUT = 2 * 1000; // 2 seconds
+	private static final long MAX_DELAY = 5 * CONNECT_TIMEOUT;
+
+	/**
+	 * Tests the behavior against a LOCAL address where no job manager is running.
+	 */
+	@Test
+	public void testExceptionWhenLocalJobManagerUnreachablelocal() {
+
+		final InetSocketAddress unreachableEndpoint;
+		try {
+			int freePort = NetUtils.getAvailablePort();
+			unreachableEndpoint = new InetSocketAddress(InetAddress.getLocalHost(), freePort);
+		}
+		catch (Throwable t) {
+			// do not fail when we spuriously fail to get a free port
+			return;
+		}
+
+		testFailureBehavior(unreachableEndpoint);
+	}
+
+	/**
+	 * Tests the behavior against a REMOTE address where no job manager is running.
+	 */
+	@Test
+	public void testExceptionWhenRemoteJobManagerUnreachable() {
+
+		final InetSocketAddress unreachableEndpoint;
+		try {
+			int freePort = NetUtils.getAvailablePort();
+			unreachableEndpoint = new InetSocketAddress(InetAddress.getByName("10.0.1.64"), freePort);
+		}
+		catch (Throwable t) {
+			// do not fail when we spuriously fail to get a free port
+			return;
+		}
+
+		testFailureBehavior(unreachableEndpoint);
+	}
+
+	private void testFailureBehavior(InetSocketAddress unreachableEndpoint) {
+
+		final Configuration config = new Configuration();
+		config.setString(ConfigConstants.AKKA_LOOKUP_TIMEOUT, (CONNECT_TIMEOUT/1000) + " s");
+
+		try {
+			AbstractJobVertex vertex = new AbstractJobVertex("Test Vertex");
+			vertex.setInvokableClass(TestInvokable.class);
+
+			final JobGraph jg = new JobGraph("Test Job", vertex);
+			final Client client = new Client(unreachableEndpoint, config, getClass().getClassLoader());
+
+			final AtomicReference<Throwable> error = new AtomicReference<Throwable>();
+
+			Thread invoker = new Thread("test invoker") {
+				@Override
+				public void run() {
+					try {
+						client.run(jg, true);
+						fail("This should fail with an exception since the JobManager is unreachable.");
+					}
+					catch (Throwable t) {
+						synchronized (error) {
+							error.set(t);
+							error.notifyAll();
+						}
+					}
+				}
+			};
+
+			invoker.setDaemon(true);
+			invoker.start();
+
+			try {
+				// wait until the caller is successful, for at most teh given time
+				long now = System.currentTimeMillis();
+				long deadline = now + MAX_DELAY;
+
+				synchronized (error) {
+					while (invoker.isAlive() && error.get() == null && now < deadline) {
+						error.wait(1000);
+						now = System.currentTimeMillis();
+					}
+				}
+
+				Throwable t = error.get();
+				if (t == null) {
+					fail("Job invocation did not fail in expected time interval.");
+				}
+				else {
+					assertNotNull(t.getMessage());
+					assertTrue(t.getMessage(), t.getMessage().contains("JobManager"));
+				}
+			}
+			finally {
+				if (invoker.isAlive()) {
+					invoker.interrupt();
+				}
+			}
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+	}
+
+	// --------------------------------------------------------------------------------------------
+
+	public static class TestInvokable extends AbstractInvokable {
+		@Override
+		public void registerInputOutput() {}
+
+		@Override
+		public void invoke() {}
+	}
+}
diff --git a/flink-clients/src/test/java/org/apache/flink/client/program/ClientTest.java b/flink-clients/src/test/java/org/apache/flink/client/program/ClientTest.java
index ba520c3159a..b5b3ac6aebb 100644
--- a/flink-clients/src/test/java/org/apache/flink/client/program/ClientTest.java
+++ b/flink-clients/src/test/java/org/apache/flink/client/program/ClientTest.java
@@ -18,11 +18,13 @@
 
 package org.apache.flink.client.program;
 
-import akka.actor.ActorRef;
 import akka.actor.ActorSystem;
-import org.apache.flink.api.java.ExecutionEnvironment;
+import akka.actor.Props;
+import akka.actor.UntypedActor;
 import org.apache.flink.api.common.InvalidProgramException;
+import org.apache.flink.api.common.JobExecutionResult;
 import org.apache.flink.api.common.Plan;
+import org.apache.flink.api.java.ExecutionEnvironment;
 import org.apache.flink.compiler.DataStatistics;
 import org.apache.flink.compiler.PactCompiler;
 import org.apache.flink.compiler.costs.CostEstimator;
@@ -30,64 +32,71 @@ import org.apache.flink.compiler.plan.OptimizedPlan;
 import org.apache.flink.compiler.plantranslate.NepheleJobGraphGenerator;
 import org.apache.flink.configuration.ConfigConstants;
 import org.apache.flink.configuration.Configuration;
-import org.apache.flink.runtime.client.JobClient$;
+import org.apache.flink.runtime.akka.AkkaUtils;
 import org.apache.flink.runtime.jobgraph.JobGraph;
+import org.apache.flink.runtime.jobgraph.JobID;
+import org.apache.flink.runtime.jobmanager.JobManager;
 import org.apache.flink.runtime.messages.JobManagerMessages;
+import org.apache.flink.runtime.net.NetUtils;
+import org.junit.After;
+
 import org.junit.Before;
 import org.junit.Test;
 import org.junit.runner.RunWith;
-import org.mockito.Mock;
 import org.mockito.invocation.InvocationOnMock;
 import org.mockito.stubbing.Answer;
 import org.powermock.core.classloader.annotations.PrepareForTest;
 import org.powermock.modules.junit4.PowerMockRunner;
-import org.powermock.reflect.Whitebox;
+import scala.Some;
 import scala.Tuple2;
-import scala.concurrent.duration.FiniteDuration;
-
-import java.io.IOException;
 
+import static org.junit.Assert.*;
 import static org.mockito.Matchers.any;
+
+import static org.mockito.Mockito.doAnswer;
 import static org.mockito.Mockito.mock;
 import static org.mockito.Mockito.times;
 import static org.mockito.Mockito.verify;
 import static org.mockito.Mockito.when;
-import static org.mockito.MockitoAnnotations.initMocks;
-import static org.powermock.api.mockito.PowerMockito.doAnswer;
-import static org.powermock.api.mockito.PowerMockito.whenNew;
 
+import static org.powermock.api.mockito.PowerMockito.whenNew;
 
 /**
  * Simple and maybe stupid test to check the {@link Client} class.
  */
 @RunWith(PowerMockRunner.class)
-@PrepareForTest({Client.class, JobClient$.class})
+@PrepareForTest(Client.class)
 public class ClientTest {
 
-	@Mock Configuration configMock;
-	@Mock PackagedProgram program;
-	@Mock JobWithJars planWithJarsMock;
-	@Mock Plan planMock;
-	@Mock PactCompiler compilerMock;
-	@Mock OptimizedPlan optimizedPlanMock;
-	@Mock NepheleJobGraphGenerator generatorMock;
-	@Mock JobGraph jobGraphMock;
-	@Mock ActorSystem mockSystem;
-	@Mock JobClient$ mockJobClient;
-	@Mock JobManagerMessages.SubmissionSuccess mockSubmissionSuccess;
-	@Mock JobManagerMessages.SubmissionFailure mockSubmissionFailure;
-	@Mock ActorRef mockJobClientActor;
+	private PackagedProgram program;
+	private PactCompiler compilerMock;
+	private NepheleJobGraphGenerator generatorMock;
+
+
+	private Configuration config;
+
+	private ActorSystem jobManagerSystem;
+
+	private JobGraph jobGraph = new JobGraph("test graph");
 
 	@Before
 	public void setUp() throws Exception {
-		initMocks(this);
 
-		when(configMock.getString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, null)).thenReturn("localhost");
-		when(configMock.getInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, ConfigConstants.DEFAULT_JOB_MANAGER_IPC_PORT)).thenReturn(6123);
-		when(configMock.getString(ConfigConstants.AKKA_ASK_TIMEOUT, ConfigConstants.DEFAULT_AKKA_ASK_TIMEOUT)).thenReturn(ConfigConstants.DEFAULT_AKKA_ASK_TIMEOUT);
+		final int freePort = NetUtils.getAvailablePort();
+		config = new Configuration();
+		config.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, "localhost");
+		config.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, freePort);
+		config.setString(ConfigConstants.AKKA_ASK_TIMEOUT, ConfigConstants.DEFAULT_AKKA_ASK_TIMEOUT);
+
+		program = mock(PackagedProgram.class);
+		compilerMock = mock(PactCompiler.class);
+		generatorMock = mock(NepheleJobGraphGenerator.class);
+
+		JobWithJars planWithJarsMock = mock(JobWithJars.class);
+		Plan planMock = mock(Plan.class);
+		OptimizedPlan optimizedPlanMock = mock(OptimizedPlan.class);
 
 		when(planMock.getJobName()).thenReturn("MockPlan");
-//		when(mockJarFile.getAbsolutePath()).thenReturn("mockFilePath");
 
 		when(program.getPlanWithJars()).thenReturn(planWithJarsMock);
 		when(planWithJarsMock.getPlan()).thenReturn(planMock);
@@ -96,51 +105,135 @@ public class ClientTest {
 		when(compilerMock.compile(planMock)).thenReturn(optimizedPlanMock);
 
 		whenNew(NepheleJobGraphGenerator.class).withNoArguments().thenReturn(generatorMock);
-		when(generatorMock.compileJobGraph(optimizedPlanMock)).thenReturn(jobGraphMock);
+		when(generatorMock.compileJobGraph(optimizedPlanMock)).thenReturn(jobGraph);
+
+		try {
+			Tuple2<String, Object> address = new Tuple2<String, Object>("localhost", freePort);
+			jobManagerSystem = AkkaUtils.createActorSystem(config, new Some<Tuple2<String, Object>>(address));
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail("Setup of test actor system failed.");
+		}
+	}
 
-		Whitebox.setInternalState(JobClient$.class, mockJobClient);
+	@After
+	public void shutDownActorSystem() {
+		if (jobManagerSystem != null) {
+			try {
+				jobManagerSystem.shutdown();
+				jobManagerSystem.awaitTermination();
+			} catch (Exception e) {
+				e.printStackTrace();
+				fail(e.getMessage());
+			}
+		}
+	}
 
-		when(mockJobClient.startActorSystemAndActor(configMock, false)).thenReturn(new Tuple2<ActorSystem,
-				ActorRef>(mockSystem, mockJobClientActor));
+	/**
+	 * This test verifies correct job submission messaging logic and plan translation calls.
+	 */
+	@Test
+	public void shouldSubmitToJobClient() {
+		try {
+			jobManagerSystem.actorOf(Props.create(SuccessReturningActor.class), JobManager.JOB_MANAGER_NAME());
+
+			Client out = new Client(config, getClass().getClassLoader());
+			JobExecutionResult result = out.run(program.getPlanWithJars(), -1, false);
+
+			assertNotNull(result);
+			assertEquals(-1, result.getNetRuntime());
+			assertNull(result.getAllAccumulatorResults());
+
+			program.deleteExtractedLibraries();
+
+			verify(this.compilerMock, times(1)).compile(any(Plan.class));
+			verify(this.generatorMock, times(1)).compileJobGraph(any(OptimizedPlan.class));
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
 	}
 
+	/**
+	 * This test verifies correct that the correct exception is thrown when the job submission fails.
+	 */
 	@Test
-	public void shouldSubmitToJobClient() throws ProgramInvocationException, IOException {
-		when(mockJobClient.submitJobDetached(any(JobGraph.class),
-				any(ActorRef.class), any(FiniteDuration.class))).thenReturn(mockSubmissionSuccess);
+	public void shouldSubmitToJobClientFails() {
+		try {
+			jobManagerSystem.actorOf(Props.create(FailureReturningActor.class), JobManager.JOB_MANAGER_NAME());
 
-		Client out = new Client(configMock, getClass().getClassLoader());
-		out.run(program.getPlanWithJars(), -1, false);
-		program.deleteExtractedLibraries();
+			Client out = new Client(config, getClass().getClassLoader());
 
-		verify(this.compilerMock, times(1)).compile(planMock);
-		verify(this.generatorMock, times(1)).compileJobGraph(optimizedPlanMock);
-	}
+			try {
+				out.run(program.getPlanWithJars(), -1, false);
+				fail("This should fail with an exception");
+			}
+			catch (ProgramInvocationException e) {
+				// bam!
+			}
+			catch (Exception e) {
+				fail("wrong exception");
+			}
 
-	@Test(expected = ProgramInvocationException.class)
-	public void shouldThrowException() throws Exception {
-		when(mockJobClient.submitJobDetached(any(JobGraph.class),
-				any(ActorRef.class), any(FiniteDuration.class))).thenReturn(mockSubmissionFailure);
+			verify(this.compilerMock, times(1)).compile(any(Plan.class));
+			verify(this.generatorMock, times(1)).compileJobGraph(any(OptimizedPlan.class));
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+	}
 
-		Client out = new Client(configMock, getClass().getClassLoader());
-		out.run(program.getPlanWithJars(), -1, false);
-		program.deleteExtractedLibraries();
+	/**
+	 * This test verifies that the local execution environment cannot be created when
+	 * the program is submitted through a client.
+	 */
+	@Test
+	public void tryLocalExecution() {
+		try {
+			PackagedProgram packagedProgramMock = mock(PackagedProgram.class);
+
+			when(packagedProgramMock.isUsingInteractiveMode()).thenReturn(true);
+
+			doAnswer(new Answer<Void>() {
+				@Override
+				public Void answer(InvocationOnMock invocation) throws Throwable {
+					ExecutionEnvironment.createLocalEnvironment();
+					return null;
+				}
+			}).when(packagedProgramMock).invokeInteractiveModeForExecution();
+
+			try {
+				new Client(config, getClass().getClassLoader()).run(packagedProgramMock, 1, true);
+				fail("Creating the local execution environment should not be possible");
+			}
+			catch (InvalidProgramException e) {
+				// that is what we want
+			}
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
 	}
 
-	@Test(expected = InvalidProgramException.class)
-	public void tryLocalExecution() throws Exception {
-		PackagedProgram packagedProgramMock = mock(PackagedProgram.class);
+	// --------------------------------------------------------------------------------------------
 
-		when(packagedProgramMock.isUsingInteractiveMode()).thenReturn(true);
+	public static class SuccessReturningActor extends UntypedActor {
 
-		doAnswer(new Answer<Void>() {
-			@Override
-			public Void answer(InvocationOnMock invocation) throws Throwable {
-				ExecutionEnvironment.createLocalEnvironment();
-				return null;
-			}
-		}).when(packagedProgramMock).invokeInteractiveModeForExecution();
+		@Override
+		public void onReceive(Object message) throws Exception {
+			getSender().tell(new JobManagerMessages.SubmissionSuccess(new JobID()), getSelf());
+		}
+	}
+
+	public static class FailureReturningActor extends UntypedActor {
 
-		new Client(configMock, getClass().getClassLoader()).run(packagedProgramMock, 1, true);
+		@Override
+		public void onReceive(Object message) throws Exception {
+			getSender().tell(new JobManagerMessages.SubmissionFailure(new JobID(), new Exception("test")), getSelf());
+		}
 	}
 }
diff --git a/flink-core/src/main/java/org/apache/flink/api/common/JobExecutionResult.java b/flink-core/src/main/java/org/apache/flink/api/common/JobExecutionResult.java
index dd0f057a0f5..406cfe9cd3d 100644
--- a/flink-core/src/main/java/org/apache/flink/api/common/JobExecutionResult.java
+++ b/flink-core/src/main/java/org/apache/flink/api/common/JobExecutionResult.java
@@ -16,38 +16,69 @@
  * limitations under the License.
  */
 
-
 package org.apache.flink.api.common;
 
 import java.util.Map;
 
+/**
+ * The result of a job execution. Gives access to the execution time of the job,
+ * and to all accumulators created by this job.
+ */
 public class JobExecutionResult {
 
 	private long netRuntime;
 	private Map<String, Object> accumulatorResults;
 
+	/**
+	 * Creates a new JobExecutionResult.
+	 *
+	 * @param netRuntime The net runtime of the job (excluding pre-flight phase like the optimizer)
+	 * @param accumulators A map of all accumulators produced by the job.
+	 */
 	public JobExecutionResult(long netRuntime, Map<String, Object> accumulators) {
 		this.netRuntime = netRuntime;
 		this.accumulatorResults = accumulators;
 	}
-	
+
+	/**
+	 * Gets the net execution time of the job, i.e., the execution time in the parallel system,
+	 * without the pre-flight steps like the optimizer.
+	 *
+	 * @return The net execution time.
+	 */
 	public long getNetRuntime() {
 		return this.netRuntime;
 	}
 
+	/**
+	 * Gets the accumulator with the given name. Returns {@code null}, if no accumulator with
+	 * that name was produced.
+	 *
+	 * @param accumulatorName The name of the accumulator.
+	 * @param <T> The generic type of the accumulator value.
+	 * @return The value of the accumulator with the given name.
+	 */
 	@SuppressWarnings("unchecked")
 	public <T> T getAccumulatorResult(String accumulatorName) {
 		return (T) this.accumulatorResults.get(accumulatorName);
 	}
 
+	/**
+	 * Gets all accumulators produced by the job. The map contains the accumulators as
+	 * mappings from the accumulator name to the accumulator value.
+	 *
+	 * @return A map containing all accumulators produced by the job.
+	 */
 	public Map<String, Object> getAllAccumulatorResults() {
 		return this.accumulatorResults;
 	}
 	
 	/**
-	 * @param accumulatorName
-	 *            Name of the counter
+	 * Gets the accumulator with the given name as an integer.
+	 *
+	 * @param accumulatorName Name of the counter
 	 * @return Result of the counter, or null if the counter does not exist
+	 * @throws java.lang.ClassCastException Thrown, if the accumulator was not aggregating a {@link java.lang.Integer}
 	 */
 	public Integer getIntCounterResult(String accumulatorName) {
 		Object result = this.accumulatorResults.get(accumulatorName);
@@ -62,5 +93,4 @@ public class JobExecutionResult {
 	}
 
 	// TODO Create convenience methods for the other shipped accumulator types
-
 }
diff --git a/flink-core/src/main/java/org/apache/flink/configuration/ConfigConstants.java b/flink-core/src/main/java/org/apache/flink/configuration/ConfigConstants.java
index 87a3d5f2256..a0bf3656a46 100644
--- a/flink-core/src/main/java/org/apache/flink/configuration/ConfigConstants.java
+++ b/flink-core/src/main/java/org/apache/flink/configuration/ConfigConstants.java
@@ -65,11 +65,6 @@ public final class ConfigConstants {
 	 * for communication with the job manager.
 	 */
 	public static final String JOB_MANAGER_IPC_PORT_KEY = "jobmanager.rpc.port";
-	
-	/**
-	 * The config parameter defining the number of handler threads for the jobmanager RPC service.
-	 */
-	public static final String JOB_MANAGER_IPC_HANDLERS_KEY = "jobmanager.rpc.numhandler";
 
 	/**
 	 * The config parameter defining the number of seconds that a task manager heartbeat may be missing before it is
@@ -362,6 +357,11 @@ public final class ConfigConstants {
 	 * Timeout for all blocking calls
 	 */
 	public static final String AKKA_ASK_TIMEOUT = "akka.ask.timeout";
+
+	/**
+	 * Timeout for all blocking calls
+	 */
+	public static final String AKKA_LOOKUP_TIMEOUT = "akka.lookup.timeout";
 	
 	// ----------------------------- Miscellaneous ----------------------------
 	
@@ -399,11 +399,6 @@ public final class ConfigConstants {
 	 * The default network port to connect to for communication with the job manager.
 	 */
 	public static final int DEFAULT_JOB_MANAGER_IPC_PORT = 6123;
-
-	/**
-	 * The default number of handler threads for the jobmanager RPC service.
-	 */
-	public static final int DEFAULT_JOB_MANAGER_IPC_HANDLERS = 8;
 	
 	/**
 	 * Default number of seconds after which a task manager is marked as failed.
@@ -604,6 +599,8 @@ public final class ConfigConstants {
 	public static String DEFAULT_AKKA_FRAMESIZE = "10485760b";
 
 	public static String DEFAULT_AKKA_ASK_TIMEOUT = "100 s";
+
+	public static String DEFAULT_AKKA_LOOKUP_TIMEOUT = "10 s";
 	
 
 	// ----------------------------- LocalExecution ----------------------------
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/client/JobExecutionException.java b/flink-runtime/src/main/java/org/apache/flink/runtime/client/JobExecutionException.java
index 8657329c766..f35f4127c8d 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/client/JobExecutionException.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/client/JobExecutionException.java
@@ -16,48 +16,46 @@
  * limitations under the License.
  */
 
-
 package org.apache.flink.runtime.client;
 
 /**
- * This exception is thrown by the {@link JobClient} if a Nephele job has been aborted either as a result of a user
+ * This exception is thrown by the {@link JobClient} if a job has been aborted either as a result of a user
  * request or an error which occurred during the execution.
- * 
  */
 public class JobExecutionException extends Exception {
 
-	/**
-	 * The generated serial UID.
-	 */
+	public static enum ExecutionErrorCause {
+		CANCELED,
+		TIMEOUT_TO_JOB_MANAGER,
+		ERROR
+	}
+
+	// ------------------------------------------------------------------------
+
 	private static final long serialVersionUID = 2818087325120827525L;
 
-	/**
-	 * Indicates whether the job has been aborted as a result of user request.
-	 */
-	private final boolean canceledByUser;
+	private final ExecutionErrorCause cause;
 
 	/**
 	 * Constructs a new job execution exception.
 	 * 
-	 * @param msg
-	 *        the message that shall be encapsulated by this exception
-	 * @param canceledByUser
-	 *        <code>true</code> if the job has been aborted as a result of a user request, <code>false</code> otherwise
+	 * @param msg The message that shall be encapsulated by this exception.
+	 * @param cause The cause for the execution exception.
 	 */
-	public JobExecutionException(final String msg, final boolean canceledByUser) {
+	public JobExecutionException(String msg, ExecutionErrorCause cause) {
 		super(msg);
-
-		this.canceledByUser = canceledByUser;
+		this.cause = cause;
 	}
 
-	/**
-	 * Returns <code>true</code> if the job has been aborted as a result of a user request, <code>false</code>
-	 * otherwise.
-	 * 
-	 * @return <code>true</code> if the job has been aborted as a result of a user request, <code>false</code> otherwise
-	 */
 	public boolean isJobCanceledByUser() {
+		return cause == ExecutionErrorCause.CANCELED;
+	}
+
+	public boolean isConnectionTimedOut() {
+		return cause == ExecutionErrorCause.TIMEOUT_TO_JOB_MANAGER;
+	}
 
-		return this.canceledByUser;
+	public boolean isError() {
+		return cause == ExecutionErrorCause.ERROR;
 	}
 }
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/JobGraph.java b/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/JobGraph.java
index 35614208338..58f4e3ab55b 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/JobGraph.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/JobGraph.java
@@ -363,6 +363,15 @@ public class JobGraph implements Serializable {
 		}
 	}
 
+	/**
+	 * Checks whether the JobGraph has user code JAR files attached.
+	 *
+	 * @return True, if the JobGraph has user code JAR files attached, false otherwise.
+	 */
+	public boolean hasUsercodeJarFiles() {
+		return this.userJars.size() > 0;
+	}
+
 	/**
 	 * Returns a set of BLOB keys referring to the JAR files required to run this job.
 	 *
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/TaskInputSplitProvider.java b/flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/TaskInputSplitProvider.java
index 8e079b94e09..16ca090d80e 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/TaskInputSplitProvider.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/TaskInputSplitProvider.java
@@ -70,6 +70,10 @@ public class TaskInputSplitProvider implements InputSplitProvider {
 
 			final Object result = Await.result(response, timeout);
 
+			if (result == null) {
+				return null;
+			}
+
 			if(!(result instanceof TaskManagerMessages.NextInputSplit)){
 				throw new RuntimeException("RequestNextInputSplit requires a response of type " +
 						"NextInputSplit. Instead response is of type " + result.getClass() + ".");
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/akka/AkkaUtils.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/akka/AkkaUtils.scala
index 0f4b5e0016c..2c9daadfd01 100644
--- a/flink-runtime/src/main/scala/org/apache/flink/runtime/akka/AkkaUtils.scala
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/akka/AkkaUtils.scala
@@ -21,8 +21,10 @@ package org.apache.flink.runtime.akka
 import java.io.IOException
 import java.util.concurrent.{TimeUnit, Callable}
 
-import akka.actor.{ActorSelection, ActorRef, ActorSystem}
+import akka.actor.Actor.Receive
+import akka.actor._
 import akka.pattern.{Patterns, ask => akkaAsk}
+import akka.remote.{RemotingLifecycleEvent, AssociationEvent}
 import com.typesafe.config.{Config, ConfigFactory}
 import org.apache.flink.configuration.{ConfigConstants, Configuration}
 import org.slf4j.LoggerFactory
@@ -177,26 +179,33 @@ object AkkaUtils {
 
     val startupTimeout = configuration.getString(ConfigConstants.AKKA_STARTUP_TIMEOUT,
       akkaAskTimeout.toString)
-    val transportHeartbeatInterval = configuration.getString(ConfigConstants.
-      AKKA_TRANSPORT_HEARTBEAT_INTERVAL,
+
+    val transportHeartbeatInterval = configuration.getString(
+      ConfigConstants.AKKA_TRANSPORT_HEARTBEAT_INTERVAL,
       ConfigConstants.DEFAULT_AKKA_TRANSPORT_HEARTBEAT_INTERVAL)
-    val transportHeartbeatPause = configuration.getString(ConfigConstants.
-      AKKA_TRANSPORT_HEARTBEAT_PAUSE,
+
+    val transportHeartbeatPause = configuration.getString(
+      ConfigConstants.AKKA_TRANSPORT_HEARTBEAT_PAUSE,
       ConfigConstants.DEFAULT_AKKA_TRANSPORT_HEARTBEAT_PAUSE)
+
     val transportThreshold = configuration.getDouble(ConfigConstants.AKKA_TRANSPORT_THRESHOLD,
       ConfigConstants.DEFAULT_AKKA_TRANSPORT_THRESHOLD)
-    val watchHeartbeatInterval = configuration.getString(ConfigConstants
-      .AKKA_WATCH_HEARTBEAT_INTERVAL, (akkaAskTimeout/10).toString)
+
+    val watchHeartbeatInterval = configuration.getString(
+        ConfigConstants.AKKA_WATCH_HEARTBEAT_INTERVAL, (akkaAskTimeout/10).toString)
+
     val watchHeartbeatPause = configuration.getString(ConfigConstants.AKKA_WATCH_HEARTBEAT_PAUSE,
       akkaAskTimeout.toString)
+
     val watchThreshold = configuration.getDouble(ConfigConstants.AKKA_WATCH_THRESHOLD,
       ConfigConstants.DEFAULT_AKKA_WATCH_THRESHOLD)
+
     val akkaTCPTimeout = configuration.getString(ConfigConstants.AKKA_TCP_TIMEOUT,
       akkaAskTimeout.toString)
+
     val akkaFramesize = configuration.getString(ConfigConstants.AKKA_FRAMESIZE,
       ConfigConstants.DEFAULT_AKKA_FRAMESIZE)
-    val akkaThroughput = configuration.getInteger(ConfigConstants.AKKA_DISPATCHER_THROUGHPUT,
-      ConfigConstants.DEFAULT_AKKA_DISPATCHER_THROUGHPUT)
+
     val lifecycleEvents = configuration.getBoolean(ConfigConstants.AKKA_LOG_LIFECYCLE_EVENTS,
       ConfigConstants.DEFAULT_AKKA_LOG_LIFECYCLE_EVENTS)
 
@@ -261,35 +270,42 @@ object AkkaUtils {
   }
 
   def getLogLevel: String = {
-    if(LOG.isDebugEnabled) {
-      "DEBUG"
+    if (LOG.isTraceEnabled) {
+      "TRACE"
     } else {
-      if (LOG.isInfoEnabled) {
-        "INFO"
+      if (LOG.isDebugEnabled) {
+        "DEBUG"
       } else {
-        if(LOG.isWarnEnabled){
-          "WARNING"
+        if (LOG.isInfoEnabled) {
+          "INFO"
         } else {
-          if (LOG.isErrorEnabled) {
-            "ERROR"
+          if (LOG.isWarnEnabled) {
+            "WARNING"
           } else {
-            "OFF"
+            if (LOG.isErrorEnabled) {
+              "ERROR"
+            } else {
+              "OFF"
+            }
           }
         }
       }
     }
   }
 
-  def getChild(parent: ActorRef, child: String)(implicit system: ActorSystem, timeout:
-  FiniteDuration): Future[ActorRef] = {
+  def getChild(parent: ActorRef, child: String,
+               system: ActorSystem,
+               timeout: FiniteDuration): Future[ActorRef] = {
     system.actorSelection(parent.path / child).resolveOne()(timeout)
   }
 
-  def getReference(path: String)(implicit system: ActorSystem, timeout: FiniteDuration):
-  Future[ActorRef] = {
+  def getReference(path: String, system:
+                   ActorSystem,
+                   timeout: FiniteDuration): Future[ActorRef] = {
     system.actorSelection(path).resolveOne()(timeout)
   }
 
+
   /**
    * Utility function to construct a future which tries multiple times to execute itself if it
    * fails. If the maximum number of tries are exceeded, then the future fails.
@@ -361,4 +377,17 @@ object AkkaUtils {
 
     new FiniteDuration(duration.toMillis, TimeUnit.MILLISECONDS)
   }
+
+  def getLookupTimeout(config: Configuration): FiniteDuration = {
+    val duration = Duration(config.getString(
+      ConfigConstants.AKKA_LOOKUP_TIMEOUT,
+      ConfigConstants.DEFAULT_AKKA_LOOKUP_TIMEOUT))
+
+    new FiniteDuration(duration.toMillis, TimeUnit.MILLISECONDS)
+  }
+
+  def getDefaultLookupTimeout: FiniteDuration = {
+    val duration = Duration(ConfigConstants.DEFAULT_AKKA_LOOKUP_TIMEOUT)
+    new FiniteDuration(duration.toMillis, TimeUnit.MILLISECONDS)
+  }
 }
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/client/JobClient.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/client/JobClient.scala
index eec10122268..60aefe45b87 100644
--- a/flink-runtime/src/main/scala/org/apache/flink/runtime/client/JobClient.scala
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/client/JobClient.scala
@@ -35,13 +35,12 @@ import org.apache.flink.runtime.messages.JobManagerMessages._
 
 import scala.concurrent.{TimeoutException, Await}
 import scala.concurrent.duration.FiniteDuration
-import scala.util.Success
 
 /**
  * Actor which constitutes the bridge between the non-actor code and the JobManager. The JobClient
  * is used to submit jobs to the JobManager and to request the port of the BlobManager.
  *
- * @param jobManager ActorRef to jobmanager
+ * @param jobManager ActorRef to JobManager
  */
 class JobClient(jobManager: ActorRef) extends
 Actor with ActorLogMessages with ActorLogging {
@@ -74,16 +73,23 @@ ActorLogging {
     case SubmissionFailure(_, t) =>
       jobSubmitter ! Failure(t)
       self ! PoisonPill
+
     case SubmissionSuccess(_) =>
+
     case JobResultSuccess(_, duration, accumulatorResults) =>
       jobSubmitter ! new JobExecutionResult(duration, accumulatorResults)
       self ! PoisonPill
+
     case JobResultCanceled(_, msg) =>
-      jobSubmitter ! Failure(new JobExecutionException(msg, true))
+      jobSubmitter ! Failure(
+        new JobExecutionException(msg, JobExecutionException.ExecutionErrorCause.CANCELED))
       self ! PoisonPill
+
     case JobResultFailed(_, msg) =>
-      jobSubmitter ! Failure(new JobExecutionException(msg, false))
+      jobSubmitter ! Failure(new JobExecutionException(msg,
+        JobExecutionException.ExecutionErrorCause.ERROR))
       self ! PoisonPill
+
     case msg =>
       // we have to use System.out.println here to avoid erroneous behavior for output redirection
       System.out.println(msg.toString)
@@ -94,38 +100,49 @@ ActorLogging {
  * JobClient's companion object containing convenience functions to start a JobClient actor, parse
  * the configuration to extract the JobClient's settings and convenience functions to submit jobs.
  */
-object JobClient{
+object JobClient {
+
   val JOB_CLIENT_NAME = "jobclient"
 
-  def startActorSystemAndActor(config: Configuration, localActorSystem: Boolean):
-  (ActorSystem, ActorRef) = {
+  @throws(classOf[IOException])
+  def startActorSystemAndActor(config: Configuration,
+                               localActorSystem: Boolean): (ActorSystem, ActorRef) = {
+
     // start a remote actor system to listen on an arbitrary port
-    implicit val actorSystem = AkkaUtils.createActorSystem(configuration = config,
-      listeningAddress = Some(("", 0)))
+    val actorSystem = AkkaUtils.createActorSystem(configuration = config,
+                                                  listeningAddress = Some(("", 0)))
+    try {
+      val jobClientActor = createJobClientFromConfig(config, localActorSystem, actorSystem)
+      (actorSystem, jobClientActor)
+    }
+    catch {
+      case t: Throwable => {
+        actorSystem.shutdown()
+        throw t
+      }
+    }
+  }
 
-    (actorSystem, startActorWithConfiguration(config, localActorSystem))
+  @throws(classOf[IOException])
+  def createJobClientFromConfig(config: Configuration,
+                                localActorSystem: Boolean,
+                                actorSystem: ActorSystem): ActorRef = {
+
+    val jobManagerAddress = getJobManagerUrlFromConfig(config, localActorSystem)
+    createJobClient(jobManagerAddress, actorSystem, config)
   }
 
-  def startActor(jobManagerURL: String)(implicit actorSystem: ActorSystem, timeout: FiniteDuration):
-  ActorRef = {
-    val jobManagerFuture = AkkaUtils.getReference(jobManagerURL)(actorSystem, timeout)
+  @throws(classOf[IOException])
+  def createJobClient(jobManagerURL: String,
+                      actorSystem: ActorSystem,
+                      config: Configuration): ActorRef = {
 
-    val jobManager = try {
-      Await.result(jobManagerFuture, timeout)
-    } catch {
-      case ex: Exception =>
-        throw new RuntimeException("Could not connect to JobManager at " + jobManagerURL + ".")
-    }
+    val timeout = AkkaUtils.getLookupTimeout(config)
+    val jobManager = JobManager.getJobManagerRemoteReference(jobManagerURL, actorSystem, timeout)
 
     actorSystem.actorOf(Props(classOf[JobClient], jobManager), JOB_CLIENT_NAME)
   }
 
-  def startActorWithConfiguration(config: Configuration, localActorSystem: Boolean)
-                                 (implicit actorSystem: ActorSystem): ActorRef = {
-    implicit val timeout = AkkaUtils.getTimeout(config)
-
-    startActor(parseConfiguration(config, localActorSystem))
-  }
 
   /**
    * Extracts the JobManager's Akka URL from the configuration. If localActorSystem is true, then
@@ -137,22 +154,25 @@ object JobClient{
    *                          otherwise false
    * @return Akka URL of the JobManager
    */
-  def parseConfiguration(configuration: Configuration, localActorSystem: Boolean): String = {
-    if(localActorSystem){
+  def getJobManagerUrlFromConfig(configuration: Configuration,
+                                 localActorSystem: Boolean): String = {
+    if (localActorSystem) {
       // JobManager and JobClient run in the same ActorSystem
-      JobManager.getLocalAkkaURL
-    }else{
-      val jobManagerAddress = configuration.getString(ConfigConstants
-          .JOB_MANAGER_IPC_ADDRESS_KEY, null)
-      val jobManagerRPCPort = configuration.getInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY,
-          ConfigConstants.DEFAULT_JOB_MANAGER_IPC_PORT)
+      JobManager.getLocalJobManagerAkkaURL
+    } else {
+      val jobManagerAddress = configuration.getString(
+        ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, null)
+
+      val jobManagerRPCPort = configuration.getInteger(
+        ConfigConstants.JOB_MANAGER_IPC_PORT_KEY,
+        ConfigConstants.DEFAULT_JOB_MANAGER_IPC_PORT)
 
       if (jobManagerAddress == null) {
-        throw new RuntimeException("JobManager address has not been specified in the " +
-          "configuration.")
+        throw new RuntimeException(
+          "JobManager address has not been specified in the configuration.")
       }
 
-      JobManager.getRemoteAkkaURL(jobManagerAddress + ":" + jobManagerRPCPort)
+      JobManager.getRemoteJobManagerAkkaURL(jobManagerAddress + ":" + jobManagerRPCPort)
     }
   }
 
@@ -167,7 +187,8 @@ object JobClient{
    *                             corresponding job, otherwise false
    * @param jobClient ActorRef to the JobClient
    * @param timeout Timeout for futures
-   * @throws org.apache.flink.runtime.client.JobExecutionException
+   * @throws org.apache.flink.runtime.client.JobExecutionException Thrown if the job
+   *                                                               execution fails.
    * @return The job execution result
    */
   @throws(classOf[JobExecutionException])
@@ -177,10 +198,10 @@ object JobClient{
     var waitForAnswer = true
     var answer: JobExecutionResult = null
 
-    val result =(jobClient ? SubmitJobAndWait(jobGraph, listenToEvents = listenToStatusEvents))(
+    val result = (jobClient ? SubmitJobAndWait(jobGraph, listenToEvents = listenToStatusEvents))(
       AkkaUtils.INF_TIMEOUT).mapTo[JobExecutionResult]
 
-    while(waitForAnswer) {
+    while (waitForAnswer) {
       try {
         answer = Await.result(result, timeout)
         waitForAnswer = false
@@ -192,8 +213,9 @@ object JobClient{
             Await.result(jmStatus, timeout)
           } catch {
             case t: Throwable =>
-              throw new JobExecutionException("JobManager not reachable anymore. Terminate " +
-                "waiting for job answer.", false)
+              throw new JobExecutionException(
+                "JobManager not reachable anymore. Terminate waiting for job answer.",
+                JobExecutionException.ExecutionErrorCause.TIMEOUT_TO_JOB_MANAGER)
           }
       }
     }
@@ -216,7 +238,7 @@ object JobClient{
   SubmissionResponse = {
     val response = (jobClient ? SubmitJobDetached(jobGraph))(timeout)
 
-    Await.result(response.mapTo[SubmissionResponse],timeout)
+    Await.result(response.mapTo[SubmissionResponse], timeout)
   }
 
   /**
@@ -228,23 +250,24 @@ object JobClient{
    * @param hostname Hostname of the instance on which the BlobServer and also the JobManager run
    * @param jobClient ActorRef to the JobClient
    * @param timeout Timeout for futures
-   * @throws IOException
-   * @return
+   * @throws IOException Thrown, if the file upload to the JobManager failed.
    */
   @throws(classOf[IOException])
-  def uploadJarFiles(jobGraph: JobGraph, hostname: String, jobClient: ActorRef)(implicit timeout:
-   FiniteDuration): Unit = {
+  def uploadJarFiles(jobGraph: JobGraph, hostname: String, jobClient: ActorRef)(
+    implicit timeout: FiniteDuration): Unit = {
 
-    val futureBlobPort = Patterns.ask(jobClient, RequestBlobManagerPort, timeout).mapTo[Int]
+    if (jobGraph.hasUsercodeJarFiles()) {
+      val futureBlobPort = Patterns.ask(jobClient, RequestBlobManagerPort, timeout).mapTo[Int]
 
-    val port = try {
-      Await.result(futureBlobPort, timeout)
-    } catch {
-      case e:Exception => throw new IOException("Could not retrieve the server's blob port.", e)
-    }
+      val port = try {
+        Await.result(futureBlobPort, timeout)
+      } catch {
+        case e: Exception => throw new IOException("Could not retrieve the server's blob port.", e)
+      }
 
-    val serverAddress = new InetSocketAddress(hostname, port)
+      val serverAddress = new InetSocketAddress(hostname, port)
 
-    jobGraph.uploadRequiredJarFiles(serverAddress)
+      jobGraph.uploadRequiredJarFiles(serverAddress)
+    }
   }
 }
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManager.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManager.scala
index 3cb86871075..1682443cabe 100644
--- a/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManager.scala
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManager.scala
@@ -51,7 +51,7 @@ import org.slf4j.LoggerFactory
 import akka.actor._
 import akka.pattern.ask
 
-import scala.concurrent.Future
+import scala.concurrent._
 import scala.concurrent.duration._
 import scala.language.postfixOps
 import scala.collection.JavaConverters._
@@ -560,6 +560,11 @@ class JobManager(val configuration: Configuration,
   }
 }
 
+/**
+ * Job Manager companion object. Contains the entry point (main method) to run the JobManager in a
+ * standalone fashion. Also contains various utility methods to start the JobManager and to
+ * look up the JobManager actor reference.
+ */
 object JobManager {
   
   import ExecutionMode._
@@ -573,6 +578,12 @@ object JobManager {
   val ARCHIVE_NAME = "archive"
   val PROFILER_NAME = "profiler"
 
+
+  /**
+   * Entry point (main method) to run the JobManager in a standalone fashion.
+   *
+   * @param args The command line arguments.
+   */
   def main(args: Array[String]): Unit = {
 
     // startup checks and logging
@@ -833,34 +844,140 @@ object JobManager {
     actorSystem.actorOf(props, JOB_MANAGER_NAME)
   }
 
-  def getRemoteAkkaURL(address: String): String = {
+  // --------------------------------------------------------------------------
+  //  Resolving the JobManager endpoint
+  // --------------------------------------------------------------------------
+
+  /**
+   * Builds the akka actor path for the JobManager actor, given the address (host:port)
+   * where the JobManager's actor system runs.
+   *
+   * @param address The address (host:port) of the JobManager's actor system.
+   * @return The akka URL of the JobManager actor.
+   */
+  def getRemoteJobManagerAkkaURL(address: String): String = {
     s"akka.tcp://flink@$address/user/$JOB_MANAGER_NAME"
   }
 
-  def getRemoteAkkaURL(address : InetSocketAddress): String = {
-    getRemoteAkkaURL(address.getHostName + ":" + address.getPort)
+  /**
+   * Builds the akka actor path for the JobManager actor, given the socket address
+   * where the JobManager's actor system runs.
+   *
+   * @param address The address of the JobManager's actor system.
+   * @return The akka URL of the JobManager actor.
+   */
+  def getRemoteJobManagerAkkaURL(address: InetSocketAddress): String = {
+    getRemoteJobManagerAkkaURL(address.getAddress().getHostAddress() + ":" + address.getPort)
   }
 
-  def getLocalAkkaURL: String = {
-    s"akka://flink/user/$JOB_MANAGER_NAME"
+  /**
+   * Builds the akka actor path for the JobManager actor to address the actor within
+   * its own actor system.
+   *
+   * @return The local akka URL of the JobManager actor.
+   */
+  def getLocalJobManagerAkkaURL: String = {
+    "akka://flink/user/" + JOB_MANAGER_NAME
   }
 
-  def getJobManager(address: InetSocketAddress)(implicit system: ActorSystem, timeout:
-  FiniteDuration): Future[ActorRef] = {
-    AkkaUtils.getReference(getRemoteAkkaURL(address))
+  def getJobManagerRemoteReferenceFuture(address: InetSocketAddress,
+                                   system: ActorSystem,
+                                   timeout: FiniteDuration): Future[ActorRef] = {
+
+    AkkaUtils.getReference(getRemoteJobManagerAkkaURL(address), system, timeout)
   }
 
+  /**
+   * Resolves the JobManager actor reference in a blocking fashion.
+   *
+   * @param jobManagerUrl The akka URL of the JobManager.
+   * @param system The local actor system that should perform the lookup.
+   * @param timeout The maximum time to wait until the lookup fails.
+   * @throws java.io.IOException Thrown, if the lookup fails.
+   * @return The ActorRef to the JobManager
+   */
+  @throws(classOf[IOException])
+  def getJobManagerRemoteReference(jobManagerUrl: String,
+                                   system: ActorSystem,
+                                   timeout: FiniteDuration): ActorRef = {
+    try {
+      val future = AkkaUtils.getReference(jobManagerUrl, system, timeout)
+      Await.result(future, timeout)
+    }
+    catch {
+      case e @ (_ : ActorNotFound | _ : TimeoutException) =>
+        throw new IOException(
+          s"JobManager at $jobManagerUrl not reachable. " +
+            s"Please make sure that the JobManager is running and its port is reachable.", e)
+
+      case e: IOException =>
+        throw new IOException("Could not connect to JobManager at " + jobManagerUrl, e)
+    }
+  }
+
+  /**
+   * Resolves the JobManager actor reference in a blocking fashion.
+   *
+   * @param address The socket address of the JobManager's actor system.
+   * @param system The local actor system that should perform the lookup.
+   * @param timeout The maximum time to wait until the lookup fails.
+   * @throws java.io.IOException Thrown, if the lookup fails.
+   * @return The ActorRef to the JobManager
+   */
+  @throws(classOf[IOException])
+  def getJobManagerRemoteReference(address: InetSocketAddress,
+                                   system: ActorSystem,
+                                   timeout: FiniteDuration): ActorRef = {
+
+    val jmAddress = getRemoteJobManagerAkkaURL(address)
+    getJobManagerRemoteReference(jmAddress, system, timeout)
+  }
+
+  /**
+   * Resolves the JobManager actor reference in a blocking fashion.
+   *
+   * @param address The socket address of the JobManager's actor system.
+   * @param system The local actor system that should perform the lookup.
+   * @param config The config describing the maximum time to wait until the lookup fails.
+   * @throws java.io.IOException Thrown, if the lookup fails.
+   * @return The ActorRef to the JobManager
+   */
+  @throws(classOf[IOException])
+  def getJobManagerRemoteReference(address: InetSocketAddress,
+                                   system: ActorSystem,
+                                   config: Configuration): ActorRef = {
+
+    val timeout = AkkaUtils.getLookupTimeout(config)
+    getJobManagerRemoteReference(address, system, timeout)
+  }
+
+
+
+  // --------------------------------------------------------------------------
+  //  Miscellaneous Utils
+  // --------------------------------------------------------------------------
+
+  /**
+   * Checks whether the Java version is lower than Java 7 (Java 1.7) and
+   * prints a warning message in that case.
+   */
   private def checkJavaVersion(): Unit = {
-    if (System.getProperty("java.version").substring(0, 3).toDouble < 1.7) {
-      LOG.warn("Flink has been started with Java 6. " +
-        "Java 6 is not maintained any more by Oracle or the OpenJDK community. " +
-        "Flink may drop support for Java 6 in future releases, due to the " +
-        "unavailability of bug fixes security patches.")
+    try {
+      if (System.getProperty("java.version").substring(0, 3).toDouble < 1.7) {
+        LOG.warn("Flink has been started with Java 6. " +
+          "Java 6 is not maintained any more by Oracle or the OpenJDK community. " +
+          "Flink may drop support for Java 6 in future releases, due to the " +
+          "unavailability of bug fixes security patches.")
+      }
+    }
+    catch {
+      case e: Exception => 
+        LOG.warn("Could not parse java version for startup checks")
+        LOG.debug("Exception when parsing java version", e)
     }
   }
 
   // --------------------------------------------------------------------------
 
   class ParseException(message: String) extends Exception(message) {}
-  
 }
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/minicluster/LocalFlinkMiniCluster.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/minicluster/LocalFlinkMiniCluster.scala
index 450480af563..c24d96a7c82 100644
--- a/flink-runtime/src/main/scala/org/apache/flink/runtime/minicluster/LocalFlinkMiniCluster.scala
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/minicluster/LocalFlinkMiniCluster.scala
@@ -107,8 +107,8 @@ class LocalFlinkMiniCluster(userConfiguration: Configuration, singleActorSystem:
         config.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, HOSTNAME)
         config.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, getJobManagerRPCPort)
 
-        val jc = JobClient.startActorWithConfiguration(config,
-          singleActorSystem)(jobClientActorSystem)
+        val jc = JobClient.createJobClientFromConfig(config, singleActorSystem,
+                                                            jobClientActorSystem)
         jobClient = Some(jc)
         jc
     }
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/taskmanager/TaskManager.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/taskmanager/TaskManager.scala
index 534f7b51f86..4a0ae72b033 100644
--- a/flink-runtime/src/main/scala/org/apache/flink/runtime/taskmanager/TaskManager.scala
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/taskmanager/TaskManager.scala
@@ -820,7 +820,7 @@ object TaskManager {
 
     val jobManagerURL = if (localAkkaCommunication) {
       // JobManager and TaskManager are in the same ActorSystem -> Use local Akka URL
-      JobManager.getLocalAkkaURL
+      JobManager.getLocalJobManagerAkkaURL
     } else {
       val jobManagerAddress = configuration.getString(ConfigConstants
           .JOB_MANAGER_IPC_ADDRESS_KEY, null)
@@ -832,7 +832,7 @@ object TaskManager {
           "configuration.")
       }
 
-      JobManager.getRemoteAkkaURL(jobManagerAddress + ":" + jobManagerRPCPort)
+      JobManager.getRemoteJobManagerAkkaURL(jobManagerAddress + ":" + jobManagerRPCPort)
     }
 
     val slots = configuration.getInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, 1)
diff --git a/flink-runtime/src/test/scala/org/apache/flink/runtime/jobmanager/JobManagerConnectionTest.scala b/flink-runtime/src/test/scala/org/apache/flink/runtime/jobmanager/JobManagerConnectionTest.scala
new file mode 100644
index 00000000000..9c329d1cf10
--- /dev/null
+++ b/flink-runtime/src/test/scala/org/apache/flink/runtime/jobmanager/JobManagerConnectionTest.scala
@@ -0,0 +1,171 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.runtime.jobmanager
+
+import java.io.IOException
+import java.net.{InetAddress, InetSocketAddress}
+import java.util.concurrent.TimeUnit
+import java.util.concurrent.atomic.{AtomicBoolean, AtomicReference}
+
+import org.apache.flink.configuration.{ConfigConstants, Configuration}
+import org.apache.flink.runtime.akka.AkkaUtils
+import org.apache.flink.runtime.net.NetUtils
+import org.junit.Assert._
+import org.junit.Test
+
+import scala.concurrent.duration.Duration
+
+class JobManagerConnectionTest {
+
+  private val timeout = 1000
+
+  /**
+   * Tests that a lookup of a local JobManager fails within a given timeout if the JobManager
+   * actor is not reachable.
+   */
+  @Test
+  def testResolveUnreachableActorLocalHost() : Unit = {
+    // startup a test actor system listening at an arbitrary address
+    val actorSystem = AkkaUtils.createActorSystem(new Configuration(), Some(("", 0)))
+
+    try {
+      // get a port that we know is unoccupied
+      val freePort = try {
+        NetUtils.getAvailablePort()
+      } catch {
+        // abort the test if we cannot find a free port
+        case _ : Throwable => return
+      }
+
+      val endpoint = new InetSocketAddress(InetAddress.getByName("127.0.0.1"), freePort)
+      val config = getConfigWithLowTimeout()
+
+      mustReturnWithinTimeout(Duration(5*timeout, TimeUnit.MILLISECONDS)) {
+        () => {
+          try {
+            JobManager.getJobManagerRemoteReference(endpoint, actorSystem, config)
+            fail("Should fail since the JobManager is not reachable")
+          }
+          catch {
+            case e: IOException => // good
+          }
+        }
+      }
+    }
+    catch {
+      case e: Exception =>
+        e.printStackTrace()
+        fail(e.getMessage)
+    }
+    finally {
+      actorSystem.shutdown()
+    }
+  }
+
+  /**
+   * Tests that a lookup of a local JobManager fails within a given timeout if the JobManager
+   * actor is not reachable.
+   */
+  @Test
+  def testResolveUnreachableActorRemoteHost() : Unit = {
+    // startup a test actor system listening at an arbitrary address
+    val actorSystem = AkkaUtils.createActorSystem(new Configuration(), Some(("", 0)))
+
+    try {
+      // some address that is not running a JobManager
+      val endpoint = new InetSocketAddress(InetAddress.getByName("10.254.254.254"), 2)
+      val config = getConfigWithLowTimeout()
+
+      mustReturnWithinTimeout(Duration(5*timeout, TimeUnit.MILLISECONDS)) {
+        () => {
+          try {
+            JobManager.getJobManagerRemoteReference(endpoint, actorSystem, config)
+            fail("Should fail since the JobManager is not reachable")
+          }
+          catch {
+            case e: IOException => // good
+          }
+        }
+      }
+    }
+    catch {
+      case e: Exception =>
+        e.printStackTrace()
+        fail(e.getMessage)
+    }
+    finally {
+      actorSystem.shutdown()
+    }
+  }
+
+  private def getConfigWithLowTimeout() : Configuration = {
+    val config = new Configuration()
+    config.setString(ConfigConstants.AKKA_LOOKUP_TIMEOUT,
+                     Duration(timeout, TimeUnit.MILLISECONDS).toSeconds + " s")
+    config
+  }
+
+  private def mustReturnWithinTimeout(timeout: Duration)(task: () => Unit) : Unit = {
+
+    val done = new AtomicBoolean()
+    val error = new AtomicReference[Throwable]()
+
+    val runnable = new Runnable {
+      override def run(): Unit = {
+        try {
+          task()
+          done.set(true)
+        }
+        catch {
+          case t: Throwable => error.set(t)
+        }
+        done.synchronized {
+          done.notifyAll()
+        }
+      }
+    }
+
+    val runner = new Thread(runnable, "Test runner")
+    runner.setDaemon(true)
+
+    var now = System.currentTimeMillis()
+    val deadline = now + timeout.toMillis
+
+    runner.start()
+
+    done.synchronized {
+      while (error.get() == null && !done.get() && now < deadline) {
+        done.wait(deadline - now)
+        now = System.currentTimeMillis()
+      }
+    }
+
+    if (error.get() != null) {
+      error.get().printStackTrace()
+      fail("Exception in the timed call: " + error.get().getMessage())
+    }
+
+    // check if we finished because we were done
+    // otherwise it is a timeout
+    if (!done.get()) {
+      runner.interrupt()
+      fail("Call did not finish within " + timeout)
+    }
+  }
+}
diff --git a/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingUtils.scala b/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingUtils.scala
index 2db1d2bfc9e..4416ba64fad 100644
--- a/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingUtils.scala
+++ b/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingUtils.scala
@@ -35,6 +35,7 @@ import scala.language.postfixOps
  * Convenience functions to test actor based components.
  */
 object TestingUtils {
+
   val testConfig = ConfigFactory.parseString(getDefaultTestingActorSystemConfigString)
 
   val TESTING_DURATION = 2 minute
@@ -54,6 +55,8 @@ object TestingUtils {
     """.stripMargin
   }
 
+  def getDefaultTestingActorSystemConfig = testConfig
+
   def startTestingTaskManagerWithConfiguration(hostname: String, jobManagerURL: String,
                                                config: Configuration)
                                               (implicit system: ActorSystem) = {
diff --git a/flink-yarn/src/main/scala/org/apache/flink/yarn/ApplicationClient.scala b/flink-yarn/src/main/scala/org/apache/flink/yarn/ApplicationClient.scala
index 3204281313b..b8079ab7a9e 100644
--- a/flink-yarn/src/main/scala/org/apache/flink/yarn/ApplicationClient.scala
+++ b/flink-yarn/src/main/scala/org/apache/flink/yarn/ApplicationClient.scala
@@ -64,9 +64,9 @@ class ApplicationClient extends Actor with ActorLogMessages with ActorLogging {
   override def receiveWithLogMessages: Receive = {
     // ----------------------------- Registration -> Status updates -> shutdown ----------------
     case LocalRegisterClient(address: String) =>
-      val jmAkkaUrl = JobManager.getRemoteAkkaURL(address)
+      val jmAkkaUrl = JobManager.getRemoteJobManagerAkkaURL(address)
 
-      val jobManagerFuture = AkkaUtils.getReference(jmAkkaUrl)(system, timeout)
+      val jobManagerFuture = AkkaUtils.getReference(jmAkkaUrl, system, timeout)
 
       jobManagerFuture.onComplete {
         case Success(jm) => self ! JobManagerActorRef(jm)
