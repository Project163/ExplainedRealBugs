diff --git a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/batch/sql/DecimalITCase.scala b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/batch/sql/DecimalITCase.scala
index c1a835206a6..28047c7498c 100644
--- a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/batch/sql/DecimalITCase.scala
+++ b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/batch/sql/DecimalITCase.scala
@@ -28,7 +28,8 @@ import org.apache.flink.table.runtime.types.TypeInfoLogicalTypeConverter.fromLog
 import org.apache.flink.table.types.logical.{DecimalType, LogicalType}
 import org.apache.flink.types.Row
 
-import org.junit.{Assert, Test}
+import org.assertj.core.api.Assertions.assertThat
+import org.junit.jupiter.api.Test
 
 import java.math.{BigDecimal => JBigDecimal}
 
@@ -66,15 +67,16 @@ class DecimalITCase extends BatchTestBase {
     val resultTable = parseQuery(queryX)
     val ts1 = expected.colTypes
     val ts2 = resultTable.getSchema.getFieldDataTypes.map(fromDataTypeToLogicalType)
-    Assert.assertEquals(ts1.length, ts2.length)
+    assertThat(ts1.length).isEqualTo(ts2.length)
 
-    Assert.assertTrue(ts1.zip(ts2).forall { case (t1, t2) => isInteroperable(t1, t2) })
+    assertThat(ts1.zip(ts2).forall { case (t1, t2) => isInteroperable(t1, t2) }).isTrue
 
     def prepareResult(isSorted: Boolean, seq: Seq[Row]) = {
       if (!isSorted) seq.map(_.toString).sortBy(s => s) else seq.map(_.toString)
     }
     val resultRows = executeQuery(resultTable)
-    Assert.assertEquals(prepareResult(isSorted, expected.rows), prepareResult(isSorted, resultRows))
+    assertThat(prepareResult(isSorted, expected.rows))
+      .isEqualTo(prepareResult(isSorted, resultRows))
   }
 
   private def checkQuery1(
diff --git a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/batch/table/DecimalITCase.scala b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/batch/table/DecimalITCase.scala
index 7e76448bfa7..e2c622142bd 100644
--- a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/batch/table/DecimalITCase.scala
+++ b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/planner/runtime/batch/table/DecimalITCase.scala
@@ -25,8 +25,8 @@ import org.apache.flink.table.planner.runtime.utils.BatchTestBase.row
 import org.apache.flink.table.types.DataType
 import org.apache.flink.types.Row
 
-import org.junit.Assert.assertEquals
-import org.junit.Test
+import org.assertj.core.api.Assertions.assertThat
+import org.junit.jupiter.api.Test
 
 import java.math.{BigDecimal => JBigDecimal}
 
@@ -51,16 +51,16 @@ class DecimalITCase extends BatchTestBase {
     // check result schema
     val resultTable = tableTransfer(t)
     val ts2 = resultTable.getResolvedSchema.getColumnDataTypes.asScala
-    assertEquals(expectedColTypes.length, ts2.length)
+    assertThat(expectedColTypes.length).isEqualTo(ts2.length)
 
-    expectedColTypes.zip(ts2).foreach { case (t1, t2) => assertEquals(t1, t2) }
+    expectedColTypes.zip(ts2).foreach { case (t1, t2) => assertThat(t1).isEqualTo(t2) }
 
     def prepareResult(isSorted: Boolean, seq: Seq[Row]) = {
       if (!isSorted) seq.map(_.toString).sortBy(s => s) else seq.map(_.toString)
     }
 
     val resultRows = executeQuery(resultTable)
-    assertEquals(prepareResult(isSorted, expectedRows), prepareResult(isSorted, resultRows))
+    assertThat(prepareResult(isSorted, expectedRows)).isEqualTo(prepareResult(isSorted, resultRows))
   }
 
   // a Seq of one Row
