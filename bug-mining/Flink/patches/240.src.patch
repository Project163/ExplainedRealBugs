diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManager.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManager.scala
index 32a4e373929..ad5c9e83388 100644
--- a/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManager.scala
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManager.scala
@@ -368,12 +368,25 @@ class JobManager(val configuration: Configuration,
       taskManager forward SendStackTrace
 
     case Terminated(taskManager) =>
-      log.info("Task manager {} terminated.", taskManager.path)
-      instanceManager.unregisterTaskManager(taskManager)
-      context.unwatch(taskManager)
+      if(instanceManager.isRegistered(taskManager)) {
+        log.info("Task manager {} terminated.", taskManager.path)
+
+        instanceManager.unregisterTaskManager(taskManager)
+        context.unwatch(taskManager)
+      }
 
     case RequestJobManagerStatus =>
       sender ! JobManagerStatusAlive
+
+    case Disconnect(msg) =>
+      val taskManager = sender
+
+      if(instanceManager.isRegistered(taskManager)){
+        log.info("Task manager {} wants to disconnect, because {}.", taskManager.path, msg)
+
+        instanceManager.unregisterTaskManager(taskManager)
+        context.unwatch(taskManager)
+      }
   }
 
   /**
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/minicluster/FlinkMiniCluster.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/minicluster/FlinkMiniCluster.scala
index 3eb1d1e137e..3679f02a995 100644
--- a/flink-runtime/src/main/scala/org/apache/flink/runtime/minicluster/FlinkMiniCluster.scala
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/minicluster/FlinkMiniCluster.scala
@@ -62,8 +62,7 @@ abstract class FlinkMiniCluster(userConfiguration: Configuration,
   val actorSystemsTaskManagers = for(i <- 0 until numTaskManagers) yield {
     val actorSystem = if(singleActorSystem) {
       jobManagerActorSystem
-    }
-    else{
+    } else {
       startTaskManagerActorSystem(i)
     }
 
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/taskmanager/TaskManager.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/taskmanager/TaskManager.scala
index ae192ce120c..9d157239fe2 100644
--- a/flink-runtime/src/main/scala/org/apache/flink/runtime/taskmanager/TaskManager.scala
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/taskmanager/TaskManager.scala
@@ -152,6 +152,10 @@ import scala.collection.JavaConverters._
   override def postStop(): Unit = {
     log.info("Stopping task manager {}.", self.path)
 
+    currentJobManager foreach {
+      _ ! Disconnect(s"TaskManager ${self.path} is shutting down.")
+    }
+
     cancelAndClearEverything(new Exception("Task Manager is shutting down."))
 
     cleanupTaskManager()
@@ -415,8 +419,8 @@ import scala.collection.JavaConverters._
           new RuntimeEnvironment(jobManager, task, tdd, userCodeClassLoader,
             memoryManager, ioManager, splitProvider, bcVarManager, networkEnvironment.get)
 
-        case None => throw new IllegalStateException("TaskManager has not yet registered at " +
-          "the JobManager.")
+        case None => throw new IllegalStateException("TaskManager has not yet been registered at " +
+          "a JobManager.")
       }
 
       task.setEnvironment(env)
diff --git a/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingCluster.scala b/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingCluster.scala
index 895da46f35a..87fca997d0f 100644
--- a/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingCluster.scala
+++ b/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingCluster.scala
@@ -19,15 +19,12 @@
 package org.apache.flink.runtime.testingUtils
 
 import akka.actor.{ActorRef, Props, ActorSystem}
-import akka.pattern.Patterns.gracefulStop
 import org.apache.flink.configuration.{ConfigConstants, Configuration}
 import org.apache.flink.runtime.jobmanager.{MemoryArchivist, JobManager}
 import org.apache.flink.runtime.minicluster.FlinkMiniCluster
 import org.apache.flink.runtime.net.NetUtils
 import org.apache.flink.runtime.taskmanager.TaskManager
 
-import scala.concurrent.Await
-
 /**
  * Testing cluster which starts the [[JobManager]] and [[TaskManager]] actors with testing support
  * in the same [[ActorSystem]].
@@ -74,11 +71,4 @@ FlinkMiniCluster(userConfiguration, singleActorSystem) {
       networkConnectionConfig) with TestingTaskManager), TaskManager.TASK_MANAGER_NAME + "_" +
       (index + 1))
   }
-    val stopped = gracefulStop(jobManagerActor, TestingUtils.TESTING_DURATION)
-    Await.result(stopped, TestingUtils.TESTING_DURATION)
-
-    jobManagerActorSystem.shutdown()
-    jobManagerActorSystem.awaitTermination()
-
-    jobManagerActorSystem = startJobManagerActorSystem()
 }
diff --git a/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingJobManager.scala b/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingJobManager.scala
index f41e114705f..89cbfe6cf44 100644
--- a/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingJobManager.scala
+++ b/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingJobManager.scala
@@ -25,7 +25,9 @@ import org.apache.flink.runtime.execution.ExecutionState
 import org.apache.flink.runtime.jobgraph.{JobStatus, JobID}
 import org.apache.flink.runtime.jobmanager.{JobManager, MemoryArchivist}
 import org.apache.flink.runtime.messages.ExecutionGraphMessages.JobStatusChanged
+import org.apache.flink.runtime.messages.Messages.Disconnect
 import org.apache.flink.runtime.testingUtils.TestingJobManagerMessages._
+import org.apache.flink.runtime.testingUtils.TestingMessages.DisableDisconnect
 
 import scala.collection.convert.WrapAsScala
 import scala.concurrent.Future
@@ -52,6 +54,8 @@ trait TestingJobManager extends ActorLogMessages with WrapAsScala {
   val waitForJobStatus = scala.collection.mutable.HashMap[JobID,
     collection.mutable.HashMap[JobStatus, Set[ActorRef]]]()
 
+  var disconnectDisabled = false
+
   abstract override def receiveWithLogMessages: Receive = {
     receiveTestingMessages orElse super.receiveWithLogMessages
   }
@@ -125,6 +129,7 @@ trait TestingJobManager extends ActorLogMessages with WrapAsScala {
             listener ! TaskManagerTerminated(taskManager)
         }
       }
+
     case RequestWorkingTaskManager(jobID) =>
       currentJobs.get(jobID) match {
         case Some((eg, _)) =>
@@ -170,6 +175,23 @@ trait TestingJobManager extends ActorLogMessages with WrapAsScala {
       if (cleanup) {
         waitForJobStatus.remove(jobID)
       }
+
+    case DisableDisconnect =>
+      disconnectDisabled = true
+
+    case msg: Disconnect =>
+      if (!disconnectDisabled) {
+        super.receiveWithLogMessages(msg)
+
+        val taskManager = sender
+
+        waitForTaskManagerToBeTerminated.remove(taskManager.path.name) foreach {
+          _ foreach {
+            listener =>
+              listener ! TaskManagerTerminated(taskManager)
+          }
+        }
+      }
   }
 
   def checkIfAllVerticesRunning(jobID: JobID): Boolean = {
diff --git a/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingTaskManager.scala b/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingTaskManager.scala
index 0ecbd046a0b..59106d332b8 100644
--- a/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingTaskManager.scala
+++ b/flink-runtime/src/test/scala/org/apache/flink/runtime/testingUtils/TestingTaskManager.scala
@@ -119,21 +119,18 @@ trait TestingTaskManager extends ActorLogMessages {
       }
 
     case msg:Disconnect =>
-      super.receiveWithLogMessages(msg)
+      if (!disconnectDisabled) {
+        super.receiveWithLogMessages(msg)
 
-      val jobManager = sender
+        val jobManager = sender
 
-      waitForJobManagerToBeTerminated.remove(jobManager.path.name) foreach {
-        _ foreach {
-          _ ! JobManagerTerminated(jobManager)
+        waitForJobManagerToBeTerminated.remove(jobManager.path.name) foreach {
+          _ foreach {
+            _ ! JobManagerTerminated(jobManager)
+          }
         }
       }
 
-    case msg:Disconnect =>
-      if (!disconnectDisabled) {
-        super.receiveWithLogMessages(msg)
-      }
-
     case DisableDisconnect =>
       disconnectDisabled = true
   }
diff --git a/flink-staging/flink-avro/src/test/java/org/apache/flink/api/avro/EncoderDecoderTest.java b/flink-staging/flink-avro/src/test/java/org/apache/flink/api/avro/EncoderDecoderTest.java
index 8f14cb3248f..8f29dca2ce3 100644
--- a/flink-staging/flink-avro/src/test/java/org/apache/flink/api/avro/EncoderDecoderTest.java
+++ b/flink-staging/flink-avro/src/test/java/org/apache/flink/api/avro/EncoderDecoderTest.java
@@ -29,7 +29,6 @@ import java.util.List;
 import java.util.Map;
 import java.util.Random;
 
-import org.apache.avro.generic.GenericData;
 import org.apache.avro.reflect.ReflectDatumReader;
 import org.apache.avro.reflect.ReflectDatumWriter;
 import org.apache.flink.api.io.avro.generated.Colors;
diff --git a/flink-test-utils/src/main/scala/org/apache/flink/test/util/ForkableFlinkMiniCluster.scala b/flink-test-utils/src/main/scala/org/apache/flink/test/util/ForkableFlinkMiniCluster.scala
index fdb13b28686..eeb622a47fa 100644
--- a/flink-test-utils/src/main/scala/org/apache/flink/test/util/ForkableFlinkMiniCluster.scala
+++ b/flink-test-utils/src/main/scala/org/apache/flink/test/util/ForkableFlinkMiniCluster.scala
@@ -19,12 +19,15 @@
 package org.apache.flink.test.util
 
 import akka.actor.{Props, ActorRef, ActorSystem}
+import akka.pattern.Patterns._
 import org.apache.flink.configuration.{ConfigConstants, Configuration}
 import org.apache.flink.runtime.jobmanager.{MemoryArchivist, JobManager}
 import org.apache.flink.runtime.minicluster.LocalFlinkMiniCluster
 import org.apache.flink.runtime.taskmanager.TaskManager
-import org.apache.flink.runtime.testingUtils.{TestingJobManager, TestingMemoryArchivist,
-TestingTaskManager}
+import org.apache.flink.runtime.testingUtils.{TestingUtils, TestingJobManager,
+TestingMemoryArchivist, TestingTaskManager}
+
+import scala.concurrent.Await
 
 /**
  * A forkable mini cluster is a special case of the mini cluster, used for parallel test execution
@@ -106,9 +109,29 @@ class ForkableFlinkMiniCluster(userConfiguration: Configuration, singleActorSyst
   }
 
   def restartJobManager(): Unit = {
-    jobManagerActorSystem.stop(jobManagerActor)
+    val stopped = gracefulStop(jobManagerActor, TestingUtils.TESTING_DURATION)
+    Await.result(stopped, TestingUtils.TESTING_DURATION)
+
+    jobManagerActorSystem.shutdown()
+    jobManagerActorSystem.awaitTermination()
+
+    jobManagerActorSystem = startJobManagerActorSystem()
     jobManagerActor = startJobManager(jobManagerActorSystem)
   }
+
+  def restartTaskManager(index: Int): Unit = {
+    val stopped = gracefulStop(taskManagerActors(index), TestingUtils.TESTING_DURATION)
+    Await.result(stopped, TestingUtils.TESTING_DURATION)
+
+    taskManagerActorSystems(index).shutdown()
+    taskManagerActorSystems(index).awaitTermination()
+
+    val taskManagerActorSystem  = startTaskManagerActorSystem(index)
+    val taskManagerActor = startTaskManager(index)(jobManagerActorSystem)
+
+    taskManagerActors = taskManagerActors.patch(index, Seq(taskManagerActor), 1)
+    taskManagerActorSystems = taskManagerActorSystems.patch(index, Seq(taskManagerActorSystem), 1)
+  }
 }
 
 object ForkableFlinkMiniCluster {
diff --git a/flink-tests/src/test/scala/org/apache/flink/api/scala/runtime/jobmanager/JobManagerFailsITCase.scala b/flink-tests/src/test/scala/org/apache/flink/api/scala/runtime/jobmanager/JobManagerFailsITCase.scala
index 3813beb2008..ac1864ce54d 100644
--- a/flink-tests/src/test/scala/org/apache/flink/api/scala/runtime/jobmanager/JobManagerFailsITCase.scala
+++ b/flink-tests/src/test/scala/org/apache/flink/api/scala/runtime/jobmanager/JobManagerFailsITCase.scala
@@ -18,12 +18,19 @@
 
 package org.apache.flink.api.scala.runtime.jobmanager
 
+import akka.actor.Status.{Success, Failure}
 import akka.actor.{ActorSystem, PoisonPill}
 import akka.testkit.{ImplicitSender, TestKit}
 import org.apache.flink.configuration.{ConfigConstants, Configuration}
 import org.apache.flink.runtime.akka.AkkaUtils
+import org.apache.flink.runtime.client.JobExecutionException
+import org.apache.flink.runtime.jobgraph.{JobGraph, AbstractJobVertex}
 import org.apache.flink.runtime.jobmanager.Tasks.{NoOpInvokable, BlockingNoOpInvokable}
-import org.apache.flink.runtime.testingUtils.TestingTaskManagerMessages.{JobManagerTerminated, NotifyWhenJobManagerTerminated}
+import org.apache.flink.runtime.messages.JobManagerMessages._
+import org.apache.flink.runtime.testingUtils.TestingMessages.DisableDisconnect
+import org.apache.flink.runtime.testingUtils.TestingTaskManagerMessages.{JobManagerTerminated,
+NotifyWhenJobManagerTerminated}
+import org.apache.flink.runtime.testingUtils.TestingUtils
 import org.apache.flink.test.util.ForkableFlinkMiniCluster
 import org.junit.runner.RunWith
 import org.scalatest.junit.JUnitRunner
@@ -39,7 +46,7 @@ with WordSpecLike with Matchers with BeforeAndAfterAll {
     TestKit.shutdownActorSystem(system)
   }
 
-  "The TaskManager" should {
+  "A TaskManager" should {
     "detect a lost connection to the JobManager and try to reconnect to it" in {
       val num_slots = 11
 
@@ -79,9 +86,7 @@ with WordSpecLike with Matchers with BeforeAndAfterAll {
         cluster.stop()
       }
     }
-  }
 
-  "The system" should {
     "go into a clean state in case of a JobManager failure" in {
       val num_slots = 20
 
@@ -95,15 +100,15 @@ with WordSpecLike with Matchers with BeforeAndAfterAll {
       noOp.setInvokableClass(classOf[NoOpInvokable])
       val jobGraph2 = new JobGraph("NoOp Testjob", noOp)
 
-      val cluster = TestingUtils.startTestingClusterDeathWatch(num_slots/2, 2)
+      val cluster = ForkableFlinkMiniCluster.startClusterDeathWatch(num_slots / 2, 2)
 
       var jm = cluster.getJobManager
       val tm = cluster.getTaskManagers(0)
 
-      try{
+      try {
         within(TestingUtils.TESTING_DURATION) {
           jm ! SubmitJob(jobGraph)
-          expectMsg(SubmissionSuccess(jobGraph.getJobID))
+          expectMsg(Success(jobGraph.getJobID))
 
           tm ! NotifyWhenJobManagerTerminated(jm)
 
@@ -118,13 +123,8 @@ with WordSpecLike with Matchers with BeforeAndAfterAll {
           cluster.waitForTaskManagersToBeRegistered()
 
           jm ! SubmitJob(jobGraph2)
-          val response = expectMsgType[SubmissionResponse]
 
-          response match {
-            case SubmissionSuccess(jobID) => jobID should equal(jobGraph2.getJobID)
-            case SubmissionFailure(jobID, t) =>
-              fail("Submission of the second job failed.", t)
-          }
+          val failure = expectMsgType[Success]
 
           val result = expectMsgType[JobResultSuccess]
 
diff --git a/flink-tests/src/test/scala/org/apache/flink/api/scala/runtime/taskmanager/TaskManagerFailsITCase.scala b/flink-tests/src/test/scala/org/apache/flink/api/scala/runtime/taskmanager/TaskManagerFailsITCase.scala
index 60c67fb9f7c..c81ec88d7fb 100644
--- a/flink-tests/src/test/scala/org/apache/flink/api/scala/runtime/taskmanager/TaskManagerFailsITCase.scala
+++ b/flink-tests/src/test/scala/org/apache/flink/api/scala/runtime/taskmanager/TaskManagerFailsITCase.scala
@@ -22,14 +22,16 @@ import akka.actor.Status.{Failure, Success}
 import akka.actor.{ActorSystem, Kill, PoisonPill}
 import akka.testkit.{ImplicitSender, TestKit}
 
-import org.apache.flink.configuration.Configuration
 import org.apache.flink.configuration.ConfigConstants
+import org.apache.flink.configuration.Configuration
 import org.apache.flink.runtime.akka.AkkaUtils
 import org.apache.flink.runtime.client.JobExecutionException
 import org.apache.flink.runtime.jobgraph.{AbstractJobVertex, DistributionPattern, JobGraph}
-import org.apache.flink.runtime.jobmanager.Tasks.{BlockingReceiver, Sender}
-import org.apache.flink.runtime.messages.JobManagerMessages.{RequestNumberRegisteredTaskManager, SubmitJob}
+import org.apache.flink.runtime.jobmanager.Tasks.{NoOpInvokable, BlockingNoOpInvokable, BlockingReceiver, Sender}
+import org.apache.flink.runtime.messages.JobManagerMessages.{JobResultSuccess, RequestNumberRegisteredTaskManager, SubmitJob}
+import org.apache.flink.runtime.messages.TaskManagerMessages.{RegisteredAtJobManager, NotifyWhenRegisteredAtJobManager}
 import org.apache.flink.runtime.testingUtils.TestingJobManagerMessages._
+import org.apache.flink.runtime.testingUtils.TestingMessages.DisableDisconnect
 import org.apache.flink.runtime.testingUtils.TestingUtils
 import org.apache.flink.test.util.ForkableFlinkMiniCluster
 
@@ -64,6 +66,8 @@ with WordSpecLike with Matchers with BeforeAndAfterAll {
       val taskManagers = cluster.getTaskManagers
       val jm = cluster.getJobManager
 
+      jm ! DisableDisconnect
+
       try{
         within(TestingUtils.TESTING_DURATION){
           jm ! RequestNumberRegisteredTaskManager
@@ -82,7 +86,6 @@ with WordSpecLike with Matchers with BeforeAndAfterAll {
       finally {
         cluster.stop()
       }
-
     }
 
     "handle gracefully failing task manager" in {
@@ -173,5 +176,67 @@ with WordSpecLike with Matchers with BeforeAndAfterAll {
         cluster.stop()
       }
     }
+    
+    "go into a clean state in case of a TaskManager failure" in {
+      val num_slots = 20      
+
+      val sender = new AbstractJobVertex("BlockingSender")
+      sender.setParallelism(num_slots)
+      sender.setInvokableClass(classOf[BlockingNoOpInvokable])
+      val jobGraph = new JobGraph("Blocking Testjob", sender)
+
+      val noOp = new AbstractJobVertex("NoOpInvokable")
+      noOp.setParallelism(num_slots)
+      noOp.setInvokableClass(classOf[NoOpInvokable])
+      val jobGraph2 = new JobGraph("NoOp Testjob", noOp)
+
+      val config = new Configuration()
+      config.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, num_slots/2)
+      config.setInteger(ConfigConstants.LOCAL_INSTANCE_MANAGER_NUMBER_TASK_MANAGER, 2)
+      config.setString(ConfigConstants.AKKA_WATCH_HEARTBEAT_INTERVAL, "1000 ms")
+      config.setString(ConfigConstants.AKKA_WATCH_HEARTBEAT_PAUSE, "4000 ms")
+      config.setDouble(ConfigConstants.AKKA_WATCH_THRESHOLD, 5)
+
+      val cluster = new ForkableFlinkMiniCluster(config, singleActorSystem = false)
+
+      var tm = cluster.getTaskManagers(0)
+      val jm = cluster.getJobManager
+
+      try{
+        within(TestingUtils.TESTING_DURATION){
+          jm ! SubmitJob(jobGraph)
+          expectMsg(Success(jobGraph.getJobID))
+
+          tm ! PoisonPill
+
+          val failure = expectMsgType[Failure]
+
+          failure.cause match {
+            case e: JobExecutionException =>
+              jobGraph.getJobID should equal(e.getJobID)
+
+            case e => fail(s"Received wrong exception $e.")
+          }
+
+          cluster.restartTaskManager(0)
+
+          tm = cluster.getTaskManagers(0)
+
+          tm ! NotifyWhenRegisteredAtJobManager
+
+          expectMsg(RegisteredAtJobManager)
+
+          jm ! SubmitJob(jobGraph2)
+
+          expectMsgType[Success]
+
+          val result = expectMsgType[JobResultSuccess]
+          result.jobID should equal(jobGraph2.getJobID)
+        }
+      } finally {
+        cluster.stop()
+      }
+    }
   }
+
 }
