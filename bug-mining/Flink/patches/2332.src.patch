diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/dispatcher/Dispatcher.java b/flink-runtime/src/main/java/org/apache/flink/runtime/dispatcher/Dispatcher.java
index 2b96a092fe3..38d63cfa23e 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/dispatcher/Dispatcher.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/dispatcher/Dispatcher.java
@@ -570,7 +570,7 @@ public abstract class Dispatcher extends FencedRpcEndpoint<DispatcherId> impleme
 				try {
 					jobIds = submittedJobGraphStore.getJobIds();
 				} catch (Exception e) {
-					log.error("Could not recover job ids from the submitted job graph store. Aborting recovery.", e);
+					onFatalError(new FlinkException("Could not recover job ids from the submitted job graph store. Aborting recovery.", e));
 					return;
 				}
 
@@ -580,7 +580,7 @@ public abstract class Dispatcher extends FencedRpcEndpoint<DispatcherId> impleme
 
 						runAsync(() -> submitJob(submittedJobGraph.getJobGraph(), RpcUtils.INF_TIMEOUT));
 					} catch (Exception e) {
-						log.error("Could not recover the job graph for " + jobId + '.', e);
+						onFatalError(new FlinkException("Could not recover the job graph for " + jobId + '.', e));
 					}
 				}
 			});
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/jobmanager/ZooKeeperSubmittedJobGraphStore.java b/flink-runtime/src/main/java/org/apache/flink/runtime/jobmanager/ZooKeeperSubmittedJobGraphStore.java
index a60a40d8426..dfa931b2cce 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/jobmanager/ZooKeeperSubmittedJobGraphStore.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/jobmanager/ZooKeeperSubmittedJobGraphStore.java
@@ -18,16 +18,17 @@
 
 package org.apache.flink.runtime.jobmanager;
 
-import org.apache.curator.framework.CuratorFramework;
-import org.apache.curator.framework.recipes.cache.PathChildrenCache;
-import org.apache.curator.framework.recipes.cache.PathChildrenCacheEvent;
-import org.apache.curator.framework.recipes.cache.PathChildrenCacheListener;
-import org.apache.curator.utils.ZKPaths;
 import org.apache.flink.api.common.JobID;
 import org.apache.flink.runtime.state.RetrievableStateHandle;
 import org.apache.flink.runtime.zookeeper.RetrievableStateStorageHelper;
 import org.apache.flink.runtime.zookeeper.ZooKeeperStateHandleStore;
 import org.apache.flink.util.FlinkException;
+
+import org.apache.curator.framework.CuratorFramework;
+import org.apache.curator.framework.recipes.cache.PathChildrenCache;
+import org.apache.curator.framework.recipes.cache.PathChildrenCacheEvent;
+import org.apache.curator.framework.recipes.cache.PathChildrenCacheListener;
+import org.apache.curator.utils.ZKPaths;
 import org.apache.zookeeper.KeeperException;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -177,7 +178,7 @@ public class ZooKeeperSubmittedJobGraphStore implements SubmittedJobGraphStore {
 					success = true;
 					return null;
 				} catch (Exception e) {
-					throw new Exception("Could not retrieve the submitted job graph state handle " +
+					throw new FlinkException("Could not retrieve the submitted job graph state handle " +
 						"for " + path + "from the submitted job graph store.", e);
 				}
 				SubmittedJobGraph jobGraph;
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManager.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManager.scala
index 2674332c5e0..64e3337e185 100644
--- a/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManager.scala
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManager.scala
@@ -40,10 +40,10 @@ import org.apache.flink.runtime.akka.{AkkaUtils, ListeningBehaviour}
 import org.apache.flink.runtime.blob.{BlobServer, BlobStore}
 import org.apache.flink.runtime.checkpoint._
 import org.apache.flink.runtime.client._
-import org.apache.flink.runtime.clusterframework.{BootstrapTools, FlinkResourceManager}
 import org.apache.flink.runtime.clusterframework.messages._
 import org.apache.flink.runtime.clusterframework.standalone.StandaloneResourceManager
 import org.apache.flink.runtime.clusterframework.types.ResourceID
+import org.apache.flink.runtime.clusterframework.{BootstrapTools, FlinkResourceManager}
 import org.apache.flink.runtime.concurrent.{FutureUtils, ScheduledExecutorServiceAdapter}
 import org.apache.flink.runtime.execution.SuppressRestartsException
 import org.apache.flink.runtime.execution.librarycache.FlinkUserCodeClassLoaders.ResolveOrder
@@ -501,7 +501,11 @@ class JobManager(
             }
           }
         } catch {
-          case t: Throwable => log.warn(s"Failed to recover job $jobId.", t)
+          case t: Throwable => {
+            log.error(s"Failed to recover job $jobId.", t)
+            // stop one self in order to be restarted and trying to recover the jobs again
+            context.stop(self)
+          }
         }
       }(context.dispatcher)
 
@@ -523,9 +527,12 @@ class JobManager(
             }
           }
         } catch {
-          case e: Exception =>
-            log.warn("Failed to recover job ids from submitted job graph store. Aborting " +
-                       "recovery.", e)
+          case e: Exception => {
+            log.error("Failed to recover job ids from submitted job graph store. Aborting " +
+              "recovery.", e)
+            // stop one self in order to be restarted and trying to recover the jobs again
+            context.stop(self)
+          }
         }
       }(context.dispatcher)
 
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/dispatcher/DispatcherTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/dispatcher/DispatcherTest.java
index cafdf54a6eb..f6d3e357221 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/dispatcher/DispatcherTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/dispatcher/DispatcherTest.java
@@ -51,6 +51,7 @@ import org.apache.flink.runtime.messages.FlinkJobNotFoundException;
 import org.apache.flink.runtime.metrics.groups.JobManagerMetricGroup;
 import org.apache.flink.runtime.metrics.groups.UnregisteredMetricGroups;
 import org.apache.flink.runtime.resourcemanager.ResourceManagerGateway;
+import org.apache.flink.runtime.resourcemanager.utils.TestingResourceManagerGateway;
 import org.apache.flink.runtime.rest.handler.legacy.utils.ArchivedExecutionGraphBuilder;
 import org.apache.flink.runtime.rpc.FatalErrorHandler;
 import org.apache.flink.runtime.rpc.RpcService;
@@ -66,6 +67,7 @@ import org.apache.flink.runtime.testutils.InMemorySubmittedJobGraphStore;
 import org.apache.flink.runtime.util.TestingFatalErrorHandler;
 import org.apache.flink.testutils.category.Flip6;
 import org.apache.flink.util.ExceptionUtils;
+import org.apache.flink.util.FlinkException;
 import org.apache.flink.util.TestLogger;
 
 import org.junit.After;
@@ -77,7 +79,6 @@ import org.junit.Test;
 import org.junit.experimental.categories.Category;
 import org.junit.rules.TemporaryFolder;
 import org.junit.rules.TestName;
-import org.mockito.Mockito;
 
 import javax.annotation.Nonnull;
 import javax.annotation.Nullable;
@@ -91,6 +92,7 @@ import java.nio.file.Path;
 import java.nio.file.Paths;
 import java.util.Collection;
 import java.util.Collections;
+import java.util.Map;
 import java.util.UUID;
 import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.CountDownLatch;
@@ -111,9 +113,6 @@ import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertThat;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.spy;
-import static org.mockito.Mockito.verify;
 
 /**
  * Test for the {@link Dispatcher} component.
@@ -137,7 +136,7 @@ public class DispatcherTest extends TestLogger {
 
 	private TestingFatalErrorHandler fatalErrorHandler;
 
-	private SubmittedJobGraphStore submittedJobGraphStore;
+	private InMemorySubmittedJobGraphStore submittedJobGraphStore;
 
 	private TestingLeaderElectionService dispatcherLeaderElectionService;
 
@@ -173,7 +172,7 @@ public class DispatcherTest extends TestLogger {
 
 		fatalErrorHandler = new TestingFatalErrorHandler();
 		final HeartbeatServices heartbeatServices = new HeartbeatServices(1000L, 10000L);
-		submittedJobGraphStore = spy(new InMemorySubmittedJobGraphStore());
+		submittedJobGraphStore = new InMemorySubmittedJobGraphStore();
 
 		dispatcherLeaderElectionService = new TestingLeaderElectionService();
 		jobMasterLeaderElectionService = new TestingLeaderElectionService();
@@ -197,7 +196,7 @@ public class DispatcherTest extends TestLogger {
 			Dispatcher.DISPATCHER_NAME + '_' + name.getMethodName(),
 			configuration,
 			haServices,
-			mock(ResourceManagerGateway.class),
+			new TestingResourceManagerGateway(),
 			new BlobServer(configuration, new VoidBlobStore()),
 			heartbeatServices,
 			UnregisteredMetricGroups.createUnregisteredJobManagerMetricGroup(),
@@ -245,6 +244,13 @@ public class DispatcherTest extends TestLogger {
 	 */
 	@Test
 	public void testLeaderElection() throws Exception {
+		CompletableFuture<Void> jobIdsFuture = new CompletableFuture<>();
+		submittedJobGraphStore.setJobIdsFunction(
+			(Collection<JobID> jobIds) -> {
+				jobIdsFuture.complete(null);
+				return jobIds;
+			});
+
 		UUID expectedLeaderSessionId = UUID.randomUUID();
 
 		assertNull(dispatcherLeaderElectionService.getConfirmationFuture());
@@ -256,7 +262,8 @@ public class DispatcherTest extends TestLogger {
 
 		assertEquals(expectedLeaderSessionId, actualLeaderSessionId);
 
-		verify(submittedJobGraphStore, Mockito.timeout(TIMEOUT.toMilliseconds()).atLeast(1)).getJobIds();
+		// wait that we asked the SubmittedJobGraphStore for the stored jobs
+		jobIdsFuture.get(TIMEOUT.toMilliseconds(), TimeUnit.MILLISECONDS);
 	}
 
 	/**
@@ -431,6 +438,72 @@ public class DispatcherTest extends TestLogger {
 		assertThat(jobStatusFuture.get(), notNullValue());
 	}
 
+	/**
+	 * Tests that the {@link Dispatcher} terminates if it cannot recover jobs ids from
+	 * the {@link SubmittedJobGraphStore}. See FLINK-8943.
+	 */
+	@Test
+	public void testFatalErrorAfterJobIdRecoveryFailure() throws Exception {
+		final FlinkException testException = new FlinkException("Test exception");
+		submittedJobGraphStore.setJobIdsFunction(
+			(Collection<JobID> jobIds) -> {
+				throw testException;
+			});
+
+		UUID expectedLeaderSessionId = UUID.randomUUID();
+
+		assertNull(dispatcherLeaderElectionService.getConfirmationFuture());
+
+		dispatcherLeaderElectionService.isLeader(expectedLeaderSessionId);
+
+		UUID actualLeaderSessionId = dispatcherLeaderElectionService.getConfirmationFuture()
+			.get(TIMEOUT.toMilliseconds(), TimeUnit.MILLISECONDS);
+
+		assertEquals(expectedLeaderSessionId, actualLeaderSessionId);
+
+		// we expect that a fatal error occurred
+		final Throwable error = fatalErrorHandler.getErrorFuture().get(TIMEOUT.toMilliseconds(), TimeUnit.MILLISECONDS);
+
+		assertThat(ExceptionUtils.findThrowableWithMessage(error, testException.getMessage()).isPresent(), is(true));
+
+		fatalErrorHandler.clearError();
+	}
+
+	/**
+	 * Tests that the {@link Dispatcher} terminates if it cannot recover jobs from
+	 * the {@link SubmittedJobGraphStore}. See FLINK-8943.
+	 */
+	@Test
+	public void testFatalErrorAfterJobRecoveryFailure() throws Exception {
+		final FlinkException testException = new FlinkException("Test exception");
+
+		final SubmittedJobGraph submittedJobGraph = new SubmittedJobGraph(jobGraph, null);
+		submittedJobGraphStore.putJobGraph(submittedJobGraph);
+
+		submittedJobGraphStore.setRecoverJobGraphFunction(
+			(JobID jobId, Map<JobID, SubmittedJobGraph> submittedJobs) -> {
+				throw testException;
+			});
+
+		UUID expectedLeaderSessionId = UUID.randomUUID();
+
+		assertNull(dispatcherLeaderElectionService.getConfirmationFuture());
+
+		dispatcherLeaderElectionService.isLeader(expectedLeaderSessionId);
+
+		UUID actualLeaderSessionId = dispatcherLeaderElectionService.getConfirmationFuture()
+			.get(TIMEOUT.toMilliseconds(), TimeUnit.MILLISECONDS);
+
+		assertEquals(expectedLeaderSessionId, actualLeaderSessionId);
+
+		// we expect that a fatal error occurred
+		final Throwable error = fatalErrorHandler.getErrorFuture().get(TIMEOUT.toMilliseconds(), TimeUnit.MILLISECONDS);
+
+		assertThat(ExceptionUtils.findThrowableWithMessage(error, testException.getMessage()).isPresent(), is(true));
+
+		fatalErrorHandler.clearError();
+	}
+
 	private static class TestingDispatcher extends Dispatcher {
 
 		private final CountDownLatch submitJobLatch = new CountDownLatch(2);
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/jobmanager/JobManagerHARecoveryTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/jobmanager/JobManagerHARecoveryTest.java
index 309ac1236d4..bb2dbf7e66e 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/jobmanager/JobManagerHARecoveryTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/jobmanager/JobManagerHARecoveryTest.java
@@ -96,6 +96,7 @@ import akka.japi.pf.ReceiveBuilder;
 import akka.pattern.Patterns;
 import akka.testkit.CallingThreadDispatcher;
 import akka.testkit.JavaTestKit;
+import akka.testkit.TestProbe;
 import org.junit.AfterClass;
 import org.junit.Assert;
 import org.junit.BeforeClass;
@@ -127,7 +128,8 @@ import scala.concurrent.duration.Deadline;
 import scala.concurrent.duration.FiniteDuration;
 import scala.runtime.BoxedUnit;
 
-import static org.hamcrest.Matchers.containsInAnyOrder;
+import static org.hamcrest.Matchers.empty;
+import static org.hamcrest.Matchers.is;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertThat;
 import static org.junit.Assert.assertTrue;
@@ -160,7 +162,7 @@ public class JobManagerHARecoveryTest extends TestLogger {
 	@Test
 	public void testJobRecoveryWhenLosingLeadership() throws Exception {
 		FiniteDuration timeout = new FiniteDuration(30, TimeUnit.SECONDS);
-		FiniteDuration jobRecoveryTimeout = new FiniteDuration(3, TimeUnit.SECONDS);
+		FiniteDuration jobRecoveryTimeout = new FiniteDuration(0, TimeUnit.SECONDS);
 		Deadline deadline = new FiniteDuration(2, TimeUnit.MINUTES).fromNow();
 		Configuration flinkConfiguration = new Configuration();
 		UUID leaderSessionID = UUID.randomUUID();
@@ -229,7 +231,7 @@ public class JobManagerHARecoveryTest extends TestLogger {
 				testingHighAvailabilityServices,
 				NoOpMetricRegistry.INSTANCE,
 				"localhost",
-				Option.apply("taskmanager"),
+				Option.<String>apply("taskmanager"),
 				true,
 				TestingTaskManager.class);
 
@@ -341,7 +343,7 @@ public class JobManagerHARecoveryTest extends TestLogger {
 	}
 
 	/**
-	 * Tests that a failing job recovery won't cause other job recoveries to fail.
+	 * Tests that a job recovery failure terminates the {@link JobManager}.
 	 */
 	@Test
 	public void testFailingJobRecovery() throws Exception {
@@ -396,6 +398,10 @@ public class JobManagerHARecoveryTest extends TestLogger {
 
 			jobManager = system.actorOf(jobManagerProps);
 
+			final TestProbe testProbe = new TestProbe(system);
+
+			testProbe.watch(jobManager);
+
 			Future<Object> started = Patterns.ask(jobManager, new Identify(42), deadline.timeLeft().toMillis());
 
 			Await.ready(started, deadline.timeLeft());
@@ -403,8 +409,11 @@ public class JobManagerHARecoveryTest extends TestLogger {
 			// make the job manager the leader --> this triggers the recovery of all jobs
 			myLeaderElectionService.isLeader(leaderSessionID);
 
-			// check that we have successfully recovered the second job
-			assertThat(recoveredJobs, containsInAnyOrder(jobId2));
+			// check that we did not recover any jobs
+			assertThat(recoveredJobs, is(empty()));
+
+			// verify that the JobManager terminated
+			testProbe.expectTerminated(jobManager, timeout);
 		} finally {
 			TestingUtils.stopActor(jobManager);
 		}
@@ -447,7 +456,7 @@ public class JobManagerHARecoveryTest extends TestLogger {
 				checkpointRecoveryFactory,
 				jobRecoveryTimeout,
 				jobManagerMetricGroup,
-				Option.empty());
+				Option.<String>empty());
 
 			this.recoveredJobs = recoveredJobs;
 		}
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/testutils/InMemorySubmittedJobGraphStore.java b/flink-runtime/src/test/java/org/apache/flink/runtime/testutils/InMemorySubmittedJobGraphStore.java
index ee208cee696..ba0dc80fbb5 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/testutils/InMemorySubmittedJobGraphStore.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/testutils/InMemorySubmittedJobGraphStore.java
@@ -22,6 +22,8 @@ import org.apache.flink.api.common.JobID;
 import org.apache.flink.runtime.jobmanager.SubmittedJobGraph;
 import org.apache.flink.runtime.jobmanager.SubmittedJobGraphStore;
 import org.apache.flink.util.Preconditions;
+import org.apache.flink.util.function.BiFunctionWithException;
+import org.apache.flink.util.function.FunctionWithException;
 
 import javax.annotation.Nullable;
 
@@ -42,6 +44,23 @@ public class InMemorySubmittedJobGraphStore implements SubmittedJobGraphStore {
 
 	private boolean started;
 
+	private volatile FunctionWithException<Collection<JobID>, Collection<JobID>, ? extends Exception> jobIdsFunction;
+
+	private volatile BiFunctionWithException<JobID, Map<JobID, SubmittedJobGraph>, SubmittedJobGraph, ? extends Exception> recoverJobGraphFunction;
+
+	public InMemorySubmittedJobGraphStore() {
+		jobIdsFunction = null;
+		recoverJobGraphFunction = null;
+	}
+
+	public void setJobIdsFunction(FunctionWithException<Collection<JobID>, Collection<JobID>, ? extends Exception> jobIdsFunction) {
+		this.jobIdsFunction = Preconditions.checkNotNull(jobIdsFunction);
+	}
+
+	public void setRecoverJobGraphFunction(BiFunctionWithException<JobID, Map<JobID, SubmittedJobGraph>, SubmittedJobGraph, ? extends Exception> recoverJobGraphFunction) {
+		this.recoverJobGraphFunction = Preconditions.checkNotNull(recoverJobGraphFunction);
+	}
+
 	@Override
 	public synchronized void start(@Nullable SubmittedJobGraphListener jobGraphListener) throws Exception {
 		started = true;
@@ -55,9 +74,14 @@ public class InMemorySubmittedJobGraphStore implements SubmittedJobGraphStore {
 	@Override
 	public synchronized SubmittedJobGraph recoverJobGraph(JobID jobId) throws Exception {
 		verifyIsStarted();
-		return requireNonNull(
-			storedJobs.get(jobId),
-			"Job graph for job " + jobId + " does not exist");
+
+		if (recoverJobGraphFunction != null) {
+			return recoverJobGraphFunction.applyWithException(jobId, storedJobs);
+		} else {
+			return requireNonNull(
+				storedJobs.get(jobId),
+				"Job graph for job " + jobId + " does not exist");
+		}
 	}
 
 	@Override
@@ -75,7 +99,12 @@ public class InMemorySubmittedJobGraphStore implements SubmittedJobGraphStore {
 	@Override
 	public synchronized Collection<JobID> getJobIds() throws Exception {
 		verifyIsStarted();
-		return Collections.unmodifiableSet(new HashSet<>(storedJobs.keySet()));
+
+		if (jobIdsFunction != null) {
+			return jobIdsFunction.apply(storedJobs.keySet());
+		} else {
+			return Collections.unmodifiableSet(new HashSet<>(storedJobs.keySet()));
+		}
 	}
 
 	public synchronized boolean contains(JobID jobId) {
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/util/TestingFatalErrorHandler.java b/flink-runtime/src/test/java/org/apache/flink/runtime/util/TestingFatalErrorHandler.java
index d07d356e32c..126625ac6a9 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/util/TestingFatalErrorHandler.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/util/TestingFatalErrorHandler.java
@@ -59,12 +59,12 @@ public class TestingFatalErrorHandler implements FatalErrorHandler {
 	@Nullable
 	public synchronized Throwable getException() {
 		if (errorFuture.isDone()) {
-			Throwable throwable = null;
+			Throwable throwable;
 
 			try {
 				throwable = errorFuture.get();
 			} catch (InterruptedException ie) {
-				Thread.interrupted();
+				ExceptionUtils.checkInterrupted(ie);
 				throw new FlinkRuntimeException("This should never happen since the future was completed.");
 			} catch (ExecutionException e) {
 				throwable = ExceptionUtils.stripExecutionException(e);
diff --git a/flink-tests/src/test/java/org/apache/flink/test/runtime/leaderelection/ZooKeeperLeaderElectionITCase.java b/flink-tests/src/test/java/org/apache/flink/test/runtime/leaderelection/ZooKeeperLeaderElectionITCase.java
index 75a885f6fff..f348b8a204b 100644
--- a/flink-tests/src/test/java/org/apache/flink/test/runtime/leaderelection/ZooKeeperLeaderElectionITCase.java
+++ b/flink-tests/src/test/java/org/apache/flink/test/runtime/leaderelection/ZooKeeperLeaderElectionITCase.java
@@ -22,6 +22,7 @@ import org.apache.flink.api.common.JobExecutionResult;
 import org.apache.flink.configuration.AkkaOptions;
 import org.apache.flink.configuration.ConfigConstants;
 import org.apache.flink.configuration.Configuration;
+import org.apache.flink.configuration.HighAvailabilityOptions;
 import org.apache.flink.runtime.akka.AkkaUtils;
 import org.apache.flink.runtime.client.JobClient;
 import org.apache.flink.runtime.instance.ActorGateway;
@@ -53,6 +54,7 @@ import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import java.io.File;
+import java.util.UUID;
 
 import scala.concurrent.Await;
 import scala.concurrent.Future;
@@ -99,6 +101,7 @@ public class ZooKeeperLeaderElectionITCase extends TestLogger {
 		Configuration configuration = ZooKeeperTestUtils.createZooKeeperHAConfig(
 			zkServer.getConnectString(),
 			rootFolder.getPath());
+		configuration.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
 
 		int numJMs = 10;
 		int numTMs = 3;
@@ -150,6 +153,7 @@ public class ZooKeeperLeaderElectionITCase extends TestLogger {
 		Configuration configuration = ZooKeeperTestUtils.createZooKeeperHAConfig(
 			zkServer.getConnectString(),
 			rootFolder.getPath());
+		configuration.setString(HighAvailabilityOptions.HA_CLUSTER_ID, UUID.randomUUID().toString());
 
 		configuration.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER, numJMs);
 		configuration.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, numTMs);
