diff --git a/flink-optimizer/src/main/java/org/apache/flink/optimizer/plantranslate/JobGraphGenerator.java b/flink-optimizer/src/main/java/org/apache/flink/optimizer/plantranslate/JobGraphGenerator.java
index 32cb7dd3053..12c1defce50 100644
--- a/flink-optimizer/src/main/java/org/apache/flink/optimizer/plantranslate/JobGraphGenerator.java
+++ b/flink-optimizer/src/main/java/org/apache/flink/optimizer/plantranslate/JobGraphGenerator.java
@@ -25,6 +25,8 @@ import org.apache.flink.api.common.aggregators.ConvergenceCriterion;
 import org.apache.flink.api.common.aggregators.LongSumAggregator;
 import org.apache.flink.api.common.cache.DistributedCache;
 import org.apache.flink.api.common.distributions.DataDistribution;
+import org.apache.flink.api.common.io.InputFormat;
+import org.apache.flink.api.common.io.OutputFormat;
 import org.apache.flink.api.common.operators.util.UserCodeWrapper;
 import org.apache.flink.api.common.typeutils.TypeSerializerFactory;
 import org.apache.flink.api.java.io.BlockingShuffleOutputFormat;
@@ -61,12 +63,13 @@ import org.apache.flink.runtime.iterative.task.IterationIntermediateTask;
 import org.apache.flink.runtime.iterative.task.IterationSynchronizationSinkTask;
 import org.apache.flink.runtime.iterative.task.IterationTailTask;
 import org.apache.flink.runtime.jobgraph.DistributionPattern;
-import org.apache.flink.runtime.jobgraph.InputFormatVertex;
+import org.apache.flink.runtime.jobgraph.InputOutputFormatContainer;
+import org.apache.flink.runtime.jobgraph.InputOutputFormatVertex;
 import org.apache.flink.runtime.jobgraph.IntermediateDataSetID;
 import org.apache.flink.runtime.jobgraph.JobEdge;
 import org.apache.flink.runtime.jobgraph.JobGraph;
 import org.apache.flink.runtime.jobgraph.JobVertex;
-import org.apache.flink.runtime.jobgraph.OutputFormatVertex;
+import org.apache.flink.runtime.jobgraph.OperatorID;
 import org.apache.flink.runtime.jobmanager.scheduler.SlotSharingGroup;
 import org.apache.flink.runtime.operators.BatchTask;
 import org.apache.flink.runtime.operators.CoGroupDriver;
@@ -947,33 +950,41 @@ public class JobGraphGenerator implements Visitor<PlanNode> {
 		return vertex;
 	}
 
-	private InputFormatVertex createDataSourceVertex(SourcePlanNode node) throws CompilerException {
-		final InputFormatVertex vertex = new InputFormatVertex(node.getNodeName());
+	private JobVertex createDataSourceVertex(SourcePlanNode node) throws CompilerException {
+		final InputOutputFormatVertex vertex = new InputOutputFormatVertex(node.getNodeName());
 		final TaskConfig config = new TaskConfig(vertex.getConfiguration());
 
+		final OperatorID operatorID = new OperatorID();
+
 		vertex.setResources(node.getMinResources(), node.getPreferredResources());
 		vertex.setInvokableClass(DataSourceTask.class);
-		vertex.setFormatDescription(getDescriptionForUserCode(node.getProgramOperator().getUserCodeWrapper()));
+		vertex.setFormatDescription(operatorID, getDescriptionForUserCode(node.getProgramOperator().getUserCodeWrapper()));
 
 		// set user code
-		config.setStubWrapper(node.getProgramOperator().getUserCodeWrapper());
-		config.setStubParameters(node.getProgramOperator().getParameters());
+		new InputOutputFormatContainer(Thread.currentThread().getContextClassLoader())
+			.addInputFormat(operatorID, (UserCodeWrapper<? extends InputFormat<?, ?>>) node.getProgramOperator().getUserCodeWrapper())
+			.addParameters(operatorID, node.getProgramOperator().getParameters())
+			.write(config);
 
 		config.setOutputSerializer(node.getSerializer());
 		return vertex;
 	}
 
 	private JobVertex createDataSinkVertex(SinkPlanNode node) throws CompilerException {
-		final OutputFormatVertex vertex = new OutputFormatVertex(node.getNodeName());
+		final InputOutputFormatVertex vertex = new InputOutputFormatVertex(node.getNodeName());
 		final TaskConfig config = new TaskConfig(vertex.getConfiguration());
 
+		final OperatorID operatorID = new OperatorID();
+
 		vertex.setResources(node.getMinResources(), node.getPreferredResources());
 		vertex.setInvokableClass(DataSinkTask.class);
-		vertex.setFormatDescription(getDescriptionForUserCode(node.getProgramOperator().getUserCodeWrapper()));
-		
+		vertex.setFormatDescription(operatorID, getDescriptionForUserCode(node.getProgramOperator().getUserCodeWrapper()));
+
 		// set user code
-		config.setStubWrapper(node.getProgramOperator().getUserCodeWrapper());
-		config.setStubParameters(node.getProgramOperator().getParameters());
+		new InputOutputFormatContainer(Thread.currentThread().getContextClassLoader())
+			.addOutputFormat(operatorID, (UserCodeWrapper<? extends OutputFormat<?>>) node.getProgramOperator().getUserCodeWrapper())
+			.addParameters(operatorID, node.getProgramOperator().getParameters())
+			.write(config);
 
 		return vertex;
 	}
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/InputFormatVertex.java b/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/InputFormatVertex.java
deleted file mode 100644
index 5627ac7b946..00000000000
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/InputFormatVertex.java
+++ /dev/null
@@ -1,97 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.flink.runtime.jobgraph;
-
-import org.apache.flink.api.common.io.InputFormat;
-import org.apache.flink.api.common.operators.util.UserCodeWrapper;
-import org.apache.flink.runtime.operators.util.TaskConfig;
-
-import java.util.List;
-
-public class InputFormatVertex extends JobVertex {
-
-	private static final long serialVersionUID = 1L;
-	
-	private String formatDescription;
-	
-	
-	public InputFormatVertex(String name) {
-		super(name);
-	}
-	
-	public InputFormatVertex(String name, JobVertexID id) {
-		super(name, id);
-	}
-
-	public InputFormatVertex(String name, JobVertexID id, List<JobVertexID> alternativeIds, List<OperatorID> operatorIds, List<OperatorID> alternativeOperatorIds) {
-		super(name, id, alternativeIds, operatorIds, alternativeOperatorIds);
-	}
-	
-	
-	public void setFormatDescription(String formatDescription) {
-		this.formatDescription = formatDescription;
-	}
-	
-	public String getFormatDescription() {
-		return formatDescription;
-	}
-	
-	@Override
-	public void initializeOnMaster(ClassLoader loader) throws Exception {
-		final TaskConfig cfg = new TaskConfig(getConfiguration());
-		
-		// deserialize from the payload
-		UserCodeWrapper<InputFormat<?, ?>> wrapper;
-		try {
-			
-			wrapper = cfg.getStubWrapper(loader);
-		}
-		catch (Throwable t) {
-			throw new Exception("Deserializing the InputFormat (" + formatDescription + ") failed: " + t.getMessage(), t);
-		}
-		if (wrapper == null) {
-			throw new Exception("No input format present in InputFormatVertex's task configuration.");
-		}
-		
-		// instantiate, if necessary
-		InputFormat<?, ?> inputFormat;
-		try {
-			inputFormat = wrapper.getUserCodeObject(InputFormat.class, loader);
-		}
-		catch (Throwable t) {
-			throw new Exception("Instantiating the InputFormat (" + formatDescription + ") failed: " + t.getMessage(), t);
-		}
-
-		Thread thread = Thread.currentThread();
-		ClassLoader original = thread.getContextClassLoader();
-		// configure
-		try {
-			thread.setContextClassLoader(loader);
-			inputFormat.configure(cfg.getStubParameters());
-		}
-		catch (Throwable t) {
-			throw new Exception("Configuring the InputFormat (" + formatDescription + ") failed: " + t.getMessage(), t);
-		}
-		finally {
-			thread.setContextClassLoader(original);
-		}
-		
-		setInputSplitSource(inputFormat);
-	}
-}
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/InputOutputFormatContainer.java b/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/InputOutputFormatContainer.java
new file mode 100644
index 00000000000..3d58d24fbdd
--- /dev/null
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/InputOutputFormatContainer.java
@@ -0,0 +1,202 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.runtime.jobgraph;
+
+import org.apache.flink.api.common.io.InputFormat;
+import org.apache.flink.api.common.io.OutputFormat;
+import org.apache.flink.api.common.operators.util.UserCodeObjectWrapper;
+import org.apache.flink.api.common.operators.util.UserCodeWrapper;
+import org.apache.flink.configuration.Configuration;
+import org.apache.flink.configuration.DelegatingConfiguration;
+import org.apache.flink.core.io.InputSplit;
+import org.apache.flink.runtime.operators.util.TaskConfig;
+import org.apache.flink.util.Preconditions;
+
+import org.apache.commons.lang3.tuple.ImmutablePair;
+import org.apache.commons.lang3.tuple.Pair;
+
+import java.io.Serializable;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+
+import static org.apache.flink.util.Preconditions.checkNotNull;
+
+/**
+ * A container for {@link InputFormat InputFormats} and {@link OutputFormat OutputFormats}, along with
+ * their {@link Configuration}.
+ */
+public class InputOutputFormatContainer {
+
+	private final FormatUserCodeTable formats;
+
+	private final Configuration parameters;
+
+	private final ClassLoader userCodeClassLoader;
+
+	public InputOutputFormatContainer(ClassLoader classLoader) {
+		this.formats = new FormatUserCodeTable();
+		this.parameters = new Configuration();
+		this.userCodeClassLoader = checkNotNull(classLoader);
+	}
+
+	public InputOutputFormatContainer(TaskConfig config, ClassLoader classLoader) {
+		checkNotNull(config);
+		this.userCodeClassLoader = checkNotNull(classLoader);
+
+		final UserCodeWrapper<FormatUserCodeTable> wrapper;
+
+		try {
+			wrapper = config.getStubWrapper(classLoader);
+		} catch (Throwable t) {
+			throw new RuntimeException("Deserializing the input/output formats failed: " + t.getMessage(), t);
+		}
+
+		if (wrapper == null) {
+			throw new RuntimeException("No InputFormat or OutputFormat present in task configuration.");
+		}
+
+		try {
+			this.formats = wrapper.getUserCodeObject(FormatUserCodeTable.class, classLoader);
+		} catch (Throwable t) {
+			throw new RuntimeException("Instantiating the input/output formats failed: " + t.getMessage(), t);
+		}
+
+		this.parameters = new Configuration();
+		Configuration stubParameters = config.getStubParameters();
+		for (String key : stubParameters.keySet()) { // copy only the parameters of input/output formats
+			parameters.setString(key, stubParameters.getString(key, null));
+		}
+	}
+
+	public Map<OperatorID, UserCodeWrapper<? extends InputFormat<?, ?>>> getInputFormats() {
+		return formats.getInputFormats();
+	}
+
+	public Map<OperatorID, UserCodeWrapper<? extends OutputFormat<?>>> getOutputFormats() {
+		return formats.getOutputFormats();
+	}
+
+	@SuppressWarnings("unchecked")
+	public <OT, T extends InputSplit> Pair<OperatorID, InputFormat<OT, T>> getUniqueInputFormat() {
+		Map<OperatorID, UserCodeWrapper<? extends InputFormat<?, ?>>> inputFormats = formats.getInputFormats();
+		Preconditions.checkState(inputFormats.size() == 1);
+
+		Map.Entry<OperatorID, UserCodeWrapper<? extends InputFormat<?, ?>>> entry = inputFormats.entrySet().iterator().next();
+
+		return new ImmutablePair<>(entry.getKey(),
+			(InputFormat<OT, T>) entry.getValue().getUserCodeObject(InputFormat.class, userCodeClassLoader));
+	}
+
+	@SuppressWarnings("unchecked")
+	public <IT> Pair<OperatorID, OutputFormat<IT>> getUniqueOutputFormat() {
+		Map<OperatorID, UserCodeWrapper<? extends OutputFormat<?>>> outputFormats = formats.getOutputFormats();
+		Preconditions.checkState(outputFormats.size() == 1);
+
+		Map.Entry<OperatorID, UserCodeWrapper<? extends OutputFormat<?>>> entry = outputFormats.entrySet().iterator().next();
+
+		return new ImmutablePair<>(entry.getKey(),
+			(OutputFormat<IT>) entry.getValue().getUserCodeObject(OutputFormat.class, userCodeClassLoader));
+	}
+
+	public InputOutputFormatContainer addInputFormat(OperatorID operatorId, InputFormat<?, ?> inputFormat) {
+		formats.addInputFormat(operatorId, new UserCodeObjectWrapper<>(inputFormat));
+		return this;
+	}
+
+	public InputOutputFormatContainer addInputFormat(OperatorID operatorId, UserCodeWrapper<? extends InputFormat<?, ?>> wrapper) {
+		formats.addInputFormat(operatorId, wrapper);
+		return this;
+	}
+
+	public InputOutputFormatContainer addOutputFormat(OperatorID operatorId, OutputFormat<?> outputFormat) {
+		formats.addOutputFormat(operatorId, new UserCodeObjectWrapper<>(outputFormat));
+		return this;
+	}
+
+	public InputOutputFormatContainer addOutputFormat(OperatorID operatorId, UserCodeWrapper<? extends OutputFormat<?>> wrapper) {
+		formats.addOutputFormat(operatorId, wrapper);
+		return this;
+	}
+
+	public Configuration getParameters(OperatorID operatorId) {
+		return new DelegatingConfiguration(parameters, getParamKeyPrefix(operatorId));
+	}
+
+	public InputOutputFormatContainer addParameters(OperatorID operatorId, Configuration parameters) {
+		for (String key : parameters.keySet()) {
+			addParameters(operatorId, key, parameters.getString(key, null));
+		}
+		return this;
+	}
+
+	public InputOutputFormatContainer addParameters(OperatorID operatorId, String key, String value) {
+		parameters.setString(getParamKeyPrefix(operatorId) + key, value);
+		return this;
+	}
+
+	public void write(TaskConfig config) {
+		config.setStubWrapper(new UserCodeObjectWrapper<>(formats));
+		config.setStubParameters(parameters);
+	}
+
+	private String getParamKeyPrefix(OperatorID operatorId) {
+		return operatorId + ".";
+	}
+
+	/**
+	 * Container for multiple wrappers containing {@link InputFormat} and {@link OutputFormat} code.
+	 */
+	public static class FormatUserCodeTable implements Serializable {
+
+		private static final long serialVersionUID = 1L;
+
+		private final Map<OperatorID, UserCodeWrapper<? extends InputFormat<?, ?>>> inputFormats;
+		private final Map<OperatorID, UserCodeWrapper<? extends OutputFormat<?>>> outputFormats;
+
+		public FormatUserCodeTable() {
+			this.inputFormats = new HashMap<>();
+			this.outputFormats = new HashMap<>();
+		}
+
+		public void addInputFormat(OperatorID operatorId, UserCodeWrapper<? extends InputFormat<?, ?>> wrapper) {
+			if (inputFormats.containsKey(checkNotNull(operatorId))) {
+				throw new IllegalStateException("The input format has been set for the operator: " + operatorId);
+			}
+
+			inputFormats.put(operatorId, checkNotNull(wrapper));
+		}
+
+		public void addOutputFormat(OperatorID operatorId, UserCodeWrapper<? extends OutputFormat<?>> wrapper) {
+			if (outputFormats.containsKey(checkNotNull(operatorId))) {
+				throw new IllegalStateException("The output format has been set for the operator: " + operatorId);
+			}
+
+			outputFormats.put(operatorId, checkNotNull(wrapper));
+		}
+
+		public Map<OperatorID, UserCodeWrapper<? extends InputFormat<?, ?>>> getInputFormats() {
+			return Collections.unmodifiableMap(inputFormats);
+		}
+
+		public Map<OperatorID, UserCodeWrapper<? extends OutputFormat<?>>> getOutputFormats() {
+			return Collections.unmodifiableMap(outputFormats);
+		}
+	}
+}
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/InputOutputFormatVertex.java b/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/InputOutputFormatVertex.java
new file mode 100644
index 00000000000..741df52f5af
--- /dev/null
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/InputOutputFormatVertex.java
@@ -0,0 +1,159 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.runtime.jobgraph;
+
+import org.apache.flink.api.common.io.FinalizeOnMaster;
+import org.apache.flink.api.common.io.InitializeOnMaster;
+import org.apache.flink.api.common.io.InputFormat;
+import org.apache.flink.api.common.io.OutputFormat;
+import org.apache.flink.api.common.operators.util.UserCodeWrapper;
+import org.apache.flink.runtime.operators.util.TaskConfig;
+
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+import static org.apache.flink.util.Preconditions.checkNotNull;
+
+/**
+ * A task vertex that runs an initialization and a finalization on the master. If necessary, it tries
+ * to deserialize input and output formats, and initialize and finalize them on master.
+ */
+public class InputOutputFormatVertex extends JobVertex {
+
+	private static final long serialVersionUID = 1L;
+
+	private final Map<OperatorID, String> formatDescriptions = new HashMap<>();
+
+	public InputOutputFormatVertex(String name) {
+		super(name);
+	}
+
+	public InputOutputFormatVertex(
+		String name,
+		JobVertexID id,
+		List<JobVertexID> alternativeIds,
+		List<OperatorID> operatorIds,
+		List<OperatorID> alternativeOperatorIds) {
+
+		super(name, id, alternativeIds, operatorIds, alternativeOperatorIds);
+	}
+
+	@Override
+	public void initializeOnMaster(ClassLoader loader) throws Exception {
+		final InputOutputFormatContainer formatContainer = initInputOutputformatContainer(loader);
+
+		final ClassLoader original = Thread.currentThread().getContextClassLoader();
+		try {
+			// set user classloader before calling user code
+			Thread.currentThread().setContextClassLoader(loader);
+
+			// configure the input format and setup input splits
+			Map<OperatorID, UserCodeWrapper<? extends InputFormat<?, ?>>> inputFormats = formatContainer.getInputFormats();
+			if (inputFormats.size() > 1) {
+				throw new UnsupportedOperationException("Multiple input formats are not supported in a job vertex.");
+			}
+			for (Map.Entry<OperatorID, UserCodeWrapper<? extends InputFormat<?, ?>>> entry : inputFormats.entrySet()) {
+				final InputFormat<?, ?> inputFormat;
+
+				try {
+					inputFormat = entry.getValue().getUserCodeObject();
+					inputFormat.configure(formatContainer.getParameters(entry.getKey()));
+				} catch (Throwable t) {
+					throw new Exception("Configuring the input format (" + getFormatDescription(entry.getKey()) + ") failed: "
+						+ t.getMessage(), t);
+				}
+
+				setInputSplitSource(inputFormat);
+			}
+
+			// configure input formats and invoke initializeGlobal()
+			Map<OperatorID, UserCodeWrapper<? extends OutputFormat<?>>> outputFormats = formatContainer.getOutputFormats();
+			for (Map.Entry<OperatorID, UserCodeWrapper<? extends OutputFormat<?>>> entry : outputFormats.entrySet()) {
+				final OutputFormat<?> outputFormat;
+
+				try {
+					outputFormat = entry.getValue().getUserCodeObject();
+					outputFormat.configure(formatContainer.getParameters(entry.getKey()));
+				} catch (Throwable t) {
+					throw new Exception("Configuring the output format (" + getFormatDescription(entry.getKey()) + ") failed: "
+						+ t.getMessage(), t);
+				}
+
+				if (outputFormat instanceof InitializeOnMaster) {
+					((InitializeOnMaster) outputFormat).initializeGlobal(getParallelism());
+				}
+			}
+
+		} finally {
+			// restore original classloader
+			Thread.currentThread().setContextClassLoader(original);
+		}
+	}
+
+	@Override
+	public void finalizeOnMaster(ClassLoader loader) throws Exception {
+		final InputOutputFormatContainer formatContainer = initInputOutputformatContainer(loader);
+
+		final ClassLoader original = Thread.currentThread().getContextClassLoader();
+		try {
+			// set user classloader before calling user code
+			Thread.currentThread().setContextClassLoader(loader);
+
+			// configure input formats and invoke finalizeGlobal()
+			Map<OperatorID, UserCodeWrapper<? extends OutputFormat<?>>> outputFormats = formatContainer.getOutputFormats();
+			for (Map.Entry<OperatorID, UserCodeWrapper<? extends OutputFormat<?>>> entry : outputFormats.entrySet()) {
+				final OutputFormat<?> outputFormat;
+
+				try {
+					outputFormat = entry.getValue().getUserCodeObject();
+					outputFormat.configure(formatContainer.getParameters(entry.getKey()));
+				} catch (Throwable t) {
+					throw new Exception("Configuring the output format (" + getFormatDescription(entry.getKey()) + ") failed: "
+						+ t.getMessage(), t);
+				}
+
+				if (outputFormat instanceof FinalizeOnMaster) {
+					((FinalizeOnMaster) outputFormat).finalizeGlobal(getParallelism());
+				}
+			}
+
+		} finally {
+			// restore original classloader
+			Thread.currentThread().setContextClassLoader(original);
+		}
+	}
+
+	public String getFormatDescription(OperatorID operatorID) {
+		return formatDescriptions.get(operatorID);
+	}
+
+	public void setFormatDescription(OperatorID operatorID, String formatDescription) {
+		formatDescriptions.put(checkNotNull(operatorID), formatDescription);
+	}
+
+	private InputOutputFormatContainer initInputOutputformatContainer(ClassLoader classLoader) throws Exception {
+		try {
+			return new InputOutputFormatContainer(new TaskConfig(getConfiguration()), classLoader);
+		} catch (Throwable t) {
+			throw new Exception("Loading the input/output formats failed: "
+				+ String.join(",", formatDescriptions.values()), t);
+		}
+	}
+}
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/OutputFormatVertex.java b/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/OutputFormatVertex.java
deleted file mode 100644
index 77f207ca759..00000000000
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/OutputFormatVertex.java
+++ /dev/null
@@ -1,139 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.flink.runtime.jobgraph;
-
-import org.apache.flink.api.common.io.FinalizeOnMaster;
-import org.apache.flink.api.common.io.InitializeOnMaster;
-import org.apache.flink.api.common.io.OutputFormat;
-import org.apache.flink.api.common.operators.util.UserCodeWrapper;
-import org.apache.flink.runtime.operators.util.TaskConfig;
-
-/**
- * A task vertex that run an initialization on the master, trying to deserialize an output format
- * and initializing it on master, if necessary.
- */
-public class OutputFormatVertex extends JobVertex {
-	
-	private static final long serialVersionUID = 1L;
-	
-	private String formatDescription;
-	
-	/**
-	 * Creates a new task vertex with the specified name.
-	 * 
-	 * @param name The name of the task vertex.
-	 */
-	public OutputFormatVertex(String name) {
-		super(name);
-	}
-	
-	public void setFormatDescription(String formatDescription) {
-		this.formatDescription = formatDescription;
-	}
-	
-	public String getFormatDescription() {
-		return formatDescription;
-	}
-	
-	@Override
-	public void initializeOnMaster(ClassLoader loader) throws Exception {
-		final TaskConfig cfg = new TaskConfig(getConfiguration());
-		
-		UserCodeWrapper<OutputFormat<?>> wrapper;
-		try {
-			wrapper = cfg.<OutputFormat<?>>getStubWrapper(loader);
-		}
-		catch (Throwable t) {
-			throw new Exception("Deserializing the OutputFormat (" + formatDescription + ") failed: " + t.getMessage(), t);
-		}
-		if (wrapper == null) {
-			throw new Exception("No input format present in InputFormatVertex's task configuration.");
-		}
-		
-		OutputFormat<?> outputFormat;
-		try {
-			outputFormat = wrapper.getUserCodeObject(OutputFormat.class, loader);
-		}
-		catch (Throwable t) {
-			throw new Exception("Instantiating the OutputFormat (" + formatDescription + ") failed: " + t.getMessage(), t);
-		}
-
-		// set user classloader before calling user code
-		final ClassLoader prevContextCl = Thread.currentThread().getContextClassLoader();
-		Thread.currentThread().setContextClassLoader(loader);
-
-		try {
-			// configure output format
-			try {
-				outputFormat.configure(cfg.getStubParameters());
-			} catch (Throwable t) {
-				throw new Exception("Configuring the OutputFormat (" + formatDescription + ") failed: " + t.getMessage(), t);
-			}
-			if (outputFormat instanceof InitializeOnMaster) {
-				((InitializeOnMaster) outputFormat).initializeGlobal(getParallelism());
-			}
-		} finally {
-			// restore previous classloader
-			Thread.currentThread().setContextClassLoader(prevContextCl);
-		}
-	}
-	
-	@Override
-	public void finalizeOnMaster(ClassLoader loader) throws Exception {
-		final TaskConfig cfg = new TaskConfig(getConfiguration());
-
-		UserCodeWrapper<OutputFormat<?>> wrapper;
-		try {
-			wrapper = cfg.<OutputFormat<?>>getStubWrapper(loader);
-		}
-		catch (Throwable t) {
-			throw new Exception("Deserializing the OutputFormat (" + formatDescription + ") failed: " + t.getMessage(), t);
-		}
-		if (wrapper == null) {
-			throw new Exception("No input format present in InputFormatVertex's task configuration.");
-		}
-
-		OutputFormat<?> outputFormat;
-		try {
-			outputFormat = wrapper.getUserCodeObject(OutputFormat.class, loader);
-		}
-		catch (Throwable t) {
-			throw new Exception("Instantiating the OutputFormat (" + formatDescription + ") failed: " + t.getMessage(), t);
-		}
-
-		// set user classloader before calling user code
-		final ClassLoader prevContextCl = Thread.currentThread().getContextClassLoader();
-		Thread.currentThread().setContextClassLoader(loader);
-
-		try {
-			// configure output format
-			try {
-				outputFormat.configure(cfg.getStubParameters());
-			} catch (Throwable t) {
-				throw new Exception("Configuring the OutputFormat (" + formatDescription + ") failed: " + t.getMessage(), t);
-			}
-			if (outputFormat instanceof FinalizeOnMaster) {
-				((FinalizeOnMaster) outputFormat).finalizeGlobal(getParallelism());
-			}
-		} finally {
-			// restore previous classloader
-			Thread.currentThread().setContextClassLoader(prevContextCl);
-		}
-	}
-}
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/operators/DataSinkTask.java b/flink-runtime/src/main/java/org/apache/flink/runtime/operators/DataSinkTask.java
index 2c263012d47..f2dc9bcea76 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/operators/DataSinkTask.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/operators/DataSinkTask.java
@@ -35,6 +35,8 @@ import org.apache.flink.runtime.execution.Environment;
 import org.apache.flink.runtime.io.network.api.reader.MutableReader;
 import org.apache.flink.runtime.io.network.api.reader.MutableRecordReader;
 import org.apache.flink.runtime.io.network.partition.consumer.UnionInputGate;
+import org.apache.flink.runtime.jobgraph.InputOutputFormatContainer;
+import org.apache.flink.runtime.jobgraph.OperatorID;
 import org.apache.flink.runtime.jobgraph.tasks.AbstractInvokable;
 import org.apache.flink.runtime.metrics.groups.OperatorIOMetricGroup;
 import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;
@@ -47,6 +49,7 @@ import org.apache.flink.runtime.operators.util.TaskConfig;
 import org.apache.flink.runtime.plugable.DeserializationDelegate;
 import org.apache.flink.util.MutableObjectIterator;
 
+import org.apache.commons.lang3.tuple.Pair;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -322,8 +325,11 @@ public class DataSinkTask<IT> extends AbstractInvokable {
 		Configuration taskConf = getTaskConfiguration();
 		this.config = new TaskConfig(taskConf);
 
+		final Pair<OperatorID, OutputFormat<IT>> operatorIDAndOutputFormat;
+		InputOutputFormatContainer formatContainer = new InputOutputFormatContainer(config, userCodeClassLoader);
 		try {
-			this.format = config.<OutputFormat<IT>>getStubWrapper(userCodeClassLoader).getUserCodeObject(OutputFormat.class, userCodeClassLoader);
+			operatorIDAndOutputFormat = formatContainer.getUniqueOutputFormat();
+			this.format = operatorIDAndOutputFormat.getValue();
 
 			// check if the class is a subclass, if the check is required
 			if (!OutputFormat.class.isAssignableFrom(this.format.getClass())) {
@@ -340,7 +346,7 @@ public class DataSinkTask<IT> extends AbstractInvokable {
 		// configure the stub. catch exceptions here extra, to report them as originating from the user code 
 		try {
 			thread.setContextClassLoader(userCodeClassLoader);
-			this.format.configure(this.config.getStubParameters());
+			this.format.configure(formatContainer.getParameters(operatorIDAndOutputFormat.getKey()));
 		}
 		catch (Throwable t) {
 			throw new RuntimeException("The user defined 'configure()' method in the Output Format caused an error: " 
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/operators/DataSourceTask.java b/flink-runtime/src/main/java/org/apache/flink/runtime/operators/DataSourceTask.java
index a5ccfab8696..7b06de0d158 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/operators/DataSourceTask.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/operators/DataSourceTask.java
@@ -31,6 +31,8 @@ import org.apache.flink.metrics.SimpleCounter;
 import org.apache.flink.runtime.execution.CancelTaskException;
 import org.apache.flink.runtime.execution.Environment;
 import org.apache.flink.runtime.io.network.api.writer.RecordWriter;
+import org.apache.flink.runtime.jobgraph.InputOutputFormatContainer;
+import org.apache.flink.runtime.jobgraph.OperatorID;
 import org.apache.flink.runtime.jobgraph.tasks.AbstractInvokable;
 import org.apache.flink.runtime.jobgraph.tasks.InputSplitProvider;
 import org.apache.flink.runtime.jobgraph.tasks.InputSplitProviderException;
@@ -43,6 +45,7 @@ import org.apache.flink.runtime.operators.util.TaskConfig;
 import org.apache.flink.runtime.operators.util.metrics.CountingCollector;
 import org.apache.flink.util.Collector;
 
+import org.apache.commons.lang3.tuple.Pair;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -268,9 +271,11 @@ public class DataSourceTask<OT> extends AbstractInvokable {
 		Configuration taskConf = getTaskConfiguration();
 		this.config = new TaskConfig(taskConf);
 
+		final Pair<OperatorID, InputFormat<OT, InputSplit>> operatorIdAndInputFormat;
+		InputOutputFormatContainer formatContainer = new InputOutputFormatContainer(config, userCodeClassLoader);
 		try {
-			this.format = config.<InputFormat<OT, InputSplit>>getStubWrapper(userCodeClassLoader)
-					.getUserCodeObject(InputFormat.class, userCodeClassLoader);
+			operatorIdAndInputFormat = formatContainer.getUniqueInputFormat();
+			this.format = operatorIdAndInputFormat.getValue();
 
 			// check if the class is a subclass, if the check is required
 			if (!InputFormat.class.isAssignableFrom(this.format.getClass())) {
@@ -288,7 +293,7 @@ public class DataSourceTask<OT> extends AbstractInvokable {
 		// configure the stub. catch exceptions here extra, to report them as originating from the user code
 		try {
 			thread.setContextClassLoader(userCodeClassLoader);
-			this.format.configure(this.config.getStubParameters());
+			this.format.configure(formatContainer.getParameters(operatorIdAndInputFormat.getKey()));
 		}
 		catch (Throwable t) {
 			throw new RuntimeException("The user defined 'configure()' method caused an error: " + t.getMessage(), t);
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/jobgraph/InputOutputFormatContainerTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/jobgraph/InputOutputFormatContainerTest.java
new file mode 100644
index 00000000000..cd4493666db
--- /dev/null
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/jobgraph/InputOutputFormatContainerTest.java
@@ -0,0 +1,171 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.runtime.jobgraph;
+
+import org.apache.flink.api.common.io.GenericInputFormat;
+import org.apache.flink.api.common.io.InputFormat;
+import org.apache.flink.api.common.io.OutputFormat;
+import org.apache.flink.api.common.operators.util.UserCodeWrapper;
+import org.apache.flink.api.java.io.DiscardingOutputFormat;
+import org.apache.flink.configuration.Configuration;
+import org.apache.flink.core.io.GenericInputSplit;
+import org.apache.flink.runtime.operators.util.TaskConfig;
+
+import org.junit.Test;
+
+import java.util.Map;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+
+/**
+ * Tests for {@link InputOutputFormatContainer}.
+ */
+public class InputOutputFormatContainerTest {
+
+	@Test
+	public void testInputOutputFormat() {
+		InputOutputFormatContainer formatContainer = new InputOutputFormatContainer(Thread.currentThread().getContextClassLoader());
+
+		OperatorID operatorID1 = new OperatorID();
+		formatContainer.addInputFormat(operatorID1, new TestInputFormat("test input format"));
+		formatContainer.addParameters(operatorID1, "parameter1", "abc123");
+
+		OperatorID operatorID2 = new OperatorID();
+		formatContainer.addOutputFormat(operatorID2, new DiscardingOutputFormat());
+		formatContainer.addParameters(operatorID2, "parameter1", "bcd234");
+
+		OperatorID operatorID3 = new OperatorID();
+		formatContainer.addOutputFormat(operatorID3, new DiscardingOutputFormat());
+		formatContainer.addParameters(operatorID3, "parameter1", "cde345");
+
+		TaskConfig taskConfig = new TaskConfig(new Configuration());
+		formatContainer.write(taskConfig);
+
+		InputOutputFormatContainer loadedFormatContainer = new InputOutputFormatContainer(taskConfig, getClass().getClassLoader());
+
+		Map<OperatorID, UserCodeWrapper<? extends InputFormat<?, ?>>> inputFormats = loadedFormatContainer.getInputFormats();
+		Map<OperatorID, UserCodeWrapper<? extends OutputFormat<?>>> outputFormats = loadedFormatContainer.getOutputFormats();
+		assertEquals(1, inputFormats.size());
+		assertEquals(2, outputFormats.size());
+
+		// verify the input format
+		TestInputFormat inputFormat = (TestInputFormat) inputFormats.get(operatorID1).getUserCodeObject();
+		assertEquals("test input format", inputFormat.getName());
+
+		Configuration inputFormatParams = loadedFormatContainer.getParameters(operatorID1);
+		assertEquals(1, inputFormatParams.keySet().size());
+		assertEquals("abc123", inputFormatParams.getString("parameter1", null));
+
+		// verify the output formats
+		assertTrue(outputFormats.get(operatorID2).getUserCodeObject() instanceof DiscardingOutputFormat);
+		Configuration outputFormatParams1 = loadedFormatContainer.getParameters(operatorID2);
+		assertEquals(1, outputFormatParams1.keySet().size());
+		assertEquals("bcd234", outputFormatParams1.getString("parameter1", null));
+
+		assertTrue(outputFormats.get(operatorID3).getUserCodeObject() instanceof DiscardingOutputFormat);
+		Configuration outputFormatParams2 = loadedFormatContainer.getParameters(operatorID3);
+		assertEquals(1, outputFormatParams2.keySet().size());
+		assertEquals("cde345", outputFormatParams2.getString("parameter1", null));
+	}
+
+	@Test
+	public void testOnlyInputFormat() {
+		InputOutputFormatContainer formatContainer = new InputOutputFormatContainer(Thread.currentThread().getContextClassLoader());
+
+		OperatorID operatorID = new OperatorID();
+		formatContainer.addInputFormat(operatorID, new TestInputFormat("test input format"));
+		formatContainer.addParameters(operatorID, "parameter1", "abc123");
+
+		TaskConfig taskConfig = new TaskConfig(new Configuration());
+		formatContainer.write(taskConfig);
+
+		InputOutputFormatContainer loadedFormatContainer = new InputOutputFormatContainer(taskConfig, getClass().getClassLoader());
+
+		Map<OperatorID, UserCodeWrapper<? extends InputFormat<?, ?>>> inputFormats = loadedFormatContainer.getInputFormats();
+		assertEquals(1, inputFormats.size());
+		assertEquals(0, loadedFormatContainer.getOutputFormats().size());
+
+		TestInputFormat inputFormat = (TestInputFormat) inputFormats.get(operatorID).getUserCodeObject();
+		assertEquals("test input format", inputFormat.getName());
+
+		Configuration parameters = loadedFormatContainer.getParameters(operatorID);
+		assertEquals(1, parameters.keySet().size());
+		assertEquals("abc123", parameters.getString("parameter1", null));
+	}
+
+	@Test
+	public void testOnlyOutputFormat() {
+		InputOutputFormatContainer formatContainer = new InputOutputFormatContainer(Thread.currentThread().getContextClassLoader());
+
+		OperatorID operatorID = new OperatorID();
+		formatContainer.addOutputFormat(operatorID, new DiscardingOutputFormat<>());
+
+		Configuration parameters = new Configuration();
+		parameters.setString("parameter1", "bcd234");
+		formatContainer.addParameters(operatorID, parameters);
+
+		TaskConfig taskConfig = new TaskConfig(new Configuration());
+		formatContainer.write(taskConfig);
+
+		InputOutputFormatContainer loadedFormatContainer = new InputOutputFormatContainer(taskConfig, getClass().getClassLoader());
+
+		Map<OperatorID, UserCodeWrapper<? extends OutputFormat<?>>> outputFormats = loadedFormatContainer.getOutputFormats();
+		assertEquals(1, outputFormats.size());
+		assertEquals(0, loadedFormatContainer.getInputFormats().size());
+
+		assertTrue(outputFormats.get(operatorID).getUserCodeObject() instanceof DiscardingOutputFormat);
+
+		Configuration loadedParameters = loadedFormatContainer.getParameters(operatorID);
+		assertEquals(1, loadedParameters.keySet().size());
+		assertEquals("bcd234", loadedParameters.getString("parameter1", null));
+	}
+
+	// -------------------------------------------------------------------------
+	//                          Utilities
+	// -------------------------------------------------------------------------
+
+	private static final class TestInputFormat extends GenericInputFormat<Object> {
+
+		private final String name;
+
+		TestInputFormat(String name) {
+			this.name = name;
+		}
+
+		public String getName() {
+			return name;
+		}
+
+		@Override
+		public boolean reachedEnd()  {
+			return true;
+		}
+
+		@Override
+		public Object nextRecord(Object reuse) {
+			return null;
+		}
+
+		@Override
+		public GenericInputSplit[] createInputSplits(int numSplits) {
+			return null;
+		}
+	}
+}
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/jobgraph/JobTaskVertexTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/jobgraph/JobTaskVertexTest.java
index 794c5c63782..bf0eb2a2d55 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/jobgraph/JobTaskVertexTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/jobgraph/JobTaskVertexTest.java
@@ -21,9 +21,6 @@ package org.apache.flink.runtime.jobgraph;
 import org.apache.flink.api.common.io.FinalizeOnMaster;
 import org.apache.flink.api.common.io.GenericInputFormat;
 import org.apache.flink.api.common.io.InitializeOnMaster;
-import org.apache.flink.api.common.io.InputFormat;
-import org.apache.flink.api.common.io.OutputFormat;
-import org.apache.flink.api.common.operators.util.UserCodeObjectWrapper;
 import org.apache.flink.api.java.io.DiscardingOutputFormat;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.core.io.GenericInputSplit;
@@ -38,7 +35,11 @@ import java.io.IOException;
 import java.net.URL;
 import java.net.URLClassLoader;
 
-import static org.junit.Assert.*;
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.fail;
 
 @SuppressWarnings("serial")
 public class JobTaskVertexTest {
@@ -48,59 +49,66 @@ public class JobTaskVertexTest {
 		JobVertex source = new JobVertex("source");
 		JobVertex target = new JobVertex("target");
 		target.connectNewDataSetAsInput(source, DistributionPattern.POINTWISE, ResultPartitionType.PIPELINED);
-		
+
 		assertTrue(source.isInputVertex());
 		assertFalse(source.isOutputVertex());
 		assertFalse(target.isInputVertex());
 		assertTrue(target.isOutputVertex());
-		
+
 		assertEquals(1, source.getNumberOfProducedIntermediateDataSets());
 		assertEquals(1, target.getNumberOfInputs());
-		
+
 		assertEquals(target.getInputs().get(0).getSource(), source.getProducedDataSets().get(0));
-		
+
 		assertEquals(1, source.getProducedDataSets().get(0).getConsumers().size());
 		assertEquals(target, source.getProducedDataSets().get(0).getConsumers().get(0).getTarget());
 	}
-	
+
 	@Test
 	public void testConnectMultipleTargets() {
 		JobVertex source = new JobVertex("source");
-		JobVertex target1= new JobVertex("target1");
+		JobVertex target1 = new JobVertex("target1");
 		JobVertex target2 = new JobVertex("target2");
 		target1.connectNewDataSetAsInput(source, DistributionPattern.POINTWISE, ResultPartitionType.PIPELINED);
 		target2.connectDataSetAsInput(source.getProducedDataSets().get(0), DistributionPattern.ALL_TO_ALL);
-		
+
 		assertTrue(source.isInputVertex());
 		assertFalse(source.isOutputVertex());
 		assertFalse(target1.isInputVertex());
 		assertTrue(target1.isOutputVertex());
 		assertFalse(target2.isInputVertex());
 		assertTrue(target2.isOutputVertex());
-		
+
 		assertEquals(1, source.getNumberOfProducedIntermediateDataSets());
 		assertEquals(2, source.getProducedDataSets().get(0).getConsumers().size());
-		
+
 		assertEquals(target1.getInputs().get(0).getSource(), source.getProducedDataSets().get(0));
 		assertEquals(target2.getInputs().get(0).getSource(), source.getProducedDataSets().get(0));
 	}
-	
+
 	@Test
-	public void testOutputFormatVertex() {
+	public void testOutputFormat() {
 		try {
-			final OutputFormat outputFormat = new TestingOutputFormat();
-			final OutputFormatVertex of = new OutputFormatVertex("Name");
-			new TaskConfig(of.getConfiguration()).setStubWrapper(new UserCodeObjectWrapper<OutputFormat<?>>(outputFormat));
+			final InputOutputFormatVertex vertex = new InputOutputFormatVertex("Name");
+
+			OperatorID operatorID = new OperatorID();
+			Configuration parameters = new Configuration();
+			parameters.setString("test_key", "test_value");
+			new InputOutputFormatContainer(Thread.currentThread().getContextClassLoader())
+				.addOutputFormat(operatorID, new TestingOutputFormat(parameters))
+				.addParameters(operatorID, parameters)
+				.write(new TaskConfig(vertex.getConfiguration()));
+
 			final ClassLoader cl = new TestClassLoader();
-			
+
 			try {
-				of.initializeOnMaster(cl);
+				vertex.initializeOnMaster(cl);
 				fail("Did not throw expected exception.");
 			} catch (TestException e) {
 				// all good
 			}
-			
-			OutputFormatVertex copy = InstantiationUtil.clone(of);
+
+			InputOutputFormatVertex copy = InstantiationUtil.clone(vertex);
 			ClassLoader ctxCl = Thread.currentThread().getContextClassLoader();
 			try {
 				copy.initializeOnMaster(cl);
@@ -125,17 +133,23 @@ public class JobTaskVertexTest {
 	}
 
 	@Test
-	public void testInputFormatVertex() {
+	public void testInputFormat() {
 		try {
-			final TestInputFormat inputFormat = new TestInputFormat();
-			final InputFormatVertex vertex = new InputFormatVertex("Name");
-			new TaskConfig(vertex.getConfiguration()).setStubWrapper(new UserCodeObjectWrapper<InputFormat<?, ?>>(inputFormat));
-			
-			final ClassLoader cl = getClass().getClassLoader();
-			
+			final InputOutputFormatVertex vertex = new InputOutputFormatVertex("Name");
+
+			OperatorID operatorID = new OperatorID();
+			Configuration parameters = new Configuration();
+			parameters.setString("test_key", "test_value");
+			new InputOutputFormatContainer(Thread.currentThread().getContextClassLoader())
+				.addInputFormat(operatorID, new TestInputFormat(parameters))
+				.addParameters(operatorID, "test_key", "test_value")
+				.write(new TaskConfig(vertex.getConfiguration()));
+
+			final ClassLoader cl = new TestClassLoader();
+
 			vertex.initializeOnMaster(cl);
 			InputSplit[] splits = vertex.getInputSplitSource().createInputSplits(77);
-			
+
 			assertNotNull(splits);
 			assertEquals(1, splits.length);
 			assertEquals(TestSplit.class, splits[0].getClass());
@@ -145,20 +159,28 @@ public class JobTaskVertexTest {
 			fail(e.getMessage());
 		}
 	}
-	
+
 	// --------------------------------------------------------------------------------------------
-	
+
 	private static final class TestException extends IOException {}
-	
+
 	private static final class TestSplit extends GenericInputSplit {
-		
+
 		public TestSplit(int partitionNumber, int totalNumberOfPartitions) {
 			super(partitionNumber, totalNumberOfPartitions);
 		}
 	}
-	
+
 	private static final class TestInputFormat extends GenericInputFormat<Object> {
 
+		private boolean isConfigured = false;
+
+		private final Configuration expectedParameters;
+
+		public TestInputFormat(Configuration expectedParameters) {
+			this.expectedParameters = expectedParameters;
+		}
+
 		@Override
 		public boolean reachedEnd()  {
 			return false;
@@ -168,17 +190,40 @@ public class JobTaskVertexTest {
 		public Object nextRecord(Object reuse) {
 			return null;
 		}
-		
+
 		@Override
-		public GenericInputSplit[] createInputSplits(int numSplits) throws IOException {
+		public GenericInputSplit[] createInputSplits(int numSplits) {
+			if (!isConfigured) {
+				throw new IllegalStateException("InputFormat was not configured before createInputSplits was called.");
+			}
 			return new GenericInputSplit[] { new TestSplit(0, 1) };
 		}
+
+		@Override
+		public void configure(Configuration parameters) {
+			if (isConfigured) {
+				throw new IllegalStateException("InputFormat is already configured.");
+			}
+			if (!(Thread.currentThread().getContextClassLoader() instanceof TestClassLoader)) {
+				throw new IllegalStateException("Context ClassLoader was not correctly switched.");
+			}
+			for (String key : expectedParameters.keySet()) {
+				assertEquals(expectedParameters.getString(key, null), parameters.getString(key, null));
+			}
+			isConfigured = true;
+		}
 	}
 
 	private static final class TestingOutputFormat extends DiscardingOutputFormat<Object> implements InitializeOnMaster, FinalizeOnMaster {
 
 		private boolean isConfigured = false;
 
+		private final Configuration expectedParameters;
+
+		public TestingOutputFormat(Configuration expectedParameters) {
+			this.expectedParameters = expectedParameters;
+		}
+
 		@Override
 		public void initializeGlobal(int parallelism) throws IOException {
 			if (!isConfigured) {
@@ -211,9 +256,11 @@ public class JobTaskVertexTest {
 			if (!(Thread.currentThread().getContextClassLoader() instanceof TestClassLoader)) {
 				throw new IllegalStateException("Context ClassLoader was not correctly switched.");
 			}
+			for (String key : expectedParameters.keySet()) {
+				assertEquals(expectedParameters.getString(key, null), parameters.getString(key, null));
+			}
 			isConfigured = true;
 		}
-
 	}
 
 	private static class TestClassLoader extends URLClassLoader {
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/operators/DataSinkTaskTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/operators/DataSinkTaskTest.java
index d2194e1d088..78512f19e0f 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/operators/DataSinkTaskTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/operators/DataSinkTaskTest.java
@@ -75,7 +75,7 @@ public class DataSinkTaskTest extends TaskTestBase {
 			DataSinkTask<Record> testTask = new DataSinkTask<>(this.mockEnv);
 
 			File tempTestFile = new File(tempFolder.getRoot(), UUID.randomUUID().toString());
-			super.registerFileOutputTask(MockOutputFormat.class, tempTestFile.toURI().toString());
+			super.registerFileOutputTask(MockOutputFormat.class, tempTestFile.toURI().toString(), new Configuration());
 
 			testTask.invoke();
 
@@ -136,7 +136,7 @@ public class DataSinkTaskTest extends TaskTestBase {
 		DataSinkTask<Record> testTask = new DataSinkTask<>(this.mockEnv);
 
 		File tempTestFile = new File(tempFolder.getRoot(), UUID.randomUUID().toString());
-		super.registerFileOutputTask(MockOutputFormat.class, tempTestFile.toURI().toString());
+		super.registerFileOutputTask(MockOutputFormat.class, tempTestFile.toURI().toString(), new Configuration());
 
 		try {
 			// For the union reader to work, we need to start notifications *after* the union reader
@@ -218,8 +218,8 @@ public class DataSinkTaskTest extends TaskTestBase {
 		super.getTaskConfig().setFilehandlesInput(0, 8);
 		super.getTaskConfig().setSpillingThresholdInput(0, 0.8f);
 
-		File tempTestFile = new File(tempFolder.getRoot(), UUID.randomUUID().toString());;
-		super.registerFileOutputTask(MockOutputFormat.class, tempTestFile.toURI().toString());
+		File tempTestFile = new File(tempFolder.getRoot(), UUID.randomUUID().toString());
+		super.registerFileOutputTask(MockOutputFormat.class, tempTestFile.toURI().toString(), new Configuration());
 
 		try {
 			testTask.invoke();
@@ -287,10 +287,9 @@ public class DataSinkTaskTest extends TaskTestBase {
 
 		DataSinkTask<Record> testTask = new DataSinkTask<>(this.mockEnv);
 		Configuration stubParams = new Configuration();
-		super.getTaskConfig().setStubParameters(stubParams);
 
 		File tempTestFile = new File(tempFolder.getRoot(), UUID.randomUUID().toString());
-		super.registerFileOutputTask(MockFailingOutputFormat.class, tempTestFile.toURI().toString());
+		super.registerFileOutputTask(MockFailingOutputFormat.class, tempTestFile.toURI().toString(), stubParams);
 
 		boolean stubFailed = false;
 
@@ -319,7 +318,6 @@ public class DataSinkTaskTest extends TaskTestBase {
 
 		DataSinkTask<Record> testTask = new DataSinkTask<>(this.mockEnv);
 		Configuration stubParams = new Configuration();
-		super.getTaskConfig().setStubParameters(stubParams);
 
 		// set sorting
 		super.getTaskConfig().setInputLocalStrategy(0, LocalStrategy.SORT);
@@ -330,7 +328,7 @@ public class DataSinkTaskTest extends TaskTestBase {
 		super.getTaskConfig().setSpillingThresholdInput(0, 0.8f);
 
 		File tempTestFile = new File(tempFolder.getRoot(), UUID.randomUUID().toString());
-		super.registerFileOutputTask(MockFailingOutputFormat.class, tempTestFile.toURI().toString());
+		super.registerFileOutputTask(MockFailingOutputFormat.class, tempTestFile.toURI().toString(), stubParams);
 
 		boolean stubFailed = false;
 
@@ -353,11 +351,10 @@ public class DataSinkTaskTest extends TaskTestBase {
 
 		final DataSinkTask<Record> testTask = new DataSinkTask<>(this.mockEnv);
 		Configuration stubParams = new Configuration();
-		super.getTaskConfig().setStubParameters(stubParams);
 
 		File tempTestFile = new File(tempFolder.getRoot(), UUID.randomUUID().toString());
 
-		super.registerFileOutputTask(MockOutputFormat.class, tempTestFile.toURI().toString());
+		super.registerFileOutputTask(MockOutputFormat.class, tempTestFile.toURI().toString(), stubParams);
 
 		Thread taskRunner = new Thread() {
 			@Override
@@ -401,7 +398,6 @@ public class DataSinkTaskTest extends TaskTestBase {
 
 		final DataSinkTask<Record> testTask = new DataSinkTask<>(this.mockEnv);
 		Configuration stubParams = new Configuration();
-		super.getTaskConfig().setStubParameters(stubParams);
 
 		// set sorting
 		super.getTaskConfig().setInputLocalStrategy(0, LocalStrategy.SORT);
@@ -412,7 +408,7 @@ public class DataSinkTaskTest extends TaskTestBase {
 		super.getTaskConfig().setSpillingThresholdInput(0, 0.8f);
 
 		File tempTestFile = new File(tempFolder.getRoot(), UUID.randomUUID().toString());
-		super.registerFileOutputTask(MockOutputFormat.class, tempTestFile.toURI().toString());
+		super.registerFileOutputTask(MockOutputFormat.class, tempTestFile.toURI().toString(), stubParams);
 
 		Thread taskRunner = new Thread() {
 			@Override
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/TaskTestBase.java b/flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/TaskTestBase.java
index 9b0b1dcd160..1a4653917ff 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/TaskTestBase.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/operators/testutils/TaskTestBase.java
@@ -22,11 +22,12 @@ import org.apache.flink.api.common.functions.RichFunction;
 import org.apache.flink.api.common.io.DelimitedInputFormat;
 import org.apache.flink.api.common.io.FileOutputFormat;
 import org.apache.flink.api.common.operators.util.UserCodeClassWrapper;
-import org.apache.flink.api.common.operators.util.UserCodeObjectWrapper;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.core.fs.FileSystem.WriteMode;
 import org.apache.flink.core.fs.Path;
 import org.apache.flink.runtime.io.network.partition.consumer.IteratorWrappingTestSingleInputGate;
+import org.apache.flink.runtime.jobgraph.InputOutputFormatContainer;
+import org.apache.flink.runtime.jobgraph.OperatorID;
 import org.apache.flink.runtime.jobgraph.tasks.AbstractInvokable;
 import org.apache.flink.runtime.memory.MemoryManager;
 import org.apache.flink.runtime.operators.Driver;
@@ -102,22 +103,35 @@ public abstract class TaskTestBase extends TestLogger {
 		config.setStubWrapper(new UserCodeClassWrapper<>(stubClass));
 	}
 
-	public void registerFileOutputTask(Class<? extends FileOutputFormat<Record>> stubClass, String outPath) {
-		registerFileOutputTask(InstantiationUtil.instantiate(stubClass, FileOutputFormat.class), outPath);
+	public void registerFileOutputTask(
+		Class<? extends FileOutputFormat<Record>> stubClass,
+		String outPath,
+		Configuration formatParams) {
+
+		registerFileOutputTask(InstantiationUtil.instantiate(stubClass, FileOutputFormat.class), outPath, formatParams);
 	}
 
-	public void registerFileOutputTask(FileOutputFormat<Record> outputFormat, String outPath) {
-		TaskConfig dsConfig = new TaskConfig(this.mockEnv.getTaskConfiguration());
+	public void registerFileOutputTask(
+		FileOutputFormat<Record> outputFormat,
+		String outPath,
+		Configuration formatParams) {
 
 		outputFormat.setOutputFilePath(new Path(outPath));
 		outputFormat.setWriteMode(WriteMode.OVERWRITE);
 
-		dsConfig.setStubWrapper(new UserCodeObjectWrapper<>(outputFormat));
+		OperatorID operatorID = new OperatorID();
+		new InputOutputFormatContainer(Thread.currentThread().getContextClassLoader())
+			.addOutputFormat(operatorID, outputFormat)
+			.addParameters(operatorID, formatParams)
+			.write(new TaskConfig(this.mockEnv.getTaskConfiguration()));
 	}
 
-	public void registerFileInputTask(AbstractInvokable inTask,
-			Class<? extends DelimitedInputFormat<Record>> stubClass, String inPath, String delimiter)
-	{
+	public void registerFileInputTask(
+		AbstractInvokable inTask,
+		Class<? extends DelimitedInputFormat<Record>> stubClass,
+		String inPath,
+		String delimiter)	{
+
 		DelimitedInputFormat<Record> format;
 		try {
 			format = stubClass.newInstance();
@@ -129,8 +143,10 @@ public abstract class TaskTestBase extends TestLogger {
 		format.setFilePath(inPath);
 		format.setDelimiter(delimiter);
 
-		TaskConfig dsConfig = new TaskConfig(this.mockEnv.getTaskConfiguration());
-		dsConfig.setStubWrapper(new UserCodeObjectWrapper<>(format));
+		OperatorID operatorID = new OperatorID();
+		new InputOutputFormatContainer(Thread.currentThread().getContextClassLoader())
+			.addInputFormat(operatorID, format)
+			.write(new TaskConfig(this.mockEnv.getTaskConfiguration()));
 
 		this.inputSplitProvider.addInputSplits(inPath, 5);
 	}
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/sink/OutputFormatSinkFunction.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/sink/OutputFormatSinkFunction.java
index 2bc47ef2614..4130a50d422 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/sink/OutputFormatSinkFunction.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/sink/OutputFormatSinkFunction.java
@@ -111,4 +111,7 @@ public class OutputFormatSinkFunction<IN> extends RichSinkFunction<IN> implement
 		}
 	}
 
+	public OutputFormat<IN> getFormat() {
+		return format;
+	}
 }
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamGraph.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamGraph.java
index 19dd21fa573..63b4724d80b 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamGraph.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamGraph.java
@@ -21,6 +21,7 @@ import org.apache.flink.annotation.Internal;
 import org.apache.flink.api.common.ExecutionConfig;
 import org.apache.flink.api.common.JobID;
 import org.apache.flink.api.common.io.InputFormat;
+import org.apache.flink.api.common.io.OutputFormat;
 import org.apache.flink.api.common.operators.ResourceSpec;
 import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.api.common.typeutils.TypeSerializer;
@@ -510,6 +511,10 @@ public class StreamGraph extends StreamingPlan {
 		getStreamNode(vertexID).setInputFormat(inputFormat);
 	}
 
+	public void setOutputFormat(Integer vertexID, OutputFormat<?> outputFormat) {
+		getStreamNode(vertexID).setOutputFormat(outputFormat);
+	}
+
 	void setTransformationUID(Integer nodeId, String transformationId) {
 		StreamNode node = streamNodes.get(nodeId);
 		if (node != null) {
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamGraphGenerator.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamGraphGenerator.java
index a38cf89ca3f..ef3162b84b7 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamGraphGenerator.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamGraphGenerator.java
@@ -24,6 +24,8 @@ import org.apache.flink.api.java.tuple.Tuple2;
 import org.apache.flink.runtime.state.KeyGroupRangeAssignment;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.api.operators.InputFormatOperatorFactory;
+import org.apache.flink.streaming.api.operators.OutputFormatOperatorFactory;
+import org.apache.flink.streaming.api.operators.StreamOperatorFactory;
 import org.apache.flink.streaming.api.transformations.CoFeedbackTransformation;
 import org.apache.flink.streaming.api.transformations.FeedbackTransformation;
 import org.apache.flink.streaming.api.transformations.OneInputTransformation;
@@ -509,6 +511,11 @@ public class StreamGraphGenerator {
 				null,
 				"Sink: " + sink.getName());
 
+		StreamOperatorFactory operatorFactory = sink.getOperatorFactory();
+		if (operatorFactory instanceof OutputFormatOperatorFactory) {
+			streamGraph.setOutputFormat(sink.getId(), ((OutputFormatOperatorFactory) operatorFactory).getOutputFormat());
+		}
+
 		streamGraph.setParallelism(sink.getId(), sink.getParallelism());
 		streamGraph.setMaxParallelism(sink.getId(), sink.getMaxParallelism());
 
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamNode.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamNode.java
index 9001c1cc09b..579a605bcb7 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamNode.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamNode.java
@@ -21,6 +21,7 @@ import org.apache.flink.annotation.Internal;
 import org.apache.flink.annotation.VisibleForTesting;
 import org.apache.flink.api.common.ExecutionConfig;
 import org.apache.flink.api.common.io.InputFormat;
+import org.apache.flink.api.common.io.OutputFormat;
 import org.apache.flink.api.common.operators.ResourceSpec;
 import org.apache.flink.api.common.typeutils.TypeSerializer;
 import org.apache.flink.api.java.functions.KeySelector;
@@ -76,6 +77,7 @@ public class StreamNode implements Serializable {
 	private final Class<? extends AbstractInvokable> jobVertexClass;
 
 	private InputFormat<?, ?> inputFormat;
+	private OutputFormat<?> outputFormat;
 
 	private String transformationUID;
 	private String userHash;
@@ -268,6 +270,14 @@ public class StreamNode implements Serializable {
 		this.inputFormat = inputFormat;
 	}
 
+	public OutputFormat<?> getOutputFormat() {
+		return outputFormat;
+	}
+
+	public void setOutputFormat(OutputFormat<?> outputFormat) {
+		this.outputFormat = outputFormat;
+	}
+
 	public void setSlotSharingGroup(String slotSharingGroup) {
 		this.slotSharingGroup = slotSharingGroup;
 	}
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamingJobGraphGenerator.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamingJobGraphGenerator.java
index fdb38f5f3f3..7bd49d00462 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamingJobGraphGenerator.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamingJobGraphGenerator.java
@@ -22,7 +22,6 @@ import org.apache.flink.api.common.ExecutionConfig;
 import org.apache.flink.api.common.JobID;
 import org.apache.flink.api.common.functions.Function;
 import org.apache.flink.api.common.operators.ResourceSpec;
-import org.apache.flink.api.common.operators.util.UserCodeObjectWrapper;
 import org.apache.flink.api.java.tuple.Tuple2;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.configuration.IllegalConfigurationException;
@@ -31,7 +30,8 @@ import org.apache.flink.runtime.checkpoint.CheckpointRetentionPolicy;
 import org.apache.flink.runtime.checkpoint.MasterTriggerRestoreHook;
 import org.apache.flink.runtime.io.network.partition.ResultPartitionType;
 import org.apache.flink.runtime.jobgraph.DistributionPattern;
-import org.apache.flink.runtime.jobgraph.InputFormatVertex;
+import org.apache.flink.runtime.jobgraph.InputOutputFormatContainer;
+import org.apache.flink.runtime.jobgraph.InputOutputFormatVertex;
 import org.apache.flink.runtime.jobgraph.JobEdge;
 import org.apache.flink.runtime.jobgraph.JobGraph;
 import org.apache.flink.runtime.jobgraph.JobVertex;
@@ -111,6 +111,8 @@ public class StreamingJobGraphGenerator {
 	private final Map<Integer, ResourceSpec> chainedMinResources;
 	private final Map<Integer, ResourceSpec> chainedPreferredResources;
 
+	private final Map<Integer, InputOutputFormatContainer> chainedInputOutputFormats;
+
 	private final StreamGraphHasher defaultStreamGraphHasher;
 	private final List<StreamGraphHasher> legacyStreamGraphHashers;
 
@@ -130,6 +132,7 @@ public class StreamingJobGraphGenerator {
 		this.chainedNames = new HashMap<>();
 		this.chainedMinResources = new HashMap<>();
 		this.chainedPreferredResources = new HashMap<>();
+		this.chainedInputOutputFormats = new HashMap<>();
 		this.physicalEdgesInOrder = new ArrayList<>();
 
 		jobGraph = new JobGraph(jobID, streamGraph.getJobName());
@@ -219,7 +222,9 @@ public class StreamingJobGraphGenerator {
 			List<StreamEdge> chainableOutputs = new ArrayList<StreamEdge>();
 			List<StreamEdge> nonChainableOutputs = new ArrayList<StreamEdge>();
 
-			for (StreamEdge outEdge : streamGraph.getStreamNode(currentNodeId).getOutEdges()) {
+			StreamNode currentNode = streamGraph.getStreamNode(currentNodeId);
+
+			for (StreamEdge outEdge : currentNode.getOutEdges()) {
 				if (isChainable(outEdge, streamGraph)) {
 					chainableOutputs.add(outEdge);
 				} else {
@@ -241,6 +246,7 @@ public class StreamingJobGraphGenerator {
 				chainedOperatorHashes.computeIfAbsent(startNodeId, k -> new ArrayList<>());
 
 			byte[] primaryHashBytes = hashes.get(currentNodeId);
+			OperatorID currentOperatorId = new OperatorID(primaryHashBytes);
 
 			for (Map<Integer, byte[]> legacyHash : legacyHashes) {
 				operatorHashes.add(new Tuple2<>(primaryHashBytes, legacyHash.get(currentNodeId)));
@@ -250,6 +256,14 @@ public class StreamingJobGraphGenerator {
 			chainedMinResources.put(currentNodeId, createChainedMinResources(currentNodeId, chainableOutputs));
 			chainedPreferredResources.put(currentNodeId, createChainedPreferredResources(currentNodeId, chainableOutputs));
 
+			if (currentNode.getInputFormat() != null) {
+				getOrCreateFormatContainer(startNodeId).addInputFormat(currentOperatorId, currentNode.getInputFormat());
+			}
+
+			if (currentNode.getOutputFormat() != null) {
+				getOrCreateFormatContainer(startNodeId).addOutputFormat(currentOperatorId, currentNode.getOutputFormat());
+			}
+
 			StreamConfig config = currentNodeId.equals(startNodeId)
 					? createJobVertex(startNodeId, hashes, legacyHashes, chainedOperatorHashes)
 					: new StreamConfig(new Configuration());
@@ -279,7 +293,7 @@ public class StreamingJobGraphGenerator {
 				chainedConfigs.get(startNodeId).put(currentNodeId, config);
 			}
 
-			config.setOperatorID(new OperatorID(primaryHashBytes));
+			config.setOperatorID(currentOperatorId);
 
 			if (chainableOutputs.isEmpty()) {
 				config.setChainEnd();
@@ -291,6 +305,11 @@ public class StreamingJobGraphGenerator {
 		}
 	}
 
+	private InputOutputFormatContainer getOrCreateFormatContainer(Integer startNodeId) {
+		return chainedInputOutputFormats
+			.computeIfAbsent(startNodeId, k -> new InputOutputFormatContainer(Thread.currentThread().getContextClassLoader()));
+	}
+
 	private String createChainedName(Integer vertexID, List<StreamEdge> chainedOutputs) {
 		String operatorName = streamGraph.getStreamNode(vertexID).getOperatorName();
 		if (chainedOutputs.size() > 1) {
@@ -358,15 +377,17 @@ public class StreamingJobGraphGenerator {
 			}
 		}
 
-		if (streamNode.getInputFormat() != null) {
-			jobVertex = new InputFormatVertex(
+		if (chainedInputOutputFormats.containsKey(streamNodeId)) {
+			jobVertex = new InputOutputFormatVertex(
 					chainedNames.get(streamNodeId),
 					jobVertexId,
 					legacyJobVertexIds,
 					chainedOperatorVertexIds,
 					userDefinedChainedOperatorVertexIds);
-			TaskConfig taskConfig = new TaskConfig(jobVertex.getConfiguration());
-			taskConfig.setStubWrapper(new UserCodeObjectWrapper<Object>(streamNode.getInputFormat()));
+
+			chainedInputOutputFormats
+				.get(streamNodeId)
+				.write(new TaskConfig(jobVertex.getConfiguration()));
 		} else {
 			jobVertex = new JobVertex(
 					chainedNames.get(streamNodeId),
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/OutputFormatOperatorFactory.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/OutputFormatOperatorFactory.java
new file mode 100644
index 00000000000..d23c74f0107
--- /dev/null
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/OutputFormatOperatorFactory.java
@@ -0,0 +1,35 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.streaming.api.operators;
+
+import org.apache.flink.annotation.Internal;
+import org.apache.flink.api.common.io.OutputFormat;
+
+/**
+ * Interface for operator factories which create the sink operator containing an {@link OutputFormat}.
+ *
+ * @param <IN> The input type of the operator.
+ */
+@Internal
+public interface OutputFormatOperatorFactory<IN> extends StreamOperatorFactory<Object> {
+
+	/**
+	 * @return output format of the operator created by this factory.
+	 */
+	OutputFormat<IN> getOutputFormat();
+}
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/SimpleOperatorFactory.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/SimpleOperatorFactory.java
index 8b2ea06af1d..a68fe319443 100644
--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/SimpleOperatorFactory.java
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/SimpleOperatorFactory.java
@@ -21,6 +21,7 @@ import org.apache.flink.annotation.Internal;
 import org.apache.flink.api.common.ExecutionConfig;
 import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.api.java.typeutils.InputTypeConfigurable;
+import org.apache.flink.streaming.api.functions.sink.OutputFormatSinkFunction;
 import org.apache.flink.streaming.api.functions.source.InputFormatSourceFunction;
 import org.apache.flink.streaming.api.graph.StreamConfig;
 import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
@@ -41,12 +42,16 @@ public class SimpleOperatorFactory<OUT> implements StreamOperatorFactory<OUT> {
 	/**
 	 * Create a SimpleOperatorFactory from existed StreamOperator.
 	 */
+	@SuppressWarnings("unchecked")
 	public static <OUT> SimpleOperatorFactory<OUT> of(StreamOperator<OUT> operator) {
 		if (operator == null) {
 			return null;
 		} else if (operator instanceof StreamSource &&
 				((StreamSource) operator).getUserFunction() instanceof InputFormatSourceFunction) {
 			return new SimpleInputFormatOperatorFactory<OUT>((StreamSource) operator);
+		} else if (operator instanceof StreamSink &&
+			((StreamSink) operator).getUserFunction() instanceof OutputFormatSinkFunction) {
+			return new SimpleOutputFormatOperatorFactory<>((StreamSink) operator);
 		} else if (operator instanceof AbstractUdfStreamOperator) {
 			return new SimpleUdfStreamOperatorFactory<OUT>((AbstractUdfStreamOperator) operator);
 		} else {
diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/SimpleOutputFormatOperatorFactory.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/SimpleOutputFormatOperatorFactory.java
new file mode 100644
index 00000000000..c927d202639
--- /dev/null
+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/SimpleOutputFormatOperatorFactory.java
@@ -0,0 +1,48 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.streaming.api.operators;
+
+import org.apache.flink.annotation.Internal;
+import org.apache.flink.api.common.io.OutputFormat;
+import org.apache.flink.streaming.api.functions.sink.OutputFormatSinkFunction;
+
+import static org.apache.flink.util.Preconditions.checkState;
+
+/**
+ * A simple operator factory which create {@link StreamSink} containing an {@link OutputFormat}.
+ *
+ * @param <IN> The input type of the operator.
+ */
+@Internal
+public class SimpleOutputFormatOperatorFactory<IN>
+	extends SimpleOperatorFactory<Object> implements OutputFormatOperatorFactory<IN> {
+
+	private final StreamSink<IN> operator;
+
+	public SimpleOutputFormatOperatorFactory(StreamSink<IN> operator) {
+		super(operator);
+
+		checkState(operator.getUserFunction() instanceof OutputFormatSinkFunction);
+		this.operator = operator;
+	}
+
+	@Override
+	public OutputFormat<IN> getOutputFormat() {
+		return ((OutputFormatSinkFunction<IN>) operator.getUserFunction()).getFormat();
+	}
+}
diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/graph/StreamingJobGraphGeneratorTest.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/graph/StreamingJobGraphGeneratorTest.java
index 93e03011d61..996ac420717 100644
--- a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/graph/StreamingJobGraphGeneratorTest.java
+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/graph/StreamingJobGraphGeneratorTest.java
@@ -21,18 +21,29 @@ import org.apache.flink.api.common.functions.FilterFunction;
 import org.apache.flink.api.common.functions.FlatMapFunction;
 import org.apache.flink.api.common.functions.MapFunction;
 import org.apache.flink.api.common.functions.ReduceFunction;
+import org.apache.flink.api.common.io.InputFormat;
+import org.apache.flink.api.common.io.OutputFormat;
 import org.apache.flink.api.common.operators.ResourceSpec;
+import org.apache.flink.api.common.operators.util.UserCodeWrapper;
+import org.apache.flink.api.common.typeinfo.TypeInformation;
+import org.apache.flink.api.java.io.DiscardingOutputFormat;
+import org.apache.flink.api.java.io.TypeSerializerInputFormat;
 import org.apache.flink.api.java.tuple.Tuple2;
 import org.apache.flink.runtime.io.network.partition.ResultPartitionType;
+import org.apache.flink.runtime.jobgraph.InputOutputFormatContainer;
+import org.apache.flink.runtime.jobgraph.InputOutputFormatVertex;
 import org.apache.flink.runtime.jobgraph.JobGraph;
 import org.apache.flink.runtime.jobgraph.JobVertex;
+import org.apache.flink.runtime.jobgraph.OperatorID;
 import org.apache.flink.runtime.jobgraph.tasks.JobCheckpointingSettings;
+import org.apache.flink.runtime.operators.util.TaskConfig;
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.datastream.DataStreamSink;
 import org.apache.flink.streaming.api.datastream.IterativeStream;
 import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.api.functions.sink.SinkFunction;
+import org.apache.flink.streaming.api.functions.source.InputFormatSourceFunction;
 import org.apache.flink.streaming.api.functions.source.ParallelSourceFunction;
 import org.apache.flink.util.Collector;
 import org.apache.flink.util.TestLogger;
@@ -40,6 +51,7 @@ import org.apache.flink.util.TestLogger;
 import org.junit.Test;
 
 import java.lang.reflect.Method;
+import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
@@ -309,4 +321,51 @@ public class StreamingJobGraphGeneratorTest extends TestLogger {
 			}
 		}
 	}
+
+	@Test
+	public void testInputOutputFormat() {
+		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
+
+		DataStream<Long> source = env.addSource(
+			new InputFormatSourceFunction<>(
+				new TypeSerializerInputFormat<>(TypeInformation.of(Long.class)),
+				TypeInformation.of(Long.class)),
+			TypeInformation.of(Long.class)).name("source");
+
+		source.writeUsingOutputFormat(new DiscardingOutputFormat<>()).name("sink1");
+		source.writeUsingOutputFormat(new DiscardingOutputFormat<>()).name("sink2");
+
+		StreamGraph streamGraph = env.getStreamGraph();
+		JobGraph jobGraph = StreamingJobGraphGenerator.createJobGraph(streamGraph);
+		assertEquals(1, jobGraph.getNumberOfVertices());
+
+		JobVertex jobVertex = jobGraph.getVertices().iterator().next();
+		assertTrue(jobVertex instanceof InputOutputFormatVertex);
+
+		InputOutputFormatContainer formatContainer = new InputOutputFormatContainer(
+			new TaskConfig(jobVertex.getConfiguration()), Thread.currentThread().getContextClassLoader());
+		Map<OperatorID, UserCodeWrapper<? extends InputFormat<?, ?>>> inputFormats = formatContainer.getInputFormats();
+		Map<OperatorID, UserCodeWrapper<? extends OutputFormat<?>>> outputFormats = formatContainer.getOutputFormats();
+		assertEquals(1, inputFormats.size());
+		assertEquals(2, outputFormats.size());
+
+		Map<String, OperatorID> nameToOperatorIds = new HashMap<>();
+		StreamConfig headConfig = new StreamConfig(jobVertex.getConfiguration());
+		nameToOperatorIds.put(headConfig.getOperatorName(), headConfig.getOperatorID());
+
+		Map<Integer, StreamConfig> chainedConfigs = headConfig
+			.getTransitiveChainedTaskConfigs(Thread.currentThread().getContextClassLoader());
+		for (StreamConfig config : chainedConfigs.values()) {
+			nameToOperatorIds.put(config.getOperatorName(), config.getOperatorID());
+		}
+
+		InputFormat<?, ?> sourceFormat = inputFormats.get(nameToOperatorIds.get("Source: source")).getUserCodeObject();
+		assertTrue(sourceFormat instanceof TypeSerializerInputFormat);
+
+		OutputFormat<?> sinkFormat1 = outputFormats.get(nameToOperatorIds.get("Sink: sink1")).getUserCodeObject();
+		assertTrue(sinkFormat1 instanceof DiscardingOutputFormat);
+
+		OutputFormat<?> sinkFormat2 = outputFormats.get(nameToOperatorIds.get("Sink: sink2")).getUserCodeObject();
+		assertTrue(sinkFormat2 instanceof DiscardingOutputFormat);
+	}
 }
