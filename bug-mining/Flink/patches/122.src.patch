diff --git a/flink-core/src/main/java/org/apache/flink/api/common/io/FinalizeOnMaster.java b/flink-core/src/main/java/org/apache/flink/api/common/io/FinalizeOnMaster.java
new file mode 100644
index 00000000000..6fa535c4ffe
--- /dev/null
+++ b/flink-core/src/main/java/org/apache/flink/api/common/io/FinalizeOnMaster.java
@@ -0,0 +1,36 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.api.common.io;
+
+import java.io.IOException;
+
+/**
+ * This interface may be implemented by {@link OutputFormat}s to have the master finalize them globally.
+ * 
+ */
+public interface FinalizeOnMaster {
+
+	/**
+	 * The method is invoked on the master (JobManager) after all (parallel) instances of an OutputFormat finished.
+	 * 
+	 * @param parallelism The degree of parallelism with which the format or functions was run.
+	 * @throws IOException The finalization may throw exceptions, which may cause the job to abort.
+	 */
+	void finalizeGlobal(int parallelism) throws IOException;
+}
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionGraph.java b/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionGraph.java
index 74e48c8f324..29f157c67c5 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionGraph.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionGraph.java
@@ -72,6 +72,9 @@ public class ExecutionGraph {
 	/** The job configuration that was originally attached to the JobGraph. */
 	private final Configuration jobConfiguration;
 	
+	/** The classloader of the user code. */
+	private final ClassLoader userClassLoader;
+	
 	/** All job vertices that are part of this graph */
 	private final ConcurrentHashMap<JobVertexID, ExecutionJobVertex> tasks;
 	
@@ -124,14 +127,20 @@ public class ExecutionGraph {
 	}
 	
 	public ExecutionGraph(JobID jobId, String jobName, Configuration jobConfig,
-						List<BlobKey> requiredJarFiles,ExecutorService executor) {
-		if (jobId == null || jobName == null || jobConfig == null) {
+						List<BlobKey> requiredJarFiles, ExecutorService executor) {
+		this(jobId, jobName, jobConfig, requiredJarFiles, Thread.currentThread().getContextClassLoader(), null);
+	}
+	
+	public ExecutionGraph(JobID jobId, String jobName, Configuration jobConfig, 
+			List<BlobKey> requiredJarFiles, ClassLoader userClassLoader, ExecutorService executor) {
+		if (jobId == null || jobName == null || jobConfig == null || userClassLoader == null) {
 			throw new NullPointerException();
 		}
 		
 		this.jobID = jobId;
 		this.jobName = jobName;
 		this.jobConfiguration = jobConfig;
+		this.userClassLoader = userClassLoader;
 		this.executor = executor;
 		
 		this.tasks = new ConcurrentHashMap<JobVertexID, ExecutionJobVertex>();
@@ -226,6 +235,10 @@ public class ExecutionGraph {
 		return jobConfiguration;
 	}
 	
+	public ClassLoader getUserClassLoader() {
+		return this.userClassLoader;
+	}
+	
 	public JobStatus getState() {
 		return state;
 	}
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionJobVertex.java b/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionJobVertex.java
index 73534f5e22a..9f8b56a486f 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionJobVertex.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionJobVertex.java
@@ -326,6 +326,15 @@ public class ExecutionJobVertex {
 				numSubtasksInFinalState++;
 				
 				if (numSubtasksInFinalState == parallelism) {
+					
+					// call finalizeOnMaster hook
+					try {
+						getJobVertex().finalizeOnMaster(getGraph().getUserClassLoader());
+					}
+					catch (Throwable t) {
+						getGraph().fail(t);
+					}
+					
 					// we are in our final state
 					stateMonitor.notifyAll();
 					
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/AbstractJobVertex.java b/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/AbstractJobVertex.java
index 0ce07ed24ff..b9e1eac1816 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/AbstractJobVertex.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/AbstractJobVertex.java
@@ -374,6 +374,15 @@ public class AbstractJobVertex implements java.io.Serializable {
 	 */
 	public void initializeOnMaster(ClassLoader loader) throws Exception {}
 	
+	/**
+	 * A hook that can be overwritten by sub classes to implement logic that is called by the 
+	 * master after the job completed.
+	 * 
+	 * @param loader The class loader for user defined code.
+	 * @throws Exception The method may throw exceptions which cause the job to fail immediately.
+	 */
+	public void finalizeOnMaster(ClassLoader loader) throws Exception {}
+	
 	// --------------------------------------------------------------------------------------------
 
 	@Override
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/OutputFormatVertex.java b/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/OutputFormatVertex.java
index 708b390166e..2a1f89ca6a9 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/OutputFormatVertex.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/OutputFormatVertex.java
@@ -18,6 +18,7 @@
 
 package org.apache.flink.runtime.jobgraph;
 
+import org.apache.flink.api.common.io.FinalizeOnMaster;
 import org.apache.flink.api.common.io.InitializeOnMaster;
 import org.apache.flink.api.common.io.OutputFormat;
 import org.apache.flink.api.common.operators.util.UserCodeWrapper;
@@ -83,4 +84,38 @@ public class OutputFormatVertex extends AbstractJobVertex {
 			((InitializeOnMaster) outputFormat).initializeGlobal(getParallelism());
 		}
 	}
+	
+	@Override
+	public void finalizeOnMaster(ClassLoader loader) throws Exception {
+		final TaskConfig cfg = new TaskConfig(getConfiguration());
+
+		UserCodeWrapper<OutputFormat<?>> wrapper;
+		try {
+			wrapper = cfg.<OutputFormat<?>>getStubWrapper(loader);
+		}
+		catch (Throwable t) {
+			throw new Exception("Deserializing the OutputFormat (" + formatDescription + ") failed: " + t.getMessage(), t);
+		}
+		if (wrapper == null) {
+			throw new Exception("No input format present in InputFormatVertex's task configuration.");
+		}
+
+		OutputFormat<?> outputFormat;
+		try {
+			outputFormat = wrapper.getUserCodeObject(OutputFormat.class, loader);
+		}
+		catch (Throwable t) {
+			throw new Exception("Instantiating the OutputFormat (" + formatDescription + ") failed: " + t.getMessage(), t);
+		}
+		try {
+			outputFormat.configure(cfg.getStubParameters());
+		}
+		catch (Throwable t) {
+			throw new Exception("Configuring the OutputFormat (" + formatDescription + ") failed: " + t.getMessage(), t);
+		}
+		
+		if (outputFormat instanceof FinalizeOnMaster) {
+			((FinalizeOnMaster) outputFormat).finalizeGlobal(getParallelism());
+		}
+	}
 }
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/jobmanager/JobManager.java b/flink-runtime/src/main/java/org/apache/flink/runtime/jobmanager/JobManager.java
index 95287d1dfe4..0cd08f5aa50 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/jobmanager/JobManager.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/jobmanager/JobManager.java
@@ -330,15 +330,21 @@ public class JobManager implements ExtendedManagementProtocol, InputSplitProvide
 			// Register this job with the library cache manager
 			libraryCacheManager.registerJob(job.getJobID(), job.getUserJarBlobKeys());
 			
+			// grab the class loader for user-defined code
+			final ClassLoader userCodeLoader = libraryCacheManager.getClassLoader(job.getJobID());
+			if (userCodeLoader == null) {
+				throw new JobException("The user code class loader could not be initialized.");
+			}
+			
 			// get the existing execution graph (if we attach), or construct a new empty one to attach
 			executionGraph = this.currentJobs.get(job.getJobID());
 			if (executionGraph == null) {
 				if (LOG.isInfoEnabled()) {
 					LOG.info("Creating new execution graph for job " + job.getJobID() + " (" + job.getName() + ')');
 				}
-				
+
 				executionGraph = new ExecutionGraph(job.getJobID(), job.getName(),
-						job.getJobConfiguration(), job.getUserJarBlobKeys(), this.executorService);
+						job.getJobConfiguration(), job.getUserJarBlobKeys(), userCodeLoader, this.executorService);
 
 				executionGraph.setNumberOfRetriesLeft(job.getNumberOfExecutionRetries() >= 0 ?
 						job.getNumberOfExecutionRetries() : this.defaultExecutionRetries);
@@ -358,12 +364,6 @@ public class JobManager implements ExtendedManagementProtocol, InputSplitProvide
 			// Register for updates on the job status
 			executionGraph.registerJobStatusListener(this);
 			
-			// grab the class loader for user-defined code
-			final ClassLoader userCodeLoader = libraryCacheManager.getClassLoader(job.getJobID());
-			if (userCodeLoader == null) {
-				throw new JobException("The user code class loader could not be initialized.");
-			}
-
 			// first, perform the master initialization of the nodes
 			if (LOG.isDebugEnabled()) {
 				LOG.debug(String.format("Running master initialization of job %s (%s)", job.getJobID(), job.getName()));
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/executiongraph/ExecutionGraphDeploymentTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/executiongraph/ExecutionGraphDeploymentTest.java
index 4cddcbd288c..14ce15ab1b8 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/executiongraph/ExecutionGraphDeploymentTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/executiongraph/ExecutionGraphDeploymentTest.java
@@ -22,12 +22,15 @@ import static org.apache.flink.runtime.executiongraph.ExecutionGraphTestUtils.ge
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.fail;
+import static org.mockito.Mockito.doAnswer;
 import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.when;
 import static org.mockito.Mockito.spy;
-import static org.mockito.Mockito.doAnswer;
+import static org.mockito.Mockito.when;
 
+import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collections;
+import java.util.Comparator;
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicReference;
@@ -45,9 +48,7 @@ import org.apache.flink.runtime.jobmanager.scheduler.Scheduler;
 import org.apache.flink.runtime.operators.RegularPactTask;
 import org.apache.flink.runtime.protocols.TaskOperationProtocol;
 import org.apache.flink.runtime.taskmanager.TaskOperationResult;
-
 import org.junit.Test;
-
 import org.mockito.Matchers;
 import org.mockito.invocation.InvocationOnMock;
 import org.mockito.stubbing.Answer;
@@ -150,7 +151,14 @@ public class ExecutionGraphDeploymentTest {
 	@Test
 	public void testRegistrationOfExecutionsFinishing() {
 		try {
-			Map<ExecutionAttemptID, Execution> executions = setupExecution(7650, 2350);
+			
+			final JobVertexID jid1 = new JobVertexID();
+			final JobVertexID jid2 = new JobVertexID();
+			
+			AbstractJobVertex v1 = new AbstractJobVertex("v1", jid1);
+			AbstractJobVertex v2 = new AbstractJobVertex("v2", jid2);
+			
+			Map<ExecutionAttemptID, Execution> executions = setupExecution(v1, 7650, v2, 2350);
 			
 			for (Execution e : executions.values()) {
 				e.markFinished();
@@ -167,7 +175,14 @@ public class ExecutionGraphDeploymentTest {
 	@Test
 	public void testRegistrationOfExecutionsFailing() {
 		try {
-			Map<ExecutionAttemptID, Execution> executions = setupExecution(7, 6);
+			
+			final JobVertexID jid1 = new JobVertexID();
+			final JobVertexID jid2 = new JobVertexID();
+			
+			AbstractJobVertex v1 = new AbstractJobVertex("v1", jid1);
+			AbstractJobVertex v2 = new AbstractJobVertex("v2", jid2);
+			
+			Map<ExecutionAttemptID, Execution> executions = setupExecution(v1, 7, v2, 6);
 			
 			for (Execution e : executions.values()) {
 				e.markFailed(null);
@@ -184,7 +199,14 @@ public class ExecutionGraphDeploymentTest {
 	@Test
 	public void testRegistrationOfExecutionsFailedExternally() {
 		try {
-			Map<ExecutionAttemptID, Execution> executions = setupExecution(7, 6);
+			
+			final JobVertexID jid1 = new JobVertexID();
+			final JobVertexID jid2 = new JobVertexID();
+			
+			AbstractJobVertex v1 = new AbstractJobVertex("v1", jid1);
+			AbstractJobVertex v2 = new AbstractJobVertex("v2", jid2);
+			
+			Map<ExecutionAttemptID, Execution> executions = setupExecution(v1, 7, v2, 6);
 			
 			for (Execution e : executions.values()) {
 				e.fail(null);
@@ -201,7 +223,14 @@ public class ExecutionGraphDeploymentTest {
 	@Test
 	public void testRegistrationOfExecutionsCanceled() {
 		try {
-			Map<ExecutionAttemptID, Execution> executions = setupExecution(19, 37);
+			
+			final JobVertexID jid1 = new JobVertexID();
+			final JobVertexID jid2 = new JobVertexID();
+			
+			AbstractJobVertex v1 = new AbstractJobVertex("v1", jid1);
+			AbstractJobVertex v2 = new AbstractJobVertex("v2", jid2);
+			
+			Map<ExecutionAttemptID, Execution> executions = setupExecution(v1, 19, v2, 37);
 			
 			for (Execution e : executions.values()) {
 				e.cancel();
@@ -216,15 +245,52 @@ public class ExecutionGraphDeploymentTest {
 		}
 	}
 	
-	private Map<ExecutionAttemptID, Execution> setupExecution(int dop1, int dop2) throws Exception {
+	@Test
+	public void testRegistrationOfExecutionsFailingFinalize() {
+		try {
+			
+			final JobVertexID jid1 = new JobVertexID();
+			final JobVertexID jid2 = new JobVertexID();
+			
+			AbstractJobVertex v1 = new FailingFinalizeJobVertex("v1", jid1);
+			AbstractJobVertex v2 = new AbstractJobVertex("v2", jid2);
+			
+			Map<ExecutionAttemptID, Execution> executions = setupExecution(v1, 6, v2, 4);
+			
+			List<Execution> execList = new ArrayList<Execution>();
+			execList.addAll(executions.values());
+			// sort executions by job vertex. Failing job vertex first
+			Collections.sort(execList, new Comparator<Execution>() {
+				@Override
+				public int compare(Execution o1, Execution o2) {
+					return o1.getVertex().getSimpleName().compareTo(o2.getVertex().getSimpleName());
+				}
+			});
+			
+			int cnt = 0;
+			for (Execution e : execList) {
+				cnt++;
+				e.markFinished();
+				if(cnt <= 6) {
+					// the last execution of the first job vertex triggers the failing finalize hook
+					assertEquals(ExecutionState.FINISHED, e.getState());
+				} else {
+					// all following executions should be canceled
+					assertEquals(ExecutionState.CANCELED, e.getState());
+				}
+			}
+			
+			assertEquals(0, executions.size());
+		}
+		catch (Exception e) {
+			e.printStackTrace();
+			fail(e.getMessage());
+		}
+	}
+	
+	private Map<ExecutionAttemptID, Execution> setupExecution(AbstractJobVertex v1, int dop1, AbstractJobVertex v2, int dop2) throws Exception {
 		final JobID jobId = new JobID();
 		
-		final JobVertexID jid1 = new JobVertexID();
-		final JobVertexID jid2 = new JobVertexID();
-		
-		AbstractJobVertex v1 = new AbstractJobVertex("v1", jid1);
-		AbstractJobVertex v2 = new AbstractJobVertex("v2", jid2);
-		
 		v1.setParallelism(dop1);
 		v2.setParallelism(dop2);
 		
@@ -269,4 +335,23 @@ public class ExecutionGraphDeploymentTest {
 		
 		return executions;
 	}
+	
+	@SuppressWarnings("serial")
+	public static class FailingFinalizeJobVertex extends AbstractJobVertex {
+
+		public FailingFinalizeJobVertex(String name) {
+			super(name);
+		}
+		
+		public FailingFinalizeJobVertex(String name, JobVertexID id) {
+			super(name, id);
+		}
+		
+		@Override
+		public void finalizeOnMaster(ClassLoader cl) throws Exception {
+			throw new Exception();
+		}
+		
+		
+	}
 }
