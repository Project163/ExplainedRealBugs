diff --git a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/api/table.scala b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/api/table.scala
index 2bcb3d89910..093013e6f24 100644
--- a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/api/table.scala
+++ b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/api/table.scala
@@ -849,7 +849,7 @@ class Table(
   def window(overWindows: OverWindow*): OverWindowedTable = {
 
     if (tableEnv.isInstanceOf[BatchTableEnvironment]) {
-      throw TableException("Over-windows for batch tables are currently not supported..")
+      throw TableException("Over-windows for batch tables are currently not supported.")
     }
 
     if (overWindows.size != 1) {
diff --git a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/codegen/CodeGenUtils.scala b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/codegen/CodeGenUtils.scala
index f8885a2c775..1d8c926233b 100644
--- a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/codegen/CodeGenUtils.scala
+++ b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/codegen/CodeGenUtils.scala
@@ -243,7 +243,7 @@ object CodeGenUtils {
         val fieldName = pt.getFieldNames()(index)
         getFieldAccessor(pt.getTypeClass, fieldName)
 
-      case _ => throw new CodeGenException("Unsupported composite type.")
+      case _ => throw new CodeGenException(s"Unsupported composite type: '${compType}'")
     }
   }
 
diff --git a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/codegen/calls/ScalarOperators.scala b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/codegen/calls/ScalarOperators.scala
index b5ebe5161b9..1af4a3410a6 100644
--- a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/codegen/calls/ScalarOperators.scala
+++ b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/codegen/calls/ScalarOperators.scala
@@ -1052,7 +1052,7 @@ object ScalarOperators {
     case "*" => "multiply"
     case "/" => "divide"
     case "%" => "remainder"
-    case _ => throw new CodeGenException("Unsupported decimal arithmetic operator.")
+    case _ => throw new CodeGenException(s"Unsupported decimal arithmetic operator: '${operator}'")
   }
 
   private def numericCasting(
@@ -1067,7 +1067,7 @@ object ScalarOperators {
       case LONG_TYPE_INFO => "longValueExact"
       case FLOAT_TYPE_INFO => "floatValue"
       case DOUBLE_TYPE_INFO => "doubleValue"
-      case _ => throw new CodeGenException("Unsupported decimal casting type.")
+      case _ => throw new CodeGenException(s"Unsupported decimal casting type: '${targetType}'")
     }
 
     val resultTypeTerm = primitiveTypeTermForTypeInfo(resultType)
diff --git a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/expressions/call.scala b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/expressions/call.scala
index 13f8a11af77..bd4fa2f5ad2 100644
--- a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/expressions/call.scala
+++ b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/expressions/call.scala
@@ -67,7 +67,7 @@ case class Call(functionName: String, args: Seq[Expression]) extends Expression
 case class UnresolvedOverCall(agg: Expression, alias: Expression) extends Expression {
 
   override private[flink] def validateInput() =
-    ValidationFailure("Over window with alias $alias could not be resolved.")
+    ValidationFailure(s"Over window with alias $alias could not be resolved.")
 
   override private[flink] def resultType = agg.resultType
 
diff --git a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/aggregate/AggregateUtil.scala b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/aggregate/AggregateUtil.scala
index 2907b99ab8f..ccfab002327 100644
--- a/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/aggregate/AggregateUtil.scala
+++ b/flink-libraries/flink-table/src/main/scala/org/apache/flink/table/runtime/aggregate/AggregateUtil.scala
@@ -1205,7 +1205,7 @@ object AggregateUtil {
               case DECIMAL =>
                 new DecimalSumWithRetractAggFunction
               case sqlType: SqlTypeName =>
-                throw new TableException("Sum aggregate does no support type:" + sqlType)
+                throw new TableException(s"Sum aggregate does no support type: '${sqlType}'")
             }
           } else {
             aggregates(index) = sqlTypeName match {
@@ -1224,7 +1224,7 @@ object AggregateUtil {
               case DECIMAL =>
                 new DecimalSumAggFunction
               case sqlType: SqlTypeName =>
-                throw new TableException("Sum aggregate does no support type:" + sqlType)
+                throw new TableException(s"Sum aggregate does no support type: '${sqlType}'")
             }
           }
 
@@ -1246,7 +1246,7 @@ object AggregateUtil {
               case DECIMAL =>
                 new DecimalSum0WithRetractAggFunction
               case sqlType: SqlTypeName =>
-                throw new TableException("Sum0 aggregate does no support type:" + sqlType)
+                throw new TableException(s"Sum0 aggregate does no support type: '${sqlType}'")
             }
           } else {
             aggregates(index) = sqlTypeName match {
@@ -1265,7 +1265,7 @@ object AggregateUtil {
               case DECIMAL =>
                 new DecimalSum0AggFunction
               case sqlType: SqlTypeName =>
-                throw new TableException("Sum0 aggregate does no support type:" + sqlType)
+                throw new TableException(s"Sum0 aggregate does no support type: '${sqlType}'")
             }
           }
 
@@ -1286,7 +1286,7 @@ object AggregateUtil {
             case DECIMAL =>
               new DecimalAvgAggFunction
             case sqlType: SqlTypeName =>
-              throw new TableException("Avg aggregate does no support type:" + sqlType)
+              throw new TableException(s"Avg aggregate does no support type: '${sqlType}'")
           }
 
         case sqlMinMaxFunction: SqlMinMaxAggFunction =>
@@ -1312,8 +1312,8 @@ object AggregateUtil {
                 case VARCHAR | CHAR =>
                   new StringMinWithRetractAggFunction
                 case sqlType: SqlTypeName =>
-                  throw new TableException("Min with retract aggregate does no support type:" +
-                                             sqlType)
+                  throw new TableException(
+                    s"Min with retract aggregate does no support type: '${sqlType}'")
               }
             } else {
               sqlTypeName match {
@@ -1336,7 +1336,7 @@ object AggregateUtil {
                 case VARCHAR | CHAR =>
                   new StringMinAggFunction
                 case sqlType: SqlTypeName =>
-                  throw new TableException("Min aggregate does no support type:" + sqlType)
+                  throw new TableException(s"Min aggregate does no support type: '${sqlType}'")
               }
             }
           } else {
@@ -1361,8 +1361,8 @@ object AggregateUtil {
                 case VARCHAR | CHAR =>
                   new StringMaxWithRetractAggFunction
                 case sqlType: SqlTypeName =>
-                  throw new TableException("Max with retract aggregate does no support type:" +
-                                             sqlType)
+                  throw new TableException(
+                    s"Max with retract aggregate does no support type: '${sqlType}'")
               }
             } else {
               sqlTypeName match {
@@ -1385,7 +1385,7 @@ object AggregateUtil {
                 case VARCHAR | CHAR =>
                   new StringMaxAggFunction
                 case sqlType: SqlTypeName =>
-                  throw new TableException("Max aggregate does no support type:" + sqlType)
+                  throw new TableException(s"Max aggregate does no support type: '${sqlType}'")
               }
             }
           }
@@ -1397,7 +1397,7 @@ object AggregateUtil {
           aggregates(index) = udagg.getFunction
 
         case unSupported: SqlAggFunction =>
-          throw new TableException("unsupported Function: " + unSupported.getName)
+          throw new TableException(s"unsupported Function: '${unSupported.getName}'")
       }
     }
 
@@ -1487,7 +1487,7 @@ object AggregateUtil {
           relDataType.head.getIndex
         } else {
           throw TableException(
-            s"Encountered more than one time attribute with the same name: $relDataType")
+            s"Encountered more than one time attribute with the same name: '${relDataType}'")
         }
       case e => throw TableException(
         "The time attribute of window in batch environment should be " +
diff --git a/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/api/scala/stream/table/OverWindowITCase.scala b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/api/scala/stream/table/OverWindowITCase.scala
index f396896aaa2..dc7d5dcf5bd 100644
--- a/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/api/scala/stream/table/OverWindowITCase.scala
+++ b/flink-libraries/flink-table/src/test/scala/org/apache/flink/table/api/scala/stream/table/OverWindowITCase.scala
@@ -147,7 +147,7 @@ class OverWindowITCase extends StreamingWithStateTestBase {
   }
 
   @Test
-  def testProcTimeBoundedPartitionedRangeOver(): Unit = {
+  def testProcTimeBoundedPartitionedRowsOver(): Unit = {
 
     val data = List(
       (1, 1L, 0, "Hallo", 1L),
