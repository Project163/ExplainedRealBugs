diff --git a/flink-core/src/main/java/org/apache/flink/configuration/NettyShuffleEnvironmentOptions.java b/flink-core/src/main/java/org/apache/flink/configuration/NettyShuffleEnvironmentOptions.java
index 2e9b5c22288..561d5e9ede0 100644
--- a/flink-core/src/main/java/org/apache/flink/configuration/NettyShuffleEnvironmentOptions.java
+++ b/flink-core/src/main/java/org/apache/flink/configuration/NettyShuffleEnvironmentOptions.java
@@ -70,15 +70,17 @@ public class NettyShuffleEnvironmentOptions {
 	/**
 	 * Boolean flag indicating whether the shuffle data will be compressed for pipelined shuffle mode.
 	 *
-	 * <p>Note: Data is compressed per sliced buffer and compression can incur extra CPU overhead, so it is not recommended
-	 * to enable compression if network is not the bottleneck or compression ratio is low.
+	 * <p>Note: Data is compressed per sliced buffer and compression is disabled for operators using broadcast partitioner.
+	 * Because of the extra CPU overhead, it is not recommended to enable compression if network is not the bottleneck or
+	 * compression ratio is low.
 	 */
 	public static final ConfigOption<Boolean> PIPELINED_SHUFFLE_COMPRESSION_ENABLED =
 		key("taskmanager.network.pipelined-shuffle.compression.enabled")
 			.defaultValue(false)
 			.withDescription("Boolean flag indicating whether the shuffle data will be compressed for pipelined shuffle" +
-				" mode. Note that data is compressed per sliced buffer and compression can incur extra CPU overhead, so" +
-				" it is not recommended to enable compression if network is not the bottleneck or compression ratio is low.");
+				" mode. Note that data is compressed per sliced buffer and compression is disabled for operators using " +
+				"broadcast partitioner. Because of the extra CPU overhead, it is not recommended to enable compression " +
+				"if network is not the bottleneck or compression ratio is low.");
 
 	/**
 	 * The codec to be used when compressing shuffle data.
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/serialization/EventSerializer.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/serialization/EventSerializer.java
index 3eea00f7b93..a71b96ea13e 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/serialization/EventSerializer.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/serialization/EventSerializer.java
@@ -284,12 +284,12 @@ public class EventSerializer {
 		return buffer;
 	}
 
-	public static BufferConsumer toBufferConsumer(AbstractEvent event) throws IOException {
+	public static BufferConsumer toBufferConsumer(AbstractEvent event, boolean isShareable) throws IOException {
 		final ByteBuffer serializedEvent = EventSerializer.toSerializedEvent(event);
 
 		MemorySegment data = MemorySegmentFactory.wrap(serializedEvent.array());
 
-		return new BufferConsumer(data, FreeingBufferRecycler.INSTANCE, false);
+		return new BufferConsumer(data, FreeingBufferRecycler.INSTANCE, false, isShareable);
 	}
 
 	public static AbstractEvent fromBuffer(Buffer buffer, ClassLoader classLoader) throws IOException {
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/writer/BroadcastRecordWriter.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/writer/BroadcastRecordWriter.java
index b4999835d7f..6a1f63f08d2 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/writer/BroadcastRecordWriter.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/writer/BroadcastRecordWriter.java
@@ -84,7 +84,7 @@ public final class BroadcastRecordWriter<T extends IOReadableWritable> extends R
 		if (bufferBuilder != null) {
 			for (int index = 0; index < numberOfChannels; index++) {
 				if (index != targetChannelIndex) {
-					targetPartition.addBufferConsumer(bufferBuilder.createBufferConsumer(), index);
+					targetPartition.addBufferConsumer(bufferBuilder.createBufferConsumer(true), index);
 				}
 			}
 		}
@@ -130,9 +130,9 @@ public final class BroadcastRecordWriter<T extends IOReadableWritable> extends R
 
 		BufferBuilder builder = targetPartition.getBufferBuilder();
 		if (randomTriggered) {
-			targetPartition.addBufferConsumer(builder.createBufferConsumer(), targetChannel);
+			targetPartition.addBufferConsumer(builder.createBufferConsumer(true), targetChannel);
 		} else {
-			try (BufferConsumer bufferConsumer = builder.createBufferConsumer()) {
+			try (BufferConsumer bufferConsumer = builder.createBufferConsumer(true)) {
 				for (int channel = 0; channel < numberOfChannels; channel++) {
 					targetPartition.addBufferConsumer(bufferConsumer.copy(), channel);
 				}
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/writer/ChannelSelectorRecordWriter.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/writer/ChannelSelectorRecordWriter.java
index 5f5e5964b98..774c272704d 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/writer/ChannelSelectorRecordWriter.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/writer/ChannelSelectorRecordWriter.java
@@ -101,7 +101,7 @@ public final class ChannelSelectorRecordWriter<T extends IOReadableWritable> ext
 		checkState(bufferBuilders[targetChannel] == null || bufferBuilders[targetChannel].isFinished());
 
 		BufferBuilder bufferBuilder = targetPartition.getBufferBuilder();
-		targetPartition.addBufferConsumer(bufferBuilder.createBufferConsumer(), targetChannel);
+		targetPartition.addBufferConsumer(bufferBuilder.createBufferConsumer(false), targetChannel);
 		bufferBuilders[targetChannel] = bufferBuilder;
 		return bufferBuilder;
 	}
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/writer/RecordWriter.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/writer/RecordWriter.java
index 6c680f5981c..08df4c2624d 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/writer/RecordWriter.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/writer/RecordWriter.java
@@ -154,7 +154,7 @@ public abstract class RecordWriter<T extends IOReadableWritable> implements Avai
 	}
 
 	public void broadcastEvent(AbstractEvent event) throws IOException {
-		try (BufferConsumer eventBufferConsumer = EventSerializer.toBufferConsumer(event)) {
+		try (BufferConsumer eventBufferConsumer = EventSerializer.toBufferConsumer(event, true)) {
 			for (int targetChannel = 0; targetChannel < numberOfChannels; targetChannel++) {
 				tryFinishCurrentBufferBuilder(targetChannel);
 
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/buffer/BufferBuilder.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/buffer/BufferBuilder.java
index bcd42d23b1b..82e103baa5d 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/buffer/BufferBuilder.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/buffer/BufferBuilder.java
@@ -18,6 +18,7 @@
 
 package org.apache.flink.runtime.io.network.buffer;
 
+import org.apache.flink.annotation.VisibleForTesting;
 import org.apache.flink.core.memory.MemorySegment;
 
 import javax.annotation.concurrent.NotThreadSafe;
@@ -49,14 +50,21 @@ public class BufferBuilder {
 	 * This method always creates a {@link BufferConsumer} starting from the current writer offset. Data written to
 	 * {@link BufferBuilder} before creation of {@link BufferConsumer} won't be visible for that {@link BufferConsumer}.
 	 *
+	 * @param isShareable whether the created {@link BufferConsumer} is shareable.
 	 * @return created matching instance of {@link BufferConsumer} to this {@link BufferBuilder}.
 	 */
-	public BufferConsumer createBufferConsumer() {
+	public BufferConsumer createBufferConsumer(boolean isShareable) {
 		return new BufferConsumer(
 			memorySegment,
 			recycler,
 			positionMarker,
-			positionMarker.cachedPosition);
+			positionMarker.cachedPosition,
+			isShareable);
+	}
+
+	@VisibleForTesting
+	public BufferConsumer createBufferConsumer() {
+		return createBufferConsumer(false);
 	}
 
 	/**
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/buffer/BufferConsumer.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/buffer/BufferConsumer.java
index ecebc673449..c5e1aaebfc1 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/buffer/BufferConsumer.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/buffer/BufferConsumer.java
@@ -44,6 +44,9 @@ public class BufferConsumer implements Closeable {
 
 	private int currentReaderPosition;
 
+	/** Whether the underlying {@link Buffer} can be shared by multi {@link BufferConsumer} instances. */
+	private final boolean isShareable;
+
 	/**
 	 * Constructs {@link BufferConsumer} instance with the initial reader position.
 	 */
@@ -51,35 +54,48 @@ public class BufferConsumer implements Closeable {
 			MemorySegment memorySegment,
 			BufferRecycler recycler,
 			PositionMarker currentWriterPosition,
-			int currentReaderPosition) {
+			int currentReaderPosition,
+			boolean isShareable) {
 		this(
 			new NetworkBuffer(checkNotNull(memorySegment), checkNotNull(recycler), true),
 			currentWriterPosition,
-			currentReaderPosition);
+			currentReaderPosition,
+			isShareable);
 	}
 
 	/**
 	 * Constructs {@link BufferConsumer} instance with static content.
 	 */
-	public BufferConsumer(MemorySegment memorySegment, BufferRecycler recycler, boolean isBuffer) {
-		this(memorySegment, recycler, memorySegment.size(), isBuffer);
+	public BufferConsumer(MemorySegment memorySegment, BufferRecycler recycler, boolean isBuffer, boolean isShareable) {
+		this(memorySegment, recycler, memorySegment.size(), isBuffer, isShareable);
 	}
 
 	/**
 	 * Constructs {@link BufferConsumer} instance with static content of a certain size.
 	 */
-	public BufferConsumer(MemorySegment memorySegment, BufferRecycler recycler, int size, boolean isBuffer) {
+	public BufferConsumer(
+			MemorySegment memorySegment,
+			BufferRecycler recycler,
+			int size,
+			boolean isBuffer,
+			boolean isShareable) {
 		this(new NetworkBuffer(checkNotNull(memorySegment), checkNotNull(recycler), isBuffer),
 				() -> -size,
-				0);
+				0,
+				isShareable);
 		checkState(memorySegment.size() > 0);
 		checkState(isFinished(), "BufferConsumer with static size must be finished after construction!");
 	}
 
-	private BufferConsumer(Buffer buffer, BufferBuilder.PositionMarker currentWriterPosition, int currentReaderPosition) {
+	private BufferConsumer(
+			Buffer buffer,
+			BufferBuilder.PositionMarker currentWriterPosition,
+			int currentReaderPosition,
+			boolean isShareable) {
 		this.buffer = checkNotNull(buffer);
 		this.writerPosition = new CachedPositionMarker(checkNotNull(currentWriterPosition));
 		this.currentReaderPosition = currentReaderPosition;
+		this.isShareable = isShareable;
 	}
 
 	/**
@@ -110,12 +126,14 @@ public class BufferConsumer implements Closeable {
 	 * Returns a retained copy with separate indexes. This allows to read from the same {@link MemorySegment} twice.
 	 *
 	 * <p>WARNING: the newly returned {@link BufferConsumer} will have its reader index copied from the original buffer.
-	 * In other words, data already consumed before copying will not be visible to the returned copies.
+	 * In other words, data already consumed before copying will not be visible to the returned copies. In addition, only
+	 * shareable {@link BufferConsumer} can be copied.
 	 *
 	 * @return a retained copy of self with separate indexes
 	 */
 	public BufferConsumer copy() {
-		return new BufferConsumer(buffer.retainBuffer(), writerPosition.positionMarker, currentReaderPosition);
+		checkState(isShareable, "The underlying buffer is not shareable.");
+		return new BufferConsumer(buffer.retainBuffer(), writerPosition.positionMarker, currentReaderPosition, true);
 	}
 
 	public boolean isBuffer() {
@@ -141,6 +159,10 @@ public class BufferConsumer implements Closeable {
 		return currentReaderPosition;
 	}
 
+	public boolean isShareable() {
+		return isShareable;
+	}
+
 	/**
 	 * Returns true if there is new data available for reading.
 	 */
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartition.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartition.java
index 626ba3b8f87..dcd45fa0016 100755
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartition.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartition.java
@@ -180,7 +180,7 @@ final class BoundedBlockingSubpartition extends ResultSubpartition {
 
 		isFinished = true;
 		flushCurrentBuffer();
-		writeAndCloseBufferConsumer(EventSerializer.toBufferConsumer(EndOfPartitionEvent.INSTANCE));
+		writeAndCloseBufferConsumer(EventSerializer.toBufferConsumer(EndOfPartitionEvent.INSTANCE, false));
 		data.finishWrite();
 	}
 
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java
index 93fc1b5ec61..f8ca24f1bdf 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartition.java
@@ -96,7 +96,7 @@ class PipelinedSubpartition extends ResultSubpartition {
 
 	@Override
 	public void finish() throws IOException {
-		add(EventSerializer.toBufferConsumer(EndOfPartitionEvent.INSTANCE), true);
+		add(EventSerializer.toBufferConsumer(EndOfPartitionEvent.INSTANCE, false), true);
 		LOG.debug("{}: Finished {}.", parent.getOwningTaskName(), this);
 	}
 
@@ -169,7 +169,7 @@ class PipelinedSubpartition extends ResultSubpartition {
 				BufferConsumer bufferConsumer = buffers.peek();
 
 				buffer = bufferConsumer.build();
-				if (!isLocalChannel && canBeCompressed(buffer)) {
+				if (!isLocalChannel && !bufferConsumer.isShareable() && canBeCompressed(buffer)) {
 					buffer = parent.bufferCompressor.compressToOriginalBuffer(buffer);
 				}
 
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/buffer/BufferBuilderAndConsumerTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/buffer/BufferBuilderAndConsumerTest.java
index 3975a71f720..f345ff6c75b 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/buffer/BufferBuilderAndConsumerTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/buffer/BufferBuilderAndConsumerTest.java
@@ -137,7 +137,7 @@ public class BufferBuilderAndConsumerTest {
 	@Test
 	public void copy() {
 		BufferBuilder bufferBuilder = createBufferBuilder();
-		BufferConsumer bufferConsumer1 = bufferBuilder.createBufferConsumer();
+		BufferConsumer bufferConsumer1 = bufferBuilder.createBufferConsumer(true);
 
 		bufferBuilder.appendAndCommit(toByteBuffer(0, 1));
 
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/buffer/BufferBuilderTestUtils.java b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/buffer/BufferBuilderTestUtils.java
index 331854c4b8e..4e28bbce4a4 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/buffer/BufferBuilderTestUtils.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/buffer/BufferBuilderTestUtils.java
@@ -67,18 +67,22 @@ public class BufferBuilderTestUtils {
 	}
 
 	public static BufferConsumer createFilledFinishedBufferConsumer(int dataSize) {
-		return createFilledBufferConsumer(dataSize, dataSize, true);
+		return createFilledBufferConsumer(dataSize, dataSize, true, false);
+	}
+
+	public static BufferConsumer createFilledFinishedBufferConsumer(int dataSize, boolean isShareable) {
+		return createFilledBufferConsumer(dataSize, dataSize, true, isShareable);
 	}
 
 	public static BufferConsumer createFilledUnfinishedBufferConsumer(int dataSize) {
-		return createFilledBufferConsumer(dataSize, dataSize, false);
+		return createFilledBufferConsumer(dataSize, dataSize, false, false);
 	}
 
-	public static BufferConsumer createFilledBufferConsumer(int size, int dataSize, boolean isFinished) {
+	public static BufferConsumer createFilledBufferConsumer(int size, int dataSize, boolean isFinished, boolean isShareable) {
 		checkArgument(size >= dataSize);
 
 		BufferBuilder bufferBuilder = createBufferBuilder(size);
-		BufferConsumer bufferConsumer = bufferBuilder.createBufferConsumer();
+		BufferConsumer bufferConsumer = bufferBuilder.createBufferConsumer(isShareable);
 		fillBufferBuilder(bufferBuilder, dataSize);
 
 		if (isFinished) {
@@ -92,6 +96,7 @@ public class BufferBuilderTestUtils {
 		return new BufferConsumer(
 			MemorySegmentFactory.allocateUnpooledSegment(size),
 			FreeingBufferRecycler.INSTANCE,
+			false,
 			false);
 	}
 
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartitionWriteReadTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartitionWriteReadTest.java
index b7950d80d83..389c7c89d24 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartitionWriteReadTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/BoundedBlockingSubpartitionWriteReadTest.java
@@ -210,7 +210,7 @@ public class BoundedBlockingSubpartitionWriteReadTest {
 				nums--;
 			}
 
-			partition.add(new BufferConsumer(memory, (ignored) -> {}, pos, true));
+			partition.add(new BufferConsumer(memory, (ignored) -> {}, pos, true, false));
 
 			// we need to flush after every buffer as long as the add() contract is that
 			// buffer are immediately added and can be filled further after that (for low latency
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/InputGateFairnessTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/InputGateFairnessTest.java
index a6572affd6c..7dbf324e0cd 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/InputGateFairnessTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/InputGateFairnessTest.java
@@ -68,7 +68,7 @@ public class InputGateFairnessTest {
 		final int buffersPerChannel = 27;
 
 		final ResultPartition resultPartition = mock(ResultPartition.class);
-		final BufferConsumer bufferConsumer = createFilledFinishedBufferConsumer(42);
+		final BufferConsumer bufferConsumer = createFilledFinishedBufferConsumer(42, true);
 
 		// ----- create some source channels and fill them with buffers -----
 
@@ -122,7 +122,7 @@ public class InputGateFairnessTest {
 		final int buffersPerChannel = 27;
 
 		final ResultPartition resultPartition = mock(ResultPartition.class);
-		try (BufferConsumer bufferConsumer = createFilledFinishedBufferConsumer(42)) {
+		try (BufferConsumer bufferConsumer = createFilledFinishedBufferConsumer(42, true)) {
 
 			// ----- create some source channels and fill them with one buffer each -----
 
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartitionWithReadViewTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartitionWithReadViewTest.java
index 4b2c44a07b6..3d856078f89 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartitionWithReadViewTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/PipelinedSubpartitionWithReadViewTest.java
@@ -318,11 +318,13 @@ public class PipelinedSubpartitionWithReadViewTest {
 
 	@Test
 	public void testBufferCompression() {
-		subpartition.add(createFilledFinishedBufferConsumer(BUFFER_SIZE));
-		subpartition.add(createFilledFinishedBufferConsumer(BUFFER_SIZE));
+		subpartition.add(createFilledFinishedBufferConsumer(BUFFER_SIZE, false));
+		subpartition.add(createFilledFinishedBufferConsumer(BUFFER_SIZE, false));
+		subpartition.add(createFilledFinishedBufferConsumer(BUFFER_SIZE, true));
 
 		assertFalse(checkNotNull(readView.getNextBuffer(true)).buffer().isCompressed());
 		assertThat(checkNotNull(readView.getNextBuffer(false)).buffer().isCompressed(), is(compressionEnabled));
+		assertFalse(checkNotNull(readView.getNextBuffer(false)).buffer().isCompressed());
 	}
 
 	private void testBacklogConsistentWithNumberOfConsumableBuffers(boolean isFlushRequested, boolean isFinished) throws Exception {
diff --git a/flink-tests/src/test/java/org/apache/flink/test/runtime/ShuffleCompressionITCase.java b/flink-tests/src/test/java/org/apache/flink/test/runtime/ShuffleCompressionITCase.java
index b4889f7b8c6..fd9ffa533f4 100644
--- a/flink-tests/src/test/java/org/apache/flink/test/runtime/ShuffleCompressionITCase.java
+++ b/flink-tests/src/test/java/org/apache/flink/test/runtime/ShuffleCompressionITCase.java
@@ -45,6 +45,8 @@ import org.apache.flink.streaming.runtime.partitioner.BroadcastPartitioner;
 import org.apache.flink.types.LongValue;
 
 import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.junit.runners.Parameterized;
 
 import java.io.IOException;
 import java.util.concurrent.CompletableFuture;
@@ -55,6 +57,7 @@ import static org.junit.Assert.assertFalse;
 /**
  * Tests pipeline/blocking shuffle when data compression is enabled.
  */
+@RunWith(Parameterized.class)
 public class ShuffleCompressionITCase {
 
 	private static final int NUM_BUFFERS_TO_SEND = 1000;
@@ -70,7 +73,13 @@ public class ShuffleCompressionITCase {
 
 	private static final LongValue RECORD_TO_SEND = new LongValue(4387942071694473832L);
 
-	private static boolean useBroadcastPartitioner = false;
+	@Parameterized.Parameter
+	public static boolean useBroadcastPartitioner = false;
+
+	@Parameterized.Parameters(name = "useBroadcastPartitioner = {0}")
+	public static Boolean[] params() {
+		return new Boolean[] { true, false };
+	}
 
 	@Test
 	public void testDataCompressionForPipelineShuffle() throws Exception {
@@ -82,12 +91,6 @@ public class ShuffleCompressionITCase {
 		executeTest(createJobGraph(ScheduleMode.LAZY_FROM_SOURCES, ResultPartitionType.BLOCKING, ExecutionMode.BATCH));
 	}
 
-	@Test
-	public void testDataCompressionForBlockingShuffleWithBroadcastPartitioner() throws Exception {
-		useBroadcastPartitioner = true;
-		executeTest(createJobGraph(ScheduleMode.LAZY_FROM_SOURCES, ResultPartitionType.BLOCKING, ExecutionMode.BATCH));
-	}
-
 	private void executeTest(JobGraph jobGraph) throws Exception {
 		Configuration configuration = new Configuration();
 		configuration.setString(TaskManagerOptions.TOTAL_FLINK_MEMORY, "1g");
