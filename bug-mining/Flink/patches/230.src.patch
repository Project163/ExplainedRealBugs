diff --git a/flink-clients/src/main/java/org/apache/flink/client/program/Client.java b/flink-clients/src/main/java/org/apache/flink/client/program/Client.java
index 04e6c4dfb1a..1fc7696a4b2 100644
--- a/flink-clients/src/main/java/org/apache/flink/client/program/Client.java
+++ b/flink-clients/src/main/java/org/apache/flink/client/program/Client.java
@@ -45,8 +45,10 @@ import org.apache.flink.configuration.ConfigConstants;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.configuration.GlobalConfiguration;
 import org.apache.flink.core.fs.Path;
+import org.apache.flink.runtime.client.JobCancellationException;
 import org.apache.flink.runtime.client.JobClient;
 import org.apache.flink.runtime.client.JobExecutionException;
+import org.apache.flink.runtime.client.JobTimeoutException;
 import org.apache.flink.runtime.jobgraph.JobGraph;
 import org.apache.flink.runtime.messages.JobManagerMessages.SubmissionFailure;
 import org.apache.flink.runtime.messages.JobManagerMessages.SubmissionResponse;
@@ -331,7 +333,11 @@ public class Client {
 
 		try {
 			JobClient.uploadJarFiles(jobGraph, hostname, client, timeout);
+		} catch (IOException e) {
+			throw new ProgramInvocationException("Could not upload the programs JAR files to the JobManager.", e);
+		}
 
+		try{
 			if (wait) {
 				return JobClient.submitJobAndWait(jobGraph, printStatusDuringExecution, client, timeout);
 			}
@@ -340,30 +346,20 @@ public class Client {
 				if (response instanceof SubmissionFailure) {
 					SubmissionFailure failure = (SubmissionFailure) response;
 					throw new ProgramInvocationException(
-							"Failed to submit the job to the flink JobManager", failure.cause());
+							"Failed to submit the job to the JobManager.", failure.cause());
 				}
 			}
-		}
-		catch (IOException e) {
-			throw new ProgramInvocationException("Could not upload the programs JAR files to the JobManager.", e);
-		}
-		catch (JobExecutionException e) {
-			if (e.isJobCanceledByUser()) {
-				throw new ProgramInvocationException("The program has been canceled.");
-			}
-			else if (e.isConnectionTimedOut()) {
-				Throwable ae = null; //getAssociationError(monitoredErrors);
-				String message = ae == null ? "." : ": " + ae.getMessage();
-				throw new ProgramInvocationException("Lost connection to the JobManager" + message);
-			}
-			else {
-				throw new ProgramInvocationException("The program execution failed: " + e.getMessage());
-			}
-		}
-		catch (Exception e) {
-			Throwable ae = null; //getAssociationError(monitoredErrors);
-			String message = ae == null ? "." : ": " + ae.getMessage();
-			throw new ProgramInvocationException("Connection to JobManager failed" + message);
+		} catch (JobExecutionException e) {
+			throw new ProgramInvocationException("The program execution failed.", e);
+		} catch (JobTimeoutException e) {
+			throw new ProgramInvocationException("Lost connection to the JobManager.", e);
+		} catch (JobCancellationException e) {
+			throw new ProgramInvocationException("The program has been canceled.", e);
+		} catch (ProgramInvocationException e) {
+			// forward exception resulting from submission failure
+			throw e;
+		} catch (Exception e) {
+			throw new ProgramInvocationException("Exception occurred during job execution.", e);
 		}
 		finally {
 			actorSystem.shutdown();
diff --git a/flink-clients/src/test/java/org/apache/flink/client/CliFrontendListCancelTest.java b/flink-clients/src/test/java/org/apache/flink/client/CliFrontendListCancelTest.java
index 9dc13ba6987..fafe9295314 100644
--- a/flink-clients/src/test/java/org/apache/flink/client/CliFrontendListCancelTest.java
+++ b/flink-clients/src/test/java/org/apache/flink/client/CliFrontendListCancelTest.java
@@ -94,8 +94,6 @@ public class CliFrontendListCancelTest {
 	@Test
 	public void testList() {
 		try {
-			final ActorRef jm = actorSystem.actorOf(Props.create(CliJobManager.class, (Object)null));
-
 			// test unrecognized option
 			{
 				String[] parameters = {"-v", "-k"};
@@ -104,16 +102,9 @@ public class CliFrontendListCancelTest {
 				assertTrue(retCode == 1);
 			}
 			
-			// test missing flags
-			{
-				String[] parameters = {};
-				CliFrontend testFrontend = new CliFrontendTestUtils.TestingCliFrontend();
-				int retCode = testFrontend.list(parameters);
-				assertTrue(retCode != 0);
-			}
-			
 			// test list properly
 			{
+				final ActorRef jm = actorSystem.actorOf(Props.create(CliJobManager.class, (Object)null));
 				String[] parameters = {"-r", "-s"};
 				InfoListTestCliFrontend testFrontend = new InfoListTestCliFrontend(jm);
 				int retCode = testFrontend.list(parameters);
diff --git a/flink-clients/src/test/resources/log4j-test.properties b/flink-clients/src/test/resources/log4j-test.properties
index 2fb9345dc1d..04ec35570b7 100644
--- a/flink-clients/src/test/resources/log4j-test.properties
+++ b/flink-clients/src/test/resources/log4j-test.properties
@@ -16,4 +16,12 @@
 # limitations under the License.
 ################################################################################
 
-log4j.rootLogger=OFF
\ No newline at end of file
+# Set root logger level to OFF and its only appender to A1.
+log4j.rootLogger=OFF, A1
+
+# A1 is set to be a ConsoleAppender.
+log4j.appender.A1=org.apache.log4j.ConsoleAppender
+
+# A1 uses PatternLayout.
+log4j.appender.A1.layout=org.apache.log4j.PatternLayout
+log4j.appender.A1.layout.ConversionPattern=%-4r [%t] %-5p %c %x - %m%n
\ No newline at end of file
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/client/JobCancellationException.java b/flink-runtime/src/main/java/org/apache/flink/runtime/client/JobCancellationException.java
new file mode 100644
index 00000000000..1a9a1d0897c
--- /dev/null
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/client/JobCancellationException.java
@@ -0,0 +1,30 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.runtime.client;
+
+/**
+ * An exception which is thrown by the JobClient if a job is aborted as a result of a user
+ * cancellation.
+ */
+public class JobCancellationException extends Exception {
+
+	public JobCancellationException(final String msg, final Throwable cause){
+		super(msg, cause);
+	}
+}
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/client/JobExecutionException.java b/flink-runtime/src/main/java/org/apache/flink/runtime/client/JobExecutionException.java
index f35f4127c8d..d5eb4922e17 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/client/JobExecutionException.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/client/JobExecutionException.java
@@ -19,43 +19,20 @@
 package org.apache.flink.runtime.client;
 
 /**
- * This exception is thrown by the {@link JobClient} if a job has been aborted either as a result of a user
- * request or an error which occurred during the execution.
+ * This exception is thrown by the {@link JobClient} if a job has been aborted as a result of an
+ * error which occurred during the execution.
  */
 public class JobExecutionException extends Exception {
 
-	public static enum ExecutionErrorCause {
-		CANCELED,
-		TIMEOUT_TO_JOB_MANAGER,
-		ERROR
-	}
-
-	// ------------------------------------------------------------------------
-
 	private static final long serialVersionUID = 2818087325120827525L;
 
-	private final ExecutionErrorCause cause;
-
 	/**
 	 * Constructs a new job execution exception.
 	 * 
-	 * @param msg The message that shall be encapsulated by this exception.
-	 * @param cause The cause for the execution exception.
+	 * @param msg The cause for the execution exception.
+	 * @param cause The cause of the exception
 	 */
-	public JobExecutionException(String msg, ExecutionErrorCause cause) {
-		super(msg);
-		this.cause = cause;
-	}
-
-	public boolean isJobCanceledByUser() {
-		return cause == ExecutionErrorCause.CANCELED;
-	}
-
-	public boolean isConnectionTimedOut() {
-		return cause == ExecutionErrorCause.TIMEOUT_TO_JOB_MANAGER;
-	}
-
-	public boolean isError() {
-		return cause == ExecutionErrorCause.ERROR;
+	public JobExecutionException(String msg, Throwable cause) {
+		super(msg, cause);
 	}
 }
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/client/JobTimeoutException.java b/flink-runtime/src/main/java/org/apache/flink/runtime/client/JobTimeoutException.java
new file mode 100644
index 00000000000..2bd6ec59c25
--- /dev/null
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/client/JobTimeoutException.java
@@ -0,0 +1,29 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.runtime.client;
+
+/**
+ * An exception which is thrown by the JobClient if the job manager is no longer reachable.
+ */
+public class JobTimeoutException extends Exception {
+
+	public JobTimeoutException(final String msg, final Throwable cause) {
+		super(msg, cause);
+	}
+}
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/execution/CancelTaskException.java b/flink-runtime/src/main/java/org/apache/flink/runtime/execution/CancelTaskException.java
index 45dc411d498..959ab07cd0e 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/execution/CancelTaskException.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/execution/CancelTaskException.java
@@ -23,4 +23,12 @@ package org.apache.flink.runtime.execution;
  */
 public class CancelTaskException extends RuntimeException {
 	private static final long serialVersionUID = 1L;
+
+	public CancelTaskException(final String msg) {
+		super(msg);
+	}
+
+	public CancelTaskException() {
+		super("");
+	}
 }
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/execution/RuntimeEnvironment.java b/flink-runtime/src/main/java/org/apache/flink/runtime/execution/RuntimeEnvironment.java
index 6be03977d74..f78ea928b78 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/execution/RuntimeEnvironment.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/execution/RuntimeEnvironment.java
@@ -205,7 +205,7 @@ public class RuntimeEnvironment implements Environment, Runnable {
 
 			// Make sure, we enter the catch block when the task has been canceled
 			if (owner.isCanceledOrFailed()) {
-				throw new CancelTaskException();
+				throw new CancelTaskException("Task has been canceled or failed");
 			}
 
 			// Finish the produced partitions
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/Execution.java b/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/Execution.java
index 83a25a7b760..56f9416a255 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/Execution.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/Execution.java
@@ -601,7 +601,7 @@ public class Execution implements Serializable {
 
 		// check if the ExecutionVertex has already been archived and thus cleared the
 		// partial partition infos queue
-		if(partialPartitionInfos != null) {
+		if(partialPartitionInfos != null && !partialPartitionInfos.isEmpty()) {
 
 			PartialPartitionInfo partialPartitionInfo;
 
@@ -730,64 +730,64 @@ public class Execution implements Serializable {
 
 	private void sendCancelRpcCall() {
 		final SimpleSlot slot = this.assignedResource;
-		if (slot == null) {
-			return;
-		}
 
-		Future<Object> cancelResult = AkkaUtils.retry(slot.getInstance().getTaskManager(), new
-						TaskManagerMessages.CancelTask(attemptId), NUM_CANCEL_CALL_TRIES,
-				AkkaUtils.globalExecutionContext(), timeout);
+		if (slot != null) {
 
-		cancelResult.onComplete(new OnComplete<Object>(){
+			Future<Object> cancelResult = AkkaUtils.retry(slot.getInstance().getTaskManager(), new
+							TaskManagerMessages.CancelTask(attemptId), NUM_CANCEL_CALL_TRIES,
+					AkkaUtils.globalExecutionContext(), timeout);
 
-			@Override
-			public void onComplete(Throwable failure, Object success) throws Throwable {
-				if (failure != null) {
-					fail(new Exception("Task could not be canceled.", failure));
-				} else {
-					TaskOperationResult result = (TaskOperationResult)success;
-					if(!result.success()){
-						LOG.debug("Cancel task call did not find task. Probably akka message call" +
-								" race.");
+			cancelResult.onComplete(new OnComplete<Object>() {
+
+				@Override
+				public void onComplete(Throwable failure, Object success) throws Throwable {
+					if (failure != null) {
+						fail(new Exception("Task could not be canceled.", failure));
+					} else {
+						TaskOperationResult result = (TaskOperationResult) success;
+						if (!result.success()) {
+							LOG.debug("Cancel task call did not find task. Probably akka message call" +
+									" race.");
+						}
 					}
 				}
-			}
-		}, AkkaUtils.globalExecutionContext());
+			}, AkkaUtils.globalExecutionContext());
+		}
 	}
 
 	private void sendFailIntermediateResultPartitionsRPCCall() {
 		final SimpleSlot slot = this.assignedResource;
-		if (slot == null) {
-			return;
-		}
 
-		final Instance instance = slot.getInstance();
+		if (slot != null) {
+			final Instance instance = slot.getInstance();
 
-		if (instance.isAlive()) {
-			try {
-				// TODO For some tests this could be a problem when querying too early if all resources were released
-				instance.getTaskManager().tell(new TaskManagerMessages.FailIntermediateResultPartitions(attemptId), ActorRef.noSender());
-			}
-			catch (Throwable t) {
-				fail(new Exception("Intermediate result partition could not be failed.", t));
+			if (instance.isAlive()) {
+				try {
+					// TODO For some tests this could be a problem when querying too early if all resources were released
+					instance.getTaskManager().tell(new TaskManagerMessages.FailIntermediateResultPartitions(attemptId), ActorRef.noSender());
+				} catch (Throwable t) {
+					fail(new Exception("Intermediate result partition could not be failed.", t));
+				}
 			}
 		}
 	}
 
 	private void sendUpdateTaskRpcCall(final SimpleSlot consumerSlot,
 									final TaskManagerMessages.UpdateTask updateTaskMsg) {
-		final Instance instance = consumerSlot.getInstance();
+		if (consumerSlot != null) {
+			final Instance instance = consumerSlot.getInstance();
 
-		Future<Object> futureUpdate = Patterns.ask(instance.getTaskManager(), updateTaskMsg,
-				new Timeout(timeout));
+			Future<Object> futureUpdate = Patterns.ask(instance.getTaskManager(), updateTaskMsg,
+					new Timeout(timeout));
 
-		futureUpdate.onFailure(new OnFailure() {
-			@Override
-			public void onFailure(Throwable failure) throws Throwable {
-				fail(new IllegalStateException("Update task on instance " + instance +
-						" failed due to:", failure));
-			}
-		}, AkkaUtils.globalExecutionContext());
+			futureUpdate.onFailure(new OnFailure() {
+				@Override
+				public void onFailure(Throwable failure) throws Throwable {
+					fail(new IllegalStateException("Update task on instance " + instance +
+							" failed due to:", failure));
+				}
+			}, AkkaUtils.globalExecutionContext());
+		}
 	}
 
 	// --------------------------------------------------------------------------------------------
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionGraph.java b/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionGraph.java
index c1f45e1e91d..7198076b098 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionGraph.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionGraph.java
@@ -398,10 +398,15 @@ public class ExecutionGraph implements Serializable {
 			}
 			else if (transitionState(current, JobStatus.FAILING, t)) {
 				this.failureCause = t;
-				
-				// cancel all. what is failed will not cancel but stay failed
-				for (ExecutionJobVertex ejv : verticesInCreationOrder) {
-					ejv.cancel();
+
+				if (!verticesInCreationOrder.isEmpty()) {
+					// cancel all. what is failed will not cancel but stay failed
+					for (ExecutionJobVertex ejv : verticesInCreationOrder) {
+						ejv.cancel();
+					}
+				} else {
+					// set the state of the job to failed
+					transitionState(current, JobStatus.FAILED, t);
 				}
 				
 				return;
@@ -568,15 +573,18 @@ public class ExecutionGraph implements Serializable {
 		this.executionListenerActors.add(listener);
 	}
 
+	public boolean containsJobStatusListener(ActorRef listener) {
+		return this.jobStatusListenerActors.contains(listener);
+	}
+
 	/**
 	 * NOTE: This method never throws an error, only logs errors caused by the notified listeners.
 	 */
 	private void notifyJobStatusChange(JobStatus newState, Throwable error) {
 		if(jobStatusListenerActors.size() > 0){
-			String message = error == null ? null : ExceptionUtils.stringifyException(error);
 			for(ActorRef listener: jobStatusListenerActors){
 				listener.tell(new ExecutionGraphMessages.JobStatusChanged(jobID, newState, System.currentTimeMillis(),
-								message), ActorRef.noSender());
+								error), ActorRef.noSender());
 			}
 		}
 	}
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/client/JobClient.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/client/JobClient.scala
index 54291a88cb6..4a64f87e429 100644
--- a/flink-runtime/src/main/scala/org/apache/flink/runtime/client/JobClient.scala
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/client/JobClient.scala
@@ -48,16 +48,28 @@ Actor with ActorLogMessages with ActorLogging {
   override def receiveWithLogMessages: Receive = {
     case SubmitJobDetached(jobGraph) =>
       jobManager forward SubmitJob(jobGraph, registerForEvents = false, detached = true)
+
     case cancelJob: CancelJob =>
       jobManager forward cancelJob
+
     case SubmitJobAndWait(jobGraph, listen) =>
       val listener = context.actorOf(Props(classOf[JobClientListener], sender))
       jobManager.tell(SubmitJob(jobGraph, registerForEvents = listen, detached = false), listener)
+
     case RequestBlobManagerPort =>
       jobManager forward RequestBlobManagerPort
+
     case RequestJobManagerStatus =>
       jobManager forward RequestJobManagerStatus
   }
+
+  /**
+   * Handle unmatched messages with an exception.
+   */
+  override def unhandled(message: Any): Unit = {
+    // let the actor crash
+    throw new RuntimeException("Received unknown message " + message)
+  }
 }
 
 /**
@@ -70,9 +82,9 @@ Actor with ActorLogMessages with ActorLogging {
 class JobClientListener(jobSubmitter: ActorRef) extends Actor with ActorLogMessages with
 ActorLogging {
   override def receiveWithLogMessages: Receive = {
-    case SubmissionFailure(_, t) =>
-      jobSubmitter ! Failure(t)
-      self ! PoisonPill
+    case SubmissionFailure(jobID, t) =>
+      System.out.println(s"Submission of job with ID $jobID was unsuccessful, " +
+        s"because ${t.getMessage}.")
 
     case SubmissionSuccess(_) =>
 
@@ -80,20 +92,26 @@ ActorLogging {
       jobSubmitter ! new JobExecutionResult(duration, accumulatorResults)
       self ! PoisonPill
 
-    case JobResultCanceled(_, msg) =>
-      jobSubmitter ! Failure(
-        new JobExecutionException(msg, JobExecutionException.ExecutionErrorCause.CANCELED))
+    case JobResultCanceled(_, t) =>
+      jobSubmitter ! Failure(new JobCancellationException("The job has been cancelled.", t))
       self ! PoisonPill
 
-    case JobResultFailed(_, msg) =>
-      jobSubmitter ! Failure(new JobExecutionException(msg,
-        JobExecutionException.ExecutionErrorCause.ERROR))
+    case JobResultFailed(_, t) =>
+      jobSubmitter ! Failure(new JobExecutionException("The job execution failed.", t))
       self ! PoisonPill
 
     case msg =>
       // we have to use System.out.println here to avoid erroneous behavior for output redirection
       System.out.println(msg.toString)
   }
+
+  /**
+   * Handle unmatched messages with an exception.
+   */
+  override def unhandled(message: Any): Unit = {
+    // let the actor crash
+    throw new RuntimeException("Received unknown message " + message)
+  }
 }
 
 /**
@@ -193,7 +211,7 @@ object JobClient {
    *                                                               execution fails.
    * @return The job execution result
    */
-  @throws(classOf[JobExecutionException])
+  @throws(classOf[Exception])
   def submitJobAndWait(jobGraph: JobGraph, listenToStatusEvents: Boolean, jobClient: ActorRef)
                       (implicit timeout: FiniteDuration): JobExecutionResult = {
 
@@ -215,9 +233,7 @@ object JobClient {
             Await.result(jmStatus, timeout)
           } catch {
             case t: Throwable =>
-              throw new JobExecutionException(
-                "JobManager not reachable anymore. Terminate waiting for job answer.",
-                JobExecutionException.ExecutionErrorCause.TIMEOUT_TO_JOB_MANAGER)
+              throw new JobTimeoutException("Lost connection to job manager.", t)
           }
       }
     }
@@ -236,11 +252,19 @@ object JobClient {
    * @param timeout Tiemout for futures
    * @return The submission response
    */
+  @throws(classOf[Exception])
   def submitJobDetached(jobGraph: JobGraph, jobClient: ActorRef)(implicit timeout: FiniteDuration):
   SubmissionResponse = {
     val response = (jobClient ? SubmitJobDetached(jobGraph))(timeout)
 
-    Await.result(response.mapTo[SubmissionResponse], timeout)
+    try {
+      Await.result(response.mapTo[SubmissionResponse], timeout)
+    } catch {
+      case timeout: TimeoutException =>
+        throw new JobTimeoutException("Timeout while waiting for the submission result.", timeout);
+      case t: Throwable =>
+        throw new JobExecutionException("Exception while waiting for the submission result.", t)
+    }
   }
 
   /**
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManager.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManager.scala
index bfce7a20360..1741cdbf65c 100644
--- a/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManager.scala
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManager.scala
@@ -50,7 +50,6 @@ import org.apache.flink.util.InstantiationUtil
 import org.slf4j.LoggerFactory
 
 import akka.actor._
-import akka.pattern.ask
 
 import scala.concurrent._
 import scala.concurrent.duration._
@@ -103,9 +102,6 @@ class JobManager(val configuration: Configuration,
   // List of current jobs running
   val currentJobs = scala.collection.mutable.HashMap[JobID, (ExecutionGraph, JobInfo)]()
 
-  // Map of actors which want to be notified once a specific job terminates
-  val finalJobStatusListener = scala.collection.mutable.HashMap[JobID, Set[ActorRef]]()
-
 
   override def preStart(): Unit = {
     LOG.info(s"Starting JobManager at ${self.path}.")
@@ -261,9 +257,9 @@ class JobManager(val configuration: Configuration,
     case JobStatusChanged(jobID, newJobStatus, timeStamp, optionalMessage) =>
       currentJobs.get(jobID) match {
         case Some((executionGraph, jobInfo)) => executionGraph.getJobName
-          log.info("Status of job {} ({}) changed to {}{}.",
+          log.info("Status of job {} ({}) changed to {} {}.",
             jobID, executionGraph.getJobName, newJobStatus,
-            if(optionalMessage == null) "" else optionalMessage)
+            if(optionalMessage == null) "" else optionalMessage.getMessage)
 
           if(newJobStatus.isTerminalState) {
             jobInfo.end = timeStamp
@@ -279,14 +275,9 @@ class JobManager(val configuration: Configuration,
                 case JobStatus.FAILED =>
                   jobInfo.client ! JobResultFailed(jobID, optionalMessage)
                 case x =>
-                  jobInfo.client ! JobResultFailed(jobID, s"$x is not a terminal state.")
-                  throw new IllegalStateException(s"$x is not a terminal state.")
-              }
-            }
-
-            finalJobStatusListener.get(jobID) foreach {
-              _ foreach {
-                _ ! CurrentJobStatus(jobID, newJobStatus)
+                  val exception = new IllegalStateException(s"$x is not a terminal state.")
+                  jobInfo.client ! JobResultFailed(jobID, exception)
+                  throw exception
               }
             }
 
@@ -296,16 +287,6 @@ class JobManager(val configuration: Configuration,
           removeJob(jobID)
       }
 
-    case RequestFinalJobStatus(jobID) =>
-      currentJobs.get(jobID) match {
-        case Some(_) =>
-          val listeners = finalJobStatusListener.getOrElse(jobID, Set())
-          finalJobStatusListener += jobID -> (listeners + sender)
-        case None =>
-          // There is no job running with this job ID. Check the archive.
-          archive forward RequestJobStatus(jobID)
-      }
-
     case ScheduleOrUpdateConsumers(jobId, executionId, partitionIndex) =>
       currentJobs.get(jobId) match {
         case Some((executionGraph, _)) =>
@@ -497,25 +478,12 @@ class JobManager(val configuration: Configuration,
              * before. That way the proper cleanup of the job is triggered in the JobStatusChanged
              * handler.
              */
-            val status = (self ? RequestFinalJobStatus(jobGraph.getJobID))(10 second)
-
-            /*
-             * if we cannot register as final job status listener, then send manually a
-             * JobStatusChanged message with JobStatus.FAILED.
-             */
-            val selfActorRef = self
-            status.onFailure{
-              case _: Throwable => selfActorRef ! JobStatusChanged(executionGraph.getJobID,
-                JobStatus.FAILED, System.currentTimeMillis(), s"Cleanup job ${jobGraph.getJobID}.")
+            if (!executionGraph.containsJobStatusListener(self)) {
+              executionGraph.registerJobStatusListener(self)
             }
 
-            /*
-             * Don't send the client the final job status because we will send him a
-             * SubmissionFailure.
-             */
-            jobInfo.detached = true
-
             executionGraph.fail(t)
+
           case None =>
             libraryCacheManager.unregisterJob(jobGraph.getJobID)
             currentJobs.remove(jobGraph.getJobID)
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManagerProfiler.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManagerProfiler.scala
index e44f7e9623d..eb8f913a342 100644
--- a/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManagerProfiler.scala
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/JobManagerProfiler.scala
@@ -41,4 +41,12 @@ class JobManagerProfiler extends Actor with ActorLogMessages with ActorLogging w
           log.error(s"Received unknown profiling data: ${x.getClass.getName}" )
       }
   }
+
+  /**
+   * Handle unmatched messages with an exception.
+   */
+  override def unhandled(message: Any): Unit = {
+    // let the actor crash
+    throw new RuntimeException("Received unknown message " + message)
+  }
 }
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/MemoryArchivist.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/MemoryArchivist.scala
index 2d055ed67df..0c3384cc634 100644
--- a/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/MemoryArchivist.scala
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/jobmanager/MemoryArchivist.scala
@@ -81,6 +81,14 @@ ActorLogging {
       }
   }
 
+  /**
+   * Handle unmatched messages with an exception.
+   */
+  override def unhandled(message: Any): Unit = {
+    // let the actor crash
+    throw new RuntimeException("Received unknown message " + message)
+  }
+
   /**
    * Gets all graphs that have not been garbage collected.
    * @return An iterable with all valid ExecutionGraphs
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/messages/ExecutionGraphMessages.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/messages/ExecutionGraphMessages.scala
index ef5b99cd5eb..d413d1322ef 100644
--- a/flink-runtime/src/main/scala/org/apache/flink/runtime/messages/ExecutionGraphMessages.scala
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/messages/ExecutionGraphMessages.scala
@@ -66,10 +66,10 @@ object ExecutionGraphMessages {
    * @param jobID identifying the correspong job
    * @param newJobStatus
    * @param timestamp
-   * @param optionalMessage
+   * @param error
    */
   case class JobStatusChanged(jobID: JobID, newJobStatus: JobStatus, timestamp: Long,
-                              optionalMessage: String){
+                              error: Throwable){
     override def toString: String = {
       s"${timestampToString(timestamp)}\tJob execution switched to status $newJobStatus."
     }
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/messages/JobmanagerMessages.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/messages/JobmanagerMessages.scala
index c270d331605..f25083f3ba5 100644
--- a/flink-runtime/src/main/scala/org/apache/flink/runtime/messages/JobmanagerMessages.scala
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/messages/JobmanagerMessages.scala
@@ -196,16 +196,16 @@ object JobManagerMessages {
   /**
    * Denotes a cancellation of the job.
    * @param jobID
-   * @param msg
+   * @param t
    */
-  case class JobResultCanceled(jobID: JobID, msg: String) extends JobResult
+  case class JobResultCanceled(jobID: JobID, t: Throwable) extends JobResult
 
   /**
    * Denotes a failed job execution.
    * @param jobID
-   * @param msg
+   * @param t
    */
-  case class JobResultFailed(jobID: JobID, msg:String) extends JobResult
+  case class JobResultFailed(jobID: JobID, t: Throwable) extends JobResult
 
   sealed trait SubmissionResponse{
     def jobID: JobID
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/taskmanager/TaskManager.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/taskmanager/TaskManager.scala
index 6d610a4242c..99d824b1671 100644
--- a/flink-runtime/src/main/scala/org/apache/flink/runtime/taskmanager/TaskManager.scala
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/taskmanager/TaskManager.scala
@@ -354,6 +354,20 @@ import scala.collection.JavaConverters._
       cleanupTaskManager()
 
       tryJobManagerRegistration()
+
+    case FailIntermediateResultPartitions(executionID) =>
+      log.info("Fail intermediate result partitions associated with execution {}.", executionID)
+      networkEnvironment foreach {
+        _.getPartitionManager.failIntermediateResultPartitions(executionID)
+      }
+  }
+
+  /**
+   * Handle unmatched messages with an exception.
+   */
+  override def unhandled(message: Any): Unit = {
+    // let the actor crash
+    throw new RuntimeException("Received unknown message " + message)
   }
 
   /**
diff --git a/flink-runtime/src/main/scala/org/apache/flink/runtime/taskmanager/TaskManagerProfiler.scala b/flink-runtime/src/main/scala/org/apache/flink/runtime/taskmanager/TaskManagerProfiler.scala
index 1a7c31d028c..abd44b1026e 100644
--- a/flink-runtime/src/main/scala/org/apache/flink/runtime/taskmanager/TaskManagerProfiler.scala
+++ b/flink-runtime/src/main/scala/org/apache/flink/runtime/taskmanager/TaskManagerProfiler.scala
@@ -137,6 +137,14 @@ ActorLogMessages with ActorLogging {
       }
   }
 
+  /**
+   * Handle unmatched messages with an exception.
+   */
+  override def unhandled(message: Any): Unit = {
+    // let the actor crash
+    throw new RuntimeException("Received unknown message " + message)
+  }
+
   def startMonitoring(): Unit = {
     val interval = new FiniteDuration(reportInterval, TimeUnit.MILLISECONDS)
     val delay = new FiniteDuration((reportInterval * Math.random()).toLong, TimeUnit.MILLISECONDS)
diff --git a/flink-runtime/src/test/resources/log4j-test.properties b/flink-runtime/src/test/resources/log4j-test.properties
index 0b686e543bb..04ec35570b7 100644
--- a/flink-runtime/src/test/resources/log4j-test.properties
+++ b/flink-runtime/src/test/resources/log4j-test.properties
@@ -16,7 +16,7 @@
 # limitations under the License.
 ################################################################################
 
-# Set root logger level to DEBUG and its only appender to A1.
+# Set root logger level to OFF and its only appender to A1.
 log4j.rootLogger=OFF, A1
 
 # A1 is set to be a ConsoleAppender.
diff --git a/flink-runtime/src/test/scala/org/apache/flink/runtime/jobmanager/JobManagerITCase.scala b/flink-runtime/src/test/scala/org/apache/flink/runtime/jobmanager/JobManagerITCase.scala
index d2fe4c2863c..89d5d438dff 100644
--- a/flink-runtime/src/test/scala/org/apache/flink/runtime/jobmanager/JobManagerITCase.scala
+++ b/flink-runtime/src/test/scala/org/apache/flink/runtime/jobmanager/JobManagerITCase.scala
@@ -72,7 +72,7 @@ WordSpecLike with Matchers with BeforeAndAfterAll {
 
           expectMsg(SubmissionFailure(jobGraph.getJobID, new NoResourceAvailableException(1,1,0)))
 
-          expectNoMsg()
+          expectMsg(JobResultFailed(jobGraph.getJobID, new NoResourceAvailableException(1,1,0)))
         }
 
         jm ! NotifyWhenJobRemoved(jobGraph.getJobID)
diff --git a/flink-tests/src/test/java/org/apache/flink/test/cancelling/CancellingTestBase.java b/flink-tests/src/test/java/org/apache/flink/test/cancelling/CancellingTestBase.java
index 3138bb6baf2..3226651bb9b 100644
--- a/flink-tests/src/test/java/org/apache/flink/test/cancelling/CancellingTestBase.java
+++ b/flink-tests/src/test/java/org/apache/flink/test/cancelling/CancellingTestBase.java
@@ -28,7 +28,7 @@ import akka.util.Timeout;
 import org.apache.flink.configuration.ConfigConstants;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.runtime.akka.AkkaUtils;
-import org.apache.flink.runtime.client.JobExecutionException;
+import org.apache.flink.runtime.client.JobCancellationException;
 import org.apache.flink.runtime.messages.JobClientMessages;
 import org.apache.flink.runtime.messages.JobManagerMessages;
 import org.apache.flink.test.util.ForkableFlinkMiniCluster;
@@ -123,12 +123,10 @@ public abstract class CancellingTestBase {
 
 			try {
 				Await.result(result, AkkaUtils.getDefaultTimeout());
-			} catch (JobExecutionException exception) {
-				if (!exception.isJobCanceledByUser()) {
-					throw new IllegalStateException("Job Failed.");
-				}
-
+			} catch (JobCancellationException exception) {
 				jobSuccessfullyCancelled = true;
+			} catch (Exception e) {
+				throw new IllegalStateException("Job failed.", e);
 			}
 
 			if (!jobSuccessfullyCancelled) {
diff --git a/flink-yarn/src/main/scala/org/apache/flink/yarn/ApplicationClient.scala b/flink-yarn/src/main/scala/org/apache/flink/yarn/ApplicationClient.scala
index dba634438b5..f7f6967fbc0 100644
--- a/flink-yarn/src/main/scala/org/apache/flink/yarn/ApplicationClient.scala
+++ b/flink-yarn/src/main/scala/org/apache/flink/yarn/ApplicationClient.scala
@@ -137,4 +137,11 @@ class ApplicationClient extends Actor with ActorLogMessages with ActorLogging {
       sender() ! messagesQueue.headOption
   }
 
+  /**
+   * Handle unmatched messages with an exception.
+   */
+  override def unhandled(message: Any): Unit = {
+    // let the actor crash
+    throw new RuntimeException("Received unknown message " + message)
+  }
 }
diff --git a/flink-yarn/src/main/scala/org/apache/flink/yarn/YarnJobManager.scala b/flink-yarn/src/main/scala/org/apache/flink/yarn/YarnJobManager.scala
index 81bdc3b3f6d..2bc81fec882 100644
--- a/flink-yarn/src/main/scala/org/apache/flink/yarn/YarnJobManager.scala
+++ b/flink-yarn/src/main/scala/org/apache/flink/yarn/YarnJobManager.scala
@@ -18,7 +18,7 @@
 
 package org.apache.flink.yarn
 
-import java.io.{IOException, File}
+import java.io.File
 import java.nio.ByteBuffer
 import java.util.Collections
 
@@ -114,7 +114,8 @@ trait YarnJobManager extends ActorLogMessages {
       sender() ! new FlinkYarnClusterStatus(instanceManager.getNumberOfRegisteredTaskManagers,
         instanceManager.getTotalNumberOfSlots)
 
-    case StartYarnSession(conf, actorSystemPort, webServerPort) => startYarnSession(conf, actorSystemPort, webServerPort)
+    case StartYarnSession(conf, actorSystemPort, webServerPort) =>
+      startYarnSession(conf, actorSystemPort, webServerPort)
 
     case PollContainerCompletion =>
       rmClientOption match {
@@ -168,7 +169,9 @@ trait YarnJobManager extends ActorLogMessages {
       }
   }
 
-  private def startYarnSession(conf: Configuration, actorSystemPort: Int, webServerPort: Int): Unit = {
+  private def startYarnSession(conf: Configuration,
+                               actorSystemPort: Int,
+                               webServerPort: Int): Unit = {
     Try {
       log.info("Start yarn session.")
       val memoryPerTaskManager = env.get(FlinkYarnClient.ENV_TM_MEMORY).toInt
