diff --git a/docs/libs/table.md b/docs/libs/table.md
index d1d42cc4c2e..1aedce3d2a3 100644
--- a/docs/libs/table.md
+++ b/docs/libs/table.md
@@ -188,11 +188,18 @@ Table result = in.where("b = 'red'");
     <tr>
       <td><strong>GroupBy</strong></td>
       <td>
-        <p>Similar to a SQL GROUPBY clause. Group the elements on the grouping keys, with a following aggregation</p>
-        <p>operator to aggregate on per-group basis.</p>
+        <p>Similar to a SQL GROUPBY clause. Group the elements on the grouping keys, with a following aggregation
+        operator to aggregate on per-group basis.</p>
 {% highlight java %}
 Table in = tableEnv.fromDataSet(ds, "a, b, c");
 Table result = in.groupBy("a").select("a, b.sum as d");
+{% endhighlight %}
+        <p><i>Note:</i> Flink can refer to nonaggregated columns in the select list that are not named in
+        the groupBy clause, it could be used to get better performance by avoiding unnecessary column sorting and
+        grouping while nonaggregated column is cogrouped with columns in groupBy clause. For example:</p>
+{% highlight java %}
+Table in = tableEnv.fromDataSet(ds, "a, b, c");
+Table result = in.groupBy("a").select("a, b, c.sum as d");
 {% endhighlight %}
       </td>
     </tr>
@@ -200,8 +207,8 @@ Table result = in.groupBy("a").select("a, b.sum as d");
     <tr>
       <td><strong>Join</strong></td>
       <td>
-        <p>Similar to a SQL JOIN clause. Join two tables, both tables must have distinct field name, and the where</p>
-        <p>clause is mandatory for join condition.</p>
+        <p>Similar to a SQL JOIN clause. Join two tables, both tables must have distinct field name, and the where
+        clause is mandatory for join condition.</p>
 {% highlight java %}
 Table left = tableEnv.fromDataSet(ds1, "a, b, c");
 Table right = tableEnv.fromDataSet(ds2, "d, e, f");
@@ -284,11 +291,18 @@ val result = in.where('b === "red");
     <tr>
       <td><strong>GroupBy</strong></td>
       <td>
-        <p>Similar to a SQL GROUPBY clause. Group the elements on the grouping keys, with a following aggregation</p>
-        <p>operator to aggregate on per-group basis.</p>
+        <p>Similar to a SQL GROUPBY clause. Group the elements on the grouping keys, with a following aggregation
+        operator to aggregate on per-group basis.</p>
 {% highlight scala %}
 val in = ds.as('a, 'b, 'c);
 val result = in.groupBy('a).select('a, 'b.sum as 'd);
+{% endhighlight %}
+        <p><i>Note:</i> Flink can refer to nonaggregated columns in the select list that are not named in
+        the groupBy clause, it could be used to get better performance by avoiding unnecessary column sorting and
+        grouping while nonaggregated column is cogrouped with columns in groupBy clause. For example:</p>
+{% highlight scala %}
+val in = ds.as('a, 'b, 'c);
+val result = in.groupBy('a).select('a, 'b, 'c.sum as 'd);
 {% endhighlight %}
       </td>
     </tr>
@@ -296,8 +310,8 @@ val result = in.groupBy('a).select('a, 'b.sum as 'd);
     <tr>
       <td><strong>Join</strong></td>
       <td>
-        <p>Similar to a SQL JOIN clause. Join two tables, both tables must have distinct field name, and the where</p>
-        <p>clause is mandatory for join condition.</p>
+        <p>Similar to a SQL JOIN clause. Join two tables, both tables must have distinct field name, and the where
+        clause is mandatory for join condition.</p>
 {% highlight scala %}
 val left = ds1.as('a, 'b, 'c);
 val right = ds2.as('d, 'e, 'f);
diff --git a/flink-staging/flink-table/src/main/scala/org/apache/flink/api/java/table/JavaBatchTranslator.scala b/flink-staging/flink-table/src/main/scala/org/apache/flink/api/java/table/JavaBatchTranslator.scala
index e0b5ac99b74..9dc9297b6c1 100644
--- a/flink-staging/flink-table/src/main/scala/org/apache/flink/api/java/table/JavaBatchTranslator.scala
+++ b/flink-staging/flink-table/src/main/scala/org/apache/flink/api/java/table/JavaBatchTranslator.scala
@@ -30,7 +30,7 @@ import org.apache.flink.api.java.operators.{GroupReduceOperator, Keys, MapOperat
 import org.apache.flink.api.java.{DataSet => JavaDataSet}
 import org.apache.flink.api.table.expressions.analysis.ExtractEquiJoinFields
 import org.apache.flink.api.table.plan._
-import org.apache.flink.api.table.runtime.{ExpressionAggregateFunction, ExpressionFilterFunction, ExpressionJoinFunction, ExpressionSelectFunction}
+import org.apache.flink.api.table.runtime._
 import org.apache.flink.api.table.expressions._
 import org.apache.flink.api.table.typeinfo.{RenameOperator, RenamingProxyTypeInfo, RowTypeInfo}
 import org.apache.flink.api.table.{ExpressionException, Row, Table}
@@ -179,8 +179,29 @@ class JavaBatchTranslator extends PlanTranslator {
         val expandedInput = ExpandAggregations(sel)
 
         if (expandedInput.eq(sel)) {
-          // no expansions took place
-          val translatedInput = translateInternal(input)
+          val translatedInput = input match {
+            case GroupBy(groupByInput, groupExpressions) =>
+              val translatedGroupByInput = translateInternal(groupByInput)
+              val inType = translatedGroupByInput.getType.asInstanceOf[CompositeType[Row]]
+
+              val keyIndices = groupExpressions map {
+                case fe: ResolvedFieldReference => inType.getFieldIndex(fe.name)
+                case e =>
+                  throw new ExpressionException(s"Expression $e is not a valid key expression.")
+              }
+
+              val keys = new Keys.ExpressionKeys(keyIndices.toArray, inType, false)
+              val grouping = new UnsortedGrouping(translatedGroupByInput, keys)
+
+              new GroupReduceOperator(
+                grouping,
+                inType,
+                new NoExpressionAggregateFunction(),
+                "Nop Expression Aggregation")
+
+            case _ => translateInternal(input)
+          }
+
           val inType = translatedInput.getType.asInstanceOf[CompositeType[Row]]
           val inputFields = inType.getFieldNames
           createSelect(
diff --git a/flink-staging/flink-table/src/main/scala/org/apache/flink/api/table/runtime/ExpressionAggregateFunction.scala b/flink-staging/flink-table/src/main/scala/org/apache/flink/api/table/runtime/ExpressionAggregateFunction.scala
index 7e9bc0d8085..932f9df63f1 100644
--- a/flink-staging/flink-table/src/main/scala/org/apache/flink/api/table/runtime/ExpressionAggregateFunction.scala
+++ b/flink-staging/flink-table/src/main/scala/org/apache/flink/api/table/runtime/ExpressionAggregateFunction.scala
@@ -70,3 +70,20 @@ class ExpressionAggregateFunction(
   }
 
 }
+
+@Combinable
+class NoExpressionAggregateFunction() extends RichGroupReduceFunction[Row, Row] {
+
+  override def reduce(in: java.lang.Iterable[Row], out: Collector[Row]): Unit = {
+
+    var first: Row = null
+
+    val values = in.iterator()
+    if (values.hasNext) {
+      first = values.next()
+    }
+
+    out.collect(first)
+  }
+
+}
diff --git a/flink-staging/flink-table/src/test/java/org/apache/flink/api/java/table/test/GroupedAggregationsITCase.java b/flink-staging/flink-table/src/test/java/org/apache/flink/api/java/table/test/GroupedAggregationsITCase.java
index 4abba3b236c..f5c9185dbbb 100644
--- a/flink-staging/flink-table/src/test/java/org/apache/flink/api/java/table/test/GroupedAggregationsITCase.java
+++ b/flink-staging/flink-table/src/test/java/org/apache/flink/api/java/table/test/GroupedAggregationsITCase.java
@@ -101,5 +101,26 @@ public class GroupedAggregationsITCase extends MultipleProgramsTestBase {
 		String expected = "1\n" + "5\n" + "15\n" + "34\n" + "65\n" + "111\n";
 		compareResultAsText(results, expected);
 	}
+
+	@Test
+	public void testGroupNoAggregation() throws Exception {
+
+		ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();
+		TableEnvironment tableEnv = new TableEnvironment();
+
+		DataSet<Tuple3<Integer, Long, String>> input = CollectionDataSets.get3TupleDataSet(env);
+
+		Table table =
+			tableEnv.fromDataSet(input, "a, b, c");
+
+		Table result = table
+			.groupBy("b").select("a.sum as d, b").groupBy("b, d").select("b");
+
+		DataSet<Row> ds = tableEnv.toDataSet(result, Row.class);
+
+		String expected = "1\n" + "2\n" + "3\n" + "4\n" + "5\n" + "6\n";
+		List<Row> results = ds.collect();
+		compareResultAsText(results, expected);
+	}
 }
 
diff --git a/flink-staging/flink-table/src/test/scala/org/apache/flink/api/scala/table/test/GroupedAggreagationsITCase.scala b/flink-staging/flink-table/src/test/scala/org/apache/flink/api/scala/table/test/GroupedAggreagationsITCase.scala
index f04faf2132c..fb76507252e 100644
--- a/flink-staging/flink-table/src/test/scala/org/apache/flink/api/scala/table/test/GroupedAggreagationsITCase.scala
+++ b/flink-staging/flink-table/src/test/scala/org/apache/flink/api/scala/table/test/GroupedAggreagationsITCase.scala
@@ -22,6 +22,7 @@ import org.apache.flink.api.table.{Row, ExpressionException}
 import org.apache.flink.api.scala._
 import org.apache.flink.api.scala.table._
 import org.apache.flink.api.scala.util.CollectionDataSets
+import org.apache.flink.core.fs.FileSystem.WriteMode
 import org.apache.flink.test.util.{TestBaseUtils, MultipleProgramsTestBase}
 import org.apache.flink.test.util.MultipleProgramsTestBase.TestExecutionMode
 import org.junit._
@@ -94,4 +95,21 @@ class GroupedAggreagationsITCase(mode: TestExecutionMode) extends MultipleProgra
     val results = ds.collect()
     TestBaseUtils.compareResultAsText(results.asJava, expected)
   }
+
+  @Test
+  def testGroupNoAggregation(): Unit = {
+
+    val env = ExecutionEnvironment.getExecutionEnvironment
+    val ds = CollectionDataSets.get3TupleDataSet(env)
+      .as('a, 'b, 'c)
+      .groupBy('b)
+      .select('a.sum as 'd, 'b)
+      .groupBy('b, 'd)
+      .select('b)
+      .toDataSet[Row]
+
+    val expected = "1\n" + "2\n" + "3\n" + "4\n" + "5\n" + "6\n"
+    val results = ds.collect()
+    TestBaseUtils.compareResultAsText(results.asJava, expected)
+  }
 }
