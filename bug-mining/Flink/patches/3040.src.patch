diff --git a/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/operations/AggregateOperationFactory.java b/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/operations/AggregateOperationFactory.java
index 57ef9fb82d1..4794bef3ddc 100644
--- a/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/operations/AggregateOperationFactory.java
+++ b/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/operations/AggregateOperationFactory.java
@@ -22,6 +22,7 @@ import org.apache.flink.annotation.Internal;
 import org.apache.flink.api.common.typeinfo.BasicTypeInfo;
 import org.apache.flink.api.common.typeinfo.SqlTimeTypeInfo;
 import org.apache.flink.api.common.typeinfo.TypeInformation;
+import org.apache.flink.api.common.typeutils.CompositeType;
 import org.apache.flink.api.java.tuple.Tuple2;
 import org.apache.flink.table.api.GroupWindow;
 import org.apache.flink.table.api.SessionWithGapOnTimeWithAlias;
@@ -43,13 +44,12 @@ import org.apache.flink.table.expressions.UnresolvedReferenceExpression;
 import org.apache.flink.table.expressions.ValueLiteralExpression;
 import org.apache.flink.table.functions.BuiltInFunctionDefinitions;
 import org.apache.flink.table.functions.FunctionDefinition;
-import org.apache.flink.table.functions.FunctionKind;
 import org.apache.flink.table.functions.FunctionRequirement;
 import org.apache.flink.table.functions.TableAggregateFunction;
 import org.apache.flink.table.functions.TableAggregateFunctionDefinition;
-import org.apache.flink.table.functions.utils.UserDefinedFunctionUtils;
 import org.apache.flink.table.operations.WindowAggregateQueryOperation.ResolvedGroupWindow;
 import org.apache.flink.table.types.logical.LogicalType;
+import org.apache.flink.table.typeutils.FieldInfoUtils;
 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
 import org.apache.flink.table.typeutils.TimeIntervalTypeInfo;
 
@@ -118,9 +118,11 @@ public class AggregateOperationFactory {
 			convertedAggregates.stream().flatMap(this::extractAggregateResultTypes)
 		).toArray(TypeInformation[]::new);
 
+		String[] groupNames = groupings.stream()
+			.map(expr -> extractName(expr).orElseGet(expr::toString)).toArray(String[]::new);
 		String[] fieldNames = Stream.concat(
-			groupings.stream().map(expr -> extractName(expr).orElseGet(expr::toString)),
-			aggregates.stream().flatMap(this::extractAggregateNames)
+			Stream.of(groupNames),
+			aggregates.stream().flatMap(p -> extractAggregateNames(p, Arrays.asList(groupNames)))
 		).toArray(String[]::new);
 
 		TableSchema tableSchema = new TableSchema(fieldNames, fieldTypes);
@@ -158,9 +160,11 @@ public class AggregateOperationFactory {
 			convertedWindowProperties.stream().map(PlannerExpression::resultType)
 		).toArray(TypeInformation[]::new);
 
+		String[] groupNames = groupings.stream()
+			.map(expr -> extractName(expr).orElseGet(expr::toString)).toArray(String[]::new);
 		String[] fieldNames = concat(
-			groupings.stream().map(expr -> extractName(expr).orElseGet(expr::toString)),
-			aggregates.stream().flatMap(this::extractAggregateNames),
+			Stream.of(groupNames),
+			aggregates.stream().flatMap(p -> extractAggregateNames(p, Arrays.asList(groupNames))),
 			windowProperties.stream().map(expr -> extractName(expr).orElseGet(expr::toString))
 		).toArray(String[]::new);
 
@@ -180,9 +184,9 @@ public class AggregateOperationFactory {
 	 * it may return multi result types when the composite return type is flattened.
 	 */
 	private Stream<TypeInformation<?>> extractAggregateResultTypes(PlannerExpression plannerExpression) {
-		if (plannerExpression instanceof AggFunctionCall &&
-			((AggFunctionCall) plannerExpression).aggregateFunction() instanceof TableAggregateFunction) {
-			return Stream.of(UserDefinedFunctionUtils.getFieldInfo(plannerExpression.resultType())._3());
+		if ((plannerExpression instanceof AggFunctionCall) &&
+			(((AggFunctionCall) plannerExpression).aggregateFunction() instanceof TableAggregateFunction)) {
+			return Stream.of(FieldInfoUtils.getFieldTypes(plannerExpression.resultType()));
 		} else {
 			return Stream.of(plannerExpression.resultType());
 		}
@@ -190,13 +194,14 @@ public class AggregateOperationFactory {
 
 	/**
 	 * Extract names for the aggregate or the table aggregate expression. For a table aggregate, it
-	 * may return multi output names when the composite return type is flattened.
+	 * may return multi output names when the composite return type is flattened. If the result type
+	 * is not a {@link CompositeType}, the result name should not conflict with the group names.
 	 */
-	private Stream<String> extractAggregateNames(Expression expression) {
-		if (isFunctionOfKind(expression, FunctionKind.TABLE_AGGREGATE)) {
+	private Stream<String> extractAggregateNames(Expression expression, List<String> groupNames) {
+		if (isFunctionOfKind(expression, TABLE_AGGREGATE)) {
 			final TableAggregateFunctionDefinition definition =
 				(TableAggregateFunctionDefinition) ((UnresolvedCallExpression) expression).getFunctionDefinition();
-			return Arrays.stream(UserDefinedFunctionUtils.getFieldInfo(definition.getResultTypeInfo())._1());
+			return Arrays.stream(FieldInfoUtils.getFieldNames(definition.getResultTypeInfo(), groupNames));
 		} else {
 			return Stream.of(extractName(expression).orElseGet(expression::toString));
 		}
diff --git a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/plan/nodes/CommonTableAggregate.scala b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/plan/nodes/CommonTableAggregate.scala
index 09eec511d91..5df3060b0f3 100644
--- a/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/plan/nodes/CommonTableAggregate.scala
+++ b/flink-table/flink-table-planner/src/main/scala/org/apache/flink/table/plan/nodes/CommonTableAggregate.scala
@@ -27,8 +27,10 @@ import org.apache.calcite.rel.core.AggregateCall
 import org.apache.calcite.util.{ImmutableBitSet, Pair, Util}
 import org.apache.flink.table.calcite.{FlinkRelBuilder, FlinkTypeFactory}
 import org.apache.flink.table.runtime.aggregate.AggregateUtil.CalcitePair
+import org.apache.flink.table.typeutils.FieldInfoUtils
 
 import scala.collection.JavaConversions._
+import scala.collection.mutable.ListBuffer
 
 trait CommonTableAggregate extends CommonAggregate {
 
@@ -40,15 +42,27 @@ trait CommonTableAggregate extends CommonAggregate {
 
     val typeFactory = cluster.getTypeFactory.asInstanceOf[FlinkTypeFactory]
     val builder = typeFactory.builder
+    val groupNames = new ListBuffer[String]
 
     // group key fields
     groupSet.asList().foreach(e => {
       val field = child.getRowType.getFieldList.get(e)
+      groupNames.append(field.getName)
       builder.add(field)
     })
 
     // agg fields
-    aggCalls.get(0).`type`.getFieldList.foreach(builder.add)
+    val aggCall = aggCalls.get(0)
+    if (aggCall.`type`.isStruct) {
+      // only a structured type contains a field list.
+      aggCall.`type`.getFieldList.foreach(builder.add)
+    } else {
+      // A non-structured type does not have a field list, so get field name through
+      // TableEnvImpl.getFieldNames.
+      val name = FieldInfoUtils
+        .getFieldNames(FlinkTypeFactory.toTypeInfo(aggCall.`type`), groupNames).head
+      builder.add(name, aggCall.`type`)
+    }
     builder.build()
   }
 
@@ -60,8 +74,13 @@ trait CommonTableAggregate extends CommonAggregate {
     namedProperties: Seq[FlinkRelBuilder.NamedWindowProperty]): String = {
 
     val outFields = rowType.getFieldNames
-    val tableAggOutputArity = namedAggregates.head.left.getType.getFieldCount
-    val groupSize = grouping.size
+    val aggOutputType = namedAggregates.head.left.getType
+    val tableAggOutputArity = if (aggOutputType.isStruct) {
+      aggOutputType.getFieldCount
+    } else {
+      1
+    }
+    val groupSize = grouping.length
     val outFieldsOfTableAgg = outFields.subList(groupSize, groupSize + tableAggOutputArity)
     val tableAggOutputFields = Seq(s"(${outFieldsOfTableAgg.mkString(", ")})")
 
diff --git a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/api/stream/table/GroupWindowTableAggregateTest.scala b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/api/stream/table/GroupWindowTableAggregateTest.scala
index 976f1e7663a..d5f59ee6a55 100644
--- a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/api/stream/table/GroupWindowTableAggregateTest.scala
+++ b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/api/stream/table/GroupWindowTableAggregateTest.scala
@@ -21,7 +21,7 @@ package org.apache.flink.table.api.stream.table
 import org.apache.flink.api.scala._
 import org.apache.flink.table.api.{Session, Slide, Tumble}
 import org.apache.flink.table.api.scala._
-import org.apache.flink.table.utils.{EmptyTableAggFunc, TableTestBase}
+import org.apache.flink.table.utils.{EmptyTableAggFunc, EmptyTableAggFuncWithIntResultType, TableTestBase}
 import org.apache.flink.table.utils.TableTestUtil._
 import org.junit.Test
 
@@ -517,4 +517,36 @@ class GroupWindowTableAggregateTest extends TableTestBase {
 
     util.verifyTable(windowedTable, expected)
   }
+
+  @Test
+  def testTableAggregateWithIntResultType(): Unit = {
+    val table = util.addTable[(Long, Int, Long, Long)]('f0, 'f1, 'f2, 'd.rowtime, 'e.proctime)
+    val func = new EmptyTableAggFuncWithIntResultType
+
+    val windowedTable = table
+      .window(Session withGap 3.milli on 'd as 'w)
+      .groupBy('w, 'f0)
+      .flatAggregate(func('f1))
+      .select('w.end as 'we1, 'f0, 'f0_0 + 1, 'w.start, 'w.end)
+
+    val expected =
+      unaryNode(
+        "DataStreamCalc",
+        unaryNode(
+          "DataStreamGroupWindowTableAggregate",
+          unaryNode(
+            "DataStreamCalc",
+            streamTableNode(table),
+            term("select", "f0", "f1", "d")
+          ),
+          term("groupBy", "f0"),
+          term("window", "SessionGroupWindow('w, 'd, 3.millis)"),
+          term("select", "f0", "EmptyTableAggFuncWithIntResultType(f1) AS (f0_0)",
+            "end('w) AS EXPR$0", "start('w) AS EXPR$1")
+        ),
+        term("select", "EXPR$0 AS we1", "f0", "+(f0_0, 1) AS _c2", "EXPR$1", "EXPR$0")
+      )
+
+    util.verifyTable(windowedTable, expected)
+  }
 }
diff --git a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/api/stream/table/TableAggregateTest.scala b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/api/stream/table/TableAggregateTest.scala
index 5c44eab180c..8282f572bca 100644
--- a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/api/stream/table/TableAggregateTest.scala
+++ b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/api/stream/table/TableAggregateTest.scala
@@ -23,7 +23,7 @@ import org.apache.flink.api.scala._
 import org.apache.flink.table.api.Types
 import org.apache.flink.table.api.scala._
 import org.apache.flink.table.expressions.utils.Func0
-import org.apache.flink.table.utils.{EmptyTableAggFunc, TableTestBase}
+import org.apache.flink.table.utils.{EmptyTableAggFunc, EmptyTableAggFuncWithIntResultType, TableTestBase}
 import org.apache.flink.table.utils.TableTestUtil._
 import org.apache.flink.types.Row
 import org.junit.Test
@@ -175,5 +175,30 @@ class TableAggregateTest extends TableTestBase {
       )
     util.verifyJavaTable(resultTable, expected)
   }
+
+  @Test
+  def testTableAggregateWithIntResultType(): Unit = {
+
+    val table = util.addTable[(Long, Int, Long, Long)]('f0, 'f1, 'f2, 'd.rowtime, 'e.proctime)
+    val func = new EmptyTableAggFuncWithIntResultType
+
+    val resultTable = table
+      .groupBy('f0)
+      .flatAggregate(func('f1))
+      .select('f0, 'f0_0)
+
+    val expected =
+      unaryNode(
+        "DataStreamGroupTableAggregate",
+        unaryNode(
+          "DataStreamCalc",
+          streamTableNode(table),
+          term("select", "f0", "f1")
+        ),
+        term("groupBy", "f0"),
+        term("select", "f0, EmptyTableAggFuncWithIntResultType(f1) AS (f0_0)")
+      )
+    util.verifyTable(resultTable, expected)
+  }
 }
 
diff --git a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/utils/UserDefinedTableAggFunctions.scala b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/utils/UserDefinedTableAggFunctions.scala
index 1a50a4c0fc7..9f819e04c6c 100644
--- a/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/utils/UserDefinedTableAggFunctions.scala
+++ b/flink-table/flink-table-planner/src/test/scala/org/apache/flink/table/utils/UserDefinedTableAggFunctions.scala
@@ -246,6 +246,9 @@ class Top3WithMapView extends TableAggregateFunction[JTuple2[JInt, JInt], Top3Wi
   }
 }
 
+/**
+  * Test function for plan test.
+  */
 class EmptyTableAggFuncWithoutEmit extends TableAggregateFunction[JTuple2[JInt, JInt], Top3Accum] {
 
   override def createAccumulator(): Top3Accum = new Top3Accum
@@ -257,10 +260,16 @@ class EmptyTableAggFuncWithoutEmit extends TableAggregateFunction[JTuple2[JInt,
   def accumulate(acc: Top3Accum, value: Int): Unit = {}
 }
 
-/**
-  * Test function for plan test.
-  */
 class EmptyTableAggFunc extends EmptyTableAggFuncWithoutEmit {
 
   def emitValue(acc: Top3Accum, out: Collector[JTuple2[JInt, JInt]]): Unit = {}
 }
+
+class EmptyTableAggFuncWithIntResultType extends TableAggregateFunction[JInt, Top3Accum] {
+
+  override def createAccumulator(): Top3Accum = new Top3Accum
+
+  def accumulate(acc: Top3Accum, value: Int): Unit = {}
+
+  def emitValue(acc: Top3Accum, out: Collector[JInt]): Unit = {}
+}
