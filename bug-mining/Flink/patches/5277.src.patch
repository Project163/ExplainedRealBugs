diff --git a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/runtime/stream/sql/CompactionITCaseBase.java b/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/runtime/stream/sql/CompactionITCaseBase.java
index 25919d5253e..4ef25d3abfe 100644
--- a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/runtime/stream/sql/CompactionITCaseBase.java
+++ b/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/runtime/stream/sql/CompactionITCaseBase.java
@@ -18,11 +18,12 @@
 
 package org.apache.flink.table.planner.runtime.stream.sql;
 
+import org.apache.flink.api.common.functions.FilterFunction;
 import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.api.common.typeinfo.Types;
 import org.apache.flink.api.java.typeutils.RowTypeInfo;
 import org.apache.flink.streaming.api.scala.DataStream;
-import org.apache.flink.table.planner.runtime.utils.ParallelFiniteTestSource;
+import org.apache.flink.streaming.util.FiniteTestSource;
 import org.apache.flink.table.planner.runtime.utils.StreamingTestBase;
 import org.apache.flink.types.Row;
 import org.apache.flink.util.CloseableIterator;
@@ -73,14 +74,16 @@ public abstract class CompactionITCaseBase extends StreamingTestBase {
 
         DataStream<Row> stream =
                 new DataStream<>(
-                        env().getJavaEnv()
-                                .addSource(
-                                        new ParallelFiniteTestSource<>(rows),
-                                        new RowTypeInfo(
-                                                new TypeInformation[] {
-                                                    Types.INT, Types.STRING, Types.STRING
-                                                },
-                                                new String[] {"a", "b", "c"})));
+                                env().getJavaEnv()
+                                        .addSource(
+                                                new FiniteTestSource<>(rows),
+                                                new RowTypeInfo(
+                                                        new TypeInformation[] {
+                                                            Types.INT, Types.STRING, Types.STRING
+                                                        },
+                                                        new String[] {"a", "b", "c"})))
+                        .filter((FilterFunction<Row>) value -> true)
+                        .setParallelism(3); // to parallel tasks
 
         tEnv().createTemporaryView("my_table", stream);
     }
@@ -102,9 +105,13 @@ public abstract class CompactionITCaseBase extends StreamingTestBase {
     }
 
     public void innerTestNonPartition(int parallelism) throws Exception {
-        env().setParallelism(parallelism);
         createTable(resultPath);
-        tEnv().executeSql("insert into sink_table select * from my_table").await();
+        String sql =
+                String.format(
+                        "insert into sink_table /*+ OPTIONS('sink.parallelism' = '%d') */"
+                                + " select * from my_table",
+                        parallelism);
+        tEnv().executeSql(sql).await();
 
         assertIterator(tEnv().executeSql("select * from sink_table").collect());
 
diff --git a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/runtime/utils/ParallelFiniteTestSource.java b/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/runtime/utils/ParallelFiniteTestSource.java
deleted file mode 100644
index 5388be6fb19..00000000000
--- a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/runtime/utils/ParallelFiniteTestSource.java
+++ /dev/null
@@ -1,97 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.flink.table.planner.runtime.utils;
-
-import org.apache.flink.configuration.Configuration;
-import org.apache.flink.runtime.state.CheckpointListener;
-import org.apache.flink.streaming.api.functions.source.ParallelSourceFunction;
-import org.apache.flink.streaming.api.functions.source.RichSourceFunction;
-import org.apache.flink.streaming.util.FiniteTestSource;
-
-import java.util.Iterator;
-
-/** Parallel {@link FiniteTestSource} version. */
-public class ParallelFiniteTestSource<T> extends RichSourceFunction<T>
-        implements CheckpointListener, ParallelSourceFunction<T> {
-
-    private final Iterable<T> elements;
-
-    private transient volatile boolean running;
-    private transient volatile long currentCheckpointId;
-
-    public ParallelFiniteTestSource(Iterable<T> elements) {
-        this.elements = elements;
-    }
-
-    @Override
-    public void open(Configuration parameters) throws Exception {
-        super.open(parameters);
-        running = true;
-        currentCheckpointId = 0;
-    }
-
-    public boolean isTaskMessage(int id) {
-        return id % getRuntimeContext().getNumberOfParallelSubtasks()
-                == getRuntimeContext().getIndexOfThisSubtask();
-    }
-
-    @Override
-    public void run(SourceContext<T> ctx) throws Exception {
-        // first round of sending the elements and waiting for the checkpoints
-        emitElementsAndWaitForCheckpoints(ctx, 2);
-
-        // second round of the same
-        emitElementsAndWaitForCheckpoints(ctx, 4);
-    }
-
-    private void emitElementsAndWaitForCheckpoints(SourceContext<T> ctx, long checkpointIdToWaitFor)
-            throws InterruptedException {
-        final Object lock = ctx.getCheckpointLock();
-
-        synchronized (lock) {
-            emitRecords(ctx);
-
-            while (running && currentCheckpointId < checkpointIdToWaitFor) {
-                lock.wait(1);
-            }
-        }
-    }
-
-    private void emitRecords(SourceContext<T> ctx) {
-        Iterator<T> iterator = elements.iterator();
-        int i = 0;
-        while (iterator.hasNext()) {
-            T next = iterator.next();
-            if (isTaskMessage(i)) {
-                ctx.collect(next);
-            }
-            i++;
-        }
-    }
-
-    @Override
-    public void cancel() {
-        running = false;
-    }
-
-    @Override
-    public void notifyCheckpointComplete(long checkpointId) throws Exception {
-        currentCheckpointId = checkpointId;
-    }
-}
