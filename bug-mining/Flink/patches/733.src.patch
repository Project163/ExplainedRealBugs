diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/operators/BatchTask.java b/flink-runtime/src/main/java/org/apache/flink/runtime/operators/BatchTask.java
index bed71bf844e..17c8119557b 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/operators/BatchTask.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/operators/BatchTask.java
@@ -48,8 +48,6 @@ import org.apache.flink.runtime.operators.chaining.ExceptionInChainedStubExcepti
 import org.apache.flink.runtime.operators.resettable.SpillingResettableMutableObjectIterator;
 import org.apache.flink.runtime.operators.shipping.OutputCollector;
 import org.apache.flink.runtime.operators.shipping.OutputEmitter;
-import org.apache.flink.runtime.operators.shipping.RecordOutputCollector;
-import org.apache.flink.runtime.operators.shipping.RecordOutputEmitter;
 import org.apache.flink.runtime.operators.shipping.ShipStrategyType;
 import org.apache.flink.runtime.operators.sort.CombiningUnilateralSortMerger;
 import org.apache.flink.runtime.operators.sort.UnilateralSortMerger;
@@ -61,7 +59,6 @@ import org.apache.flink.runtime.operators.util.TaskConfig;
 import org.apache.flink.runtime.plugable.DeserializationDelegate;
 import org.apache.flink.runtime.plugable.SerializationDelegate;
 import org.apache.flink.runtime.taskmanager.TaskManagerRuntimeInfo;
-import org.apache.flink.types.Record;
 import org.apache.flink.util.Collector;
 import org.apache.flink.util.InstantiationUtil;
 import org.apache.flink.util.MutableObjectIterator;
@@ -1208,82 +1205,40 @@ public class BatchTask<S extends Function, OT> extends AbstractInvokable impleme
 
 		// get the factory for the serializer
 		final TypeSerializerFactory<T> serializerFactory = config.getOutputSerializer(cl);
-
-		// special case the Record
-		if (serializerFactory.getDataType().equals(Record.class)) {
-			final List<RecordWriter<Record>> writers = new ArrayList<RecordWriter<Record>>(numOutputs);
-
-			// create a writer for each output
-			for (int i = 0; i < numOutputs; i++) {
-				// create the OutputEmitter from output ship strategy
-				final ShipStrategyType strategy = config.getOutputShipStrategy(i);
-				final TypeComparatorFactory<?> compFact = config.getOutputComparator(i, cl);
-				final RecordOutputEmitter oe;
-				if (compFact == null) {
-					oe = new RecordOutputEmitter(strategy);
-				} else {
-					@SuppressWarnings("unchecked")
-					TypeComparator<Record> comparator = (TypeComparator<Record>) compFact.createComparator();
-					if (!comparator.supportsCompareAgainstReference()) {
-						throw new Exception("Incompatibe serializer-/comparator factories.");
-					}
-					final DataDistribution distribution = config.getOutputDataDistribution(i, cl);
-					final Partitioner<?> partitioner = config.getOutputPartitioner(i, cl);
-
-					oe = new RecordOutputEmitter(strategy, comparator, partitioner, distribution);
-				}
-
-				// setup accumulator counters
-				final RecordWriter<Record> recordWriter = new RecordWriter<Record>(task.getEnvironment().getWriter(outputOffset + i), oe);
-				recordWriter.setReporter(reporter);
-
-				writers.add(recordWriter);
+		final List<RecordWriter<SerializationDelegate<T>>> writers = new ArrayList<>(numOutputs);
+
+		// create a writer for each output
+		for (int i = 0; i < numOutputs; i++)
+		{
+			// create the OutputEmitter from output ship strategy
+			final ShipStrategyType strategy = config.getOutputShipStrategy(i);
+			final int indexInSubtaskGroup = task.getIndexInSubtaskGroup();
+			final TypeComparatorFactory<T> compFactory = config.getOutputComparator(i, cl);
+
+			final ChannelSelector<SerializationDelegate<T>> oe;
+			if (compFactory == null) {
+				oe = new OutputEmitter<T>(strategy, indexInSubtaskGroup);
 			}
-			if (eventualOutputs != null) {
-				eventualOutputs.addAll(writers);
-			}
-
-			@SuppressWarnings("unchecked")
-			final Collector<T> outColl = (Collector<T>) new RecordOutputCollector(writers);
-			return outColl;
-		}
-		else {
-			// generic case
-			final List<RecordWriter<SerializationDelegate<T>>> writers = new ArrayList<RecordWriter<SerializationDelegate<T>>>(numOutputs);
-
-			// create a writer for each output
-			for (int i = 0; i < numOutputs; i++)
-			{
-				// create the OutputEmitter from output ship strategy
-				final ShipStrategyType strategy = config.getOutputShipStrategy(i);
-				final int indexInSubtaskGroup = task.getIndexInSubtaskGroup();
-				final TypeComparatorFactory<T> compFactory = config.getOutputComparator(i, cl);
-
-				final ChannelSelector<SerializationDelegate<T>> oe;
-				if (compFactory == null) {
-					oe = new OutputEmitter<T>(strategy, indexInSubtaskGroup);
-				}
-				else {
-					final DataDistribution dataDist = config.getOutputDataDistribution(i, cl);
-					final Partitioner<?> partitioner = config.getOutputPartitioner(i, cl);
+			else {
+				final DataDistribution dataDist = config.getOutputDataDistribution(i, cl);
+				final Partitioner<?> partitioner = config.getOutputPartitioner(i, cl);
 
-					final TypeComparator<T> comparator = compFactory.createComparator();
-					oe = new OutputEmitter<T>(strategy, indexInSubtaskGroup, comparator, partitioner, dataDist);
-				}
+				final TypeComparator<T> comparator = compFactory.createComparator();
+				oe = new OutputEmitter<T>(strategy, indexInSubtaskGroup, comparator, partitioner, dataDist);
+			}
 
-				final RecordWriter<SerializationDelegate<T>> recordWriter =
-						new RecordWriter<SerializationDelegate<T>>(task.getEnvironment().getWriter(outputOffset + i), oe);
+			final RecordWriter<SerializationDelegate<T>> recordWriter =
+					new RecordWriter<SerializationDelegate<T>>(task.getEnvironment().getWriter(outputOffset + i), oe);
 
-				// setup live accumulator counters
-				recordWriter.setReporter(reporter);
+			// setup live accumulator counters
+			recordWriter.setReporter(reporter);
 
-				writers.add(recordWriter);
-			}
-			if (eventualOutputs != null) {
-				eventualOutputs.addAll(writers);
-			}
-			return new OutputCollector<T>(writers, serializerFactory.getSerializer());
+			writers.add(recordWriter);
+		}
+		if (eventualOutputs != null) {
+			eventualOutputs.addAll(writers);
 		}
+		return new OutputCollector<T>(writers, serializerFactory.getSerializer());
 	}
 
 	/**
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/operators/shipping/OutputEmitter.java b/flink-runtime/src/main/java/org/apache/flink/runtime/operators/shipping/OutputEmitter.java
index 62e3494ac0b..082b764ec9a 100644
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/operators/shipping/OutputEmitter.java
+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/operators/shipping/OutputEmitter.java
@@ -16,7 +16,6 @@
  * limitations under the License.
  */
 
-
 package org.apache.flink.runtime.operators.shipping;
 
 import org.apache.flink.api.common.distributions.DataDistribution;
@@ -25,15 +24,26 @@ import org.apache.flink.api.common.typeutils.TypeComparator;
 import org.apache.flink.runtime.io.network.api.writer.ChannelSelector;
 import org.apache.flink.runtime.plugable.SerializationDelegate;
 
+/**
+ * The output emitter decides to which of the possibly multiple output channels a record is sent.
+ * It implement routing based on hash-partitioning, broadcasting, round-robin, custom partition
+ * functions, etc.
+ * 
+ * @param <T> The type of the element handled by the emitter.
+ */
 public class OutputEmitter<T> implements ChannelSelector<SerializationDelegate<T>> {
 	
-	private final ShipStrategyType strategy;		// the shipping strategy used by this output emitter
+	/** the shipping strategy used by this output emitter */
+	private final ShipStrategyType strategy; 
 
-	private int[] channels;						// the reused array defining target channels
+	/** the reused array defining target channels */
+	private int[] channels;
 
-	private int nextChannelToSendTo = 0;		// counter to go over channels round robin
+	/** counter to go over channels round robin */
+	private int nextChannelToSendTo = 0;
 	
-	private final TypeComparator<T> comparator;	// the comparator for hashing / sorting
+	/** the comparator for hashing / sorting */
+	private final TypeComparator<T> comparator;
 	
 	private final Partitioner<Object> partitioner;
 	
@@ -43,13 +53,6 @@ public class OutputEmitter<T> implements ChannelSelector<SerializationDelegate<T
 	// Constructors
 	// ------------------------------------------------------------------------
 
-	/**
-	 * Creates a new channel selector that distributes data round robin.
-	 */
-	public OutputEmitter() {
-		this(ShipStrategyType.NONE, 0);
-	}
-
 	/**
 	 * Creates a new channel selector that uses the given strategy (broadcasting, partitioning, ...)
 	 * and uses the supplied task index perform a round robin distribution.
@@ -58,7 +61,7 @@ public class OutputEmitter<T> implements ChannelSelector<SerializationDelegate<T
 	 */
 	public OutputEmitter(ShipStrategyType strategy, int indexInSubtaskGroup) {
 		this(strategy, indexInSubtaskGroup, null, null, null);
-	}	
+	}
 	
 	/**
 	 * Creates a new channel selector that uses the given strategy (broadcasting, partitioning, ...)
@@ -71,24 +74,10 @@ public class OutputEmitter<T> implements ChannelSelector<SerializationDelegate<T
 		this(strategy, 0, comparator, null, null);
 	}
 	
-	/**
-	 * Creates a new channel selector that uses the given strategy (broadcasting, partitioning, ...)
-	 * and uses the supplied comparator to hash / compare records for partitioning them deterministically.
-	 * 
-	 * @param strategy The distribution strategy to be used.
-	 * @param comparator The comparator used to hash / compare the records.
-	 * @param distr The distribution pattern used in the case of a range partitioning.
-	 */
-	public OutputEmitter(ShipStrategyType strategy, TypeComparator<T> comparator, DataDistribution distr) {
-		this(strategy, 0, comparator, null, distr);
-	}
 	
-	public OutputEmitter(ShipStrategyType strategy, TypeComparator<T> comparator, Partitioner<?> partitioner) {
-		this(strategy, 0, comparator, partitioner, null);
-	}
-		
 	@SuppressWarnings("unchecked")
-	public OutputEmitter(ShipStrategyType strategy, int indexInSubtaskGroup, TypeComparator<T> comparator, Partitioner<?> partitioner, DataDistribution distr) {
+	public OutputEmitter(ShipStrategyType strategy, int indexInSubtaskGroup, 
+							TypeComparator<T> comparator, Partitioner<?> partitioner, DataDistribution distr) {
 		if (strategy == null) { 
 			throw new NullPointerException();
 		}
@@ -139,8 +128,6 @@ public class OutputEmitter<T> implements ChannelSelector<SerializationDelegate<T
 			return broadcast(numberOfChannels);
 		case PARTITION_CUSTOM:
 			return customPartition(record.getInstance(), numberOfChannels);
-		case PARTITION_RANGE:
-			return rangePartition(record.getInstance(), numberOfChannels);
 		default:
 			throw new UnsupportedOperationException("Unsupported distribution strategy: " + strategy.name());
 		}
@@ -215,10 +202,6 @@ public class OutputEmitter<T> implements ChannelSelector<SerializationDelegate<T
 
 		return k;
 	}
-
-	private int[] rangePartition(T record, int numberOfChannels) {
-		throw new UnsupportedOperationException();
-	}
 	
 	private int[] customPartition(T record, int numberOfChannels) {
 		try {
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/operators/shipping/RecordOutputCollector.java b/flink-runtime/src/main/java/org/apache/flink/runtime/operators/shipping/RecordOutputCollector.java
deleted file mode 100644
index dfd58dc83d5..00000000000
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/operators/shipping/RecordOutputCollector.java
+++ /dev/null
@@ -1,111 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.flink.runtime.operators.shipping;
-
-import java.io.IOException;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.List;
-
-import org.apache.flink.runtime.io.network.api.writer.RecordWriter;
-import org.apache.flink.types.Record;
-import org.apache.flink.util.Collector;
-
-/**
- * The OutputCollector collects {@link Record}s, and emits the pair to a set of Nephele {@link RecordWriter}s.
- * The OutputCollector tracks to which writers a deep-copy must be given and which not.
- */
-public class RecordOutputCollector implements Collector<Record>
-{
-	// list of writers
-	protected RecordWriter<Record>[] writers;
-
-	/**
-	 * Initializes the output collector with a set of writers.
-	 * To specify for a writer that it must be fed with a deep-copy, set the bit in the copy flag bit mask to 1 that
-	 * corresponds to the position of the writer within the {@link List}.
-	 *
-	 * @param writers List of all writers.
-	 */
-	@SuppressWarnings("unchecked")
-	public RecordOutputCollector(List<RecordWriter<Record>> writers) {
-
-		this.writers = (RecordWriter<Record>[]) writers.toArray(new RecordWriter[writers.size()]);
-	}
-
-	/**
-	 * Adds a writer to the OutputCollector.
-	 *
-	 * @param writer The writer to add.
-	 */
-	@SuppressWarnings("unchecked")
-	public void addWriter(RecordWriter<Record> writer)
-	{
-		// avoid using the array-list here to reduce one level of object indirection
-		if (this.writers == null) {
-			this.writers = new RecordWriter[] {writer};
-		}
-		else {
-			RecordWriter<Record>[] ws = new RecordWriter[this.writers.length + 1];
-			System.arraycopy(this.writers, 0, ws, 0, this.writers.length);
-			ws[this.writers.length] = writer;
-			this.writers = ws;
-		}
-	}
-
-	/**
-	 * Collects a {@link Record}, and emits it to all writers.
-	 * Writers which require a deep-copy are fed with a copy.
-	 */
-	@Override
-	public void collect(Record record)
-	{
-		try {
-			for (int i = 0; i < writers.length; i++) {
-				this.writers[i].emit(record);
-			}
-		}
-		catch (IOException e) {
-			throw new RuntimeException("Emitting the record caused an I/O exception: " + e.getMessage(), e);
-		}
-		catch (InterruptedException e) {
-			throw new RuntimeException("Emitting the record was interrupted: " + e.getMessage(), e);
-		}
-	}
-
-	@Override
-	public void close() {
-		for (RecordWriter<?> writer : writers) {
-			try {
-				writer.flush();
-			} catch (IOException e) {
-				throw new RuntimeException(e.getMessage(), e);
-			}
-		}
-	}
-
-	/**
-	 * List of writers that are associated with this output collector
-	 * @return list of writers
-	 */
-	public List<RecordWriter<Record>> getWriters() {
-		return Collections.unmodifiableList(Arrays.asList(writers));
-	}
-}
diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/operators/shipping/RecordOutputEmitter.java b/flink-runtime/src/main/java/org/apache/flink/runtime/operators/shipping/RecordOutputEmitter.java
deleted file mode 100644
index 300d73f3c1a..00000000000
--- a/flink-runtime/src/main/java/org/apache/flink/runtime/operators/shipping/RecordOutputEmitter.java
+++ /dev/null
@@ -1,247 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.flink.runtime.operators.shipping;
-
-import org.apache.flink.api.common.distributions.DataDistribution;
-import org.apache.flink.api.common.functions.Partitioner;
-import org.apache.flink.api.common.typeutils.TypeComparator;
-import org.apache.flink.runtime.io.network.api.writer.ChannelSelector;
-import org.apache.flink.types.Key;
-import org.apache.flink.types.Record;
-
-public class RecordOutputEmitter implements ChannelSelector<Record> {
-	
-	// ------------------------------------------------------------------------
-	// Fields
-	// ------------------------------------------------------------------------
-
-	private static final byte[] DEFAULT_SALT = new byte[] { 17, 31, 47, 51, 83, 1 };
-	
-	private final ShipStrategyType strategy;			// the shipping strategy used by this output emitter
-	
-	private final TypeComparator<Record> comparator;	// the comparator for hashing / sorting
-	
-	private int[] channels;							// the reused array defining target channels
-	
-	private Key<?>[][] partitionBoundaries;		// the partition boundaries for range partitioning
-	
-	private final DataDistribution distribution; // the data distribution to create the partition boundaries for range partitioning
-	
-	private final Partitioner<Object> partitioner;
-	
-	private int nextChannelToSendTo;				// counter to go over channels round robin
-	
-	private Object[] extractedKeys;
-
-	// ------------------------------------------------------------------------
-	// Constructors
-	// ------------------------------------------------------------------------
-
-	/**
-	 * Creates a new channel selector that uses the given strategy (broadcasting, partitioning, ...).
-	 * 
-	 * @param strategy The distribution strategy to be used.
-	 */
-	public RecordOutputEmitter(ShipStrategyType strategy) {
-		this(strategy, null);
-	}	
-	
-	/**
-	 * Creates a new channel selector that uses the given strategy (broadcasting, partitioning, ...)
-	 * and uses the supplied comparator to hash / compare records for partitioning them deterministically.
-	 * 
-	 * @param strategy The distribution strategy to be used.
-	 * @param comparator The comparator used to hash / compare the records.
-	 */
-	public RecordOutputEmitter(ShipStrategyType strategy, TypeComparator<Record> comparator) {
-		this(strategy, comparator, null, null);
-	}
-
-	/**
-	 * Creates a new channel selector that uses the given strategy (broadcasting, partitioning, ...)
-	 * and uses the supplied comparator to hash / compare records for partitioning them deterministically.
-	 * 
-	 * @param strategy The distribution strategy to be used.
-	 * @param comparator The comparator used to hash / compare the records.
-	 * @param distr The distribution pattern used in the case of a range partitioning.
-	 */
-	public RecordOutputEmitter(ShipStrategyType strategy, TypeComparator<Record> comparator, DataDistribution distr) {
-		this(strategy, comparator, null, distr);
-	}
-	
-	public RecordOutputEmitter(ShipStrategyType strategy, TypeComparator<Record> comparator, Partitioner<?> partitioner) {
-		this(strategy, comparator, partitioner, null);
-	}
-		
-	@SuppressWarnings("unchecked")
-	public RecordOutputEmitter(ShipStrategyType strategy, TypeComparator<Record> comparator, Partitioner<?> partitioner, DataDistribution distr) {
-		if (strategy == null) { 
-			throw new NullPointerException();
-		}
-		
-		this.strategy = strategy;
-		this.comparator = comparator;
-		this.distribution = distr;
-		this.partitioner = (Partitioner<Object>) partitioner;
-		
-		switch (strategy) {
-		case FORWARD:
-		case PARTITION_FORCED_REBALANCE:
-		case PARTITION_HASH:
-		case PARTITION_RANGE:
-		case PARTITION_RANDOM:
-			this.channels = new int[1];
-			break;
-		case BROADCAST:
-		case PARTITION_CUSTOM:
-			break;
-		default:
-			throw new IllegalArgumentException("Invalid shipping strategy for OutputEmitter: " + strategy.name());
-		}
-		
-		if (strategy == ShipStrategyType.PARTITION_RANGE && distr == null) {
-			throw new NullPointerException("Data distribution must not be null when the ship strategy is range partitioning.");
-		}
-		if (strategy == ShipStrategyType.PARTITION_CUSTOM && partitioner == null) {
-			throw new NullPointerException("Partitioner must not be null when the ship strategy is set to custom partitioning.");
-		}
-	}
-
-	// ------------------------------------------------------------------------
-	// Channel Selection
-	// ------------------------------------------------------------------------
-
-	@Override
-	public final int[] selectChannels(Record record, int numberOfChannels) {
-		switch (strategy) {
-		case FORWARD:
-		case PARTITION_RANDOM:
-		case PARTITION_FORCED_REBALANCE:
-			return robin(numberOfChannels);
-		case PARTITION_HASH:
-			return hashPartitionDefault(record, numberOfChannels);
-		case PARTITION_CUSTOM:
-			return customPartition(record, numberOfChannels);
-		case BROADCAST:
-			return broadcast(numberOfChannels);
-		case PARTITION_RANGE:
-			return rangePartition(record, numberOfChannels);
-		default:
-			throw new UnsupportedOperationException("Unsupported distribution strategy: " + strategy.name());
-		}
-	}
-	
-	// --------------------------------------------------------------------------------------------
-
-	private final int[] robin(int numberOfChannels) {
-		final int channel = this.nextChannelToSendTo;
-		this.nextChannelToSendTo = channel > 0 ? channel - 1 : numberOfChannels - 1;
-		this.channels[0] = channel;
-		return this.channels;
-	}
-
-	private final int[] broadcast(int numberOfChannels) {
-		if (this.channels == null || this.channels.length != numberOfChannels) {
-			this.channels = new int[numberOfChannels];
-			for (int i = 0; i < numberOfChannels; i++) {
-				this.channels[i] = i;
-			}
-		}
-		
-		return this.channels;
-	}
-
-	private final int[] hashPartitionDefault(final Record record, int numberOfChannels) {
-		int hash = this.comparator.hash(record);
-		for (int i = 0; i < DEFAULT_SALT.length; i++) {
-			hash ^= ((hash << 5) + DEFAULT_SALT[i] + (hash >> 2));
-		}
-		
-		if(hash < 0) {
-			if(hash == Integer.MIN_VALUE) {
-				this.channels[0] = Integer.MAX_VALUE % numberOfChannels;
-			} else {
-				this.channels[0] = -hash % numberOfChannels;
-			}
-		} else {
-			this.channels[0] = hash % numberOfChannels;
-		}
-		return this.channels;
-	}
-	
-	private final int[] rangePartition(final Record record, int numberOfChannels) {
-		if (this.partitionBoundaries == null) {
-			this.partitionBoundaries = new Key[numberOfChannels - 1][];
-			for (int i = 0; i < numberOfChannels - 1; i++) {
-				this.partitionBoundaries[i] = this.distribution.getBucketBoundary(i, numberOfChannels);
-			}
-		}
-		
-		if (numberOfChannels == this.partitionBoundaries.length + 1) {
-			final Key<?>[][] boundaries = this.partitionBoundaries;
-			this.comparator.setReference(record);
-			
-			// bin search the bucket
-			int low = 0;
-			int high = this.partitionBoundaries.length - 1;
-			
-			while (low <= high) {
-				final int mid = (low + high) >>> 1;
-				final int result = this.comparator.compareAgainstReference(boundaries[mid]);
-				
-				if (result < 0) {
-					low = mid + 1;
-				} else if (result > 0) {
-					high = mid - 1;
-				} else {
-					this.channels[0] = mid;
-					return this.channels;
-				}
-			}
-			this.channels[0] = low;	// key not found, but the low index is the target
-									// bucket, since the boundaries are the upper bound
-			return this.channels;
-		} else {
-			throw new IllegalStateException(
-			"The number of channels to partition among is inconsistent with the partitioners state.");
-		}
-	}
-	
-	private final int[] customPartition(Record record, int numberOfChannels) {
-		if (channels == null) {
-			channels = new int[1];
-			extractedKeys = new Object[1];
-		}
-		
-		try {
-			if (comparator.extractKeys(record, extractedKeys, 0) == 1) {
-				final Object key = extractedKeys[0];
-				channels[0] = partitioner.partition(key, numberOfChannels);
-				return channels;
-			}
-			else {
-				throw new RuntimeException("Inconsistency in the key comparator - comparator extracted more than one field.");
-			}
-		}
-		catch (Throwable t) {
-			throw new RuntimeException("Error while calling custom partitioner.", t);
-		}
-	}
-}
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/operators/util/OutputEmitterTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/operators/util/OutputEmitterTest.java
index 16e02df54fb..6bf5dcc2727 100644
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/operators/util/OutputEmitterTest.java
+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/operators/util/OutputEmitterTest.java
@@ -16,7 +16,6 @@
  * limitations under the License.
  */
 
-
 package org.apache.flink.runtime.operators.util;
 
 import java.io.DataInputStream;
@@ -25,8 +24,6 @@ import java.io.IOException;
 import java.io.PipedInputStream;
 import java.io.PipedOutputStream;
 
-import junit.framework.TestCase;
-
 import org.apache.flink.api.common.typeutils.base.IntComparator;
 import org.junit.Assert;
 import org.apache.flink.api.common.typeutils.TypeComparator;
@@ -49,16 +46,19 @@ import org.apache.flink.types.KeyFieldOutOfBoundsException;
 import org.apache.flink.types.NullKeyFieldException;
 import org.apache.flink.types.Record;
 import org.apache.flink.types.StringValue;
+
 import org.junit.Test;
 
-public class OutputEmitterTest extends TestCase {
+import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.fail;
+
+public class OutputEmitterTest {
 	
-//	private static final long SEED = 485213591485399L;
 	
 	@Test
 	public void testPartitionHash() {
 		// Test for IntValue
-		@SuppressWarnings("unchecked")
+		@SuppressWarnings({"unchecked", "rawtypes"})
 		final TypeComparator<Record> intComp = new RecordComparatorFactory(new int[] {0}, new Class[] {IntValue.class}).createComparator();
 		final ChannelSelector<SerializationDelegate<Record>> oe1 = new OutputEmitter<Record>(ShipStrategyType.PARTITION_HASH, intComp);
 		final SerializationDelegate<Record> delegate = new SerializationDelegate<Record>(new RecordSerializerFactory().getSerializer());
@@ -74,20 +74,20 @@ public class OutputEmitterTest extends TestCase {
 			delegate.setInstance(rec);
 			
 			int[] chans = oe1.selectChannels(delegate, hit.length);
-			for(int j=0; j < chans.length; j++) {
-				hit[chans[j]]++;
+			for (int chan : chans) {
+				hit[chan]++;
 			}
 		}
 
 		int cnt = 0;
-		for (int i = 0; i < hit.length; i++) {
-			assertTrue(hit[i] > 0);
-			cnt += hit[i];
+		for (int aHit : hit) {
+			assertTrue(aHit > 0);
+			cnt += aHit;
 		}
 		assertTrue(cnt == numRecs);
 
 		// Test for StringValue
-		@SuppressWarnings("unchecked")
+		@SuppressWarnings({"unchecked", "rawtypes"})
 		final TypeComparator<Record> stringComp = new RecordComparatorFactory(new int[] {0}, new Class[] {StringValue.class}).createComparator();
 		final ChannelSelector<SerializationDelegate<Record>> oe2 = new OutputEmitter<Record>(ShipStrategyType.PARTITION_HASH, stringComp);
 
@@ -102,15 +102,15 @@ public class OutputEmitterTest extends TestCase {
 			delegate.setInstance(rec);
 				
 			int[] chans = oe2.selectChannels(delegate, hit.length);
-			for(int j=0; j < chans.length; j++) {
-				hit[chans[j]]++;
+			for (int chan : chans) {
+				hit[chan]++;
 			}
 		}
 
 		cnt = 0;
-		for (int i = 0; i < hit.length; i++) {
-			assertTrue(hit[i] > 0);
-			cnt += hit[i];
+		for (int aHit : hit) {
+			assertTrue(aHit > 0);
+			cnt += aHit;
 		}
 		assertTrue(cnt == numRecs);
 		
@@ -155,7 +155,7 @@ public class OutputEmitterTest extends TestCase {
 	@Test
 	public void testForward() {
 		// Test for IntValue
-		@SuppressWarnings("unchecked")
+		@SuppressWarnings({"unchecked", "rawtypes"})
 		final TypeComparator<Record> intComp = new RecordComparatorFactory(new int[] {0}, new Class[] {IntValue.class}).createComparator();
 		final ChannelSelector<SerializationDelegate<Record>> oe1 = new OutputEmitter<Record>(ShipStrategyType.FORWARD, intComp);
 		final SerializationDelegate<Record> delegate = new SerializationDelegate<Record>(new RecordSerializerFactory().getSerializer());
@@ -171,8 +171,8 @@ public class OutputEmitterTest extends TestCase {
 			delegate.setInstance(rec);
 
 			int[] chans = oe1.selectChannels(delegate, hit.length);
-			for(int j=0; j < chans.length; j++) {
-				hit[chans[j]]++;
+			for (int chan : chans) {
+				hit[chan]++;
 			}
 		}
 
@@ -182,7 +182,7 @@ public class OutputEmitterTest extends TestCase {
 		}
 
 		// Test for StringValue
-		@SuppressWarnings("unchecked")
+		@SuppressWarnings({"unchecked", "rawtypes"})
 		final TypeComparator<Record> stringComp = new RecordComparatorFactory(new int[] {0}, new Class[] {StringValue.class}).createComparator();
 		final ChannelSelector<SerializationDelegate<Record>> oe2 = new OutputEmitter<Record>(ShipStrategyType.FORWARD, stringComp);
 
@@ -197,8 +197,8 @@ public class OutputEmitterTest extends TestCase {
 			delegate.setInstance(rec);
 
 			int[] chans = oe2.selectChannels(delegate, hit.length);
-			for(int j=0; j < chans.length; j++) {
-				hit[chans[j]]++;
+			for (int chan : chans) {
+				hit[chan]++;
 			}
 		}
 
@@ -214,7 +214,7 @@ public class OutputEmitterTest extends TestCase {
 		int numChannels = 100;
 		int toTaskIndex = numChannels * 6/7;
 		int fromTaskIndex = toTaskIndex + numChannels;
-		int extraRecords = numChannels * 1/3;
+		int extraRecords = numChannels / 3;
 		int numRecords = 50000 + extraRecords;
 
 		final ChannelSelector<SerializationDelegate<Record>> oe1 = new OutputEmitter<Record>(ShipStrategyType.PARTITION_FORCED_REBALANCE, fromTaskIndex);
@@ -228,8 +228,8 @@ public class OutputEmitterTest extends TestCase {
 			delegate.setInstance(rec);
 
 			int[] chans = oe1.selectChannels(delegate, hit.length);
-			for(int j=0; j < chans.length; j++) {
-				hit[chans[j]]++;
+			for (int chan : chans) {
+				hit[chan]++;
 			}
 		}
 
@@ -261,8 +261,8 @@ public class OutputEmitterTest extends TestCase {
 			delegate.setInstance(rec);
 
 			int[] chans = oe2.selectChannels(delegate, hit.length);
-			for(int j=0; j < chans.length; j++) {
-				hit[chans[j]]++;
+			for (int chan : chans) {
+				hit[chan]++;
 			}
 		}
 
@@ -281,7 +281,7 @@ public class OutputEmitterTest extends TestCase {
 	@Test
 	public void testBroadcast() {
 		// Test for IntValue
-		@SuppressWarnings("unchecked")
+		@SuppressWarnings({"unchecked", "rawtypes"})
 		final TypeComparator<Record> intComp = new RecordComparatorFactory(new int[] {0}, new Class[] {IntValue.class}).createComparator();
 		final ChannelSelector<SerializationDelegate<Record>> oe1 = new OutputEmitter<Record>(ShipStrategyType.BROADCAST, intComp);
 		final SerializationDelegate<Record> delegate = new SerializationDelegate<Record>(new RecordSerializerFactory().getSerializer());
@@ -297,17 +297,17 @@ public class OutputEmitterTest extends TestCase {
 			delegate.setInstance(rec);
 			
 			int[] chans = oe1.selectChannels(delegate, hit.length);
-			for(int j=0; j < chans.length; j++) {
-				hit[chans[j]]++;
+			for (int chan : chans) {
+				hit[chan]++;
 			}
 		}
 
-		for (int i = 0; i < hit.length; i++) {
-			assertTrue(hit[i]+"", hit[i] == numRecords);
+		for (int aHit : hit) {
+			assertTrue(aHit + "", aHit == numRecords);
 		}
 		
 		// Test for StringValue
-		@SuppressWarnings("unchecked")
+		@SuppressWarnings({"unchecked", "rawtypes"})
 		final TypeComparator<Record> stringComp = new RecordComparatorFactory(new int[] {0}, new Class[] {StringValue.class}).createComparator();
 		final ChannelSelector<SerializationDelegate<Record>> oe2 = new OutputEmitter<Record>(ShipStrategyType.BROADCAST, stringComp);
 
@@ -322,19 +322,19 @@ public class OutputEmitterTest extends TestCase {
 			delegate.setInstance(rec);
 				
 			int[] chans = oe2.selectChannels(delegate, hit.length);
-			for(int j=0; j < chans.length; j++) {
-				hit[chans[j]]++;
+			for (int chan : chans) {
+				hit[chan]++;
 			}
 		}
 
-		for (int i = 0; i < hit.length; i++) {
-			assertTrue(hit[i]+"", hit[i] == numRecords);
+		for (int aHit : hit) {
+			assertTrue(aHit + "", aHit == numRecords);
 		}
 	}
 	
 	@Test
 	public void testMultiKeys() {
-		@SuppressWarnings("unchecked")
+		@SuppressWarnings({"unchecked", "rawtypes"})
 		final TypeComparator<Record> multiComp = new RecordComparatorFactory(new int[] {0,1,3}, new Class[] {IntValue.class, StringValue.class, DoubleValue.class}).createComparator();
 		final ChannelSelector<SerializationDelegate<Record>> oe1 = new OutputEmitter<Record>(ShipStrategyType.PARTITION_HASH, multiComp);
 		final SerializationDelegate<Record> delegate = new SerializationDelegate<Record>(new RecordSerializerFactory().getSerializer());
@@ -352,15 +352,15 @@ public class OutputEmitterTest extends TestCase {
 			delegate.setInstance(rec);
 			
 			int[] chans = oe1.selectChannels(delegate, hit.length);
-			for(int j=0; j < chans.length; j++) {
-				hit[chans[j]]++;
+			for (int chan : chans) {
+				hit[chan]++;
 			}
 		}
 
 		int cnt = 0;
-		for (int i = 0; i < hit.length; i++) {
-			assertTrue(hit[i] > 0);
-			cnt += hit[i];
+		for (int aHit : hit) {
+			assertTrue(aHit > 0);
+			cnt += aHit;
 		}
 		assertTrue(cnt == numRecords);
 		
@@ -369,7 +369,7 @@ public class OutputEmitterTest extends TestCase {
 	@Test
 	public void testMissingKey() {
 		// Test for IntValue
-		@SuppressWarnings("unchecked")
+		@SuppressWarnings({"unchecked", "rawtypes"})
 		final TypeComparator<Record> intComp = new RecordComparatorFactory(new int[] {1}, new Class[] {IntValue.class}).createComparator();
 		final ChannelSelector<SerializationDelegate<Record>> oe1 = new OutputEmitter<Record>(ShipStrategyType.PARTITION_HASH, intComp);
 		final SerializationDelegate<Record> delegate = new SerializationDelegate<Record>(new RecordSerializerFactory().getSerializer());
@@ -390,7 +390,7 @@ public class OutputEmitterTest extends TestCase {
 	@Test
 	public void testNullKey() {
 		// Test for IntValue
-		@SuppressWarnings("unchecked")
+		@SuppressWarnings({"unchecked", "rawtypes"})
 		final TypeComparator<Record> intComp = new RecordComparatorFactory(new int[] {0}, new Class[] {IntValue.class}).createComparator();
 		final ChannelSelector<SerializationDelegate<Record>> oe1 = new OutputEmitter<Record>(ShipStrategyType.PARTITION_HASH, intComp);
 		final SerializationDelegate<Record> delegate = new SerializationDelegate<Record>(new RecordSerializerFactory().getSerializer());
@@ -412,7 +412,7 @@ public class OutputEmitterTest extends TestCase {
 	public void testWrongKeyClass() {
 		
 		// Test for IntValue
-		@SuppressWarnings("unchecked")
+		@SuppressWarnings({"unchecked", "rawtypes"})
 		final TypeComparator<Record> doubleComp = new RecordComparatorFactory(new int[] {0}, new Class[] {DoubleValue.class}).createComparator();
 		final ChannelSelector<SerializationDelegate<Record>> oe1 = new OutputEmitter<Record>(ShipStrategyType.PARTITION_HASH, doubleComp);
 		final SerializationDelegate<Record> delegate = new SerializationDelegate<Record>(new RecordSerializerFactory().getSerializer());
@@ -517,53 +517,4 @@ public class OutputEmitterTest extends TestCase {
 			return comparators;
 		}
 	}
-	
-//	@Test
-//	public void testPartitionRange() {
-//		final Random rnd = new Random(SEED);
-//		
-//		final int DISTR_MIN = 0;
-//		final int DISTR_MAX = 1000000;
-//		final int DISTR_RANGE = DISTR_MAX - DISTR_MIN + 1;
-//		final int NUM_BUCKETS = 137;
-//		final float BUCKET_WIDTH = DISTR_RANGE / ((float) NUM_BUCKETS);
-//		
-//		final int NUM_ELEMENTS = 10000000;
-//		
-//		final DataDistribution distri = new UniformIntegerDistribution(DISTR_MIN, DISTR_MAX);
-//		
-//		@SuppressWarnings("unchecked")
-//		final TypeComparator<Record> intComp = new RecordComparatorFactory(new int[] {0}, new Class[] {IntValue.class}).createComparator();
-//		final ChannelSelector<SerializationDelegate<Record>> oe = new OutputEmitter<Record>(ShipStrategyType.PARTITION_RANGE, intComp, distri);
-//		final SerializationDelegate<Record> delegate = new SerializationDelegate<Record>(new RecordSerializerFactory().getSerializer());
-//		
-//		final IntValue integer = new IntValue();
-//		final Record rec = new Record();
-//		
-//		for (int i = 0; i < NUM_ELEMENTS; i++) {
-//			final int nextValue = rnd.nextInt(DISTR_RANGE) + DISTR_MIN;
-//			integer.setValue(nextValue);
-//			rec.setField(0, integer);
-//			delegate.setInstance(rec);
-//			
-//			final int[] channels = oe.selectChannels(delegate, NUM_BUCKETS);
-//			if (channels.length != 1) {
-//				Assert.fail("Resulting channels array has more than one channel.");
-//			}
-//			
-//			final int bucket = channels[0];
-//			final int shouldBeBucket = (int) ((nextValue - DISTR_MIN) / BUCKET_WIDTH);
-//			
-//			if (shouldBeBucket != bucket) {
-//				// we may have a rounding imprecision in the 'should be bucket' computation.
-//				final int lowerBoundaryForSelectedBucket = DISTR_MIN + (int) ((bucket    ) * BUCKET_WIDTH);
-//				final int upperBoundaryForSelectedBucket = DISTR_MIN + (int) ((bucket + 1) * BUCKET_WIDTH);
-//				if (nextValue <= lowerBoundaryForSelectedBucket || nextValue > upperBoundaryForSelectedBucket) {
-//					Assert.fail("Wrong bucket selected");
-//				}
-//			}
-//			
-//		}
-//	}
-	
 }
diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/operators/util/RecordOutputEmitterTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/operators/util/RecordOutputEmitterTest.java
deleted file mode 100644
index b831a7d5d3a..00000000000
--- a/flink-runtime/src/test/java/org/apache/flink/runtime/operators/util/RecordOutputEmitterTest.java
+++ /dev/null
@@ -1,369 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.flink.runtime.operators.util;
-
-import java.io.DataInputStream;
-import java.io.DataOutputStream;
-import java.io.IOException;
-import java.io.PipedInputStream;
-import java.io.PipedOutputStream;
-import java.util.Random;
-
-import junit.framework.TestCase;
-
-import org.apache.flink.api.common.distributions.DataDistribution;
-import org.apache.flink.api.common.distributions.UniformIntegerDistribution;
-import org.apache.flink.api.common.typeutils.record.RecordComparator;
-import org.apache.flink.core.memory.InputViewDataInputStreamWrapper;
-import org.apache.flink.core.memory.OutputViewDataOutputStreamWrapper;
-import org.apache.flink.runtime.io.network.api.writer.ChannelSelector;
-import org.apache.flink.runtime.operators.shipping.RecordOutputEmitter;
-import org.apache.flink.runtime.operators.shipping.ShipStrategyType;
-import org.apache.flink.types.DeserializationException;
-import org.apache.flink.types.DoubleValue;
-import org.apache.flink.types.IntValue;
-import org.apache.flink.types.KeyFieldOutOfBoundsException;
-import org.apache.flink.types.NullKeyFieldException;
-import org.apache.flink.types.Record;
-import org.apache.flink.types.StringValue;
-import org.junit.Assert;
-import org.junit.Test;
-
-public class RecordOutputEmitterTest extends TestCase {
-	
-	private static final long SEED = 485213591485399L;
-	
-	@Test
-	public void testPartitionHash() {
-		// Test for IntValue
-		@SuppressWarnings("unchecked")
-		final RecordComparator intComp = new RecordComparator(new int[] {0}, new Class[] {IntValue.class});
-		final ChannelSelector<Record> oe1 = new RecordOutputEmitter(ShipStrategyType.PARTITION_HASH, intComp);
-
-		int numChans = 100;
-		int numRecs = 50000;
-		int[] hit = new int[numChans];
-
-		for (int i = 0; i < numRecs; i++) {
-			IntValue k = new IntValue(i);
-			Record rec = new Record(k);
-			
-			int[] chans = oe1.selectChannels(rec, hit.length);
-			for(int j=0; j < chans.length; j++) {
-				hit[chans[j]]++;
-			}
-		}
-
-		int cnt = 0;
-		for (int i = 0; i < hit.length; i++) {
-			assertTrue(hit[i] > 0);
-			cnt += hit[i];
-		}
-		assertTrue(cnt == numRecs);
-
-		// Test for StringValue
-		@SuppressWarnings("unchecked")
-		final RecordComparator stringComp = new RecordComparator(new int[] {0}, new Class[] {StringValue.class});
-		ChannelSelector<Record> oe2 = new RecordOutputEmitter(ShipStrategyType.PARTITION_HASH, stringComp);
-
-		numChans = 100;
-		numRecs = 10000;
-		
-		hit = new int[numChans];
-
-		for (int i = 0; i < numRecs; i++) {
-			StringValue k = new StringValue(i + "");
-			Record rec = new Record(k);
-				
-			int[] chans = oe2.selectChannels(rec, hit.length);
-			for(int j=0; j < chans.length; j++) {
-				hit[chans[j]]++;
-			}
-		}
-
-		cnt = 0;
-		for (int i = 0; i < hit.length; i++) {
-			assertTrue(hit[i] > 0);
-			cnt += hit[i];
-		}
-		assertTrue(cnt == numRecs);
-		
-	}
-	
-	@Test
-	public void testForward() {
-		// Test for IntValue
-		@SuppressWarnings("unchecked")
-		final RecordComparator intComp = new RecordComparator(new int[] {0}, new Class[] {IntValue.class});
-		final ChannelSelector<Record> oe1 = new RecordOutputEmitter(ShipStrategyType.FORWARD, intComp);
-
-		int numChannels = 100;
-		int numRecords = 50000;
-		
-		int[] hit = new int[numChannels];
-
-		for (int i = 0; i < numRecords; i++) {
-			IntValue k = new IntValue(i);
-			Record rec = new Record(k);
-			
-			int[] chans = oe1.selectChannels(rec, hit.length);
-			for(int j=0; j < chans.length; j++) {
-				hit[chans[j]]++;
-			}
-		}
-
-		int cnt = 0;
-		for (int i = 0; i < hit.length; i++) {
-			assertTrue(hit[i] == (numRecords/numChannels) || hit[i] == (numRecords/numChannels)-1);
-			cnt += hit[i];
-		}
-		assertTrue(cnt == numRecords);
-
-		// Test for StringValue
-		@SuppressWarnings("unchecked")
-		final RecordComparator stringComp = new RecordComparator(new int[] {0}, new Class[] {StringValue.class});
-		final ChannelSelector<Record> oe2 = new RecordOutputEmitter(ShipStrategyType.FORWARD, stringComp);
-
-		numChannels = 100;
-		numRecords = 10000;
-		
-		hit = new int[numChannels];
-
-		for (int i = 0; i < numRecords; i++) {
-			StringValue k = new StringValue(i + "");
-			Record rec = new Record(k);
-				
-			int[] chans = oe2.selectChannels(rec, hit.length);
-			for(int j=0; j < chans.length; j++) {
-				hit[chans[j]]++;
-			}
-		}
-
-		cnt = 0;
-		for (int i = 0; i < hit.length; i++) {
-			assertTrue(hit[i] == (numRecords/numChannels) || hit[i] == (numRecords/numChannels)-1);
-			cnt += hit[i];
-		}
-		assertTrue(cnt == numRecords);
-		
-	}
-	
-	@Test
-	public void testBroadcast() {
-		// Test for IntValue
-		@SuppressWarnings("unchecked")
-		final RecordComparator intComp = new RecordComparator(new int[] {0}, new Class[] {IntValue.class});
-		final ChannelSelector<Record> oe1 = new RecordOutputEmitter(ShipStrategyType.BROADCAST, intComp);
-
-		int numChannels = 100;
-		int numRecords = 50000;
-		
-		int[] hit = new int[numChannels];
-
-		for (int i = 0; i < numRecords; i++) {
-			IntValue k = new IntValue(i);
-			Record rec = new Record(k);
-			
-			int[] chans = oe1.selectChannels(rec, hit.length);
-			for(int j=0; j < chans.length; j++) {
-				hit[chans[j]]++;
-			}
-		}
-
-		for (int i = 0; i < hit.length; i++) {
-			assertTrue(hit[i]+"", hit[i] == numRecords);
-		}
-		
-		// Test for StringValue
-		@SuppressWarnings("unchecked")
-		final RecordComparator stringComp = new RecordComparator(new int[] {0}, new Class[] {StringValue.class});
-		final ChannelSelector<Record> oe2 = new RecordOutputEmitter(ShipStrategyType.BROADCAST, stringComp);
-
-		numChannels = 100;
-		numRecords = 5000;
-		
-		hit = new int[numChannels];
-
-		for (int i = 0; i < numRecords; i++) {
-			StringValue k = new StringValue(i + "");
-			Record rec = new Record(k);
-				
-			int[] chans = oe2.selectChannels(rec, hit.length);
-			for(int j=0; j < chans.length; j++) {
-				hit[chans[j]]++;
-			}
-		}
-
-		for (int i = 0; i < hit.length; i++) {
-			assertTrue(hit[i]+"", hit[i] == numRecords);
-		}
-	}
-	
-	@Test
-	public void testMultiKeys() {
-		@SuppressWarnings("unchecked")
-		final RecordComparator multiComp = new RecordComparator(new int[] {0,1,3}, new Class[] {IntValue.class, StringValue.class, DoubleValue.class});
-		final ChannelSelector<Record> oe1 = new RecordOutputEmitter(ShipStrategyType.PARTITION_HASH, multiComp);
-
-		int numChannels = 100;
-		int numRecords = 5000;
-		
-		int[] hit = new int[numChannels];
-
-		for (int i = 0; i < numRecords; i++) {
-			Record rec = new Record(4);
-			rec.setField(0, new IntValue(i));
-			rec.setField(1, new StringValue("AB"+i+"CD"+i));
-			rec.setField(3, new DoubleValue(i*3.141d));
-			
-			int[] chans = oe1.selectChannels(rec, hit.length);
-			for(int j=0; j < chans.length; j++) {
-				hit[chans[j]]++;
-			}
-		}
-
-		int cnt = 0;
-		for (int i = 0; i < hit.length; i++) {
-			assertTrue(hit[i] > 0);
-			cnt += hit[i];
-		}
-		assertTrue(cnt == numRecords);
-		
-	}
-	
-	@Test
-	public void testMissingKey() {
-		// Test for IntValue
-		@SuppressWarnings("unchecked")
-		final RecordComparator intComp = new RecordComparator(new int[] {1}, new Class[] {IntValue.class});
-		final ChannelSelector<Record> oe1 = new RecordOutputEmitter(ShipStrategyType.PARTITION_HASH, intComp);
-
-		Record rec = new Record(0);
-		rec.setField(0, new IntValue(1));
-		
-		try {
-			oe1.selectChannels(rec, 100);
-		} catch (KeyFieldOutOfBoundsException re) {
-			Assert.assertEquals(1, re.getFieldNumber());
-			return;
-		}
-		Assert.fail("Expected a KeyFieldOutOfBoundsException.");
-	}
-	
-	@Test
-	public void testNullKey() {
-		// Test for IntValue
-		@SuppressWarnings("unchecked")
-		final RecordComparator intComp = new RecordComparator(new int[] {0}, new Class[] {IntValue.class});
-		final ChannelSelector<Record> oe1 = new RecordOutputEmitter(ShipStrategyType.PARTITION_HASH, intComp);
-
-		Record rec = new Record(2);
-		rec.setField(1, new IntValue(1));
-
-		try {
-			oe1.selectChannels(rec, 100);
-		} catch (NullKeyFieldException re) {
-			Assert.assertEquals(0, re.getFieldNumber());
-			return;
-		}
-		Assert.fail("Expected a NullKeyFieldException.");
-	}
-	
-	@Test
-	public void testWrongKeyClass() {
-		
-		// Test for IntValue
-		@SuppressWarnings("unchecked")
-		final RecordComparator doubleComp = new RecordComparator(new int[] {0}, new Class[] {DoubleValue.class});
-		final ChannelSelector<Record> oe1 = new RecordOutputEmitter(ShipStrategyType.PARTITION_HASH, doubleComp);
-
-		PipedInputStream pipedInput = new PipedInputStream(1024*1024);
-		DataInputStream in = new DataInputStream(pipedInput);
-		DataOutputStream out;
-		Record rec = null;
-		
-		try {
-			out = new DataOutputStream(new PipedOutputStream(pipedInput));
-			
-			rec = new Record(1);
-			rec.setField(0, new IntValue());
-			
-			rec.write(new OutputViewDataOutputStreamWrapper(out));
-			rec = new Record();
-			rec.read(new InputViewDataInputStreamWrapper(in));
-		
-		} catch (IOException e) {
-			fail("Test erroneous");
-		}
-
-		try {
-			oe1.selectChannels(rec, 100);
-		} catch (DeserializationException re) {
-			return;
-		}
-		Assert.fail("Expected a NullKeyFieldException.");
-	}
-	
-	@Test
-	public void testPartitionRange() {
-		final Random rnd = new Random(SEED);
-		
-		final int DISTR_MIN = 0;
-		final int DISTR_MAX = 1000000;
-		final int DISTR_RANGE = DISTR_MAX - DISTR_MIN + 1;
-		final int NUM_BUCKETS = 137;
-		final double BUCKET_WIDTH = DISTR_RANGE / ((double) NUM_BUCKETS);
-		
-		final int NUM_ELEMENTS = 10000000;
-		
-		final DataDistribution distri = new UniformIntegerDistribution(DISTR_MIN, DISTR_MAX);
-		
-		@SuppressWarnings("unchecked")
-		final RecordComparator intComp = new RecordComparator(new int[] {0}, new Class[] {IntValue.class});
-		final ChannelSelector<Record> oe = new RecordOutputEmitter(ShipStrategyType.PARTITION_RANGE, intComp, distri);
-		
-		final IntValue integer = new IntValue();
-		final Record rec = new Record();
-		
-		for (int i = 0; i < NUM_ELEMENTS; i++) {
-			final int nextValue = rnd.nextInt(DISTR_RANGE) + DISTR_MIN;
-			integer.setValue(nextValue);
-			rec.setField(0, integer);
-			
-			final int[] channels = oe.selectChannels(rec, NUM_BUCKETS);
-			if (channels.length != 1) {
-				Assert.fail("Resulting channels array has more than one channel.");
-			}
-			
-			final int bucket = channels[0];
-			final int shouldBeBucket = (int) ((nextValue - DISTR_MIN) / BUCKET_WIDTH);
-			
-			if (shouldBeBucket != bucket) {
-				// we may have a rounding imprecision in the 'should be bucket' computation.
-				final int lowerBoundaryForSelectedBucket = DISTR_MIN + (int) ((bucket    ) * BUCKET_WIDTH);
-				final int upperBoundaryForSelectedBucket = DISTR_MIN + (int) ((bucket + 1) * BUCKET_WIDTH);
-				if (nextValue <= lowerBoundaryForSelectedBucket || nextValue > upperBoundaryForSelectedBucket) {
-					Assert.fail("Wrong bucket selected");
-				}
-			}
-			
-		}
-	}
-}
