diff --git a/docs/dev/table/connectors/formats/debezium.zh.md b/docs/dev/table/connectors/formats/debezium.zh.md
index 5623ab81cad..b3419123181 100644
--- a/docs/dev/table/connectors/formats/debezium.zh.md
+++ b/docs/dev/table/connectors/formats/debezium.zh.md
@@ -376,5 +376,5 @@ Flink 提供了 `debezium-avro-confluent` 和 `debezium-json` 两种 format 来
 数据类型映射
 ----------------
 
-目前，Debezium Format 使用 JSON Format 进行序列化和反序列化。有关数据类型映射的更多详细信息，请参考 [JSON Format 文档]({% link dev/table/connectors/formats/json.zh.md %}#data-type-mapping) 和 [Confluent Avro Format 文档]({% link dev/table/connectors/formats/avro-confluent.md %}#data-type-mapping)。
+目前，Debezium Format 使用 JSON Format 进行序列化和反序列化。有关数据类型映射的更多详细信息，请参考 [JSON Format 文档]({% link dev/table/connectors/formats/json.zh.md %}#data-type-mapping) 和 [Confluent Avro Format 文档]({% link dev/table/connectors/formats/avro-confluent.zh.md %}#data-type-mapping)。
 
diff --git a/docs/dev/table/connectors/formats/index.zh.md b/docs/dev/table/connectors/formats/index.zh.md
index d7ba24ada7f..19820e35551 100644
--- a/docs/dev/table/connectors/formats/index.zh.md
+++ b/docs/dev/table/connectors/formats/index.zh.md
@@ -74,7 +74,7 @@ Flink 支持以下格式：
         <tr>
         <td><a href="{% link dev/table/connectors/formats/raw.zh.md %}">Raw</a></td>
         <td><a href="{% link dev/table/connectors/kafka.zh.md %}">Apache Kafka</a>,
-          <a href="{% link dev/table/connectors/kinesis.md %}">Amazon Kinesis Data Streams</a>,
+          <a href="{% link dev/table/connectors/kinesis.zh.md %}">Amazon Kinesis Data Streams</a>,
           <a href="{% link dev/table/connectors/filesystem.zh.md %}">Filesystem</a></td>
         </tr>        
     </tbody>
diff --git a/docs/dev/table/sql/create.zh.md b/docs/dev/table/sql/create.zh.md
index 54b721a8066..a56998d677c 100644
--- a/docs/dev/table/sql/create.zh.md
+++ b/docs/dev/table/sql/create.zh.md
@@ -324,11 +324,11 @@ CREATE TABLE MyTable (
 The expression may contain any combination of columns, constants, or functions. The expression cannot
 contain a subquery.
 
-Computed columns are commonly used in Flink for defining [time attributes]({% link dev/table/streaming/time_attributes.md %})
+Computed columns are commonly used in Flink for defining [time attributes]({% link dev/table/streaming/time_attributes.zh.md %})
 in `CREATE TABLE` statements.
-- A [processing time attribute]({% link dev/table/streaming/time_attributes.md %}#processing-time)
+- A [processing time attribute]({% link dev/table/streaming/time_attributes.zh.md %}#processing-time)
 can be defined easily via `proc AS PROCTIME()` using the system's `PROCTIME()` function.
-- An [event time attribute]({% link dev/table/streaming/time_attributes.md %}#event-time) timestamp
+- An [event time attribute]({% link dev/table/streaming/time_attributes.zh.md %}#event-time) timestamp
 can be pre-processed before the `WATERMARK` declaration. For example, the computed column can be used
 if the original field is not `TIMESTAMP(3)` type or is nested in a JSON string.
 
