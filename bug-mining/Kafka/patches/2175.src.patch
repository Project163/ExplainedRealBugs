diff --git a/streams/src/main/java/org/apache/kafka/streams/kstream/internals/ForwardingCacheFlushListener.java b/streams/src/main/java/org/apache/kafka/streams/kstream/internals/ForwardingCacheFlushListener.java
index 57c5a1a7bb..6c6b8fd33b 100644
--- a/streams/src/main/java/org/apache/kafka/streams/kstream/internals/ForwardingCacheFlushListener.java
+++ b/streams/src/main/java/org/apache/kafka/streams/kstream/internals/ForwardingCacheFlushListener.java
@@ -39,7 +39,7 @@ class ForwardingCacheFlushListener<K, V> implements CacheFlushListener<K, V> {
         final ProcessorNode prev = context.currentNode();
         context.setCurrentNode(myNode);
         try {
-            context.forward(key, new Change<>(newValue, oldValue),  To.all().withTimestamp(timestamp));
+            context.forward(key, new Change<>(newValue, oldValue), To.all().withTimestamp(timestamp));
         } finally {
             context.setCurrentNode(prev);
         }
diff --git a/streams/src/main/java/org/apache/kafka/streams/state/TimestampedKeyValueStore.java b/streams/src/main/java/org/apache/kafka/streams/state/TimestampedKeyValueStore.java
new file mode 100644
index 0000000000..ef5ef57443
--- /dev/null
+++ b/streams/src/main/java/org/apache/kafka/streams/state/TimestampedKeyValueStore.java
@@ -0,0 +1,25 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.kafka.streams.state;
+
+/**
+ * A key-(value/timestamp) store that supports put/get/delete and range queries.
+ *
+ * @param <K> The key type
+ * @param <V> The value type
+ */
+public interface TimestampedKeyValueStore<K, V> extends KeyValueStore<K, ValueAndTimestamp<V>> { }
\ No newline at end of file
diff --git a/streams/src/main/java/org/apache/kafka/streams/state/ValueAndTimestamp.java b/streams/src/main/java/org/apache/kafka/streams/state/ValueAndTimestamp.java
new file mode 100644
index 0000000000..a0acc77483
--- /dev/null
+++ b/streams/src/main/java/org/apache/kafka/streams/state/ValueAndTimestamp.java
@@ -0,0 +1,74 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.kafka.streams.state;
+
+import org.apache.kafka.streams.KeyValue;
+
+import java.util.Objects;
+
+/**
+ * Combines a value from a {@link KeyValue} with a timestamp.
+ *
+ * @param <V>
+ */
+public class ValueAndTimestamp<V> {
+    private final V value;
+    private final long timestamp;
+
+    private ValueAndTimestamp(final V value,
+                              final long timestamp) {
+        Objects.requireNonNull(value);
+        this.value = value;
+        this.timestamp = timestamp;
+    }
+
+    public static <V> ValueAndTimestamp<V> make(final V value,
+                                                final long timestamp) {
+        return value == null ? null : new ValueAndTimestamp<>(value, timestamp);
+    }
+
+    public V value() {
+        return value;
+    }
+
+    public long timestamp() {
+        return timestamp;
+    }
+
+    @Override
+    public String toString() {
+        return "<" + value + "," + timestamp + ">";
+    }
+
+    @Override
+    public boolean equals(final Object o) {
+        if (this == o) {
+            return true;
+        }
+        if (o == null || getClass() != o.getClass()) {
+            return false;
+        }
+        final ValueAndTimestamp<?> that = (ValueAndTimestamp<?>) o;
+        return timestamp == that.timestamp &&
+            Objects.equals(value, that.value);
+    }
+
+    @Override
+    public int hashCode() {
+        return Objects.hash(value, timestamp);
+    }
+}
\ No newline at end of file
diff --git a/streams/src/main/java/org/apache/kafka/streams/state/internals/CachingKeyValueStore.java b/streams/src/main/java/org/apache/kafka/streams/state/internals/CachingKeyValueStore.java
index 9632385258..bb347de9d1 100644
--- a/streams/src/main/java/org/apache/kafka/streams/state/internals/CachingKeyValueStore.java
+++ b/streams/src/main/java/org/apache/kafka/streams/state/internals/CachingKeyValueStore.java
@@ -73,12 +73,12 @@ class CachingKeyValueStore
     private void putAndMaybeForward(final ThreadCache.DirtyEntry entry,
                                     final InternalProcessorContext context) {
         if (flushListener != null) {
-            final byte[] newValueBytes = entry.newValue();
-            final byte[] oldValueBytes = newValueBytes == null || sendOldValues ? wrapped().get(entry.key()) : null;
+            final byte[] rawNewValue = entry.newValue();
+            final byte[] rawOldValue = rawNewValue == null || sendOldValues ? wrapped().get(entry.key()) : null;
 
             // this is an optimization: if this key did not exist in underlying store and also not in the cache,
             // we can skip flushing to downstream as well as writing to underlying store
-            if (newValueBytes != null || oldValueBytes != null) {
+            if (rawNewValue != null || rawOldValue != null) {
                 // we need to get the old values if needed, and then put to store, and then flush
                 wrapped().put(entry.key(), entry.newValue());
 
@@ -87,8 +87,8 @@ class CachingKeyValueStore
                 try {
                     flushListener.apply(
                         entry.key().get(),
-                        newValueBytes,
-                        sendOldValues ? oldValueBytes : null,
+                        rawNewValue,
+                        sendOldValues ? rawOldValue : null,
                         entry.entry().context().timestamp());
                 } finally {
                     context.setRecordContext(current);
@@ -237,7 +237,8 @@ class CachingKeyValueStore
     @Override
     public KeyValueIterator<Bytes, byte[]> all() {
         validateStoreOpen();
-        final KeyValueIterator<Bytes, byte[]> storeIterator = new DelegatingPeekingKeyValueIterator<>(this.name(), wrapped().all());
+        final KeyValueIterator<Bytes, byte[]> storeIterator =
+            new DelegatingPeekingKeyValueIterator<>(this.name(), wrapped().all());
         final ThreadCache.MemoryLRUCacheBytesIterator cacheIterator = cache.all(cacheName);
         return new MergedSortedCacheKeyValueBytesStoreIterator(cacheIterator, storeIterator);
     }
diff --git a/streams/src/main/java/org/apache/kafka/streams/state/internals/CachingSessionStore.java b/streams/src/main/java/org/apache/kafka/streams/state/internals/CachingSessionStore.java
index 2fad28d3c2..edea7e0d4b 100644
--- a/streams/src/main/java/org/apache/kafka/streams/state/internals/CachingSessionStore.java
+++ b/streams/src/main/java/org/apache/kafka/streams/state/internals/CachingSessionStore.java
@@ -143,7 +143,8 @@ class CachingSessionStore
                                                                              key,
                                                                              earliestSessionEndTime,
                                                                              latestSessionStartTime);
-        final PeekingKeyValueIterator<Bytes, LRUCacheEntry> filteredCacheIterator = new FilteredCacheIterator(cacheIterator, hasNextCondition, cacheFunction);
+        final PeekingKeyValueIterator<Bytes, LRUCacheEntry> filteredCacheIterator =
+            new FilteredCacheIterator(cacheIterator, hasNextCondition, cacheFunction);
         return new MergedSortedCacheSessionStoreIterator(filteredCacheIterator, storeIterator, cacheFunction);
     }
 
@@ -165,7 +166,8 @@ class CachingSessionStore
                                                                              keyTo,
                                                                              earliestSessionEndTime,
                                                                              latestSessionStartTime);
-        final PeekingKeyValueIterator<Bytes, LRUCacheEntry> filteredCacheIterator = new FilteredCacheIterator(cacheIterator, hasNextCondition, cacheFunction);
+        final PeekingKeyValueIterator<Bytes, LRUCacheEntry> filteredCacheIterator =
+            new FilteredCacheIterator(cacheIterator, hasNextCondition, cacheFunction);
         return new MergedSortedCacheSessionStoreIterator(filteredCacheIterator, storeIterator, cacheFunction);
     }
 
@@ -194,7 +196,8 @@ class CachingSessionStore
     }
 
     @Override
-    public KeyValueIterator<Windowed<Bytes>, byte[]> fetch(final Bytes from, final Bytes to) {
+    public KeyValueIterator<Windowed<Bytes>, byte[]> fetch(final Bytes from,
+                                                           final Bytes to) {
         Objects.requireNonNull(from, "from cannot be null");
         Objects.requireNonNull(to, "to cannot be null");
         return findSessions(from, to, 0, Long.MAX_VALUE);
diff --git a/streams/src/main/java/org/apache/kafka/streams/state/internals/CachingWindowStore.java b/streams/src/main/java/org/apache/kafka/streams/state/internals/CachingWindowStore.java
index 6f8424b4b6..50a2c7c7ca 100644
--- a/streams/src/main/java/org/apache/kafka/streams/state/internals/CachingWindowStore.java
+++ b/streams/src/main/java/org/apache/kafka/streams/state/internals/CachingWindowStore.java
@@ -82,31 +82,32 @@ class CachingWindowStore
         final byte[] binaryWindowKey = cacheFunction.key(entry.key()).get();
         final Windowed<Bytes> windowedKeyBytes = WindowKeySchema.fromStoreBytesKey(binaryWindowKey, windowSize);
         final long windowStartTimestamp = windowedKeyBytes.window().start();
-        final Bytes key = windowedKeyBytes.key();
+        final Bytes binaryKey = windowedKeyBytes.key();
         if (flushListener != null) {
-            final byte[] newValueBytes = entry.newValue();
-            final byte[] oldValueBytes = newValueBytes == null || sendOldValues ? wrapped().fetch(key, windowStartTimestamp) : null;
+            final byte[] rawNewValue = entry.newValue();
+            final byte[] rawOldValue = rawNewValue == null || sendOldValues ?
+                wrapped().fetch(binaryKey, windowStartTimestamp) : null;
 
             // this is an optimization: if this key did not exist in underlying store and also not in the cache,
             // we can skip flushing to downstream as well as writing to underlying store
-            if (newValueBytes != null || oldValueBytes != null) {
+            if (rawNewValue != null || rawOldValue != null) {
                 // we need to get the old values if needed, and then put to store, and then flush
-                wrapped().put(key, entry.newValue(), windowStartTimestamp);
+                wrapped().put(binaryKey, entry.newValue(), windowStartTimestamp);
 
                 final ProcessorRecordContext current = context.recordContext();
                 context.setRecordContext(entry.entry().context());
                 try {
                     flushListener.apply(
                         binaryWindowKey,
-                        newValueBytes,
-                        sendOldValues ? oldValueBytes : null,
+                        rawNewValue,
+                        sendOldValues ? rawOldValue : null,
                         entry.entry().context().timestamp());
                 } finally {
                     context.setRecordContext(current);
                 }
             }
         } else {
-            wrapped().put(key, entry.newValue(), windowStartTimestamp);
+            wrapped().put(binaryKey, entry.newValue(), windowStartTimestamp);
         }
     }
 
diff --git a/streams/src/main/java/org/apache/kafka/streams/state/internals/ChangeLoggingKeyValueBytesStore.java b/streams/src/main/java/org/apache/kafka/streams/state/internals/ChangeLoggingKeyValueBytesStore.java
index f4fda6aef9..a924af600b 100644
--- a/streams/src/main/java/org/apache/kafka/streams/state/internals/ChangeLoggingKeyValueBytesStore.java
+++ b/streams/src/main/java/org/apache/kafka/streams/state/internals/ChangeLoggingKeyValueBytesStore.java
@@ -32,7 +32,7 @@ public class ChangeLoggingKeyValueBytesStore
     extends WrappedStateStore<KeyValueStore<Bytes, byte[]>, byte[], byte[]>
     implements KeyValueStore<Bytes, byte[]> {
 
-    private StoreChangeLogger<Bytes, byte[]> changeLogger;
+    StoreChangeLogger<Bytes, byte[]> changeLogger;
 
     ChangeLoggingKeyValueBytesStore(final KeyValueStore<Bytes, byte[]> inner) {
         super(inner);
@@ -43,13 +43,16 @@ public class ChangeLoggingKeyValueBytesStore
                      final StateStore root) {
         super.init(context, root);
         final String topic = ProcessorStateManager.storeChangelogTopic(context.applicationId(), name());
-        changeLogger = new StoreChangeLogger<>(name(), context, new StateSerdes<>(topic, Serdes.Bytes(), Serdes.ByteArray()));
+        changeLogger = new StoreChangeLogger<>(
+            name(),
+            context,
+            new StateSerdes<>(topic, Serdes.Bytes(), Serdes.ByteArray()));
 
         // if the inner store is an LRU cache, add the eviction listener to log removed record
         if (wrapped() instanceof MemoryLRUCache) {
             ((MemoryLRUCache) wrapped()).setWhenEldestRemoved((key, value) -> {
                 // pass null to indicate removal
-                changeLogger.logChange(key, null);
+                log(key, null);
             });
         }
     }
@@ -63,7 +66,7 @@ public class ChangeLoggingKeyValueBytesStore
     public void put(final Bytes key,
                     final byte[] value) {
         wrapped().put(key, value);
-        changeLogger.logChange(key, value);
+        log(key, value);
     }
 
     @Override
@@ -72,7 +75,7 @@ public class ChangeLoggingKeyValueBytesStore
         final byte[] previous = wrapped().putIfAbsent(key, value);
         if (previous == null) {
             // then it was absent
-            changeLogger.logChange(key, value);
+            log(key, value);
         }
         return previous;
     }
@@ -81,14 +84,14 @@ public class ChangeLoggingKeyValueBytesStore
     public void putAll(final List<KeyValue<Bytes, byte[]>> entries) {
         wrapped().putAll(entries);
         for (final KeyValue<Bytes, byte[]> entry : entries) {
-            changeLogger.logChange(entry.key, entry.value);
+            log(entry.key, entry.value);
         }
     }
 
     @Override
     public byte[] delete(final Bytes key) {
         final byte[] oldValue = wrapped().delete(key);
-        changeLogger.logChange(key, null);
+        log(key, null);
         return oldValue;
     }
 
@@ -107,4 +110,9 @@ public class ChangeLoggingKeyValueBytesStore
     public KeyValueIterator<Bytes, byte[]> all() {
         return wrapped().all();
     }
+
+    void log(final Bytes key,
+             final byte[] value) {
+        changeLogger.logChange(key, value);
+    }
 }
diff --git a/streams/src/main/java/org/apache/kafka/streams/state/internals/ChangeLoggingTimestampedKeyValueBytesStore.java b/streams/src/main/java/org/apache/kafka/streams/state/internals/ChangeLoggingTimestampedKeyValueBytesStore.java
new file mode 100644
index 0000000000..02568b6106
--- /dev/null
+++ b/streams/src/main/java/org/apache/kafka/streams/state/internals/ChangeLoggingTimestampedKeyValueBytesStore.java
@@ -0,0 +1,39 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.kafka.streams.state.internals;
+
+import org.apache.kafka.common.utils.Bytes;
+import org.apache.kafka.streams.state.KeyValueStore;
+
+import static org.apache.kafka.streams.state.internals.ValueAndTimestampDeserializer.rawValue;
+import static org.apache.kafka.streams.state.internals.ValueAndTimestampDeserializer.timestamp;
+
+public class ChangeLoggingTimestampedKeyValueBytesStore extends ChangeLoggingKeyValueBytesStore {
+    ChangeLoggingTimestampedKeyValueBytesStore(final KeyValueStore<Bytes, byte[]> inner) {
+        super(inner);
+    }
+
+    @Override
+    void log(final Bytes key,
+             final byte[] valueAndTimestamp) {
+        if (valueAndTimestamp != null) {
+            changeLogger.logChange(key, rawValue(valueAndTimestamp), timestamp(valueAndTimestamp));
+        } else {
+            changeLogger.logChange(key, null);
+        }
+    }
+}
\ No newline at end of file
diff --git a/streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStore.java b/streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStore.java
index c21568b6c5..51da3ed1bf 100644
--- a/streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStore.java
+++ b/streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStore.java
@@ -49,9 +49,9 @@ public class MeteredKeyValueStore<K, V>
     extends WrappedStateStore<KeyValueStore<Bytes, byte[]>, K, V>
     implements KeyValueStore<K, V> {
 
-    private final Serde<K> keySerde;
-    private final Serde<V> valueSerde;
-    private StateSerdes<K, V> serdes;
+    final Serde<K> keySerde;
+    final Serde<V> valueSerde;
+    StateSerdes<K, V> serdes;
 
     private final String metricScope;
     protected final Time time;
@@ -78,7 +78,6 @@ public class MeteredKeyValueStore<K, V>
         this.valueSerde = valueSerde;
     }
 
-    @SuppressWarnings("unchecked")
     @Override
     public void init(final ProcessorContext context,
                      final StateStore root) {
@@ -89,10 +88,7 @@ public class MeteredKeyValueStore<K, V>
         final Map<String, String> taskTags = metrics.tagMap("task-id", taskName, metricScope + "-id", "all");
         final Map<String, String> storeTags = metrics.tagMap("task-id", taskName, metricScope + "-id", name());
 
-        serdes = new StateSerdes<>(
-            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),
-            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,
-            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);
+        initStoreSerde(context);
 
         putTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, "put", metrics, metricsGroup, taskName, name(), taskTags, storeTags);
         putIfAbsentTime = createTaskAndStoreLatencyAndThroughputSensors(DEBUG, "put-if-absent", metrics, metricsGroup, taskName, name(), taskTags, storeTags);
@@ -117,6 +113,14 @@ public class MeteredKeyValueStore<K, V>
         }
     }
 
+    @SuppressWarnings("unchecked")
+    void initStoreSerde(final ProcessorContext context) {
+        serdes = new StateSerdes<>(
+            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),
+            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,
+            valueSerde == null ? (Serde<V>) context.valueSerde() : valueSerde);
+    }
+
     @SuppressWarnings("unchecked")
     @Override
     public boolean setFlushListener(final CacheFlushListener<K, V> listener,
@@ -124,10 +128,10 @@ public class MeteredKeyValueStore<K, V>
         final KeyValueStore<Bytes, byte[]> wrapped = wrapped();
         if (wrapped instanceof CachedStateStore) {
             return ((CachedStateStore<byte[], byte[]>) wrapped).setFlushListener(
-                (key, newValue, oldValue, timestamp) -> listener.apply(
-                    serdes.keyFrom(key),
-                    newValue != null ? serdes.valueFrom(newValue) : null,
-                    oldValue != null ? serdes.valueFrom(oldValue) : null,
+                (rawKey, rawNewValue, rawOldValue, timestamp) -> listener.apply(
+                    serdes.keyFrom(rawKey),
+                    rawNewValue != null ? serdes.valueFrom(rawNewValue) : null,
+                    rawOldValue != null ? serdes.valueFrom(rawOldValue) : null,
                     timestamp
                 ),
                 sendOldValues);
@@ -260,7 +264,7 @@ public class MeteredKeyValueStore<K, V>
     }
 
     private V outerValue(final byte[] value) {
-        return value == null ? null : serdes.valueFrom(value);
+        return value != null ? serdes.valueFrom(value) : null;
     }
 
     private Bytes keyBytes(final K key) {
@@ -298,7 +302,7 @@ public class MeteredKeyValueStore<K, V>
             final KeyValue<Bytes, byte[]> keyValue = iter.next();
             return KeyValue.pair(
                 serdes.keyFrom(keyValue.key.get()),
-                keyValue.value == null ? null : serdes.valueFrom(keyValue.value));
+                outerValue(keyValue.value));
         }
 
         @Override
diff --git a/streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredTimestampedKeyValueStore.java b/streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredTimestampedKeyValueStore.java
new file mode 100644
index 0000000000..2fa7c96633
--- /dev/null
+++ b/streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredTimestampedKeyValueStore.java
@@ -0,0 +1,56 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.kafka.streams.state.internals;
+
+import org.apache.kafka.common.serialization.Serde;
+import org.apache.kafka.common.utils.Bytes;
+import org.apache.kafka.common.utils.Time;
+import org.apache.kafka.streams.processor.ProcessorContext;
+import org.apache.kafka.streams.processor.internals.ProcessorStateManager;
+import org.apache.kafka.streams.state.KeyValueStore;
+import org.apache.kafka.streams.state.StateSerdes;
+import org.apache.kafka.streams.state.TimestampedKeyValueStore;
+import org.apache.kafka.streams.state.ValueAndTimestamp;
+
+/**
+ * A Metered {@link TimestampedKeyValueStore} wrapper that is used for recording operation metrics, and hence its
+ * inner KeyValueStore implementation do not need to provide its own metrics collecting functionality.
+ * The inner {@link KeyValueStore} of this class is of type &lt;Bytes,byte[]&gt;, hence we use {@link Serde}s
+ * to convert from &lt;K,ValueAndTimestamp&lt;V&gt&gt; to &lt;Bytes,byte[]&gt;
+ * @param <K>
+ * @param <V>
+ */
+public class MeteredTimestampedKeyValueStore<K, V>
+    extends MeteredKeyValueStore<K, ValueAndTimestamp<V>>
+    implements TimestampedKeyValueStore<K, V> {
+
+    MeteredTimestampedKeyValueStore(final KeyValueStore<Bytes, byte[]> inner,
+                                    final String metricScope,
+                                    final Time time,
+                                    final Serde<K> keySerde,
+                                    final Serde<ValueAndTimestamp<V>> valueSerde) {
+        super(inner, metricScope, time, keySerde, valueSerde);
+    }
+
+    @SuppressWarnings("unchecked")
+    void initStoreSerde(final ProcessorContext context) {
+        serdes = new StateSerdes<>(
+            ProcessorStateManager.storeChangelogTopic(context.applicationId(), name()),
+            keySerde == null ? (Serde<K>) context.keySerde() : keySerde,
+            valueSerde == null ? new ValueAndTimestampSerde<>((Serde<V>) context.keySerde()) : valueSerde);
+    }
+}
\ No newline at end of file
diff --git a/streams/src/main/java/org/apache/kafka/streams/state/internals/StoreChangeLogger.java b/streams/src/main/java/org/apache/kafka/streams/state/internals/StoreChangeLogger.java
index 74134d63bb..ada243d8ab 100644
--- a/streams/src/main/java/org/apache/kafka/streams/state/internals/StoreChangeLogger.java
+++ b/streams/src/main/java/org/apache/kafka/streams/state/internals/StoreChangeLogger.java
@@ -32,12 +32,12 @@ import org.apache.kafka.streams.state.StateSerdes;
  */
 class StoreChangeLogger<K, V> {
 
-    protected final StateSerdes<K, V> serialization;
-
     private final String topic;
     private final int partition;
     private final ProcessorContext context;
     private final RecordCollector collector;
+    private final Serializer<K> keySerializer;
+    private final Serializer<V> valueSerializer;
 
     StoreChangeLogger(final String storeName,
                       final ProcessorContext context,
@@ -49,20 +49,23 @@ class StoreChangeLogger<K, V> {
                               final ProcessorContext context,
                               final int partition,
                               final StateSerdes<K, V> serialization) {
-        this.topic = ProcessorStateManager.storeChangelogTopic(context.applicationId(), storeName);
+        topic = ProcessorStateManager.storeChangelogTopic(context.applicationId(), storeName);
         this.context = context;
         this.partition = partition;
-        this.serialization = serialization;
         this.collector = ((RecordCollector.Supplier) context).recordCollector();
+        keySerializer = serialization.keySerializer();
+        valueSerializer = serialization.valueSerializer();
     }
 
     void logChange(final K key,
                    final V value) {
-        if (collector != null) {
-            final Serializer<K> keySerializer = serialization.keySerializer();
-            final Serializer<V> valueSerializer = serialization.valueSerializer();
-            // Sending null headers to changelog topics (KIP-244)
-            collector.send(this.topic, key, value, null, this.partition, context.timestamp(), keySerializer, valueSerializer);
-        }
+        logChange(key, value, context.timestamp());
+    }
+
+    void logChange(final K key,
+                   final V value,
+                   final long timestamp) {
+        // Sending null headers to changelog topics (KIP-244)
+        collector.send(topic, key, value, null, partition, timestamp, keySerializer, valueSerializer);
     }
 }
diff --git a/streams/src/main/java/org/apache/kafka/streams/state/internals/TimestampedKeyValueStoreBuilder.java b/streams/src/main/java/org/apache/kafka/streams/state/internals/TimestampedKeyValueStoreBuilder.java
new file mode 100644
index 0000000000..5a0bf22e99
--- /dev/null
+++ b/streams/src/main/java/org/apache/kafka/streams/state/internals/TimestampedKeyValueStoreBuilder.java
@@ -0,0 +1,70 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.kafka.streams.state.internals;
+
+import org.apache.kafka.common.serialization.Serde;
+import org.apache.kafka.common.utils.Bytes;
+import org.apache.kafka.common.utils.Time;
+import org.apache.kafka.streams.state.KeyValueBytesStoreSupplier;
+import org.apache.kafka.streams.state.KeyValueStore;
+import org.apache.kafka.streams.state.TimestampedKeyValueStore;
+import org.apache.kafka.streams.state.ValueAndTimestamp;
+
+import java.util.Objects;
+
+public class TimestampedKeyValueStoreBuilder<K, V>
+    extends AbstractStoreBuilder<K, ValueAndTimestamp<V>, TimestampedKeyValueStore<K, V>> {
+
+    private final KeyValueBytesStoreSupplier storeSupplier;
+
+    public TimestampedKeyValueStoreBuilder(final KeyValueBytesStoreSupplier storeSupplier,
+                                           final Serde<K> keySerde,
+                                           final Serde<V> valueSerde,
+                                           final Time time) {
+        super(
+            storeSupplier.name(),
+            keySerde,
+            valueSerde == null ? null : new ValueAndTimestampSerde<>(valueSerde),
+            time);
+        Objects.requireNonNull(storeSupplier, "bytesStoreSupplier can't be null");
+        this.storeSupplier = storeSupplier;
+    }
+
+    @Override
+    public TimestampedKeyValueStore<K, V> build() {
+        return new MeteredTimestampedKeyValueStore<>(
+            maybeWrapCaching(maybeWrapLogging(storeSupplier.get())),
+            storeSupplier.metricsScope(),
+            time,
+            keySerde,
+            valueSerde);
+    }
+
+    private KeyValueStore<Bytes, byte[]> maybeWrapCaching(final KeyValueStore<Bytes, byte[]> inner) {
+        if (!enableCaching) {
+            return inner;
+        }
+        return new CachingKeyValueStore(inner);
+    }
+
+    private KeyValueStore<Bytes, byte[]> maybeWrapLogging(final KeyValueStore<Bytes, byte[]> inner) {
+        if (!enableLogging) {
+            return inner;
+        }
+        return new ChangeLoggingTimestampedKeyValueBytesStore(inner);
+    }
+}
\ No newline at end of file
diff --git a/streams/src/main/java/org/apache/kafka/streams/state/internals/ValueAndTimestampDeserializer.java b/streams/src/main/java/org/apache/kafka/streams/state/internals/ValueAndTimestampDeserializer.java
new file mode 100644
index 0000000000..7cd37d2121
--- /dev/null
+++ b/streams/src/main/java/org/apache/kafka/streams/state/internals/ValueAndTimestampDeserializer.java
@@ -0,0 +1,84 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.kafka.streams.state.internals;
+
+import org.apache.kafka.common.serialization.Deserializer;
+import org.apache.kafka.common.serialization.LongDeserializer;
+import org.apache.kafka.streams.state.ValueAndTimestamp;
+
+import java.nio.ByteBuffer;
+import java.util.Map;
+import java.util.Objects;
+
+class ValueAndTimestampDeserializer<V> implements Deserializer<ValueAndTimestamp<V>> {
+    private final static LongDeserializer LONG_DESERIALIZER = new LongDeserializer();
+
+    public final Deserializer<V> valueDeserializer;
+    private final Deserializer<Long> timestampDeserializer;
+
+    ValueAndTimestampDeserializer(final Deserializer<V> valueDeserializer) {
+        Objects.requireNonNull(valueDeserializer);
+        this.valueDeserializer = valueDeserializer;
+        timestampDeserializer = new LongDeserializer();
+    }
+
+    @Override
+    public void configure(final Map<String, ?> configs,
+                          final boolean isKey) {
+        valueDeserializer.configure(configs, isKey);
+        timestampDeserializer.configure(configs, isKey);
+    }
+
+    @Override
+    public ValueAndTimestamp<V> deserialize(final String topic,
+                                            final byte[] valueAndTimestamp) {
+        if (valueAndTimestamp == null) {
+            return null;
+        }
+
+        final long timestamp = timestampDeserializer.deserialize(topic, rawTimestamp(valueAndTimestamp));
+        final V value = valueDeserializer.deserialize(topic, rawValue(valueAndTimestamp));
+        return ValueAndTimestamp.make(value, timestamp);
+    }
+
+    @Override
+    public void close() {
+        valueDeserializer.close();
+        timestampDeserializer.close();
+    }
+
+    static byte[] rawValue(final byte[] rawValueAndTimestamp) {
+        final int rawValueLength = rawValueAndTimestamp.length - 8;
+
+        return ByteBuffer
+            .allocate(rawValueLength)
+            .put(rawValueAndTimestamp, 8, rawValueLength)
+            .array();
+    }
+
+    private static byte[] rawTimestamp(final byte[] rawValueAndTimestamp) {
+        return ByteBuffer
+            .allocate(8)
+            .put(rawValueAndTimestamp, 0, 8)
+            .array();
+    }
+
+    static long timestamp(final byte[] rawValueAndTimestamp) {
+        return LONG_DESERIALIZER.deserialize(null, rawTimestamp(rawValueAndTimestamp));
+    }
+
+}
\ No newline at end of file
diff --git a/streams/src/main/java/org/apache/kafka/streams/state/internals/ValueAndTimestampSerde.java b/streams/src/main/java/org/apache/kafka/streams/state/internals/ValueAndTimestampSerde.java
new file mode 100644
index 0000000000..8be11f3289
--- /dev/null
+++ b/streams/src/main/java/org/apache/kafka/streams/state/internals/ValueAndTimestampSerde.java
@@ -0,0 +1,59 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.kafka.streams.state.internals;
+
+import org.apache.kafka.common.serialization.Deserializer;
+import org.apache.kafka.common.serialization.Serde;
+import org.apache.kafka.common.serialization.Serializer;
+import org.apache.kafka.streams.state.ValueAndTimestamp;
+
+import java.util.Map;
+import java.util.Objects;
+
+public class ValueAndTimestampSerde<V> implements Serde<ValueAndTimestamp<V>> {
+    private final ValueAndTimestampSerializer<V> valueAndTimestampSerializer;
+    private final ValueAndTimestampDeserializer<V> valueAndTimestampDeserializer;
+
+    ValueAndTimestampSerde(final Serde<V> valueSerde) {
+        Objects.requireNonNull(valueSerde);
+        valueAndTimestampSerializer = new ValueAndTimestampSerializer<>(valueSerde.serializer());
+        valueAndTimestampDeserializer = new ValueAndTimestampDeserializer<>(valueSerde.deserializer());
+    }
+
+    @Override
+    public void configure(final Map<String, ?> configs,
+                          final boolean isKey) {
+        valueAndTimestampSerializer.configure(configs, isKey);
+        valueAndTimestampDeserializer.configure(configs, isKey);
+    }
+
+    @Override
+    public void close() {
+        valueAndTimestampSerializer.close();
+        valueAndTimestampDeserializer.close();
+    }
+
+    @Override
+    public Serializer<ValueAndTimestamp<V>> serializer() {
+        return valueAndTimestampSerializer;
+    }
+
+    @Override
+    public Deserializer<ValueAndTimestamp<V>> deserializer() {
+        return valueAndTimestampDeserializer;
+    }
+}
\ No newline at end of file
diff --git a/streams/src/main/java/org/apache/kafka/streams/state/internals/ValueAndTimestampSerializer.java b/streams/src/main/java/org/apache/kafka/streams/state/internals/ValueAndTimestampSerializer.java
new file mode 100644
index 0000000000..17903952dd
--- /dev/null
+++ b/streams/src/main/java/org/apache/kafka/streams/state/internals/ValueAndTimestampSerializer.java
@@ -0,0 +1,73 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.kafka.streams.state.internals;
+
+import org.apache.kafka.common.serialization.LongSerializer;
+import org.apache.kafka.common.serialization.Serializer;
+import org.apache.kafka.streams.state.ValueAndTimestamp;
+
+import java.nio.ByteBuffer;
+import java.util.Map;
+import java.util.Objects;
+
+class ValueAndTimestampSerializer<V> implements Serializer<ValueAndTimestamp<V>> {
+    public final Serializer<V> valueSerializer;
+    private final Serializer<Long> timestampSerializer;
+
+    ValueAndTimestampSerializer(final Serializer<V> valueSerializer) {
+        Objects.requireNonNull(valueSerializer);
+        this.valueSerializer = valueSerializer;
+        timestampSerializer = new LongSerializer();
+    }
+
+    @Override
+    public void configure(final Map<String, ?> configs,
+                          final boolean isKey) {
+        valueSerializer.configure(configs, isKey);
+        timestampSerializer.configure(configs, isKey);
+    }
+
+    @Override
+    public byte[] serialize(final String topic,
+                            final ValueAndTimestamp<V> data) {
+        if (data == null) {
+            return null;
+        }
+        return serialize(topic, data.value(), data.timestamp());
+    }
+
+    public byte[] serialize(final String topic,
+                            final V data,
+                            final long timestamp) {
+        if (data == null) {
+            return null;
+        }
+        final byte[] rawValue = valueSerializer.serialize(topic, data);
+        final byte[] rawTimestamp = timestampSerializer.serialize(topic, timestamp);
+        return ByteBuffer
+            .allocate(rawTimestamp.length + rawValue.length)
+            .put(rawTimestamp)
+            .put(rawValue)
+            .array();
+    }
+
+    @Override
+    public void close() {
+        valueSerializer.close();
+        timestampSerializer.close();
+    }
+}
\ No newline at end of file
diff --git a/streams/src/test/java/org/apache/kafka/streams/state/internals/CachingKeyValueStoreTest.java b/streams/src/test/java/org/apache/kafka/streams/state/internals/CachingKeyValueStoreTest.java
index d0a501f24b..71e15d46d9 100644
--- a/streams/src/test/java/org/apache/kafka/streams/state/internals/CachingKeyValueStoreTest.java
+++ b/streams/src/test/java/org/apache/kafka/streams/state/internals/CachingKeyValueStoreTest.java
@@ -359,7 +359,7 @@ public class CachingKeyValueStoreTest extends AbstractKeyValueStoreTest {
 
     @Test
     public void shouldReturnUnderlying() {
-        assertEquals(store.wrapped(), underlyingStore);
+        assertEquals(underlyingStore, store.wrapped());
     }
 
     @Test(expected = InvalidStateStoreException.class)
diff --git a/streams/src/test/java/org/apache/kafka/streams/state/internals/CachingSessionStoreTest.java b/streams/src/test/java/org/apache/kafka/streams/state/internals/CachingSessionStoreTest.java
index a6b169fad4..66b27f0a25 100644
--- a/streams/src/test/java/org/apache/kafka/streams/state/internals/CachingSessionStoreTest.java
+++ b/streams/src/test/java/org/apache/kafka/streams/state/internals/CachingSessionStoreTest.java
@@ -74,8 +74,9 @@ public class CachingSessionStoreTest {
     @Before
     public void setUp() {
         final SessionKeySchema schema = new SessionKeySchema();
-        final RocksDBSegmentedBytesStore underlying = new RocksDBSegmentedBytesStore("test", "metrics-scope", 0L, SEGMENT_INTERVAL, schema);
-        final RocksDBSessionStore sessionStore = new RocksDBSessionStore(underlying);
+        final RocksDBSegmentedBytesStore root =
+            new RocksDBSegmentedBytesStore("test", "metrics-scope", 0L, SEGMENT_INTERVAL, schema);
+        final RocksDBSessionStore sessionStore = new RocksDBSessionStore(root);
         cachingStore = new CachingSessionStore(sessionStore, SEGMENT_INTERVAL);
         cache = new ThreadCache(new LogContext("testCache "), MAX_CACHE_SIZE_BYTES, new MockStreamsMetrics(new Metrics()));
         final InternalMockProcessorContext context = new InternalMockProcessorContext(TestUtils.tempDirectory(), null, null, null, cache);
@@ -105,7 +106,6 @@ public class CachingSessionStoreTest {
         assertFalse(b.hasNext());
     }
 
-
     @Test
     public void shouldPutFetchAllKeysFromCache() {
         cachingStore.put(new Windowed<>(keyA, new SessionWindow(0, 0)), "1".getBytes());
diff --git a/streams/src/test/java/org/apache/kafka/streams/state/internals/ChangeLoggingKeyValueBytesStoreTest.java b/streams/src/test/java/org/apache/kafka/streams/state/internals/ChangeLoggingKeyValueBytesStoreTest.java
index 5645b8bc84..11f7c4c76d 100644
--- a/streams/src/test/java/org/apache/kafka/streams/state/internals/ChangeLoggingKeyValueBytesStoreTest.java
+++ b/streams/src/test/java/org/apache/kafka/streams/state/internals/ChangeLoggingKeyValueBytesStoreTest.java
@@ -42,7 +42,6 @@ import static org.hamcrest.MatcherAssert.assertThat;
 
 public class ChangeLoggingKeyValueBytesStoreTest {
 
-    private InternalMockProcessorContext context;
     private final InMemoryKeyValueStore inner = new InMemoryKeyValueStore("kv");
     private final ChangeLoggingKeyValueBytesStore store = new ChangeLoggingKeyValueBytesStore(inner);
     private final Map<Object, Object> sent = new HashMap<>();
@@ -66,7 +65,7 @@ public class ChangeLoggingKeyValueBytesStoreTest {
                 sent.put(key, value);
             }
         };
-        context = new InternalMockProcessorContext(
+        final InternalMockProcessorContext context = new InternalMockProcessorContext(
             TestUtils.tempDirectory(),
             Serdes.String(),
             Serdes.Long(),
@@ -90,7 +89,7 @@ public class ChangeLoggingKeyValueBytesStoreTest {
     @Test
     public void shouldLogChangeOnPut() {
         store.put(hi, there);
-        assertThat((byte[]) sent.get(hi), equalTo(there));
+        assertThat(sent.get(hi), equalTo(there));
     }
 
     @Test
@@ -105,8 +104,8 @@ public class ChangeLoggingKeyValueBytesStoreTest {
     public void shouldLogChangesOnPutAll() {
         store.putAll(Arrays.asList(KeyValue.pair(hi, there),
                                    KeyValue.pair(hello, world)));
-        assertThat((byte[]) sent.get(hi), equalTo(there));
-        assertThat((byte[]) sent.get(hello), equalTo(world));
+        assertThat(sent.get(hi), equalTo(there));
+        assertThat(sent.get(hello), equalTo(world));
     }
 
     @Test
@@ -147,14 +146,14 @@ public class ChangeLoggingKeyValueBytesStoreTest {
     @Test
     public void shouldWriteToChangelogOnPutIfAbsentWhenNoPreviousValue() {
         store.putIfAbsent(hi, there);
-        assertThat((byte[]) sent.get(hi), equalTo(there));
+        assertThat(sent.get(hi), equalTo(there));
     }
 
     @Test
     public void shouldNotWriteToChangeLogOnPutIfAbsentWhenValueForKeyExists() {
         store.put(hi, there);
         store.putIfAbsent(hi, world);
-        assertThat((byte[]) sent.get(hi), equalTo(there));
+        assertThat(sent.get(hi), equalTo(there));
     }
 
     @Test
diff --git a/streams/src/test/java/org/apache/kafka/streams/state/internals/ChangeLoggingTimestampedKeyValueBytesStoreTest.java b/streams/src/test/java/org/apache/kafka/streams/state/internals/ChangeLoggingTimestampedKeyValueBytesStoreTest.java
new file mode 100644
index 0000000000..2c19c48aa2
--- /dev/null
+++ b/streams/src/test/java/org/apache/kafka/streams/state/internals/ChangeLoggingTimestampedKeyValueBytesStoreTest.java
@@ -0,0 +1,195 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.kafka.streams.state.internals;
+
+import org.apache.kafka.common.header.Headers;
+import org.apache.kafka.common.metrics.Metrics;
+import org.apache.kafka.common.serialization.Serdes;
+import org.apache.kafka.common.serialization.Serializer;
+import org.apache.kafka.common.utils.Bytes;
+import org.apache.kafka.common.utils.LogContext;
+import org.apache.kafka.streams.KeyValue;
+import org.apache.kafka.streams.processor.internals.MockStreamsMetrics;
+import org.apache.kafka.streams.state.ValueAndTimestamp;
+import org.apache.kafka.test.InternalMockProcessorContext;
+import org.apache.kafka.test.NoOpRecordCollector;
+import org.apache.kafka.test.TestUtils;
+import org.junit.After;
+import org.junit.Before;
+import org.junit.Test;
+
+import java.util.Arrays;
+import java.util.HashMap;
+import java.util.Map;
+
+import static org.hamcrest.CoreMatchers.equalTo;
+import static org.hamcrest.CoreMatchers.is;
+import static org.hamcrest.CoreMatchers.nullValue;
+import static org.hamcrest.MatcherAssert.assertThat;
+
+public class ChangeLoggingTimestampedKeyValueBytesStoreTest {
+
+    private final InMemoryKeyValueStore root = new InMemoryKeyValueStore("kv");
+    private final ChangeLoggingTimestampedKeyValueBytesStore store = new ChangeLoggingTimestampedKeyValueBytesStore(root);
+    private final Map<Object, ValueAndTimestamp<byte[]>> sent = new HashMap<>();
+    private final Bytes hi = Bytes.wrap("hi".getBytes());
+    private final Bytes hello = Bytes.wrap("hello".getBytes());
+    private final ValueAndTimestamp<byte[]> there = ValueAndTimestamp.make("there".getBytes(), 97L);
+    // timestamp is 97 what is ASCII of 'a'
+    private final byte[] rawThere = "\0\0\0\0\0\0\0athere".getBytes();
+    private final ValueAndTimestamp<byte[]> world = ValueAndTimestamp.make("world".getBytes(), 98L);
+    // timestamp is 98 what is ASCII of 'b'
+    private final byte[] rawWorld = "\0\0\0\0\0\0\0bworld".getBytes();
+
+    @Before
+    public void before() {
+        final NoOpRecordCollector collector = new NoOpRecordCollector() {
+            @Override
+            public <K, V> void send(final String topic,
+                                    final K key,
+                                    final V value,
+                                    final Headers headers,
+                                    final Integer partition,
+                                    final Long timestamp,
+                                    final Serializer<K> keySerializer,
+                                    final Serializer<V> valueSerializer) {
+                sent.put(key, ValueAndTimestamp.make((byte[]) value, timestamp));
+            }
+        };
+        final InternalMockProcessorContext context = new InternalMockProcessorContext(
+            TestUtils.tempDirectory(),
+            Serdes.String(),
+            Serdes.Long(),
+            collector,
+            new ThreadCache(new LogContext("testCache "), 0, new MockStreamsMetrics(new Metrics())));
+        context.setTime(0);
+        store.init(context, store);
+    }
+
+    @After
+    public void after() {
+        store.close();
+    }
+
+    @Test
+    public void shouldWriteKeyValueBytesToInnerStoreOnPut() {
+        store.put(hi, rawThere);
+        assertThat(root.get(hi), equalTo(rawThere));
+    }
+
+    @Test
+    public void shouldLogChangeOnPut() {
+        store.put(hi, rawThere);
+        final ValueAndTimestamp<byte[]> logged = sent.get(hi);
+        assertThat(logged.value(), equalTo(there.value()));
+        assertThat(logged.timestamp(), equalTo(there.timestamp()));
+    }
+
+    @Test
+    public void shouldWriteAllKeyValueToInnerStoreOnPutAll() {
+        store.putAll(Arrays.asList(KeyValue.pair(hi, rawThere),
+                                   KeyValue.pair(hello, rawWorld)));
+        assertThat(root.get(hi), equalTo(rawThere));
+        assertThat(root.get(hello), equalTo(rawWorld));
+    }
+
+    @Test
+    public void shouldLogChangesOnPutAll() {
+        store.putAll(Arrays.asList(KeyValue.pair(hi, rawThere),
+                                   KeyValue.pair(hello, rawWorld)));
+        final ValueAndTimestamp<byte[]> logged = sent.get(hi);
+        assertThat(logged.value(), equalTo(there.value()));
+        assertThat(logged.timestamp(), equalTo(there.timestamp()));
+        final ValueAndTimestamp<byte[]> logged2 = sent.get(hello);
+        assertThat(logged2.value(), equalTo(world.value()));
+        assertThat(logged2.timestamp(), equalTo(world.timestamp()));
+    }
+
+    @Test
+    public void shouldPropagateDelete() {
+        store.put(hi, rawThere);
+        store.delete(hi);
+        assertThat(root.approximateNumEntries(), equalTo(0L));
+        assertThat(root.get(hi), nullValue());
+    }
+
+    @Test
+    public void shouldReturnOldValueOnDelete() {
+        store.put(hi, rawThere);
+        assertThat(store.delete(hi), equalTo(rawThere));
+    }
+
+    @Test
+    public void shouldLogKeyNullOnDelete() {
+        store.put(hi, rawThere);
+        store.delete(hi);
+        assertThat(sent.containsKey(hi), is(true));
+        assertThat(sent.get(hi), nullValue());
+    }
+
+    @Test
+    public void shouldWriteToInnerOnPutIfAbsentNoPreviousValue() {
+        store.putIfAbsent(hi, rawThere);
+        assertThat(root.get(hi), equalTo(rawThere));
+    }
+
+    @Test
+    public void shouldNotWriteToInnerOnPutIfAbsentWhenValueForKeyExists() {
+        store.put(hi, rawThere);
+        store.putIfAbsent(hi, rawWorld);
+        assertThat(root.get(hi), equalTo(rawThere));
+    }
+
+    @Test
+    public void shouldWriteToChangelogOnPutIfAbsentWhenNoPreviousValue() {
+        store.putIfAbsent(hi, rawThere);
+        final ValueAndTimestamp<byte[]> logged = sent.get(hi);
+        assertThat(logged.value(), equalTo(there.value()));
+        assertThat(logged.timestamp(), equalTo(there.timestamp()));
+    }
+
+    @Test
+    public void shouldNotWriteToChangeLogOnPutIfAbsentWhenValueForKeyExists() {
+        store.put(hi, rawThere);
+        store.putIfAbsent(hi, rawWorld);
+        final ValueAndTimestamp<byte[]> logged = sent.get(hi);
+        assertThat(logged.value(), equalTo(there.value()));
+        assertThat(logged.timestamp(), equalTo(there.timestamp()));
+    }
+
+    @Test
+    public void shouldReturnCurrentValueOnPutIfAbsent() {
+        store.put(hi, rawThere);
+        assertThat(store.putIfAbsent(hi, rawWorld), equalTo(rawThere));
+    }
+
+    @Test
+    public void shouldReturnNullOnPutIfAbsentWhenNoPreviousValue() {
+        assertThat(store.putIfAbsent(hi, rawThere), is(nullValue()));
+    }
+
+    @Test
+    public void shouldReturnValueOnGetWhenExists() {
+        store.put(hello, rawWorld);
+        assertThat(store.get(hello), equalTo(rawWorld));
+    }
+
+    @Test
+    public void shouldReturnNullOnGetWhenDoesntExist() {
+        assertThat(store.get(hello), is(nullValue()));
+    }
+}
diff --git a/streams/src/test/java/org/apache/kafka/streams/state/internals/KeyValueStoreBuilderTest.java b/streams/src/test/java/org/apache/kafka/streams/state/internals/KeyValueStoreBuilderTest.java
index 8642cfac90..1f4384a8c7 100644
--- a/streams/src/test/java/org/apache/kafka/streams/state/internals/KeyValueStoreBuilderTest.java
+++ b/streams/src/test/java/org/apache/kafka/streams/state/internals/KeyValueStoreBuilderTest.java
@@ -51,12 +51,12 @@ public class KeyValueStoreBuilderTest {
         EasyMock.expect(supplier.get()).andReturn(inner);
         EasyMock.expect(supplier.name()).andReturn("name");
         EasyMock.replay(supplier);
-        builder = new KeyValueStoreBuilder<>(supplier,
-                                             Serdes.String(),
-                                             Serdes.String(),
-                                             new MockTime()
+        builder = new KeyValueStoreBuilder<>(
+            supplier,
+            Serdes.String(),
+            Serdes.String(),
+            new MockTime()
         );
-
     }
 
     @Test
diff --git a/streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStoreTest.java b/streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStoreTest.java
index f4d3d76566..b8fc88e62f 100644
--- a/streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStoreTest.java
+++ b/streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStoreTest.java
@@ -14,7 +14,6 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-
 package org.apache.kafka.streams.state.internals;
 
 import org.apache.kafka.common.MetricName;
@@ -32,7 +31,6 @@ import org.apache.kafka.streams.processor.internals.MockStreamsMetrics;
 import org.apache.kafka.streams.state.KeyValueIterator;
 import org.apache.kafka.streams.state.KeyValueStore;
 import org.apache.kafka.test.KeyValueIteratorStub;
-import org.easymock.EasyMock;
 import org.easymock.EasyMockRunner;
 import org.easymock.Mock;
 import org.easymock.MockType;
@@ -47,8 +45,10 @@ import java.util.Map;
 import static org.apache.kafka.common.utils.Utils.mkEntry;
 import static org.apache.kafka.common.utils.Utils.mkMap;
 import static org.easymock.EasyMock.anyObject;
+import static org.easymock.EasyMock.aryEq;
 import static org.easymock.EasyMock.eq;
 import static org.easymock.EasyMock.expect;
+import static org.easymock.EasyMock.expectLastCall;
 import static org.easymock.EasyMock.mock;
 import static org.easymock.EasyMock.replay;
 import static org.easymock.EasyMock.verify;
@@ -76,6 +76,7 @@ public class MeteredKeyValueStoreTest {
     private final Bytes keyBytes = Bytes.wrap(key.getBytes());
     private final String value = "value";
     private final byte[] valueBytes = value.getBytes();
+    private final KeyValue<Bytes, byte[]> byteKeyValuePair = KeyValue.pair(keyBytes, valueBytes);
     private final Metrics metrics = new Metrics();
 
     @Before
@@ -88,13 +89,13 @@ public class MeteredKeyValueStoreTest {
             Serdes.String()
         );
         metrics.config().recordLevel(Sensor.RecordingLevel.DEBUG);
-        EasyMock.expect(context.metrics()).andReturn(new MockStreamsMetrics(metrics));
-        EasyMock.expect(context.taskId()).andReturn(taskId);
-        EasyMock.expect(inner.name()).andReturn("metered").anyTimes();
+        expect(context.metrics()).andReturn(new MockStreamsMetrics(metrics));
+        expect(context.taskId()).andReturn(taskId);
+        expect(inner.name()).andReturn("metered").anyTimes();
     }
 
     private void init() {
-        EasyMock.replay(inner, context);
+        replay(inner, context);
         metered.init(context, metered);
     }
 
@@ -111,43 +112,39 @@ public class MeteredKeyValueStoreTest {
 
     @Test
     public void shouldWriteBytesToInnerStoreAndRecordPutMetric() {
-        inner.put(eq(keyBytes), EasyMock.aryEq(valueBytes));
-        EasyMock.expectLastCall();
-
+        inner.put(eq(keyBytes), aryEq(valueBytes));
+        expectLastCall();
         init();
 
         metered.put(key, value);
 
         final KafkaMetric metric = metric("put-rate");
-
         assertTrue((Double) metric.metricValue() > 0);
-        EasyMock.verify(inner);
+        verify(inner);
     }
 
-
     @Test
     public void shouldGetBytesFromInnerStoreAndReturnGetMetric() {
-        EasyMock.expect(inner.get(keyBytes)).andReturn(valueBytes);
+        expect(inner.get(keyBytes)).andReturn(valueBytes);
         init();
 
         assertThat(metered.get(key), equalTo(value));
 
         final KafkaMetric metric = metric("get-rate");
         assertTrue((Double) metric.metricValue() > 0);
-        EasyMock.verify(inner);
+        verify(inner);
     }
 
     @Test
     public void shouldPutIfAbsentAndRecordPutIfAbsentMetric() {
-        EasyMock.expect(inner.putIfAbsent(eq(keyBytes), EasyMock.aryEq(valueBytes)))
-                .andReturn(null);
+        expect(inner.putIfAbsent(eq(keyBytes), aryEq(valueBytes))).andReturn(null);
         init();
 
         metered.putIfAbsent(key, value);
 
         final KafkaMetric metric = metric("put-if-absent-rate");
         assertTrue((Double) metric.metricValue() > 0);
-        EasyMock.verify(inner);
+        verify(inner);
     }
 
     private KafkaMetric metric(final String name) {
@@ -157,36 +154,33 @@ public class MeteredKeyValueStoreTest {
     @SuppressWarnings("unchecked")
     @Test
     public void shouldPutAllToInnerStoreAndRecordPutAllMetric() {
-        inner.putAll(EasyMock.anyObject(List.class));
-        EasyMock.expectLastCall();
-
+        inner.putAll(anyObject(List.class));
+        expectLastCall();
         init();
 
         metered.putAll(Collections.singletonList(KeyValue.pair(key, value)));
 
         final KafkaMetric metric = metric("put-all-rate");
         assertTrue((Double) metric.metricValue() > 0);
-        EasyMock.verify(inner);
+        verify(inner);
     }
 
     @Test
     public void shouldDeleteFromInnerStoreAndRecordDeleteMetric() {
-        EasyMock.expect(inner.delete(keyBytes)).andReturn(valueBytes);
-
+        expect(inner.delete(keyBytes)).andReturn(valueBytes);
         init();
 
         metered.delete(key);
 
         final KafkaMetric metric = metric("delete-rate");
         assertTrue((Double) metric.metricValue() > 0);
-        EasyMock.verify(inner);
+        verify(inner);
     }
 
     @Test
     public void shouldGetRangeFromInnerStoreAndRecordRangeMetric() {
-        EasyMock.expect(inner.range(keyBytes, keyBytes))
-                .andReturn(new KeyValueIteratorStub<>(Collections.singletonList(KeyValue.pair(keyBytes, valueBytes)).iterator()));
-
+        expect(inner.range(keyBytes, keyBytes))
+            .andReturn(new KeyValueIteratorStub<>(Collections.singletonList(byteKeyValuePair).iterator()));
         init();
 
         final KeyValueIterator<String, String> iterator = metered.range(key, key);
@@ -196,14 +190,12 @@ public class MeteredKeyValueStoreTest {
 
         final KafkaMetric metric = metric("range-rate");
         assertTrue((Double) metric.metricValue() > 0);
-        EasyMock.verify(inner);
+        verify(inner);
     }
 
     @Test
     public void shouldGetAllFromInnerStoreAndRecordAllMetric() {
-        EasyMock.expect(inner.all())
-                .andReturn(new KeyValueIteratorStub<>(Collections.singletonList(KeyValue.pair(keyBytes, valueBytes)).iterator()));
-
+        expect(inner.all()).andReturn(new KeyValueIteratorStub<>(Collections.singletonList(byteKeyValuePair).iterator()));
         init();
 
         final KeyValueIterator<String, String> iterator = metered.all();
@@ -213,28 +205,28 @@ public class MeteredKeyValueStoreTest {
 
         final KafkaMetric metric = metric(new MetricName("all-rate", "stream-scope-metrics", "", tags));
         assertTrue((Double) metric.metricValue() > 0);
-        EasyMock.verify(inner);
+        verify(inner);
     }
 
     @Test
     public void shouldFlushInnerWhenFlushTimeRecords() {
         inner.flush();
-        EasyMock.expectLastCall().once();
+        expectLastCall().once();
         init();
 
         metered.flush();
 
         final KafkaMetric metric = metric("flush-rate");
         assertTrue((Double) metric.metricValue() > 0);
-        EasyMock.verify(inner);
+        verify(inner);
     }
 
-    private interface CachedKeyValueStore<K, V> extends KeyValueStore<K, V>, CachedStateStore<K, V> { }
+    private interface CachedKeyValueStore extends KeyValueStore<Bytes, byte[]>, CachedStateStore<byte[], byte[]> { }
 
     @SuppressWarnings("unchecked")
     @Test
     public void shouldSetFlushListenerOnWrappedCachingStore() {
-        final CachedKeyValueStore<Bytes, byte[]> cachedKeyValueStore = mock(CachedKeyValueStore.class);
+        final CachedKeyValueStore cachedKeyValueStore = mock(CachedKeyValueStore.class);
 
         expect(cachedKeyValueStore.setFlushListener(anyObject(CacheFlushListener.class), eq(false))).andReturn(true);
         replay(cachedKeyValueStore);
@@ -260,5 +252,4 @@ public class MeteredKeyValueStoreTest {
         return this.metrics.metric(metricName);
     }
 
-
-}
+}
\ No newline at end of file
diff --git a/streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredSessionStoreTest.java b/streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredSessionStoreTest.java
index 7dbf192dee..b349f178ac 100644
--- a/streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredSessionStoreTest.java
+++ b/streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredSessionStoreTest.java
@@ -251,12 +251,12 @@ public class MeteredSessionStoreTest {
         metered.findSessions("a", null, 0, 0);
     }
 
-    private interface CachedSessionStore<K, V> extends SessionStore<K, V>, CachedStateStore<K, V> { }
+    private interface CachedSessionStore extends SessionStore<Bytes, byte[]>, CachedStateStore<byte[], byte[]> { }
 
     @SuppressWarnings("unchecked")
     @Test
     public void shouldSetFlushListenerOnWrappedCachingStore() {
-        final CachedSessionStore<Bytes, byte[]> cachedSessionStore = mock(CachedSessionStore.class);
+        final CachedSessionStore cachedSessionStore = mock(CachedSessionStore.class);
 
         expect(cachedSessionStore.setFlushListener(anyObject(CacheFlushListener.class), eq(false))).andReturn(true);
         replay(cachedSessionStore);
diff --git a/streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredTimestampedKeyValueStoreTest.java b/streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredTimestampedKeyValueStoreTest.java
new file mode 100644
index 0000000000..0f60d24947
--- /dev/null
+++ b/streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredTimestampedKeyValueStoreTest.java
@@ -0,0 +1,257 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.kafka.streams.state.internals;
+
+import org.apache.kafka.common.MetricName;
+import org.apache.kafka.common.metrics.JmxReporter;
+import org.apache.kafka.common.metrics.KafkaMetric;
+import org.apache.kafka.common.metrics.Metrics;
+import org.apache.kafka.common.metrics.Sensor;
+import org.apache.kafka.common.serialization.Serdes;
+import org.apache.kafka.common.utils.Bytes;
+import org.apache.kafka.common.utils.MockTime;
+import org.apache.kafka.streams.KeyValue;
+import org.apache.kafka.streams.processor.ProcessorContext;
+import org.apache.kafka.streams.processor.TaskId;
+import org.apache.kafka.streams.processor.internals.MockStreamsMetrics;
+import org.apache.kafka.streams.state.KeyValueIterator;
+import org.apache.kafka.streams.state.KeyValueStore;
+import org.apache.kafka.streams.state.ValueAndTimestamp;
+import org.apache.kafka.test.KeyValueIteratorStub;
+import org.easymock.EasyMockRunner;
+import org.easymock.Mock;
+import org.easymock.MockType;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
+
+import static org.apache.kafka.common.utils.Utils.mkEntry;
+import static org.apache.kafka.common.utils.Utils.mkMap;
+import static org.easymock.EasyMock.anyObject;
+import static org.easymock.EasyMock.aryEq;
+import static org.easymock.EasyMock.eq;
+import static org.easymock.EasyMock.expect;
+import static org.easymock.EasyMock.expectLastCall;
+import static org.easymock.EasyMock.mock;
+import static org.easymock.EasyMock.replay;
+import static org.easymock.EasyMock.verify;
+import static org.hamcrest.CoreMatchers.equalTo;
+import static org.hamcrest.MatcherAssert.assertThat;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+
+@RunWith(EasyMockRunner.class)
+public class MeteredTimestampedKeyValueStoreTest {
+
+    private final TaskId taskId = new TaskId(0, 0);
+    private final Map<String, String> tags = mkMap(
+        mkEntry("client-id", "test"),
+        mkEntry("task-id", taskId.toString()),
+        mkEntry("scope-id", "metered")
+    );
+    @Mock(type = MockType.NICE)
+    private KeyValueStore<Bytes, byte[]> inner;
+    @Mock(type = MockType.NICE)
+    private ProcessorContext context;
+
+    private MeteredTimestampedKeyValueStore<String, String> metered;
+    private final String key = "key";
+    private final Bytes keyBytes = Bytes.wrap(key.getBytes());
+    private final String value = "value";
+    private final ValueAndTimestamp<String> valueAndTimestamp = ValueAndTimestamp.make("value", 97L);
+    // timestamp is 97 what is ASCII of 'a'
+    private final byte[] valueAndTimestampBytes = "\0\0\0\0\0\0\0avalue".getBytes();
+    private final KeyValue<Bytes, byte[]> byteKeyValueTimestampPair = KeyValue.pair(keyBytes, valueAndTimestampBytes);
+    private final Metrics metrics = new Metrics();
+
+    @Before
+    public void before() {
+        metered = new MeteredTimestampedKeyValueStore<>(
+            inner,
+            "scope",
+            new MockTime(),
+            Serdes.String(),
+            new ValueAndTimestampSerde<>(Serdes.String())
+        );
+        metrics.config().recordLevel(Sensor.RecordingLevel.DEBUG);
+        expect(context.metrics()).andReturn(new MockStreamsMetrics(metrics));
+        expect(context.taskId()).andReturn(taskId);
+        expect(inner.name()).andReturn("metered").anyTimes();
+    }
+
+    private void init() {
+        replay(inner, context);
+        metered.init(context, metered);
+    }
+
+    @Test
+    public void testMetrics() {
+        init();
+        final JmxReporter reporter = new JmxReporter("kafka.streams");
+        metrics.addReporter(reporter);
+        assertTrue(reporter.containsMbean(String.format("kafka.streams:type=stream-%s-metrics,client-id=%s,task-id=%s,%s-id=%s",
+                "scope", "test", taskId.toString(), "scope", "metered")));
+        assertTrue(reporter.containsMbean(String.format("kafka.streams:type=stream-%s-metrics,client-id=%s,task-id=%s,%s-id=%s",
+                "scope", "test", taskId.toString(), "scope", "all")));
+    }
+    @Test
+    public void shouldWriteBytesToInnerStoreAndRecordPutMetric() {
+        inner.put(eq(keyBytes), aryEq(valueAndTimestampBytes));
+        expectLastCall();
+        init();
+
+        metered.put(key, valueAndTimestamp);
+
+        final KafkaMetric metric = metric("put-rate");
+        assertTrue((Double) metric.metricValue() > 0);
+        verify(inner);
+    }
+
+    @Test
+    public void shouldGetBytesFromInnerStoreAndReturnGetMetric() {
+        expect(inner.get(keyBytes)).andReturn(valueAndTimestampBytes);
+        init();
+
+        assertThat(metered.get(key), equalTo(valueAndTimestamp));
+
+        final KafkaMetric metric = metric("get-rate");
+        assertTrue((Double) metric.metricValue() > 0);
+        verify(inner);
+    }
+
+    @Test
+    public void shouldPutIfAbsentAndRecordPutIfAbsentMetric() {
+        expect(inner.putIfAbsent(eq(keyBytes), aryEq(valueAndTimestampBytes))).andReturn(null);
+        init();
+
+        metered.putIfAbsent(key, valueAndTimestamp);
+
+        final KafkaMetric metric = metric("put-if-absent-rate");
+        assertTrue((Double) metric.metricValue() > 0);
+        verify(inner);
+    }
+
+    private KafkaMetric metric(final String name) {
+        return this.metrics.metric(new MetricName(name, "stream-scope-metrics", "", this.tags));
+    }
+
+    @SuppressWarnings("unchecked")
+    @Test
+    public void shouldPutAllToInnerStoreAndRecordPutAllMetric() {
+        inner.putAll(anyObject(List.class));
+        expectLastCall();
+        init();
+
+        metered.putAll(Collections.singletonList(KeyValue.pair(key, valueAndTimestamp)));
+
+        final KafkaMetric metric = metric("put-all-rate");
+        assertTrue((Double) metric.metricValue() > 0);
+        verify(inner);
+    }
+
+    @Test
+    public void shouldDeleteFromInnerStoreAndRecordDeleteMetric() {
+        expect(inner.delete(keyBytes)).andReturn(valueAndTimestampBytes);
+        init();
+
+        metered.delete(key);
+
+        final KafkaMetric metric = metric("delete-rate");
+        assertTrue((Double) metric.metricValue() > 0);
+        verify(inner);
+    }
+
+    @Test
+    public void shouldGetRangeFromInnerStoreAndRecordRangeMetric() {
+        expect(inner.range(keyBytes, keyBytes)).andReturn(
+            new KeyValueIteratorStub<>(Collections.singletonList(byteKeyValueTimestampPair).iterator()));
+        init();
+
+        final KeyValueIterator<String, ValueAndTimestamp<String>> iterator = metered.range(key, key);
+        assertThat(iterator.next().value, equalTo(valueAndTimestamp));
+        assertFalse(iterator.hasNext());
+        iterator.close();
+
+        final KafkaMetric metric = metric("range-rate");
+        assertTrue((Double) metric.metricValue() > 0);
+        verify(inner);
+    }
+
+    @Test
+    public void shouldGetAllFromInnerStoreAndRecordAllMetric() {
+        expect(inner.all())
+            .andReturn(new KeyValueIteratorStub<>(Collections.singletonList(byteKeyValueTimestampPair).iterator()));
+        init();
+
+        final KeyValueIterator<String, ValueAndTimestamp<String>> iterator = metered.all();
+        assertThat(iterator.next().value, equalTo(valueAndTimestamp));
+        assertFalse(iterator.hasNext());
+        iterator.close();
+
+        final KafkaMetric metric = metric(new MetricName("all-rate", "stream-scope-metrics", "", tags));
+        assertTrue((Double) metric.metricValue() > 0);
+        verify(inner);
+    }
+
+    @Test
+    public void shouldFlushInnerWhenFlushTimeRecords() {
+        inner.flush();
+        expectLastCall().once();
+        init();
+
+        metered.flush();
+
+        final KafkaMetric metric = metric("flush-rate");
+        assertTrue((Double) metric.metricValue() > 0);
+        verify(inner);
+    }
+
+    private interface CachedKeyValueStore extends KeyValueStore<Bytes, byte[]>, CachedStateStore<byte[], byte[]> { }
+
+    @SuppressWarnings("unchecked")
+    @Test
+    public void shouldSetFlushListenerOnWrappedCachingStore() {
+        final CachedKeyValueStore cachedKeyValueStore = mock(CachedKeyValueStore.class);
+
+        expect(cachedKeyValueStore.setFlushListener(anyObject(CacheFlushListener.class), eq(false))).andReturn(true);
+        replay(cachedKeyValueStore);
+
+        metered = new MeteredTimestampedKeyValueStore<>(
+            cachedKeyValueStore,
+            "scope",
+            new MockTime(),
+            Serdes.String(),
+            new ValueAndTimestampSerde<>(Serdes.String()));
+        assertTrue(metered.setFlushListener(null, false));
+
+        verify(cachedKeyValueStore);
+    }
+
+    @Test
+    public void shouldNotSetFlushListenerOnWrappedNoneCachingStore() {
+        assertFalse(metered.setFlushListener(null, false));
+    }
+
+    private KafkaMetric metric(final MetricName metricName) {
+        return this.metrics.metric(metricName);
+    }
+
+}
\ No newline at end of file
diff --git a/streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredWindowStoreTest.java b/streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredWindowStoreTest.java
index b4ddb9fddf..962888ae9c 100644
--- a/streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredWindowStoreTest.java
+++ b/streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredWindowStoreTest.java
@@ -186,12 +186,12 @@ public class MeteredWindowStoreTest {
         assertNull(store.fetch("a", 0));
     }
 
-    private interface CachedWindowStore<K, V> extends WindowStore<K, V>, CachedStateStore<K, V> { }
+    private interface CachedWindowStore extends WindowStore<Bytes, byte[]>, CachedStateStore<byte[], byte[]> { }
 
     @SuppressWarnings("unchecked")
     @Test
     public void shouldSetFlushListenerOnWrappedCachingStore() {
-        final CachedWindowStore<Bytes, byte[]> cachedWindowStore = mock(CachedWindowStore.class);
+        final CachedWindowStore cachedWindowStore = mock(CachedWindowStore.class);
 
         expect(cachedWindowStore.setFlushListener(anyObject(CacheFlushListener.class), eq(false))).andReturn(true);
         replay(cachedWindowStore);
diff --git a/streams/src/test/java/org/apache/kafka/streams/state/internals/StoreChangeLoggerTest.java b/streams/src/test/java/org/apache/kafka/streams/state/internals/StoreChangeLoggerTest.java
index 3e9b3c393f..e8d3b9c8f3 100644
--- a/streams/src/test/java/org/apache/kafka/streams/state/internals/StoreChangeLoggerTest.java
+++ b/streams/src/test/java/org/apache/kafka/streams/state/internals/StoreChangeLoggerTest.java
@@ -26,6 +26,7 @@ import org.apache.kafka.streams.errors.DefaultProductionExceptionHandler;
 import org.apache.kafka.streams.processor.StreamPartitioner;
 import org.apache.kafka.streams.processor.internals.RecordCollectorImpl;
 import org.apache.kafka.streams.state.StateSerdes;
+import org.apache.kafka.streams.state.ValueAndTimestamp;
 import org.apache.kafka.test.InternalMockProcessorContext;
 import org.junit.Test;
 
@@ -39,7 +40,7 @@ public class StoreChangeLoggerTest {
 
     private final String topic = "topic";
 
-    private final Map<Integer, String> logged = new HashMap<>();
+    private final Map<Integer, ValueAndTimestamp<String>> logged = new HashMap<>();
     private final Map<Integer, Headers> loggedHeaders = new HashMap<>();
 
     private final InternalMockProcessorContext context = new InternalMockProcessorContext(
@@ -59,7 +60,7 @@ public class StoreChangeLoggerTest {
                                       final Long timestamp,
                                       final Serializer<K1> keySerializer,
                                       final Serializer<V1> valueSerializer) {
-                logged.put((Integer) key, (String) value);
+                logged.put((Integer) key, ValueAndTimestamp.make((String) value, timestamp));
                 loggedHeaders.put((Integer) key, headers);
             }
 
@@ -84,12 +85,15 @@ public class StoreChangeLoggerTest {
     public void testAddRemove() {
         context.setTime(1);
         changeLogger.logChange(0, "zero");
+        context.setTime(5);
         changeLogger.logChange(1, "one");
         changeLogger.logChange(2, "two");
+        changeLogger.logChange(3, "three", 42L);
 
-        assertEquals("zero", logged.get(0));
-        assertEquals("one", logged.get(1));
-        assertEquals("two", logged.get(2));
+        assertEquals(ValueAndTimestamp.make("zero", 1L), logged.get(0));
+        assertEquals(ValueAndTimestamp.make("one", 5L), logged.get(1));
+        assertEquals(ValueAndTimestamp.make("two", 5L), logged.get(2));
+        assertEquals(ValueAndTimestamp.make("three", 42L), logged.get(3));
 
         changeLogger.logChange(0, null);
         assertNull(logged.get(0));
@@ -99,6 +103,7 @@ public class StoreChangeLoggerTest {
     public void shouldNotSendRecordHeadersToChangelogTopic() {
         context.headers().add(new RecordHeader("key", "value".getBytes()));
         changeLogger.logChange(0, "zero");
+        changeLogger.logChange(0, "zero", 42L);
 
         assertNull(loggedHeaders.get(0));
     }
diff --git a/streams/src/test/java/org/apache/kafka/streams/state/internals/TimestampedKeyValueStoreBuilderTest.java b/streams/src/test/java/org/apache/kafka/streams/state/internals/TimestampedKeyValueStoreBuilderTest.java
new file mode 100644
index 0000000000..e6dbc6692a
--- /dev/null
+++ b/streams/src/test/java/org/apache/kafka/streams/state/internals/TimestampedKeyValueStoreBuilderTest.java
@@ -0,0 +1,143 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.kafka.streams.state.internals;
+
+import org.apache.kafka.common.serialization.Serdes;
+import org.apache.kafka.common.utils.Bytes;
+import org.apache.kafka.common.utils.MockTime;
+import org.apache.kafka.streams.processor.StateStore;
+import org.apache.kafka.streams.state.KeyValueBytesStoreSupplier;
+import org.apache.kafka.streams.state.KeyValueStore;
+import org.apache.kafka.streams.state.TimestampedKeyValueStore;
+import org.easymock.EasyMock;
+import org.easymock.EasyMockRunner;
+import org.easymock.Mock;
+import org.easymock.MockType;
+import org.hamcrest.CoreMatchers;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+
+import java.util.Collections;
+
+import static org.hamcrest.MatcherAssert.assertThat;
+import static org.hamcrest.core.IsInstanceOf.instanceOf;
+
+@RunWith(EasyMockRunner.class)
+public class TimestampedKeyValueStoreBuilderTest {
+
+    @Mock(type = MockType.NICE)
+    private KeyValueBytesStoreSupplier supplier;
+    @Mock(type = MockType.NICE)
+    private KeyValueStore<Bytes, byte[]> inner;
+    private TimestampedKeyValueStoreBuilder<String, String> builder;
+
+    @Before
+    public void setUp() {
+        EasyMock.expect(supplier.get()).andReturn(inner);
+        EasyMock.expect(supplier.name()).andReturn("name");
+        EasyMock.replay(supplier);
+        builder = new TimestampedKeyValueStoreBuilder<>(
+            supplier,
+            Serdes.String(),
+            Serdes.String(),
+            new MockTime()
+        );
+    }
+
+    @Test
+    public void shouldHaveMeteredStoreAsOuterStore() {
+        final TimestampedKeyValueStore<String, String> store = builder.build();
+        assertThat(store, instanceOf(MeteredTimestampedKeyValueStore.class));
+    }
+
+    @Test
+    public void shouldHaveChangeLoggingStoreByDefault() {
+        final TimestampedKeyValueStore<String, String> store = builder.build();
+        assertThat(store, instanceOf(MeteredTimestampedKeyValueStore.class));
+        final StateStore next = ((WrappedStateStore) store).wrapped();
+        assertThat(next, instanceOf(ChangeLoggingTimestampedKeyValueBytesStore.class));
+    }
+
+    @Test
+    public void shouldNotHaveChangeLoggingStoreWhenDisabled() {
+        final TimestampedKeyValueStore<String, String> store = builder.withLoggingDisabled().build();
+        final StateStore next = ((WrappedStateStore) store).wrapped();
+        assertThat(next, CoreMatchers.equalTo(inner));
+    }
+
+    @Test
+    public void shouldHaveCachingStoreWhenEnabled() {
+        final TimestampedKeyValueStore<String, String> store = builder.withCachingEnabled().build();
+        final StateStore wrapped = ((WrappedStateStore) store).wrapped();
+        assertThat(store, instanceOf(MeteredTimestampedKeyValueStore.class));
+        assertThat(wrapped, instanceOf(CachingKeyValueStore.class));
+    }
+
+    @Test
+    public void shouldHaveChangeLoggingStoreWhenLoggingEnabled() {
+        final TimestampedKeyValueStore<String, String> store = builder
+                .withLoggingEnabled(Collections.emptyMap())
+                .build();
+        final StateStore wrapped = ((WrappedStateStore) store).wrapped();
+        assertThat(store, instanceOf(MeteredTimestampedKeyValueStore.class));
+        assertThat(wrapped, instanceOf(ChangeLoggingTimestampedKeyValueBytesStore.class));
+        assertThat(((WrappedStateStore) wrapped).wrapped(), CoreMatchers.equalTo(inner));
+    }
+
+    @Test
+    public void shouldHaveCachingAndChangeLoggingWhenBothEnabled() {
+        final TimestampedKeyValueStore<String, String> store = builder
+                .withLoggingEnabled(Collections.emptyMap())
+                .withCachingEnabled()
+                .build();
+        final WrappedStateStore caching = (WrappedStateStore) ((WrappedStateStore) store).wrapped();
+        final WrappedStateStore changeLogging = (WrappedStateStore) caching.wrapped();
+        assertThat(store, instanceOf(MeteredTimestampedKeyValueStore.class));
+        assertThat(caching, instanceOf(CachingKeyValueStore.class));
+        assertThat(changeLogging, instanceOf(ChangeLoggingTimestampedKeyValueBytesStore.class));
+        assertThat(changeLogging.wrapped(), CoreMatchers.equalTo(inner));
+    }
+
+    @SuppressWarnings("all")
+    @Test(expected = NullPointerException.class)
+    public void shouldThrowNullPointerIfInnerIsNull() {
+        new TimestampedKeyValueStoreBuilder<>(null, Serdes.String(), Serdes.String(), new MockTime());
+    }
+
+    @Test(expected = NullPointerException.class)
+    public void shouldThrowNullPointerIfKeySerdeIsNull() {
+        new TimestampedKeyValueStoreBuilder<>(supplier, null, Serdes.String(), new MockTime());
+    }
+
+    @Test(expected = NullPointerException.class)
+    public void shouldThrowNullPointerIfValueSerdeIsNull() {
+        new TimestampedKeyValueStoreBuilder<>(supplier, Serdes.String(), null, new MockTime());
+    }
+
+    @Test(expected = NullPointerException.class)
+    public void shouldThrowNullPointerIfTimeIsNull() {
+        new TimestampedKeyValueStoreBuilder<>(supplier, Serdes.String(), Serdes.String(), null);
+    }
+
+    @Test(expected = NullPointerException.class)
+    public void shouldThrowNullPointerIfMetricsScopeIsNull() {
+        new TimestampedKeyValueStoreBuilder<>(supplier, Serdes.String(), Serdes.String(), new MockTime());
+    }
+
+}
\ No newline at end of file
