diff --git a/checkstyle/import-control.xml b/checkstyle/import-control.xml
index fdedef8a7b..ab4f15d2f4 100644
--- a/checkstyle/import-control.xml
+++ b/checkstyle/import-control.xml
@@ -50,6 +50,11 @@
     <allow pkg="org.apache.kafka.common.internals" exact-match="true" />
     <allow pkg="org.apache.kafka.test" />
 
+    <subpackage name="acl">
+      <allow pkg="org.apache.kafka.common.acl" />
+      <allow pkg="org.apache.kafka.common.resource" />
+    </subpackage>
+
     <subpackage name="config">
       <allow pkg="org.apache.kafka.common.config" />
       <!-- for testing -->
@@ -68,6 +73,10 @@
       <allow pkg="org.apache.kafka.common.security" />
     </subpackage>
 
+    <subpackage name="resource">
+      <allow pkg="org.apache.kafka.common.resource" />
+    </subpackage>
+
     <subpackage name="security">
       <allow pkg="org.apache.kafka.common.annotation" />
       <allow pkg="org.apache.kafka.common.network" />
@@ -109,9 +118,11 @@
 
     <subpackage name="requests">
       <allow pkg="org.apache.kafka.clients.admin" />
+      <allow pkg="org.apache.kafka.common.acl" />
       <allow pkg="org.apache.kafka.common.protocol" />
       <allow pkg="org.apache.kafka.common.network" />
       <allow pkg="org.apache.kafka.common.requests" />
+      <allow pkg="org.apache.kafka.common.resource" />
       <allow pkg="org.apache.kafka.common.record" />
       <!-- for testing -->
       <allow pkg="org.apache.kafka.common.errors" />
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/AdminClient.java b/clients/src/main/java/org/apache/kafka/clients/admin/AdminClient.java
index 96b8ebbbdd..8ae32496fe 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/AdminClient.java
+++ b/clients/src/main/java/org/apache/kafka/clients/admin/AdminClient.java
@@ -18,7 +18,10 @@
 package org.apache.kafka.clients.admin;
 
 import org.apache.kafka.common.Node;
+import org.apache.kafka.common.acl.AclBinding;
+import org.apache.kafka.common.acl.AclBindingFilter;
 import org.apache.kafka.common.annotation.InterfaceStability;
+import org.apache.kafka.common.config.ConfigResource;
 
 import java.util.Collection;
 import java.util.Map;
@@ -81,9 +84,9 @@ public abstract class AdminClient implements AutoCloseable {
      * Create a batch of new topics with the default options.
      *
      * @param newTopics         The new topics to create.
-     * @return                  The CreateTopicsResults.
+     * @return                  The CreateTopicsResult.
      */
-    public CreateTopicResults createTopics(Collection<NewTopic> newTopics) {
+    public CreateTopicsResult createTopics(Collection<NewTopic> newTopics) {
         return createTopics(newTopics, new CreateTopicsOptions());
     }
 
@@ -97,9 +100,9 @@ public abstract class AdminClient implements AutoCloseable {
      *
      * @param newTopics         The new topics to create.
      * @param options           The options to use when creating the new topics.
-     * @return                  The CreateTopicsResults.
+     * @return                  The CreateTopicsResult.
      */
-    public abstract CreateTopicResults createTopics(Collection<NewTopic> newTopics,
+    public abstract CreateTopicsResult createTopics(Collection<NewTopic> newTopics,
                                                     CreateTopicsOptions options);
 
     /**
@@ -107,9 +110,9 @@ public abstract class AdminClient implements AutoCloseable {
      * but uses the default options.
      *
      * @param topics            The topic names to delete.
-     * @return                  The DeleteTopicsResults.
+     * @return                  The DeleteTopicsResult.
      */
-    public DeleteTopicResults deleteTopics(Collection<String> topics) {
+    public DeleteTopicsResult deleteTopics(Collection<String> topics) {
         return deleteTopics(topics, new DeleteTopicsOptions());
     }
 
@@ -127,16 +130,16 @@ public abstract class AdminClient implements AutoCloseable {
      *
      * @param topics            The topic names to delete.
      * @param options           The options to use when deleting the topics.
-     * @return                  The DeleteTopicsResults.
+     * @return                  The DeleteTopicsResult.
      */
-    public abstract DeleteTopicResults deleteTopics(Collection<String> topics, DeleteTopicsOptions options);
+    public abstract DeleteTopicsResult deleteTopics(Collection<String> topics, DeleteTopicsOptions options);
 
     /**
      * List the topics available in the cluster with the default options.
      *
-     * @return                  The ListTopicsResults.
+     * @return                  The ListTopicsResult.
      */
-    public ListTopicsResults listTopics() {
+    public ListTopicsResult listTopics() {
         return listTopics(new ListTopicsOptions());
     }
 
@@ -144,9 +147,9 @@ public abstract class AdminClient implements AutoCloseable {
      * List the topics available in the cluster.
      *
      * @param options           The options to use when listing the topics.
-     * @return                  The ListTopicsResults.
+     * @return                  The ListTopicsResult.
      */
-    public abstract ListTopicsResults listTopics(ListTopicsOptions options);
+    public abstract ListTopicsResult listTopics(ListTopicsOptions options);
 
     /**
      * Describe some topics in the cluster, with the default options.
@@ -155,9 +158,9 @@ public abstract class AdminClient implements AutoCloseable {
      *
      * @param topicNames        The names of the topics to describe.
      *
-     * @return                  The DescribeTopicsResults.
+     * @return                  The DescribeTopicsResult.
      */
-    public DescribeTopicsResults describeTopics(Collection<String> topicNames) {
+    public DescribeTopicsResult describeTopics(Collection<String> topicNames) {
         return describeTopics(topicNames, new DescribeTopicsOptions());
     }
 
@@ -173,17 +176,17 @@ public abstract class AdminClient implements AutoCloseable {
      * @param topicNames        The names of the topics to describe.
      * @param options           The options to use when describing the topic.
      *
-     * @return                  The DescribeTopicsResults.
+     * @return                  The DescribeTopicsResult.
      */
-    public abstract DescribeTopicsResults describeTopics(Collection<String> topicNames,
+    public abstract DescribeTopicsResult describeTopics(Collection<String> topicNames,
                                                          DescribeTopicsOptions options);
 
     /**
      * Get information about the nodes in the cluster, using the default options.
      *
-     * @return                  The DescribeClusterResults.
+     * @return                  The DescribeClusterResult.
      */
-    public DescribeClusterResults describeCluster() {
+    public DescribeClusterResult describeCluster() {
         return describeCluster(new DescribeClusterOptions());
     }
 
@@ -191,18 +194,18 @@ public abstract class AdminClient implements AutoCloseable {
      * Get information about the nodes in the cluster.
      *
      * @param options           The options to use when getting information about the cluster.
-     * @return                  The DescribeClusterResults.
+     * @return                  The DescribeClusterResult.
      */
-    public abstract DescribeClusterResults describeCluster(DescribeClusterOptions options);
+    public abstract DescribeClusterResult describeCluster(DescribeClusterOptions options);
 
     /**
      * Get information about the api versions of nodes in the cluster with the default options.
      * See {@link AdminClient#apiVersions(Collection<Node>, ApiVersionsOptions)}
      *
      * @param nodes             The nodes to get information about, or null to get information about all nodes.
-     * @return                  The ApiVersionsResults.
+     * @return                  The ApiVersionsResult.
      */
-    public ApiVersionsResults apiVersions(Collection<Node> nodes) {
+    public ApiVersionsResult apiVersions(Collection<Node> nodes) {
         return apiVersions(nodes, new ApiVersionsOptions());
     }
 
@@ -211,19 +214,18 @@ public abstract class AdminClient implements AutoCloseable {
      *
      * @param nodes             The nodes to get information about, or null to get information about all nodes.
      * @param options           The options to use when getting api versions of the nodes.
-     * @return                  The ApiVersionsResults.
+     * @return                  The ApiVersionsResult.
      */
-    public abstract ApiVersionsResults apiVersions(Collection<Node> nodes, ApiVersionsOptions options);
+    public abstract ApiVersionsResult apiVersions(Collection<Node> nodes, ApiVersionsOptions options);
 
     /**
-<<<<<<< HEAD
      * Similar to #{@link AdminClient#describeAcls(AclBindingFilter, DescribeAclsOptions),
      * but uses the default options.
      *
      * @param filter            The filter to use.
      * @return                  The DeleteAclsResult.
      */
-    public DescribeAclsResults describeAcls(AclBindingFilter filter) {
+    public DescribeAclsResult describeAcls(AclBindingFilter filter) {
         return describeAcls(filter, new DescribeAclsOptions());
     }
 
@@ -237,7 +239,7 @@ public abstract class AdminClient implements AutoCloseable {
      * @param options           The options to use when listing the ACLs.
      * @return                  The DeleteAclsResult.
      */
-    public abstract DescribeAclsResults describeAcls(AclBindingFilter filter, DescribeAclsOptions options);
+    public abstract DescribeAclsResult describeAcls(AclBindingFilter filter, DescribeAclsOptions options);
 
     /**
      * Similar to #{@link AdminClient#createAcls(Collection<AclBinding>, CreateAclsOptions),
@@ -246,7 +248,7 @@ public abstract class AdminClient implements AutoCloseable {
      * @param acls              The ACLs to create
      * @return                  The CreateAclsResult.
      */
-    public CreateAclsResults createAcls(Collection<AclBinding> acls) {
+    public CreateAclsResult createAcls(Collection<AclBinding> acls) {
         return createAcls(acls, new CreateAclsOptions());
     }
 
@@ -260,7 +262,7 @@ public abstract class AdminClient implements AutoCloseable {
      * @param options           The options to use when creating the ACLs.
      * @return                  The CreateAclsResult.
      */
-    public abstract CreateAclsResults createAcls(Collection<AclBinding> acls, CreateAclsOptions options);
+    public abstract CreateAclsResult createAcls(Collection<AclBinding> acls, CreateAclsOptions options);
 
     /**
      * Similar to #{@link AdminClient#deleteAcls(Collection<AclBinding>, DeleteAclsOptions),
@@ -269,7 +271,7 @@ public abstract class AdminClient implements AutoCloseable {
      * @param filters           The filters to use.
      * @return                  The DeleteAclsResult.
      */
-    public DeleteAclsResults deleteAcls(Collection<AclBindingFilter> filters) {
+    public DeleteAclsResult deleteAcls(Collection<AclBindingFilter> filters) {
         return deleteAcls(filters, new DeleteAclsOptions());
     }
 
@@ -280,7 +282,7 @@ public abstract class AdminClient implements AutoCloseable {
      * @param options           The options to use when deleting the ACLs.
      * @return                  The DeleteAclsResult.
      */
-    public abstract DeleteAclsResults deleteAcls(Collection<AclBindingFilter> filters, DeleteAclsOptions options);
+    public abstract DeleteAclsResult deleteAcls(Collection<AclBindingFilter> filters, DeleteAclsOptions options);
 
 
      /**
@@ -289,9 +291,9 @@ public abstract class AdminClient implements AutoCloseable {
      * See {@link #describeConfigs(Collection, DescribeConfigsOptions)} for more details.
      *
      * @param resources         The resources (topic and broker resource types are currently supported)
-     * @return                  The DescribeConfigsResults
+     * @return                  The DescribeConfigsResult
      */
-    public DescribeConfigsResults describeConfigs(Collection<ConfigResource> resources) {
+    public DescribeConfigsResult describeConfigs(Collection<ConfigResource> resources) {
         return describeConfigs(resources, new DescribeConfigsOptions());
     }
 
@@ -308,9 +310,9 @@ public abstract class AdminClient implements AutoCloseable {
      *
      * @param resources         The resources (topic and broker resource types are currently supported)
      * @param options           The options to use when describing configs
-     * @return                  The DescribeConfigsResults
+     * @return                  The DescribeConfigsResult
      */
-    public abstract DescribeConfigsResults describeConfigs(Collection<ConfigResource> resources,
+    public abstract DescribeConfigsResult describeConfigs(Collection<ConfigResource> resources,
                                                            DescribeConfigsOptions options);
 
     /**
@@ -320,9 +322,9 @@ public abstract class AdminClient implements AutoCloseable {
      *
      * @param configs         The resources with their configs (topic is the only resource type with configs that can
      *                        be updated currently)
-     * @return                The AlterConfigsResults
+     * @return                The AlterConfigsResult
      */
-    public AlterConfigsResults alterConfigs(Map<ConfigResource, Config> configs) {
+    public AlterConfigsResult alterConfigs(Map<ConfigResource, Config> configs) {
         return alterConfigs(configs, new AlterConfigsOptions());
     }
 
@@ -335,8 +337,8 @@ public abstract class AdminClient implements AutoCloseable {
      * @param configs         The resources with their configs (topic is the only resource type with configs that can
      *                        be updated currently)
      * @param options         The options to use when describing configs
-     * @return                The AlterConfigsResults
+     * @return                The AlterConfigsResult
      */
-    public abstract AlterConfigsResults alterConfigs(Map<ConfigResource, Config> configs, AlterConfigsOptions options);
+    public abstract AlterConfigsResult alterConfigs(Map<ConfigResource, Config> configs, AlterConfigsOptions options);
 
 }
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/AlterConfigsResults.java b/clients/src/main/java/org/apache/kafka/clients/admin/AlterConfigsResult.java
similarity index 89%
rename from clients/src/main/java/org/apache/kafka/clients/admin/AlterConfigsResults.java
rename to clients/src/main/java/org/apache/kafka/clients/admin/AlterConfigsResult.java
index 3f44cfd766..19d7946260 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/AlterConfigsResults.java
+++ b/clients/src/main/java/org/apache/kafka/clients/admin/AlterConfigsResult.java
@@ -19,15 +19,16 @@ package org.apache.kafka.clients.admin;
 
 import org.apache.kafka.common.KafkaFuture;
 import org.apache.kafka.common.annotation.InterfaceStability;
+import org.apache.kafka.common.config.ConfigResource;
 
 import java.util.Map;
 
 @InterfaceStability.Unstable
-public class AlterConfigsResults {
+public class AlterConfigsResult {
 
     private final Map<ConfigResource, KafkaFuture<Void>> futures;
 
-    AlterConfigsResults(Map<ConfigResource, KafkaFuture<Void>> futures) {
+    AlterConfigsResult(Map<ConfigResource, KafkaFuture<Void>> futures) {
         this.futures = futures;
     }
 
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/ApiVersionsResults.java b/clients/src/main/java/org/apache/kafka/clients/admin/ApiVersionsResult.java
similarity index 95%
rename from clients/src/main/java/org/apache/kafka/clients/admin/ApiVersionsResults.java
rename to clients/src/main/java/org/apache/kafka/clients/admin/ApiVersionsResult.java
index 456c64d3de..62b6d7fa89 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/ApiVersionsResults.java
+++ b/clients/src/main/java/org/apache/kafka/clients/admin/ApiVersionsResult.java
@@ -30,10 +30,10 @@ import java.util.concurrent.ExecutionException;
  * Results of the apiVersions call.
  */
 @InterfaceStability.Unstable
-public class ApiVersionsResults {
+public class ApiVersionsResult {
     private final Map<Node, KafkaFuture<NodeApiVersions>> futures;
 
-    ApiVersionsResults(Map<Node, KafkaFuture<NodeApiVersions>> futures) {
+    ApiVersionsResult(Map<Node, KafkaFuture<NodeApiVersions>> futures) {
         this.futures = futures;
     }
 
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/CreateAclsResults.java b/clients/src/main/java/org/apache/kafka/clients/admin/CreateAclsResult.java
similarity index 91%
rename from clients/src/main/java/org/apache/kafka/clients/admin/CreateAclsResults.java
rename to clients/src/main/java/org/apache/kafka/clients/admin/CreateAclsResult.java
index 6908037f87..de83509f08 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/CreateAclsResults.java
+++ b/clients/src/main/java/org/apache/kafka/clients/admin/CreateAclsResult.java
@@ -18,16 +18,17 @@
 package org.apache.kafka.clients.admin;
 
 import org.apache.kafka.common.KafkaFuture;
+import org.apache.kafka.common.acl.AclBinding;
 
 import java.util.Map;
 
 /**
  * The result of the createAcls call.
  */
-public class CreateAclsResults {
+public class CreateAclsResult {
     private final Map<AclBinding, KafkaFuture<Void>> futures;
 
-    CreateAclsResults(Map<AclBinding, KafkaFuture<Void>> futures) {
+    CreateAclsResult(Map<AclBinding, KafkaFuture<Void>> futures) {
         this.futures = futures;
     }
 
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/CreateTopicResults.java b/clients/src/main/java/org/apache/kafka/clients/admin/CreateTopicsResult.java
similarity index 94%
rename from clients/src/main/java/org/apache/kafka/clients/admin/CreateTopicResults.java
rename to clients/src/main/java/org/apache/kafka/clients/admin/CreateTopicsResult.java
index 03da7d0d52..49bf21c728 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/CreateTopicResults.java
+++ b/clients/src/main/java/org/apache/kafka/clients/admin/CreateTopicsResult.java
@@ -25,10 +25,10 @@ import java.util.Map;
  * The result of newTopics.
  */
 @InterfaceStability.Unstable
-public class CreateTopicResults {
+public class CreateTopicsResult {
     private final Map<String, KafkaFuture<Void>> futures;
 
-    CreateTopicResults(Map<String, KafkaFuture<Void>> futures) {
+    CreateTopicsResult(Map<String, KafkaFuture<Void>> futures) {
         this.futures = futures;
     }
 
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/DeleteAclsResults.java b/clients/src/main/java/org/apache/kafka/clients/admin/DeleteAclsResult.java
similarity index 93%
rename from clients/src/main/java/org/apache/kafka/clients/admin/DeleteAclsResults.java
rename to clients/src/main/java/org/apache/kafka/clients/admin/DeleteAclsResult.java
index dfb2e6bd1d..da92752f83 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/DeleteAclsResults.java
+++ b/clients/src/main/java/org/apache/kafka/clients/admin/DeleteAclsResult.java
@@ -19,6 +19,8 @@ package org.apache.kafka.clients.admin;
 
 import org.apache.kafka.common.KafkaException;
 import org.apache.kafka.common.KafkaFuture;
+import org.apache.kafka.common.acl.AclBinding;
+import org.apache.kafka.common.acl.AclBindingFilter;
 import org.apache.kafka.common.errors.ApiException;
 
 import java.util.ArrayList;
@@ -29,7 +31,7 @@ import java.util.Map;
 /**
  * The result of the deleteAcls call.
  */
-public class DeleteAclsResults {
+public class DeleteAclsResult {
     public static class FilterResult {
         private final AclBinding acl;
         private final ApiException exception;
@@ -62,7 +64,7 @@ public class DeleteAclsResults {
 
     private final Map<AclBindingFilter, KafkaFuture<FilterResults>> futures;
 
-    DeleteAclsResults(Map<AclBindingFilter, KafkaFuture<FilterResults>> futures) {
+    DeleteAclsResult(Map<AclBindingFilter, KafkaFuture<FilterResults>> futures) {
         this.futures = futures;
     }
 
@@ -91,7 +93,7 @@ public class DeleteAclsResults {
                         } catch (Throwable e) {
                             // This should be unreachable, since the future returned by KafkaFuture#allOf should
                             // have failed if any Future failed.
-                            throw new KafkaException("DeleteAclsResults#all: internal error", e);
+                            throw new KafkaException("DeleteAclsResult#all: internal error", e);
                         }
                         for (FilterResult result : results.acls()) {
                             if (result.exception() != null) {
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/DeleteTopicResults.java b/clients/src/main/java/org/apache/kafka/clients/admin/DeleteTopicsResult.java
similarity index 94%
rename from clients/src/main/java/org/apache/kafka/clients/admin/DeleteTopicResults.java
rename to clients/src/main/java/org/apache/kafka/clients/admin/DeleteTopicsResult.java
index 3dd488914c..169ee968ed 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/DeleteTopicResults.java
+++ b/clients/src/main/java/org/apache/kafka/clients/admin/DeleteTopicsResult.java
@@ -26,10 +26,10 @@ import java.util.Map;
  * The result of the deleteTopics call.
  */
 @InterfaceStability.Unstable
-public class DeleteTopicResults {
+public class DeleteTopicsResult {
     final Map<String, KafkaFuture<Void>> futures;
 
-    DeleteTopicResults(Map<String, KafkaFuture<Void>> futures) {
+    DeleteTopicsResult(Map<String, KafkaFuture<Void>> futures) {
         this.futures = futures;
     }
 
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/DescribeAclsResults.java b/clients/src/main/java/org/apache/kafka/clients/admin/DescribeAclsResult.java
similarity index 88%
rename from clients/src/main/java/org/apache/kafka/clients/admin/DescribeAclsResults.java
rename to clients/src/main/java/org/apache/kafka/clients/admin/DescribeAclsResult.java
index dea98ab02f..6d65da608f 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/DescribeAclsResults.java
+++ b/clients/src/main/java/org/apache/kafka/clients/admin/DescribeAclsResult.java
@@ -18,16 +18,17 @@
 package org.apache.kafka.clients.admin;
 
 import org.apache.kafka.common.KafkaFuture;
+import org.apache.kafka.common.acl.AclBinding;
 
 import java.util.Collection;
 
 /**
  * The result of the describeAcls call.
  */
-public class DescribeAclsResults {
+public class DescribeAclsResult {
     private final KafkaFuture<Collection<AclBinding>> future;
 
-    DescribeAclsResults(KafkaFuture<Collection<AclBinding>> future) {
+    DescribeAclsResult(KafkaFuture<Collection<AclBinding>> future) {
         this.future = future;
     }
 
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/DescribeClusterResults.java b/clients/src/main/java/org/apache/kafka/clients/admin/DescribeClusterResult.java
similarity index 95%
rename from clients/src/main/java/org/apache/kafka/clients/admin/DescribeClusterResults.java
rename to clients/src/main/java/org/apache/kafka/clients/admin/DescribeClusterResult.java
index a51c1c8e0d..34be2f4399 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/DescribeClusterResults.java
+++ b/clients/src/main/java/org/apache/kafka/clients/admin/DescribeClusterResult.java
@@ -27,12 +27,12 @@ import java.util.Collection;
  * The results of the describeCluster call.
  */
 @InterfaceStability.Unstable
-public class DescribeClusterResults {
+public class DescribeClusterResult {
     private final KafkaFuture<Collection<Node>> nodes;
     private final KafkaFuture<Node> controller;
     private final KafkaFuture<String> clusterId;
 
-    DescribeClusterResults(KafkaFuture<Collection<Node>> nodes,
+    DescribeClusterResult(KafkaFuture<Collection<Node>> nodes,
                            KafkaFuture<Node> controller,
                            KafkaFuture<String> clusterId) {
         this.nodes = nodes;
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/DescribeConfigsResults.java b/clients/src/main/java/org/apache/kafka/clients/admin/DescribeConfigsResult.java
similarity index 93%
rename from clients/src/main/java/org/apache/kafka/clients/admin/DescribeConfigsResults.java
rename to clients/src/main/java/org/apache/kafka/clients/admin/DescribeConfigsResult.java
index c29872aa3e..2379724b86 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/DescribeConfigsResults.java
+++ b/clients/src/main/java/org/apache/kafka/clients/admin/DescribeConfigsResult.java
@@ -19,17 +19,18 @@ package org.apache.kafka.clients.admin;
 
 import org.apache.kafka.common.KafkaFuture;
 import org.apache.kafka.common.annotation.InterfaceStability;
+import org.apache.kafka.common.config.ConfigResource;
 
 import java.util.HashMap;
 import java.util.Map;
 import java.util.concurrent.ExecutionException;
 
 @InterfaceStability.Unstable
-public class DescribeConfigsResults {
+public class DescribeConfigsResult {
 
     private final Map<ConfigResource, KafkaFuture<Config>> futures;
 
-    DescribeConfigsResults(Map<ConfigResource, KafkaFuture<Config>> futures) {
+    DescribeConfigsResult(Map<ConfigResource, KafkaFuture<Config>> futures) {
         this.futures = futures;
     }
 
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResults.java b/clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResult.java
similarity index 95%
rename from clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResults.java
rename to clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResult.java
index 5c309bb796..e7cd6b3567 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResults.java
+++ b/clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResult.java
@@ -28,10 +28,10 @@ import java.util.concurrent.ExecutionException;
  * The results of the describeTopic call.
  */
 @InterfaceStability.Unstable
-public class DescribeTopicsResults {
+public class DescribeTopicsResult {
     private final Map<String, KafkaFuture<TopicDescription>> futures;
 
-    DescribeTopicsResults(Map<String, KafkaFuture<TopicDescription>> futures) {
+    DescribeTopicsResult(Map<String, KafkaFuture<TopicDescription>> futures) {
         this.futures = futures;
     }
 
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java b/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java
index 98fc3f3b3f..9fa0cadb6f 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java
+++ b/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java
@@ -25,14 +25,18 @@ import org.apache.kafka.clients.KafkaClient;
 import org.apache.kafka.clients.Metadata;
 import org.apache.kafka.clients.NetworkClient;
 import org.apache.kafka.clients.NodeApiVersions;
-import org.apache.kafka.clients.admin.DeleteAclsResults.FilterResult;
-import org.apache.kafka.clients.admin.DeleteAclsResults.FilterResults;
+import org.apache.kafka.clients.admin.DeleteAclsResult.FilterResult;
+import org.apache.kafka.clients.admin.DeleteAclsResult.FilterResults;
 import org.apache.kafka.common.Cluster;
 import org.apache.kafka.common.KafkaException;
 import org.apache.kafka.common.KafkaFuture;
 import org.apache.kafka.common.Node;
 import org.apache.kafka.common.PartitionInfo;
+import org.apache.kafka.common.TopicPartitionInfo;
+import org.apache.kafka.common.acl.AclBinding;
+import org.apache.kafka.common.acl.AclBindingFilter;
 import org.apache.kafka.common.annotation.InterfaceStability;
+import org.apache.kafka.common.config.ConfigResource;
 import org.apache.kafka.common.errors.ApiException;
 import org.apache.kafka.common.errors.BrokerNotAvailableException;
 import org.apache.kafka.common.errors.DisconnectException;
@@ -995,7 +999,7 @@ public class KafkaAdminClient extends AdminClient {
     }
 
     @Override
-    public CreateTopicResults createTopics(final Collection<NewTopic> newTopics,
+    public CreateTopicsResult createTopics(final Collection<NewTopic> newTopics,
                                            final CreateTopicsOptions options) {
         final Map<String, KafkaFutureImpl<Void>> topicFutures = new HashMap<>(newTopics.size());
         final Map<String, CreateTopicsRequest.TopicDetails> topicsMap = new HashMap<>(newTopics.size());
@@ -1046,11 +1050,11 @@ public class KafkaAdminClient extends AdminClient {
                 completeAllExceptionally(topicFutures.values(), throwable);
             }
         }, now);
-        return new CreateTopicResults(new HashMap<String, KafkaFuture<Void>>(topicFutures));
+        return new CreateTopicsResult(new HashMap<String, KafkaFuture<Void>>(topicFutures));
     }
 
     @Override
-    public DeleteTopicResults deleteTopics(final Collection<String> topicNames,
+    public DeleteTopicsResult deleteTopics(final Collection<String> topicNames,
                                            DeleteTopicsOptions options) {
         final Map<String, KafkaFutureImpl<Void>> topicFutures = new HashMap<>(topicNames.size());
         for (String topicName : topicNames) {
@@ -1099,11 +1103,11 @@ public class KafkaAdminClient extends AdminClient {
                 completeAllExceptionally(topicFutures.values(), throwable);
             }
         }, now);
-        return new DeleteTopicResults(new HashMap<String, KafkaFuture<Void>>(topicFutures));
+        return new DeleteTopicsResult(new HashMap<String, KafkaFuture<Void>>(topicFutures));
     }
 
     @Override
-    public ListTopicsResults listTopics(final ListTopicsOptions options) {
+    public ListTopicsResult listTopics(final ListTopicsOptions options) {
         final KafkaFutureImpl<Map<String, TopicListing>> topicListingFuture = new KafkaFutureImpl<>();
         final long now = time.milliseconds();
         runnable.call(new Call("listTopics", calcDeadlineMs(now, options.timeoutMs()),
@@ -1132,11 +1136,11 @@ public class KafkaAdminClient extends AdminClient {
                 topicListingFuture.completeExceptionally(throwable);
             }
         }, now);
-        return new ListTopicsResults(topicListingFuture);
+        return new ListTopicsResult(topicListingFuture);
     }
 
     @Override
-    public DescribeTopicsResults describeTopics(final Collection<String> topicNames, DescribeTopicsOptions options) {
+    public DescribeTopicsResult describeTopics(final Collection<String> topicNames, DescribeTopicsOptions options) {
         final Map<String, KafkaFutureImpl<TopicDescription>> topicFutures = new HashMap<>(topicNames.size());
         final ArrayList<String> topicNamesList = new ArrayList<>();
         for (String topicName : topicNames) {
@@ -1190,11 +1194,11 @@ public class KafkaAdminClient extends AdminClient {
                 completeAllExceptionally(topicFutures.values(), throwable);
             }
         }, now);
-        return new DescribeTopicsResults(new HashMap<String, KafkaFuture<TopicDescription>>(topicFutures));
+        return new DescribeTopicsResult(new HashMap<String, KafkaFuture<TopicDescription>>(topicFutures));
     }
 
     @Override
-    public DescribeClusterResults describeCluster(DescribeClusterOptions options) {
+    public DescribeClusterResult describeCluster(DescribeClusterOptions options) {
         final KafkaFutureImpl<Collection<Node>> describeClusterFuture = new KafkaFutureImpl<>();
         final KafkaFutureImpl<Node> controllerFuture = new KafkaFutureImpl<>();
         final KafkaFutureImpl<String> clusterIdFuture = new KafkaFutureImpl<>();
@@ -1223,11 +1227,11 @@ public class KafkaAdminClient extends AdminClient {
             }
         }, now);
 
-        return new DescribeClusterResults(describeClusterFuture, controllerFuture, clusterIdFuture);
+        return new DescribeClusterResult(describeClusterFuture, controllerFuture, clusterIdFuture);
     }
 
     @Override
-    public ApiVersionsResults apiVersions(Collection<Node> nodes, ApiVersionsOptions options) {
+    public ApiVersionsResult apiVersions(Collection<Node> nodes, ApiVersionsOptions options) {
         final long now = time.milliseconds();
         final long deadlineMs = calcDeadlineMs(now, options.timeoutMs());
         Map<Node, KafkaFuture<NodeApiVersions>> nodeFutures = new HashMap<>();
@@ -1254,12 +1258,12 @@ public class KafkaAdminClient extends AdminClient {
                     }
                 }, now);
         }
-        return new ApiVersionsResults(nodeFutures);
+        return new ApiVersionsResult(nodeFutures);
 
     }
 
     @Override
-    public DescribeAclsResults describeAcls(final AclBindingFilter filter, DescribeAclsOptions options) {
+    public DescribeAclsResult describeAcls(final AclBindingFilter filter, DescribeAclsOptions options) {
         final long now = time.milliseconds();
         final KafkaFutureImpl<Collection<AclBinding>> future = new KafkaFutureImpl<>();
         runnable.call(new Call("describeAcls", calcDeadlineMs(now, options.timeoutMs()),
@@ -1285,11 +1289,11 @@ public class KafkaAdminClient extends AdminClient {
                 future.completeExceptionally(throwable);
             }
         }, now);
-        return new DescribeAclsResults(future);
+        return new DescribeAclsResult(future);
     }
 
     @Override
-    public CreateAclsResults createAcls(Collection<AclBinding> acls, CreateAclsOptions options) {
+    public CreateAclsResult createAcls(Collection<AclBinding> acls, CreateAclsOptions options) {
         final long now = time.milliseconds();
         final Map<AclBinding, KafkaFutureImpl<Void>> futures = new HashMap<>();
         final List<AclCreation> aclCreations = new ArrayList<>();
@@ -1340,11 +1344,11 @@ public class KafkaAdminClient extends AdminClient {
                 completeAllExceptionally(futures.values(), throwable);
             }
         }, now);
-        return new CreateAclsResults(new HashMap<AclBinding, KafkaFuture<Void>>(futures));
+        return new CreateAclsResult(new HashMap<AclBinding, KafkaFuture<Void>>(futures));
     }
 
     @Override
-    public DeleteAclsResults deleteAcls(Collection<AclBindingFilter> filters, DeleteAclsOptions options) {
+    public DeleteAclsResult deleteAcls(Collection<AclBindingFilter> filters, DeleteAclsOptions options) {
         final long now = time.milliseconds();
         final Map<AclBindingFilter, KafkaFutureImpl<FilterResults>> futures = new HashMap<>();
         final List<AclBindingFilter> filterList = new ArrayList<>();
@@ -1392,11 +1396,11 @@ public class KafkaAdminClient extends AdminClient {
                 completeAllExceptionally(futures.values(), throwable);
             }
         }, now);
-        return new DeleteAclsResults(new HashMap<AclBindingFilter, KafkaFuture<FilterResults>>(futures));
+        return new DeleteAclsResult(new HashMap<AclBindingFilter, KafkaFuture<FilterResults>>(futures));
     }
 
     @Override
-    public DescribeConfigsResults describeConfigs(Collection<ConfigResource> configResources, final DescribeConfigsOptions options) {
+    public DescribeConfigsResult describeConfigs(Collection<ConfigResource> configResources, final DescribeConfigsOptions options) {
         final Map<ConfigResource, KafkaFutureImpl<Config>> singleRequestFutures = new HashMap<>();
         final Collection<Resource> singleRequestResources = new ArrayList<>(configResources.size());
 
@@ -1487,7 +1491,7 @@ public class KafkaAdminClient extends AdminClient {
         Map<ConfigResource, KafkaFutureImpl<Config>> allFutures = new HashMap<>(configResources.size());
         allFutures.putAll(singleRequestFutures);
         allFutures.putAll(brokerFutures);
-        return new DescribeConfigsResults(new HashMap<ConfigResource, KafkaFuture<Config>>(allFutures));
+        return new DescribeConfigsResult(new HashMap<ConfigResource, KafkaFuture<Config>>(allFutures));
     }
 
     private Resource configResourceToResource(ConfigResource configResource) {
@@ -1506,7 +1510,7 @@ public class KafkaAdminClient extends AdminClient {
     }
 
     @Override
-    public AlterConfigsResults alterConfigs(Map<ConfigResource, Config> configs, final AlterConfigsOptions options) {
+    public AlterConfigsResult alterConfigs(Map<ConfigResource, Config> configs, final AlterConfigsOptions options) {
         final Map<ConfigResource, KafkaFutureImpl<Void>> futures = new HashMap<>(configs.size());
         for (ConfigResource configResource : configs.keySet()) {
             futures.put(configResource, new KafkaFutureImpl<Void>());
@@ -1548,6 +1552,6 @@ public class KafkaAdminClient extends AdminClient {
                 completeAllExceptionally(futures.values(), throwable);
             }
         }, now);
-        return new AlterConfigsResults(new HashMap<ConfigResource, KafkaFuture<Void>>(futures));
+        return new AlterConfigsResult(new HashMap<ConfigResource, KafkaFuture<Void>>(futures));
     }
 }
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/ListTopicsResults.java b/clients/src/main/java/org/apache/kafka/clients/admin/ListTopicsResult.java
similarity index 95%
rename from clients/src/main/java/org/apache/kafka/clients/admin/ListTopicsResults.java
rename to clients/src/main/java/org/apache/kafka/clients/admin/ListTopicsResult.java
index 7e9448de32..7b2fae88a3 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/ListTopicsResults.java
+++ b/clients/src/main/java/org/apache/kafka/clients/admin/ListTopicsResult.java
@@ -27,10 +27,10 @@ import java.util.Map;
  * The result of the listTopics call.
  */
 @InterfaceStability.Unstable
-public class ListTopicsResults {
+public class ListTopicsResult {
     final KafkaFuture<Map<String, TopicListing>> future;
 
-    ListTopicsResults(KafkaFuture<Map<String, TopicListing>> future) {
+    ListTopicsResult(KafkaFuture<Map<String, TopicListing>> future) {
         this.future = future;
     }
 
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/TopicDescription.java b/clients/src/main/java/org/apache/kafka/clients/admin/TopicDescription.java
index f13dfff74a..bf1431eeb8 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/TopicDescription.java
+++ b/clients/src/main/java/org/apache/kafka/clients/admin/TopicDescription.java
@@ -17,6 +17,7 @@
 
 package org.apache.kafka.clients.admin;
 
+import org.apache.kafka.common.TopicPartitionInfo;
 import org.apache.kafka.common.utils.Utils;
 
 import java.util.NavigableMap;
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/TopicPartitionInfo.java b/clients/src/main/java/org/apache/kafka/common/TopicPartitionInfo.java
similarity index 95%
rename from clients/src/main/java/org/apache/kafka/clients/admin/TopicPartitionInfo.java
rename to clients/src/main/java/org/apache/kafka/common/TopicPartitionInfo.java
index 5241602ba5..70352bddf2 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/TopicPartitionInfo.java
+++ b/clients/src/main/java/org/apache/kafka/common/TopicPartitionInfo.java
@@ -15,9 +15,8 @@
  * limitations under the License.
  */
 
-package org.apache.kafka.clients.admin;
+package org.apache.kafka.common;
 
-import org.apache.kafka.common.Node;
 import org.apache.kafka.common.utils.Utils;
 
 import java.util.List;
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/AccessControlEntry.java b/clients/src/main/java/org/apache/kafka/common/acl/AccessControlEntry.java
similarity index 98%
rename from clients/src/main/java/org/apache/kafka/clients/admin/AccessControlEntry.java
rename to clients/src/main/java/org/apache/kafka/common/acl/AccessControlEntry.java
index 0c36a2184c..68464b3549 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/AccessControlEntry.java
+++ b/clients/src/main/java/org/apache/kafka/common/acl/AccessControlEntry.java
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.kafka.clients.admin;
+package org.apache.kafka.common.acl;
 
 import java.util.Objects;
 
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/AccessControlEntryData.java b/clients/src/main/java/org/apache/kafka/common/acl/AccessControlEntryData.java
similarity index 98%
rename from clients/src/main/java/org/apache/kafka/clients/admin/AccessControlEntryData.java
rename to clients/src/main/java/org/apache/kafka/common/acl/AccessControlEntryData.java
index 81f57ad58c..cf692639bd 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/AccessControlEntryData.java
+++ b/clients/src/main/java/org/apache/kafka/common/acl/AccessControlEntryData.java
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.kafka.clients.admin;
+package org.apache.kafka.common.acl;
 
 import java.util.Objects;
 
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/AccessControlEntryFilter.java b/clients/src/main/java/org/apache/kafka/common/acl/AccessControlEntryFilter.java
similarity index 98%
rename from clients/src/main/java/org/apache/kafka/clients/admin/AccessControlEntryFilter.java
rename to clients/src/main/java/org/apache/kafka/common/acl/AccessControlEntryFilter.java
index 0ec1027ec3..7817865c2b 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/AccessControlEntryFilter.java
+++ b/clients/src/main/java/org/apache/kafka/common/acl/AccessControlEntryFilter.java
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.kafka.clients.admin;
+package org.apache.kafka.common.acl;
 
 import java.util.Objects;
 
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/AclBinding.java b/clients/src/main/java/org/apache/kafka/common/acl/AclBinding.java
similarity index 96%
rename from clients/src/main/java/org/apache/kafka/clients/admin/AclBinding.java
rename to clients/src/main/java/org/apache/kafka/common/acl/AclBinding.java
index 45761b46a4..91c1c79ed9 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/AclBinding.java
+++ b/clients/src/main/java/org/apache/kafka/common/acl/AclBinding.java
@@ -14,7 +14,10 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-package org.apache.kafka.clients.admin;
+
+package org.apache.kafka.common.acl;
+
+import org.apache.kafka.common.resource.Resource;
 
 import java.util.Objects;
 
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/AclBindingFilter.java b/clients/src/main/java/org/apache/kafka/common/acl/AclBindingFilter.java
similarity index 95%
rename from clients/src/main/java/org/apache/kafka/clients/admin/AclBindingFilter.java
rename to clients/src/main/java/org/apache/kafka/common/acl/AclBindingFilter.java
index 5e4142db25..765fac27fd 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/AclBindingFilter.java
+++ b/clients/src/main/java/org/apache/kafka/common/acl/AclBindingFilter.java
@@ -14,7 +14,11 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-package org.apache.kafka.clients.admin;
+
+package org.apache.kafka.common.acl;
+
+import org.apache.kafka.common.resource.ResourceFilter;
+import org.apache.kafka.common.resource.ResourceType;
 
 import java.util.Objects;
 
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/AclOperation.java b/clients/src/main/java/org/apache/kafka/common/acl/AclOperation.java
similarity index 98%
rename from clients/src/main/java/org/apache/kafka/clients/admin/AclOperation.java
rename to clients/src/main/java/org/apache/kafka/common/acl/AclOperation.java
index 0c3ff50d05..c63320d9cc 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/AclOperation.java
+++ b/clients/src/main/java/org/apache/kafka/common/acl/AclOperation.java
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.kafka.clients.admin;
+package org.apache.kafka.common.acl;
 
 import java.util.HashMap;
 import java.util.Locale;
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/AclPermissionType.java b/clients/src/main/java/org/apache/kafka/common/acl/AclPermissionType.java
similarity index 98%
rename from clients/src/main/java/org/apache/kafka/clients/admin/AclPermissionType.java
rename to clients/src/main/java/org/apache/kafka/common/acl/AclPermissionType.java
index 9181c6b95f..8c7793882e 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/AclPermissionType.java
+++ b/clients/src/main/java/org/apache/kafka/common/acl/AclPermissionType.java
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.kafka.clients.admin;
+package org.apache.kafka.common.acl;
 
 import java.util.HashMap;
 import java.util.Locale;
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/ConfigResource.java b/clients/src/main/java/org/apache/kafka/common/config/ConfigResource.java
similarity index 97%
rename from clients/src/main/java/org/apache/kafka/clients/admin/ConfigResource.java
rename to clients/src/main/java/org/apache/kafka/common/config/ConfigResource.java
index 61af4a844e..5395671a78 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/ConfigResource.java
+++ b/clients/src/main/java/org/apache/kafka/common/config/ConfigResource.java
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.kafka.clients.admin;
+package org.apache.kafka.common.config;
 
 public final class ConfigResource {
 
diff --git a/clients/src/main/java/org/apache/kafka/common/config/TopicConfig.java b/clients/src/main/java/org/apache/kafka/common/config/TopicConfig.java
new file mode 100755
index 0000000000..554c97b89a
--- /dev/null
+++ b/clients/src/main/java/org/apache/kafka/common/config/TopicConfig.java
@@ -0,0 +1,163 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.kafka.common.config;
+
+/**
+ * Keys that can be used to configure a topic.  These keys are useful when creating or reconfiguring a
+ * topic using the AdminClient.
+ *
+ * The intended pattern is for broker configs to include a `log.` prefix. For example, to set the default broker
+ * cleanup policy, one would set log.cleanup.policy instead of cleanup.policy. Unfortunately, there are many cases
+ * where this pattern is not followed.
+ */
+// This is a public API, so we should not remove or alter keys without a discussion and a deprecation period.
+// Eventually this should replace LogConfig.scala.
+public class TopicConfig {
+    public static final String SEGMENT_BYTES_CONFIG = "segment.bytes";
+    public static final String SEGMENT_BYTES_DOC = "This configuration controls the segment file size for " +
+        "the log. Retention and cleaning is always done a file at a time so a larger segment size means " +
+        "fewer files but less granular control over retention.";
+
+    public static final String SEGMENT_MS_CONFIG = "segment.ms";
+    public static final String SEGMENT_MS_DOC = "This configuration controls the period of time after " +
+        "which Kafka will force the log to roll even if the segment file isn't full to ensure that retention " +
+        "can delete or compact old data.";
+
+    public static final String SEGMENT_JITTER_MS_CONFIG = "segment.jitter.ms";
+    public static final String SEGMENT_JITTER_MS_DOC = "The maximum random jitter subtracted from the scheduled " +
+        "segment roll time to avoid thundering herds of segment rolling";
+
+    public static final String SEGMENT_INDEX_BYTES_CONFIG = "segment.index.bytes";
+    public static final String SEGMENT_INDEX_BYTES_DOC = "This configuration controls the size of the index that " +
+        "maps offsets to file positions. We preallocate this index file and shrink it only after log " +
+        "rolls. You generally should not need to change this setting.";
+
+    public static final String FLUSH_MESSAGES_INTERVAL_CONFIG = "flush.messages";
+    public static final String FLUSH_MESSAGES_INTERVAL_DOC = "This setting allows specifying an interval at " +
+        "which we will force an fsync of data written to the log. For example if this was set to 1 " +
+        "we would fsync after every message; if it were 5 we would fsync after every five messages. " +
+        "In general we recommend you not set this and use replication for durability and allow the " +
+        "operating system's background flush capabilities as it is more efficient. This setting can " +
+        "be overridden on a per-topic basis (see <a href=\"#topic-config\">the per-topic configuration section</a>).";
+
+    public static final String FLUSH_MS_CONFIG = "flush.ms";
+    public static final String FLUSH_MS_DOC = "This setting allows specifying a time interval at which we will " +
+        "force an fsync of data written to the log. For example if this was set to 1000 " +
+        "we would fsync after 1000 ms had passed. In general we recommend you not set " +
+        "this and use replication for durability and allow the operating system's background " +
+        "flush capabilities as it is more efficient.";
+
+    public static final String RETENTION_BYTES_CONFIG = "retention.bytes";
+    public static final String RETENTION_BYTES_DOC = "This configuration controls the maximum size a log can grow " +
+        "to before we will discard old log segments to free up space if we are using the " +
+        "\"delete\" retention policy. By default there is no size limit only a time limit.";
+
+    public static final String RETENTION_MS_CONFIG = "retention.ms";
+    public static final String RETENTION_MS_DOC = "This configuration controls the maximum time we will retain a " +
+        "log before we will discard old log segments to free up space if we are using the " +
+        "\"delete\" retention policy. This represents an SLA on how soon consumers must read " +
+        "their data.";
+
+    public static final String MAX_MESSAGE_BYTES_CONFIG = "max.message.bytes";
+    public static final String MAX_MESSAGE_BYTES_DOC = "This is largest message size Kafka will allow to be " +
+        "appended. Note that if you increase this size you must also increase your consumer's fetch size so " +
+        "they can fetch messages this large.";
+
+    public static final String INDEX_INTERVAL_BYTES_CONFIG = "index.interval.bytes";
+    public static final String INDEX_INTERVAL_BYTES_DOCS = "This setting controls how frequently " +
+        "Kafka adds an index entry to it's offset index. The default setting ensures that we index a " +
+        "message roughly every 4096 bytes. More indexing allows reads to jump closer to the exact " +
+        "position in the log but makes the index larger. You probably don't need to change this.";
+
+    public static final String FILE_DELETE_DELAY_MS_CONFIG = "file.delete.delay.ms";
+    public static final String FILE_DELETE_DELAY_MS_DOC = "The time to wait before deleting a file from the " +
+        "filesystem";
+
+    public static final String DELETE_RETENTION_MS_CONFIG = "delete.retention.ms";
+    public static final String DELETE_RETENTION_MS_DOC = "The amount of time to retain delete tombstone markers " +
+        "for <a href=\"#compaction\">log compacted</a> topics. This setting also gives a bound " +
+        "on the time in which a consumer must complete a read if they begin from offset 0 " +
+        "to ensure that they get a valid snapshot of the final stage (otherwise delete " +
+        "tombstones may be collected before they complete their scan).";
+
+    public static final String MIN_COMPACTION_LAG_MS_CONFIG = "min.compaction.lag.ms";
+    public static final String MIN_COMPACTION_LAG_MS_DOC = "The minimum time a message will remain " +
+        "uncompacted in the log. Only applicable for logs that are being compacted.";
+
+    public static final String MIN_CLEANABLE_DIRTY_RATIO_CONFIG = "min.cleanable.dirty.ratio";
+    public static final String MIN_CLEANABLE_DIRTY_RATIO_DOC = "This configuration controls how frequently " +
+        "the log compactor will attempt to clean the log (assuming <a href=\"#compaction\">log " +
+        "compaction</a> is enabled). By default we will avoid cleaning a log where more than " +
+        "50% of the log has been compacted. This ratio bounds the maximum space wasted in " +
+        "the log by duplicates (at 50% at most 50% of the log could be duplicates). A " +
+        "higher ratio will mean fewer, more efficient cleanings but will mean more wasted " +
+        "space in the log.";
+
+    public static final String CLEANUP_POLICY_CONFIG = "cleanup.policy";
+    public static final String CLEANUP_POLICY_COMPACT = "compact";
+    public static final String CLEANUP_POLICY_DELETE = "delete";
+    public static final String CLEANUP_POLICY_DOC = "A string that is either \"" + CLEANUP_POLICY_DELETE +
+        "\" or \"" + CLEANUP_POLICY_COMPACT + "\". This string designates the retention policy to use on " +
+        "old log segments. The default policy (\"delete\") will discard old segments when their retention " +
+        "time or size limit has been reached. The \"compact\" setting will enable <a href=\"#compaction\">log " +
+        "compaction</a> on the topic.";
+
+    public static final String UNCLEAN_LEADER_ELECTION_ENABLE_CONFIG = "unclean.leader.election.enable";
+    public static final String UNCLEAN_LEADER_ELECTION_ENABLE_DOC = "Indicates whether to enable replicas " +
+        "not in the ISR set to be elected as leader as a last resort, even though doing so may result in data " +
+        "loss.";
+
+    public static final String MIN_IN_SYNC_REPLICAS_CONFIG = "min.insync.replicas";
+    public static final String MIN_IN_SYNC_REPLICAS_DOC = "When a producer sets acks to \"all\" (or \"-1\"), " +
+        "this configuration specifies the minimum number of replicas that must acknowledge " +
+        "a write for the write to be considered successful. If this minimum cannot be met, " +
+        "then the producer will raise an exception (either NotEnoughReplicas or " +
+        "NotEnoughReplicasAfterAppend).<br>When used together, min.insync.replicas and acks " +
+        "allow you to enforce greater durability guarantees. A typical scenario would be to " +
+        "create a topic with a replication factor of 3, set min.insync.replicas to 2, and " +
+        "produce with acks of \"all\". This will ensure that the producer raises an exception " +
+        "if a majority of replicas do not receive a write.";
+
+    public static final String COMPRESSION_TYPE_CONFIG = "compression.type";
+    public static final String COMPRESSION_TYPE_DOC = "Specify the final compression type for a given topic. " +
+        "This configuration accepts the standard compression codecs ('gzip', 'snappy', lz4). It additionally " +
+        "accepts 'uncompressed' which is equivalent to no compression; and 'producer' which means retain the " +
+        "original compression codec set by the producer.";
+
+    public static final String PREALLOCATE_CONFIG = "preallocate";
+    public static final String PREALLOCATE_DOC = "True if we should preallocate the file on disk when " +
+        "creating a new log segment.";
+
+    public static final String MESSAGE_FORMAT_VERSION_CONFIG = "message.format.version";
+    public static final String MESSAGE_FORMAT_VERSION_DOC = "Specify the message format version the broker " +
+        "will use to append messages to the logs. The value should be a valid ApiVersion. Some examples are: " +
+        "0.8.2, 0.9.0.0, 0.10.0, check ApiVersion for more details. By setting a particular message format " +
+        "version, the user is certifying that all the existing messages on disk are smaller or equal than the " +
+        "specified version. Setting this value incorrectly will cause consumers with older versions to break as " +
+        "they will receive messages with a format that they don't understand.";
+
+    public static final String MESSAGE_TIMESTAMP_TYPE_CONFIG = "message.timestamp.type";
+    public static final String MESSAGE_TIMESTAMP_TYPE_DOC = "Define whether the timestamp in the message is " +
+        "message create time or log append time. The value should be either `CreateTime` or `LogAppendTime`";
+
+    public static final String MESSAGE_TIMESTAMP_DIFFERENCE_MAX_MS_CONFIG = "message.timestamp.difference.max.ms";
+    public static final String MESSAGE_TIMESTAMP_DIFFERENCE_MAX_MS_DOC = "The maximum difference allowed between " +
+        "the timestamp when a broker receives a message and the timestamp specified in the message. If " +
+        "message.timestamp.type=CreateTime, a message will be rejected if the difference in timestamp " +
+        "exceeds this threshold. This configuration is ignored if message.timestamp.type=LogAppendTime.";
+}
diff --git a/clients/src/main/java/org/apache/kafka/common/requests/CreateAclsRequest.java b/clients/src/main/java/org/apache/kafka/common/requests/CreateAclsRequest.java
index f792bbdd6a..757b5af38d 100644
--- a/clients/src/main/java/org/apache/kafka/common/requests/CreateAclsRequest.java
+++ b/clients/src/main/java/org/apache/kafka/common/requests/CreateAclsRequest.java
@@ -17,11 +17,11 @@
 
 package org.apache.kafka.common.requests;
 
-import org.apache.kafka.clients.admin.AccessControlEntry;
-import org.apache.kafka.clients.admin.AclBinding;
-import org.apache.kafka.clients.admin.Resource;
+import org.apache.kafka.common.acl.AccessControlEntry;
+import org.apache.kafka.common.acl.AclBinding;
 import org.apache.kafka.common.protocol.ApiKeys;
 import org.apache.kafka.common.protocol.types.Struct;
+import org.apache.kafka.common.resource.Resource;
 import org.apache.kafka.common.utils.Utils;
 
 import java.nio.ByteBuffer;
diff --git a/clients/src/main/java/org/apache/kafka/common/requests/DeleteAclsRequest.java b/clients/src/main/java/org/apache/kafka/common/requests/DeleteAclsRequest.java
index 8a9ee19097..246b5e5a79 100644
--- a/clients/src/main/java/org/apache/kafka/common/requests/DeleteAclsRequest.java
+++ b/clients/src/main/java/org/apache/kafka/common/requests/DeleteAclsRequest.java
@@ -16,11 +16,11 @@
  */
 package org.apache.kafka.common.requests;
 
-import org.apache.kafka.clients.admin.AccessControlEntryFilter;
-import org.apache.kafka.clients.admin.AclBindingFilter;
-import org.apache.kafka.clients.admin.ResourceFilter;
+import org.apache.kafka.common.acl.AccessControlEntryFilter;
+import org.apache.kafka.common.acl.AclBindingFilter;
 import org.apache.kafka.common.protocol.ApiKeys;
 import org.apache.kafka.common.protocol.types.Struct;
+import org.apache.kafka.common.resource.ResourceFilter;
 import org.apache.kafka.common.utils.Utils;
 
 import java.nio.ByteBuffer;
diff --git a/clients/src/main/java/org/apache/kafka/common/requests/DeleteAclsResponse.java b/clients/src/main/java/org/apache/kafka/common/requests/DeleteAclsResponse.java
index 341021bfd6..796e2004e0 100644
--- a/clients/src/main/java/org/apache/kafka/common/requests/DeleteAclsResponse.java
+++ b/clients/src/main/java/org/apache/kafka/common/requests/DeleteAclsResponse.java
@@ -16,13 +16,13 @@
  */
 package org.apache.kafka.common.requests;
 
-import org.apache.kafka.clients.admin.AccessControlEntry;
-import org.apache.kafka.clients.admin.AclBinding;
-import org.apache.kafka.clients.admin.Resource;
+import org.apache.kafka.common.acl.AccessControlEntry;
+import org.apache.kafka.common.acl.AclBinding;
 import org.apache.kafka.common.errors.ApiException;
 import org.apache.kafka.common.protocol.ApiKeys;
 import org.apache.kafka.common.protocol.Errors;
 import org.apache.kafka.common.protocol.types.Struct;
+import org.apache.kafka.common.resource.Resource;
 import org.apache.kafka.common.utils.Utils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
diff --git a/clients/src/main/java/org/apache/kafka/common/requests/DescribeAclsRequest.java b/clients/src/main/java/org/apache/kafka/common/requests/DescribeAclsRequest.java
index 8d4eba6e3b..6573b6e9fb 100644
--- a/clients/src/main/java/org/apache/kafka/common/requests/DescribeAclsRequest.java
+++ b/clients/src/main/java/org/apache/kafka/common/requests/DescribeAclsRequest.java
@@ -16,12 +16,12 @@
  */
 package org.apache.kafka.common.requests;
 
-import org.apache.kafka.clients.admin.AccessControlEntryFilter;
-import org.apache.kafka.clients.admin.AclBinding;
-import org.apache.kafka.clients.admin.AclBindingFilter;
-import org.apache.kafka.clients.admin.ResourceFilter;
+import org.apache.kafka.common.acl.AccessControlEntryFilter;
+import org.apache.kafka.common.acl.AclBinding;
+import org.apache.kafka.common.acl.AclBindingFilter;
 import org.apache.kafka.common.protocol.ApiKeys;
 import org.apache.kafka.common.protocol.types.Struct;
+import org.apache.kafka.common.resource.ResourceFilter;
 
 import java.nio.ByteBuffer;
 import java.util.Collections;
diff --git a/clients/src/main/java/org/apache/kafka/common/requests/DescribeAclsResponse.java b/clients/src/main/java/org/apache/kafka/common/requests/DescribeAclsResponse.java
index 127493b8a9..cf21aa6450 100644
--- a/clients/src/main/java/org/apache/kafka/common/requests/DescribeAclsResponse.java
+++ b/clients/src/main/java/org/apache/kafka/common/requests/DescribeAclsResponse.java
@@ -17,12 +17,12 @@
 
 package org.apache.kafka.common.requests;
 
-import org.apache.kafka.clients.admin.AccessControlEntry;
-import org.apache.kafka.clients.admin.AclBinding;
-import org.apache.kafka.clients.admin.Resource;
+import org.apache.kafka.common.acl.AccessControlEntry;
+import org.apache.kafka.common.acl.AclBinding;
 import org.apache.kafka.common.protocol.ApiKeys;
 import org.apache.kafka.common.protocol.Errors;
 import org.apache.kafka.common.protocol.types.Struct;
+import org.apache.kafka.common.resource.Resource;
 
 import java.nio.ByteBuffer;
 import java.util.ArrayList;
diff --git a/clients/src/main/java/org/apache/kafka/common/requests/RequestUtils.java b/clients/src/main/java/org/apache/kafka/common/requests/RequestUtils.java
index f2ce55fc1a..fa235594b9 100644
--- a/clients/src/main/java/org/apache/kafka/common/requests/RequestUtils.java
+++ b/clients/src/main/java/org/apache/kafka/common/requests/RequestUtils.java
@@ -16,14 +16,14 @@
  */
 package org.apache.kafka.common.requests;
 
-import org.apache.kafka.clients.admin.AccessControlEntry;
-import org.apache.kafka.clients.admin.AccessControlEntryFilter;
-import org.apache.kafka.clients.admin.AclOperation;
-import org.apache.kafka.clients.admin.AclPermissionType;
-import org.apache.kafka.clients.admin.Resource;
-import org.apache.kafka.clients.admin.ResourceFilter;
-import org.apache.kafka.clients.admin.ResourceType;
+import org.apache.kafka.common.acl.AccessControlEntry;
+import org.apache.kafka.common.acl.AccessControlEntryFilter;
+import org.apache.kafka.common.acl.AclOperation;
+import org.apache.kafka.common.acl.AclPermissionType;
 import org.apache.kafka.common.protocol.types.Struct;
+import org.apache.kafka.common.resource.Resource;
+import org.apache.kafka.common.resource.ResourceFilter;
+import org.apache.kafka.common.resource.ResourceType;
 
 class RequestUtils {
     static Resource resourceFromStructFields(Struct struct) {
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/Resource.java b/clients/src/main/java/org/apache/kafka/common/resource/Resource.java
similarity index 98%
rename from clients/src/main/java/org/apache/kafka/clients/admin/Resource.java
rename to clients/src/main/java/org/apache/kafka/common/resource/Resource.java
index 9148aac789..2883a03601 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/Resource.java
+++ b/clients/src/main/java/org/apache/kafka/common/resource/Resource.java
@@ -14,7 +14,8 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-package org.apache.kafka.clients.admin;
+
+package org.apache.kafka.common.resource;
 
 import java.util.Objects;
 
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/ResourceFilter.java b/clients/src/main/java/org/apache/kafka/common/resource/ResourceFilter.java
similarity index 98%
rename from clients/src/main/java/org/apache/kafka/clients/admin/ResourceFilter.java
rename to clients/src/main/java/org/apache/kafka/common/resource/ResourceFilter.java
index 6f453b6e1b..572b7dcccc 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/ResourceFilter.java
+++ b/clients/src/main/java/org/apache/kafka/common/resource/ResourceFilter.java
@@ -14,7 +14,8 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-package org.apache.kafka.clients.admin;
+
+package org.apache.kafka.common.resource;
 
 import java.util.Objects;
 
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/ResourceType.java b/clients/src/main/java/org/apache/kafka/common/resource/ResourceType.java
similarity index 98%
rename from clients/src/main/java/org/apache/kafka/clients/admin/ResourceType.java
rename to clients/src/main/java/org/apache/kafka/common/resource/ResourceType.java
index ca4fa0a324..a1b7b2b26b 100644
--- a/clients/src/main/java/org/apache/kafka/clients/admin/ResourceType.java
+++ b/clients/src/main/java/org/apache/kafka/common/resource/ResourceType.java
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.kafka.clients.admin;
+package org.apache.kafka.common.resource;
 
 import java.util.HashMap;
 import java.util.Locale;
diff --git a/clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java b/clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java
index 2ef654d0cc..6f9e6af814 100644
--- a/clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java
+++ b/clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java
@@ -17,11 +17,17 @@
 package org.apache.kafka.clients.admin;
 
 import org.apache.kafka.clients.NodeApiVersions;
-import org.apache.kafka.clients.admin.DeleteAclsResults.FilterResults;
+import org.apache.kafka.clients.admin.DeleteAclsResult.FilterResults;
 import org.apache.kafka.common.Cluster;
 import org.apache.kafka.common.KafkaFuture;
 import org.apache.kafka.common.Node;
 import org.apache.kafka.common.PartitionInfo;
+import org.apache.kafka.common.acl.AccessControlEntry;
+import org.apache.kafka.common.acl.AccessControlEntryFilter;
+import org.apache.kafka.common.acl.AclBinding;
+import org.apache.kafka.common.acl.AclBindingFilter;
+import org.apache.kafka.common.acl.AclOperation;
+import org.apache.kafka.common.acl.AclPermissionType;
 import org.apache.kafka.common.errors.SecurityDisabledException;
 import org.apache.kafka.common.errors.TimeoutException;
 import org.apache.kafka.common.protocol.Errors;
@@ -33,6 +39,9 @@ import org.apache.kafka.common.requests.DeleteAclsResponse;
 import org.apache.kafka.common.requests.DeleteAclsResponse.AclDeletionResult;
 import org.apache.kafka.common.requests.DeleteAclsResponse.AclFilterResponse;
 import org.apache.kafka.common.requests.DescribeAclsResponse;
+import org.apache.kafka.common.resource.Resource;
+import org.apache.kafka.common.resource.ResourceFilter;
+import org.apache.kafka.common.resource.ResourceType;
 import org.junit.Rule;
 import org.junit.Test;
 import org.junit.rules.Timeout;
@@ -234,7 +243,7 @@ public class KafkaAdminClientTest {
                         add(new AclCreationResponse(null));
                         add(new AclCreationResponse(null));
                     }}));
-            CreateAclsResults results = env.adminClient().createAcls(new ArrayList<AclBinding>() {{
+            CreateAclsResult results = env.adminClient().createAcls(new ArrayList<AclBinding>() {{
                         add(ACL1);
                         add(ACL2);
                     }});
@@ -278,7 +287,7 @@ public class KafkaAdminClientTest {
                     add(new AclFilterResponse(new SecurityDisabledException("No security"),
                         Collections.<AclDeletionResult>emptySet()));
                 }}));
-            DeleteAclsResults results = env.adminClient().deleteAcls(new ArrayList<AclBindingFilter>() {{
+            DeleteAclsResult results = env.adminClient().deleteAcls(new ArrayList<AclBindingFilter>() {{
                         add(FILTER1);
                         add(FILTER2);
                     }});
diff --git a/clients/src/test/java/org/apache/kafka/clients/admin/AclBindingTest.java b/clients/src/test/java/org/apache/kafka/common/acl/AclBindingTest.java
similarity index 96%
rename from clients/src/test/java/org/apache/kafka/clients/admin/AclBindingTest.java
rename to clients/src/test/java/org/apache/kafka/common/acl/AclBindingTest.java
index 34cedb623d..e0a0598a4b 100644
--- a/clients/src/test/java/org/apache/kafka/clients/admin/AclBindingTest.java
+++ b/clients/src/test/java/org/apache/kafka/common/acl/AclBindingTest.java
@@ -14,8 +14,11 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-package org.apache.kafka.clients.admin;
+package org.apache.kafka.common.acl;
 
+import org.apache.kafka.common.resource.Resource;
+import org.apache.kafka.common.resource.ResourceFilter;
+import org.apache.kafka.common.resource.ResourceType;
 import org.junit.Test;
 
 import static org.junit.Assert.assertEquals;
diff --git a/clients/src/test/java/org/apache/kafka/clients/admin/AclOperationTest.java b/clients/src/test/java/org/apache/kafka/common/acl/AclOperationTest.java
similarity index 98%
rename from clients/src/test/java/org/apache/kafka/clients/admin/AclOperationTest.java
rename to clients/src/test/java/org/apache/kafka/common/acl/AclOperationTest.java
index 0e3441f04f..5f5a87cd8e 100644
--- a/clients/src/test/java/org/apache/kafka/clients/admin/AclOperationTest.java
+++ b/clients/src/test/java/org/apache/kafka/common/acl/AclOperationTest.java
@@ -14,7 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-package org.apache.kafka.clients.admin;
+package org.apache.kafka.common.acl;
 
 import org.junit.Test;
 
diff --git a/clients/src/test/java/org/apache/kafka/clients/admin/AclPermissionTypeTest.java b/clients/src/test/java/org/apache/kafka/common/acl/AclPermissionTypeTest.java
similarity index 98%
rename from clients/src/test/java/org/apache/kafka/clients/admin/AclPermissionTypeTest.java
rename to clients/src/test/java/org/apache/kafka/common/acl/AclPermissionTypeTest.java
index aa6deca738..8e7fdc70d0 100644
--- a/clients/src/test/java/org/apache/kafka/clients/admin/AclPermissionTypeTest.java
+++ b/clients/src/test/java/org/apache/kafka/common/acl/AclPermissionTypeTest.java
@@ -14,7 +14,8 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-package org.apache.kafka.clients.admin;
+
+package org.apache.kafka.common.acl;
 
 import org.junit.Test;
 
diff --git a/clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java b/clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java
index e0f48bf627..56f0215668 100644
--- a/clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java
+++ b/clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java
@@ -16,15 +16,12 @@
  */
 package org.apache.kafka.common.requests;
 
-import org.apache.kafka.clients.admin.AccessControlEntry;
-import org.apache.kafka.clients.admin.AccessControlEntryFilter;
-import org.apache.kafka.clients.admin.AclBinding;
-import org.apache.kafka.clients.admin.AclBindingFilter;
-import org.apache.kafka.clients.admin.AclOperation;
-import org.apache.kafka.clients.admin.AclPermissionType;
-import org.apache.kafka.clients.admin.Resource;
-import org.apache.kafka.clients.admin.ResourceFilter;
-import org.apache.kafka.clients.admin.ResourceType;
+import org.apache.kafka.common.acl.AccessControlEntry;
+import org.apache.kafka.common.acl.AccessControlEntryFilter;
+import org.apache.kafka.common.acl.AclBinding;
+import org.apache.kafka.common.acl.AclBindingFilter;
+import org.apache.kafka.common.acl.AclOperation;
+import org.apache.kafka.common.acl.AclPermissionType;
 import org.apache.kafka.common.Node;
 import org.apache.kafka.common.TopicPartition;
 import org.apache.kafka.common.errors.InvalidRequestException;
@@ -50,6 +47,9 @@ import org.apache.kafka.common.requests.CreateAclsRequest.AclCreation;
 import org.apache.kafka.common.requests.CreateAclsResponse.AclCreationResponse;
 import org.apache.kafka.common.requests.DeleteAclsResponse.AclDeletionResult;
 import org.apache.kafka.common.requests.DeleteAclsResponse.AclFilterResponse;
+import org.apache.kafka.common.resource.Resource;
+import org.apache.kafka.common.resource.ResourceFilter;
+import org.apache.kafka.common.resource.ResourceType;
 import org.apache.kafka.common.utils.Utils;
 import org.junit.Test;
 
diff --git a/clients/src/test/java/org/apache/kafka/clients/admin/ResourceTypeTest.java b/clients/src/test/java/org/apache/kafka/common/resource/ResourceTypeTest.java
similarity index 98%
rename from clients/src/test/java/org/apache/kafka/clients/admin/ResourceTypeTest.java
rename to clients/src/test/java/org/apache/kafka/common/resource/ResourceTypeTest.java
index af72de2956..4dc4cac7b8 100644
--- a/clients/src/test/java/org/apache/kafka/clients/admin/ResourceTypeTest.java
+++ b/clients/src/test/java/org/apache/kafka/common/resource/ResourceTypeTest.java
@@ -14,7 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-package org.apache.kafka.clients.admin;
+package org.apache.kafka.common.resource;
 
 import org.junit.Test;
 
diff --git a/core/src/main/scala/kafka/log/LogConfig.scala b/core/src/main/scala/kafka/log/LogConfig.scala
index 6a329d8962..ad50aabe15 100755
--- a/core/src/main/scala/kafka/log/LogConfig.scala
+++ b/core/src/main/scala/kafka/log/LogConfig.scala
@@ -24,7 +24,7 @@ import kafka.api.ApiVersion
 import kafka.message.{BrokerCompressionCodec, Message}
 import kafka.server.{KafkaConfig, ThrottledReplicaListValidator}
 import org.apache.kafka.common.errors.InvalidConfigurationException
-import org.apache.kafka.common.config.{AbstractConfig, ConfigDef}
+import org.apache.kafka.common.config.{AbstractConfig, ConfigDef, TopicConfig}
 import org.apache.kafka.common.record.TimestampType
 import org.apache.kafka.common.utils.Utils
 
@@ -100,107 +100,66 @@ object LogConfig {
     println(configDef.toHtmlTable)
   }
 
-  val Delete = "delete"
-  val Compact = "compact"
+  val SegmentBytesProp = TopicConfig.SEGMENT_BYTES_CONFIG
+  val SegmentMsProp = TopicConfig.SEGMENT_MS_CONFIG
+  val SegmentJitterMsProp = TopicConfig.SEGMENT_JITTER_MS_CONFIG
+  val SegmentIndexBytesProp = TopicConfig.SEGMENT_INDEX_BYTES_CONFIG
+  val FlushMessagesProp = TopicConfig.FLUSH_MESSAGES_INTERVAL_CONFIG
+  val FlushMsProp = TopicConfig.FLUSH_MS_CONFIG
+  val RetentionBytesProp = TopicConfig.RETENTION_BYTES_CONFIG
+  val RetentionMsProp = TopicConfig.RETENTION_MS_CONFIG
+  val MaxMessageBytesProp = TopicConfig.MAX_MESSAGE_BYTES_CONFIG
+  val IndexIntervalBytesProp = TopicConfig.INDEX_INTERVAL_BYTES_CONFIG
+  val DeleteRetentionMsProp = TopicConfig.DELETE_RETENTION_MS_CONFIG
+  val MinCompactionLagMsProp = TopicConfig.MIN_COMPACTION_LAG_MS_CONFIG
+  val FileDeleteDelayMsProp = TopicConfig.FILE_DELETE_DELAY_MS_CONFIG
+  val MinCleanableDirtyRatioProp = TopicConfig.MIN_CLEANABLE_DIRTY_RATIO_CONFIG
+  val CleanupPolicyProp = TopicConfig.CLEANUP_POLICY_CONFIG
+  val Delete = TopicConfig.CLEANUP_POLICY_DELETE
+  val Compact = TopicConfig.CLEANUP_POLICY_COMPACT
+  val UncleanLeaderElectionEnableProp = TopicConfig.UNCLEAN_LEADER_ELECTION_ENABLE_CONFIG
+  val MinInSyncReplicasProp = TopicConfig.MIN_IN_SYNC_REPLICAS_CONFIG
+  val CompressionTypeProp = TopicConfig.COMPRESSION_TYPE_CONFIG
+  val PreAllocateEnableProp = TopicConfig.PREALLOCATE_CONFIG
+  val MessageFormatVersionProp = TopicConfig.MESSAGE_FORMAT_VERSION_CONFIG
+  val MessageTimestampTypeProp = TopicConfig.MESSAGE_TIMESTAMP_TYPE_CONFIG
+  val MessageTimestampDifferenceMaxMsProp = TopicConfig.MESSAGE_TIMESTAMP_DIFFERENCE_MAX_MS_CONFIG
 
-  val SegmentBytesProp = "segment.bytes"
-  val SegmentMsProp = "segment.ms"
-  val SegmentJitterMsProp = "segment.jitter.ms"
-  val SegmentIndexBytesProp = "segment.index.bytes"
-  val FlushMessagesProp = "flush.messages"
-  val FlushMsProp = "flush.ms"
-  val RetentionBytesProp = "retention.bytes"
-  val RetentionMsProp = "retention.ms"
-  val MaxMessageBytesProp = "max.message.bytes"
-  val IndexIntervalBytesProp = "index.interval.bytes"
-  val DeleteRetentionMsProp = "delete.retention.ms"
-  val MinCompactionLagMsProp = "min.compaction.lag.ms"
-  val FileDeleteDelayMsProp = "file.delete.delay.ms"
-  val MinCleanableDirtyRatioProp = "min.cleanable.dirty.ratio"
-  val CleanupPolicyProp = "cleanup.policy"
-  val UncleanLeaderElectionEnableProp = "unclean.leader.election.enable"
-  val MinInSyncReplicasProp = "min.insync.replicas"
-  val CompressionTypeProp = "compression.type"
-  val PreAllocateEnableProp = "preallocate"
-  val MessageFormatVersionProp = "message.format.version"
-  val MessageTimestampTypeProp = "message.timestamp.type"
-  val MessageTimestampDifferenceMaxMsProp = "message.timestamp.difference.max.ms"
+  // Leave these out of TopicConfig for now as they are replication quota configs
   val LeaderReplicationThrottledReplicasProp = "leader.replication.throttled.replicas"
   val FollowerReplicationThrottledReplicasProp = "follower.replication.throttled.replicas"
 
-  val SegmentSizeDoc = "This configuration controls the segment file size for " +
-    "the log. Retention and cleaning is always done a file at a time so a larger " +
-    "segment size means fewer files but less granular control over retention."
-  val SegmentMsDoc = "This configuration controls the period of time after " +
-    "which Kafka will force the log to roll even if the segment file isn't full " +
-    "to ensure that retention can delete or compact old data."
-  val SegmentJitterMsDoc = "The maximum random jitter subtracted from the scheduled segment roll time to avoid" +
-    " thundering herds of segment rolling"
-  val FlushIntervalDoc = "This setting allows specifying an interval at which we " +
-    "will force an fsync of data written to the log. For example if this was set to 1 " +
-    "we would fsync after every message; if it were 5 we would fsync after every five " +
-    "messages. In general we recommend you not set this and use replication for " +
-    "durability and allow the operating system's background flush capabilities as it " +
-    "is more efficient. This setting can be overridden on a per-topic basis (see <a " +
-    "href=\"#topic-config\">the per-topic configuration section</a>)."
-  val FlushMsDoc = "This setting allows specifying a time interval at which we will " +
-    "force an fsync of data written to the log. For example if this was set to 1000 " +
-    "we would fsync after 1000 ms had passed. In general we recommend you not set " +
-    "this and use replication for durability and allow the operating system's background " +
-    "flush capabilities as it is more efficient."
-  val RetentionSizeDoc = "This configuration controls the maximum size a log can grow " +
-    "to before we will discard old log segments to free up space if we are using the " +
-    "\"delete\" retention policy. By default there is no size limit only a time limit."
-  val RetentionMsDoc = "This configuration controls the maximum time we will retain a " +
-    "log before we will discard old log segments to free up space if we are using the " +
-    "\"delete\" retention policy. This represents an SLA on how soon consumers must read " +
-    "their data."
-  val MaxIndexSizeDoc = "This configuration controls the size of the index that maps " +
-    "offsets to file positions. We preallocate this index file and shrink it only after log " +
-    "rolls. You generally should not need to change this setting."
-  val MaxMessageSizeDoc = "This is largest message size Kafka will allow to be appended. Note that if you increase" +
-    " this size you must also increase your consumer's fetch size so they can fetch messages this large."
-  val IndexIntervalDoc = "This setting controls how frequently Kafka adds an index " +
-    "entry to it's offset index. The default setting ensures that we index a message " +
-    "roughly every 4096 bytes. More indexing allows reads to jump closer to the exact " +
-    "position in the log but makes the index larger. You probably don't need to change " +
-    "this."
-  val FileDeleteDelayMsDoc = "The time to wait before deleting a file from the filesystem"
-  val DeleteRetentionMsDoc = "The amount of time to retain delete tombstone markers " +
-    "for <a href=\"#compaction\">log compacted</a> topics. This setting also gives a bound " +
-    "on the time in which a consumer must complete a read if they begin from offset 0 " +
-    "to ensure that they get a valid snapshot of the final stage (otherwise delete " +
-    "tombstones may be collected before they complete their scan)."
-  val MinCompactionLagMsDoc = "The minimum time a message will remain uncompacted in the log. " +
-    "Only applicable for logs that are being compacted."
-  val MinCleanableRatioDoc = "This configuration controls how frequently the log " +
-    "compactor will attempt to clean the log (assuming <a href=\"#compaction\">log " +
-    "compaction</a> is enabled). By default we will avoid cleaning a log where more than " +
-    "50% of the log has been compacted. This ratio bounds the maximum space wasted in " +
-    "the log by duplicates (at 50% at most 50% of the log could be duplicates). A " +
-    "higher ratio will mean fewer, more efficient cleanings but will mean more wasted " +
-    "space in the log."
-  val CompactDoc = "A string that is either \"delete\" or \"compact\". This string " +
-    "designates the retention policy to use on old log segments. The default policy " +
-    "(\"delete\") will discard old segments when their retention time or size limit has " +
-    "been reached. The \"compact\" setting will enable <a href=\"#compaction\">log " +
-    "compaction</a> on the topic."
-  val UncleanLeaderElectionEnableDoc = "Indicates whether to enable replicas not in the ISR set to be elected as" +
-    " leader as a last resort, even though doing so may result in data loss"
-  val MinInSyncReplicasDoc = KafkaConfig.MinInSyncReplicasDoc
-  val CompressionTypeDoc = "Specify the final compression type for a given topic. This configuration accepts the " +
-    "standard compression codecs ('gzip', 'snappy', lz4). It additionally accepts 'uncompressed' which is equivalent to " +
-    "no compression; and 'producer' which means retain the original compression codec set by the producer."
-  val PreAllocateEnableDoc ="Should pre allocate file when create new segment?"
-  val MessageFormatVersionDoc = KafkaConfig.LogMessageFormatVersionDoc
-  val MessageTimestampTypeDoc = KafkaConfig.LogMessageTimestampTypeDoc
-  val MessageTimestampDifferenceMaxMsDoc = "The maximum difference allowed between the timestamp when a broker receives " +
-    "a message and the timestamp specified in the message. If message.timestamp.type=CreateTime, a message will be rejected " +
-    "if the difference in timestamp exceeds this threshold. This configuration is ignored if message.timestamp.type=LogAppendTime."
-  val LeaderReplicationThrottledReplicasDoc = "A list of replicas for which log replication should be throttled on the leader side. The list should describe a set of " +
-    "replicas in the form [PartitionId]:[BrokerId],[PartitionId]:[BrokerId]:... or alternatively the wildcard '*' can be used to throttle all replicas for this topic."
-  val FollowerReplicationThrottledReplicasDoc = "A list of replicas for which log replication should be throttled on the follower side. The list should describe a set of " +
-    "replicas in the form [PartitionId]:[BrokerId],[PartitionId]:[BrokerId]:... or alternatively the wildcard '*' can be used to throttle all replicas for this topic."
+  val SegmentSizeDoc = TopicConfig.SEGMENT_BYTES_DOC
+  val SegmentMsDoc = TopicConfig.SEGMENT_MS_DOC
+  val SegmentJitterMsDoc = TopicConfig.SEGMENT_JITTER_MS_DOC
+  val MaxIndexSizeDoc = TopicConfig.SEGMENT_INDEX_BYTES_DOC
+  val FlushIntervalDoc = TopicConfig.FLUSH_MESSAGES_INTERVAL_DOC
+  val FlushMsDoc = TopicConfig.FLUSH_MS_DOC
+  val RetentionSizeDoc = TopicConfig.RETENTION_BYTES_DOC
+  val RetentionMsDoc = TopicConfig.RETENTION_MS_DOC
+  val MaxMessageSizeDoc = TopicConfig.MAX_MESSAGE_BYTES_DOC
+  val IndexIntervalDoc = TopicConfig.INDEX_INTERVAL_BYTES_DOCS
+  val FileDeleteDelayMsDoc = TopicConfig.FILE_DELETE_DELAY_MS_DOC
+  val DeleteRetentionMsDoc = TopicConfig.DELETE_RETENTION_MS_DOC
+  val MinCompactionLagMsDoc = TopicConfig.MIN_COMPACTION_LAG_MS_DOC
+  val MinCleanableRatioDoc = TopicConfig.MIN_CLEANABLE_DIRTY_RATIO_DOC
+  val CompactDoc = TopicConfig.CLEANUP_POLICY_DOC
+  val UncleanLeaderElectionEnableDoc = TopicConfig.UNCLEAN_LEADER_ELECTION_ENABLE_DOC
+  val MinInSyncReplicasDoc = TopicConfig.MIN_IN_SYNC_REPLICAS_DOC
+  val CompressionTypeDoc = TopicConfig.COMPRESSION_TYPE_DOC
+  val PreAllocateEnableDoc = TopicConfig.PREALLOCATE_DOC
+  val MessageFormatVersionDoc = TopicConfig.MESSAGE_FORMAT_VERSION_DOC
+  val MessageTimestampTypeDoc = TopicConfig.MESSAGE_TIMESTAMP_TYPE_DOC
+  val MessageTimestampDifferenceMaxMsDoc = TopicConfig.MESSAGE_TIMESTAMP_DIFFERENCE_MAX_MS_DOC
+
+  val LeaderReplicationThrottledReplicasDoc = "A list of replicas for which log replication should be throttled on " +
+    "the leader side. The list should describe a set of replicas in the form " +
+    "[PartitionId]:[BrokerId],[PartitionId]:[BrokerId]:... or alternatively the wildcard '*' can be used to throttle " +
+    "all replicas for this topic."
+  val FollowerReplicationThrottledReplicasDoc = "A list of replicas for which log replication should be throttled on " +
+    "the follower side. The list should describe a set of " + "replicas in the form " +
+    "[PartitionId]:[BrokerId],[PartitionId]:[BrokerId]:... or alternatively the wildcard '*' can be used to throttle " +
+    "all replicas for this topic."
 
   private class LogConfigDef extends ConfigDef {
 
diff --git a/core/src/main/scala/kafka/security/auth/Operation.scala b/core/src/main/scala/kafka/security/auth/Operation.scala
index 420c3eb031..d3a25b5a07 100644
--- a/core/src/main/scala/kafka/security/auth/Operation.scala
+++ b/core/src/main/scala/kafka/security/auth/Operation.scala
@@ -17,7 +17,7 @@
 package kafka.security.auth
 
 import kafka.common.{BaseEnum, KafkaException}
-import org.apache.kafka.clients.admin.AclOperation
+import org.apache.kafka.common.acl.AclOperation
 
 import scala.util.{Failure, Success, Try}
 
diff --git a/core/src/main/scala/kafka/security/auth/PermissionType.scala b/core/src/main/scala/kafka/security/auth/PermissionType.scala
index c4209e565e..ec99ae4cfd 100644
--- a/core/src/main/scala/kafka/security/auth/PermissionType.scala
+++ b/core/src/main/scala/kafka/security/auth/PermissionType.scala
@@ -17,7 +17,7 @@
 package kafka.security.auth
 
 import kafka.common.{BaseEnum, KafkaException}
-import org.apache.kafka.clients.admin.AclPermissionType
+import org.apache.kafka.common.acl.AclPermissionType
 
 import scala.util.{Failure, Success, Try}
 
diff --git a/core/src/main/scala/kafka/server/KafkaApis.scala b/core/src/main/scala/kafka/server/KafkaApis.scala
index d7f677313a..b780823c62 100644
--- a/core/src/main/scala/kafka/server/KafkaApis.scala
+++ b/core/src/main/scala/kafka/server/KafkaApis.scala
@@ -51,7 +51,8 @@ import org.apache.kafka.common.utils.{Time, Utils}
 import org.apache.kafka.common.{Node, TopicPartition}
 import org.apache.kafka.common.requests.SaslHandshakeResponse
 import org.apache.kafka.common.security.auth.KafkaPrincipal
-import org.apache.kafka.clients.admin.{AccessControlEntry, AclBinding, AclBindingFilter, AclOperation, AclPermissionType, Resource => AdminResource, ResourceType => AdminResourceType}
+import org.apache.kafka.common.resource.{Resource => AdminResource, ResourceType => AdminResourceType}
+import org.apache.kafka.common.acl.{AccessControlEntry, AclBinding, AclBindingFilter, AclOperation, AclPermissionType}
 
 import scala.collection._
 import scala.collection.JavaConverters._
diff --git a/core/src/test/scala/integration/kafka/api/KafkaAdminClientIntegrationTest.scala b/core/src/test/scala/integration/kafka/api/KafkaAdminClientIntegrationTest.scala
index c52594b642..065759ffe6 100644
--- a/core/src/test/scala/integration/kafka/api/KafkaAdminClientIntegrationTest.scala
+++ b/core/src/test/scala/integration/kafka/api/KafkaAdminClientIntegrationTest.scala
@@ -28,10 +28,14 @@ import org.apache.kafka.clients.admin._
 import kafka.utils.{Logging, TestUtils}
 import org.apache.kafka.clients.admin.NewTopic
 import org.apache.kafka.common.KafkaFuture
+import org.apache.kafka.common.acl.{AccessControlEntry, AclBinding, AclBindingFilter, AclOperation, AclPermissionType}
+import org.apache.kafka.common.config.ConfigResource
+import org.apache.kafka.common.errors.{InvalidRequestException, SecurityDisabledException, TopicExistsException}
 import org.apache.kafka.common.errors.{InvalidRequestException, SecurityDisabledException, TimeoutException, TopicExistsException}
 import org.apache.kafka.common.protocol.ApiKeys
 import org.junit.{After, Before, Rule, Test}
 import org.apache.kafka.common.requests.MetadataResponse
+import org.apache.kafka.common.resource.{Resource, ResourceType}
 import org.junit.rules.Timeout
 import org.junit.Assert._
 
diff --git a/core/src/test/scala/integration/kafka/api/SaslSslAdminClientIntegrationTest.scala b/core/src/test/scala/integration/kafka/api/SaslSslAdminClientIntegrationTest.scala
index cb43b099a9..d27b0bfeaf 100644
--- a/core/src/test/scala/integration/kafka/api/SaslSslAdminClientIntegrationTest.scala
+++ b/core/src/test/scala/integration/kafka/api/SaslSslAdminClientIntegrationTest.scala
@@ -18,8 +18,10 @@ import kafka.security.auth.SimpleAclAuthorizer
 import org.apache.kafka.common.protocol.SecurityProtocol
 import kafka.server.KafkaConfig
 import kafka.utils.{JaasTestUtils, TestUtils}
-import org.apache.kafka.clients.admin.{AccessControlEntry, AccessControlEntryFilter, AclBinding, AclBindingFilter, AclOperation, AclPermissionType, AdminClient, CreateAclsOptions, DeleteAclsOptions, Resource, ResourceFilter, ResourceType}
+import org.apache.kafka.clients.admin.{AdminClient, CreateAclsOptions, DeleteAclsOptions}
+import org.apache.kafka.common.acl.{AccessControlEntry, AccessControlEntryFilter, AclBinding, AclBindingFilter, AclOperation, AclPermissionType}
 import org.apache.kafka.common.errors.InvalidRequestException
+import org.apache.kafka.common.resource.{Resource, ResourceFilter, ResourceType}
 import org.junit.Assert.assertEquals
 import org.junit.{After, Assert, Before, Test}
 
diff --git a/core/src/test/scala/unit/kafka/server/RequestQuotaTest.scala b/core/src/test/scala/unit/kafka/server/RequestQuotaTest.scala
index fa2e55b534..b261cb2ee4 100644
--- a/core/src/test/scala/unit/kafka/server/RequestQuotaTest.scala
+++ b/core/src/test/scala/unit/kafka/server/RequestQuotaTest.scala
@@ -24,7 +24,8 @@ import kafka.log.LogConfig
 import kafka.network.RequestChannel.Session
 import kafka.security.auth._
 import kafka.utils.TestUtils
-import org.apache.kafka.clients.admin.{AccessControlEntry, AccessControlEntryFilter, AclBinding, AclBindingFilter, AclOperation, AclPermissionType, ResourceFilter, Resource => AdminResource, ResourceType => AdminResourceType}
+import org.apache.kafka.common.acl.{AccessControlEntry, AccessControlEntryFilter, AclBinding, AclBindingFilter, AclOperation, AclPermissionType}
+import org.apache.kafka.common.resource.{ResourceFilter, Resource => AdminResource, ResourceType => AdminResourceType}
 import org.apache.kafka.common.{Node, TopicPartition}
 import org.apache.kafka.common.metrics.{KafkaMetric, Quota, Sensor}
 import org.apache.kafka.common.network.{Authenticator, ListenerName, TransportLayer}
