diff --git a/core/src/main/scala/kafka/consumer/ConsumerFetcherManager.scala b/core/src/main/scala/kafka/consumer/ConsumerFetcherManager.scala
index 1e29da5def..d94b9ace82 100644
--- a/core/src/main/scala/kafka/consumer/ConsumerFetcherManager.scala
+++ b/core/src/main/scala/kafka/consumer/ConsumerFetcherManager.scala
@@ -88,7 +88,9 @@ class ConsumerFetcherManager(private val consumerIdString: String,
 
 
   override def createFetcherThread(fetcherId: Int, sourceBroker: Broker): AbstractFetcherThread = {
-    new ConsumerFetcherThread("ConsumerFetcherThread-%s-%d-%d".format(consumerIdString, fetcherId, sourceBroker.id), config, sourceBroker, this)
+    new ConsumerFetcherThread(
+      "ConsumerFetcherThread-%s-%d-%d".format(consumerIdString, fetcherId, sourceBroker.id),
+      config, sourceBroker, partitionMap, this)
   }
 
   def startConnections(topicInfos: Iterable[PartitionTopicInfo], cluster: Cluster) {
@@ -106,29 +108,15 @@ class ConsumerFetcherManager(private val consumerIdString: String,
   }
 
   def stopAllConnections() {
-    // first, clear noLeaderPartitionSet so that no more fetchers can be added to leader_finder_thread
     lock.lock()
+    // first, clear noLeaderPartitionSet so that no more fetchers can be added to leader_finder_thread
     noLeaderPartitionSet.clear()
-    lock.unlock()
-
-    // second, stop all existing fetchers
-    closeAllFetchers()
-
-    // finally clear partitionMap
-    lock.lock()
+    // second, clear partitionMap
     partitionMap = null
     lock.unlock()
-  }
 
-  def getPartitionTopicInfo(topicAndPartition: TopicAndPartition) : PartitionTopicInfo = {
-    var pti :PartitionTopicInfo =null
-    lock.lock()
-    try {
-      pti = partitionMap(topicAndPartition)
-    } finally {
-      lock.unlock()
-    }
-    pti      
+    // third, stop all existing fetchers
+    closeAllFetchers()
   }
 
   def addPartitionsWithError(partitionList: Iterable[TopicAndPartition]) {
diff --git a/core/src/main/scala/kafka/consumer/ConsumerFetcherThread.scala b/core/src/main/scala/kafka/consumer/ConsumerFetcherThread.scala
index d7e5a25a18..c902e20af1 100644
--- a/core/src/main/scala/kafka/consumer/ConsumerFetcherThread.scala
+++ b/core/src/main/scala/kafka/consumer/ConsumerFetcherThread.scala
@@ -27,6 +27,7 @@ import kafka.common.TopicAndPartition
 class ConsumerFetcherThread(name: String,
                             val config: ConsumerConfig,
                             sourceBroker: Broker,
+                            partitionMap: Map[TopicAndPartition, PartitionTopicInfo],
                             val consumerFetcherManager: ConsumerFetcherManager)
         extends AbstractFetcherThread(name = name, 
                                       clientId = config.clientId,
@@ -40,7 +41,7 @@ class ConsumerFetcherThread(name: String,
 
   // process fetched data
   def processPartitionData(topicAndPartition: TopicAndPartition, fetchOffset: Long, partitionData: FetchResponsePartitionData) {
-    val pti = consumerFetcherManager.getPartitionTopicInfo(topicAndPartition)
+    val pti = partitionMap(topicAndPartition)
     if (pti.getFetchOffset != fetchOffset)
       throw new RuntimeException("Offset doesn't match for topic %s partition: %d pti offset: %d fetch offset: %d"
                                 .format(topicAndPartition.topic, topicAndPartition.partition, pti.getFetchOffset, fetchOffset))
@@ -57,7 +58,7 @@ class ConsumerFetcherThread(name: String,
     }
     val request = OffsetRequest(Map(topicAndPartition -> PartitionOffsetRequestInfo(startTimestamp, 1)))
     val newOffset = simpleConsumer.getOffsetsBefore(request).partitionErrorAndOffsets(topicAndPartition).offsets.head
-    val pti = consumerFetcherManager.getPartitionTopicInfo(topicAndPartition)
+    val pti = partitionMap(topicAndPartition)
     pti.resetFetchOffset(newOffset)
     pti.resetConsumeOffset(newOffset)
     newOffset
diff --git a/core/src/main/scala/kafka/server/AbstractFetcherThread.scala b/core/src/main/scala/kafka/server/AbstractFetcherThread.scala
index 42681e23ea..d1b15d34f8 100644
--- a/core/src/main/scala/kafka/server/AbstractFetcherThread.scala
+++ b/core/src/main/scala/kafka/server/AbstractFetcherThread.scala
@@ -34,7 +34,7 @@ import java.util.concurrent.TimeUnit
 /**
  *  Abstract class for fetching data from multiple partitions from the same broker.
  */
-abstract class  AbstractFetcherThread(name: String, clientId: String, sourceBroker: Broker, socketTimeout: Int, socketBufferSize: Int,
+abstract class AbstractFetcherThread(name: String, clientId: String, sourceBroker: Broker, socketTimeout: Int, socketBufferSize: Int,
                                      fetchSize: Int, fetcherBrokerId: Int = -1, maxWait: Int = 0, minBytes: Int = 1)
   extends ShutdownableThread(name) {
 
