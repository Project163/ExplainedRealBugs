diff --git a/core/src/test/scala/integration/kafka/api/AuthorizerIntegrationTest.scala b/core/src/test/scala/integration/kafka/api/AuthorizerIntegrationTest.scala
index 3337d67ec7..377290db5f 100644
--- a/core/src/test/scala/integration/kafka/api/AuthorizerIntegrationTest.scala
+++ b/core/src/test/scala/integration/kafka/api/AuthorizerIntegrationTest.scala
@@ -2450,6 +2450,39 @@ class AuthorizerIntegrationTest extends BaseRequestTest {
     }
   }
 
+  @ParameterizedTest
+  @ValueSource(strings = Array("zk", "kraft"))
+  def testHostAddressBasedAcls(quorum: String): Unit = {
+    createTopicWithBrokerPrincipal(topic)
+    removeAllClientAcls()
+
+    val socket = connect(anySocketServer, listenerName)
+    try {
+      val acls = Set(
+        new AccessControlEntry(clientPrincipalString, socket.getLocalAddress.getHostAddress, DESCRIBE, ALLOW)
+      )
+
+      addAndVerifyAcls(acls, topicResource)
+
+      val metadataRequestTopic = new MetadataRequestTopic()
+        .setName(topic)
+
+      val metadataRequest = new MetadataRequest.Builder(new MetadataRequestData()
+        .setTopics(Collections.singletonList(metadataRequestTopic))
+        .setAllowAutoTopicCreation(false)
+      ).build()
+
+      val metadataResponse = sendAndReceive[MetadataResponse](metadataRequest, socket)
+      val topicResponseOpt = metadataResponse.topicMetadata().asScala.find(_.topic == topic)
+      assertTrue(topicResponseOpt.isDefined)
+
+      val topicResponse = topicResponseOpt.get
+      assertEquals(Errors.NONE, topicResponse.error)
+    } finally {
+      socket.close()
+    }
+  }
+
   private def testDescribeClusterClusterAuthorizedOperations(
     version: Short,
     expectedClusterAuthorizedOperations: Int
diff --git a/metadata/src/main/java/org/apache/kafka/metadata/authorizer/StandardAuthorizerData.java b/metadata/src/main/java/org/apache/kafka/metadata/authorizer/StandardAuthorizerData.java
index 8fee9f5e40..a70fa8ca45 100644
--- a/metadata/src/main/java/org/apache/kafka/metadata/authorizer/StandardAuthorizerData.java
+++ b/metadata/src/main/java/org/apache/kafka/metadata/authorizer/StandardAuthorizerData.java
@@ -373,7 +373,7 @@ public class StandardAuthorizerData {
         // The hostname should be cached in the InetAddress object, so calling this more
         // than once shouldn't be too expensive.
         if (!acl.host().equals(WILDCARD)) {
-            String host = requestContext.clientAddress().getHostName();
+            String host = requestContext.clientAddress().getHostAddress();
             if (!acl.host().equals(host)) return null;
         }
         // Check if the operation field matches. Here we hit a slight complication.
diff --git a/metadata/src/test/java/org/apache/kafka/metadata/authorizer/StandardAuthorizerTest.java b/metadata/src/test/java/org/apache/kafka/metadata/authorizer/StandardAuthorizerTest.java
index 734a96989c..ee09bb4c12 100644
--- a/metadata/src/test/java/org/apache/kafka/metadata/authorizer/StandardAuthorizerTest.java
+++ b/metadata/src/test/java/org/apache/kafka/metadata/authorizer/StandardAuthorizerTest.java
@@ -33,6 +33,7 @@ import org.apache.kafka.server.authorizer.AuthorizableRequestContext;
 import org.junit.jupiter.api.Test;
 import org.junit.jupiter.api.Timeout;
 
+import java.net.InetAddress;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
@@ -340,6 +341,57 @@ public class StandardAuthorizerTest {
             .build();
     }
 
+    @Test
+    public void testHostAddressAclValidation() throws Exception {
+        InetAddress host1 = InetAddress.getByName("192.168.1.1");
+        InetAddress host2 = InetAddress.getByName("192.168.1.2");
+
+        StandardAuthorizer authorizer = new StandardAuthorizer();
+        authorizer.configure(Collections.emptyMap());
+        List<StandardAcl> acls = Arrays.asList(
+            new StandardAcl(TOPIC, "foo", LITERAL, "User:alice", host1.getHostAddress(), READ, DENY),
+            new StandardAcl(TOPIC, "foo", LITERAL, "User:alice", "*", READ, ALLOW),
+            new StandardAcl(TOPIC, "bar", LITERAL, "User:bob", host2.getHostAddress(), READ, ALLOW),
+            new StandardAcl(TOPIC, "bar", LITERAL, "User:*", InetAddress.getLocalHost().getHostAddress(), DESCRIBE, ALLOW)
+        );
+
+        acls.forEach(acl -> {
+            StandardAclWithId aclWithId = withId(acl);
+            authorizer.addAcl(aclWithId.id(), aclWithId.acl());
+        });
+
+        List<Action> actions = Arrays.asList(
+            newAction(READ, TOPIC, "foo"),
+            newAction(READ, TOPIC, "bar"),
+            newAction(DESCRIBE, TOPIC, "bar")
+        );
+
+        assertEquals(Arrays.asList(ALLOWED, DENIED, ALLOWED), authorizer.authorize(
+            newRequestContext("alice", InetAddress.getLocalHost()), actions));
+
+        assertEquals(Arrays.asList(DENIED, DENIED, DENIED), authorizer.authorize(
+            newRequestContext("alice", host1), actions));
+
+        assertEquals(Arrays.asList(ALLOWED, DENIED, DENIED), authorizer.authorize(
+            newRequestContext("alice", host2), actions));
+
+        assertEquals(Arrays.asList(DENIED, DENIED, ALLOWED), authorizer.authorize(
+            newRequestContext("bob", InetAddress.getLocalHost()), actions));
+
+        assertEquals(Arrays.asList(DENIED, DENIED, DENIED), authorizer.authorize(
+            newRequestContext("bob", host1), actions));
+
+        assertEquals(Arrays.asList(DENIED, ALLOWED, ALLOWED), authorizer.authorize(
+            newRequestContext("bob", host2), actions));
+    }
+
+    private AuthorizableRequestContext newRequestContext(String principal, InetAddress clientAddress) throws Exception {
+        return new MockAuthorizableRequestContext.Builder()
+            .setPrincipal(new KafkaPrincipal(USER_TYPE, principal))
+            .setClientAddress(clientAddress)
+            .build();
+    }
+
     private static StandardAuthorizer createAuthorizerWithManyAcls() {
         StandardAuthorizer authorizer = new StandardAuthorizer();
         authorizer.configure(Collections.emptyMap());
