diff --git a/checkstyle/suppressions.xml b/checkstyle/suppressions.xml
index 82fd176daa..6de2b778dd 100644
--- a/checkstyle/suppressions.xml
+++ b/checkstyle/suppressions.xml
@@ -273,7 +273,7 @@
 
     <!-- metadata -->
     <suppress checks="ClassDataAbstractionCoupling"
-              files="(QuorumControllerTest|ReplicationControlManager|ReplicationControlManagerTest).java"/>
+              files="(QuorumController|QuorumControllerTest|ReplicationControlManager|ReplicationControlManagerTest).java"/>
     <suppress checks="ClassFanOutComplexity"
               files="(QuorumController|ReplicationControlManager|ReplicationControlManagerTest).java"/>
     <suppress checks="ParameterNumber"
diff --git a/core/src/main/scala/kafka/server/ControllerConfigurationValidator.scala b/core/src/main/scala/kafka/server/ControllerConfigurationValidator.scala
index dfb78b25e3..59a1f3c995 100644
--- a/core/src/main/scala/kafka/server/ControllerConfigurationValidator.scala
+++ b/core/src/main/scala/kafka/server/ControllerConfigurationValidator.scala
@@ -25,6 +25,7 @@ import org.apache.kafka.common.config.ConfigResource
 import org.apache.kafka.common.config.ConfigResource.Type.{BROKER, TOPIC}
 import org.apache.kafka.controller.ConfigurationValidator
 import org.apache.kafka.common.errors.InvalidRequestException
+import org.apache.kafka.common.internals.Topic
 
 import scala.collection.mutable
 
@@ -32,6 +33,10 @@ class ControllerConfigurationValidator extends ConfigurationValidator {
   override def validate(resource: ConfigResource, config: util.Map[String, String]): Unit = {
     resource.`type`() match {
       case TOPIC =>
+        if (resource.name().isEmpty()) {
+          throw new InvalidRequestException("Default topic resources are not allowed.")
+        }
+        Topic.validate(resource.name())
         val properties = new Properties()
         val nullTopicConfigs = new mutable.ArrayBuffer[String]()
         config.entrySet().forEach(e => {
@@ -47,7 +52,17 @@ class ControllerConfigurationValidator extends ConfigurationValidator {
         }
         LogConfig.validate(properties)
       case BROKER =>
-        // TODO: add broker configuration validation
+        if (resource.name().nonEmpty) {
+          val brokerId = try {
+            Integer.valueOf(resource.name())
+          } catch {
+            case _: NumberFormatException =>
+              throw new InvalidRequestException("Unable to parse broker name as a base 10 number.")
+          }
+          if (brokerId < 0) {
+            throw new InvalidRequestException("Invalid negative broker ID.")
+          }
+        }
       case _ =>
         // Note: we should never handle BROKER_LOGGER resources here, since changes to
         // those resources are not persisted in the metadata.
diff --git a/core/src/test/scala/unit/kafka/server/ControllerConfigurationValidatorTest.scala b/core/src/test/scala/unit/kafka/server/ControllerConfigurationValidatorTest.scala
index 3c85299d1d..bece00354c 100644
--- a/core/src/test/scala/unit/kafka/server/ControllerConfigurationValidatorTest.scala
+++ b/core/src/test/scala/unit/kafka/server/ControllerConfigurationValidatorTest.scala
@@ -22,12 +22,29 @@ import java.util.Collections.emptyMap
 
 import org.junit.jupiter.api.Test
 import org.apache.kafka.common.config.ConfigResource
-import org.apache.kafka.common.config.ConfigResource.Type.{BROKER_LOGGER, TOPIC}
+import org.apache.kafka.common.config.ConfigResource.Type.{BROKER, BROKER_LOGGER, TOPIC}
 import org.apache.kafka.common.config.TopicConfig.{SEGMENT_BYTES_CONFIG, SEGMENT_JITTER_MS_CONFIG, SEGMENT_MS_CONFIG}
-import org.apache.kafka.common.errors.{InvalidConfigurationException, InvalidRequestException}
+import org.apache.kafka.common.errors.{InvalidConfigurationException, InvalidRequestException, InvalidTopicException}
 import org.junit.jupiter.api.Assertions.{assertEquals, assertThrows}
 
 class ControllerConfigurationValidatorTest {
+  @Test
+  def testDefaultTopicResourceIsRejected(): Unit = {
+    val validator = new ControllerConfigurationValidator()
+    assertEquals("Default topic resources are not allowed.",
+        assertThrows(classOf[InvalidRequestException], () => validator.validate(
+        new ConfigResource(TOPIC, ""), emptyMap())). getMessage())
+  }
+
+  @Test
+  def testInvalidTopicNameRejected(): Unit = {
+    val validator = new ControllerConfigurationValidator()
+    assertEquals("Topic name \"(<-invalid->)\" is illegal, it contains a character " +
+      "other than ASCII alphanumerics, '.', '_' and '-'",
+        assertThrows(classOf[InvalidTopicException], () => validator.validate(
+          new ConfigResource(TOPIC, "(<-invalid->)"), emptyMap())). getMessage())
+  }
+
   @Test
   def testUnknownResourceType(): Unit = {
     val validator = new ControllerConfigurationValidator()
@@ -68,4 +85,24 @@ class ControllerConfigurationValidatorTest {
       assertThrows(classOf[InvalidConfigurationException], () => validator.validate(
         new ConfigResource(TOPIC, "foo"), config)). getMessage())
   }
+
+  @Test
+  def testInvalidBrokerEntity(): Unit = {
+    val validator = new ControllerConfigurationValidator()
+    val config = new TreeMap[String, String]()
+    config.put(SEGMENT_JITTER_MS_CONFIG, "1000")
+    assertEquals("Unable to parse broker name as a base 10 number.",
+      assertThrows(classOf[InvalidRequestException], () => validator.validate(
+        new ConfigResource(BROKER, "blah"), config)). getMessage())
+  }
+
+  @Test
+  def testInvalidNegativeBrokerId(): Unit = {
+    val validator = new ControllerConfigurationValidator()
+    val config = new TreeMap[String, String]()
+    config.put(SEGMENT_JITTER_MS_CONFIG, "1000")
+    assertEquals("Invalid negative broker ID.",
+      assertThrows(classOf[InvalidRequestException], () => validator.validate(
+        new ConfigResource(BROKER, "-1"), config)). getMessage())
+  }
 }
\ No newline at end of file
diff --git a/core/src/test/scala/unit/kafka/server/DynamicConfigChangeTest.scala b/core/src/test/scala/unit/kafka/server/DynamicConfigChangeTest.scala
index 4b39824105..8565385146 100644
--- a/core/src/test/scala/unit/kafka/server/DynamicConfigChangeTest.scala
+++ b/core/src/test/scala/unit/kafka/server/DynamicConfigChangeTest.scala
@@ -17,39 +17,51 @@
 package kafka.server
 
 import kafka.api.KAFKA_3_0_IV1
-
 import java.net.InetAddress
 import java.nio.charset.StandardCharsets
+import java.util
+import java.util.Collections.{singletonList, singletonMap}
 import java.util.Properties
 import java.util.concurrent.ExecutionException
+
 import kafka.integration.KafkaServerTestHarness
 import kafka.log.LogConfig._
 import kafka.utils._
 import kafka.server.Constants._
 import kafka.zk.ConfigEntityChangeNotificationZNode
 import org.apache.kafka.clients.CommonClientConfigs
+import org.apache.kafka.clients.admin.AlterConfigOp.OpType.SET
 import org.apache.kafka.clients.admin.{Admin, AlterConfigOp, ConfigEntry}
 import org.apache.kafka.common.TopicPartition
 import org.apache.kafka.common.config.ConfigResource
 import org.apache.kafka.common.config.internals.QuotaConfigs
-import org.apache.kafka.common.errors.UnknownTopicOrPartitionException
+import org.apache.kafka.common.errors.{InvalidRequestException, UnknownTopicOrPartitionException}
 import org.apache.kafka.common.metrics.Quota
+import org.apache.kafka.common.quota.ClientQuotaAlteration.Op
+import org.apache.kafka.common.quota.ClientQuotaEntity.{CLIENT_ID, IP, USER}
+import org.apache.kafka.common.quota.{ClientQuotaAlteration, ClientQuotaEntity}
 import org.apache.kafka.common.record.{CompressionType, RecordVersion}
+import org.apache.kafka.common.security.auth.KafkaPrincipal
 import org.easymock.EasyMock
 import org.junit.jupiter.api.Assertions._
 import org.junit.jupiter.api.Test
+import org.junit.jupiter.params.ParameterizedTest
+import org.junit.jupiter.params.provider.ValueSource
 
 import scala.annotation.nowarn
 import scala.collection.{Map, Seq}
 import scala.jdk.CollectionConverters._
 
 class DynamicConfigChangeTest extends KafkaServerTestHarness {
-  def generateConfigs = List(KafkaConfig.fromProps(TestUtils.createBrokerConfig(0, zkConnect)))
-
-  @Test
-  def testConfigChange(): Unit = {
-    assertTrue(this.servers.head.dynamicConfigHandlers.contains(ConfigType.Topic),
-      "Should contain a ConfigHandler for topics")
+  def generateConfigs = List(KafkaConfig.fromProps(TestUtils.createBrokerConfig(0, zkConnectOrNull)))
+
+  @ParameterizedTest
+  @ValueSource(strings = Array("zk", "kraft"))
+  def testConfigChange(quorum: String): Unit = {
+    if (!isKRaftTest()) {
+      assertTrue(this.servers.head.dynamicConfigHandlers.contains(ConfigType.Topic),
+        "Should contain a ConfigHandler for topics")
+    }
     val oldVal: java.lang.Long = 100000L
     val newVal: java.lang.Long = 200000L
     val tp = new TopicPartition("test", 0)
@@ -57,47 +69,75 @@ class DynamicConfigChangeTest extends KafkaServerTestHarness {
     logProps.put(FlushMessagesProp, oldVal.toString)
     createTopic(tp.topic, 1, 1, logProps)
     TestUtils.retry(10000) {
-      val logOpt = this.servers.head.logManager.getLog(tp)
+      val logOpt = this.brokers.head.logManager.getLog(tp)
       assertTrue(logOpt.isDefined)
       assertEquals(oldVal, logOpt.get.config.flushInterval)
     }
-    logProps.put(FlushMessagesProp, newVal.toString)
-    adminZkClient.changeTopicConfig(tp.topic, logProps)
+    if (isKRaftTest()) {
+      val admin = createAdminClient()
+      try {
+        val resource = new ConfigResource(ConfigResource.Type.TOPIC, tp.topic())
+        val op = new AlterConfigOp(new ConfigEntry(FlushMessagesProp, newVal.toString()),
+          SET)
+        admin.incrementalAlterConfigs(Map(resource -> List(op).asJavaCollection).asJava).all.get
+      } finally {
+        admin.close()
+      }
+    } else {
+      val newProps = new Properties()
+      newProps.setProperty(FlushMessagesProp, newVal.toString())
+      adminZkClient.changeTopicConfig(tp.topic, newProps)
+    }
     TestUtils.retry(10000) {
-      assertEquals(newVal, this.servers.head.logManager.getLog(tp).get.config.flushInterval)
+      assertEquals(newVal, this.brokers.head.logManager.getLog(tp).get.config.flushInterval)
     }
   }
 
-  @Test
-  def testDynamicTopicConfigChange(): Unit = {
+  @ParameterizedTest
+  @ValueSource(strings = Array("zk", "kraft"))
+  def testDynamicTopicConfigChange(quorum: String): Unit = {
     val tp = new TopicPartition("test", 0)
     val oldSegmentSize = 1000
     val logProps = new Properties()
     logProps.put(SegmentBytesProp, oldSegmentSize.toString)
     createTopic(tp.topic, 1, 1, logProps)
     TestUtils.retry(10000) {
-      val logOpt = this.servers.head.logManager.getLog(tp)
+      val logOpt = this.brokers.head.logManager.getLog(tp)
       assertTrue(logOpt.isDefined)
       assertEquals(oldSegmentSize, logOpt.get.config.segmentSize)
     }
 
-    val log = servers.head.logManager.getLog(tp).get
-
     val newSegmentSize = 2000
-    logProps.put(SegmentBytesProp, newSegmentSize.toString)
-    adminZkClient.changeTopicConfig(tp.topic, logProps)
+    if (isKRaftTest()) {
+      val admin = createAdminClient()
+      try {
+        val resource = new ConfigResource(ConfigResource.Type.TOPIC, tp.topic())
+        val op = new AlterConfigOp(new ConfigEntry(SegmentBytesProp, newSegmentSize.toString()),
+          SET)
+        admin.incrementalAlterConfigs(Map(resource -> List(op).asJavaCollection).asJava).all.get
+      } finally {
+        admin.close()
+      }
+    } else {
+      val newProps = new Properties()
+      newProps.put(SegmentBytesProp, newSegmentSize.toString)
+      adminZkClient.changeTopicConfig(tp.topic, newProps)
+    }
+
+    val log = brokers.head.logManager.getLog(tp).get
     TestUtils.retry(10000) {
       assertEquals(newSegmentSize, log.config.segmentSize)
     }
 
-    (1 to 50).foreach(i => TestUtils.produceMessage(servers, tp.topic, i.toString))
+    (1 to 50).foreach(i => TestUtils.produceMessage(brokers, tp.topic, i.toString))
     // Verify that the new config is used for all segments
     assertTrue(log.logSegments.forall(_.size > 1000), "Log segment size change not applied")
   }
 
   @nowarn("cat=deprecation")
-  @Test
-  def testMessageFormatVersionChange(): Unit = {
+  @ParameterizedTest
+  @ValueSource(strings = Array("zk"))
+  def testMessageFormatVersionChange(quorum: String): Unit = {
     val tp = new TopicPartition("test", 0)
     val logProps = new Properties()
     logProps.put(MessageFormatVersionProp, "0.10.2")
@@ -122,79 +162,102 @@ class DynamicConfigChangeTest extends KafkaServerTestHarness {
     assertEquals(RecordVersion.V2, log.config.recordVersion)
   }
 
-  private def testQuotaConfigChange(user: String, clientId: String, rootEntityType: String, configEntityName: String): Unit = {
-    assertTrue(this.servers.head.dynamicConfigHandlers.contains(rootEntityType), "Should contain a ConfigHandler for " + rootEntityType)
-    val props = new Properties()
-    props.put(QuotaConfigs.PRODUCER_BYTE_RATE_OVERRIDE_CONFIG, "1000")
-    props.put(QuotaConfigs.CONSUMER_BYTE_RATE_OVERRIDE_CONFIG, "2000")
-
-    val quotaManagers = servers.head.dataPlaneRequestProcessor.quotas
-    rootEntityType match {
-      case ConfigType.Client => adminZkClient.changeClientIdConfig(configEntityName, props)
-      case _ => adminZkClient.changeUserOrUserClientIdConfig(configEntityName, props)
-    }
-
-    TestUtils.retry(10000) {
-      val overrideProducerQuota = quotaManagers.produce.quota(user, clientId)
-      val overrideConsumerQuota = quotaManagers.fetch.quota(user, clientId)
+  private def testQuotaConfigChange(entity: ClientQuotaEntity,
+                                    user: KafkaPrincipal,
+                                    clientId: String): Unit = {
+    val admin = createAdminClient()
+    try {
+      val alterations = util.Arrays.asList(
+        new ClientQuotaAlteration(entity, util.Arrays.asList(
+          new Op(QuotaConfigs.PRODUCER_BYTE_RATE_OVERRIDE_CONFIG, 1000),
+          new Op(QuotaConfigs.CONSUMER_BYTE_RATE_OVERRIDE_CONFIG, 2000))))
+      admin.alterClientQuotas(alterations).all().get()
 
-      assertEquals(Quota.upperBound(1000),
-        overrideProducerQuota, s"User $user clientId $clientId must have overridden producer quota of 1000")
-      assertEquals(Quota.upperBound(2000),
-        overrideConsumerQuota, s"User $user clientId $clientId must have overridden consumer quota of 2000")
-    }
+      val quotaManagers = brokers.head.dataPlaneRequestProcessor.quotas
+      TestUtils.retry(10000) {
+        val overrideProducerQuota = quotaManagers.produce.quota(user, clientId)
+        val overrideConsumerQuota = quotaManagers.fetch.quota(user, clientId)
+        assertEquals(Quota.upperBound(1000),
+          overrideProducerQuota, s"User $user clientId $clientId must have overridden producer quota of 1000")
+        assertEquals(Quota.upperBound(2000),
+          overrideConsumerQuota, s"User $user clientId $clientId must have overridden consumer quota of 2000")
+      }
 
-    val defaultProducerQuota = Long.MaxValue.asInstanceOf[Double]
-    val defaultConsumerQuota = Long.MaxValue.asInstanceOf[Double]
+      val defaultProducerQuota = Long.MaxValue.asInstanceOf[Double]
+      val defaultConsumerQuota = Long.MaxValue.asInstanceOf[Double]
 
-    val emptyProps = new Properties()
-    rootEntityType match {
-      case ConfigType.Client => adminZkClient.changeClientIdConfig(configEntityName, emptyProps)
-      case _ => adminZkClient.changeUserOrUserClientIdConfig(configEntityName, emptyProps)
-    }
-    TestUtils.retry(10000) {
-      val producerQuota = quotaManagers.produce.quota(user, clientId)
-      val consumerQuota = quotaManagers.fetch.quota(user, clientId)
+      val removals = util.Arrays.asList(
+        new ClientQuotaAlteration(entity, util.Arrays.asList(
+          new Op(QuotaConfigs.PRODUCER_BYTE_RATE_OVERRIDE_CONFIG, null),
+          new Op(QuotaConfigs.CONSUMER_BYTE_RATE_OVERRIDE_CONFIG, null))))
+      admin.alterClientQuotas(removals).all().get()
+      TestUtils.retry(10000) {
+        val producerQuota = quotaManagers.produce.quota(user, clientId)
+        val consumerQuota = quotaManagers.fetch.quota(user, clientId)
 
-      assertEquals(Quota.upperBound(defaultProducerQuota),
-        producerQuota, s"User $user clientId $clientId must have reset producer quota to " + defaultProducerQuota)
-      assertEquals(Quota.upperBound(defaultConsumerQuota),
-        consumerQuota, s"User $user clientId $clientId must have reset consumer quota to " + defaultConsumerQuota)
+        assertEquals(Quota.upperBound(defaultProducerQuota),
+          producerQuota, s"User $user clientId $clientId must have reset producer quota to " + defaultProducerQuota)
+        assertEquals(Quota.upperBound(defaultConsumerQuota),
+          consumerQuota, s"User $user clientId $clientId must have reset consumer quota to " + defaultConsumerQuota)
+      }
+    } finally {
+      admin.close()
     }
   }
 
-  @Test
-  def testClientIdQuotaConfigChange(): Unit = {
-    testQuotaConfigChange("ANONYMOUS", "testClient", ConfigType.Client, "testClient")
+  @ParameterizedTest
+  @ValueSource(strings = Array("zk", "kraft"))
+  def testClientIdQuotaConfigChange(quorum: String): Unit = {
+    val m = new util.HashMap[String, String]
+    m.put(CLIENT_ID, "testClient")
+    testQuotaConfigChange(new ClientQuotaEntity(m), KafkaPrincipal.ANONYMOUS, "testClient")
   }
 
-  @Test
-  def testUserQuotaConfigChange(): Unit = {
-    testQuotaConfigChange("ANONYMOUS", "testClient", ConfigType.User, "ANONYMOUS")
+  @ParameterizedTest
+  @ValueSource(strings = Array("zk", "kraft"))
+  def testUserQuotaConfigChange(quorum: String): Unit = {
+    val m = new util.HashMap[String, String]
+    m.put(USER, "ANONYMOUS")
+    testQuotaConfigChange(new ClientQuotaEntity(m), KafkaPrincipal.ANONYMOUS, "testClient")
   }
 
-  @Test
-  def testUserClientIdQuotaChange(): Unit = {
-    testQuotaConfigChange("ANONYMOUS", "testClient", ConfigType.User, "ANONYMOUS/clients/testClient")
+  @ParameterizedTest
+  @ValueSource(strings = Array("zk", "kraft"))
+  def testUserClientIdQuotaChange(quorum: String): Unit = {
+    val m = new util.HashMap[String, String]
+    m.put(USER, "ANONYMOUS")
+    m.put(CLIENT_ID, "testClient")
+    testQuotaConfigChange(new ClientQuotaEntity(m), KafkaPrincipal.ANONYMOUS, "testClient")
   }
 
-  @Test
-  def testDefaultClientIdQuotaConfigChange(): Unit = {
-    testQuotaConfigChange("ANONYMOUS", "testClient", ConfigType.Client, "<default>")
+  @ParameterizedTest
+  @ValueSource(strings = Array("zk", "kraft"))
+  def testDefaultClientIdQuotaConfigChange(quorum: String): Unit = {
+    val m = new util.HashMap[String, String]
+    m.put(CLIENT_ID, null)
+    testQuotaConfigChange(new ClientQuotaEntity(m), KafkaPrincipal.ANONYMOUS, "testClient")
   }
 
-  @Test
-  def testDefaultUserQuotaConfigChange(): Unit = {
-    testQuotaConfigChange("ANONYMOUS", "testClient", ConfigType.User, "<default>")
+  @ParameterizedTest
+  @ValueSource(strings = Array("zk", "kraft"))
+  def testDefaultUserQuotaConfigChange(quorum: String): Unit = {
+    val m = new util.HashMap[String, String]
+    m.put(USER, null)
+    testQuotaConfigChange(new ClientQuotaEntity(m), KafkaPrincipal.ANONYMOUS, "testClient")
   }
 
-  @Test
-  def testDefaultUserClientIdQuotaConfigChange(): Unit = {
-    testQuotaConfigChange("ANONYMOUS", "testClient", ConfigType.User, "<default>/clients/<default>")
+  @ParameterizedTest
+  @ValueSource(strings = Array("zk", "kraft"))
+  def testDefaultUserClientIdQuotaConfigChange(quorum: String): Unit = {
+    val m = new util.HashMap[String, String]
+    m.put(USER, null)
+    m.put(CLIENT_ID, null)
+    testQuotaConfigChange(new ClientQuotaEntity(m), KafkaPrincipal.ANONYMOUS, "testClient")
   }
 
-  @Test
-  def testQuotaInitialization(): Unit = {
+  @ParameterizedTest
+  @ValueSource(strings = Array("zk"))
+  def testQuotaInitialization(quorum: String): Unit = {
     val server = servers.head
     val clientIdProps = new Properties()
     server.shutdown()
@@ -224,85 +287,105 @@ class DynamicConfigChangeTest extends KafkaServerTestHarness {
     assertEquals(Quota.upperBound(200000),  quotaManagers.fetch.quota("ANONYMOUS", "overriddenUserClientId"))
   }
 
-  @Test
-  def testIpHandlerUnresolvableAddress(): Unit = {
-    val configHandler = new IpConfigHandler(null)
-    val props: Properties = new Properties()
-    props.put(QuotaConfigs.IP_CONNECTION_RATE_OVERRIDE_CONFIG, "1")
+  @ParameterizedTest
+  @ValueSource(strings = Array("zk", "kraft"))
+  def testIpQuotaInitialization(quorum: String): Unit = {
+    val broker = brokers.head
+    if (isKRaftTest()) {
+      val admin = createAdminClient()
+      try {
+        val alterations = util.Arrays.asList(
+          new ClientQuotaAlteration(new ClientQuotaEntity(singletonMap(IP, null)),
+            singletonList(new Op(QuotaConfigs.IP_CONNECTION_RATE_OVERRIDE_CONFIG, 20))),
+          new ClientQuotaAlteration(new ClientQuotaEntity(singletonMap(IP, "1.2.3.4")),
+            singletonList(new Op(QuotaConfigs.IP_CONNECTION_RATE_OVERRIDE_CONFIG, 10))))
+        admin.alterClientQuotas(alterations).all().get()
+      } finally {
+        admin.close()
+      }
+    } else {
+      broker.shutdown()
 
-    assertThrows(classOf[IllegalArgumentException], () => configHandler.processConfigChanges("illegal-hostname", props))
-  }
+      val ipDefaultProps = new Properties()
+      ipDefaultProps.put(QuotaConfigs.IP_CONNECTION_RATE_OVERRIDE_CONFIG, "20")
+      adminZkClient.changeIpConfig(ConfigEntityName.Default, ipDefaultProps)
 
-  @Test
-  def testIpQuotaInitialization(): Unit = {
-    val server = servers.head
-    val ipOverrideProps = new Properties()
-    ipOverrideProps.put(QuotaConfigs.IP_CONNECTION_RATE_OVERRIDE_CONFIG, "10")
-    val ipDefaultProps = new Properties()
-    ipDefaultProps.put(QuotaConfigs.IP_CONNECTION_RATE_OVERRIDE_CONFIG, "20")
-    server.shutdown()
-
-    adminZkClient.changeIpConfig(ConfigEntityName.Default, ipDefaultProps)
-    adminZkClient.changeIpConfig("1.2.3.4", ipOverrideProps)
+      val ipOverrideProps = new Properties()
+      ipOverrideProps.put(QuotaConfigs.IP_CONNECTION_RATE_OVERRIDE_CONFIG, "10")
+      adminZkClient.changeIpConfig("1.2.3.4", ipOverrideProps)
 
-    // Remove config change znodes to force quota initialization only through loading of ip quotas
-    zkClient.getChildren(ConfigEntityChangeNotificationZNode.path).foreach { p =>
-      zkClient.deletePath(ConfigEntityChangeNotificationZNode.path + "/" + p)
+      // Remove config change znodes to force quota initialization only through loading of ip quotas
+      zkClient.getChildren(ConfigEntityChangeNotificationZNode.path).foreach { p =>
+        zkClient.deletePath(ConfigEntityChangeNotificationZNode.path + "/" + p)
+      }
+      broker.startup()
+    }
+    TestUtils.retry(10000) {
+      val connectionQuotas = broker.socketServer.connectionQuotas
+      assertEquals(10L, connectionQuotas.connectionRateForIp(InetAddress.getByName("1.2.3.4")))
+      assertEquals(20L, connectionQuotas.connectionRateForIp(InetAddress.getByName("2.4.6.8")))
     }
-    server.startup()
-
-    val connectionQuotas = server.socketServer.connectionQuotas
-    assertEquals(10L, connectionQuotas.connectionRateForIp(InetAddress.getByName("1.2.3.4")))
-    assertEquals(20L, connectionQuotas.connectionRateForIp(InetAddress.getByName("2.4.6.8")))
   }
 
-  @Test
-  def testIpQuotaConfigChange(): Unit = {
-    val ipOverrideProps = new Properties()
-    ipOverrideProps.put(QuotaConfigs.IP_CONNECTION_RATE_OVERRIDE_CONFIG, "10")
-    val ipDefaultProps = new Properties()
-    ipDefaultProps.put(QuotaConfigs.IP_CONNECTION_RATE_OVERRIDE_CONFIG, "20")
-
-    val overrideQuotaIp = InetAddress.getByName("1.2.3.4")
-    val defaultQuotaIp = InetAddress.getByName("2.3.4.5")
-    adminZkClient.changeIpConfig(ConfigEntityName.Default, ipDefaultProps)
-    adminZkClient.changeIpConfig(overrideQuotaIp.getHostAddress, ipOverrideProps)
-
-    val connectionQuotas = servers.head.socketServer.connectionQuotas
-
-    def verifyConnectionQuota(ip: InetAddress, expectedQuota: Integer) = {
-      TestUtils.retry(10000) {
-        val quota = connectionQuotas.connectionRateForIp(ip)
-        assertEquals(expectedQuota, quota, s"Unexpected quota for IP $ip")
+  @ParameterizedTest
+  @ValueSource(strings = Array("zk", "kraft"))
+  def testIpQuotaConfigChange(quorum: String): Unit = {
+    val admin = createAdminClient()
+    try {
+      val alterations = util.Arrays.asList(
+        new ClientQuotaAlteration(new ClientQuotaEntity(singletonMap(IP, null)),
+          singletonList(new Op(QuotaConfigs.IP_CONNECTION_RATE_OVERRIDE_CONFIG, 20))),
+        new ClientQuotaAlteration(new ClientQuotaEntity(singletonMap(IP, "1.2.3.4")),
+          singletonList(new Op(QuotaConfigs.IP_CONNECTION_RATE_OVERRIDE_CONFIG, 10))))
+      admin.alterClientQuotas(alterations).all().get()
+
+      def verifyConnectionQuota(ip: InetAddress, expectedQuota: Integer) = {
+        val connectionQuotas = brokers.head.socketServer.connectionQuotas
+        TestUtils.retry(10000) {
+          val quota = connectionQuotas.connectionRateForIp(ip)
+          assertEquals(expectedQuota, quota, s"Unexpected quota for IP $ip")
+        }
       }
-    }
 
-    verifyConnectionQuota(overrideQuotaIp, 10)
-    verifyConnectionQuota(defaultQuotaIp, 20)
+      val overrideQuotaIp = InetAddress.getByName("1.2.3.4")
+      verifyConnectionQuota(overrideQuotaIp, 10)
 
-    val emptyProps = new Properties()
-    adminZkClient.changeIpConfig(overrideQuotaIp.getHostAddress, emptyProps)
-    verifyConnectionQuota(overrideQuotaIp, 20)
+      val defaultQuotaIp = InetAddress.getByName("2.3.4.5")
+      verifyConnectionQuota(defaultQuotaIp, 20)
 
-    adminZkClient.changeIpConfig(ConfigEntityName.Default, emptyProps)
-    verifyConnectionQuota(overrideQuotaIp, QuotaConfigs.IP_CONNECTION_RATE_DEFAULT)
+      val deletions1 = util.Arrays.asList(
+        new ClientQuotaAlteration(new ClientQuotaEntity(singletonMap(IP, "1.2.3.4")),
+          singletonList(new Op(QuotaConfigs.IP_CONNECTION_RATE_OVERRIDE_CONFIG, null))))
+      admin.alterClientQuotas(deletions1).all().get()
+      verifyConnectionQuota(overrideQuotaIp, 20)
+
+      val deletions2 = util.Arrays.asList(
+        new ClientQuotaAlteration(new ClientQuotaEntity(singletonMap(IP, null)),
+          singletonList(new Op(QuotaConfigs.IP_CONNECTION_RATE_OVERRIDE_CONFIG, null))))
+      admin.alterClientQuotas(deletions2).all().get()
+      verifyConnectionQuota(overrideQuotaIp, QuotaConfigs.IP_CONNECTION_RATE_DEFAULT)
+    } finally {
+      admin.close()
+    }
   }
 
-  @Test
-  def testConfigChangeOnNonExistingTopic(): Unit = {
+  @ParameterizedTest
+  @ValueSource(strings = Array("zk"))
+  def testConfigChangeOnNonExistingTopic(quorum: String): Unit = {
     val topic = TestUtils.tempTopic()
     val logProps = new Properties()
     logProps.put(FlushMessagesProp, 10000: java.lang.Integer)
     assertThrows(classOf[UnknownTopicOrPartitionException], () => adminZkClient.changeTopicConfig(topic, logProps))
   }
 
-  @Test
-  def testConfigChangeOnNonExistingTopicWithAdminClient(): Unit = {
+  @ParameterizedTest
+  @ValueSource(strings = Array("zk", "kraft"))
+  def testConfigChangeOnNonExistingTopicWithAdminClient(quorum: String): Unit = {
     val topic = TestUtils.tempTopic()
     val admin = createAdminClient()
     try {
       val resource = new ConfigResource(ConfigResource.Type.TOPIC, topic)
-      val op = new AlterConfigOp(new ConfigEntry(FlushMessagesProp, "10000"), AlterConfigOp.OpType.SET)
+      val op = new AlterConfigOp(new ConfigEntry(FlushMessagesProp, "10000"), SET)
       admin.incrementalAlterConfigs(Map(resource -> List(op).asJavaCollection).asJava).all.get
       fail("Should fail with UnknownTopicOrPartitionException for topic doesn't exist")
     } catch {
@@ -313,8 +396,9 @@ class DynamicConfigChangeTest extends KafkaServerTestHarness {
     }
   }
 
-  @Test
-  def testProcessNotification(): Unit = {
+  @ParameterizedTest
+  @ValueSource(strings = Array("zk"))
+  def testProcessNotification(quorum: String): Unit = {
     val props = new Properties()
     props.put("a.b", "10")
 
@@ -352,6 +436,40 @@ class DynamicConfigChangeTest extends KafkaServerTestHarness {
     EasyMock.verify(handler)
   }
 
+  @ParameterizedTest
+  @ValueSource(strings = Array("zk", "kraft"))
+  def testConfigureDefaultTopic(quorum: String): Unit = {
+    val admin = createAdminClient()
+    try {
+      val resource = new ConfigResource(ConfigResource.Type.TOPIC, "")
+      val op = new AlterConfigOp(new ConfigEntry(FlushMessagesProp, "200000"), SET)
+      admin.incrementalAlterConfigs(Map(resource -> List(op).asJavaCollection).asJava).all.get
+      fail("Should fail with InvalidRequestException for topic doesn't exist")
+    } catch {
+      case e: ExecutionException =>
+        assertEquals(classOf[InvalidRequestException], e.getCause().getClass())
+    } finally {
+      admin.close()
+    }
+  }
+
+  private def createAdminClient(): Admin = {
+    val props = new Properties()
+    props.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, brokerList)
+    Admin.create(props)
+  }
+}
+
+class DynamicConfigChangeUnitTest {
+  @Test
+  def testIpHandlerUnresolvableAddress(): Unit = {
+    val configHandler = new IpConfigHandler(null)
+    val props: Properties = new Properties()
+    props.put(QuotaConfigs.IP_CONNECTION_RATE_OVERRIDE_CONFIG, "1")
+
+    assertThrows(classOf[IllegalArgumentException], () => configHandler.processConfigChanges("illegal-hostname", props))
+  }
+
   @Test
   def shouldParseReplicationQuotaProperties(): Unit = {
     val configHandler: TopicConfigHandler = new TopicConfigHandler(null, null, null, null)
@@ -380,6 +498,21 @@ class DynamicConfigChangeTest extends KafkaServerTestHarness {
     assertEquals(AllReplicas, result)
   }
 
+  @Test
+  def shouldParseRegardlessOfWhitespaceAroundValues(): Unit = {
+    def parse(configHandler: TopicConfigHandler, value: String): Seq[Int] = {
+      configHandler.parseThrottledPartitions(
+        CoreUtils.propsWith(LeaderReplicationThrottledReplicasProp, value),
+        102, LeaderReplicationThrottledReplicasProp)
+    }
+    val configHandler: TopicConfigHandler = new TopicConfigHandler(null, null, null, null)
+    assertEquals(AllReplicas, parse(configHandler, "* "))
+    assertEquals(Seq(), parse(configHandler, " "))
+    assertEquals(Seq(6), parse(configHandler, "6:102"))
+    assertEquals(Seq(6), parse(configHandler, "6:102 "))
+    assertEquals(Seq(6), parse(configHandler, " 6:102"))
+  }
+
   @Test
   def shouldParseReplicationQuotaReset(): Unit = {
     val configHandler: TopicConfigHandler = new TopicConfigHandler(null, null, null, null)
@@ -394,25 +527,4 @@ class DynamicConfigChangeTest extends KafkaServerTestHarness {
     //Then
     assertEquals(Seq(), result)
   }
-
-  @Test
-  def shouldParseRegardlessOfWhitespaceAroundValues(): Unit = {
-    val configHandler: TopicConfigHandler = new TopicConfigHandler(null, null, null, null)
-    assertEquals(AllReplicas, parse(configHandler, "* "))
-    assertEquals(Seq(), parse(configHandler, " "))
-    assertEquals(Seq(6), parse(configHandler, "6:102"))
-    assertEquals(Seq(6), parse(configHandler, "6:102 "))
-    assertEquals(Seq(6), parse(configHandler, " 6:102"))
-  }
-
-  def parse(configHandler: TopicConfigHandler, value: String): Seq[Int] = {
-    configHandler.parseThrottledPartitions(CoreUtils.propsWith(LeaderReplicationThrottledReplicasProp, value), 102, LeaderReplicationThrottledReplicasProp)
-  }
-
-  private def createAdminClient(): Admin = {
-    val props = new Properties()
-    props.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, brokerList)
-    Admin.create(props)
-  }
-
 }
diff --git a/metadata/src/main/java/org/apache/kafka/controller/ConfigurationControlManager.java b/metadata/src/main/java/org/apache/kafka/controller/ConfigurationControlManager.java
index 83f1cbf193..6b80079cec 100644
--- a/metadata/src/main/java/org/apache/kafka/controller/ConfigurationControlManager.java
+++ b/metadata/src/main/java/org/apache/kafka/controller/ConfigurationControlManager.java
@@ -23,9 +23,7 @@ import org.apache.kafka.common.config.ConfigDef;
 import org.apache.kafka.common.config.ConfigException;
 import org.apache.kafka.common.config.ConfigResource.Type;
 import org.apache.kafka.common.config.ConfigResource;
-import org.apache.kafka.common.internals.Topic;
 import org.apache.kafka.common.metadata.ConfigRecord;
-import org.apache.kafka.common.protocol.Errors;
 import org.apache.kafka.common.requests.ApiError;
 import org.apache.kafka.common.utils.LogContext;
 import org.apache.kafka.server.common.ApiMessageAndVersion;
@@ -46,6 +44,7 @@ import java.util.Map.Entry;
 import java.util.NoSuchElementException;
 import java.util.Objects;
 import java.util.Optional;
+import java.util.function.Consumer;
 
 import static org.apache.kafka.clients.admin.AlterConfigOp.OpType.APPEND;
 import static org.apache.kafka.common.metadata.MetadataRecordType.CONFIG_RECORD;
@@ -53,6 +52,8 @@ import static org.apache.kafka.common.protocol.Errors.INVALID_CONFIG;
 
 
 public class ConfigurationControlManager {
+    final static Consumer<ConfigResource> NO_OP_EXISTENCE_CHECKER = __ -> { };
+
     private final Logger log;
     private final SnapshotRegistry snapshotRegistry;
     private final Map<ConfigResource.Type, ConfigDef> configDefs;
@@ -68,9 +69,9 @@ public class ConfigurationControlManager {
         this.log = logContext.logger(ConfigurationControlManager.class);
         this.snapshotRegistry = snapshotRegistry;
         this.configDefs = configDefs;
-        this.configData = new TimelineHashMap<>(snapshotRegistry, 0);
         this.alterConfigPolicy = alterConfigPolicy;
         this.validator = validator;
+        this.configData = new TimelineHashMap<>(snapshotRegistry, 0);
     }
 
     /**
@@ -87,13 +88,15 @@ public class ConfigurationControlManager {
      * @return                  The result.
      */
     ControllerResult<Map<ConfigResource, ApiError>> incrementalAlterConfigs(
-            Map<ConfigResource, Map<String, Entry<OpType, String>>> configChanges) {
+            Map<ConfigResource, Map<String, Entry<OpType, String>>> configChanges,
+            Consumer<ConfigResource> existenceChecker) {
         List<ApiMessageAndVersion> outputRecords = new ArrayList<>();
         Map<ConfigResource, ApiError> outputResults = new HashMap<>();
         for (Entry<ConfigResource, Map<String, Entry<OpType, String>>> resourceEntry :
                 configChanges.entrySet()) {
             incrementalAlterConfigResource(resourceEntry.getKey(),
                 resourceEntry.getValue(),
+                existenceChecker,
                 outputRecords,
                 outputResults);
         }
@@ -102,13 +105,9 @@ public class ConfigurationControlManager {
 
     private void incrementalAlterConfigResource(ConfigResource configResource,
                                                 Map<String, Entry<OpType, String>> keysToOps,
+                                                Consumer<ConfigResource> existenceChecker,
                                                 List<ApiMessageAndVersion> outputRecords,
                                                 Map<ConfigResource, ApiError> outputResults) {
-        ApiError error = checkConfigResource(configResource);
-        if (error.isFailure()) {
-            outputResults.put(configResource, error);
-            return;
-        }
         List<ApiMessageAndVersion> newRecords = new ArrayList<>();
         for (Entry<String, Entry<OpType, String>> keysToOpsEntry : keysToOps.entrySet()) {
             String key = keysToOpsEntry.getKey();
@@ -155,7 +154,7 @@ public class ConfigurationControlManager {
                     setValue(newValue), CONFIG_RECORD.highestSupportedVersion()));
             }
         }
-        error = validateAlterConfig(configResource, newRecords);
+        ApiError error = validateAlterConfig(configResource, newRecords, existenceChecker);
         if (error.isFailure()) {
             outputResults.put(configResource, error);
             return;
@@ -165,7 +164,8 @@ public class ConfigurationControlManager {
     }
 
     private ApiError validateAlterConfig(ConfigResource configResource,
-                                         List<ApiMessageAndVersion> newRecords) {
+                                         List<ApiMessageAndVersion> newRecords,
+                                         Consumer<ConfigResource> existenceChecker) {
         Map<String, String> newConfigs = new HashMap<>();
         TimelineHashMap<String, String> existingConfigs = configData.get(configResource);
         if (existingConfigs != null) newConfigs.putAll(existingConfigs);
@@ -179,6 +179,7 @@ public class ConfigurationControlManager {
         }
         try {
             validator.validate(configResource, newConfigs);
+            existenceChecker.accept(configResource);
             if (alterConfigPolicy.isPresent()) {
                 alterConfigPolicy.get().validate(new RequestMetadata(configResource, newConfigs));
             }
@@ -200,13 +201,16 @@ public class ConfigurationControlManager {
      * @return                  The result.
      */
     ControllerResult<Map<ConfigResource, ApiError>> legacyAlterConfigs(
-        Map<ConfigResource, Map<String, String>> newConfigs) {
+        Map<ConfigResource, Map<String, String>> newConfigs,
+        Consumer<ConfigResource> existenceChecker
+    ) {
         List<ApiMessageAndVersion> outputRecords = new ArrayList<>();
         Map<ConfigResource, ApiError> outputResults = new HashMap<>();
         for (Entry<ConfigResource, Map<String, String>> resourceEntry :
             newConfigs.entrySet()) {
             legacyAlterConfigResource(resourceEntry.getKey(),
                 resourceEntry.getValue(),
+                existenceChecker,
                 outputRecords,
                 outputResults);
         }
@@ -215,13 +219,9 @@ public class ConfigurationControlManager {
 
     private void legacyAlterConfigResource(ConfigResource configResource,
                                            Map<String, String> newConfigs,
+                                           Consumer<ConfigResource> existenceChecker,
                                            List<ApiMessageAndVersion> outputRecords,
                                            Map<ConfigResource, ApiError> outputResults) {
-        ApiError error = checkConfigResource(configResource);
-        if (error.isFailure()) {
-            outputResults.put(configResource, error);
-            return;
-        }
         List<ApiMessageAndVersion> newRecords = new ArrayList<>();
         Map<String, String> currentConfigs = configData.get(configResource);
         if (currentConfigs == null) {
@@ -248,7 +248,7 @@ public class ConfigurationControlManager {
                     setValue(null), CONFIG_RECORD.highestSupportedVersion()));
             }
         }
-        error = validateAlterConfig(configResource, newRecords);
+        ApiError error = validateAlterConfig(configResource, newRecords, existenceChecker);
         if (error.isFailure()) {
             outputResults.put(configResource, error);
             return;
@@ -274,50 +274,6 @@ public class ConfigurationControlManager {
         return parts;
     }
 
-    static ApiError checkConfigResource(ConfigResource configResource) {
-        switch (configResource.type()) {
-            case BROKER_LOGGER:
-                // We do not handle resources of type BROKER_LOGGER in
-                // ConfigurationControlManager, since they are not persisted to the
-                // metadata log.
-                //
-                // When using incrementalAlterConfigs, we handle changes to BROKER_LOGGER
-                // in ControllerApis.scala.  When using the legacy alterConfigs,
-                // BROKER_LOGGER is not supported at all.
-                return new ApiError(Errors.INVALID_REQUEST, "Unsupported " +
-                    "configuration resource type BROKER_LOGGER ");
-            case BROKER:
-                // Note: A Resource with type BROKER and an empty name represents a
-                // cluster configuration that applies to all brokers.
-                if (!configResource.name().isEmpty()) {
-                    try {
-                        int brokerId = Integer.parseInt(configResource.name());
-                        if (brokerId < 0) {
-                            return new ApiError(Errors.INVALID_REQUEST, "Illegal " +
-                                "negative broker ID in BROKER resource.");
-                        }
-                    } catch (NumberFormatException e) {
-                        return new ApiError(Errors.INVALID_REQUEST, "Illegal " +
-                            "non-integral BROKER resource type name.");
-                    }
-                }
-                return ApiError.NONE;
-            case TOPIC:
-                try {
-                    Topic.validate(configResource.name());
-                } catch (Exception e) {
-                    return new ApiError(Errors.INVALID_REQUEST, "Illegal topic name.");
-                }
-                return ApiError.NONE;
-            case UNKNOWN:
-                return new ApiError(Errors.INVALID_REQUEST, "Unsupported configuration " +
-                    "resource type UNKNOWN.");
-            default:
-                return new ApiError(Errors.INVALID_REQUEST, "Unsupported unexpected " +
-                    "resource type");
-        }
-    }
-
     boolean isSplittable(ConfigResource.Type type, String key) {
         ConfigDef configDef = configDefs.get(type);
         if (configDef == null) {
@@ -381,9 +337,10 @@ public class ConfigurationControlManager {
         Map<ConfigResource, ResultOrError<Map<String, String>>> results = new HashMap<>();
         for (Entry<ConfigResource, Collection<String>> resourceEntry : resources.entrySet()) {
             ConfigResource resource = resourceEntry.getKey();
-            ApiError error = checkConfigResource(resource);
-            if (error.isFailure()) {
-                results.put(resource, new ResultOrError<>(error));
+            try {
+                validator.validate(resource, Collections.emptyMap());
+            } catch (Throwable e) {
+                results.put(resource, new ResultOrError<>(ApiError.fromThrowable(e)));
                 continue;
             }
             Map<String, String> foundConfigs = new HashMap<>();
diff --git a/metadata/src/main/java/org/apache/kafka/controller/QuorumController.java b/metadata/src/main/java/org/apache/kafka/controller/QuorumController.java
index 16b3ab3f48..cdb35c8aa7 100644
--- a/metadata/src/main/java/org/apache/kafka/controller/QuorumController.java
+++ b/metadata/src/main/java/org/apache/kafka/controller/QuorumController.java
@@ -22,8 +22,10 @@ import org.apache.kafka.common.Uuid;
 import org.apache.kafka.common.config.ConfigDef;
 import org.apache.kafka.common.config.ConfigResource;
 import org.apache.kafka.common.errors.ApiException;
+import org.apache.kafka.common.errors.BrokerIdNotRegisteredException;
 import org.apache.kafka.common.errors.NotControllerException;
 import org.apache.kafka.common.errors.UnknownServerException;
+import org.apache.kafka.common.errors.UnknownTopicOrPartitionException;
 import org.apache.kafka.common.message.AllocateProducerIdsRequestData;
 import org.apache.kafka.common.message.AllocateProducerIdsResponseData;
 import org.apache.kafka.common.message.AlterIsrRequestData;
@@ -96,6 +98,7 @@ import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.RejectedExecutionException;
 import java.util.concurrent.TimeUnit;
+import java.util.function.Consumer;
 import java.util.function.Supplier;
 import java.util.stream.Collectors;
 
@@ -251,6 +254,41 @@ public final class QuorumController implements Controller {
         }
     }
 
+    /**
+     * Checks that a configuration resource exists.
+     *
+     * This object must be used only from the controller event thread.
+     */
+    class ConfigResourceExistenceChecker implements Consumer<ConfigResource> {
+        @Override
+        public void accept(ConfigResource configResource) {
+            switch (configResource.type()) {
+                case BROKER_LOGGER:
+                    break;
+                case BROKER:
+                    int brokerId;
+                    try {
+                        brokerId = Integer.parseInt(configResource.name());
+                    } catch (NumberFormatException e) {
+                        brokerId = -1;
+                    }
+                    if (!clusterControl.brokerRegistrations().containsKey(brokerId)) {
+                        throw new BrokerIdNotRegisteredException("No broker with id " +
+                            brokerId + " found.");
+                    }
+                    break;
+                case TOPIC:
+                    if (replicationControl.getTopicId(configResource.name()) == null) {
+                        throw new UnknownTopicOrPartitionException("The topic '" +
+                            configResource.name() + "' does not exist.");
+                    }
+                    break;
+                default:
+                    break;
+            }
+        }
+    }
+
     public static final String CONTROLLER_THREAD_SUFFIX = "QuorumControllerEventHandler";
 
     private static final String ACTIVE_CONTROLLER_EXCEPTION_TEXT_PREFIX =
@@ -1015,6 +1053,11 @@ public final class QuorumController implements Controller {
      */
     private final ControllerPurgatory purgatory;
 
+    /**
+     * A predicate that returns information about whether a ConfigResource exists.
+     */
+    private final Consumer<ConfigResource> resourceExists;
+
     /**
      * An object which stores the controller's dynamic configuration.
      * This must be accessed only by the event queue thread.
@@ -1130,6 +1173,7 @@ public final class QuorumController implements Controller {
         this.controllerMetrics = controllerMetrics;
         this.snapshotRegistry = new SnapshotRegistry(logContext);
         this.purgatory = new ControllerPurgatory();
+        this.resourceExists = new ConfigResourceExistenceChecker();
         this.configurationControl = new ConfigurationControlManager(logContext,
             snapshotRegistry, configDefs, alterConfigPolicy, configurationValidator);
         this.clientQuotaControlManager = new ClientQuotaControlManager(snapshotRegistry);
@@ -1236,7 +1280,7 @@ public final class QuorumController implements Controller {
         }
         return appendWriteEvent("incrementalAlterConfigs", () -> {
             ControllerResult<Map<ConfigResource, ApiError>> result =
-                configurationControl.incrementalAlterConfigs(configChanges);
+                configurationControl.incrementalAlterConfigs(configChanges, resourceExists);
             if (validateOnly) {
                 return result.withoutRecords();
             } else {
@@ -1276,7 +1320,7 @@ public final class QuorumController implements Controller {
         }
         return appendWriteEvent("legacyAlterConfigs", () -> {
             ControllerResult<Map<ConfigResource, ApiError>> result =
-                configurationControl.legacyAlterConfigs(newConfigs);
+                configurationControl.legacyAlterConfigs(newConfigs, resourceExists);
             if (validateOnly) {
                 return result.withoutRecords();
             } else {
diff --git a/metadata/src/main/java/org/apache/kafka/controller/ReplicationControlManager.java b/metadata/src/main/java/org/apache/kafka/controller/ReplicationControlManager.java
index 5462dea198..f3dc6fd984 100644
--- a/metadata/src/main/java/org/apache/kafka/controller/ReplicationControlManager.java
+++ b/metadata/src/main/java/org/apache/kafka/controller/ReplicationControlManager.java
@@ -114,6 +114,7 @@ import static org.apache.kafka.common.protocol.Errors.INVALID_UPDATE_VERSION;
 import static org.apache.kafka.common.protocol.Errors.NO_REASSIGNMENT_IN_PROGRESS;
 import static org.apache.kafka.common.protocol.Errors.UNKNOWN_TOPIC_ID;
 import static org.apache.kafka.common.protocol.Errors.UNKNOWN_TOPIC_OR_PARTITION;
+import static org.apache.kafka.controller.ConfigurationControlManager.NO_OP_EXISTENCE_CHECKER;
 import static org.apache.kafka.metadata.LeaderConstants.NO_LEADER;
 import static org.apache.kafka.metadata.LeaderConstants.NO_LEADER_CHANGE;
 
@@ -377,7 +378,7 @@ public class ReplicationControlManager {
         Map<ConfigResource, Map<String, Entry<OpType, String>>> configChanges =
             computeConfigChanges(topicErrors, request.topics());
         ControllerResult<Map<ConfigResource, ApiError>> configResult =
-            configurationControl.incrementalAlterConfigs(configChanges);
+            configurationControl.incrementalAlterConfigs(configChanges, NO_OP_EXISTENCE_CHECKER);
         for (Entry<ConfigResource, ApiError> entry : configResult.response().entrySet()) {
             if (entry.getValue().isFailure()) {
                 topicErrors.put(entry.getKey().name(), entry.getValue());
@@ -644,6 +645,10 @@ public class ReplicationControlManager {
         return topics.get(topicId);
     }
 
+    Uuid getTopicId(String name) {
+        return topicsByName.get(name);
+    }
+
     // VisibleForTesting
     BrokersToIsrs brokersToIsrs() {
         return brokersToIsrs;
diff --git a/metadata/src/test/java/org/apache/kafka/controller/ConfigurationControlManagerTest.java b/metadata/src/test/java/org/apache/kafka/controller/ConfigurationControlManagerTest.java
index f84b12e6ef..e2f11b2d3e 100644
--- a/metadata/src/test/java/org/apache/kafka/controller/ConfigurationControlManagerTest.java
+++ b/metadata/src/test/java/org/apache/kafka/controller/ConfigurationControlManagerTest.java
@@ -49,9 +49,8 @@ import static org.apache.kafka.clients.admin.AlterConfigOp.OpType.DELETE;
 import static org.apache.kafka.clients.admin.AlterConfigOp.OpType.SET;
 import static org.apache.kafka.clients.admin.AlterConfigOp.OpType.SUBTRACT;
 import static org.apache.kafka.common.config.ConfigResource.Type.BROKER;
-import static org.apache.kafka.common.config.ConfigResource.Type.BROKER_LOGGER;
 import static org.apache.kafka.common.config.ConfigResource.Type.TOPIC;
-import static org.apache.kafka.common.config.ConfigResource.Type.UNKNOWN;
+import static org.apache.kafka.controller.ConfigurationControlManager.NO_OP_EXISTENCE_CHECKER;
 import static org.junit.jupiter.api.Assertions.assertEquals;
 import static org.junit.jupiter.api.Assertions.assertFalse;
 import static org.junit.jupiter.api.Assertions.assertTrue;
@@ -123,31 +122,6 @@ public class ConfigurationControlManagerTest {
             manager.iterator(Long.MAX_VALUE));
     }
 
-    @Test
-    public void testCheckConfigResource() {
-        assertEquals(new ApiError(Errors.INVALID_REQUEST, "Unsupported " +
-            "configuration resource type BROKER_LOGGER ").toString(),
-            ConfigurationControlManager.checkConfigResource(
-                new ConfigResource(BROKER_LOGGER, "kafka.server.FetchContext")).toString());
-        assertEquals(new ApiError(Errors.INVALID_REQUEST, "Illegal topic name.").toString(),
-            ConfigurationControlManager.checkConfigResource(
-                new ConfigResource(TOPIC, "* @ invalid$")).toString());
-        assertEquals(new ApiError(Errors.INVALID_REQUEST, "Illegal topic name.").toString(),
-            ConfigurationControlManager.checkConfigResource(
-                new ConfigResource(TOPIC, "")).toString());
-        assertEquals(new ApiError(Errors.INVALID_REQUEST, "Illegal non-integral " +
-                "BROKER resource type name.").toString(),
-            ConfigurationControlManager.checkConfigResource(
-                new ConfigResource(BROKER, "bob")).toString());
-        assertEquals(new ApiError(Errors.NONE, null).toString(),
-            ConfigurationControlManager.checkConfigResource(
-                new ConfigResource(BROKER, "")).toString());
-        assertEquals(new ApiError(Errors.INVALID_REQUEST, "Unsupported configuration " +
-                "resource type UNKNOWN.").toString(),
-            ConfigurationControlManager.checkConfigResource(
-                new ConfigResource(UNKNOWN, "bob")).toString());
-    }
-
     @Test
     public void testIncrementalAlterConfigs() {
         SnapshotRegistry snapshotRegistry = new SnapshotRegistry(new LogContext());
@@ -159,7 +133,8 @@ public class ConfigurationControlManagerTest {
             incrementalAlterConfigs(toMap(entry(BROKER0, toMap(
                 entry("baz", entry(SUBTRACT, "abc")),
                 entry("quux", entry(SET, "abc")))),
-                entry(MYTOPIC, toMap(entry("abc", entry(APPEND, "123"))))));
+                entry(MYTOPIC, toMap(entry("abc", entry(APPEND, "123"))))),
+                NO_OP_EXISTENCE_CHECKER);
 
         assertEquals(ControllerResult.atomicOf(Collections.singletonList(new ApiMessageAndVersion(
                 new ConfigRecord().setResourceType(TOPIC.id()).setResourceName("mytopic").
@@ -175,7 +150,8 @@ public class ConfigurationControlManagerTest {
                     setName("abc").setValue(null), (short) 0)),
                 toMap(entry(MYTOPIC, ApiError.NONE))),
             manager.incrementalAlterConfigs(toMap(entry(MYTOPIC, toMap(
-                entry("abc", entry(DELETE, "xyz")))))));
+                entry("abc", entry(DELETE, "xyz"))))),
+                NO_OP_EXISTENCE_CHECKER));
     }
 
     private static class MockAlterConfigsPolicy implements AlterConfigPolicy {
@@ -237,7 +213,8 @@ public class ConfigurationControlManagerTest {
                 entry("foo.bar", entry(SET, "123")))),
                 entry(BROKER0, toMap(
                 entry("foo.bar", entry(SET, "123")),
-                entry("quux", entry(SET, "456")))))));
+                entry("quux", entry(SET, "456"))))),
+                NO_OP_EXISTENCE_CHECKER));
     }
 
     @Test
@@ -278,33 +255,24 @@ public class ConfigurationControlManagerTest {
             new ApiMessageAndVersion(new ConfigRecord().
                 setResourceType(TOPIC.id()).setResourceName("mytopic").
                 setName("def").setValue("901"), (short) 0));
-        assertEquals(
-            ControllerResult.atomicOf(
-                expectedRecords1,
-                toMap(entry(MYTOPIC, ApiError.NONE))
-            ),
+        assertEquals(ControllerResult.atomicOf(
+                expectedRecords1, toMap(entry(MYTOPIC, ApiError.NONE))),
             manager.legacyAlterConfigs(
-                toMap(entry(MYTOPIC, toMap(entry("abc", "456"), entry("def", "901"))))
-            )
-        );
+                toMap(entry(MYTOPIC, toMap(entry("abc", "456"), entry("def", "901")))),
+                NO_OP_EXISTENCE_CHECKER));
         for (ApiMessageAndVersion message : expectedRecords1) {
             manager.replay((ConfigRecord) message.message());
         }
-        assertEquals(
-            ControllerResult.atomicOf(
-                asList(
-                    new ApiMessageAndVersion(
-                        new ConfigRecord()
-                            .setResourceType(TOPIC.id())
-                            .setResourceName("mytopic")
-                            .setName("abc")
-                            .setValue(null),
-                        (short) 0
-                    )
-                ),
-                toMap(entry(MYTOPIC, ApiError.NONE))
-            ),
-            manager.legacyAlterConfigs(toMap(entry(MYTOPIC, toMap(entry("def", "901")))))
-        );
+        assertEquals(ControllerResult.atomicOf(asList(
+            new ApiMessageAndVersion(
+                new ConfigRecord()
+                    .setResourceType(TOPIC.id())
+                    .setResourceName("mytopic")
+                    .setName("abc")
+                    .setValue(null),
+                (short) 0)),
+            toMap(entry(MYTOPIC, ApiError.NONE))),
+            manager.legacyAlterConfigs(toMap(entry(MYTOPIC, toMap(entry("def", "901")))),
+                NO_OP_EXISTENCE_CHECKER));
     }
 }
diff --git a/metadata/src/test/java/org/apache/kafka/controller/QuorumControllerTest.java b/metadata/src/test/java/org/apache/kafka/controller/QuorumControllerTest.java
index a102cf6088..b079c16d25 100644
--- a/metadata/src/test/java/org/apache/kafka/controller/QuorumControllerTest.java
+++ b/metadata/src/test/java/org/apache/kafka/controller/QuorumControllerTest.java
@@ -124,6 +124,8 @@ public class QuorumControllerTest {
             LocalLogManagerTestEnv logEnv = new LocalLogManagerTestEnv(1, Optional.empty());
             QuorumControllerTestEnv controlEnv = new QuorumControllerTestEnv(logEnv, b -> b.setConfigDefs(CONFIGS))
         ) {
+            controlEnv.activeController().registerBroker(new BrokerRegistrationRequestData().
+                setBrokerId(0)).get();
             testConfigurationOperations(controlEnv.activeController());
         }
     }
@@ -155,6 +157,8 @@ public class QuorumControllerTest {
             LocalLogManagerTestEnv logEnv = new LocalLogManagerTestEnv(1, Optional.empty());
             QuorumControllerTestEnv controlEnv = new QuorumControllerTestEnv(logEnv, b -> b.setConfigDefs(CONFIGS))
         ) {
+            controlEnv.activeController().registerBroker(new BrokerRegistrationRequestData().
+                setBrokerId(0)).get();
             testDelayedConfigurationOperations(logEnv, controlEnv.activeController());
         }
     }
@@ -171,7 +175,7 @@ public class QuorumControllerTest {
             new ResultOrError<>(Collections.emptyMap())),
             controller.describeConfigs(Collections.singletonMap(
                 BROKER0, Collections.emptyList())).get());
-        logEnv.logManagers().forEach(m -> m.setMaxReadOffset(1L));
+        logEnv.logManagers().forEach(m -> m.setMaxReadOffset(2L));
         assertEquals(Collections.singletonMap(BROKER0, ApiError.NONE), future1.get());
     }
 
