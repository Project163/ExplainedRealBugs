diff --git a/core/src/main/scala/kafka/log/LogConfig.scala b/core/src/main/scala/kafka/log/LogConfig.scala
index d5b5884c32..55669c061e 100755
--- a/core/src/main/scala/kafka/log/LogConfig.scala
+++ b/core/src/main/scala/kafka/log/LogConfig.scala
@@ -234,6 +234,8 @@ object LogConfig {
         case _ => super.getConfigValue(key, headerName)
       }
     }
+
+    def serverConfigName(configName: String): Option[String] = serverDefaultConfigNames.get(configName)
   }
 
   private val configDef: LogConfigDef = {
@@ -299,6 +301,8 @@ object LogConfig {
 
   def configNames: Seq[String] = configDef.names.asScala.toSeq.sorted
 
+  def serverConfigName(configName: String): Option[String] = configDef.serverConfigName(configName)
+
   /**
    * Create a log config instance using the given properties and defaults
    */
diff --git a/core/src/main/scala/kafka/server/KafkaConfig.scala b/core/src/main/scala/kafka/server/KafkaConfig.scala
index 08e50dd7b4..40a5e1099d 100755
--- a/core/src/main/scala/kafka/server/KafkaConfig.scala
+++ b/core/src/main/scala/kafka/server/KafkaConfig.scala
@@ -22,7 +22,6 @@ import kafka.api.{ApiVersion, KAFKA_0_10_0_IV1}
 import kafka.cluster.EndPoint
 import kafka.consumer.ConsumerConfig
 import kafka.coordinator.OffsetConfig
-import kafka.log.LogConfig
 import kafka.message.{BrokerCompressionCodec, CompressionCodec, Message, MessageSet}
 import kafka.utils.CoreUtils
 import org.apache.kafka.clients.CommonClientConfigs
@@ -267,9 +266,9 @@ object KafkaConfig {
   val LogFlushIntervalMsProp = "log.flush.interval.ms"
   val LogFlushOffsetCheckpointIntervalMsProp = "log.flush.offset.checkpoint.interval.ms"
   val LogPreAllocateProp = "log.preallocate"
-  val LogMessageFormatVersionProp = LogConfigPrefix + LogConfig.MessageFormatVersionProp
-  val LogMessageTimestampTypeProp = LogConfigPrefix + LogConfig.MessageTimestampTypeProp
-  val LogMessageTimestampDifferenceMaxMsProp = LogConfigPrefix + LogConfig.MessageTimestampDifferenceMaxMsProp
+  val LogMessageFormatVersionProp = LogConfigPrefix + "message.format.version"
+  val LogMessageTimestampTypeProp = LogConfigPrefix + "message.timestamp.type"
+  val LogMessageTimestampDifferenceMaxMsProp = LogConfigPrefix + "message.timestamp.difference.max.ms"
   val NumRecoveryThreadsPerDataDirProp = "num.recovery.threads.per.data.dir"
   val AutoCreateTopicsEnableProp = "auto.create.topics.enable"
   val MinInSyncReplicasProp = "min.insync.replicas"
diff --git a/core/src/test/scala/unit/kafka/log/LogConfigTest.scala b/core/src/test/scala/unit/kafka/log/LogConfigTest.scala
index 569264a482..e79cefffa4 100644
--- a/core/src/test/scala/unit/kafka/log/LogConfigTest.scala
+++ b/core/src/test/scala/unit/kafka/log/LogConfigTest.scala
@@ -28,6 +28,23 @@ import org.scalatest.Assertions._
 
 class LogConfigTest {
 
+  /** 
+   * This test verifies that KafkaConfig object initialization does not depend on 
+   * LogConfig initialization. Bad things happen due to static initialization 
+   * order dependencies. For example, LogConfig.configDef ends up adding null 
+   * values in serverDefaultConfigNames. This test ensures that the mapping of 
+   * keys from LogConfig to KafkaConfig are not missing values.
+   */
+  @Test
+  def ensureNoStaticInitializationOrderDependency() {
+    // Access any KafkaConfig val to load KafkaConfig object before LogConfig.
+    assertTrue(KafkaConfig.LogRetentionTimeMillisProp != null)
+    assertTrue(LogConfig.configNames.forall { config =>
+      val serverConfigOpt = LogConfig.serverConfigName(config)
+      serverConfigOpt.isDefined && (serverConfigOpt.get != null)
+    })
+  }
+
   @Test
   def testKafkaConfigToProps() {
     val millisInHour = 60L * 60L * 1000L
