diff --git a/core/src/main/scala/kafka/consumer/ConsoleConsumer.scala b/core/src/main/scala/kafka/consumer/ConsoleConsumer.scala
index 49a6f396f7..32c2df871b 100644
--- a/core/src/main/scala/kafka/consumer/ConsoleConsumer.scala
+++ b/core/src/main/scala/kafka/consumer/ConsoleConsumer.scala
@@ -62,7 +62,17 @@ object ConsoleConsumer extends Logging {
                            .withRequiredArg
                            .describedAs("size")
                            .ofType(classOf[java.lang.Integer])
-                           .defaultsTo(1024 * 1024)   
+                           .defaultsTo(1024 * 1024)
+    val minFetchBytesOpt = parser.accepts("min-fetch-bytes", "The min number of bytes each fetch request waits for.")
+                           .withRequiredArg
+                           .describedAs("bytes")
+                           .ofType(classOf[java.lang.Integer])
+                           .defaultsTo(1)
+    val maxWaitMsOpt = parser.accepts("max-wait-ms", "The max amount of time each fetch request waits.")
+                           .withRequiredArg
+                           .describedAs("ms")
+                           .ofType(classOf[java.lang.Integer])
+                           .defaultsTo(100)
     val socketBufferSizeOpt = parser.accepts("socket-buffer-size", "The size of the tcp RECV size.")
                            .withRequiredArg
                            .describedAs("size")
@@ -116,6 +126,8 @@ object ConsoleConsumer extends Logging {
     props.put("groupid", options.valueOf(groupIdOpt))
     props.put("socket.buffersize", options.valueOf(socketBufferSizeOpt).toString)
     props.put("fetch.size", options.valueOf(fetchSizeOpt).toString)
+    props.put("min.fetch.bytes", options.valueOf(minFetchBytesOpt).toString)
+    props.put("max.fetch.wait.ms", options.valueOf(maxWaitMsOpt).toString)
     props.put("auto.commit", "true")
     props.put("autocommit.interval.ms", options.valueOf(autoCommitIntervalOpt).toString)
     props.put("autooffset.reset", if(options.has(resetBeginningOpt)) "smallest" else "largest")
diff --git a/core/src/main/scala/kafka/consumer/ConsumerConfig.scala b/core/src/main/scala/kafka/consumer/ConsumerConfig.scala
index 0f6abb2469..19525585f3 100644
--- a/core/src/main/scala/kafka/consumer/ConsumerConfig.scala
+++ b/core/src/main/scala/kafka/consumer/ConsumerConfig.scala
@@ -33,7 +33,7 @@ object ConsumerConfig {
   val AutoOffsetReset = OffsetRequest.SmallestTimeString
   val ConsumerTimeoutMs = -1
   val MinFetchBytes = 1
-  val MaxFetchWaitMs = 3000
+  val MaxFetchWaitMs = 100
   val MirrorTopicsWhitelist = ""
   val MirrorTopicsBlacklist = ""
   val MirrorConsumerNumThreads = 1
diff --git a/core/src/main/scala/kafka/consumer/FetcherRunnable.scala b/core/src/main/scala/kafka/consumer/FetcherRunnable.scala
index 6aa7043fdd..f2bcff650c 100644
--- a/core/src/main/scala/kafka/consumer/FetcherRunnable.scala
+++ b/core/src/main/scala/kafka/consumer/FetcherRunnable.scala
@@ -67,7 +67,8 @@ class FetcherRunnable(val name: String,
         val fetchRequest = builder.build()
         val start = System.currentTimeMillis
         val response = simpleConsumer.fetch(fetchRequest)
-        trace("Fetch completed in " + (System.currentTimeMillis - start) + " ms with max wait of " + config.maxFetchWaitMs)
+        trace("Fetch request %s completed in %d ms with max wait of %d".format(fetchRequest,
+          (System.currentTimeMillis - start), config.maxFetchWaitMs))
 
         var read = 0L
         for(infopti <- partitionTopicInfos) {
diff --git a/core/src/main/scala/kafka/log/Log.scala b/core/src/main/scala/kafka/log/Log.scala
index 857601ae4c..bb90060357 100644
--- a/core/src/main/scala/kafka/log/Log.scala
+++ b/core/src/main/scala/kafka/log/Log.scala
@@ -301,7 +301,6 @@ private[kafka] class Log(val dir: File, val maxSize: Long, val flushInterval: In
    * The byte offset of the message that will be appended next.
    */
   def nextAppendOffset: Long = {
-    flush
     val last = segments.view.last
     last.start + last.size
   }
@@ -329,6 +328,7 @@ private[kafka] class Log(val dir: File, val maxSize: Long, val flushInterval: In
    */
   def roll() {
     lock synchronized {
+      flush
       val newOffset = nextAppendOffset
       val newFile = new File(dir, nameFromOffset(newOffset))
       if (newFile.exists) {
