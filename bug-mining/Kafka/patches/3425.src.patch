diff --git a/checkstyle/suppressions.xml b/checkstyle/suppressions.xml
index 74358a2b3a..6402c315b6 100644
--- a/checkstyle/suppressions.xml
+++ b/checkstyle/suppressions.xml
@@ -310,7 +310,7 @@
     <suppress checks="CyclomaticComplexity"
               files="(ClientQuotasImage|KafkaEventQueue|MetadataDelta|QuorumController|ReplicationControlManager).java"/>
     <suppress checks="NPathComplexity"
-              files="(ClientQuotasImage|KafkaEventQueue|ReplicationControlManager|FeatureControlManager).java"/>
+              files="(ClientQuotasImage|KafkaEventQueue|ReplicationControlManager|FeatureControlManager|KRaftMigrationDriver).java"/>
     <suppress checks="(NPathComplexity|ClassFanOutComplexity|CyclomaticComplexity|ClassDataAbstractionCoupling|LocalVariableName|MemberName|ParameterName|MethodLength|JavaNCSS|AvoidStarImport)"
             files="metadata[\\/]src[\\/](generated|generated-test)[\\/].+.java$"/>
     <suppress checks="BooleanExpressionComplexity"
diff --git a/core/src/test/scala/integration/kafka/server/KafkaServerKRaftRegistrationTest.scala b/core/src/test/scala/integration/kafka/server/KafkaServerKRaftRegistrationTest.scala
index d6f39c76f3..367d81d8c7 100644
--- a/core/src/test/scala/integration/kafka/server/KafkaServerKRaftRegistrationTest.scala
+++ b/core/src/test/scala/integration/kafka/server/KafkaServerKRaftRegistrationTest.scala
@@ -81,8 +81,8 @@ class KafkaServerKRaftRegistrationTest {
         case t: Throwable => fail("Had some other error waiting for brokers", t)
       }
     } finally {
-      zkCluster.stop()
       kraftCluster.close()
+      zkCluster.stop()
     }
   }
 
@@ -112,8 +112,8 @@ class KafkaServerKRaftRegistrationTest {
       zkCluster.config().serverProperties().put(KafkaConfig.ListenerSecurityProtocolMapProp, "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT")
       assertThrows(classOf[IllegalArgumentException], () => zkCluster.rollingBrokerRestart())
     } finally {
-      zkCluster.stop()
       kraftCluster.close()
+      zkCluster.stop()
     }
   }
 }
diff --git a/metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java b/metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java
index fd2d85081c..7b06982d0c 100644
--- a/metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java
+++ b/metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java
@@ -42,6 +42,7 @@ import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutionException;
+import java.util.concurrent.RejectedExecutionException;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.function.Consumer;
 import java.util.function.Function;
@@ -55,6 +56,8 @@ import static java.util.concurrent.TimeUnit.SECONDS;
  * serialize events coming from various threads and listeners.
  */
 public class KRaftMigrationDriver implements MetadataPublisher {
+    private final static Consumer<Throwable> NO_OP_HANDLER = ex -> { };
+
     private final Time time;
     private final Logger log;
     private final int nodeId;
@@ -67,7 +70,7 @@ public class KRaftMigrationDriver implements MetadataPublisher {
      * A callback for when the migration state has been recovered from ZK. This is used to delay the installation of this
      * MetadataPublisher with MetadataLoader.
      */
-    private final Consumer<KRaftMigrationDriver> initialZkLoadHandler;
+    private final Consumer<MetadataPublisher> initialZkLoadHandler;
     private volatile LeaderAndEpoch leaderAndEpoch;
     private volatile MigrationState migrationState;
     private volatile ZkMigrationLeadershipState migrationLeadershipState;
@@ -78,7 +81,7 @@ public class KRaftMigrationDriver implements MetadataPublisher {
         ZkRecordConsumer zkRecordConsumer,
         MigrationClient zkMigrationClient,
         LegacyPropagator propagator,
-        Consumer<KRaftMigrationDriver> initialZkLoadHandler,
+        Consumer<MetadataPublisher> initialZkLoadHandler,
         FaultHandler faultHandler
     ) {
         this.nodeId = nodeId;
@@ -106,6 +109,13 @@ public class KRaftMigrationDriver implements MetadataPublisher {
         eventQueue.close();
     }
 
+    // Visible for testing
+    CompletableFuture<MigrationState> migrationState() {
+        CompletableFuture<MigrationState> stateFuture = new CompletableFuture<>();
+        eventQueue.append(() -> stateFuture.complete(migrationState));
+        return stateFuture;
+    }
+
     private void initializeMigrationState() {
         log.info("Recovering migration state");
         apply("Recovery", zkMigrationClient::getOrCreateMigrationRecoveryState);
@@ -210,7 +220,7 @@ public class KRaftMigrationDriver implements MetadataPublisher {
 
     @Override
     public void publishSnapshot(MetadataDelta delta, MetadataImage newImage, SnapshotManifest manifest) {
-        eventQueue.append(new MetadataChangeEvent(delta, newImage, manifest.provenance(), true));
+        enqueueMetadataChangeEvent(delta, newImage, manifest.provenance(), true, NO_OP_HANDLER);
     }
 
     @Override
@@ -218,9 +228,30 @@ public class KRaftMigrationDriver implements MetadataPublisher {
         if (!leaderAndEpoch.equals(manifest.leaderAndEpoch())) {
             eventQueue.append(new KRaftLeaderEvent(manifest.leaderAndEpoch()));
         }
-        eventQueue.append(new MetadataChangeEvent(delta, newImage, manifest.provenance(), false));
+        enqueueMetadataChangeEvent(delta, newImage, manifest.provenance(), false, NO_OP_HANDLER);
     }
 
+    /**
+     * Construct and enqueue a {@link MetadataChangeEvent} with a given completion handler. In production use cases,
+     * this handler is a no-op. This method exists so we can add additional logic in our unit tests to wait for the
+     * enqueued event to finish executing.
+     */
+    void enqueueMetadataChangeEvent(
+        MetadataDelta delta,
+        MetadataImage newImage,
+        MetadataProvenance provenance,
+        boolean isSnapshot,
+        Consumer<Throwable> completionHandler
+    ) {
+        MetadataChangeEvent metadataChangeEvent = new MetadataChangeEvent(
+            delta,
+            newImage,
+            provenance,
+            isSnapshot,
+            completionHandler
+        );
+        eventQueue.append(metadataChangeEvent);
+    }
 
     @Override
     public void close() throws Exception {
@@ -231,7 +262,12 @@ public class KRaftMigrationDriver implements MetadataPublisher {
     abstract class MigrationEvent implements EventQueue.Event {
         @Override
         public void handleException(Throwable e) {
-            KRaftMigrationDriver.this.faultHandler.handleFault("Error during ZK migration", e);
+            if (e instanceof RejectedExecutionException) {
+                log.info("Not processing {} because the event queue is closed.", this);
+            } else {
+                KRaftMigrationDriver.this.faultHandler.handleFault(
+                    "Unhandled error in " + this.getClass().getSimpleName(), e);
+            }
         }
     }
 
@@ -274,11 +310,6 @@ public class KRaftMigrationDriver implements MetadataPublisher {
                 new EventQueue.DeadlineFunction(deadline),
                 new PollEvent());
         }
-
-        @Override
-        public void handleException(Throwable e) {
-            log.error("Had an exception in " + this.getClass().getSimpleName(), e);
-        }
     }
 
     class KRaftLeaderEvent extends MigrationEvent {
@@ -316,11 +347,6 @@ public class KRaftMigrationDriver implements MetadataPublisher {
                     break;
             }
         }
-
-        @Override
-        public void handleException(Throwable e) {
-            log.error("Had an exception in " + this.getClass().getSimpleName(), e);
-        }
     }
 
     class WaitForControllerQuorumEvent extends MigrationEvent {
@@ -341,11 +367,6 @@ public class KRaftMigrationDriver implements MetadataPublisher {
                     break;
             }
         }
-
-        @Override
-        public void handleException(Throwable e) {
-            log.error("Had an exception in " + this.getClass().getSimpleName(), e);
-        }
     }
 
     class BecomeZkControllerEvent extends MigrationEvent {
@@ -370,11 +391,6 @@ public class KRaftMigrationDriver implements MetadataPublisher {
                     break;
             }
         }
-
-        @Override
-        public void handleException(Throwable e) {
-            log.error("Had an exception in " + this.getClass().getSimpleName(), e);
-        }
     }
 
     class WaitForZkBrokersEvent extends MigrationEvent {
@@ -392,11 +408,6 @@ public class KRaftMigrationDriver implements MetadataPublisher {
                     break;
             }
         }
-
-        @Override
-        public void handleException(Throwable e) {
-            log.error("Had an exception in " + this.getClass().getSimpleName(), e);
-        }
     }
 
     class MigrateMetadataEvent extends MigrationEvent {
@@ -439,14 +450,9 @@ public class KRaftMigrationDriver implements MetadataPublisher {
                 transitionTo(MigrationState.KRAFT_CONTROLLER_TO_BROKER_COMM);
             } catch (Throwable t) {
                 zkRecordConsumer.abortMigration();
-                // TODO ???
+                super.handleException(t);
             }
         }
-
-        @Override
-        public void handleException(Throwable e) {
-            log.error("Had an exception in " + this.getClass().getSimpleName(), e);
-        }
     }
 
     class SendRPCsToBrokersEvent extends MigrationEvent {
@@ -474,12 +480,20 @@ public class KRaftMigrationDriver implements MetadataPublisher {
         private final MetadataImage image;
         private final MetadataProvenance provenance;
         private final boolean isSnapshot;
-
-        MetadataChangeEvent(MetadataDelta delta, MetadataImage image, MetadataProvenance provenance, boolean isSnapshot) {
+        private final Consumer<Throwable> completionHandler;
+
+        MetadataChangeEvent(
+            MetadataDelta delta,
+            MetadataImage image,
+            MetadataProvenance provenance,
+            boolean isSnapshot,
+            Consumer<Throwable> completionHandler
+        ) {
             this.delta = delta;
             this.image = image;
             this.provenance = provenance;
             this.isSnapshot = isSnapshot;
+            this.completionHandler = completionHandler;
         }
 
         @Override
@@ -490,6 +504,7 @@ public class KRaftMigrationDriver implements MetadataPublisher {
             if (migrationState != MigrationState.DUAL_WRITE) {
                 log.trace("Received metadata {}, but the controller is not in dual-write " +
                     "mode. Ignoring the change to be replicated to Zookeeper", metadataType);
+                completionHandler.accept(null);
                 return;
             }
             if (delta.featuresDelta() != null) {
@@ -538,12 +553,23 @@ public class KRaftMigrationDriver implements MetadataPublisher {
 
                 // TODO: Unhappy path: Probably relinquish leadership and let new controller
                 //  retry the write?
-                log.trace("Sending RPCs to brokers for metadata {}.", metadataType);
-                propagator.sendRPCsToBrokersFromMetadataDelta(delta, image,
-                        migrationLeadershipState.zkControllerEpoch());
+                if (delta.topicsDelta() != null || delta.clusterDelta() != null) {
+                    log.trace("Sending RPCs to brokers for metadata {}.", metadataType);
+                    propagator.sendRPCsToBrokersFromMetadataDelta(delta, image,
+                            migrationLeadershipState.zkControllerEpoch());
+                } else {
+                    log.trace("Not sending RPCs to brokers for metadata {} since no relevant metadata has changed", metadataType);
+                }
             } else {
                 log.info("Ignoring {} {} which contains metadata that has already been written to ZK.", metadataType, provenance);
             }
+            completionHandler.accept(null);
+        }
+
+        @Override
+        public void handleException(Throwable e) {
+            completionHandler.accept(e);
+            super.handleException(e);
         }
     }
 
diff --git a/metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java b/metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java
new file mode 100644
index 0000000000..1bb1275fd3
--- /dev/null
+++ b/metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java
@@ -0,0 +1,318 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.kafka.metadata.migration;
+
+import org.apache.kafka.common.Uuid;
+import org.apache.kafka.common.config.ConfigResource;
+import org.apache.kafka.common.metadata.BrokerRegistrationChangeRecord;
+import org.apache.kafka.common.metadata.ConfigRecord;
+import org.apache.kafka.common.metadata.RegisterBrokerRecord;
+import org.apache.kafka.image.MetadataDelta;
+import org.apache.kafka.image.MetadataImage;
+import org.apache.kafka.image.MetadataProvenance;
+import org.apache.kafka.image.loader.LogDeltaManifest;
+import org.apache.kafka.metadata.BrokerRegistrationFencingChange;
+import org.apache.kafka.metadata.BrokerRegistrationInControlledShutdownChange;
+import org.apache.kafka.metadata.PartitionRegistration;
+import org.apache.kafka.raft.LeaderAndEpoch;
+import org.apache.kafka.raft.OffsetAndEpoch;
+import org.apache.kafka.server.common.ApiMessageAndVersion;
+import org.apache.kafka.server.common.MetadataVersion;
+import org.apache.kafka.server.fault.MockFaultHandler;
+import org.apache.kafka.test.TestUtils;
+import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.api.Test;
+
+import java.util.Arrays;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.OptionalInt;
+import java.util.Set;
+import java.util.concurrent.CompletableFuture;
+import java.util.concurrent.TimeUnit;
+import java.util.function.Consumer;
+
+public class KRaftMigrationDriverTest {
+    class NoOpRecordConsumer implements ZkRecordConsumer {
+        @Override
+        public void beginMigration() {
+
+        }
+
+        @Override
+        public CompletableFuture<?> acceptBatch(List<ApiMessageAndVersion> recordBatch) {
+            return null;
+        }
+
+        @Override
+        public OffsetAndEpoch completeMigration() {
+            return new OffsetAndEpoch(100, 1);
+        }
+
+        @Override
+        public void abortMigration() {
+
+        }
+    }
+
+    class CapturingMigrationClient implements MigrationClient {
+
+        private final Set<Integer> brokerIds;
+        public final Map<ConfigResource, Map<String, String>> capturedConfigs = new HashMap<>();
+
+        public CapturingMigrationClient(Set<Integer> brokerIdsInZk) {
+            this.brokerIds = brokerIdsInZk;
+        }
+
+        @Override
+        public ZkMigrationLeadershipState getOrCreateMigrationRecoveryState(ZkMigrationLeadershipState initialState) {
+            return initialState;
+        }
+
+        @Override
+        public ZkMigrationLeadershipState setMigrationRecoveryState(ZkMigrationLeadershipState state) {
+            return state;
+        }
+
+        @Override
+        public ZkMigrationLeadershipState claimControllerLeadership(ZkMigrationLeadershipState state) {
+            return state;
+        }
+
+        @Override
+        public ZkMigrationLeadershipState releaseControllerLeadership(ZkMigrationLeadershipState state) {
+            return state;
+        }
+
+        @Override
+        public ZkMigrationLeadershipState createTopic(
+            String topicName,
+            Uuid topicId,
+            Map<Integer, PartitionRegistration> topicPartitions,
+            ZkMigrationLeadershipState state
+        ) {
+            return state;
+        }
+
+        @Override
+        public ZkMigrationLeadershipState updateTopicPartitions(
+            Map<String, Map<Integer, PartitionRegistration>> topicPartitions,
+            ZkMigrationLeadershipState state
+        ) {
+            return state;
+        }
+
+        @Override
+        public ZkMigrationLeadershipState writeConfigs(
+            ConfigResource configResource,
+            Map<String, String> configMap,
+            ZkMigrationLeadershipState state
+        ) {
+            capturedConfigs.computeIfAbsent(configResource, __ -> new HashMap<>()).putAll(configMap);
+            return state;
+        }
+
+        @Override
+        public ZkMigrationLeadershipState writeClientQuotas(
+            Map<String, String> clientQuotaEntity,
+            Map<String, Double> quotas,
+            ZkMigrationLeadershipState state
+        ) {
+            return state;
+        }
+
+        @Override
+        public ZkMigrationLeadershipState writeProducerId(
+            long nextProducerId,
+            ZkMigrationLeadershipState state
+        ) {
+            return state;
+        }
+
+        @Override
+        public void readAllMetadata(
+            Consumer<List<ApiMessageAndVersion>> batchConsumer,
+            Consumer<Integer> brokerIdConsumer
+        ) {
+
+        }
+
+        @Override
+        public Set<Integer> readBrokerIds() {
+            return brokerIds;
+        }
+
+        @Override
+        public Set<Integer> readBrokerIdsFromTopicAssignments() {
+            return brokerIds;
+        }
+
+        @Override
+        public ZkMigrationLeadershipState writeMetadataDeltaToZookeeper(
+            MetadataDelta delta,
+            MetadataImage image,
+            ZkMigrationLeadershipState state
+        ) {
+            return state;
+        }
+    }
+
+    class CountingMetadataPropagator implements LegacyPropagator {
+
+        public int deltas = 0;
+        public int images = 0;
+
+        @Override
+        public void startup() {
+
+        }
+
+        @Override
+        public void shutdown() {
+
+        }
+
+        @Override
+        public void publishMetadata(MetadataImage image) {
+
+        }
+
+        @Override
+        public void sendRPCsToBrokersFromMetadataDelta(
+            MetadataDelta delta,
+            MetadataImage image,
+            int zkControllerEpoch
+        ) {
+            deltas += 1;
+        }
+
+        @Override
+        public void sendRPCsToBrokersFromMetadataImage(MetadataImage image, int zkControllerEpoch) {
+            images += 1;
+        }
+
+        @Override
+        public void clear() {
+
+        }
+
+        @Override
+        public void setMetadataVersion(MetadataVersion metadataVersion) {
+
+        }
+    }
+
+    RegisterBrokerRecord zkBrokerRecord(int id) {
+        RegisterBrokerRecord record = new RegisterBrokerRecord();
+        record.setBrokerId(id);
+        record.setIsMigratingZkBroker(true);
+        record.setFenced(false);
+        return record;
+    }
+
+    /**
+     * Enqueues a metadata change event with the migration driver and returns a future that can be waited on in
+     * the test code. The future will complete once the metadata change event executes completely.
+     */
+    CompletableFuture<Void> enqueueMetadataChangeEventWithFuture(
+        KRaftMigrationDriver driver,
+        MetadataDelta delta,
+        MetadataImage newImage,
+        MetadataProvenance provenance
+    ) {
+        CompletableFuture<Void> future = new CompletableFuture<>();
+        Consumer<Throwable> completionHandler = ex -> {
+            if (ex == null) {
+                future.complete(null);
+            } else {
+                future.completeExceptionally(ex);
+            }
+        };
+
+        driver.enqueueMetadataChangeEvent(delta, newImage, provenance, false, completionHandler);
+        return future;
+    }
+
+    /**
+     * Don't send RPCs to brokers for every metadata change, only when brokers or topics change.
+     * This is a regression test for KAFKA-14668
+     */
+    @Test
+    public void testOnlySendNeededRPCsToBrokers() throws Exception {
+        CountingMetadataPropagator metadataPropagator = new CountingMetadataPropagator();
+        CapturingMigrationClient migrationClient = new CapturingMigrationClient(new HashSet<>(Arrays.asList(1, 2, 3)));
+        KRaftMigrationDriver driver = new KRaftMigrationDriver(
+            3000,
+            new NoOpRecordConsumer(),
+            migrationClient,
+            metadataPropagator,
+            metadataPublisher -> { },
+            new MockFaultHandler("test")
+        );
+
+        MetadataImage image = MetadataImage.EMPTY;
+        MetadataDelta delta = new MetadataDelta(image);
+
+        driver.start();
+        delta.replay(zkBrokerRecord(1));
+        delta.replay(zkBrokerRecord(2));
+        delta.replay(zkBrokerRecord(3));
+        MetadataProvenance provenance = new MetadataProvenance(100, 1, 1);
+        image = delta.apply(provenance);
+
+        // Publish a delta with this node (3000) as the leader
+        driver.publishLogDelta(delta, image, new LogDeltaManifest(provenance,
+            new LeaderAndEpoch(OptionalInt.of(3000), 1), 1, 100, 42));
+
+        TestUtils.waitForCondition(() -> driver.migrationState().get(1, TimeUnit.MINUTES).equals(MigrationState.DUAL_WRITE),
+            "Waiting for KRaftMigrationDriver to enter DUAL_WRITE state");
+
+        Assertions.assertEquals(1, metadataPropagator.images);
+        Assertions.assertEquals(0, metadataPropagator.deltas);
+
+        delta = new MetadataDelta(image);
+        delta.replay(new ConfigRecord()
+            .setResourceType(ConfigResource.Type.BROKER.id())
+            .setResourceName("1")
+            .setName("foo")
+            .setValue("bar"));
+        provenance = new MetadataProvenance(120, 1, 2);
+        image = delta.apply(provenance);
+        enqueueMetadataChangeEventWithFuture(driver, delta, image, provenance).get(1, TimeUnit.MINUTES);
+
+        Assertions.assertEquals(1, migrationClient.capturedConfigs.size());
+        Assertions.assertEquals(1, metadataPropagator.images);
+        Assertions.assertEquals(0, metadataPropagator.deltas);
+
+        delta = new MetadataDelta(image);
+        delta.replay(new BrokerRegistrationChangeRecord()
+            .setBrokerId(1)
+            .setBrokerEpoch(0)
+            .setFenced(BrokerRegistrationFencingChange.NONE.value())
+            .setInControlledShutdown(BrokerRegistrationInControlledShutdownChange.IN_CONTROLLED_SHUTDOWN.value()));
+        provenance = new MetadataProvenance(130, 1, 3);
+        image = delta.apply(provenance);
+        enqueueMetadataChangeEventWithFuture(driver, delta, image, provenance).get(1, TimeUnit.MINUTES);
+
+        Assertions.assertEquals(1, metadataPropagator.images);
+        Assertions.assertEquals(1, metadataPropagator.deltas);
+
+        driver.close();
+    }
+}
diff --git a/server-common/src/main/java/org/apache/kafka/queue/KafkaEventQueue.java b/server-common/src/main/java/org/apache/kafka/queue/KafkaEventQueue.java
index 7d4f46aa77..6b9d537d5b 100644
--- a/server-common/src/main/java/org/apache/kafka/queue/KafkaEventQueue.java
+++ b/server-common/src/main/java/org/apache/kafka/queue/KafkaEventQueue.java
@@ -250,7 +250,7 @@ public final class KafkaEventQueue implements EventQueue {
                             continue;
                         } else if (shuttingDown) {
                             remove(eventContext);
-                            toDeliver = new TimeoutException();
+                            toDeliver = new RejectedExecutionException();
                             toRun = eventContext;
                             continue;
                         }
diff --git a/server-common/src/test/java/org/apache/kafka/queue/KafkaEventQueueTest.java b/server-common/src/test/java/org/apache/kafka/queue/KafkaEventQueueTest.java
index d210df3b7a..7310cff637 100644
--- a/server-common/src/test/java/org/apache/kafka/queue/KafkaEventQueueTest.java
+++ b/server-common/src/test/java/org/apache/kafka/queue/KafkaEventQueueTest.java
@@ -218,7 +218,7 @@ public class KafkaEventQueueTest {
             __ -> OptionalLong.of(Time.SYSTEM.nanoseconds() + HOURS.toNanos(1)),
             new FutureEvent<>(future, () -> count.getAndAdd(1)));
         queue.beginShutdown("testShutdownBeforeDeferred");
-        assertThrows(ExecutionException.class, () -> future.get());
+        assertEquals(RejectedExecutionException.class, assertThrows(ExecutionException.class, () -> future.get()).getCause().getClass());
         assertEquals(0, count.get());
         queue.close();
     }
