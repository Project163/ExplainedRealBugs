diff --git a/core/src/main/scala/kafka/consumer/ZookeeperConsumerConnector.scala b/core/src/main/scala/kafka/consumer/ZookeeperConsumerConnector.scala
index d13c16d46a..6d38fc5011 100644
--- a/core/src/main/scala/kafka/consumer/ZookeeperConsumerConnector.scala
+++ b/core/src/main/scala/kafka/consumer/ZookeeperConsumerConnector.scala
@@ -120,7 +120,7 @@ private[kafka] class ZookeeperConsumerConnector(val config: ConsumerConfig,
   connectZk()
   createFetcher()
   if (config.autoCommit) {
-    scheduler.startUp
+    scheduler.startup
     info("starting auto committer every " + config.autoCommitIntervalMs + " ms")
     scheduler.scheduleWithRate(autoCommit, "Kafka-consumer-autocommit-", config.autoCommitIntervalMs,
       config.autoCommitIntervalMs, false)
diff --git a/core/src/main/scala/kafka/server/KafkaController.scala b/core/src/main/scala/kafka/server/KafkaController.scala
index 988e24bc93..68f5dd2ee1 100644
--- a/core/src/main/scala/kafka/server/KafkaController.scala
+++ b/core/src/main/scala/kafka/server/KafkaController.scala
@@ -38,14 +38,14 @@ class RequestSendThread(val controllerId: Int,
         extends Thread("requestSendThread-" + toBrokerId) with Logging {
   this.logIdent = "Controller %d, request send thread to broker %d, ".format(controllerId, toBrokerId)
   val isRunning: AtomicBoolean = new AtomicBoolean(true)
-  private val shutDownLatch = new CountDownLatch(1)
+  private val shutdownLatch = new CountDownLatch(1)
   private val lock = new Object()
 
-  def shutDown(): Unit = {
+  def shutdown(): Unit = {
     info("shutting down")
     isRunning.set(false)
     interrupt()
-    shutDownLatch.await()
+    shutdownLatch.await()
     info("shutted down completed")
   }
 
@@ -84,7 +84,7 @@ class RequestSendThread(val controllerId: Int,
       case e: InterruptedException => warn("intterrupted. Shutting down")
       case e1 => error("Error due to ", e1)
     }
-    shutDownLatch.countDown()
+    shutdownLatch.countDown()
   }
 }
 
@@ -107,7 +107,7 @@ class ControllerChannelManager(allBrokers: Set[Broker], config : KafkaConfig) ex
     messageQueues.put(broker.id, new LinkedBlockingQueue[(RequestOrResponse, (RequestOrResponse) => Unit)](config.controllerMessageQueueSize))
   }
 
-  def startUp() = {
+  def startup() = {
     for((brokerId, broker) <- brokers){
       val thread = new RequestSendThread(config.brokerId, brokerId, messageQueues(brokerId), messageChannels(brokerId))
       thread.setDaemon(false)
@@ -116,7 +116,7 @@ class ControllerChannelManager(allBrokers: Set[Broker], config : KafkaConfig) ex
     }
   }
 
-  def shutDown() = {
+  def shutdown() = {
     lock synchronized {
       for((brokerId, broker) <- brokers){
         removeBroker(brokerId)
@@ -152,7 +152,7 @@ class ControllerChannelManager(allBrokers: Set[Broker], config : KafkaConfig) ex
         messageChannels(brokerId).disconnect()
         messageChannels.remove(brokerId)
         messageQueues.remove(brokerId)
-        messageThreads(brokerId).shutDown()
+        messageThreads(brokerId).shutdown()
         messageThreads.remove(brokerId)
       }catch {
         case e => error("Error while removing broker by the controller", e)
@@ -163,7 +163,8 @@ class ControllerChannelManager(allBrokers: Set[Broker], config : KafkaConfig) ex
 
 class KafkaController(config : KafkaConfig, zkClient: ZkClient) extends Logging {
   this.logIdent = "Controller " + config.brokerId + ", "
-  info("startup");
+  info("startup")
+  private var isRunning = true
   private val controllerLock = new Object
   private var controllerChannelManager: ControllerChannelManager = null
   private var allBrokers : Set[Broker] = null
@@ -189,7 +190,7 @@ class KafkaController(config : KafkaConfig, zkClient: ZkClient) extends Logging
       info("allPartitionReplicaAssignment: %s".format(allPartitionReplicaAssignment))
       allLeaders = new mutable.HashMap[(String, Int), Int]
       controllerChannelManager = new ControllerChannelManager(allBrokers, config)
-      controllerChannelManager.startUp()
+      controllerChannelManager.startup()
       return true
     } catch {
       case e: ZkNodeExistsException =>
@@ -201,6 +202,10 @@ class KafkaController(config : KafkaConfig, zkClient: ZkClient) extends Logging
   }
 
   private def controllerRegisterOrFailover(){
+    if(!isRunning){
+      info("controller has already been shut down, don't need to compete for lead controller any more")
+      return
+    }
     info("try to become controller")
     if(tryToBecomeController() == true){
       info("won the controller competition and work on leader and isr recovery")
@@ -209,12 +214,7 @@ class KafkaController(config : KafkaConfig, zkClient: ZkClient) extends Logging
       onBrokerChange()
 
       // If there are some partition with leader not initialized, init the leader for them
-      val partitionReplicaAssignment = allPartitionReplicaAssignment.clone()
-      for((topicPartition, replicas) <- partitionReplicaAssignment){
-        if (allLeaders.contains(topicPartition)){
-          partitionReplicaAssignment.remove(topicPartition)
-        }
-      }
+      val partitionReplicaAssignment = allPartitionReplicaAssignment.filter(m => !allLeaders.contains(m._1))
       debug("work on init leaders: %s, current cache for all leader is: %s".format(partitionReplicaAssignment.toString(), allLeaders))
       initLeaders(partitionReplicaAssignment)
     }
@@ -228,18 +228,20 @@ class KafkaController(config : KafkaConfig, zkClient: ZkClient) extends Logging
     controllerLock synchronized {
       registerSessionExpirationListener()
       registerControllerExistListener()
+      isRunning = true
       controllerRegisterOrFailover()
     }
   }
 
-  def shutDown() = {
+  def shutdown() = {
     controllerLock synchronized {
       if(controllerChannelManager != null){
         info("shut down")
-        controllerChannelManager.shutDown()
+        controllerChannelManager.shutdown()
         controllerChannelManager = null
         info("shutted down completely")
       }
+      isRunning = false
     }
   }
 
@@ -280,11 +282,13 @@ class KafkaController(config : KafkaConfig, zkClient: ZkClient) extends Logging
     @throws(classOf[Exception])
     def handleNewSession() {
       controllerLock synchronized {
-        info("session expires, clean up the state")
-        controllerChannelManager.shutDown()
-        controllerChannelManager = null
-        controllerRegisterOrFailover()
+        if(controllerChannelManager != null){
+          info("session expires, clean up the state")
+          controllerChannelManager.shutdown()
+          controllerChannelManager = null
+        }
       }
+      controllerRegisterOrFailover()
     }
   }
 
diff --git a/core/src/main/scala/kafka/server/KafkaServer.scala b/core/src/main/scala/kafka/server/KafkaServer.scala
index 70bc70652b..3038399270 100644
--- a/core/src/main/scala/kafka/server/KafkaServer.scala
+++ b/core/src/main/scala/kafka/server/KafkaServer.scala
@@ -65,7 +65,7 @@ class KafkaServer(val config: KafkaConfig, time: Time = SystemTime) extends Logg
     }
 
     /* start scheduler */
-    kafkaScheduler.startUp
+    kafkaScheduler.startup
 
     /* start log manager */
     logManager = new LogManager(config,
@@ -132,7 +132,7 @@ class KafkaServer(val config: KafkaConfig, time: Time = SystemTime) extends Logg
         logManager.shutdown()
 
       if(kafkaController != null)
-        kafkaController.shutDown()
+        kafkaController.shutdown()
 
       val cleanShutDownFile = new File(new File(config.logDir), CleanShutdownFile)
       debug("creating clean shutdown file " + cleanShutDownFile.getAbsolutePath())
diff --git a/core/src/main/scala/kafka/utils/KafkaScheduler.scala b/core/src/main/scala/kafka/utils/KafkaScheduler.scala
index e3d915b3b4..4a70e8173e 100644
--- a/core/src/main/scala/kafka/utils/KafkaScheduler.scala
+++ b/core/src/main/scala/kafka/utils/KafkaScheduler.scala
@@ -34,7 +34,7 @@ class KafkaScheduler(val numThreads: Int) extends Logging {
     }
   private val threadNamesAndIds = new HashMap[String, AtomicInteger]()
 
-  def startUp = {
+  def startup = {
     executor = new ScheduledThreadPoolExecutor(numThreads)
     executor.setContinueExistingPeriodicTasksAfterShutdownPolicy(false)
     executor.setExecuteExistingDelayedTasksAfterShutdownPolicy(false)
diff --git a/core/src/test/scala/unit/kafka/log/LogManagerTest.scala b/core/src/test/scala/unit/kafka/log/LogManagerTest.scala
index ca16909f30..1fd176b028 100644
--- a/core/src/test/scala/unit/kafka/log/LogManagerTest.scala
+++ b/core/src/test/scala/unit/kafka/log/LogManagerTest.scala
@@ -46,7 +46,7 @@ class LogManagerTest extends JUnit3Suite with ZooKeeperTestHarness {
                    override val logFileSize = 1024
                    override val flushInterval = 100
                  }
-    scheduler.startUp
+    scheduler.startup
     logManager = new LogManager(config, scheduler, time, veryLargeLogFlushInterval, maxLogAge, false)
     logManager.startup
     logDir = logManager.logDir
diff --git a/core/src/test/scala/unit/kafka/server/HighwatermarkPersistenceTest.scala b/core/src/test/scala/unit/kafka/server/HighwatermarkPersistenceTest.scala
index a2f1de924f..2b9f86a11e 100644
--- a/core/src/test/scala/unit/kafka/server/HighwatermarkPersistenceTest.scala
+++ b/core/src/test/scala/unit/kafka/server/HighwatermarkPersistenceTest.scala
@@ -37,7 +37,7 @@ class HighwatermarkPersistenceTest extends JUnit3Suite {
     EasyMock.replay(zkClient)
     // create kafka scheduler
     val scheduler = new KafkaScheduler(2)
-    scheduler.startUp
+    scheduler.startup
     // create replica manager
     val replicaManager = new ReplicaManager(configs.head, new MockTime(), zkClient, scheduler, null)
     replicaManager.startup()
@@ -80,7 +80,7 @@ class HighwatermarkPersistenceTest extends JUnit3Suite {
     EasyMock.replay(zkClient)
     // create kafka scheduler
     val scheduler = new KafkaScheduler(2)
-    scheduler.startUp
+    scheduler.startup
     // create replica manager
     val replicaManager = new ReplicaManager(configs.head, new MockTime(), zkClient, scheduler, null)
     replicaManager.startup()
