diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/AssignedTasks.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/AssignedTasks.java
index 5afcd7473f..c0c9ccce10 100644
--- a/streams/src/main/java/org/apache/kafka/streams/processor/internals/AssignedTasks.java
+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/AssignedTasks.java
@@ -116,6 +116,7 @@ class AssignedTasks {
             final Map.Entry<TaskId, Task> entry = it.next();
             try {
                 if (!entry.getValue().initialize()) {
+                    log.debug("{} transitioning {} {} to restoring", logPrefix, taskTypeName, entry.getKey());
                     restoring.put(entry.getKey(), entry.getValue());
                 } else {
                     transitionToRunning(entry.getValue());
@@ -142,6 +143,16 @@ class AssignedTasks {
                 transitionToRunning(task);
                 resume.addAll(task.partitions());
                 it.remove();
+            } else {
+                if (log.isTraceEnabled()) {
+                    final HashSet<TopicPartition> outstandingPartitions = new HashSet<>(task.changelogPartitions());
+                    outstandingPartitions.removeAll(restoredPartitions);
+                    log.trace("{} partition restoration not complete for {} {} partitions: {}",
+                              logPrefix,
+                              taskTypeName,
+                              task.id(),
+                              task.changelogPartitions());
+                }
             }
         }
         if (allTasksRunning()) {
@@ -252,6 +263,7 @@ class AssignedTasks {
     }
 
     private void transitionToRunning(final Task task) {
+        log.debug("{} transitioning {} {} to running", logPrefix, taskTypeName, task.id());
         running.put(task.id(), task);
         for (TopicPartition topicPartition : task.partitions()) {
             runningByPartition.put(topicPartition, task);
diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreChangelogReader.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreChangelogReader.java
index d26ace1d7e..e2cb3a233d 100644
--- a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreChangelogReader.java
+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreChangelogReader.java
@@ -46,11 +46,11 @@ public class StoreChangelogReader implements ChangelogReader {
     private final Time time;
     private final long partitionValidationTimeoutMs;
     private final Map<String, List<PartitionInfo>> partitionInfo = new HashMap<>();
-    private final Map<TopicPartition, StateRestorer> stateRestorers = new HashMap<>();
     private final StateRestoreListener stateRestoreListener;
+    private final Map<TopicPartition, StateRestorer> stateRestorers = new HashMap<>();
     private final Map<TopicPartition, StateRestorer> needsRestoring = new HashMap<>();
+    private final Map<TopicPartition, StateRestorer> needsInitializing = new HashMap<>();
     private final Map<TopicPartition, Long> endOffsets = new HashMap<>();
-    private boolean initialized = false;
 
     public StoreChangelogReader(final String threadId, final Consumer<byte[], byte[]> consumer, final Time time,
                                 final long partitionValidationTimeoutMs, final StateRestoreListener stateRestoreListener) {
@@ -103,62 +103,67 @@ public class StoreChangelogReader implements ChangelogReader {
     public void register(final StateRestorer restorer) {
         restorer.setGlobalRestoreListener(stateRestoreListener);
         stateRestorers.put(restorer.partition(), restorer);
+        needsInitializing.put(restorer.partition(), restorer);
     }
 
 
     public Collection<TopicPartition> restore() {
-        final List<TopicPartition> completed = new ArrayList<>();
-        if (!initialized) {
-            completed.addAll(initialize());
+        if (!needsInitializing.isEmpty()) {
+            initialize();
         }
 
         if (needsRestoring.isEmpty()) {
             consumer.assign(Collections.<TopicPartition>emptyList());
-            return completed;
+            return completed();
         }
 
         final Set<TopicPartition> partitions = new HashSet<>(needsRestoring.keySet());
         final ConsumerRecords<byte[], byte[]> allRecords = consumer.poll(10);
         for (final TopicPartition partition : partitions) {
-            if (restorePartition(allRecords, partition)) {
-                completed.add(partition);
-            }
+            restorePartition(allRecords, partition);
         }
 
         if (needsRestoring.isEmpty()) {
             consumer.assign(Collections.<TopicPartition>emptyList());
         }
-        return completed;
+
+        return completed();
     }
 
-    private Collection<TopicPartition> initialize() {
-        needsRestoring.clear();
+    private void initialize() {
+        final Map<TopicPartition, StateRestorer> newTasksNeedingRestoration = new HashMap<>();
+
         if (!consumer.subscription().isEmpty()) {
             throw new IllegalStateException(String.format("Restore consumer should have not subscribed to any partitions (%s) beforehand", consumer.subscription()));
         }
-        endOffsets.putAll(consumer.endOffsets(stateRestorers.keySet()));
+        endOffsets.putAll(consumer.endOffsets(needsInitializing.keySet()));
 
         // remove any partitions where we already have all of the data
         for (final Map.Entry<TopicPartition, Long> entry : endOffsets.entrySet()) {
             TopicPartition topicPartition = entry.getKey();
             Long offset = entry.getValue();
-            final StateRestorer restorer = stateRestorers.get(topicPartition);
-            if (restorer.checkpoint() >= offset) {
-                restorer.setRestoredOffset(restorer.checkpoint());
-            } else if (restorer.offsetLimit() == 0) {
-                restorer.setRestoredOffset(0);
-            } else {
-                needsRestoring.put(topicPartition, restorer);
-                final Long endOffset = endOffsets.get(topicPartition);
-                restorer.restoreStarted(restorer.startingOffset(), endOffset);
+            final StateRestorer restorer = needsInitializing.get(topicPartition);
+            // might be null as has was initialized in a previous invocation.
+            if (restorer != null) {
+                if (restorer.checkpoint() >= offset) {
+                    restorer.setRestoredOffset(restorer.checkpoint());
+                } else if (restorer.offsetLimit() == 0 || endOffsets.get(topicPartition) == 0) {
+                    restorer.setRestoredOffset(0);
+                } else {
+                    newTasksNeedingRestoration.put(topicPartition, restorer);
+                    final Long endOffset = endOffsets.get(topicPartition);
+                    restorer.restoreStarted(restorer.startingOffset(), endOffset);
+                }
             }
         }
 
-        log.debug("{} Starting restoring state stores from changelog topics {}", logPrefix, needsRestoring.keySet());
+        log.debug("{} Starting restoring state stores from changelog topics {}", logPrefix, newTasksNeedingRestoration.keySet());
 
-        consumer.assign(needsRestoring.keySet());
+        final Set<TopicPartition> assignment = new HashSet<>(consumer.assignment());
+        assignment.addAll(newTasksNeedingRestoration.keySet());
+        consumer.assign(assignment);
         final List<StateRestorer> needsPositionUpdate = new ArrayList<>();
-        for (final StateRestorer restorer : needsRestoring.values()) {
+        for (final StateRestorer restorer : newTasksNeedingRestoration.values()) {
             if (restorer.checkpoint() != StateRestorer.NO_CHECKPOINT) {
                 consumer.seek(restorer.partition(), restorer.checkpoint());
                 logRestoreOffsets(restorer.partition(),
@@ -179,10 +184,8 @@ public class StoreChangelogReader implements ChangelogReader {
                               endOffsets.get(restorer.partition()));
         }
 
-        final Set<TopicPartition> completed = new HashSet<>(stateRestorers.keySet());
-        completed.removeAll(needsRestoring.keySet());
-        initialized = true;
-        return completed;
+        needsRestoring.putAll(newTasksNeedingRestoration);
+        needsInitializing.clear();
     }
 
     private void logRestoreOffsets(final TopicPartition partition, final long startingOffset, final Long endOffset) {
@@ -193,6 +196,13 @@ public class StoreChangelogReader implements ChangelogReader {
                   endOffset);
     }
 
+    private Collection<TopicPartition> completed() {
+        final Set<TopicPartition> completed = new HashSet<>(stateRestorers.keySet());
+        completed.removeAll(needsRestoring.keySet());
+        log.debug("{} completed partitions {}", logPrefix, completed);
+        return completed;
+    }
+
     @Override
     public Map<TopicPartition, Long> restoredOffsets() {
         final Map<TopicPartition, Long> restoredOffsets = new HashMap<>();
@@ -211,10 +221,10 @@ public class StoreChangelogReader implements ChangelogReader {
         stateRestorers.clear();
         needsRestoring.clear();
         endOffsets.clear();
-        initialized = false;
+        needsInitializing.clear();
     }
 
-    private boolean restorePartition(final ConsumerRecords<byte[], byte[]> allRecords,
+    private void restorePartition(final ConsumerRecords<byte[], byte[]> allRecords,
                                     final TopicPartition topicPartition) {
         final StateRestorer restorer = stateRestorers.get(topicPartition);
         final Long endOffset = endOffsets.get(topicPartition);
@@ -238,9 +248,7 @@ public class StoreChangelogReader implements ChangelogReader {
 
             restorer.restoreDone();
             needsRestoring.remove(topicPartition);
-            return true;
         }
-        return false;
     }
 
     private long processNext(final List<ConsumerRecord<byte[], byte[]>> records,
diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StoreChangelogReaderTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StoreChangelogReaderTest.java
index be3cb408d4..8ac9a6233d 100644
--- a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StoreChangelogReaderTest.java
+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StoreChangelogReaderTest.java
@@ -34,6 +34,7 @@ import org.hamcrest.CoreMatchers;
 import org.junit.Before;
 import org.junit.Test;
 
+import java.util.Collection;
 import java.util.Collections;
 import java.util.List;
 import java.util.Map;
@@ -43,6 +44,7 @@ import static org.apache.kafka.test.MockStateRestoreListener.RESTORE_END;
 import static org.apache.kafka.test.MockStateRestoreListener.RESTORE_START;
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.core.IsEqual.equalTo;
+import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 public class StoreChangelogReaderTest {
@@ -332,13 +334,54 @@ public class StoreChangelogReaderTest {
         assertThat(callback.restored, CoreMatchers.equalTo(Utils.mkList(KeyValue.pair(bytes, bytes), KeyValue.pair(bytes, bytes))));
     }
 
+    @Test
+    public void shouldCompleteImmediatelyWhenEndOffsetIs0() {
+        final Collection<TopicPartition> expected = Collections.singleton(topicPartition);
+        setupConsumer(0, topicPartition);
+        changelogReader.register(new StateRestorer(topicPartition, restoreListener, null, Long.MAX_VALUE, true, "store"));
+        final Collection<TopicPartition> restored = changelogReader.restore();
+        assertThat(restored, equalTo(expected));
+    }
+
+    @Test
+    public void shouldRestorePartitionsRegisteredPostInitialization() {
+        final MockRestoreCallback callbackTwo = new MockRestoreCallback();
+        final CompositeRestoreListener restoreListener2 = new CompositeRestoreListener(callbackTwo);
+
+        setupConsumer(1, topicPartition);
+        consumer.updateEndOffsets(Collections.singletonMap(topicPartition, 10L));
+        changelogReader.register(new StateRestorer(topicPartition, restoreListener, null, Long.MAX_VALUE, false,
+                                                   "storeName"));
+
+        assertTrue(changelogReader.restore().isEmpty());
+
+        final TopicPartition postInitialization = new TopicPartition("other", 0);
+        consumer.updateBeginningOffsets(Collections.singletonMap(postInitialization, 0L));
+        consumer.updateEndOffsets(Collections.singletonMap(postInitialization, 3L));
+
+        changelogReader.register(new StateRestorer(postInitialization, restoreListener2, null, Long.MAX_VALUE, false, "otherStore"));
+
+        addRecords(9, topicPartition, 1);
+
+        final Collection<TopicPartition> expected = Utils.mkSet(topicPartition, postInitialization);
+
+        consumer.assign(expected);
+        addRecords(3, postInitialization, 0);
+        assertThat(changelogReader.restore(), equalTo(expected));
+        assertThat(callback.restored.size(), equalTo(10));
+        assertThat(callbackTwo.restored.size(), equalTo(3));
+    }
+
     private void setupConsumer(final long messages, final TopicPartition topicPartition) {
         assignPartition(messages, topicPartition);
+        addRecords(messages, topicPartition, 0);
+        consumer.assign(Collections.<TopicPartition>emptyList());
+    }
 
+    private void addRecords(final long messages, final TopicPartition topicPartition, final int startingOffset) {
         for (int i = 0; i < messages; i++) {
-            consumer.addRecord(new ConsumerRecord<>(topicPartition.topic(), topicPartition.partition(), i, new byte[0], new byte[0]));
+            consumer.addRecord(new ConsumerRecord<>(topicPartition.topic(), topicPartition.partition(), startingOffset + i, new byte[0], new byte[0]));
         }
-        consumer.assign(Collections.<TopicPartition>emptyList());
     }
 
     private void assignPartition(final long messages, final TopicPartition topicPartition) {
