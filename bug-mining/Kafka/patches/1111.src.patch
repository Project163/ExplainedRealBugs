diff --git a/core/src/main/scala/kafka/log/FileMessageSet.scala b/core/src/main/scala/kafka/log/FileMessageSet.scala
index a454f2cbe2..c8bce658d9 100755
--- a/core/src/main/scala/kafka/log/FileMessageSet.scala
+++ b/core/src/main/scala/kafka/log/FileMessageSet.scala
@@ -54,12 +54,12 @@ class FileMessageSet private[kafka](@volatile var file: File,
     if(isSlice)
       new AtomicInteger(end - start) // don't check the file size if this is just a slice view
     else
-      new AtomicInteger(math.min(channel.size().toInt, end) - start)
+      new AtomicInteger(math.min(channel.size.toInt, end) - start)
 
   /* if this is not a slice, update the file pointer to the end of the file */
   if (!isSlice)
     /* set the file position to the last byte in the file */
-    channel.position(math.min(channel.size().toInt, end))
+    channel.position(math.min(channel.size.toInt, end))
 
   /**
    * Create a file message set with no slicing.
@@ -157,7 +157,7 @@ class FileMessageSet private[kafka](@volatile var file: File,
    */
   def writeTo(destChannel: GatheringByteChannel, writePosition: Long, size: Int): Int = {
     // Ensure that the underlying size has not changed.
-    val newSize = math.min(channel.size().toInt, end) - start
+    val newSize = math.min(channel.size.toInt, end) - start
     if (newSize < _size.get()) {
       throw new KafkaException("Size of FileMessageSet %s has been truncated during write: old size %d, new size %d"
         .format(file.getAbsolutePath, _size.get(), newSize))
@@ -333,7 +333,11 @@ class FileMessageSet private[kafka](@volatile var file: File,
   /**
    * Truncate this file message set to the given size in bytes. Note that this API does no checking that the
    * given size falls on a valid message boundary.
-   * @param targetSize The size to truncate to.
+   * In some versions of the JDK truncating to the same size as the file message set will cause an
+   * update of the files mtime, so truncate is only performed if the targetSize is smaller than the
+   * size of the underlying FileChannel.
+   * It is expected that no other threads will do writes to the log when this function is called.
+   * @param targetSize The size to truncate to. Must be between 0 and sizeInBytes.
    * @return The number of bytes truncated off
    */
   def truncateTo(targetSize: Int): Int = {
@@ -341,9 +345,11 @@ class FileMessageSet private[kafka](@volatile var file: File,
     if(targetSize > originalSize || targetSize < 0)
       throw new KafkaException("Attempt to truncate log segment to " + targetSize + " bytes failed, " +
                                " size of this log segment is " + originalSize + " bytes.")
-    channel.truncate(targetSize)
-    channel.position(targetSize)
-    _size.set(targetSize)
+    if (targetSize < channel.size.toInt) {
+      channel.truncate(targetSize)
+      channel.position(targetSize)
+      _size.set(targetSize)
+    }
     originalSize - targetSize
   }
 
diff --git a/core/src/test/scala/unit/kafka/log/FileMessageSetTest.scala b/core/src/test/scala/unit/kafka/log/FileMessageSetTest.scala
index 417aa7528e..a64454d316 100644
--- a/core/src/test/scala/unit/kafka/log/FileMessageSetTest.scala
+++ b/core/src/test/scala/unit/kafka/log/FileMessageSetTest.scala
@@ -19,12 +19,14 @@ package kafka.log
 
 import java.io._
 import java.nio._
-import java.util.concurrent.atomic._
+import java.nio.channels._
 
 import kafka.common.LongRef
 import org.junit.Assert._
 import kafka.utils.TestUtils._
 import kafka.message._
+import kafka.common.KafkaException
+import org.easymock.EasyMock
 import org.junit.Test
 
 class FileMessageSetTest extends BaseMessageSetTestCases {
@@ -152,6 +154,69 @@ class FileMessageSetTest extends BaseMessageSetTestCases {
     assertEquals(MessageSet.entrySize(message.message), messageSet.sizeInBytes)
   }
 
+  /**
+    * Test that truncateTo only calls truncate on the FileChannel if the size of the
+    * FileChannel is bigger than the target size. This is important because some JVMs
+    * change the mtime of the file, even if truncate should do nothing.
+    */
+  @Test
+  def testTruncateNotCalledIfSizeIsSameAsTargetSize() {
+    val channelMock = EasyMock.createMock(classOf[FileChannel])
+
+    EasyMock.expect(channelMock.size).andReturn(42L).atLeastOnce()
+    EasyMock.expect(channelMock.position(42L)).andReturn(null)
+    EasyMock.replay(channelMock)
+
+    val msgSet = new FileMessageSet(tempFile(), channelMock)
+    msgSet.truncateTo(42)
+
+    EasyMock.verify(channelMock)
+  }
+
+  /**
+    * Expect a KafkaException if targetSize is bigger than the size of
+    * the FileMessageSet.
+    */
+  @Test
+  def testTruncateNotCalledIfSizeIsBiggerThanTargetSize() {
+    val channelMock = EasyMock.createMock(classOf[FileChannel])
+
+    EasyMock.expect(channelMock.size).andReturn(42L).atLeastOnce()
+    EasyMock.expect(channelMock.position(42L)).andReturn(null)
+    EasyMock.replay(channelMock)
+
+    val msgSet = new FileMessageSet(tempFile(), channelMock)
+
+    try {
+      msgSet.truncateTo(43)
+      fail("Should throw KafkaException")
+    } catch {
+      case e: KafkaException => // expected
+    }
+
+    EasyMock.verify(channelMock)
+  }
+
+  /**
+    * see #testTruncateNotCalledIfSizeIsSameAsTargetSize
+    */
+  @Test
+  def testTruncateIfSizeIsDifferentToTargetSize() {
+    val channelMock = EasyMock.createMock(classOf[FileChannel])
+
+    EasyMock.expect(channelMock.size).andReturn(42L).atLeastOnce()
+    EasyMock.expect(channelMock.position(42L)).andReturn(null).once()
+    EasyMock.expect(channelMock.truncate(23L)).andReturn(null).once()
+    EasyMock.expect(channelMock.position(23L)).andReturn(null).once()
+    EasyMock.replay(channelMock)
+
+    val msgSet = new FileMessageSet(tempFile(), channelMock)
+    msgSet.truncateTo(23)
+
+    EasyMock.verify(channelMock)
+  }
+
+
   /**
    * Test the new FileMessageSet with pre allocate as true
    */
