diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/AsyncKafkaConsumer.java b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/AsyncKafkaConsumer.java
index cca3fbc44b..fd0a9d0f38 100644
--- a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/AsyncKafkaConsumer.java
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/AsyncKafkaConsumer.java
@@ -54,7 +54,6 @@ import org.apache.kafka.clients.consumer.internals.events.ErrorEvent;
 import org.apache.kafka.clients.consumer.internals.events.EventProcessor;
 import org.apache.kafka.clients.consumer.internals.events.FetchCommittedOffsetsEvent;
 import org.apache.kafka.clients.consumer.internals.events.ListOffsetsEvent;
-import org.apache.kafka.clients.consumer.internals.events.NewTopicsMetadataUpdateRequestEvent;
 import org.apache.kafka.clients.consumer.internals.events.PollEvent;
 import org.apache.kafka.clients.consumer.internals.events.ResetPositionsEvent;
 import org.apache.kafka.clients.consumer.internals.events.SubscriptionChangeEvent;
@@ -1443,12 +1442,9 @@ public class AsyncKafkaConsumer<K, V> implements ConsumerDelegate<K, V> {
             // be no following rebalance.
             //
             // See the ApplicationEventProcessor.process() method that handles this event for more detail.
-            applicationEventHandler.add(new AssignmentChangeEvent(subscriptions.allConsumed(), time.milliseconds()));
-
-            log.info("Assigned to partition(s): {}", partitions.stream().map(TopicPartition::toString).collect(Collectors.joining(", ")));
-
-            if (subscriptions.assignFromUser(new HashSet<>(partitions)))
-                applicationEventHandler.add(new NewTopicsMetadataUpdateRequestEvent());
+            Timer timer = time.timer(defaultApiTimeoutMs);
+            AssignmentChangeEvent assignmentChangeEvent = new AssignmentChangeEvent(timer.currentTimeMs(), calculateDeadlineMs(timer), partitions);
+            applicationEventHandler.addAndGet(assignmentChangeEvent);
         } finally {
             release();
         }
diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerUtils.java b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerUtils.java
index d553a4980a..89f3fefae2 100644
--- a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerUtils.java
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerUtils.java
@@ -219,6 +219,8 @@ public final class ConsumerUtils {
         try {
             return future.get(timer.remainingMs(), TimeUnit.MILLISECONDS);
         } catch (ExecutionException e) {
+            if (e.getCause() instanceof IllegalStateException)
+                throw (IllegalStateException) e.getCause();
             throw maybeWrapAsKafkaException(e.getCause());
         } catch (InterruptedException e) {
             throw new InterruptException(e);
@@ -231,6 +233,8 @@ public final class ConsumerUtils {
         try {
             return future.get();
         } catch (ExecutionException e) {
+            if (e.getCause() instanceof IllegalStateException)
+                throw (IllegalStateException) e.getCause();
             throw maybeWrapAsKafkaException(e.getCause());
         } catch (InterruptedException e) {
             throw new InterruptException(e);
diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/events/ApplicationEventProcessor.java b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/events/ApplicationEventProcessor.java
index 76159e45ee..b28750ac7f 100644
--- a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/events/ApplicationEventProcessor.java
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/events/ApplicationEventProcessor.java
@@ -34,11 +34,13 @@ import org.apache.kafka.common.utils.LogContext;
 
 import org.slf4j.Logger;
 
+import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.CompletableFuture;
 import java.util.function.BiConsumer;
 import java.util.function.Supplier;
+import java.util.stream.Collectors;
 
 /**
  * An {@link EventProcessor} that is created and executes in the {@link ConsumerNetworkThread network thread}
@@ -81,10 +83,6 @@ public class ApplicationEventProcessor implements EventProcessor<ApplicationEven
                 process((FetchCommittedOffsetsEvent) event);
                 return;
 
-            case NEW_TOPICS_METADATA_UPDATE:
-                process((NewTopicsMetadataUpdateRequestEvent) event);
-                return;
-
             case ASSIGNMENT_CHANGE:
                 process((AssignmentChangeEvent) event);
                 return;
@@ -194,21 +192,26 @@ public class ApplicationEventProcessor implements EventProcessor<ApplicationEven
         future.whenComplete(complete(event.future()));
     }
 
-    private void process(final NewTopicsMetadataUpdateRequestEvent ignored) {
-        metadata.requestUpdateForNewTopics();
-    }
-
     /**
      * Commit all consumed if auto-commit is enabled. Note this will trigger an async commit,
      * that will not be retried if the commit request fails.
      */
     private void process(final AssignmentChangeEvent event) {
-        if (!requestManagers.commitRequestManager.isPresent()) {
-            return;
+        if (requestManagers.commitRequestManager.isPresent()) {
+            CommitRequestManager manager = requestManagers.commitRequestManager.get();
+            manager.updateAutoCommitTimer(event.currentTimeMs());
+            manager.maybeAutoCommitAsync();
+        }
+
+        log.info("Assigned to partition(s): {}", event.partitions().stream().map(TopicPartition::toString).collect(Collectors.joining(", ")));
+        try {
+            if (subscriptions.assignFromUser(new HashSet<>(event.partitions())))
+                metadata.requestUpdateForNewTopics();
+
+            event.future().complete(null);
+        } catch (Exception e) {
+            event.future().completeExceptionally(e);
         }
-        CommitRequestManager manager = requestManagers.commitRequestManager.get();
-        manager.updateAutoCommitTimer(event.currentTimeMs());
-        manager.maybeAutoCommitAsync();
     }
 
     /**
diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/events/AssignmentChangeEvent.java b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/events/AssignmentChangeEvent.java
index c9efa2e9df..68e1bbc5e6 100644
--- a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/events/AssignmentChangeEvent.java
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/events/AssignmentChangeEvent.java
@@ -16,33 +16,33 @@
  */
 package org.apache.kafka.clients.consumer.internals.events;
 
-import org.apache.kafka.clients.consumer.OffsetAndMetadata;
 import org.apache.kafka.common.TopicPartition;
 
+import java.util.Collection;
 import java.util.Collections;
-import java.util.Map;
+import java.util.HashSet;
 
-public class AssignmentChangeEvent extends ApplicationEvent {
+public class AssignmentChangeEvent extends CompletableApplicationEvent<Void> {
 
-    private final Map<TopicPartition, OffsetAndMetadata> offsets;
     private final long currentTimeMs;
+    private final Collection<TopicPartition> partitions;
 
-    public AssignmentChangeEvent(final Map<TopicPartition, OffsetAndMetadata> offsets, final long currentTimeMs) {
-        super(Type.ASSIGNMENT_CHANGE);
-        this.offsets = Collections.unmodifiableMap(offsets);
+    public AssignmentChangeEvent(final long currentTimeMs, final long deadlineMs, final Collection<TopicPartition> partitions) {
+        super(Type.ASSIGNMENT_CHANGE, deadlineMs);
         this.currentTimeMs = currentTimeMs;
-    }
-
-    public Map<TopicPartition, OffsetAndMetadata> offsets() {
-        return offsets;
+        this.partitions = Collections.unmodifiableSet(new HashSet<>(partitions));
     }
 
     public long currentTimeMs() {
         return currentTimeMs;
     }
 
+    public Collection<TopicPartition> partitions() {
+        return partitions;
+    }
+
     @Override
     protected String toStringBase() {
-        return super.toStringBase() + ", offsets=" + offsets + ", currentTimeMs=" + currentTimeMs;
+        return super.toStringBase() + ", currentTimeMs=" + currentTimeMs + ", partitions=" + partitions;
     }
 }
diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/events/NewTopicsMetadataUpdateRequestEvent.java b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/events/NewTopicsMetadataUpdateRequestEvent.java
deleted file mode 100644
index b06bd456f5..0000000000
--- a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/events/NewTopicsMetadataUpdateRequestEvent.java
+++ /dev/null
@@ -1,24 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License. You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.kafka.clients.consumer.internals.events;
-
-public class NewTopicsMetadataUpdateRequestEvent extends ApplicationEvent {
-
-    public NewTopicsMetadataUpdateRequestEvent() {
-        super(Type.NEW_TOPICS_METADATA_UPDATE);
-    }
-}
diff --git a/clients/src/test/java/org/apache/kafka/clients/consumer/internals/AsyncKafkaConsumerTest.java b/clients/src/test/java/org/apache/kafka/clients/consumer/internals/AsyncKafkaConsumerTest.java
index c00129c3c6..028f61f0bf 100644
--- a/clients/src/test/java/org/apache/kafka/clients/consumer/internals/AsyncKafkaConsumerTest.java
+++ b/clients/src/test/java/org/apache/kafka/clients/consumer/internals/AsyncKafkaConsumerTest.java
@@ -43,7 +43,6 @@ import org.apache.kafka.clients.consumer.internals.events.ErrorEvent;
 import org.apache.kafka.clients.consumer.internals.events.EventProcessor;
 import org.apache.kafka.clients.consumer.internals.events.FetchCommittedOffsetsEvent;
 import org.apache.kafka.clients.consumer.internals.events.ListOffsetsEvent;
-import org.apache.kafka.clients.consumer.internals.events.NewTopicsMetadataUpdateRequestEvent;
 import org.apache.kafka.clients.consumer.internals.events.PollEvent;
 import org.apache.kafka.clients.consumer.internals.events.ResetPositionsEvent;
 import org.apache.kafka.clients.consumer.internals.events.SubscriptionChangeEvent;
@@ -90,6 +89,7 @@ import java.util.Arrays;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
@@ -401,6 +401,7 @@ public class AsyncKafkaConsumerTest {
         completeFetchedCommittedOffsetApplicationEventSuccessfully(offsets);
         completeCommitSyncApplicationEventSuccessfully();
         doReturn(LeaderAndEpoch.noLeaderOrEpoch()).when(metadata).currentLeader(any());
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(singleton(tp));
 
         consumer.wakeup();
@@ -423,6 +424,7 @@ public class AsyncKafkaConsumerTest {
         completeFetchedCommittedOffsetApplicationEventSuccessfully(offsets);
         completeCommitSyncApplicationEventSuccessfully();
         doReturn(LeaderAndEpoch.noLeaderOrEpoch()).when(metadata).currentLeader(any());
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(singleton(tp));
 
         assertThrows(WakeupException.class, () -> consumer.poll(Duration.ofMinutes(1)));
@@ -447,6 +449,7 @@ public class AsyncKafkaConsumerTest {
         completeFetchedCommittedOffsetApplicationEventSuccessfully(offsets);
         completeCommitSyncApplicationEventSuccessfully();
         doReturn(LeaderAndEpoch.noLeaderOrEpoch()).when(metadata).currentLeader(any());
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(singleton(tp));
 
         // since wakeup() is called when the non-empty fetch is returned the wakeup should be ignored
@@ -541,6 +544,7 @@ public class AsyncKafkaConsumerTest {
         completeFetchedCommittedOffsetApplicationEventSuccessfully(offsets);
         completeCommitSyncApplicationEventSuccessfully();
         doReturn(LeaderAndEpoch.noLeaderOrEpoch()).when(metadata).currentLeader(any());
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(singleton(tp));
 
         consumer.poll(Duration.ZERO);
@@ -587,6 +591,7 @@ public class AsyncKafkaConsumerTest {
         consumer = newConsumer();
         long timeoutMs = 0;
         doReturn(Fetch.empty()).when(fetchCollector).collectFetch(any(FetchBuffer.class));
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(Collections.singleton(new TopicPartition("topic1", 0)));
 
         // The first attempt at poll() creates an event, enqueues it, but its Future does not complete within the
@@ -616,6 +621,7 @@ public class AsyncKafkaConsumerTest {
 
         // The first attempt at poll() retrieves data for partition 0 of the topic. poll() creates an event,
         // enqueues it, but its Future does not complete within the timeout, leaving a pending fetch.
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(Collections.singleton(new TopicPartition("topic1", 0)));
         consumer.poll(Duration.ofMillis(timeoutMs));
         verify(applicationEventHandler).add(any(FetchCommittedOffsetsEvent.class));
@@ -652,6 +658,7 @@ public class AsyncKafkaConsumerTest {
         consumer = newConsumer();
         long timeoutMs = 0;
         doReturn(Fetch.empty()).when(fetchCollector).collectFetch(any(FetchBuffer.class));
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(Collections.singleton(new TopicPartition("topic1", 0)));
 
         // The first attempt at poll() creates an event, enqueues it, but its Future does not complete within
@@ -680,6 +687,7 @@ public class AsyncKafkaConsumerTest {
         consumer = newConsumer();
         long timeoutMs = 0;
         doReturn(Fetch.empty()).when(fetchCollector).collectFetch(any(FetchBuffer.class));
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(Collections.singleton(new TopicPartition("topic1", 0)));
 
         consumer.poll(Duration.ofMillis(timeoutMs));
@@ -697,6 +705,7 @@ public class AsyncKafkaConsumerTest {
         consumer = newConsumer();
         long timeoutMs = 0;
         doReturn(Fetch.empty()).when(fetchCollector).collectFetch(any(FetchBuffer.class));
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(Collections.singleton(new TopicPartition("topic1", 0)));
 
         consumer.poll(Duration.ofMillis(timeoutMs));
@@ -715,6 +724,7 @@ public class AsyncKafkaConsumerTest {
         consumer = newConsumer();
         long timeoutMs = 0;
         doReturn(Fetch.empty()).when(fetchCollector).collectFetch(any(FetchBuffer.class));
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(Collections.singleton(new TopicPartition("topic1", 0)));
 
         consumer.poll(Duration.ofMillis(timeoutMs));
@@ -737,6 +747,7 @@ public class AsyncKafkaConsumerTest {
         topicPartitionOffsets.put(t1, new OffsetAndMetadata(20L, Optional.of(1), ""));
         completeCommitSyncApplicationEventSuccessfully();
 
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(Arrays.asList(t0, t1));
 
         assertDoesNotThrow(() -> consumer.commitSync(topicPartitionOffsets));
@@ -768,6 +779,7 @@ public class AsyncKafkaConsumerTest {
         when(metadata.currentLeader(t1)).thenReturn(
             new LeaderAndEpoch(Optional.of(
                 new Node(1, "host", 9000)), Optional.of(1)));
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(Arrays.asList(t0, t1));
         consumer.seek(t0, 10);
         consumer.seek(t1, 20);
@@ -802,6 +814,7 @@ public class AsyncKafkaConsumerTest {
         completeFetchedCommittedOffsetApplicationEventSuccessfully(mkMap());
         doReturn(LeaderAndEpoch.noLeaderOrEpoch()).when(metadata).currentLeader(any());
         final TopicPartition tp = new TopicPartition("foo", 0);
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(Collections.singleton(tp));
         consumer.seek(tp, 20);
 
@@ -824,6 +837,7 @@ public class AsyncKafkaConsumerTest {
         completeFetchedCommittedOffsetApplicationEventSuccessfully(mkMap());
         doReturn(LeaderAndEpoch.noLeaderOrEpoch()).when(metadata).currentLeader(any());
         final TopicPartition tp = new TopicPartition("foo", 0);
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(Collections.singleton(tp));
         consumer.seek(tp, 20);
 
@@ -890,6 +904,7 @@ public class AsyncKafkaConsumerTest {
 
         // Commit async (incomplete)
         doReturn(LeaderAndEpoch.noLeaderOrEpoch()).when(metadata).currentLeader(any());
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(Collections.singleton(tp));
         consumer.seek(tp, 20);
         consumer.commitAsync();
@@ -920,6 +935,7 @@ public class AsyncKafkaConsumerTest {
         completeFetchedCommittedOffsetApplicationEventSuccessfully(mkMap());
         doReturn(LeaderAndEpoch.noLeaderOrEpoch()).when(metadata).currentLeader(any());
         final TopicPartition tp = new TopicPartition("foo", 0);
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(Collections.singleton(tp));
         consumer.seek(tp, 20);
 
@@ -937,6 +953,7 @@ public class AsyncKafkaConsumerTest {
         doReturn(Fetch.empty()).when(fetchCollector).collectFetch(any(FetchBuffer.class));
         completeFetchedCommittedOffsetApplicationEventSuccessfully(mkMap());
 
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(Collections.singleton(new TopicPartition("foo", 0)));
         assertDoesNotThrow(() -> consumer.commitAsync(new HashMap<>(), callback));
         assertMockCommitCallbackInvoked(() -> consumer.poll(Duration.ZERO),
@@ -1062,11 +1079,11 @@ public class AsyncKafkaConsumerTest {
     public void testAssign() {
         consumer = newConsumer();
         final TopicPartition tp = new TopicPartition("foo", 3);
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(singleton(tp));
         assertTrue(consumer.subscription().isEmpty());
         assertTrue(consumer.assignment().contains(tp));
-        verify(applicationEventHandler).add(any(AssignmentChangeEvent.class));
-        verify(applicationEventHandler).add(any(NewTopicsMetadataUpdateRequestEvent.class));
+        verify(applicationEventHandler).addAndGet(any(AssignmentChangeEvent.class));
     }
 
     @Test
@@ -1285,6 +1302,7 @@ public class AsyncKafkaConsumerTest {
     public void testNoWakeupInCloseCommit() {
         TopicPartition tp = new TopicPartition("topic1", 0);
         consumer = newConsumer();
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(Collections.singleton(tp));
         doReturn(LeaderAndEpoch.noLeaderOrEpoch()).when(metadata).currentLeader(any());
         consumer.seek(tp, 10);
@@ -1314,6 +1332,7 @@ public class AsyncKafkaConsumerTest {
         // Commit async (incomplete)
         doReturn(LeaderAndEpoch.noLeaderOrEpoch()).when(metadata).currentLeader(any());
         final TopicPartition tp = new TopicPartition("foo", 0);
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(Collections.singleton(tp));
         consumer.seek(tp, 20);
 
@@ -1331,6 +1350,7 @@ public class AsyncKafkaConsumerTest {
         // Commit async (complete)
         doReturn(LeaderAndEpoch.noLeaderOrEpoch()).when(metadata).currentLeader(any());
         final TopicPartition tp = new TopicPartition("foo", 0);
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(Collections.singleton(tp));
         consumer.seek(tp, 20);
         completeCommitAsyncApplicationEventSuccessfully();
@@ -1730,6 +1750,7 @@ public class AsyncKafkaConsumerTest {
         final KafkaException expectedException = new KafkaException("Nobody expects the Spanish Inquisition");
         final ErrorEvent errorEvent = new ErrorEvent(expectedException);
         backgroundEventQueue.add(errorEvent);
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(singletonList(new TopicPartition("topic", 0)));
         final KafkaException exception = assertThrows(KafkaException.class, () -> consumer.poll(Duration.ZERO));
 
@@ -1748,6 +1769,7 @@ public class AsyncKafkaConsumerTest {
         final KafkaException expectedException2 = new KafkaException("Spam, Spam, Spam");
         final ErrorEvent errorEvent2 = new ErrorEvent(expectedException2);
         backgroundEventQueue.add(errorEvent2);
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(singletonList(new TopicPartition("topic", 0)));
         final KafkaException exception = assertThrows(KafkaException.class, () -> consumer.poll(Duration.ZERO));
 
@@ -1877,6 +1899,7 @@ public class AsyncKafkaConsumerTest {
         completeFetchedCommittedOffsetApplicationEventExceptionally(new TimeoutException());
         doReturn(Fetch.empty()).when(fetchCollector).collectFetch(any(FetchBuffer.class));
 
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(singleton(new TopicPartition("t1", 1)));
 
         consumer.poll(Duration.ZERO);
@@ -1905,6 +1928,7 @@ public class AsyncKafkaConsumerTest {
         doReturn(Fetch.empty()).when(fetchCollector).collectFetch(any(FetchBuffer.class));
         doReturn(LeaderAndEpoch.noLeaderOrEpoch()).when(metadata).currentLeader(any());
 
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(partitions);
 
         consumer.poll(Duration.ZERO);
@@ -2038,6 +2062,7 @@ public class AsyncKafkaConsumerTest {
         Map<TopicPartition, OffsetAndMetadata> offsets = mkMap(mkEntry(tp, new OffsetAndMetadata(1)));
         completeFetchedCommittedOffsetApplicationEventSuccessfully(offsets);
         doReturn(LeaderAndEpoch.noLeaderOrEpoch()).when(metadata).currentLeader(any());
+        completeAssignmentChangeEventSuccessfully();
         consumer.assign(singleton(tp));
 
         // interrupt the thread and call poll
@@ -2182,6 +2207,15 @@ public class AsyncKafkaConsumerTest {
         }).when(applicationEventHandler).add(ArgumentMatchers.isA(UnsubscribeEvent.class));
     }
 
+    private void completeAssignmentChangeEventSuccessfully() {
+        doAnswer(invocation -> {
+            AssignmentChangeEvent event = invocation.getArgument(0);
+            consumer.subscriptions().assignFromUser(new HashSet<>(event.partitions()));
+            event.future().complete(null);
+            return null;
+        }).when(applicationEventHandler).addAndGet(ArgumentMatchers.isA(AssignmentChangeEvent.class));
+    }
+
     private void forceCommitCallbackInvocation() {
         // Invokes callback
         consumer.commitAsync();
diff --git a/clients/src/test/java/org/apache/kafka/clients/consumer/internals/events/ApplicationEventProcessorTest.java b/clients/src/test/java/org/apache/kafka/clients/consumer/internals/events/ApplicationEventProcessorTest.java
index 0612b30d99..df90c43bf4 100644
--- a/clients/src/test/java/org/apache/kafka/clients/consumer/internals/events/ApplicationEventProcessorTest.java
+++ b/clients/src/test/java/org/apache/kafka/clients/consumer/internals/events/ApplicationEventProcessorTest.java
@@ -16,7 +16,6 @@
  */
 package org.apache.kafka.clients.consumer.internals.events;
 
-import org.apache.kafka.clients.consumer.OffsetAndMetadata;
 import org.apache.kafka.clients.consumer.internals.CommitRequestManager;
 import org.apache.kafka.clients.consumer.internals.ConsumerHeartbeatRequestManager;
 import org.apache.kafka.clients.consumer.internals.ConsumerMembershipManager;
@@ -45,13 +44,19 @@ import java.util.List;
 import java.util.Map;
 import java.util.Optional;
 import java.util.concurrent.CompletableFuture;
+import java.util.concurrent.ExecutionException;
 import java.util.stream.Stream;
 
 import static org.apache.kafka.clients.consumer.internals.events.CompletableEvent.calculateDeadlineMs;
+import static org.junit.jupiter.api.Assertions.assertDoesNotThrow;
+import static org.junit.jupiter.api.Assertions.assertInstanceOf;
+import static org.junit.jupiter.api.Assertions.assertThrows;
 import static org.mockito.ArgumentMatchers.any;
 import static org.mockito.ArgumentMatchers.anyLong;
 import static org.mockito.Mockito.doReturn;
+import static org.mockito.Mockito.doThrow;
 import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.never;
 import static org.mockito.Mockito.verify;
 import static org.mockito.Mockito.when;
 
@@ -61,6 +66,7 @@ public class ApplicationEventProcessorTest {
     private final ConsumerHeartbeatRequestManager heartbeatRequestManager = mock(ConsumerHeartbeatRequestManager.class);
     private final ConsumerMembershipManager membershipManager = mock(ConsumerMembershipManager.class);
     private final SubscriptionState subscriptionState = mock(SubscriptionState.class);
+    private final ConsumerMetadata metadata = mock(ConsumerMetadata.class);
     private ApplicationEventProcessor processor;
 
     private void setupProcessor(boolean withGroupId) {
@@ -76,7 +82,7 @@ public class ApplicationEventProcessorTest {
         processor = new ApplicationEventProcessor(
                 new LogContext(),
                 requestManagers,
-                mock(ConsumerMetadata.class),
+                metadata,
                 subscriptionState
         );
     }
@@ -115,17 +121,14 @@ public class ApplicationEventProcessorTest {
     }
 
     private static Stream<Arguments> applicationEvents() {
-        Map<TopicPartition, OffsetAndMetadata> offset = new HashMap<>();
-        final long currentTimeMs = 12345;
         return Stream.of(
                 Arguments.of(new PollEvent(100)),
-                Arguments.of(new NewTopicsMetadataUpdateRequestEvent()),
                 Arguments.of(new AsyncCommitEvent(new HashMap<>())),
                 Arguments.of(new SyncCommitEvent(new HashMap<>(), 500)),
                 Arguments.of(new ResetPositionsEvent(500)),
                 Arguments.of(new ValidatePositionsEvent(500)),
                 Arguments.of(new TopicMetadataEvent("topic", Long.MAX_VALUE)),
-                Arguments.of(new AssignmentChangeEvent(offset, currentTimeMs)));
+                Arguments.of(new AssignmentChangeEvent(12345, 12345, Collections.emptyList())));
     }
 
     @ParameterizedTest
@@ -146,6 +149,40 @@ public class ApplicationEventProcessorTest {
         verify(applicationEventProcessor).process(any(ResetPositionsEvent.class));
     }
 
+    @ParameterizedTest
+    @ValueSource(booleans = {true, false})
+    public void testAssignmentChangeEvent(boolean withGroupId) {
+        final long currentTimeMs = 12345;
+        TopicPartition tp = new TopicPartition("topic", 0);
+        AssignmentChangeEvent event = new AssignmentChangeEvent(currentTimeMs, 12345, Collections.singleton(tp));
+
+        setupProcessor(withGroupId);
+        doReturn(true).when(subscriptionState).assignFromUser(Collections.singleton(tp));
+        processor.process(event);
+        if (withGroupId) {
+            verify(commitRequestManager).updateAutoCommitTimer(currentTimeMs);
+            verify(commitRequestManager).maybeAutoCommitAsync();
+        } else {
+            verify(commitRequestManager, never()).updateAutoCommitTimer(currentTimeMs);
+            verify(commitRequestManager, never()).maybeAutoCommitAsync();
+        }
+        verify(metadata).requestUpdateForNewTopics();
+        verify(subscriptionState).assignFromUser(Collections.singleton(tp));
+        assertDoesNotThrow(() -> event.future().get());
+    }
+
+    @Test
+    public void testAssignmentChangeEventWithException() {
+        AssignmentChangeEvent event = new AssignmentChangeEvent(12345, 12345, Collections.emptyList());
+
+        setupProcessor(false);
+        doThrow(new IllegalStateException()).when(subscriptionState).assignFromUser(any());
+        processor.process(event);
+
+        ExecutionException e = assertThrows(ExecutionException.class, () -> event.future().get());
+        assertInstanceOf(IllegalStateException.class, e.getCause());
+    }
+
     private List<NetworkClientDelegate.UnsentRequest> mockCommitResults() {
         return Collections.singletonList(mock(NetworkClientDelegate.UnsentRequest.class));
     }
