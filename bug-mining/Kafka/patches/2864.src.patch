diff --git a/clients/src/main/java/org/apache/kafka/common/Cluster.java b/clients/src/main/java/org/apache/kafka/common/Cluster.java
index 782fa165c7..8c9bbcb6ef 100644
--- a/clients/src/main/java/org/apache/kafka/common/Cluster.java
+++ b/clients/src/main/java/org/apache/kafka/common/Cluster.java
@@ -232,9 +232,9 @@ public final class Cluster {
     }
 
     /**
-     * Get the node by the node id (or null if no such node exists)
+     * Get the node by the node id (or null if the node is not online or does not exist)
      * @param id The id of the node
-     * @return The node, or null if no such node exists
+     * @return The node, or null if the node is not online or does not exist
      */
     public Node nodeById(int id) {
         return this.nodesById.get(id);
diff --git a/core/src/main/scala/kafka/server/MetadataCache.scala b/core/src/main/scala/kafka/server/MetadataCache.scala
index ec45a05a7d..9abef3d668 100755
--- a/core/src/main/scala/kafka/server/MetadataCache.scala
+++ b/core/src/main/scala/kafka/server/MetadataCache.scala
@@ -266,8 +266,16 @@ class MetadataCache(brokerId: Int) extends Logging {
 
   def getClusterMetadata(clusterId: String, listenerName: ListenerName): Cluster = {
     val snapshot = metadataSnapshot
-    val nodes = snapshot.aliveNodes.map { case (id, nodes) => (id, nodes.get(listenerName).orNull) }
-    def node(id: Integer): Node = nodes.get(id.toLong).orNull
+    val nodes = snapshot.aliveNodes.flatMap { case (id, nodesByListener) =>
+      nodesByListener.get(listenerName).map { node =>
+        id -> node
+      }
+    }
+
+    def node(id: Integer): Node = {
+      nodes.getOrElse(id.toLong, new Node(id, "", -1))
+    }
+
     val partitions = getAllPartitions(snapshot)
       .filter { case (_, state) => state.leader != LeaderAndIsr.LeaderDuringDelete }
       .map { case (tp, state) =>
@@ -278,7 +286,7 @@ class MetadataCache(brokerId: Int) extends Logging {
       }
     val unauthorizedTopics = Collections.emptySet[String]
     val internalTopics = getAllTopics(snapshot).filter(Topic.isInternal).asJava
-    new Cluster(clusterId, nodes.values.filter(_ != null).toBuffer.asJava,
+    new Cluster(clusterId, nodes.values.toBuffer.asJava,
       partitions.toBuffer.asJava,
       unauthorizedTopics, internalTopics,
       snapshot.controllerId.map(id => node(id)).orNull)
diff --git a/core/src/test/scala/unit/kafka/server/MetadataCacheTest.scala b/core/src/test/scala/unit/kafka/server/MetadataCacheTest.scala
index f385aef952..ba26e8ecf4 100644
--- a/core/src/test/scala/unit/kafka/server/MetadataCacheTest.scala
+++ b/core/src/test/scala/unit/kafka/server/MetadataCacheTest.scala
@@ -20,7 +20,7 @@ import java.util
 import java.util.Collections
 import util.Arrays.asList
 
-import org.apache.kafka.common.Uuid
+import org.apache.kafka.common.{Node, TopicPartition, Uuid}
 import org.apache.kafka.common.message.UpdateMetadataRequestData.{UpdateMetadataBroker, UpdateMetadataEndpoint, UpdateMetadataPartitionState}
 import org.apache.kafka.common.network.ListenerName
 import org.apache.kafka.common.protocol.{ApiKeys, Errors}
@@ -417,7 +417,7 @@ class MetadataCacheTest {
     val controllerEpoch = 1
     val leader = 0
     val leaderEpoch = 0
-    val replicas = asList[Integer](0)
+    val replicas = asList[Integer](0, 1)
     val isr = asList[Integer](0, 1)
     val partitionStates = Seq(new UpdateMetadataPartitionState()
       .setTopicName(topic)
@@ -459,7 +459,7 @@ class MetadataCacheTest {
       val controllerEpoch = 1
       val leader = 0
       val leaderEpoch = 0
-      val replicas = asList[Integer](0)
+      val replicas = asList[Integer](0, 1)
       val isr = asList[Integer](0, 1)
       val partitionStates = Seq(new UpdateMetadataPartitionState()
         .setTopicName(topic)
@@ -484,4 +484,61 @@ class MetadataCacheTest {
     assertEquals(initialBrokerIds.toSet, aliveBrokersFromCache.map(_.id).toSet)
   }
 
+  @Test
+  def testGetClusterMetadataWithOfflineReplicas(): Unit = {
+    val cache = new MetadataCache(1)
+    val topic = "topic"
+    val topicPartition = new TopicPartition(topic, 0)
+    val securityProtocol = SecurityProtocol.PLAINTEXT
+    val listenerName = ListenerName.forSecurityProtocol(securityProtocol)
+
+    val brokers = Seq(
+      new UpdateMetadataBroker()
+        .setId(0)
+        .setRack("")
+        .setEndpoints(Seq(new UpdateMetadataEndpoint()
+          .setHost("foo")
+          .setPort(9092)
+          .setSecurityProtocol(securityProtocol.id)
+          .setListener(listenerName.value)).asJava),
+      new UpdateMetadataBroker()
+        .setId(1)
+        .setEndpoints(Seq.empty.asJava)
+    )
+    val controllerEpoch = 1
+    val leader = 1
+    val leaderEpoch = 0
+    val replicas = asList[Integer](0, 1)
+    val isr = asList[Integer](0, 1)
+    val offline = asList[Integer](1)
+    val partitionStates = Seq(new UpdateMetadataPartitionState()
+      .setTopicName(topic)
+      .setPartitionIndex(topicPartition.partition)
+      .setControllerEpoch(controllerEpoch)
+      .setLeader(leader)
+      .setLeaderEpoch(leaderEpoch)
+      .setIsr(isr)
+      .setZkVersion(3)
+      .setReplicas(replicas)
+      .setOfflineReplicas(offline))
+    val version = ApiKeys.UPDATE_METADATA.latestVersion
+    val updateMetadataRequest = new UpdateMetadataRequest.Builder(version, 2, controllerEpoch, brokerEpoch, partitionStates.asJava,
+      brokers.asJava, Collections.emptyMap()).build()
+    cache.updateMetadata(15, updateMetadataRequest)
+
+    val expectedNode0 = new Node(0, "foo", 9092)
+    val expectedNode1 = new Node(1, "", -1)
+
+    val cluster = cache.getClusterMetadata("clusterId", listenerName)
+    assertEquals(expectedNode0, cluster.nodeById(0))
+    assertNull(cluster.nodeById(1))
+    assertEquals(expectedNode1, cluster.leaderFor(topicPartition))
+
+    val partitionInfo = cluster.partition(topicPartition)
+    assertEquals(expectedNode1, partitionInfo.leader)
+    assertEquals(Seq(expectedNode0, expectedNode1), partitionInfo.replicas.toSeq)
+    assertEquals(Seq(expectedNode0, expectedNode1), partitionInfo.inSyncReplicas.toSeq)
+    assertEquals(Seq(expectedNode1), partitionInfo.offlineReplicas.toSeq)
+  }
+
 }
