diff --git a/core/src/main/scala/kafka/consumer/BaseConsumer.scala b/core/src/main/scala/kafka/consumer/BaseConsumer.scala
index fd5aa416f2..cec74d0529 100644
--- a/core/src/main/scala/kafka/consumer/BaseConsumer.scala
+++ b/core/src/main/scala/kafka/consumer/BaseConsumer.scala
@@ -17,22 +17,18 @@
 
 package kafka.consumer
 
-import java.util
 import java.util.{Collections, Properties}
 import java.util.regex.Pattern
 
 import kafka.api.OffsetRequest
 import kafka.common.StreamEndException
 import kafka.message.Message
-import org.apache.kafka.clients.consumer.{ConsumerRecord, OffsetAndMetadata}
 import org.apache.kafka.clients.consumer.internals.NoOpConsumerRebalanceListener
 import org.apache.kafka.common.record.TimestampType
 import org.apache.kafka.common.TopicPartition
 import org.apache.kafka.common.header.Headers
 import org.apache.kafka.common.header.internals.RecordHeaders
 
-import scala.collection.mutable.HashMap
-
 /**
  * A base consumer used to abstract both old and new consumer
  * this class should be removed (along with BaseProducer)
@@ -64,13 +60,8 @@ class NewShinyConsumer(topic: Option[String], partitionId: Option[Int], offset:
   import org.apache.kafka.clients.consumer.KafkaConsumer
 
   val consumer = new KafkaConsumer[Array[Byte], Array[Byte]](consumerProps)
-  val offsets = new HashMap[TopicPartition, Long]()
-
   consumerInit()
-  private var currentPartition: TopicPartition = null
-  private var polledRecords = consumer.poll(0)
-  private var partitionIter = polledRecords.partitions.iterator
-  private var recordIter: util.Iterator[ConsumerRecord[Array[Byte], Array[Byte]]] = null
+  var recordIter = consumer.poll(0).iterator
 
   def consumerInit() {
     (topic, partitionId, offset, whitelist) match {
@@ -102,30 +93,21 @@ class NewShinyConsumer(topic: Option[String], partitionId: Option[Int], offset:
   }
 
   override def receive(): BaseConsumerRecord = {
-    if (recordIter == null || !recordIter.hasNext) {
-      if (!partitionIter.hasNext) {
-        polledRecords = consumer.poll(timeoutMs)
-        partitionIter = polledRecords.partitions.iterator
-
-        if (!partitionIter.hasNext)
-          throw new ConsumerTimeoutException
-      }
-
-      currentPartition = partitionIter.next
-      recordIter = polledRecords.records(currentPartition).iterator
+    if (!recordIter.hasNext) {
+      recordIter = consumer.poll(timeoutMs).iterator
+      if (!recordIter.hasNext)
+        throw new ConsumerTimeoutException
     }
 
     val record = recordIter.next
-    offsets.put(currentPartition, record.offset + 1)
-
     BaseConsumerRecord(record.topic,
-      record.partition,
-      record.offset,
-      record.timestamp,
-      record.timestampType,
-      record.key,
-      record.value,
-      record.headers)
+                       record.partition,
+                       record.offset,
+                       record.timestamp,
+                       record.timestampType,
+                       record.key,
+                       record.value,
+                       record.headers)
   }
 
   override def stop() {
@@ -137,9 +119,7 @@ class NewShinyConsumer(topic: Option[String], partitionId: Option[Int], offset:
   }
 
   override def commit() {
-    import scala.collection.JavaConverters._
-    consumer.commitSync(offsets.map { case (tp, offset) =>  (tp, new OffsetAndMetadata(offset))}.asJava)
-    offsets.clear()
+    this.consumer.commitSync()
   }
 }
 
diff --git a/core/src/main/scala/kafka/tools/ConsoleConsumer.scala b/core/src/main/scala/kafka/tools/ConsoleConsumer.scala
index a1e2ffaa71..335c724ee5 100755
--- a/core/src/main/scala/kafka/tools/ConsoleConsumer.scala
+++ b/core/src/main/scala/kafka/tools/ConsoleConsumer.scala
@@ -77,7 +77,6 @@ object ConsoleConsumer extends Logging {
     try {
       process(conf.maxMessages, conf.formatter, consumer, System.out, conf.skipMessageOnError)
     } finally {
-      consumer.commit()
       consumer.cleanup()
       conf.formatter.close()
       reportRecordCount()
@@ -201,9 +200,7 @@ object ConsoleConsumer extends Logging {
     props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, config.bootstrapServer)
     props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.ByteArrayDeserializer")
     props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.ByteArrayDeserializer")
-    props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "false")
     props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, config.isolationLevel)
-
     props
   }
 
