diff --git a/core/src/main/scala/kafka/producer/async/DefaultEventHandler.scala b/core/src/main/scala/kafka/producer/async/DefaultEventHandler.scala
index ae167dff67..6d2198d745 100644
--- a/core/src/main/scala/kafka/producer/async/DefaultEventHandler.scala
+++ b/core/src/main/scala/kafka/producer/async/DefaultEventHandler.scala
@@ -104,7 +104,8 @@ private[kafka] class DefaultEventHandler[T](val config: ProducerConfig,
       remainingEvents = topicEvents._2
       distinctPartitions.foreach { p =>
         val topicPartitionEvents = (topicEvents._1 partition (e => (e.getPartition == p)))._1
-        collatedEvents += ( (topic, p) -> topicPartitionEvents.map(q => q.getData))
+		if(topicPartitionEvents.size > 0)
+          collatedEvents += ( (topic, p) -> topicPartitionEvents.map(q => q.getData))
       }
     }
     collatedEvents
diff --git a/core/src/main/scala/kafka/producer/async/ProducerSendThread.scala b/core/src/main/scala/kafka/producer/async/ProducerSendThread.scala
index f3ae9202b5..3657bb58ca 100644
--- a/core/src/main/scala/kafka/producer/async/ProducerSendThread.scala
+++ b/core/src/main/scala/kafka/producer/async/ProducerSendThread.scala
@@ -109,7 +109,8 @@ private[async] class ProducerSendThread[T](val threadName: String,
   def tryToHandle(events: Seq[QueueItem[T]]) {
     try {
       if(logger.isDebugEnabled) logger.debug("Handling " + events.size + " events")
-      handler.handle(events, underlyingProducer, serializer)
+      if(events.size > 0)
+        handler.handle(events, underlyingProducer, serializer)
     }catch {
       case e: Exception => logger.error("Error in handling batch of " + events.size + " events", e)
     }
