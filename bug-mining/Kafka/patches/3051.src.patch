diff --git a/jmh-benchmarks/src/main/java/org/apache/kafka/jmh/timeline/TimelineHashMapBenchmark.java b/jmh-benchmarks/src/main/java/org/apache/kafka/jmh/timeline/TimelineHashMapBenchmark.java
index 2ab5dbbacb..ae6c56ee2e 100644
--- a/jmh-benchmarks/src/main/java/org/apache/kafka/jmh/timeline/TimelineHashMapBenchmark.java
+++ b/jmh-benchmarks/src/main/java/org/apache/kafka/jmh/timeline/TimelineHashMapBenchmark.java
@@ -77,7 +77,7 @@ public class TimelineHashMapBenchmark {
             int key = (int) (0xffffffff & ((i * 2862933555777941757L) + 3037000493L));
             if (j > 10 && key % 3 == 0) {
                 snapshotRegistry.deleteSnapshotsUpTo(epoch - 1000);
-                snapshotRegistry.createSnapshot(epoch);
+                snapshotRegistry.getOrCreateSnapshot(epoch);
                 j = 0;
             } else {
                 j++;
diff --git a/metadata/src/main/java/org/apache/kafka/controller/QuorumController.java b/metadata/src/main/java/org/apache/kafka/controller/QuorumController.java
index 4c6d712572..c05df50659 100644
--- a/metadata/src/main/java/org/apache/kafka/controller/QuorumController.java
+++ b/metadata/src/main/java/org/apache/kafka/controller/QuorumController.java
@@ -383,6 +383,11 @@ public final class QuorumController implements Controller {
             log.error("Cancelling snapshot {}", generator.lastContainedLogOffset());
             generator.writer().close();
             generator = null;
+
+            // Delete every in-memory snapshot up to the committed offset. They are not needed since this
+            // snapshot generation was canceled.
+            snapshotRegistry.deleteSnapshotsUpTo(lastCommittedOffset);
+
             queue.cancelDeferred(GENERATE_SNAPSHOT);
         }
 
@@ -411,16 +416,20 @@ public final class QuorumController implements Controller {
                 log.info("Finished generating snapshot {}.", generator.lastContainedLogOffset());
                 generator.writer().close();
                 generator = null;
+
+                // Delete every in-memory snapshot up to the committed offset. They are not needed since this
+                // snapshot generation finished.
+                snapshotRegistry.deleteSnapshotsUpTo(lastCommittedOffset);
                 return;
             }
             reschedule(nextDelay.getAsLong());
         }
 
-        long snapshotLastOffsetFromLog() {
+        OptionalLong snapshotLastOffsetFromLog() {
             if (generator == null) {
-                return Long.MAX_VALUE;
+                return OptionalLong.empty();
             }
-            return generator.lastContainedLogOffset();
+            return OptionalLong.of(generator.lastContainedLogOffset());
         }
     }
 
@@ -582,7 +591,7 @@ public final class QuorumController implements Controller {
                 for (ApiMessageAndVersion message : result.records()) {
                     replay(message.message(), Optional.empty(), offset);
                 }
-                snapshotRegistry.createSnapshot(offset);
+                snapshotRegistry.getOrCreateSnapshot(offset);
                 log.debug("Read-write operation {} will be completed when the log " +
                     "reaches offset {}.", this, resultAndOffset.offset());
             }
@@ -637,12 +646,13 @@ public final class QuorumController implements Controller {
                     while (reader.hasNext()) {
                         Batch<ApiMessageAndVersion> batch = reader.next();
                         long offset = batch.lastOffset();
+                        int epoch = batch.epoch();
                         List<ApiMessageAndVersion> messages = batch.records();
 
                         if (isActiveController) {
                             // If the controller is active, the records were already replayed,
                             // so we don't need to do it here.
-                            log.debug("Completing purgatory items up to offset {}.", offset);
+                            log.debug("Completing purgatory items up to offset {} and epoch {}.", offset, epoch);
 
                             // Complete any events in the purgatory that were waiting for this offset.
                             purgatory.completeUpTo(offset);
@@ -651,7 +661,7 @@ public final class QuorumController implements Controller {
                             // If we are writing a new snapshot, then we need to keep that around;
                             // otherwise, we should delete up to the current committed offset.
                             snapshotRegistry.deleteSnapshotsUpTo(
-                                Math.min(offset, snapshotGeneratorManager.snapshotLastOffsetFromLog()));
+                                snapshotGeneratorManager.snapshotLastOffsetFromLog().orElse(offset));
 
                         } else {
                             // If the controller is a standby, replay the records that were
@@ -659,12 +669,12 @@ public final class QuorumController implements Controller {
                             if (log.isDebugEnabled()) {
                                 if (log.isTraceEnabled()) {
                                     log.trace("Replaying commits from the active node up to " +
-                                        "offset {}: {}.", offset, messages.stream()
+                                        "offset {} and epoch {}: {}.", offset, epoch, messages.stream()
                                         .map(ApiMessageAndVersion::toString)
                                         .collect(Collectors.joining(", ")));
                                 } else {
                                     log.debug("Replaying commits from the active node up to " +
-                                        "offset {}.", offset);
+                                        "offset {} and epoch {}.", offset, epoch);
                                 }
                             }
                             for (ApiMessageAndVersion messageAndVersion : messages) {
@@ -673,12 +683,12 @@ public final class QuorumController implements Controller {
                         }
 
                         lastCommittedOffset = offset;
-                        lastCommittedEpoch = batch.epoch();
+                        lastCommittedEpoch = epoch;
                         lastCommittedTimestamp = batch.appendTimestamp();
                         processedRecordsSize += batch.sizeInBytes();
                     }
 
-                    checkSnapshotGeneration(processedRecordsSize);
+                    maybeGenerateSnapshot(processedRecordsSize);
                 } finally {
                     reader.close();
                 }
@@ -737,7 +747,7 @@ public final class QuorumController implements Controller {
                     lastCommittedOffset = reader.lastContainedLogOffset();
                     lastCommittedEpoch = reader.lastContainedLogEpoch();
                     lastCommittedTimestamp = reader.lastContainedLogTimestamp();
-                    snapshotRegistry.createSnapshot(lastCommittedOffset);
+                    snapshotRegistry.getOrCreateSnapshot(lastCommittedOffset);
                 } finally {
                     reader.close();
                 }
@@ -755,11 +765,20 @@ public final class QuorumController implements Controller {
                             newEpoch + ", but we never renounced controller epoch " +
                             curEpoch);
                     }
-                    log.warn("Becoming active at controller epoch {}.", newEpoch);
+                    log.info(
+                        "Becoming the active controller at epoch {}, committed offset {} and committed epoch {}.",
+                        newEpoch, lastCommittedOffset, lastCommittedEpoch
+                    );
+
                     curClaimEpoch = newEpoch;
                     controllerMetrics.setActive(true);
                     writeOffset = lastCommittedOffset;
                     clusterControl.activate();
+
+                    // Before switching to active, create an in-memory snapshot at the last committed offset. This is
+                    // required because the active controller assumes that there is always an in-memory snapshot at the
+                    // last committed offset.
+                    snapshotRegistry.getOrCreateSnapshot(lastCommittedOffset);
                 });
             } else if (curClaimEpoch != -1) {
                 appendControlEvent("handleRenounce[" + curClaimEpoch + "]", () -> {
@@ -782,7 +801,6 @@ public final class QuorumController implements Controller {
         controllerMetrics.setActive(false);
         purgatory.failAll(newNotControllerException());
         snapshotRegistry.revertToSnapshot(lastCommittedOffset);
-        snapshotRegistry.deleteSnapshotsUpTo(lastCommittedOffset);
         writeOffset = -1;
         clusterControl.deactivate();
         cancelMaybeFenceReplicas();
@@ -885,7 +903,7 @@ public final class QuorumController implements Controller {
         }
     }
 
-    private void checkSnapshotGeneration(long batchSizeInBytes) {
+    private void maybeGenerateSnapshot(long batchSizeInBytes) {
         newBytesSinceLastSnapshot += batchSizeInBytes;
         if (newBytesSinceLastSnapshot >= snapshotMaxNewRecordBytes &&
             snapshotGeneratorManager.generator == null
@@ -895,7 +913,7 @@ public final class QuorumController implements Controller {
                 // The active controller creates in-memory snapshot every time an uncommitted
                 // batch gets appended. The in-active controller can be more efficient and only
                 // create an in-memory snapshot when needed.
-                snapshotRegistry.createSnapshot(lastCommittedOffset);
+                snapshotRegistry.getOrCreateSnapshot(lastCommittedOffset);
             }
 
             log.info("Generating a snapshot that includes (epoch={}, offset={}) after {} committed bytes since the last snapshot.",
@@ -913,8 +931,6 @@ public final class QuorumController implements Controller {
         newBytesSinceLastSnapshot = 0;
         lastCommittedOffset = -1;
         lastCommittedEpoch = -1;
-
-        snapshotRegistry.createSnapshot(lastCommittedOffset);
     }
 
     private final LogContext logContext;
diff --git a/metadata/src/main/java/org/apache/kafka/timeline/SnapshotRegistry.java b/metadata/src/main/java/org/apache/kafka/timeline/SnapshotRegistry.java
index b34aceeadb..997d49acb1 100644
--- a/metadata/src/main/java/org/apache/kafka/timeline/SnapshotRegistry.java
+++ b/metadata/src/main/java/org/apache/kafka/timeline/SnapshotRegistry.java
@@ -178,14 +178,18 @@ public class SnapshotRegistry {
     /**
      * Creates a new snapshot at the given epoch.
      *
+     * If {@code epoch} already exists and it is the last snapshot then just return that snapshot.
+     *
      * @param epoch             The epoch to create the snapshot at.  The current epoch
      *                          will be advanced to one past this epoch.
      */
-    public Snapshot createSnapshot(long epoch) {
+    public Snapshot getOrCreateSnapshot(long epoch) {
         Snapshot last = head.prev();
-        if (last.epoch() >= epoch) {
+        if (last.epoch() > epoch) {
             throw new RuntimeException("Can't create a new snapshot at epoch " + epoch +
                 " because there is already a snapshot with epoch " + last.epoch());
+        } else if (last.epoch() == epoch) {
+            return last;
         }
         Snapshot snapshot = new Snapshot(epoch);
         last.appendNext(snapshot);
diff --git a/metadata/src/test/java/org/apache/kafka/controller/FeatureControlManagerTest.java b/metadata/src/test/java/org/apache/kafka/controller/FeatureControlManagerTest.java
index 37e834ab72..680253c712 100644
--- a/metadata/src/test/java/org/apache/kafka/controller/FeatureControlManagerTest.java
+++ b/metadata/src/test/java/org/apache/kafka/controller/FeatureControlManagerTest.java
@@ -56,7 +56,7 @@ public class FeatureControlManagerTest {
     @Test
     public void testUpdateFeatures() {
         SnapshotRegistry snapshotRegistry = new SnapshotRegistry(new LogContext());
-        snapshotRegistry.createSnapshot(-1);
+        snapshotRegistry.getOrCreateSnapshot(-1);
         FeatureControlManager manager = new FeatureControlManager(
             rangeMap("foo", 1, 2), snapshotRegistry);
         assertEquals(new FeatureMapAndEpoch(new FeatureMap(Collections.emptyMap()), -1),
@@ -87,11 +87,11 @@ public class FeatureControlManagerTest {
         FeatureLevelRecord record = new FeatureLevelRecord().
             setName("foo").setMinFeatureLevel((short) 1).setMaxFeatureLevel((short) 2);
         SnapshotRegistry snapshotRegistry = new SnapshotRegistry(new LogContext());
-        snapshotRegistry.createSnapshot(-1);
+        snapshotRegistry.getOrCreateSnapshot(-1);
         FeatureControlManager manager = new FeatureControlManager(
             rangeMap("foo", 1, 2), snapshotRegistry);
         manager.replay(record);
-        snapshotRegistry.createSnapshot(123);
+        snapshotRegistry.getOrCreateSnapshot(123);
         assertEquals(new FeatureMapAndEpoch(new FeatureMap(rangeMap("foo", 1, 2)), 123),
             manager.finalizedFeatures(123));
     }
@@ -124,7 +124,7 @@ public class FeatureControlManagerTest {
             rangeMap("foo", 1, 3), Collections.emptySet(), Collections.emptyMap());
         assertEquals(Collections.singletonMap("foo", ApiError.NONE), result.response());
         manager.replay((FeatureLevelRecord) result.records().get(0).message());
-        snapshotRegistry.createSnapshot(3);
+        snapshotRegistry.getOrCreateSnapshot(3);
 
         assertEquals(ControllerResult.atomicOf(Collections.emptyList(), Collections.
                 singletonMap("foo", new ApiError(Errors.INVALID_UPDATE_VERSION,
diff --git a/metadata/src/test/java/org/apache/kafka/timeline/SnapshotRegistryTest.java b/metadata/src/test/java/org/apache/kafka/timeline/SnapshotRegistryTest.java
index 687976d959..8922423189 100644
--- a/metadata/src/test/java/org/apache/kafka/timeline/SnapshotRegistryTest.java
+++ b/metadata/src/test/java/org/apache/kafka/timeline/SnapshotRegistryTest.java
@@ -55,23 +55,23 @@ public class SnapshotRegistryTest {
     @Test
     public void testCreateSnapshots() {
         SnapshotRegistry registry = new SnapshotRegistry(new LogContext());
-        Snapshot snapshot123 = registry.createSnapshot(123);
+        Snapshot snapshot123 = registry.getOrCreateSnapshot(123);
         assertEquals(snapshot123, registry.getSnapshot(123));
         assertThrows(RuntimeException.class, () -> registry.getSnapshot(456));
         assertIteratorContains(registry.iterator(), snapshot123);
         assertEquals("Can't create a new snapshot at epoch 1 because there is already " +
             "a snapshot with epoch 123", assertThrows(RuntimeException.class,
-                () -> registry.createSnapshot(1)).getMessage());
-        Snapshot snapshot456 = registry.createSnapshot(456);
+                () -> registry.getOrCreateSnapshot(1)).getMessage());
+        Snapshot snapshot456 = registry.getOrCreateSnapshot(456);
         assertIteratorContains(registry.iterator(), snapshot123, snapshot456);
     }
 
     @Test
     public void testCreateAndDeleteSnapshots() {
         SnapshotRegistry registry = new SnapshotRegistry(new LogContext());
-        Snapshot snapshot123 = registry.createSnapshot(123);
-        Snapshot snapshot456 = registry.createSnapshot(456);
-        Snapshot snapshot789 = registry.createSnapshot(789);
+        Snapshot snapshot123 = registry.getOrCreateSnapshot(123);
+        Snapshot snapshot456 = registry.getOrCreateSnapshot(456);
+        Snapshot snapshot789 = registry.getOrCreateSnapshot(789);
         registry.deleteSnapshot(snapshot456.epoch());
         assertIteratorContains(registry.iterator(), snapshot123, snapshot789);
     }
@@ -79,10 +79,20 @@ public class SnapshotRegistryTest {
     @Test
     public void testDeleteSnapshotUpTo() {
         SnapshotRegistry registry = new SnapshotRegistry(new LogContext());
-        registry.createSnapshot(10);
-        registry.createSnapshot(12);
-        Snapshot snapshot14 = registry.createSnapshot(14);
+        registry.getOrCreateSnapshot(10);
+        registry.getOrCreateSnapshot(12);
+        Snapshot snapshot14 = registry.getOrCreateSnapshot(14);
         registry.deleteSnapshotsUpTo(14);
         assertIteratorContains(registry.iterator(), snapshot14);
     }
+
+    @Test
+    public void testCreateSnapshotOfLatest() {
+        SnapshotRegistry registry = new SnapshotRegistry(new LogContext());
+        registry.getOrCreateSnapshot(10);
+        Snapshot latest = registry.getOrCreateSnapshot(12);
+        Snapshot duplicate = registry.getOrCreateSnapshot(12);
+
+        assertEquals(latest, duplicate);
+    }
 }
diff --git a/metadata/src/test/java/org/apache/kafka/timeline/SnapshottableHashTableTest.java b/metadata/src/test/java/org/apache/kafka/timeline/SnapshottableHashTableTest.java
index 972ff58749..7f1ddcc3ff 100644
--- a/metadata/src/test/java/org/apache/kafka/timeline/SnapshottableHashTableTest.java
+++ b/metadata/src/test/java/org/apache/kafka/timeline/SnapshottableHashTableTest.java
@@ -105,7 +105,7 @@ public class SnapshottableHashTableTest {
             new SnapshottableHashTable<>(registry, 1);
         assertTrue(null == table.snapshottableAddOrReplace(E_1B));
         assertEquals(1, table.snapshottableSize(Long.MAX_VALUE));
-        registry.createSnapshot(0);
+        registry.getOrCreateSnapshot(0);
         assertTrue(E_1B == table.snapshottableAddOrReplace(E_1A));
         assertTrue(E_1B == table.snapshottableGet(E_1A, 0));
         assertTrue(E_1A == table.snapshottableGet(E_1A, Long.MAX_VALUE));
@@ -113,7 +113,7 @@ public class SnapshottableHashTableTest {
         assertEquals(null, table.snapshottableAddOrReplace(E_3A));
         assertEquals(3, table.snapshottableSize(Long.MAX_VALUE));
         assertEquals(1, table.snapshottableSize(0));
-        registry.createSnapshot(1);
+        registry.getOrCreateSnapshot(1);
         assertEquals(E_1A, table.snapshottableRemove(E_1B));
         assertEquals(E_2A, table.snapshottableRemove(E_2A));
         assertEquals(E_3A, table.snapshottableRemove(E_3A));
@@ -137,7 +137,7 @@ public class SnapshottableHashTableTest {
         assertFalse(table.snapshottableAddUnlessPresent(E_1A));
         assertTrue(table.snapshottableAddUnlessPresent(E_2A));
         assertTrue(table.snapshottableAddUnlessPresent(E_3A));
-        registry.createSnapshot(0);
+        registry.getOrCreateSnapshot(0);
         assertIteratorYields(table.snapshottableIterator(0), E_1B, E_2A, E_3A);
         assertEquals(E_1B, table.snapshottableRemove(E_1B));
         assertIteratorYields(table.snapshottableIterator(0), E_1B, E_2A, E_3A);
@@ -154,7 +154,7 @@ public class SnapshottableHashTableTest {
         SnapshottableHashTable<TestElement> table =
             new SnapshottableHashTable<>(registry, 1);
         assertEquals(null, table.snapshottableAddOrReplace(E_1A));
-        registry.createSnapshot(0);
+        registry.getOrCreateSnapshot(0);
         Iterator<TestElement> iter = table.snapshottableIterator(0);
         assertTrue(table.snapshottableAddUnlessPresent(E_2A));
         assertTrue(table.snapshottableAddUnlessPresent(E_3A));
@@ -171,7 +171,7 @@ public class SnapshottableHashTableTest {
         assertEquals(null, table.snapshottableAddOrReplace(E_3A));
         assertEquals(E_1A, table.snapshottableRemove(E_1A));
         assertEquals(null, table.snapshottableAddOrReplace(E_1B));
-        registry.createSnapshot(0);
+        registry.getOrCreateSnapshot(0);
         Iterator<TestElement> iter = table.snapshottableIterator(0);
         List<TestElement> iterElements = new ArrayList<>();
         iterElements.add(iter.next());
@@ -192,10 +192,10 @@ public class SnapshottableHashTableTest {
         assertEquals(null, table.snapshottableAddOrReplace(E_1A));
         assertEquals(null, table.snapshottableAddOrReplace(E_2A));
         assertEquals(null, table.snapshottableAddOrReplace(E_3A));
-        registry.createSnapshot(0);
+        registry.getOrCreateSnapshot(0);
         assertEquals(E_1A, table.snapshottableAddOrReplace(E_1B));
         assertEquals(E_3A, table.snapshottableAddOrReplace(E_3B));
-        registry.createSnapshot(1);
+        registry.getOrCreateSnapshot(1);
         assertEquals(3, table.snapshottableSize(Long.MAX_VALUE));
         assertIteratorYields(table.snapshottableIterator(Long.MAX_VALUE), E_1B, E_2A, E_3B);
         table.snapshottableRemove(E_1B);
@@ -216,10 +216,10 @@ public class SnapshottableHashTableTest {
         assertEquals(null, table.snapshottableAddOrReplace(E_1A));
         assertEquals(null, table.snapshottableAddOrReplace(E_2A));
         assertEquals(null, table.snapshottableAddOrReplace(E_3A));
-        registry.createSnapshot(0);
+        registry.getOrCreateSnapshot(0);
         assertEquals(E_1A, table.snapshottableAddOrReplace(E_1B));
         assertEquals(E_3A, table.snapshottableAddOrReplace(E_3B));
-        registry.createSnapshot(1);
+        registry.getOrCreateSnapshot(1);
 
         registry.reset();
 
diff --git a/metadata/src/test/java/org/apache/kafka/timeline/TimelineHashMapTest.java b/metadata/src/test/java/org/apache/kafka/timeline/TimelineHashMapTest.java
index 19edceb49a..afffd3dda4 100644
--- a/metadata/src/test/java/org/apache/kafka/timeline/TimelineHashMapTest.java
+++ b/metadata/src/test/java/org/apache/kafka/timeline/TimelineHashMapTest.java
@@ -67,7 +67,7 @@ public class TimelineHashMapTest {
         assertTrue(map.containsValue("abc"));
         assertTrue(map.containsKey(456));
         assertFalse(map.isEmpty());
-        registry.createSnapshot(2);
+        registry.getOrCreateSnapshot(2);
         Iterator<Map.Entry<Integer, String>> iter = map.entrySet(2).iterator();
         map.clear();
         List<String> snapshotValues = new ArrayList<>();
diff --git a/metadata/src/test/java/org/apache/kafka/timeline/TimelineHashSetTest.java b/metadata/src/test/java/org/apache/kafka/timeline/TimelineHashSetTest.java
index 4a605c1f6f..070893cdc8 100644
--- a/metadata/src/test/java/org/apache/kafka/timeline/TimelineHashSetTest.java
+++ b/metadata/src/test/java/org/apache/kafka/timeline/TimelineHashSetTest.java
@@ -62,7 +62,7 @@ public class TimelineHashSetTest {
         assertTrue(set.retainAll(Arrays.asList("a", "b", "c")));
         assertFalse(set.retainAll(Arrays.asList("a", "b", "c")));
         assertFalse(set.removeAll(Arrays.asList("d")));
-        registry.createSnapshot(2);
+        registry.getOrCreateSnapshot(2);
         assertTrue(set.removeAll(Arrays.asList("c")));
         assertThat(TimelineHashMapTest.iteratorToList(set.iterator(2)),
             containsInAnyOrder("a", "b", "c"));
@@ -99,7 +99,7 @@ public class TimelineHashSetTest {
         assertTrue(set.containsAll(Arrays.asList("def", "jkl")));
         assertFalse(set.containsAll(Arrays.asList("abc", "def", "xyz")));
         assertTrue(set.removeAll(Arrays.asList("def", "ghi", "xyz")));
-        registry.createSnapshot(5);
+        registry.getOrCreateSnapshot(5);
         assertThat(TimelineHashMapTest.iteratorToList(set.iterator(5)),
             containsInAnyOrder("abc", "jkl"));
         assertThat(TimelineHashMapTest.iteratorToList(set.iterator()),
diff --git a/metadata/src/test/java/org/apache/kafka/timeline/TimelineIntegerTest.java b/metadata/src/test/java/org/apache/kafka/timeline/TimelineIntegerTest.java
index 13a5d358c8..736c4cba13 100644
--- a/metadata/src/test/java/org/apache/kafka/timeline/TimelineIntegerTest.java
+++ b/metadata/src/test/java/org/apache/kafka/timeline/TimelineIntegerTest.java
@@ -56,14 +56,14 @@ public class TimelineIntegerTest {
     public void testSnapshot() {
         SnapshotRegistry registry = new SnapshotRegistry(new LogContext());
         TimelineInteger integer = new TimelineInteger(registry);
-        registry.createSnapshot(2);
+        registry.getOrCreateSnapshot(2);
         integer.set(1);
-        registry.createSnapshot(3);
+        registry.getOrCreateSnapshot(3);
         integer.set(2);
         integer.increment();
         integer.increment();
         integer.decrement();
-        registry.createSnapshot(4);
+        registry.getOrCreateSnapshot(4);
         assertEquals(0, integer.get(2));
         assertEquals(1, integer.get(3));
         assertEquals(3, integer.get(4));
@@ -77,9 +77,9 @@ public class TimelineIntegerTest {
     public void testReset() {
         SnapshotRegistry registry = new SnapshotRegistry(new LogContext());
         TimelineInteger value = new TimelineInteger(registry);
-        registry.createSnapshot(2);
+        registry.getOrCreateSnapshot(2);
         value.set(1);
-        registry.createSnapshot(3);
+        registry.getOrCreateSnapshot(3);
         value.set(2);
 
         registry.reset();
diff --git a/metadata/src/test/java/org/apache/kafka/timeline/TimelineLongTest.java b/metadata/src/test/java/org/apache/kafka/timeline/TimelineLongTest.java
index 10ce56671a..26412a50c1 100644
--- a/metadata/src/test/java/org/apache/kafka/timeline/TimelineLongTest.java
+++ b/metadata/src/test/java/org/apache/kafka/timeline/TimelineLongTest.java
@@ -56,14 +56,14 @@ public class TimelineLongTest {
     public void testSnapshot() {
         SnapshotRegistry registry = new SnapshotRegistry(new LogContext());
         TimelineLong value = new TimelineLong(registry);
-        registry.createSnapshot(2);
+        registry.getOrCreateSnapshot(2);
         value.set(1L);
-        registry.createSnapshot(3);
+        registry.getOrCreateSnapshot(3);
         value.set(2L);
         value.increment();
         value.increment();
         value.decrement();
-        registry.createSnapshot(4);
+        registry.getOrCreateSnapshot(4);
         assertEquals(0L, value.get(2));
         assertEquals(1L, value.get(3));
         assertEquals(3L, value.get(4));
@@ -77,9 +77,9 @@ public class TimelineLongTest {
     public void testReset() {
         SnapshotRegistry registry = new SnapshotRegistry(new LogContext());
         TimelineLong value = new TimelineLong(registry);
-        registry.createSnapshot(2);
+        registry.getOrCreateSnapshot(2);
         value.set(1L);
-        registry.createSnapshot(3);
+        registry.getOrCreateSnapshot(3);
         value.set(2L);
 
         registry.reset();
diff --git a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java
index f70651052b..800da2b929 100644
--- a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java
+++ b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java
@@ -302,17 +302,13 @@ public class KafkaRaftClient<T> implements RaftClient<T> {
     }
 
     private void updateListenersProgress(long highWatermark) {
-        updateListenersProgress(listenerContexts, highWatermark);
-    }
-
-    private void updateListenersProgress(List<ListenerContext> listenerContexts, long highWatermark) {
         for (ListenerContext listenerContext : listenerContexts) {
             listenerContext.nextExpectedOffset().ifPresent(nextExpectedOffset -> {
                 if (nextExpectedOffset < log.startOffset() && nextExpectedOffset < highWatermark) {
                     SnapshotReader<T> snapshot = latestSnapshot().orElseThrow(() -> new IllegalStateException(
                         String.format(
                             "Snapshot expected since next offset of %s is %s, log start offset is %s and high-watermark is %s",
-                            listenerContext.listener.getClass().getTypeName(),
+                            listenerContext.listenerName(),
                             nextExpectedOffset,
                             log.startOffset(),
                             highWatermark
@@ -2118,16 +2114,7 @@ public class KafkaRaftClient<T> implements RaftClient<T> {
 
         // Check listener progress to see if reads are expected
         quorum.highWatermark().ifPresent(highWatermarkMetadata -> {
-            long highWatermark = highWatermarkMetadata.offset;
-
-            List<ListenerContext> listenersToUpdate = listenerContexts.stream()
-                .filter(listenerContext -> {
-                    OptionalLong nextExpectedOffset = listenerContext.nextExpectedOffset();
-                    return nextExpectedOffset.isPresent() && nextExpectedOffset.getAsLong() < highWatermark;
-                })
-                .collect(Collectors.toList());
-
-            updateListenersProgress(listenersToUpdate, highWatermarkMetadata.offset);
+            updateListenersProgress(highWatermarkMetadata.offset);
         });
     }
 
@@ -2447,6 +2434,7 @@ public class KafkaRaftClient<T> implements RaftClient<T> {
                 lastSent = null;
             }
 
+            logger.debug("Notifying listener {} of snapshot {}", listenerName(), reader.snapshotId());
             listener.handleSnapshot(reader);
         }
 
@@ -2488,16 +2476,27 @@ public class KafkaRaftClient<T> implements RaftClient<T> {
             fireHandleCommit(reader);
         }
 
+        public String listenerName() {
+            return listener.getClass().getTypeName();
+        }
+
         private void fireHandleCommit(BatchReader<T> reader) {
             synchronized (this) {
                 this.lastSent = reader;
             }
+            logger.debug(
+                "Notifying listener {} of batch for baseOffset {} and lastOffset {}",
+                listenerName(),
+                reader.baseOffset(),
+                reader.lastOffset()
+            );
             listener.handleCommit(reader);
         }
 
         void maybeFireLeaderChange(LeaderAndEpoch leaderAndEpoch) {
             if (shouldFireLeaderChange(leaderAndEpoch)) {
                 lastFiredLeaderChange = leaderAndEpoch;
+                logger.debug("Notifying listener {} of leader change {}", listenerName(), leaderAndEpoch);
                 listener.handleLeaderChange(leaderAndEpoch);
             }
         }
diff --git a/raft/src/test/java/org/apache/kafka/raft/RaftClientTestContext.java b/raft/src/test/java/org/apache/kafka/raft/RaftClientTestContext.java
index ef5b724f16..c0edc6d4de 100644
--- a/raft/src/test/java/org/apache/kafka/raft/RaftClientTestContext.java
+++ b/raft/src/test/java/org/apache/kafka/raft/RaftClientTestContext.java
@@ -399,7 +399,7 @@ public final class RaftClientTestContext {
         return localId.orElseThrow(() -> new AssertionError("Required local id is not defined"));
     }
 
-    void expectBeginEpoch(
+    private void expectBeginEpoch(
         int epoch
     ) throws Exception {
         pollUntilRequest();
@@ -1175,11 +1175,9 @@ public final class RaftClientTestContext {
             this.currentLeaderAndEpoch = leaderAndEpoch;
 
             currentClaimedEpoch().ifPresent(claimedEpoch -> {
-                if (claimedEpoch == leaderAndEpoch.epoch()) {
-                    long claimedEpochStartOffset = lastCommitOffset().isPresent() ?
-                        lastCommitOffset().getAsLong() + 1 : 0L;
-                    this.claimedEpochStartOffsets.put(leaderAndEpoch.epoch(), claimedEpochStartOffset);
-                }
+                long claimedEpochStartOffset = lastCommitOffset().isPresent() ?
+                    lastCommitOffset().getAsLong() + 1 : 0L;
+                this.claimedEpochStartOffsets.put(leaderAndEpoch.epoch(), claimedEpochStartOffset);
             });
         }
 
