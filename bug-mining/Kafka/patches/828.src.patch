diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java
index 2e359d6920..359a79c8e1 100644
--- a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java
@@ -92,6 +92,15 @@ public class Worker {
         producerProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, Utils.join(config.getList(WorkerConfig.BOOTSTRAP_SERVERS_CONFIG), ","));
         producerProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.ByteArraySerializer");
         producerProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.ByteArraySerializer");
+
+        // These settings are designed to ensure there is no data loss. They *may* be overridden via configs passed to the
+        // worker, but this may compromise the delivery guarantees of Kafka Connect.
+        producerProps.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, ((Integer) Integer.MAX_VALUE).toString());
+        producerProps.put(ProducerConfig.RETRIES_CONFIG, ((Integer) Integer.MAX_VALUE).toString());
+        producerProps.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, ((Long) Long.MAX_VALUE).toString());
+        producerProps.put(ProducerConfig.ACKS_CONFIG, "all");
+        producerProps.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, "1");
+
         producerProps.putAll(config.unusedConfigs());
 
         producer = new KafkaProducer<>(producerProps);
diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSourceTask.java b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSourceTask.java
index 141e4307c2..6cf1dd716a 100644
--- a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSourceTask.java
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSourceTask.java
@@ -122,7 +122,7 @@ class WorkerSourceTask implements WorkerTask {
      * @param records
      */
     private synchronized void sendRecords(List<SourceRecord> records) {
-        for (SourceRecord record : records) {
+        for (final SourceRecord record : records) {
             byte[] key = keyConverter.fromConnectData(record.topic(), record.keySchema(), record.key());
             byte[] value = valueConverter.fromConnectData(record.topic(), record.valueSchema(), record.value());
             final ProducerRecord<byte[], byte[]> producerRecord = new ProducerRecord<>(record.topic(), record.kafkaPartition(), key, value);
@@ -138,7 +138,15 @@ class WorkerSourceTask implements WorkerTask {
                         @Override
                         public void onCompletion(RecordMetadata recordMetadata, Exception e) {
                             if (e != null) {
-                                log.error("Failed to send record: ", e);
+                                // Given the default settings for zero data loss, this should basically never happen --
+                                // between "infinite" retries, indefinite blocking on full buffers, and "infinite" request
+                                // timeouts, callbacks with exceptions should never be invoked in practice. If the
+                                // user overrode these settings, the best we can do is notify them of the failure via
+                                // logging.
+                                log.error("{} failed to send record to {}: {}", id, record.topic(), e);
+                                log.debug("Failed record: topic {}, Kafka partition {}, key {}, value {}, source offset {}, source partition {}",
+                                        record.topic(), record.kafkaPartition(), record.key(), record.value(),
+                                        record.sourceOffset(), record.sourcePartition());
                             } else {
                                 log.trace("Wrote record successfully: topic {} partition {} offset {}",
                                         recordMetadata.topic(), recordMetadata.partition(),
