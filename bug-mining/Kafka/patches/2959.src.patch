diff --git a/clients/src/main/resources/common/message/DescribeClientQuotasRequest.json b/clients/src/main/resources/common/message/DescribeClientQuotasRequest.json
index 5ada552e29..d14cfc9573 100644
--- a/clients/src/main/resources/common/message/DescribeClientQuotasRequest.json
+++ b/clients/src/main/resources/common/message/DescribeClientQuotasRequest.json
@@ -16,7 +16,7 @@
 {
   "apiKey": 48,
   "type": "request",
-  "listeners": ["zkBroker"],
+  "listeners": ["zkBroker", "broker"],
   "name": "DescribeClientQuotasRequest",
   // Version 1 enables flexible versions.
   "validVersions": "0-1",
diff --git a/core/src/main/scala/kafka/server/BrokerServer.scala b/core/src/main/scala/kafka/server/BrokerServer.scala
index 65620d3ae5..4790b9f8b1 100644
--- a/core/src/main/scala/kafka/server/BrokerServer.scala
+++ b/core/src/main/scala/kafka/server/BrokerServer.scala
@@ -115,6 +115,7 @@ class BrokerServer(
   var metadataCache: RaftMetadataCache = null
 
   var quotaManagers: QuotaFactory.QuotaManagers = null
+
   var quotaCache: ClientQuotaCache = null
 
   private var _brokerTopicStats: BrokerTopicStats = null
@@ -323,7 +324,7 @@ class BrokerServer(
 
       // Start processing requests once we've caught up on the metadata log, recovered logs if necessary,
       // and started all services that we previously delayed starting.
-      val raftSupport = RaftSupport(forwardingManager, metadataCache)
+      val raftSupport = RaftSupport(forwardingManager, metadataCache, quotaCache)
       dataPlaneRequestProcessor = new KafkaApis(socketServer.dataPlaneRequestChannel, raftSupport,
         replicaManager, groupCoordinator, transactionCoordinator, autoTopicCreationManager,
         config.nodeId, config, configRepository, metadataCache, metrics, authorizer, quotaManagers,
diff --git a/core/src/main/scala/kafka/server/KafkaApis.scala b/core/src/main/scala/kafka/server/KafkaApis.scala
index 42a203c4a5..ef8476381d 100644
--- a/core/src/main/scala/kafka/server/KafkaApis.scala
+++ b/core/src/main/scala/kafka/server/KafkaApis.scala
@@ -59,6 +59,7 @@ import org.apache.kafka.common.message._
 import org.apache.kafka.common.metrics.Metrics
 import org.apache.kafka.common.network.{ListenerName, Send}
 import org.apache.kafka.common.protocol.{ApiKeys, Errors}
+import org.apache.kafka.common.quota.ClientQuotaEntity
 import org.apache.kafka.common.record._
 import org.apache.kafka.common.replica.ClientMetadata
 import org.apache.kafka.common.replica.ClientMetadata.DefaultClientMetadata
@@ -3030,37 +3031,50 @@ class KafkaApis(val requestChannel: RequestChannel,
   }
 
   def handleDescribeClientQuotasRequest(request: RequestChannel.Request): Unit = {
-    val zkSupport = metadataSupport.requireZkOrThrow(KafkaApis.notYetSupported(request))
     val describeClientQuotasRequest = request.body[DescribeClientQuotasRequest]
 
-    if (authHelper.authorize(request.context, DESCRIBE_CONFIGS, CLUSTER, CLUSTER_NAME)) {
-      val result = zkSupport.adminManager.describeClientQuotas(describeClientQuotasRequest.filter)
-
-      val entriesData = result.iterator.map { case (quotaEntity, quotaValues) =>
-        val entityData = quotaEntity.entries.asScala.iterator.map { case (entityType, entityName) =>
-          new DescribeClientQuotasResponseData.EntityData()
-            .setEntityType(entityType)
-            .setEntityName(entityName)
-        }.toBuffer
-
-        val valueData = quotaValues.iterator.map { case (key, value) =>
-          new DescribeClientQuotasResponseData.ValueData()
-            .setKey(key)
-            .setValue(value)
-        }.toBuffer
-
-        new DescribeClientQuotasResponseData.EntryData()
-          .setEntity(entityData.asJava)
-          .setValues(valueData.asJava)
-      }.toBuffer
-
-      requestHelper.sendResponseMaybeThrottle(request, requestThrottleMs =>
-        new DescribeClientQuotasResponse(new DescribeClientQuotasResponseData()
-          .setThrottleTimeMs(requestThrottleMs)
-          .setEntries(entriesData.asJava)))
-    } else {
+    if (!authHelper.authorize(request.context, DESCRIBE_CONFIGS, CLUSTER, CLUSTER_NAME)) {
       requestHelper.sendResponseMaybeThrottle(request, requestThrottleMs =>
         describeClientQuotasRequest.getErrorResponse(requestThrottleMs, Errors.CLUSTER_AUTHORIZATION_FAILED.exception))
+    } else {
+      metadataSupport match {
+        case ZkSupport(adminManager, controller, zkClient, forwardingManager, metadataCache) =>
+          val result = adminManager.describeClientQuotas(describeClientQuotasRequest.filter)
+
+          val entriesData = result.iterator.map { case (quotaEntity, quotaValues) =>
+            val entityData = quotaEntity.entries.asScala.iterator.map { case (entityType, entityName) =>
+              new DescribeClientQuotasResponseData.EntityData()
+                .setEntityType(entityType)
+                .setEntityName(entityName)
+            }.toBuffer
+
+            val valueData = quotaValues.iterator.map { case (key, value) =>
+              new DescribeClientQuotasResponseData.ValueData()
+                .setKey(key)
+                .setValue(value)
+            }.toBuffer
+
+            new DescribeClientQuotasResponseData.EntryData()
+              .setEntity(entityData.asJava)
+              .setValues(valueData.asJava)
+          }.toBuffer
+
+          requestHelper.sendResponseMaybeThrottle(request, requestThrottleMs =>
+            new DescribeClientQuotasResponse(new DescribeClientQuotasResponseData()
+              .setThrottleTimeMs(requestThrottleMs)
+              .setEntries(entriesData.asJava)))
+        case RaftSupport(fwdMgr, metadataCache, quotaCache) =>
+          val result = quotaCache.describeClientQuotas(
+            describeClientQuotasRequest.filter().components().asScala.toSeq,
+            describeClientQuotasRequest.filter().strict())
+          val resultAsJava = new util.HashMap[ClientQuotaEntity, util.Map[String, java.lang.Double]](result.size)
+          result.foreach { case (entity, quotas) =>
+            resultAsJava.put(entity, quotas.map { case (key, quota) => key -> Double.box(quota)}.asJava)
+          }
+          requestHelper.sendResponseMaybeThrottle(request, requestThrottleMs =>
+            DescribeClientQuotasResponse.fromQuotaEntities(resultAsJava, requestThrottleMs)
+          )
+      }
     }
   }
 
diff --git a/core/src/main/scala/kafka/server/MetadataSupport.scala b/core/src/main/scala/kafka/server/MetadataSupport.scala
index 86390eaa09..3970f49883 100644
--- a/core/src/main/scala/kafka/server/MetadataSupport.scala
+++ b/core/src/main/scala/kafka/server/MetadataSupport.scala
@@ -19,7 +19,7 @@ package kafka.server
 
 import kafka.controller.KafkaController
 import kafka.network.RequestChannel
-import kafka.server.metadata.RaftMetadataCache
+import kafka.server.metadata.{ClientQuotaCache, RaftMetadataCache}
 import kafka.zk.{AdminZkClient, KafkaZkClient}
 import org.apache.kafka.common.requests.AbstractResponse
 
@@ -91,7 +91,8 @@ case class ZkSupport(adminManager: ZkAdminManager,
   override def controllerId: Option[Int] =  metadataCache.getControllerId
 }
 
-case class RaftSupport(fwdMgr: ForwardingManager, metadataCache: RaftMetadataCache) extends MetadataSupport {
+case class RaftSupport(fwdMgr: ForwardingManager, metadataCache: RaftMetadataCache, quotaCache: ClientQuotaCache)
+    extends MetadataSupport {
   override val forwardingManager: Option[ForwardingManager] = Some(fwdMgr)
   override def requireZkOrThrow(createException: => Exception): ZkSupport = throw createException
   override def requireRaftOrThrow(createException: => Exception): RaftSupport = this
diff --git a/core/src/main/scala/kafka/server/metadata/ClientQuotaCache.scala b/core/src/main/scala/kafka/server/metadata/ClientQuotaCache.scala
index ad2378efc3..3a148e63bd 100644
--- a/core/src/main/scala/kafka/server/metadata/ClientQuotaCache.scala
+++ b/core/src/main/scala/kafka/server/metadata/ClientQuotaCache.scala
@@ -122,6 +122,14 @@ class ClientQuotaCache {
       entityFilters.put(entityType, entityMatch)
     }
 
+    // Special case for non-strict empty filter, match everything
+    if (filters.isEmpty && !strict) {
+      val allResults: Map[QuotaEntity, Map[String, Double]] = quotaCache.map {
+        entry => entry._1 -> entry._2.toMap
+      }.toMap
+      return allResults
+    }
+
     if (entityFilters.isEmpty) {
       return Map.empty
     }
@@ -130,7 +138,7 @@ class ClientQuotaCache {
     val matchingEntities: Set[QuotaEntity] = if (entityFilters.contains(ClientQuotaEntity.IP)) {
       if (entityFilters.size > 1) {
         throw new InvalidRequestException("Invalid entity filter component combination, IP filter component should " +
-          "not be used with user or clientId filter component.")
+          "not be used with User or ClientId filter component.")
       }
       val ipMatch = entityFilters.get(ClientQuotaEntity.IP)
       ipMatch.fold(Set.empty[QuotaEntity]) {
@@ -294,4 +302,6 @@ class ClientQuotaCache {
         updateCacheIndexPartial(ipEntityIndex, DefaultIp)
     }
   }
+
+  override def toString = s"ClientQuotaCache($quotaCache)"
 }
diff --git a/core/src/main/scala/kafka/server/metadata/ClientQuotaMetadataManager.scala b/core/src/main/scala/kafka/server/metadata/ClientQuotaMetadataManager.scala
index 76e0b54d90..c7e0e92174 100644
--- a/core/src/main/scala/kafka/server/metadata/ClientQuotaMetadataManager.scala
+++ b/core/src/main/scala/kafka/server/metadata/ClientQuotaMetadataManager.scala
@@ -121,16 +121,20 @@ class ClientQuotaMetadataManager(private[metadata] val quotaManagers: QuotaManag
       return
     }
 
-    // Update the cache
-    quotaCache.updateQuotaCache(ipEntity, quotaRecord.key, quotaRecord.value, quotaRecord.remove)
-
     // Convert the value to an appropriate Option for the quota manager
     val newValue = if (quotaRecord.remove()) {
       None
     } else {
       Some(quotaRecord.value).map(_.toInt)
     }
-    connectionQuotas.updateIpConnectionRateQuota(inetAddress, newValue)
+    try {
+      connectionQuotas.updateIpConnectionRateQuota(inetAddress, newValue)
+    } catch {
+      case t: Throwable => error(s"Failed to update IP quota $ipEntity", t)
+    }
+
+    // Update the cache
+    quotaCache.updateQuotaCache(ipEntity, quotaRecord.key, quotaRecord.value, quotaRecord.remove)
   }
 
   def handleUserClientQuota(quotaEntity: QuotaEntity, quotaRecord: QuotaRecord): Unit = {
@@ -163,11 +167,15 @@ class ClientQuotaMetadataManager(private[metadata] val quotaManagers: QuotaManag
       Some(new Quota(quotaRecord.value(), true))
     }
 
-    manager.updateQuota(
-      sanitizedUser = sanitizedUser,
-      clientId = sanitizedClientId.map(Sanitizer.desanitize),
-      sanitizedClientId = sanitizedClientId,
-      quota = quotaValue)
+    try {
+      manager.updateQuota(
+        sanitizedUser = sanitizedUser,
+        clientId = sanitizedClientId.map(Sanitizer.desanitize),
+        sanitizedClientId = sanitizedClientId,
+        quota = quotaValue)
+    } catch {
+      case t: Throwable => error(s"Failed to update user-client quota $quotaEntity", t)
+    }
 
     quotaCache.updateQuotaCache(quotaEntity, quotaRecord.key, quotaRecord.value, quotaRecord.remove)
   }
diff --git a/core/src/test/java/kafka/test/ClusterConfig.java b/core/src/test/java/kafka/test/ClusterConfig.java
index db5f14e1a4..e7e8bf5a02 100644
--- a/core/src/test/java/kafka/test/ClusterConfig.java
+++ b/core/src/test/java/kafka/test/ClusterConfig.java
@@ -119,8 +119,8 @@ public class ClusterConfig {
     public Map<String, String> nameTags() {
         Map<String, String> tags = new LinkedHashMap<>(3);
         name().ifPresent(name -> tags.put("Name", name));
-        tags.put("security", securityProtocol.name());
-        listenerName().ifPresent(listener -> tags.put("listener", listener));
+        tags.put("Security", securityProtocol.name());
+        listenerName().ifPresent(listener -> tags.put("Listener", listener));
         return tags;
     }
 
diff --git a/core/src/test/java/kafka/test/junit/ClusterTestExtensions.java b/core/src/test/java/kafka/test/junit/ClusterTestExtensions.java
index ced1e6fcbd..94eefbd91c 100644
--- a/core/src/test/java/kafka/test/junit/ClusterTestExtensions.java
+++ b/core/src/test/java/kafka/test/junit/ClusterTestExtensions.java
@@ -98,14 +98,14 @@ public class ClusterTestExtensions implements TestTemplateInvocationContextProvi
         // Process single @ClusterTest annotation
         ClusterTest clusterTestAnnot = context.getRequiredTestMethod().getDeclaredAnnotation(ClusterTest.class);
         if (clusterTestAnnot != null) {
-            processClusterTest(clusterTestAnnot, defaults, generatedContexts::add);
+            processClusterTest(context, clusterTestAnnot, defaults, generatedContexts::add);
         }
 
         // Process multiple @ClusterTest annotation within @ClusterTests
         ClusterTests clusterTestsAnnot = context.getRequiredTestMethod().getDeclaredAnnotation(ClusterTests.class);
         if (clusterTestsAnnot != null) {
             for (ClusterTest annot : clusterTestsAnnot.value()) {
-                processClusterTest(annot, defaults, generatedContexts::add);
+                processClusterTest(context, annot, defaults, generatedContexts::add);
             }
         }
 
@@ -137,7 +137,7 @@ public class ClusterTestExtensions implements TestTemplateInvocationContextProvi
         ReflectionUtils.invokeMethod(method, testInstance, generator);
     }
 
-    private void processClusterTest(ClusterTest annot, ClusterTestDefaults defaults,
+    private void processClusterTest(ExtensionContext context, ClusterTest annot, ClusterTestDefaults defaults,
                                     Consumer<TestTemplateInvocationContext> testInvocations) {
         final Type type;
         if (annot.clusterType() == Type.DEFAULT) {
@@ -182,6 +182,8 @@ public class ClusterTestExtensions implements TestTemplateInvocationContextProvi
         ClusterConfig.Builder builder = ClusterConfig.clusterBuilder(type, brokers, controllers, autoStart, annot.securityProtocol());
         if (!annot.name().isEmpty()) {
             builder.name(annot.name());
+        } else {
+            builder.name(context.getDisplayName());
         }
         if (!annot.listener().isEmpty()) {
             builder.listenerName(annot.listener());
diff --git a/core/src/test/java/kafka/test/junit/RaftClusterInvocationContext.java b/core/src/test/java/kafka/test/junit/RaftClusterInvocationContext.java
index aa3fa057b0..b4e50c59bf 100644
--- a/core/src/test/java/kafka/test/junit/RaftClusterInvocationContext.java
+++ b/core/src/test/java/kafka/test/junit/RaftClusterInvocationContext.java
@@ -68,7 +68,7 @@ public class RaftClusterInvocationContext implements TestTemplateInvocationConte
         String clusterDesc = clusterConfig.nameTags().entrySet().stream()
             .map(Object::toString)
             .collect(Collectors.joining(", "));
-        return String.format("[Quorum %d] %s", invocationIndex, clusterDesc);
+        return String.format("[%d] Type=Raft, %s", invocationIndex, clusterDesc);
     }
 
     @Override
@@ -77,7 +77,7 @@ public class RaftClusterInvocationContext implements TestTemplateInvocationConte
             (BeforeTestExecutionCallback) context -> {
                 KafkaClusterTestKit.Builder builder = new KafkaClusterTestKit.Builder(
                     new TestKitNodes.Builder().
-                        setNumKip500BrokerNodes(clusterConfig.numBrokers()).
+                        setNumBrokerNodes(clusterConfig.numBrokers()).
                         setNumControllerNodes(clusterConfig.numControllers()).build());
 
                 // Copy properties into the TestKit builder
diff --git a/core/src/test/java/kafka/test/junit/ZkClusterInvocationContext.java b/core/src/test/java/kafka/test/junit/ZkClusterInvocationContext.java
index 62cc80df27..8d4660b773 100644
--- a/core/src/test/java/kafka/test/junit/ZkClusterInvocationContext.java
+++ b/core/src/test/java/kafka/test/junit/ZkClusterInvocationContext.java
@@ -70,7 +70,7 @@ public class ZkClusterInvocationContext implements TestTemplateInvocationContext
         String clusterDesc = clusterConfig.nameTags().entrySet().stream()
             .map(Object::toString)
             .collect(Collectors.joining(", "));
-        return String.format("[Zk %d] %s", invocationIndex, clusterDesc);
+        return String.format("[%d] Type=ZK, %s", invocationIndex, clusterDesc);
     }
 
     @Override
diff --git a/core/src/test/java/kafka/testkit/TestKitNodes.java b/core/src/test/java/kafka/testkit/TestKitNodes.java
index b2d9504158..2950887c29 100644
--- a/core/src/test/java/kafka/testkit/TestKitNodes.java
+++ b/core/src/test/java/kafka/testkit/TestKitNodes.java
@@ -81,7 +81,7 @@ public class TestKitNodes {
             return this;
         }
 
-        public Builder setNumKip500BrokerNodes(int numBrokerNodes) {
+        public Builder setNumBrokerNodes(int numBrokerNodes) {
             if (numBrokerNodes < 0) {
                 throw new RuntimeException("Invalid negative value for numBrokerNodes");
             }
diff --git a/core/src/test/scala/integration/kafka/server/RaftClusterTest.scala b/core/src/test/scala/integration/kafka/server/RaftClusterTest.scala
index b19fd5a0d3..1b5c008bdd 100644
--- a/core/src/test/scala/integration/kafka/server/RaftClusterTest.scala
+++ b/core/src/test/scala/integration/kafka/server/RaftClusterTest.scala
@@ -20,12 +20,14 @@ package kafka.server
 import kafka.testkit.{KafkaClusterTestKit, TestKitNodes}
 import kafka.utils.TestUtils
 import org.apache.kafka.clients.admin.{Admin, NewTopic}
+import org.apache.kafka.common.quota.{ClientQuotaAlteration, ClientQuotaEntity, ClientQuotaFilter, ClientQuotaFilterComponent}
 import org.apache.kafka.metadata.BrokerState
 import org.junit.jupiter.api.{Test, Timeout}
 import org.junit.jupiter.api.Assertions._
 
 import java.util
 import java.util.Collections
+import scala.jdk.CollectionConverters._
 
 @Timeout(120000)
 class RaftClusterTest {
@@ -34,7 +36,7 @@ class RaftClusterTest {
   def testCreateClusterAndClose(): Unit = {
     val cluster = new KafkaClusterTestKit.Builder(
       new TestKitNodes.Builder().
-        setNumKip500BrokerNodes(1).
+        setNumBrokerNodes(1).
         setNumControllerNodes(1).build()).build()
     try {
       cluster.format()
@@ -48,7 +50,7 @@ class RaftClusterTest {
   def testCreateClusterAndWaitForBrokerInRunningState(): Unit = {
     val cluster = new KafkaClusterTestKit.Builder(
       new TestKitNodes.Builder().
-        setNumKip500BrokerNodes(3).
+        setNumBrokerNodes(3).
         setNumControllerNodes(3).build()).build()
     try {
       cluster.format()
@@ -73,7 +75,7 @@ class RaftClusterTest {
   def testCreateClusterAndCreateListDeleteTopic(): Unit = {
     val cluster = new KafkaClusterTestKit.Builder(
       new TestKitNodes.Builder().
-        setNumKip500BrokerNodes(3).
+        setNumBrokerNodes(3).
         setNumControllerNodes(3).build()).build()
     try {
       cluster.format()
@@ -131,7 +133,7 @@ class RaftClusterTest {
   def testCreateClusterAndCreateAndManyTopics(): Unit = {
     val cluster = new KafkaClusterTestKit.Builder(
       new TestKitNodes.Builder().
-        setNumKip500BrokerNodes(3).
+        setNumBrokerNodes(3).
         setNumControllerNodes(3).build()).build()
     try {
       cluster.format()
@@ -174,7 +176,7 @@ class RaftClusterTest {
   def testCreateClusterAndCreateAndManyTopicsWithManyPartitions(): Unit = {
     val cluster = new KafkaClusterTestKit.Builder(
       new TestKitNodes.Builder().
-        setNumKip500BrokerNodes(3).
+        setNumBrokerNodes(3).
         setNumControllerNodes(3).build()).build()
     try {
       cluster.format()
@@ -212,4 +214,103 @@ class RaftClusterTest {
       cluster.close()
     }
   }
+
+  @Test
+  def testClientQuotas(): Unit = {
+    val cluster = new KafkaClusterTestKit.Builder(
+      new TestKitNodes.Builder().
+        setNumBrokerNodes(1).
+        setNumControllerNodes(1).build()).build()
+    try {
+      cluster.format()
+      cluster.startup()
+      TestUtils.waitUntilTrue(() => cluster.brokers().get(0).currentState() == BrokerState.RUNNING,
+        "Broker never made it to RUNNING state.")
+      val admin = Admin.create(cluster.clientProperties())
+      try {
+        val entity = new ClientQuotaEntity(Map("user" -> "testkit").asJava)
+        var filter = ClientQuotaFilter.containsOnly(
+          List(ClientQuotaFilterComponent.ofEntity("user", "testkit")).asJava)
+
+        def alterThenDescribe(entity: ClientQuotaEntity,
+                              quotas: Seq[ClientQuotaAlteration.Op],
+                              filter: ClientQuotaFilter,
+                              expectCount: Int): java.util.Map[ClientQuotaEntity, java.util.Map[String, java.lang.Double]] = {
+          val alterResult = admin.alterClientQuotas(Seq(new ClientQuotaAlteration(entity, quotas.asJava)).asJava)
+          try {
+            alterResult.all().get()
+          } catch {
+            case t: Throwable => fail("AlterClientQuotas request failed", t)
+          }
+
+          def describeOrFail(filter: ClientQuotaFilter): java.util.Map[ClientQuotaEntity, java.util.Map[String, java.lang.Double]] = {
+            try {
+              admin.describeClientQuotas(filter).entities().get()
+            } catch {
+              case t: Throwable => fail("DescribeClientQuotas request failed", t)
+            }
+          }
+
+          val (describeResult, ok) = TestUtils.computeUntilTrue(describeOrFail(filter)) {
+            results => results.getOrDefault(entity, java.util.Collections.emptyMap[String, java.lang.Double]()).size() == expectCount
+          }
+          assertTrue(ok, "Broker never saw new client quotas")
+          describeResult
+        }
+
+        var describeResult = alterThenDescribe(entity,
+          Seq(new ClientQuotaAlteration.Op("request_percentage", 0.99)), filter, 1)
+        assertEquals(0.99, describeResult.get(entity).get("request_percentage"), 1e-6)
+
+        describeResult = alterThenDescribe(entity, Seq(
+          new ClientQuotaAlteration.Op("request_percentage", 0.97),
+          new ClientQuotaAlteration.Op("producer_byte_rate", 10000),
+          new ClientQuotaAlteration.Op("consumer_byte_rate", 10001)
+        ), filter, 3)
+        assertEquals(0.97, describeResult.get(entity).get("request_percentage"), 1e-6)
+        assertEquals(10000.0, describeResult.get(entity).get("producer_byte_rate"), 1e-6)
+        assertEquals(10001.0, describeResult.get(entity).get("consumer_byte_rate"), 1e-6)
+
+        describeResult = alterThenDescribe(entity, Seq(
+          new ClientQuotaAlteration.Op("request_percentage", 0.95),
+          new ClientQuotaAlteration.Op("producer_byte_rate", null),
+          new ClientQuotaAlteration.Op("consumer_byte_rate", null)
+        ), filter, 1)
+        assertEquals(0.95, describeResult.get(entity).get("request_percentage"), 1e-6)
+
+        describeResult = alterThenDescribe(entity, Seq(
+          new ClientQuotaAlteration.Op("request_percentage", null)), filter, 0)
+
+        describeResult = alterThenDescribe(entity,
+          Seq(new ClientQuotaAlteration.Op("producer_byte_rate", 9999)), filter, 1)
+        assertEquals(9999.0, describeResult.get(entity).get("producer_byte_rate"), 1e-6)
+
+        // Add another quota for a different entity with same user part
+        val entity2 = new ClientQuotaEntity(Map("user" -> "testkit", "client-id" -> "some-client").asJava)
+        filter = ClientQuotaFilter.containsOnly(
+          List(
+            ClientQuotaFilterComponent.ofEntity("user", "testkit"),
+            ClientQuotaFilterComponent.ofEntity("client-id", "some-client"),
+          ).asJava)
+        describeResult = alterThenDescribe(entity2,
+          Seq(new ClientQuotaAlteration.Op("producer_byte_rate", 9998)), filter, 1)
+        assertEquals(9998.0, describeResult.get(entity2).get("producer_byte_rate"), 1e-6)
+
+        // non-strict match
+        filter = ClientQuotaFilter.contains(
+          List(ClientQuotaFilterComponent.ofEntity("user", "testkit")).asJava)
+
+        TestUtils.tryUntilNoAssertionError(){
+          val results = admin.describeClientQuotas(filter).entities().get()
+          assertEquals(2, results.size(), "Broker did not see two client quotas")
+          assertEquals(9999.0, results.get(entity).get("producer_byte_rate"), 1e-6)
+          assertEquals(9998.0, results.get(entity2).get("producer_byte_rate"), 1e-6)
+        }
+      } finally {
+        admin.close()
+      }
+    } finally {
+      cluster.close()
+    }
+  }
 }
diff --git a/core/src/test/scala/unit/kafka/server/ClientQuotasRequestTest.scala b/core/src/test/scala/unit/kafka/server/ClientQuotasRequestTest.scala
index 61bd02a063..e495f3e865 100644
--- a/core/src/test/scala/unit/kafka/server/ClientQuotasRequestTest.scala
+++ b/core/src/test/scala/unit/kafka/server/ClientQuotasRequestTest.scala
@@ -38,7 +38,7 @@ import kafka.test.junit.ClusterTestExtensions
 
 import scala.jdk.CollectionConverters._
 
-@ClusterTestDefaults(clusterType = Type.ZK)
+@ClusterTestDefaults(clusterType = Type.BOTH)
 @ExtendWith(value = Array(classOf[ClusterTestExtensions]))
 class ClientQuotasRequestTest(cluster: ClusterInstance) {
   private val ConsumerByteRateProp = QuotaConfigs.CONSUMER_BYTE_RATE_OVERRIDE_CONFIG
@@ -174,7 +174,7 @@ class ClientQuotasRequestTest(cluster: ClusterInstance) {
     ))
   }
 
-  @ClusterTest
+  @ClusterTest(clusterType = Type.ZK) // No SCRAM for Raft yet
   def testClientQuotasForScramUsers(): Unit = {
     val userName = "user"
 
@@ -208,23 +208,23 @@ class ClientQuotasRequestTest(cluster: ClusterInstance) {
     val allIpEntityFilter = ClientQuotaFilterComponent.ofEntityType(ClientQuotaEntity.IP)
 
     def verifyIpQuotas(entityFilter: ClientQuotaFilterComponent, expectedMatches: Map[ClientQuotaEntity, Double]): Unit = {
-      val result = describeClientQuotas(ClientQuotaFilter.containsOnly(List(entityFilter).asJava))
-      assertEquals(expectedMatches.keySet, result.asScala.keySet)
-      result.asScala.foreach { case (entity, props) =>
-        assertEquals(Set(IpConnectionRateProp), props.asScala.keySet)
-        assertEquals(expectedMatches(entity), props.get(IpConnectionRateProp))
-        val entityName = entity.entries.get(ClientQuotaEntity.IP)
-        // ClientQuotaEntity with null name maps to default entity
-        val entityIp = if (entityName == null)
-          InetAddress.getByName(unknownHost)
-        else
-          InetAddress.getByName(entityName)
-        var currentServerQuota = 0
-        TestUtils.waitUntilTrue(
-          () => {
-            currentServerQuota = cluster.brokerSocketServers().asScala.head.connectionQuotas.connectionRateForIp(entityIp)
-            Math.abs(expectedMatches(entity) - currentServerQuota) < 0.01
-          }, s"Connection quota of $entity is not ${expectedMatches(entity)} but $currentServerQuota")
+      TestUtils.tryUntilNoAssertionError() {
+        val result = describeClientQuotas(ClientQuotaFilter.containsOnly(List(entityFilter).asJava))
+        assertEquals(expectedMatches.keySet, result.asScala.keySet)
+        result.asScala.foreach { case (entity, props) =>
+          assertEquals(Set(IpConnectionRateProp), props.asScala.keySet)
+          assertEquals(expectedMatches(entity), props.get(IpConnectionRateProp))
+          val entityName = entity.entries.get(ClientQuotaEntity.IP)
+          // ClientQuotaEntity with null name maps to default entity
+          val entityIp = if (entityName == null)
+            InetAddress.getByName(unknownHost)
+          else
+            InetAddress.getByName(entityName)
+          var currentServerQuota = 0
+          currentServerQuota = cluster.brokerSocketServers().asScala.head.connectionQuotas.connectionRateForIp(entityIp)
+          assertTrue(Math.abs(expectedMatches(entity) - currentServerQuota) < 0.01,
+            s"Connection quota of $entity is not ${expectedMatches(entity)} but $currentServerQuota")
+        }
       }
     }
 
@@ -362,12 +362,14 @@ class ClientQuotasRequestTest(cluster: ClusterInstance) {
 
     // Test exact matches.
     matchUserClientEntities.foreach { case (e, v) =>
-      val result = matchEntity(e)
-      assertEquals(1, result.size)
-      assertTrue(result.get(e) != null)
-      val value = result.get(e).get(RequestPercentageProp)
-      assertNotNull(value)
-      assertEquals(value, v, 1e-6)
+      TestUtils.tryUntilNoAssertionError() {
+        val result = matchEntity(e)
+        assertEquals(1, result.size)
+        assertTrue(result.get(e) != null)
+        val value = result.get(e).get(RequestPercentageProp)
+        assertNotNull(value)
+        assertEquals(value, v, 1e-6)
+      }
     }
 
     // Entities not contained in `matchEntityList`.
@@ -396,31 +398,33 @@ class ClientQuotasRequestTest(cluster: ClusterInstance) {
     setupDescribeClientQuotasMatchTest()
 
     def testMatchEntities(filter: ClientQuotaFilter, expectedMatchSize: Int, partition: ClientQuotaEntity => Boolean): Unit = {
-      val result = describeClientQuotas(filter)
-      val (expectedMatches, _) = (matchUserClientEntities ++ matchIpEntities).partition(e => partition(e._1))
-      assertEquals(expectedMatchSize, expectedMatches.size)  // for test verification
-      assertEquals(expectedMatchSize, result.size)
-      val expectedMatchesMap = expectedMatches.toMap
-      matchUserClientEntities.foreach { case (entity, expectedValue) =>
-        if (expectedMatchesMap.contains(entity)) {
-          val config = result.get(entity)
-          assertNotNull(config)
-          val value = config.get(RequestPercentageProp)
-          assertNotNull(value)
-          assertEquals(expectedValue, value, 1e-6)
-        } else {
-          assertNull(result.get(entity))
+      TestUtils.tryUntilNoAssertionError() {
+        val result = describeClientQuotas(filter)
+        val (expectedMatches, _) = (matchUserClientEntities ++ matchIpEntities).partition(e => partition(e._1))
+        assertEquals(expectedMatchSize, expectedMatches.size)  // for test verification
+        assertEquals(expectedMatchSize, result.size, s"Failed to match $expectedMatchSize entities for $filter")
+        val expectedMatchesMap = expectedMatches.toMap
+        matchUserClientEntities.foreach { case (entity, expectedValue) =>
+          if (expectedMatchesMap.contains(entity)) {
+            val config = result.get(entity)
+            assertNotNull(config)
+            val value = config.get(RequestPercentageProp)
+            assertNotNull(value)
+            assertEquals(expectedValue, value, 1e-6)
+          } else {
+            assertNull(result.get(entity))
+          }
         }
-      }
-      matchIpEntities.foreach { case (entity, expectedValue) =>
-        if (expectedMatchesMap.contains(entity)) {
-          val config = result.get(entity)
-          assertNotNull(config)
-          val value = config.get(IpConnectionRateProp)
-          assertNotNull(value)
-          assertEquals(expectedValue, value, 1e-6)
-        } else {
-          assertNull(result.get(entity))
+        matchIpEntities.foreach { case (entity, expectedValue) =>
+          if (expectedMatchesMap.contains(entity)) {
+            val config = result.get(entity)
+            assertNotNull(config)
+            val value = config.get(IpConnectionRateProp)
+            assertNotNull(value)
+            assertEquals(expectedValue, value, 1e-6)
+          } else {
+            assertNull(result.get(entity))
+          }
         }
       }
     }
@@ -533,23 +537,25 @@ class ClientQuotasRequestTest(cluster: ClusterInstance) {
   }
 
   private def verifyDescribeEntityQuotas(entity: ClientQuotaEntity, quotas: Map[String, Double]) = {
-    val components = entity.entries.asScala.map { case (entityType, entityName) =>
-      Option(entityName).map{ name => ClientQuotaFilterComponent.ofEntity(entityType, name)}
-        .getOrElse(ClientQuotaFilterComponent.ofDefaultEntity(entityType)
-      )
-    }
-    val describe = describeClientQuotas(ClientQuotaFilter.containsOnly(components.toList.asJava))
-    if (quotas.isEmpty) {
-      assertEquals(0, describe.size)
-    } else {
-      assertEquals(1, describe.size)
-      val configs = describe.get(entity)
-      assertNotNull(configs)
-      assertEquals(quotas.size, configs.size)
-      quotas.foreach { case (k, v) =>
-        val value = configs.get(k)
-        assertNotNull(value)
-        assertEquals(v, value, 1e-6)
+    TestUtils.tryUntilNoAssertionError(waitTime = 5000L) {
+      val components = entity.entries.asScala.map { case (entityType, entityName) =>
+        Option(entityName).map{ name => ClientQuotaFilterComponent.ofEntity(entityType, name)}
+          .getOrElse(ClientQuotaFilterComponent.ofDefaultEntity(entityType)
+          )
+      }
+      val describe = describeClientQuotas(ClientQuotaFilter.containsOnly(components.toList.asJava))
+      if (quotas.isEmpty) {
+        assertEquals(0, describe.size)
+      } else {
+        assertEquals(1, describe.size)
+        val configs = describe.get(entity)
+        assertNotNull(configs)
+        assertEquals(quotas.size, configs.size)
+        quotas.foreach { case (k, v) =>
+          val value = configs.get(k)
+          assertNotNull(value)
+          assertEquals(v, value, 1e-6)
+        }
       }
     }
   }
@@ -570,7 +576,7 @@ class ClientQuotasRequestTest(cluster: ClusterInstance) {
   private def sendDescribeClientQuotasRequest(filter: ClientQuotaFilter): DescribeClientQuotasResponse = {
     val request = new DescribeClientQuotasRequest.Builder(filter).build()
     IntegrationTestUtils.connectAndReceive[DescribeClientQuotasResponse](request,
-      destination = cluster.anyControllerSocketServer(),
+      destination = cluster.anyBrokerSocketServer(),
       listenerName = cluster.clientListener())
   }
 
@@ -598,7 +604,7 @@ class ClientQuotasRequestTest(cluster: ClusterInstance) {
   private def sendAlterClientQuotasRequest(entries: Iterable[ClientQuotaAlteration], validateOnly: Boolean): AlterClientQuotasResponse = {
     val request = new AlterClientQuotasRequest.Builder(entries.asJavaCollection, validateOnly).build()
     IntegrationTestUtils.connectAndReceive[AlterClientQuotasResponse](request,
-      destination = cluster.anyControllerSocketServer(),
+      destination = cluster.anyBrokerSocketServer(),
       listenerName = cluster.clientListener())
   }
 
diff --git a/core/src/test/scala/unit/kafka/server/KafkaApisTest.scala b/core/src/test/scala/unit/kafka/server/KafkaApisTest.scala
index 8280380b71..7813c2dca1 100644
--- a/core/src/test/scala/unit/kafka/server/KafkaApisTest.scala
+++ b/core/src/test/scala/unit/kafka/server/KafkaApisTest.scala
@@ -23,7 +23,6 @@ import java.util
 import java.util.Arrays.asList
 import java.util.concurrent.TimeUnit
 import java.util.{Collections, Optional, Properties, Random}
-
 import kafka.api.{ApiVersion, KAFKA_0_10_2_IV0, KAFKA_2_2_IV1, LeaderAndIsr}
 import kafka.cluster.{Broker, Partition}
 import kafka.controller.{ControllerContext, KafkaController}
@@ -33,7 +32,7 @@ import kafka.coordinator.transaction.{InitProducerIdResult, TransactionCoordinat
 import kafka.log.AppendOrigin
 import kafka.network.RequestChannel
 import kafka.server.QuotaFactory.QuotaManagers
-import kafka.server.metadata.{CachedConfigRepository, ConfigRepository, RaftMetadataCache}
+import kafka.server.metadata.{CachedConfigRepository, ClientQuotaCache, ConfigRepository, RaftMetadataCache}
 import kafka.utils.{MockTime, TestUtils}
 import kafka.zk.KafkaZkClient
 import org.apache.kafka.clients.admin.AlterConfigOp.OpType
@@ -108,6 +107,7 @@ class KafkaApisTest {
   private val replicaQuotaManager: ReplicationQuotaManager = EasyMock.createNiceMock(classOf[ReplicationQuotaManager])
   private val quotas = QuotaManagers(clientQuotaManager, clientQuotaManager, clientRequestQuotaManager,
     clientControllerQuotaManager, replicaQuotaManager, replicaQuotaManager, replicaQuotaManager, None)
+  private val quotaCache = new ClientQuotaCache()
   private val fetchManager: FetchManager = EasyMock.createNiceMock(classOf[FetchManager])
   private val brokerTopicStats = new BrokerTopicStats
   private val clusterId = "clusterId"
@@ -150,7 +150,7 @@ class KafkaApisTest {
       // with a RaftMetadataCache instance
       metadataCache match {
         case raftMetadataCache: RaftMetadataCache =>
-          RaftSupport(forwardingManager, raftMetadataCache)
+          RaftSupport(forwardingManager, raftMetadataCache, quotaCache)
         case _ => throw new IllegalStateException("Test must set an instance of RaftMetadataCache")
       }
     } else {
diff --git a/core/src/test/scala/unit/kafka/utils/TestUtils.scala b/core/src/test/scala/unit/kafka/utils/TestUtils.scala
index b9e5667dc3..7114d5dda9 100755
--- a/core/src/test/scala/unit/kafka/utils/TestUtils.scala
+++ b/core/src/test/scala/unit/kafka/utils/TestUtils.scala
@@ -878,6 +878,28 @@ object TestUtils extends Logging {
     throw new RuntimeException("unexpected error")
   }
 
+  /**
+   * Invoke `assertions` until no AssertionErrors are thrown or `waitTime` elapses.
+   *
+   * This method is useful in cases where there may be some expected delay in a particular test condition that is
+   * otherwise difficult to poll for. `computeUntilTrue` and `waitUntilTrue` should be preferred in cases where we can
+   * easily wait on a condition before evaluating the assertions.
+   */
+  def tryUntilNoAssertionError(waitTime: Long = JTestUtils.DEFAULT_MAX_WAIT_MS, pause: Long = 100L)(assertions: => Unit) = {
+    val (error, success) = TestUtils.computeUntilTrue({
+      try {
+        assertions
+        None
+      } catch {
+        case ae: AssertionError => Some(ae)
+      }
+    }, waitTime = waitTime, pause = pause)(_.isEmpty)
+
+    if (!success) {
+      throw error.get
+    }
+  }
+
   def isLeaderLocalOnBroker(topic: String, partitionId: Int, server: KafkaServer): Boolean = {
     server.replicaManager.onlinePartition(new TopicPartition(topic, partitionId)).exists(_.leaderLogIfLocal.isDefined)
   }
diff --git a/metadata/src/main/java/org/apache/kafka/controller/ClientQuotaControlManager.java b/metadata/src/main/java/org/apache/kafka/controller/ClientQuotaControlManager.java
index f6a24973b5..c1a98016f4 100644
--- a/metadata/src/main/java/org/apache/kafka/controller/ClientQuotaControlManager.java
+++ b/metadata/src/main/java/org/apache/kafka/controller/ClientQuotaControlManager.java
@@ -147,8 +147,10 @@ public class ClientQuotaControlManager {
 
         List<ApiMessageAndVersion> newRecords = new ArrayList<>(newQuotaConfigs.size());
         Map<String, Double> currentQuotas = clientQuotaData.containsKey(entity) ?
-            clientQuotaData.get(entity) : Collections.emptyMap();
-        newQuotaConfigs.forEach((key, newValue) -> {
+                clientQuotaData.get(entity) : Collections.emptyMap();
+        for (Map.Entry<String, Double> entry : newQuotaConfigs.entrySet()) {
+            String key = entry.getKey();
+            Double newValue = entry.getValue();
             if (newValue == null) {
                 if (currentQuotas.containsKey(key)) {
                     // Null value indicates removal
@@ -161,6 +163,7 @@ public class ClientQuotaControlManager {
                 ApiError validationError = validateQuotaKeyValue(configKeys, key, newValue);
                 if (validationError.isFailure()) {
                     outputResults.put(entity, validationError);
+                    return;
                 } else {
                     final Double currentValue = currentQuotas.get(key);
                     if (!Objects.equals(currentValue, newValue)) {
@@ -172,7 +175,7 @@ public class ClientQuotaControlManager {
                     }
                 }
             }
-        });
+        }
 
         outputRecords.addAll(newRecords);
         outputResults.put(entity, ApiError.NONE);
@@ -186,18 +189,23 @@ public class ClientQuotaControlManager {
         boolean hasIp = entity.containsKey(ClientQuotaEntity.IP);
 
         final Map<String, ConfigDef.ConfigKey> configKeys;
-        if (hasUser && hasClientId && !hasIp) {
+        if (hasIp) {
+            if (hasUser || hasClientId) {
+                return new ApiError(Errors.INVALID_REQUEST, "Invalid quota entity combination, IP entity should" +
+                    "not be combined with User or ClientId");
+            } else {
+                if (isValidIpEntity(entity.get(ClientQuotaEntity.IP))) {
+                    configKeys = QuotaConfigs.ipConfigs().configKeys();
+                } else {
+                    return new ApiError(Errors.INVALID_REQUEST, entity.get(ClientQuotaEntity.IP) + " is not a valid IP or resolvable host.");
+                }
+            }
+        } else if (hasUser && hasClientId) {
             configKeys = QuotaConfigs.userConfigs().configKeys();
-        } else if (hasUser && !hasClientId && !hasIp) {
+        } else if (hasUser) {
             configKeys = QuotaConfigs.userConfigs().configKeys();
-        } else if (!hasUser && hasClientId && !hasIp) {
+        } else if (hasClientId) {
             configKeys = QuotaConfigs.clientConfigs().configKeys();
-        } else if (!hasUser && !hasClientId && hasIp) {
-            if (isValidIpEntity(entity.get(ClientQuotaEntity.IP))) {
-                configKeys = QuotaConfigs.ipConfigs().configKeys();
-            } else {
-                return new ApiError(Errors.INVALID_REQUEST, entity.get(ClientQuotaEntity.IP) + " is not a valid IP or resolvable host.");
-            }
         } else {
             return new ApiError(Errors.INVALID_REQUEST, "Invalid empty client quota entity");
         }
@@ -218,6 +226,8 @@ public class ClientQuotaControlManager {
         switch (configKey.type()) {
             case DOUBLE:
                 break;
+            case SHORT:
+            case INT:
             case LONG:
                 Double epsilon = 1e-6;
                 Long longValue = Double.valueOf(value + epsilon).longValue();
@@ -257,7 +267,7 @@ public class ClientQuotaControlManager {
             String entityType = entityEntry.getKey();
             String entityName = entityEntry.getValue();
             if (validatedEntityMap.containsKey(entityType)) {
-                return new ApiError(Errors.INVALID_REQUEST, "Invalid empty client quota entity, duplicate entity entry " + entityType);
+                return new ApiError(Errors.INVALID_REQUEST, "Invalid client quota entity, duplicate entity entry " + entityType);
             }
             if (Objects.equals(entityType, ClientQuotaEntity.USER)) {
                 validatedEntityMap.put(ClientQuotaEntity.USER, entityName);
diff --git a/metadata/src/test/java/org/apache/kafka/controller/ClientQuotaControlManagerTest.java b/metadata/src/test/java/org/apache/kafka/controller/ClientQuotaControlManagerTest.java
index f24853a16a..47726964c2 100644
--- a/metadata/src/test/java/org/apache/kafka/controller/ClientQuotaControlManagerTest.java
+++ b/metadata/src/test/java/org/apache/kafka/controller/ClientQuotaControlManagerTest.java
@@ -71,8 +71,28 @@ public class ClientQuotaControlManagerTest {
     }
 
     private void assertInvalidEntity(ClientQuotaControlManager manager, ClientQuotaEntity entity) {
+        assertInvalidQuota(manager, entity, quotas(QuotaConfigs.PRODUCER_BYTE_RATE_OVERRIDE_CONFIG, 10000.0));
+    }
+
+    @Test
+    public void testInvalidQuotaKeys() {
+        SnapshotRegistry snapshotRegistry = new SnapshotRegistry(new LogContext());
+        ClientQuotaControlManager manager = new ClientQuotaControlManager(snapshotRegistry);
+        ClientQuotaEntity entity = entity(ClientQuotaEntity.USER, "user-1");
+
+        // Invalid + valid keys
+        assertInvalidQuota(manager, entity, quotas("not.a.quota.key", 0.0, QuotaConfigs.REQUEST_PERCENTAGE_OVERRIDE_CONFIG, 99.9));
+
+        // Valid + invalid keys
+        assertInvalidQuota(manager, entity, quotas(QuotaConfigs.REQUEST_PERCENTAGE_OVERRIDE_CONFIG, 99.9, "not.a.quota.key", 0.0));
+
+        // Null key
+        assertInvalidQuota(manager, entity, quotas(null, 99.9));
+    }
+
+    private void assertInvalidQuota(ClientQuotaControlManager manager, ClientQuotaEntity entity, Map<String, Double> quota) {
         List<ClientQuotaAlteration> alters = new ArrayList<>();
-        entityQuotaToAlterations(entity, quotas(QuotaConfigs.PRODUCER_BYTE_RATE_OVERRIDE_CONFIG, 10000.0), alters::add);
+        entityQuotaToAlterations(entity, quota, alters::add);
         ControllerResult<Map<ClientQuotaEntity, ApiError>> result = manager.alterClientQuotas(alters);
         assertEquals(Errors.INVALID_REQUEST, result.response().get(entity).error());
         assertEquals(0, result.records().size());
