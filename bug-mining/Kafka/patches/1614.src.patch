diff --git a/connect/transforms/src/main/java/org/apache/kafka/connect/transforms/ExtractField.java b/connect/transforms/src/main/java/org/apache/kafka/connect/transforms/ExtractField.java
index bb4b53927d..eb8c357f3f 100644
--- a/connect/transforms/src/main/java/org/apache/kafka/connect/transforms/ExtractField.java
+++ b/connect/transforms/src/main/java/org/apache/kafka/connect/transforms/ExtractField.java
@@ -24,13 +24,14 @@ import org.apache.kafka.connect.transforms.util.SimpleConfig;
 
 import java.util.Map;
 
-import static org.apache.kafka.connect.transforms.util.Requirements.requireMap;
-import static org.apache.kafka.connect.transforms.util.Requirements.requireStruct;
+import static org.apache.kafka.connect.transforms.util.Requirements.requireMapOrNull;
+import static org.apache.kafka.connect.transforms.util.Requirements.requireStructOrNull;
 
 public abstract class ExtractField<R extends ConnectRecord<R>> implements Transformation<R> {
 
     public static final String OVERVIEW_DOC =
-            "Extract the specified field from a Struct when schema present, or a Map in the case of schemaless data."
+            "Extract the specified field from a Struct when schema present, or a Map in the case of schemaless data. "
+                    + "Any null values are passed through unmodified."
                     + "<p/>Use the concrete transformation type designed for the record key (<code>" + Key.class.getName() + "</code>) "
                     + "or value (<code>" + Value.class.getName() + "</code>).";
 
@@ -53,11 +54,11 @@ public abstract class ExtractField<R extends ConnectRecord<R>> implements Transf
     public R apply(R record) {
         final Schema schema = operatingSchema(record);
         if (schema == null) {
-            final Map<String, Object> value = requireMap(operatingValue(record), PURPOSE);
-            return newRecord(record, null, value.get(fieldName));
+            final Map<String, Object> value = requireMapOrNull(operatingValue(record), PURPOSE);
+            return newRecord(record, null, value == null ? null : value.get(fieldName));
         } else {
-            final Struct value = requireStruct(operatingValue(record), PURPOSE);
-            return newRecord(record, schema.field(fieldName).schema(), value.get(fieldName));
+            final Struct value = requireStructOrNull(operatingValue(record), PURPOSE);
+            return newRecord(record, schema.field(fieldName).schema(), value == null ? null : value.get(fieldName));
         }
     }
 
diff --git a/connect/transforms/src/main/java/org/apache/kafka/connect/transforms/util/Requirements.java b/connect/transforms/src/main/java/org/apache/kafka/connect/transforms/util/Requirements.java
index 6f1be19b5e..6d1cd78f94 100644
--- a/connect/transforms/src/main/java/org/apache/kafka/connect/transforms/util/Requirements.java
+++ b/connect/transforms/src/main/java/org/apache/kafka/connect/transforms/util/Requirements.java
@@ -40,6 +40,13 @@ public class Requirements {
         return (Map<String, Object>) value;
     }
 
+    public static Map<String, Object> requireMapOrNull(Object value, String purpose) {
+        if (value == null) {
+            return null;
+        }
+        return requireMap(value, purpose);
+    }
+
     public static Struct requireStruct(Object value, String purpose) {
         if (!(value instanceof Struct)) {
             throw new DataException("Only Struct objects supported for [" + purpose + "], found: " + nullSafeClassName(value));
@@ -47,6 +54,13 @@ public class Requirements {
         return (Struct) value;
     }
 
+    public static Struct requireStructOrNull(Object value, String purpose) {
+        if (value == null) {
+            return null;
+        }
+        return requireStruct(value, purpose);
+    }
+
     public static SinkRecord requireSinkRecord(ConnectRecord<?> record, String purpose) {
         if (!(record instanceof SinkRecord)) {
             throw new DataException("Only SinkRecord supported for [" + purpose + "], found: " + nullSafeClassName(record));
diff --git a/connect/transforms/src/test/java/org/apache/kafka/connect/transforms/ExtractFieldTest.java b/connect/transforms/src/test/java/org/apache/kafka/connect/transforms/ExtractFieldTest.java
index 0b7ce96eb2..acb0beb004 100644
--- a/connect/transforms/src/test/java/org/apache/kafka/connect/transforms/ExtractFieldTest.java
+++ b/connect/transforms/src/test/java/org/apache/kafka/connect/transforms/ExtractFieldTest.java
@@ -24,6 +24,7 @@ import org.junit.After;
 import org.junit.Test;
 
 import java.util.Collections;
+import java.util.Map;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNull;
@@ -47,6 +48,18 @@ public class ExtractFieldTest {
         assertEquals(42, transformedRecord.key());
     }
 
+    @Test
+    public void testNullSchemaless() {
+        xform.configure(Collections.singletonMap("field", "magic"));
+
+        final Map<String, Object> key = null;
+        final SinkRecord record = new SinkRecord("test", 0, null, key, null, null, 0);
+        final SinkRecord transformedRecord = xform.apply(record);
+
+        assertNull(transformedRecord.keySchema());
+        assertNull(transformedRecord.key());
+    }
+
     @Test
     public void withSchema() {
         xform.configure(Collections.singletonMap("field", "magic"));
@@ -60,4 +73,17 @@ public class ExtractFieldTest {
         assertEquals(42, transformedRecord.key());
     }
 
+    @Test
+    public void testNullWithSchema() {
+        xform.configure(Collections.singletonMap("field", "magic"));
+
+        final Schema keySchema = SchemaBuilder.struct().field("magic", Schema.INT32_SCHEMA).optional().build();
+        final Struct key = null;
+        final SinkRecord record = new SinkRecord("test", 0, keySchema, key, null, null, 0);
+        final SinkRecord transformedRecord = xform.apply(record);
+
+        assertEquals(Schema.INT32_SCHEMA, transformedRecord.keySchema());
+        assertNull(transformedRecord.key());
+    }
+
 }
