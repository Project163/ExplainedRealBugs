diff --git a/core/src/main/scala/kafka/server/KafkaRequestHandler.scala b/core/src/main/scala/kafka/server/KafkaRequestHandler.scala
index d1d63f161c..8dfbe6419e 100755
--- a/core/src/main/scala/kafka/server/KafkaRequestHandler.scala
+++ b/core/src/main/scala/kafka/server/KafkaRequestHandler.scala
@@ -131,8 +131,10 @@ class BrokerTopicMetrics(name: Option[String]) extends KafkaMetricsGroup {
     removeMetric(BrokerTopicStats.BytesInPerSec, tags)
     removeMetric(BrokerTopicStats.BytesOutPerSec, tags)
     removeMetric(BrokerTopicStats.BytesRejectedPerSec, tags)
-    removeMetric(BrokerTopicStats.ReplicationBytesInPerSec, tags)
-    removeMetric(BrokerTopicStats.ReplicationBytesOutPerSec, tags)
+    if (replicationBytesInRate.isDefined)
+      removeMetric(BrokerTopicStats.ReplicationBytesInPerSec, tags)
+    if (replicationBytesOutRate.isDefined)
+      removeMetric(BrokerTopicStats.ReplicationBytesOutPerSec, tags)
     removeMetric(BrokerTopicStats.FailedProduceRequestsPerSec, tags)
     removeMetric(BrokerTopicStats.FailedFetchRequestsPerSec, tags)
     removeMetric(BrokerTopicStats.TotalProduceRequestsPerSec, tags)
diff --git a/core/src/test/scala/unit/kafka/metrics/MetricsTest.scala b/core/src/test/scala/unit/kafka/metrics/MetricsTest.scala
index c586a54a4c..745fea6a63 100644
--- a/core/src/test/scala/unit/kafka/metrics/MetricsTest.scala
+++ b/core/src/test/scala/unit/kafka/metrics/MetricsTest.scala
@@ -35,11 +35,11 @@ import scala.collection.JavaConverters._
 import scala.util.matching.Regex
 import kafka.consumer.{ConsumerConfig, ZookeeperConsumerConnector}
 import kafka.log.LogConfig
+import org.apache.kafka.common.TopicPartition
 
 class MetricsTest extends KafkaServerTestHarness with Logging {
   val numNodes = 2
   val numParts = 2
-  val topic = "topic1"
 
   val overridingProps = new Properties
   overridingProps.put(KafkaConfig.NumPartitionsProp, numParts.toString)
@@ -52,6 +52,7 @@ class MetricsTest extends KafkaServerTestHarness with Logging {
   @Test
   @deprecated("This test has been deprecated and it will be removed in a future release", "0.10.0.0")
   def testMetricsLeak() {
+    val topic = "test-metrics-leak"
     // create topic topic1 with 1 partition on broker 0
     createTopic(zkUtils, topic, numPartitions = 1, replicationFactor = 1, servers = servers)
     // force creation not client's specific metrics.
@@ -74,19 +75,21 @@ class MetricsTest extends KafkaServerTestHarness with Logging {
     AdminUtils.createTopic(zkUtils, topic, 1, 1)
     AdminUtils.deleteTopic(zkUtils, topic)
     TestUtils.verifyTopicDeletion(zkUtils, topic, 1, servers)
-    assertFalse("Topic metrics exists after deleteTopic", checkTopicMetricsExists(topic))
+    assertEquals("Topic metrics exists after deleteTopic", Set.empty, topicMetricGroups(topic))
   }
 
   @Test
   def testBrokerTopicMetricsUnregisteredAfterDeletingTopic() {
     val topic = "test-broker-topic-metric"
     AdminUtils.createTopic(zkUtils, topic, 2, 1)
-    createAndShutdownStep(topic, "group0", "consumer0", "producer0")
-    assertTrue("Topic metrics don't exist", checkTopicMetricsExists(topic))
+    // Produce a few messages to create the metrics
+    // Don't consume messages as it may cause metrics to be re-created causing the test to fail, see KAFKA-5238
+    TestUtils.produceMessages(servers, topic, nMessages)
+    assertTrue("Topic metrics don't exist", topicMetricGroups(topic).nonEmpty)
     assertNotNull(BrokerTopicStats.getBrokerTopicStats(topic))
     AdminUtils.deleteTopic(zkUtils, topic)
     TestUtils.verifyTopicDeletion(zkUtils, topic, 1, servers)
-    assertFalse("Topic metrics exists after deleteTopic", checkTopicMetricsExists(topic))
+    assertEquals("Topic metrics exists after deleteTopic", Set.empty, topicMetricGroups(topic))
   }
 
   @Test
@@ -110,6 +113,7 @@ class MetricsTest extends KafkaServerTestHarness with Logging {
 
   @Test
   def testBrokerTopicMetricsBytesInOut(): Unit = {
+    val topic = "test-bytes-in-out"
     val replicationBytesIn = BrokerTopicStats.ReplicationBytesInPerSec
     val replicationBytesOut = BrokerTopicStats.ReplicationBytesOutPerSec
     val bytesIn = s"${BrokerTopicStats.BytesInPerSec},topic=$topic"
@@ -121,6 +125,17 @@ class MetricsTest extends KafkaServerTestHarness with Logging {
     // Produce a few messages to create the metrics
     TestUtils.produceMessages(servers, topic, nMessages)
 
+    // Check the log size for each broker so that we can distinguish between failures caused by replication issues
+    // versus failures caused by the metrics
+    val topicPartition = new TopicPartition(topic, 0)
+    servers.foreach { server =>
+      val log = server.logManager.logsByTopicPartition.get(new TopicPartition(topic, 0))
+      val brokerId = server.config.brokerId
+      val logSize = log.map(_.size)
+      assertTrue(s"Expected broker $brokerId to have a Log for $topicPartition with positive size, actual: $logSize",
+        logSize.map(_ > 0).getOrElse(false))
+    }
+
     val initialReplicationBytesIn = meterCount(replicationBytesIn)
     val initialReplicationBytesOut = meterCount(replicationBytesOut)
     val initialBytesIn = meterCount(bytesIn)
@@ -151,13 +166,9 @@ class MetricsTest extends KafkaServerTestHarness with Logging {
       .count
   }
 
-  private def checkTopicMetricsExists(topic: String): Boolean = {
+  private def topicMetricGroups(topic: String): Set[String] = {
     val topicMetricRegex = new Regex(".*BrokerTopicMetrics.*("+topic+")$")
-    val metricGroups = Metrics.defaultRegistry.groupedMetrics(MetricPredicate.ALL).entrySet
-    for (metricGroup <- metricGroups.asScala) {
-      if (topicMetricRegex.pattern.matcher(metricGroup.getKey).matches)
-        return true
-    }
-    false
+    val metricGroups = Metrics.defaultRegistry.groupedMetrics(MetricPredicate.ALL).keySet.asScala
+    metricGroups.filter(topicMetricRegex.pattern.matcher(_).matches)
   }
 }
