diff --git a/docs/streams/core-concepts.html b/docs/streams/core-concepts.html
index 79f5b82bef..1e1aeb7b1a 100644
--- a/docs/streams/core-concepts.html
+++ b/docs/streams/core-concepts.html
@@ -224,7 +224,7 @@
 
     <p>
         Besides the guarantee that each record will be processed exactly-once, another issue that many stream processing application will face is how to
-        handle <a href="https://www.confluent.io/wp-content/uploads/streams-tables-two-sides-same-coin.pdf">out-of-order data</a> that may impact their business logic. In Kafka Streams, there are two causes that could potentially
+        handle <a href="https://dl.acm.org/citation.cfm?id=3242155">out-of-order data</a> that may impact their business logic. In Kafka Streams, there are two causes that could potentially
         result in out-of-order data arrivals with respect to their timestamps:
     </p>
 
