diff --git a/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KGroupedTableImpl.java b/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KGroupedTableImpl.java
index 7e627277c9..4455848238 100644
--- a/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KGroupedTableImpl.java
+++ b/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KGroupedTableImpl.java
@@ -26,6 +26,7 @@ import org.apache.kafka.streams.kstream.KTable;
 import org.apache.kafka.streams.kstream.Initializer;
 import org.apache.kafka.streams.kstream.Aggregator;
 import org.apache.kafka.streams.kstream.KGroupedTable;
+import org.apache.kafka.streams.processor.FailOnInvalidTimestamp;
 import org.apache.kafka.streams.processor.ProcessorSupplier;
 import org.apache.kafka.streams.processor.StateStoreSupplier;
 import org.apache.kafka.streams.state.KeyValueStore;
@@ -134,8 +135,8 @@ public class KGroupedTableImpl<K, V> extends AbstractStream<K> implements KGroup
         topology.addInternalTopic(topic);
         topology.addSink(sinkName, topic, keySerializer, changedValueSerializer, this.name);
 
-        // read the intermediate topic
-        topology.addSource(sourceName, keyDeserializer, changedValueDeserializer, topic);
+        // read the intermediate topic with RecordMetadataTimestampExtractor
+        topology.addSource(null, sourceName, new FailOnInvalidTimestamp(), keyDeserializer, changedValueDeserializer, topic);
 
         // aggregate the values with the aggregator and local store
         topology.addProcessor(funcName, aggregateSupplier, sourceName);
diff --git a/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KStreamImpl.java b/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KStreamImpl.java
index 38b0a85fbd..9cf8b3848e 100644
--- a/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KStreamImpl.java
+++ b/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KStreamImpl.java
@@ -35,6 +35,7 @@ import org.apache.kafka.streams.kstream.TransformerSupplier;
 import org.apache.kafka.streams.kstream.ValueJoiner;
 import org.apache.kafka.streams.kstream.ValueMapper;
 import org.apache.kafka.streams.kstream.ValueTransformerSupplier;
+import org.apache.kafka.streams.processor.FailOnInvalidTimestamp;
 import org.apache.kafka.streams.processor.ProcessorSupplier;
 import org.apache.kafka.streams.processor.StateStoreSupplier;
 import org.apache.kafka.streams.processor.StreamPartitioner;
@@ -308,7 +309,7 @@ public class KStreamImpl<K, V> extends AbstractStream<K> implements KStream<K, V
     public KStream<K, V> through(Serde<K> keySerde, Serde<V> valSerde, StreamPartitioner<? super K, ? super V> partitioner, String topic) {
         to(keySerde, valSerde, partitioner, topic);
 
-        return topology.stream(keySerde, valSerde, topic);
+        return topology.stream(null, new FailOnInvalidTimestamp(), keySerde, valSerde, topic);
     }
 
     @Override
@@ -525,7 +526,7 @@ public class KStreamImpl<K, V> extends AbstractStream<K> implements KStream<K, V
 
         stream.topology.addSink(sinkName, repartitionTopic, keySerializer,
                          valSerializer, filterName);
-        stream.topology.addSource(sourceName, keyDeserializer, valDeserializer,
+        stream.topology.addSource(null, sourceName, new FailOnInvalidTimestamp(), keyDeserializer, valDeserializer,
                            repartitionTopic);
 
         return sourceName;
diff --git a/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KTableImpl.java b/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KTableImpl.java
index 2103ff2f24..912f42cd11 100644
--- a/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KTableImpl.java
+++ b/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KTableImpl.java
@@ -29,6 +29,7 @@ import org.apache.kafka.streams.kstream.KeyValueMapper;
 import org.apache.kafka.streams.kstream.Predicate;
 import org.apache.kafka.streams.kstream.ValueJoiner;
 import org.apache.kafka.streams.kstream.ValueMapper;
+import org.apache.kafka.streams.processor.FailOnInvalidTimestamp;
 import org.apache.kafka.streams.processor.ProcessorSupplier;
 import org.apache.kafka.streams.processor.StateStoreSupplier;
 import org.apache.kafka.streams.processor.StreamPartitioner;
@@ -304,7 +305,7 @@ public class KTableImpl<K, S, V> extends AbstractStream<K> implements KTable<K,
 
         to(keySerde, valSerde, partitioner, topic);
 
-        return topology.table(keySerde, valSerde, topic, internalStoreName);
+        return topology.table(null, new FailOnInvalidTimestamp(), keySerde, valSerde, topic, internalStoreName);
     }
 
     @Override
@@ -316,7 +317,7 @@ public class KTableImpl<K, S, V> extends AbstractStream<K> implements KTable<K,
         Objects.requireNonNull(storeSupplier, "storeSupplier can't be null");
         to(keySerde, valSerde, partitioner, topic);
 
-        return topology.table(keySerde, valSerde, topic, storeSupplier);
+        return topology.table(null, new FailOnInvalidTimestamp(), keySerde, valSerde, topic, storeSupplier);
     }
 
     @Override
diff --git a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamImplTest.java b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamImplTest.java
index d214fb174e..abe9924487 100644
--- a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamImplTest.java
+++ b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamImplTest.java
@@ -18,6 +18,7 @@ package org.apache.kafka.streams.kstream.internals;
 
 import org.apache.kafka.common.serialization.Serde;
 import org.apache.kafka.common.serialization.Serdes;
+import org.apache.kafka.streams.KeyValue;
 import org.apache.kafka.streams.errors.TopologyBuilderException;
 import org.apache.kafka.streams.kstream.GlobalKTable;
 import org.apache.kafka.streams.kstream.JoinWindows;
@@ -27,6 +28,10 @@ import org.apache.kafka.streams.kstream.KTable;
 import org.apache.kafka.streams.kstream.Predicate;
 import org.apache.kafka.streams.kstream.ValueJoiner;
 import org.apache.kafka.streams.kstream.ValueMapper;
+import org.apache.kafka.streams.kstream.KeyValueMapper;
+import org.apache.kafka.streams.processor.FailOnInvalidTimestamp;
+import org.apache.kafka.streams.processor.internals.SourceNode;
+import org.apache.kafka.streams.processor.internals.ProcessorTopology;
 import org.apache.kafka.test.MockKeyValueMapper;
 import org.apache.kafka.test.MockProcessorSupplier;
 import org.apache.kafka.test.MockValueJoiner;
@@ -34,8 +39,11 @@ import org.junit.Before;
 import org.junit.Test;
 
 import java.util.Collections;
+import java.util.concurrent.TimeUnit;
 
 import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertThat;
+import static org.hamcrest.core.IsInstanceOf.instanceOf;
 
 
 public class KStreamImplTest {
@@ -148,6 +156,56 @@ public class KStreamImplTest {
             builder.setApplicationId("X").build(null).processors().size());
     }
 
+    @Test
+    public void shouldUseRecordMetadataTimestampExtractorWithThrough() {
+        final KStreamBuilder builder = new KStreamBuilder();
+        KStream<String, String> stream1 = builder.stream(stringSerde, stringSerde, "topic-1", "topic-2");
+        KStream<String, String> stream2 = builder.stream(stringSerde, stringSerde, "topic-3", "topic-4");
+
+        stream1.to("topic-5");
+        stream2.through("topic-6");
+
+        ProcessorTopology processorTopology = builder.setApplicationId("X").build(null);
+        assertThat(processorTopology.source("topic-6").getTimestampExtractor(), instanceOf(FailOnInvalidTimestamp.class));
+        assertEquals(processorTopology.source("topic-4").getTimestampExtractor(), null);
+        assertEquals(processorTopology.source("topic-3").getTimestampExtractor(), null);
+        assertEquals(processorTopology.source("topic-2").getTimestampExtractor(), null);
+        assertEquals(processorTopology.source("topic-1").getTimestampExtractor(), null);
+    }
+
+    @Test
+    public void shouldUseRecordMetadataTimestampExtractorWhenInternalRepartitioningTopicCreated() {
+        final KStreamBuilder builder = new KStreamBuilder();
+        KStream<String, String> kStream = builder.stream(stringSerde, stringSerde, "topic-1");
+        ValueJoiner<String, String, String> valueJoiner = MockValueJoiner.instance(":");
+        long windowSize = TimeUnit.MILLISECONDS.convert(1, TimeUnit.DAYS);
+        final KStream<String, String> stream = kStream
+                        .map(new KeyValueMapper<String, String, KeyValue<? extends String, ? extends String>>() {
+                            @Override
+                            public KeyValue<? extends String, ? extends String> apply(String key, String value) {
+                                return KeyValue.pair(value, value);
+                            }
+                        });
+        stream.join(kStream,
+                valueJoiner,
+                JoinWindows.of(windowSize).until(3 * windowSize),
+                Serdes.String(),
+                Serdes.String(),
+                Serdes.String())
+                .to(Serdes.String(), Serdes.String(), "output-topic");
+
+        ProcessorTopology processorTopology = builder.setApplicationId("X").build(null);
+        SourceNode originalSourceNode = processorTopology.source("topic-1");
+
+        for (SourceNode sourceNode: processorTopology.sources()) {
+            if (sourceNode.name().equals(originalSourceNode.name())) {
+                assertEquals(sourceNode.getTimestampExtractor(), null);
+            } else {
+                assertThat(sourceNode.getTimestampExtractor(), instanceOf(FailOnInvalidTimestamp.class));
+            }
+        }
+    }
+    
     @Test
     public void testToWithNullValueSerdeDoesntNPE() {
         final KStreamBuilder builder = new KStreamBuilder();
