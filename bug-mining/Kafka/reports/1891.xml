<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:10:04 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6796] Surprising UNKNOWN_TOPIC error for produce/fetch requests to non-replicas</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6796</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Currently if the client sends a produce request or a fetch request to a broker which isn&apos;t a replica, we return UNKNOWN_TOPIC_OR_PARTITION. This is a bit surprising to see when the topic actually exists. It would be better to return NOT_LEADER to avoid confusion. Clients typically handle both errors by refreshing metadata and retrying, so changing this should not cause any change in behavior on the client. This case can be hit following a partition reassignment after the leader is moved and the local replica is deleted.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13152854">KAFKA-6796</key>
            <summary>Surprising UNKNOWN_TOPIC error for produce/fetch requests to non-replicas</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hachikuji">Jason Gustafson</assignee>
                                    <reporter username="hachikuji">Jason Gustafson</reporter>
                        <labels>
                    </labels>
                <created>Mon, 16 Apr 2018 22:27:27 +0000</created>
                <updated>Wed, 25 Apr 2018 09:42:37 +0000</updated>
                            <resolved>Wed, 25 Apr 2018 05:00:29 +0000</resolved>
                                    <version>1.0.1</version>
                    <version>1.1.0</version>
                                    <fixVersion>2.0.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="16440133" author="githubbot" created="Mon, 16 Apr 2018 22:49:09 +0000"  >&lt;p&gt;hachikuji opened a new pull request #4883: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6796&quot; title=&quot;Surprising UNKNOWN_TOPIC error for produce/fetch requests to non-replicas&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6796&quot;&gt;&lt;del&gt;KAFKA-6796&lt;/del&gt;&lt;/a&gt;; Fix surprising UNKNOWN_TOPIC error from requests to non-replicas&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4883&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4883&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Currently if the client sends a produce request or a fetch request to a broker which isn&apos;t a replica, we return UNKNOWN_TOPIC_OR_PARTITION. This is a bit surprising to see when the topic actually exists. It would be better to return NOT_LEADER to avoid confusion. Clients typically handle both errors by refreshing metadata and retrying, so changing this should not cause any change in behavior on the client. This case can be hit following a partition reassignment after the leader is moved and the local replica is deleted.&lt;/p&gt;

&lt;p&gt;   To validate the current behavior and the fix, I&apos;ve added  integration tests for the fetch and produce APIs.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16451660" author="githubbot" created="Wed, 25 Apr 2018 04:49:47 +0000"  >&lt;p&gt;ijuma closed pull request #4883: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6796&quot; title=&quot;Surprising UNKNOWN_TOPIC error for produce/fetch requests to non-replicas&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6796&quot;&gt;&lt;del&gt;KAFKA-6796&lt;/del&gt;&lt;/a&gt;; Fix surprising UNKNOWN_TOPIC error from requests to non-replicas&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4883&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4883&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/core/src/main/scala/kafka/server/KafkaApis.scala b/core/src/main/scala/kafka/server/KafkaApis.scala&lt;br/&gt;
index a0caa4a53c0..7bc9e3ee750 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/server/KafkaApis.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/server/KafkaApis.scala&lt;br/&gt;
@@ -287,7 +287,7 @@ class KafkaApis(val requestChannel: RequestChannel,&lt;br/&gt;
       for ((topicPartition, partitionData) &amp;lt;- offsetCommitRequest.offsetData.asScala) {&lt;br/&gt;
         if (!authorize(request.session, Read, new Resource(Topic, topicPartition.topic)))&lt;br/&gt;
           unauthorizedTopicErrors += (topicPartition -&amp;gt; Errors.TOPIC_AUTHORIZATION_FAILED)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;else if (!metadataCache.contains(topicPartition.topic))&lt;br/&gt;
+        else if (!metadataCache.contains(topicPartition))&lt;br/&gt;
           nonExistingTopicErrors += (topicPartition -&amp;gt; Errors.UNKNOWN_TOPIC_OR_PARTITION)&lt;br/&gt;
         else&lt;br/&gt;
           authorizedTopicRequestInfoBldr += (topicPartition -&amp;gt; partitionData)&lt;br/&gt;
@@ -401,7 +401,7 @@ class KafkaApis(val requestChannel: RequestChannel,&lt;br/&gt;
     for ((topicPartition, memoryRecords) &amp;lt;- produceRequest.partitionRecordsOrFail.asScala) {&lt;br/&gt;
       if (!authorize(request.session, Write, new Resource(Topic, topicPartition.topic)))&lt;br/&gt;
         unauthorizedTopicResponses += topicPartition -&amp;gt; new PartitionResponse(Errors.TOPIC_AUTHORIZATION_FAILED)&lt;/li&gt;
	&lt;li&gt;else if (!metadataCache.contains(topicPartition.topic))&lt;br/&gt;
+      else if (!metadataCache.contains(topicPartition))&lt;br/&gt;
         nonExistingTopicResponses += topicPartition -&amp;gt; new PartitionResponse(Errors.UNKNOWN_TOPIC_OR_PARTITION)&lt;br/&gt;
       else&lt;br/&gt;
         authorizedRequestInfo += (topicPartition -&amp;gt; memoryRecords)&lt;br/&gt;
@@ -502,13 +502,13 @@ class KafkaApis(val requestChannel: RequestChannel,&lt;br/&gt;
     if (fetchRequest.isFromFollower()) {&lt;br/&gt;
       // The follower must have ClusterAction on ClusterResource in order to fetch partition data.&lt;br/&gt;
       if (authorize(request.session, ClusterAction, Resource.ClusterResource)) {&lt;/li&gt;
	&lt;li&gt;fetchContext.foreachPartition((part, data) =&amp;gt; {&lt;/li&gt;
	&lt;li&gt;if (!metadataCache.contains(part.topic)) {&lt;/li&gt;
	&lt;li&gt;erroneous += part -&amp;gt; new FetchResponse.PartitionData(Errors.UNKNOWN_TOPIC_OR_PARTITION,&lt;br/&gt;
+        fetchContext.foreachPartition((topicPartition, data) =&amp;gt; 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+          if (!metadataCache.contains(topicPartition)) {
+            erroneous += topicPartition -&amp;gt; new FetchResponse.PartitionData(Errors.UNKNOWN_TOPIC_OR_PARTITION,
               FetchResponse.INVALID_HIGHWATERMARK, FetchResponse.INVALID_LAST_STABLE_OFFSET,
               FetchResponse.INVALID_LOG_START_OFFSET, null, MemoryRecords.EMPTY)
           } else {
-            interesting += (part -&amp;gt; data)
+            interesting += (topicPartition -&amp;gt; data)
           }         }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;)&lt;br/&gt;
       } else &lt;/p&gt;
{
@@ -520,17 +520,17 @@ class KafkaApis(val requestChannel: RequestChannel,
       }
&lt;p&gt;     } else {&lt;br/&gt;
       // Regular Kafka consumers need READ permission on each partition they are fetching.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;fetchContext.foreachPartition((part, data) =&amp;gt; {&lt;/li&gt;
	&lt;li&gt;if (!authorize(request.session, Read, new Resource(Topic, part.topic)))&lt;/li&gt;
	&lt;li&gt;erroneous += part -&amp;gt; new FetchResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,&lt;br/&gt;
+      fetchContext.foreachPartition((topicPartition, data) =&amp;gt; 
{
+        if (!authorize(request.session, Read, new Resource(Topic, topicPartition.topic)))
+          erroneous += topicPartition -&amp;gt; new FetchResponse.PartitionData(Errors.TOPIC_AUTHORIZATION_FAILED,
             FetchResponse.INVALID_HIGHWATERMARK, FetchResponse.INVALID_LAST_STABLE_OFFSET,
             FetchResponse.INVALID_LOG_START_OFFSET, null, MemoryRecords.EMPTY)
-        else if (!metadataCache.contains(part.topic))
-          erroneous += part -&amp;gt; new FetchResponse.PartitionData(Errors.UNKNOWN_TOPIC_OR_PARTITION,
+        else if (!metadataCache.contains(topicPartition))
+          erroneous += topicPartition -&amp;gt; new FetchResponse.PartitionData(Errors.UNKNOWN_TOPIC_OR_PARTITION,
             FetchResponse.INVALID_HIGHWATERMARK, FetchResponse.INVALID_LAST_STABLE_OFFSET,
             FetchResponse.INVALID_LOG_START_OFFSET, null, MemoryRecords.EMPTY)
         else
-          interesting += (part -&amp;gt; data)
+          interesting += (topicPartition -&amp;gt; data)
       }
&lt;p&gt;)&lt;br/&gt;
     }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -1062,7 +1062,7 @@ class KafkaApis(val requestChannel: RequestChannel,&lt;br/&gt;
             // version 0 reads offsets from ZK&lt;br/&gt;
             val authorizedPartitionData = authorizedPartitions.map { topicPartition =&amp;gt;&lt;br/&gt;
               try {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (!metadataCache.contains(topicPartition.topic))&lt;br/&gt;
+                if (!metadataCache.contains(topicPartition))&lt;br/&gt;
                   (topicPartition, OffsetFetchResponse.UNKNOWN_PARTITION)&lt;br/&gt;
                 else {&lt;br/&gt;
                   val payloadOpt = zkClient.getConsumerOffset(offsetFetchRequest.groupId, topicPartition)&lt;br/&gt;
@@ -1508,7 +1508,7 @@ class KafkaApis(val requestChannel: RequestChannel,&lt;br/&gt;
       if (!authorize(request.session, Delete, new Resource(Topic, topicPartition.topic)))&lt;br/&gt;
         unauthorizedTopicResponses += topicPartition -&amp;gt; new DeleteRecordsResponse.PartitionResponse(&lt;br/&gt;
           DeleteRecordsResponse.INVALID_LOW_WATERMARK, Errors.TOPIC_AUTHORIZATION_FAILED)&lt;/li&gt;
	&lt;li&gt;else if (!metadataCache.contains(topicPartition.topic))&lt;br/&gt;
+      else if (!metadataCache.contains(topicPartition))&lt;br/&gt;
         nonExistingTopicResponses += topicPartition -&amp;gt; new DeleteRecordsResponse.PartitionResponse(&lt;br/&gt;
           DeleteRecordsResponse.INVALID_LOW_WATERMARK, Errors.UNKNOWN_TOPIC_OR_PARTITION)&lt;br/&gt;
       else&lt;br/&gt;
@@ -1720,7 +1720,7 @@ class KafkaApis(val requestChannel: RequestChannel,&lt;br/&gt;
         if (org.apache.kafka.common.internals.Topic.isInternal(topicPartition.topic) ||&lt;br/&gt;
             !authorize(request.session, Write, new Resource(Topic, topicPartition.topic)))&lt;br/&gt;
           unauthorizedTopicErrors += topicPartition -&amp;gt; Errors.TOPIC_AUTHORIZATION_FAILED&lt;/li&gt;
	&lt;li&gt;else if (!metadataCache.contains(topicPartition.topic))&lt;br/&gt;
+        else if (!metadataCache.contains(topicPartition))&lt;br/&gt;
           nonExistingTopicErrors += topicPartition -&amp;gt; Errors.UNKNOWN_TOPIC_OR_PARTITION&lt;br/&gt;
         else&lt;br/&gt;
           authorizedPartitions.add(topicPartition)&lt;br/&gt;
@@ -1806,7 +1806,7 @@ class KafkaApis(val requestChannel: RequestChannel,&lt;br/&gt;
       for ((topicPartition, commitedOffset) &amp;lt;- txnOffsetCommitRequest.offsets.asScala) {&lt;br/&gt;
         if (!authorize(request.session, Read, new Resource(Topic, topicPartition.topic)))&lt;br/&gt;
           unauthorizedTopicErrors += topicPartition -&amp;gt; Errors.TOPIC_AUTHORIZATION_FAILED&lt;/li&gt;
	&lt;li&gt;else if (!metadataCache.contains(topicPartition.topic))&lt;br/&gt;
+        else if (!metadataCache.contains(topicPartition))&lt;br/&gt;
           nonExistingTopicErrors += topicPartition -&amp;gt; Errors.UNKNOWN_TOPIC_OR_PARTITION&lt;br/&gt;
         else&lt;br/&gt;
           authorizedTopicCommittedOffsets += (topicPartition -&amp;gt; commitedOffset)&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/server/ReplicaManager.scala b/core/src/main/scala/kafka/server/ReplicaManager.scala&lt;br/&gt;
index 0c2b0d805f8..da501174acd 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/main/scala/kafka/server/ReplicaManager.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/server/ReplicaManager.scala&lt;br/&gt;
@@ -426,8 +426,16 @@ class ReplicaManager(val config: KafkaConfig,&lt;br/&gt;
   def getPartitionAndLeaderReplicaIfLocal(topicPartition: TopicPartition): (Partition, Replica) =  {&lt;br/&gt;
     val partitionOpt = getPartition(topicPartition)&lt;br/&gt;
     partitionOpt match {&lt;br/&gt;
+      case None if metadataCache.contains(topicPartition) =&amp;gt;&lt;br/&gt;
+        // The topic exists, but this broker is no longer a replica of it, so we return NOT_LEADER which&lt;br/&gt;
+        // forces clients to refresh metadata to find the new location. This can happen, for example,&lt;br/&gt;
+        // during a partition reassignment if a produce request from the client is sent to a broker after&lt;br/&gt;
+        // the local replica has been deleted.&lt;br/&gt;
+        throw new NotLeaderForPartitionException(s&quot;Broker $localBrokerId is not a replica of $topicPartition&quot;)&lt;br/&gt;
+&lt;br/&gt;
       case None =&amp;gt;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;throw new UnknownTopicOrPartitionException(s&quot;Partition $topicPartition doesn&apos;t exist on $localBrokerId&quot;)&lt;br/&gt;
+        throw new UnknownTopicOrPartitionException(s&quot;Partition $topicPartition doesn&apos;t exist&quot;)&lt;br/&gt;
+&lt;br/&gt;
       case Some(partition) =&amp;gt;&lt;br/&gt;
         if (partition eq ReplicaManager.OfflinePartition)&lt;br/&gt;
           throw new KafkaStorageException(s&quot;Partition $topicPartition is in an offline log directory on broker $localBrokerId&quot;)&lt;br/&gt;
@@ -736,17 +744,8 @@ class ReplicaManager(val config: KafkaConfig,&lt;br/&gt;
           Some(new InvalidTopicException(s&quot;Cannot append to internal topic ${topicPartition.topic}&quot;))))&lt;br/&gt;
       } else {&lt;br/&gt;
         try {&lt;/li&gt;
	&lt;li&gt;val partitionOpt = getPartition(topicPartition)&lt;/li&gt;
	&lt;li&gt;val info = partitionOpt match 
{
-            case Some(partition) =&amp;gt;
-              if (partition eq ReplicaManager.OfflinePartition)
-                throw new KafkaStorageException(s&quot;Partition $topicPartition is in an offline log directory on broker $localBrokerId&quot;)
-              partition.appendRecordsToLeader(records, isFromClient, requiredAcks)
-
-            case None =&amp;gt; throw new UnknownTopicOrPartitionException(&quot;Partition %s doesn&apos;t exist on %d&quot;
-              .format(topicPartition, localBrokerId))
-          }
&lt;p&gt;-&lt;br/&gt;
+          val (partition, _) = getPartitionAndLeaderReplicaIfLocal(topicPartition)&lt;br/&gt;
+          val info = partition.appendRecordsToLeader(records, isFromClient, requiredAcks)&lt;br/&gt;
           val numAppendedMessages = info.numMessages&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;           // update stats for successfully appended bytes and messages as bytesInRate and messageInRate&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/server/FetchRequestTest.scala b/core/src/test/scala/unit/kafka/server/FetchRequestTest.scala&lt;br/&gt;
index f2b3552feaf..03137e10dea 100644&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/server/FetchRequestTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/server/FetchRequestTest.scala&lt;br/&gt;
@@ -170,6 +170,27 @@ class FetchRequestTest extends BaseRequestTest &lt;/p&gt;
{
     assertEquals(0, records(partitionData).map(_.sizeInBytes).sum)
   }

&lt;p&gt;+  @Test&lt;br/&gt;
+  def testFetchRequestToNonReplica(): Unit = &lt;/p&gt;
{
+    val topic = &quot;topic&quot;
+    val partition = 0
+    val topicPartition = new TopicPartition(topic, partition)
+
+    // Create a single-partition topic and find a broker which is not the leader
+    val partitionToLeader = TestUtils.createTopic(zkClient, topic, numPartitions = 1, 1, servers)
+    val leader = partitionToLeader(partition)
+    val nonReplicaOpt = servers.find(_.config.brokerId != leader)
+    assertTrue(nonReplicaOpt.isDefined)
+    val nonReplicaId =  nonReplicaOpt.get.config.brokerId
+
+    // Send the fetch request to the non-replica and verify the error code
+    val fetchRequest = FetchRequest.Builder.forConsumer(Int.MaxValue, 0, createPartitionMap(1024,
+      Seq(topicPartition))).build()
+    val fetchResponse = sendFetchRequest(nonReplicaId, fetchRequest)
+    val partitionData = fetchResponse.responseData.get(topicPartition)
+    assertEquals(Errors.NOT_LEADER_FOR_PARTITION, partitionData.error)
+  }
&lt;p&gt;+&lt;br/&gt;
   /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Tests that down-conversions dont leak memory. Large down conversions are triggered&lt;/li&gt;
	&lt;li&gt;in the server. The client closes its connection after reading partial data when the&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/server/KafkaApisTest.scala b/core/src/test/scala/unit/kafka/server/KafkaApisTest.scala&lt;br/&gt;
index 382364f7a83..96f74a0fffc 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/test/scala/unit/kafka/server/KafkaApisTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/server/KafkaApisTest.scala&lt;br/&gt;
@@ -20,6 +20,7 @@ package kafka.server&lt;br/&gt;
 import java.lang.
{Long =&amp;gt; JLong}
&lt;p&gt; import java.net.InetAddress&lt;br/&gt;
 import java.util&lt;br/&gt;
+import java.util.Collections&lt;/p&gt;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import kafka.api.&lt;/p&gt;
{ApiVersion, KAFKA_0_10_2_IV0}
&lt;p&gt; import kafka.cluster.Replica&lt;br/&gt;
@@ -40,6 +41,7 @@ import org.apache.kafka.common.network.ListenerName&lt;br/&gt;
 import org.apache.kafka.common.protocol.&lt;/p&gt;
{ApiKeys, Errors}
&lt;p&gt; import org.apache.kafka.common.record.RecordBatch&lt;br/&gt;
 import org.apache.kafka.common.requests.ProduceResponse.PartitionResponse&lt;br/&gt;
+import org.apache.kafka.common.requests.UpdateMetadataRequest.&lt;/p&gt;
{Broker, EndPoint}
&lt;p&gt; import org.apache.kafka.common.requests.WriteTxnMarkersRequest.TxnMarkerEntry&lt;br/&gt;
 import org.apache.kafka.common.requests._&lt;br/&gt;
 import org.apache.kafka.common.security.auth.&lt;/p&gt;
{KafkaPrincipal, SecurityProtocol}
&lt;p&gt;@@ -106,6 +108,84 @@ class KafkaApisTest &lt;/p&gt;
{
     )
   }

&lt;p&gt;+  @Test&lt;br/&gt;
+  def testOffsetCommitWithInvalidPartition(): Unit = {&lt;br/&gt;
+    val topic = &quot;topic&quot;&lt;br/&gt;
+    setupBasicMetadataCache(topic, numPartitions = 1)&lt;br/&gt;
+&lt;br/&gt;
+    def checkInvalidPartition(invalidPartitionId: Int): Unit = &lt;/p&gt;
{
+      EasyMock.reset(replicaManager, clientRequestQuotaManager, requestChannel)
+
+      val invalidTopicPartition = new TopicPartition(topic, invalidPartitionId)
+      val partitionOffsetCommitData = new OffsetCommitRequest.PartitionData(15L, &quot;&quot;)
+      val (offsetCommitRequest, request) = buildRequest(new OffsetCommitRequest.Builder(&quot;groupId&quot;,
+        Map(invalidTopicPartition -&amp;gt; partitionOffsetCommitData).asJava))
+
+      val capturedResponse = expectThrottleCallbackAndInvoke()
+      EasyMock.replay(replicaManager, clientRequestQuotaManager, requestChannel)
+      createKafkaApis().handleOffsetCommitRequest(request)
+
+      val response = readResponse(ApiKeys.OFFSET_COMMIT, offsetCommitRequest, capturedResponse)
+        .asInstanceOf[OffsetCommitResponse]
+      assertEquals(Errors.UNKNOWN_TOPIC_OR_PARTITION, response.responseData().get(invalidTopicPartition))
+    }
&lt;p&gt;+&lt;br/&gt;
+    checkInvalidPartition(-1)&lt;br/&gt;
+    checkInvalidPartition(1) // topic has only one partition&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  def testTxnOffsetCommitWithInvalidPartition(): Unit = {&lt;br/&gt;
+    val topic = &quot;topic&quot;&lt;br/&gt;
+    setupBasicMetadataCache(topic, numPartitions = 1)&lt;br/&gt;
+&lt;br/&gt;
+    def checkInvalidPartition(invalidPartitionId: Int): Unit = &lt;/p&gt;
{
+      EasyMock.reset(replicaManager, clientRequestQuotaManager, requestChannel)
+
+      val invalidTopicPartition = new TopicPartition(topic, invalidPartitionId)
+      val partitionOffsetCommitData = new TxnOffsetCommitRequest.CommittedOffset(15L, &quot;&quot;)
+      val (offsetCommitRequest, request) = buildRequest(new TxnOffsetCommitRequest.Builder(&quot;txnlId&quot;, &quot;groupId&quot;,
+        15L, 0.toShort, Map(invalidTopicPartition -&amp;gt; partitionOffsetCommitData).asJava))
+
+      val capturedResponse = expectThrottleCallbackAndInvoke()
+      EasyMock.replay(replicaManager, clientRequestQuotaManager, requestChannel)
+      createKafkaApis().handleTxnOffsetCommitRequest(request)
+
+      val response = readResponse(ApiKeys.TXN_OFFSET_COMMIT, offsetCommitRequest, capturedResponse)
+        .asInstanceOf[TxnOffsetCommitResponse]
+      assertEquals(Errors.UNKNOWN_TOPIC_OR_PARTITION, response.errors().get(invalidTopicPartition))
+    }
&lt;p&gt;+&lt;br/&gt;
+    checkInvalidPartition(-1)&lt;br/&gt;
+    checkInvalidPartition(1) // topic has only one partition&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  def testAddPartitionsToTxnWithInvalidPartition(): Unit = {&lt;br/&gt;
+    val topic = &quot;topic&quot;&lt;br/&gt;
+    setupBasicMetadataCache(topic, numPartitions = 1)&lt;br/&gt;
+&lt;br/&gt;
+    def checkInvalidPartition(invalidPartitionId: Int): Unit = &lt;/p&gt;
{
+      EasyMock.reset(replicaManager, clientRequestQuotaManager, requestChannel)
+
+      val invalidTopicPartition = new TopicPartition(topic, invalidPartitionId)
+
+      val (addPartitionsToTxnRequest, request) = buildRequest(new AddPartitionsToTxnRequest.Builder(
+        &quot;txnlId&quot;, 15L, 0.toShort, List(invalidTopicPartition).asJava))
+
+      val capturedResponse = expectThrottleCallbackAndInvoke()
+      EasyMock.replay(replicaManager, clientRequestQuotaManager, requestChannel)
+      createKafkaApis().handleAddPartitionToTxnRequest(request)
+
+      val response = readResponse(ApiKeys.ADD_PARTITIONS_TO_TXN, addPartitionsToTxnRequest, capturedResponse)
+        .asInstanceOf[AddPartitionsToTxnResponse]
+      assertEquals(Errors.UNKNOWN_TOPIC_OR_PARTITION, response.errors().get(invalidTopicPartition))
+    }
&lt;p&gt;+&lt;br/&gt;
+    checkInvalidPartition(-1)&lt;br/&gt;
+    checkInvalidPartition(1) // topic has only one partition&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
   @Test(expected = classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;UnsupportedVersionException&amp;#93;&lt;/span&gt;)&lt;br/&gt;
   def shouldThrowUnsupportedVersionExceptionOnHandleAddOffsetToTxnRequestWhenInterBrokerProtocolNotSupported(): Unit = {&lt;br/&gt;
     createKafkaApis(KAFKA_0_10_2_IV0).handleAddOffsetsToTxnRequest(null)&lt;br/&gt;
@@ -284,8 +364,6 @@ class KafkaApisTest {&lt;br/&gt;
     val timestamp: JLong = time.milliseconds()&lt;br/&gt;
     val limitOffset = 15L&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val capturedResponse = EasyMock.newCapture&lt;span class=&quot;error&quot;&gt;&amp;#91;RequestChannel.Response&amp;#93;&lt;/span&gt;()&lt;/li&gt;
	&lt;li&gt;val capturedThrottleCallback = EasyMock.newCapture&lt;span class=&quot;error&quot;&gt;&amp;#91;Int =&amp;gt; Unit&amp;#93;&lt;/span&gt;()&lt;br/&gt;
     val replica = EasyMock.mock(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;Replica&amp;#93;&lt;/span&gt;)&lt;br/&gt;
     val log = EasyMock.mock(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;Log&amp;#93;&lt;/span&gt;)&lt;br/&gt;
     EasyMock.expect(replicaManager.getLeaderReplicaIfLocal(tp)).andReturn(replica)&lt;br/&gt;
@@ -295,8 +373,7 @@ class KafkaApisTest {&lt;br/&gt;
       EasyMock.expect(replica.lastStableOffset).andReturn(LogOffsetMetadata(messageOffset = limitOffset))&lt;br/&gt;
     EasyMock.expect(replicaManager.getLog(tp)).andReturn(Some(log))&lt;br/&gt;
     EasyMock.expect(log.fetchOffsetsByTimestamp(timestamp)).andReturn(Some(TimestampOffset(timestamp = timestamp, offset = limitOffset)))&lt;/li&gt;
	&lt;li&gt;expectThrottleCallbackAndInvoke(capturedThrottleCallback)&lt;/li&gt;
	&lt;li&gt;EasyMock.expect(requestChannel.sendResponse(EasyMock.capture(capturedResponse)))&lt;br/&gt;
+    val capturedResponse = expectThrottleCallbackAndInvoke()&lt;br/&gt;
     EasyMock.replay(replicaManager, clientRequestQuotaManager, requestChannel, replica, log)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val builder = ListOffsetRequest.Builder.forConsumer(true, isolationLevel)&lt;br/&gt;
@@ -327,8 +404,6 @@ class KafkaApisTest {&lt;br/&gt;
     val tp = new TopicPartition(&quot;foo&quot;, 0)&lt;br/&gt;
     val limitOffset = 15L&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val capturedResponse = EasyMock.newCapture&lt;span class=&quot;error&quot;&gt;&amp;#91;RequestChannel.Response&amp;#93;&lt;/span&gt;()&lt;/li&gt;
	&lt;li&gt;val capturedThrottleCallback = EasyMock.newCapture&lt;span class=&quot;error&quot;&gt;&amp;#91;Int =&amp;gt; Unit&amp;#93;&lt;/span&gt;()&lt;br/&gt;
     val replica = EasyMock.mock(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;Replica&amp;#93;&lt;/span&gt;)&lt;br/&gt;
     val log = EasyMock.mock(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;Log&amp;#93;&lt;/span&gt;)&lt;br/&gt;
     EasyMock.expect(replicaManager.getLeaderReplicaIfLocal(tp)).andReturn(replica)&lt;br/&gt;
@@ -339,8 +414,7 @@ class KafkaApisTest {&lt;br/&gt;
     EasyMock.expect(replicaManager.getLog(tp)).andReturn(Some(log))&lt;br/&gt;
     EasyMock.expect(log.fetchOffsetsByTimestamp(ListOffsetRequest.EARLIEST_TIMESTAMP))&lt;br/&gt;
       .andReturn(Some(TimestampOffset(timestamp = ListOffsetResponse.UNKNOWN_TIMESTAMP, offset = limitOffset)))&lt;/li&gt;
	&lt;li&gt;expectThrottleCallbackAndInvoke(capturedThrottleCallback)&lt;/li&gt;
	&lt;li&gt;EasyMock.expect(requestChannel.sendResponse(EasyMock.capture(capturedResponse)))&lt;br/&gt;
+    val capturedResponse = expectThrottleCallbackAndInvoke()&lt;br/&gt;
     EasyMock.replay(replicaManager, clientRequestQuotaManager, requestChannel, replica, log)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val builder = ListOffsetRequest.Builder.forConsumer(true, isolationLevel)&lt;br/&gt;
@@ -393,14 +467,12 @@ class KafkaApisTest {&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Return pair of listener names in the metadataCache: PLAINTEXT and LISTENER2 respectively.&lt;br/&gt;
    */&lt;br/&gt;
   private def updateMetadataCacheWithInconsistentListeners(): (ListenerName, ListenerName) = {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;import UpdateMetadataRequest.
{Broker =&amp;gt; UBroker}&lt;/li&gt;
	&lt;li&gt;import UpdateMetadataRequest.
{EndPoint =&amp;gt; UEndPoint}
&lt;p&gt;     val plaintextListener = ListenerName.forSecurityProtocol(SecurityProtocol.PLAINTEXT)&lt;br/&gt;
     val anotherListener = new ListenerName(&quot;LISTENER2&quot;)&lt;br/&gt;
     val brokers = Set(&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;new UBroker(0, Seq(new UEndPoint(&quot;broker0&quot;, 9092, SecurityProtocol.PLAINTEXT, plaintextListener),&lt;/li&gt;
	&lt;li&gt;new UEndPoint(&quot;broker0&quot;, 9093, SecurityProtocol.PLAINTEXT, anotherListener)).asJava, &quot;rack&quot;),&lt;/li&gt;
	&lt;li&gt;new UBroker(1, Seq(new UEndPoint(&quot;broker1&quot;, 9092, SecurityProtocol.PLAINTEXT, plaintextListener)).asJava,&lt;br/&gt;
+      new Broker(0, Seq(new EndPoint(&quot;broker0&quot;, 9092, SecurityProtocol.PLAINTEXT, plaintextListener),&lt;br/&gt;
+        new EndPoint(&quot;broker0&quot;, 9093, SecurityProtocol.PLAINTEXT, anotherListener)).asJava, &quot;rack&quot;),&lt;br/&gt;
+      new Broker(1, Seq(new EndPoint(&quot;broker1&quot;, 9092, SecurityProtocol.PLAINTEXT, plaintextListener)).asJava,&lt;br/&gt;
         &quot;rack&quot;)&lt;br/&gt;
     )&lt;br/&gt;
     val updateMetadataRequest = new UpdateMetadataRequest.Builder(ApiKeys.UPDATE_METADATA.latestVersion, 0,&lt;br/&gt;
@@ -410,10 +482,7 @@ class KafkaApisTest {&lt;br/&gt;
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   private def sendMetadataRequestWithInconsistentListeners(requestListener: ListenerName): MetadataResponse = {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val capturedResponse = EasyMock.newCapture&lt;span class=&quot;error&quot;&gt;&amp;#91;RequestChannel.Response&amp;#93;&lt;/span&gt;()&lt;/li&gt;
	&lt;li&gt;val capturedThrottleCallback = EasyMock.newCapture&lt;span class=&quot;error&quot;&gt;&amp;#91;Int =&amp;gt; Unit&amp;#93;&lt;/span&gt;()&lt;/li&gt;
	&lt;li&gt;expectThrottleCallbackAndInvoke(capturedThrottleCallback)&lt;/li&gt;
	&lt;li&gt;EasyMock.expect(requestChannel.sendResponse(EasyMock.capture(capturedResponse)))&lt;br/&gt;
+    val capturedResponse = expectThrottleCallbackAndInvoke()&lt;br/&gt;
     EasyMock.replay(clientRequestQuotaManager, requestChannel)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val (metadataRequest, requestChannelRequest) = buildRequest(MetadataRequest.Builder.allTopics, requestListener)&lt;br/&gt;
@@ -426,8 +495,6 @@ class KafkaApisTest {&lt;br/&gt;
     val tp = new TopicPartition(&quot;foo&quot;, 0)&lt;br/&gt;
     val latestOffset = 15L&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val capturedResponse = EasyMock.newCapture&lt;span class=&quot;error&quot;&gt;&amp;#91;RequestChannel.Response&amp;#93;&lt;/span&gt;()&lt;/li&gt;
	&lt;li&gt;val capturedThrottleCallback = EasyMock.newCapture&lt;span class=&quot;error&quot;&gt;&amp;#91;Int =&amp;gt; Unit&amp;#93;&lt;/span&gt;()&lt;br/&gt;
     val replica = EasyMock.mock(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;Replica&amp;#93;&lt;/span&gt;)&lt;br/&gt;
     val log = EasyMock.mock(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;Log&amp;#93;&lt;/span&gt;)&lt;br/&gt;
     EasyMock.expect(replicaManager.getLeaderReplicaIfLocal(tp)).andReturn(replica)&lt;br/&gt;
@@ -435,8 +502,8 @@ class KafkaApisTest {&lt;br/&gt;
       EasyMock.expect(replica.highWatermark).andReturn(LogOffsetMetadata(messageOffset = latestOffset))&lt;br/&gt;
     else&lt;br/&gt;
       EasyMock.expect(replica.lastStableOffset).andReturn(LogOffsetMetadata(messageOffset = latestOffset))&lt;/li&gt;
	&lt;li&gt;expectThrottleCallbackAndInvoke(capturedThrottleCallback)&lt;/li&gt;
	&lt;li&gt;EasyMock.expect(requestChannel.sendResponse(EasyMock.capture(capturedResponse)))&lt;br/&gt;
+&lt;br/&gt;
+    val capturedResponse = expectThrottleCallbackAndInvoke()&lt;br/&gt;
     EasyMock.replay(replicaManager, clientRequestQuotaManager, requestChannel, replica, log)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val builder = ListOffsetRequest.Builder.forConsumer(true, isolationLevel)&lt;br/&gt;
@@ -484,7 +551,8 @@ class KafkaApisTest &lt;/p&gt;
{
     AbstractResponse.parseResponse(api, struct)
   }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private def expectThrottleCallbackAndInvoke(capturedThrottleCallback: Capture&lt;span class=&quot;error&quot;&gt;&amp;#91;Int =&amp;gt; Unit&amp;#93;&lt;/span&gt;): Unit = {&lt;br/&gt;
+  private def expectThrottleCallbackAndInvoke(): Capture&lt;span class=&quot;error&quot;&gt;&amp;#91;RequestChannel.Response&amp;#93;&lt;/span&gt; = 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+    val capturedThrottleCallback = EasyMock.newCapture[Int =&amp;gt; Unit]()     EasyMock.expect(clientRequestQuotaManager.maybeRecordAndThrottle(       EasyMock.anyObject[RequestChannel.Request](),       EasyMock.capture(capturedThrottleCallback)))@@ -494,6 +562,21 @@ class KafkaApisTest {
           callback(0)
         }       }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;)&lt;br/&gt;
+&lt;br/&gt;
+    val capturedResponse = EasyMock.newCapture&lt;span class=&quot;error&quot;&gt;&amp;#91;RequestChannel.Response&amp;#93;&lt;/span&gt;()&lt;br/&gt;
+    EasyMock.expect(requestChannel.sendResponse(EasyMock.capture(capturedResponse)))&lt;br/&gt;
+    capturedResponse&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  private def setupBasicMetadataCache(topic: String, numPartitions: Int = 1): Unit = &lt;/p&gt;
{
+    val replicas = List(0.asInstanceOf[Integer]).asJava
+    val partitionState = new UpdateMetadataRequest.PartitionState(1, 0, 1, replicas, 0, replicas, Collections.emptyList())
+    val plaintextListener = ListenerName.forSecurityProtocol(SecurityProtocol.PLAINTEXT)
+    val broker = new Broker(0, Seq(new EndPoint(&quot;broker0&quot;, 9092, SecurityProtocol.PLAINTEXT, plaintextListener)).asJava, &quot;rack&quot;)
+    val partitions = (0 until numPartitions).map(new TopicPartition(topic, _) -&amp;gt; partitionState).toMap
+    val updateMetadataRequest = new UpdateMetadataRequest.Builder(ApiKeys.UPDATE_METADATA.latestVersion, 0,
+      0, partitions.asJava, Set(broker).asJava).build()
+    metadataCache.updateCache(correlationId = 0, updateMetadataRequest)
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; }&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/server/ProduceRequestTest.scala b/core/src/test/scala/unit/kafka/server/ProduceRequestTest.scala&lt;br/&gt;
index 60244996dc8..4e66494374f 100644&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/server/ProduceRequestTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/server/ProduceRequestTest.scala&lt;br/&gt;
@@ -59,6 +59,29 @@ class ProduceRequestTest extends BaseRequestTest &lt;/p&gt;
{
       new SimpleRecord(System.currentTimeMillis(), &quot;key2&quot;.getBytes, &quot;value2&quot;.getBytes)), 1)
   }

&lt;p&gt;+  @Test&lt;br/&gt;
+  def testProduceToNonReplica() &lt;/p&gt;
{
+    val topic = &quot;topic&quot;
+    val partition = 0
+
+    // Create a single-partition topic and find a broker which is not the leader
+    val partitionToLeader = TestUtils.createTopic(zkClient, topic, numPartitions = 1, 1, servers)
+    val leader = partitionToLeader(partition)
+    val nonReplicaOpt = servers.find(_.config.brokerId != leader)
+    assertTrue(nonReplicaOpt.isDefined)
+    val nonReplicaId =  nonReplicaOpt.get.config.brokerId
+
+    // Send the produce request to the non-replica
+    val records = MemoryRecords.withRecords(CompressionType.NONE, new SimpleRecord(&quot;key&quot;.getBytes, &quot;value&quot;.getBytes))
+    val topicPartition = new TopicPartition(&quot;topic&quot;, partition)
+    val partitionRecords = Map(topicPartition -&amp;gt; records)
+    val produceRequest = ProduceRequest.Builder.forCurrentMagic(-1, 3000, partitionRecords.asJava).build()
+
+    val produceResponse = sendProduceRequest(nonReplicaId, produceRequest)
+    assertEquals(1, produceResponse.responses.size)
+    assertEquals(Errors.NOT_LEADER_FOR_PARTITION, produceResponse.responses.asScala.head._2.error)
+  }
&lt;p&gt;+&lt;br/&gt;
   /* returns a pair of partition id and leader id */&lt;br/&gt;
   private def createTopicAndFindPartitionWithLeader(topic: String): (Int, Int) = {&lt;br/&gt;
     val partitionToLeader = TestUtils.createTopic(zkClient, topic, 3, 2, servers)&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 29 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3smdz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>