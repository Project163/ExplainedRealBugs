<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:37:00 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-698] broker may expose uncommitted data to a consumer</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-698</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;We saw the following error in the log during testing. The problem seems to be that when the high watermark was at offset 39021, the broker incorrectly exposed an uncommitted message (at offset 39022) to the client. This doesn&apos;t always happen, but can happen when certain conditions are met, which I should explain in the comments.&lt;/p&gt;

&lt;p&gt;2013/01/11 00:54:42.059 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;KafkaApis&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-request-handler-2&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka&amp;#93;&lt;/span&gt; []  &lt;span class=&quot;error&quot;&gt;&amp;#91;KafkaApi-277&amp;#93;&lt;/span&gt; error when processing request (service_metrics,2,39022,2000000)&lt;br/&gt;
java.lang.IllegalArgumentException: Attempt to read with a maximum offset (39021) less than the start offset (39022).&lt;br/&gt;
        at kafka.log.LogSegment.read(LogSegment.scala:105)&lt;br/&gt;
        at kafka.log.Log.read(Log.scala:386)&lt;br/&gt;
        at kafka.server.KafkaApis.kafka$server$KafkaApis$$readMessageSet(KafkaApis.scala:369)&lt;br/&gt;
        at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$readMessageSets$1.apply(KafkaApis.scala:327)&lt;br/&gt;
        at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$readMessageSets$1.apply(KafkaApis.scala:323)&lt;br/&gt;
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)&lt;br/&gt;
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:206)&lt;br/&gt;
        at scala.collection.immutable.Map$Map1.foreach(Map.scala:105)&lt;br/&gt;
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:206)&lt;br/&gt;
        at scala.collection.immutable.Map$Map1.map(Map.scala:93)&lt;br/&gt;
        at kafka.server.KafkaApis.kafka$server$KafkaApis$$readMessageSets(KafkaApis.scala:323)&lt;br/&gt;
        at kafka.server.KafkaApis$$anonfun$maybeUnblockDelayedFetchRequests$2.apply(KafkaApis.scala:165)&lt;br/&gt;
        at kafka.server.KafkaApis$$anonfun$maybeUnblockDelayedFetchRequests$2.apply(KafkaApis.scala:164)&lt;br/&gt;
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:57)&lt;br/&gt;
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:43)&lt;br/&gt;
        at kafka.server.KafkaApis.maybeUnblockDelayedFetchRequests(KafkaApis.scala:164)&lt;br/&gt;
        at kafka.server.KafkaApis$$anonfun$handleProducerRequest$3.apply(KafkaApis.scala:186)&lt;br/&gt;
        at kafka.server.KafkaApis$$anonfun$handleProducerRequest$3.apply(KafkaApis.scala:185)&lt;br/&gt;
        at scala.collection.immutable.Map$Map1.foreach(Map.scala:105)&lt;br/&gt;
        at kafka.server.KafkaApis.handleProducerRequest(KafkaApis.scala:185)&lt;br/&gt;
        at kafka.server.KafkaApis.handle(KafkaApis.scala:58)&lt;br/&gt;
        at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:41)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:619)&lt;/p&gt;</description>
                <environment></environment>
        <key id="12627366">KAFKA-698</key>
            <summary>broker may expose uncommitted data to a consumer</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jkreps">Jay Kreps</assignee>
                                    <reporter username="junrao">Jun Rao</reporter>
                        <labels>
                    </labels>
                <created>Mon, 14 Jan 2013 01:24:34 +0000</created>
                <updated>Sun, 20 Jan 2013 18:42:53 +0000</updated>
                            <resolved>Wed, 16 Jan 2013 04:40:35 +0000</resolved>
                                    <version>0.8.0</version>
                                    <fixVersion>0.8.0</fixVersion>
                                    <component>core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="13552375" author="junrao" created="Mon, 14 Jan 2013 01:25:25 +0000"  >&lt;p&gt;My analysis is the following. In LogSegment.read(), we have the following code that calculates the end position of the maxOffset. When maxOffset is the high watermark, we won&apos;t find its position in the file (since the offset is exclusive). Therefore, we read the size of the segment file as the end position. What can happen is that a new message gets appended btw we call translateOffset and messageSet.sizeInBytes(). That message (may be uncommitted) will then be incorrectly returned to the consumer.&lt;/p&gt;

&lt;p&gt;    // calculate the length of the message set to read based on whether or not they gave us a maxOffset&lt;br/&gt;
    val length = &lt;br/&gt;
      maxOffset match {&lt;br/&gt;
        case None =&amp;gt;&lt;br/&gt;
          // no max offset, just use the max size they gave unmolested&lt;br/&gt;
          maxSize&lt;br/&gt;
        case Some(offset) =&amp;gt; &lt;/p&gt;
{
          // there is a max offset, translate it to a file position and use that to calculate the max read size
          if(offset &amp;lt; startOffset)
            throw new IllegalArgumentException(&quot;Attempt to read with a maximum offset (%d) less than the start offset (%d).&quot;.format(offset, startOffset))
          val mapping = translateOffset(offset)
          val endPosition = 
            if(mapping == null)
              messageSet.sizeInBytes() // the max offset is off the end of the log, use the end of the file
            else
              mapping.position
          min(endPosition - startPosition.position, maxSize) 
        }
&lt;p&gt;      }&lt;/p&gt;

&lt;p&gt;I think the actual problem seems to be that in log.append, we advance nextoffset before the data is actually appended to the log. This causes the problem in log.read since it may see an offset that doesn&apos;t exist in the segment file yet. To fix this, we will need to advance nextOffset after the data is appended to the log.&lt;/p&gt;</comment>
                            <comment id="13552914" author="jkreps" created="Mon, 14 Jan 2013 17:34:51 +0000"  >&lt;p&gt;Attached is a hacky but small patch that should fix this.&lt;/p&gt;

&lt;p&gt;The proper fix is to refactor ByteBufferMessageSet to no longer take an AtomicLong directly, but this is not very straight-forward  and will be very conflict prone with trunk. So let&apos;s hack it for now and I will file a follow up ticket to refactor this.&lt;/p&gt;</comment>
                            <comment id="13553023" author="junrao" created="Mon, 14 Jan 2013 19:32:09 +0000"  >&lt;p&gt;+1 on the patch.&lt;/p&gt;</comment>
                            <comment id="13553392" author="nehanarkhede" created="Tue, 15 Jan 2013 01:40:35 +0000"  >&lt;p&gt;+1 on the patch&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12564738" name="KAFKA-698-v1.patch" size="2026" author="jkreps" created="Mon, 14 Jan 2013 17:34:51 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>304139</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            12 years, 45 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i17jnz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>252155</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>