<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:19:03 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-8106] Reducing the allocation and copying of ByteBuffer  when logValidator  do validation.</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-8106</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;&#160; &#160; &#160; We do performance testing about Kafka in specific scenarios as described below .We build a kafka cluster with one broker,and create topics with different number of partitions.Then we start lots of producer processes to send large amounts of messages to one of the topics at one&#160; testing .&lt;/p&gt;

&lt;p&gt;&lt;b&gt;&lt;em&gt;Specific Scenario&lt;/em&gt;&lt;/b&gt;&lt;br/&gt;
 &#160;&lt;br/&gt;
 &lt;b&gt;&lt;em&gt;1.Main config of Kafka&lt;/em&gt;&lt;/b&gt;&#160;&#160;&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Main config of Kafka&#160; server:&lt;a href=&quot;http://num.network.threads%3D6%3Bnum.io.threads%3D128%3Bqueued.max.requests%3D500/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;num.network.threads=6;num.io.threads=128;queued.max.requests=500&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;Number&#160;of TopicPartition : 50~2000&lt;/li&gt;
	&lt;li&gt;Size of Single Message&#160;:&#160;1024B&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&#160;&lt;br/&gt;
 &lt;b&gt;&lt;em&gt;2.Config of KafkaProducer&lt;/em&gt;&lt;/b&gt;&#160;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;compression.type&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&lt;a href=&quot;http://linger.ms/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;linger.ms&lt;/a&gt;&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;batch.size&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;buffer.memory&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;lz4&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1000ms~5000ms&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;16KB/10KB/100KB&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;128MB&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;&lt;b&gt;&lt;em&gt;3.The best result of performance testing&lt;/em&gt;&lt;/b&gt;&#160;&#160;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Network inflow rate&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;CPU Used (%)&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Disk write speed&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;Performance of production&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;550MB/s~610MB/s&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;97%&#65374;99%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;550MB/s~610MB/s &#160; &#160; &#160;&#160;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;23,000,000 messages/s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;&lt;b&gt;&lt;em&gt;4.Phenomenon and&#160; my&#160;doubt&lt;/em&gt;&lt;/b&gt;&lt;br/&gt;
 &#160;&#160;&#160;&#160;&#160;&#160; &lt;em&gt;The upper limit of CPU usage has been reached&#160; But&#160;&#160;it does not reach the upper limit of the bandwidth of the server&#160; network. &lt;b&gt;We are doubtful about which&#160; cost&#160;too&#160;much&#160;CPU&#160;time and we want to&#160;Improve&#160;&#160;performance and&#160;reduces&#160;CPU&#160;usage of Kafka server.&lt;/b&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;b&gt;5.Analysis&lt;/b&gt;&lt;/em&gt;&lt;br/&gt;
 &#160; &#160; &#160; &#160;We analysis the JFIR of Kafka server when doing performance testing .After we checked and completed the performance test again, we located the code &quot;&lt;b&gt;ByteBuffer recordBuffer = ByteBuffer.allocate(sizeOfBodyInBytes);&lt;/b&gt;(&lt;b&gt;Class:DefaultRecord,Function:readFrom()&lt;/b&gt;)&#8221; which consumed CPU resources and caused a lot of GC .Our modified code reduces the allocation and copying of ByteBuffer, so the test performance is greatly improved, and the CPU&apos;s stable usage is&#160;&lt;b&gt;below 60%&lt;/b&gt;. The following is a comparison of different code test performance under the same conditions.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Result of performance testing&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Main config of Kafka: Single Message:1024B;TopicPartitions:200;linger.ms:1000ms.&lt;/b&gt;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&#160;Single Message&#160;:&#160;1024B,&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Network inflow rate&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;CPU(%)&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Messages/s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Source code&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;600M/s&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;97%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;25,000,000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Modified code&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1GB/s&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;lt;60%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;41,660,000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;*&lt;b&gt;1.Before modified code(Source code) GC:&lt;/b&gt;*&lt;br/&gt;
![](&lt;a href=&quot;https://i.loli.net/2019/05/07/5cd16df163ad3.png&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://i.loli.net/2019/05/07/5cd16df163ad3.png&lt;/a&gt;)&lt;br/&gt;
*&lt;b&gt;2.After modified code(remove allocation of ByteBuffer) GC:&lt;/b&gt;*&lt;br/&gt;
![](&lt;a href=&quot;https://i.loli.net/2019/05/07/5cd16dae1dbc2.png&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://i.loli.net/2019/05/07/5cd16dae1dbc2.png&lt;/a&gt;)&lt;/p&gt;</description>
                <environment>Server : &lt;br/&gt;
cpu:2*16 ; &lt;br/&gt;
MemTotal : 256G;&lt;br/&gt;
Ethernet controller:Intel Corporation 82599ES 10-Gigabit SFI/SFP+ Network Connection ; &lt;br/&gt;
SSD.</environment>
        <key id="13221733">KAFKA-8106</key>
            <summary>Reducing the allocation and copying of ByteBuffer  when logValidator  do validation.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="Flower.min">Flower.min</assignee>
                                    <reporter username="Flower.min">Flower.min</reporter>
                        <labels>
                            <label>performance</label>
                    </labels>
                <created>Thu, 14 Mar 2019 17:41:05 +0000</created>
                <updated>Thu, 4 Jul 2019 08:06:50 +0000</updated>
                            <resolved>Fri, 21 Jun 2019 19:45:55 +0000</resolved>
                                    <version>2.1.1</version>
                    <version>2.2.0</version>
                                    <fixVersion>2.4.0</fixVersion>
                                    <component>core</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>11</watches>
                                                                                                                <comments>
                            <comment id="16794193" author="flower.min" created="Sat, 16 Mar 2019 09:13:57 +0000"  >&lt;p&gt;&#160;My team and I modify some code of Kafka&#160; and I need&#160;permission to commit Code.&#160;We do performance testing again with package include of modified code .The performance of production&#160;improved by 40%~50%,and resource usage of CPU reduced by 30%~50%.&lt;/p&gt;</comment>
                            <comment id="16795688" author="flower.min" created="Tue, 19 Mar 2019 05:13:26 +0000"  >&lt;p&gt;&#160;&#160;&#160;&#160;&#160;We do performance testing again with package include of modified code .the result of perfoemance testing is shown as below.&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Performance of production&#160;&lt;b&gt;:32,000,000 messages/s&lt;/b&gt;.&lt;/li&gt;
	&lt;li&gt;Resource usage:&#160;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Network inflow rate&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;CPU(%)&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;Disk write speed&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;800M/s~1GB/s&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;10%&#65374;40%&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;800M/s~1GB/s&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="16795714" author="omkreddy" created="Tue, 19 Mar 2019 05:49:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Flower.min&quot; class=&quot;user-hover&quot; rel=&quot;Flower.min&quot;&gt;Flower.min&lt;/a&gt;   Instructions for the submitting code changes are here:&lt;br/&gt;
&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/Contributing+Code+Changes&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://cwiki.apache.org/confluence/display/KAFKA/Contributing+Code+Changes&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16797016" author="flower.min" created="Wed, 20 Mar 2019 10:28:17 +0000"  >&lt;p&gt;We suggest that&#160;removing unnecessary decompression operation&#160;when doing&#160; validation for compressed message&#160; when magic value to use is above 1 and no format conversion or value overwriting is required for compressed messages.And&#160;improved code is as follows.&#160;&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Add a class &lt;b&gt;&lt;em&gt;SimplifiedDefaultRecord&lt;/em&gt;&lt;/b&gt; implementing&lt;br/&gt;
 class &lt;b&gt;&lt;em&gt;Record&lt;/em&gt;&lt;/b&gt; which defines various attributes of a message .&lt;/li&gt;
&lt;/ol&gt;


&lt;ol&gt;
	&lt;li&gt;Add a&#160; function&#160;&lt;em&gt;&lt;b&gt;simplifiedreadFrom()&lt;/b&gt;&lt;/em&gt;&#160;at class&#160;&lt;b&gt;&lt;em&gt;DefaultRecord&lt;/em&gt;&lt;/b&gt;&#160;.This function will&#160;not decompress a full message,it just&#160;read size in bytes of record body and compute size in bytes of one record then return a instance of &lt;b&gt;&lt;em&gt;SimplifiedDefaultRecord&lt;/em&gt;&lt;/b&gt;&#160;.&lt;/li&gt;
	&lt;li&gt;Add function&#160;&lt;em&gt;&lt;b&gt;simplifiedIterator()&lt;/b&gt;&lt;/em&gt;&#160;and&#160;&lt;em&gt;&lt;b&gt;simplifiedCompressedIterator&lt;/b&gt;&lt;/em&gt;()&#160;at class&#160;&lt;b&gt;&lt;em&gt;DefaultRecordBatch&lt;/em&gt;&lt;/b&gt;.This two functions will return iterator of instance belongs to class &lt;em&gt;&lt;b&gt;SimplifiedDefaultRecord&lt;/b&gt;&lt;/em&gt;.&lt;/li&gt;
	&lt;li&gt;Modify code of function&#160;&lt;b&gt;&lt;em&gt;validateMessagesAndAssignOffsetsCompressed&lt;/em&gt;&lt;/b&gt;()&#160;at class&#160;&#160;&lt;b&gt;&lt;em&gt;LogValidator&lt;/em&gt;&lt;/b&gt;.&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="16797927" author="flower.min" created="Thu, 21 Mar 2019 09:02:17 +0000"  >&lt;p&gt;&lt;em&gt;&lt;b&gt;We only don&apos;t decompress key and value of a record, it still can validate the offset and timestamp.&lt;/b&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;When all of the following conditions are met, we recommend removing unnecessary decompression operations when validating compressed messages:&lt;br/&gt;
&lt;b&gt;1. The compression type of Kafka servers and topic is consistent with Kafka producer.&lt;/b&gt;&lt;br/&gt;
&lt;b&gt;2. The magic value to use is above 1&lt;/b&gt;&lt;br/&gt;
&lt;b&gt;3. No format conversion and value overwriting is required for messages compressed.&lt;/b&gt;&lt;/p&gt;</comment>
                            <comment id="16799597" author="qiaochao911" created="Sat, 23 Mar 2019 10:33:06 +0000"  >&lt;p&gt;In the scene of inPlaceAssignment,I think the server should set the flag so that the user can choose to get a higher performance limit to shield the decompression of the server.In addition, the current changes to decompress a small part, the upper limit performance is also greatly improved, it still makes sense.&#160; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16804003" author="hackerwin7" created="Thu, 28 Mar 2019 14:43:56 +0000"  >&lt;p&gt;The `validateRecord()` is placed in every branch of `validateMessagesAndAssignOffsets()`,&lt;br/&gt;
Any ideas to put it somewhere to prevent the broker decompression ?&lt;/p&gt;</comment>
                            <comment id="16804532" author="hackerwin7" created="Fri, 29 Mar 2019 02:28:49 +0000"  >&lt;p&gt;Maybe we can put the record level validation to client endpoint or others? And record message format add a validation filed to header, In broker side, broker can check this validation field to prevent record level validation.&lt;/p&gt;</comment>
                            <comment id="16805539" author="junrao" created="Fri, 29 Mar 2019 23:04:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Flower.min&quot; class=&quot;user-hover&quot; rel=&quot;Flower.min&quot;&gt;Flower.min&lt;/a&gt;, one of the validation that the broker has to do is to verify that the timestamp of each record is within the allowed max diff. One can only know the timestamp of a record after decompressing the batch.&#160;&lt;/p&gt;</comment>
                            <comment id="16805757" author="hackerwin7" created="Sat, 30 Mar 2019 10:43:14 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt;, can we batches for this to prevent the record level validation? Such as, we can add the `batch.min.timestamp` and `batch.max.timestamp` in client side to the batch level, and broker side can validate these two boundaries within the configured timestamp max diff range instead of every record validation timestamp.&lt;/p&gt;</comment>
                            <comment id="16806334" author="flower.min" created="Mon, 1 Apr 2019 02:23:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt; Of course,we need read timestamp and offset from record for validating.In the scene of inPlaceAssignment ,we can also read timestamp and offset from a record without decompress record&apos;s&#160; key and value . We suggest remove decompression of record&apos;s&#160; key and value not removing operation of reading record&apos;s timestamp and offset .&lt;/p&gt;</comment>
                            <comment id="16806336" author="wlwolf87" created="Mon, 1 Apr 2019 02:37:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hackerwin7&quot; class=&quot;user-hover&quot; rel=&quot;hackerwin7&quot;&gt;hackerwin7&lt;/a&gt;&#160;First,&#160;you have to be clear that the parameters of the client are not completely trusted.&lt;/p&gt;

&lt;p&gt;Second, the &quot;&lt;b&gt;validateMessagesAndAssignOffsetsCompressed&lt;/b&gt;&quot; method&#160;not only validate the &quot;&lt;b&gt;Timestamp&lt;/b&gt;&quot;, but also &quot;&lt;b&gt;Offset&lt;/b&gt;&quot; and &quot;&lt;b&gt;Key&lt;/b&gt;&quot;.&lt;/p&gt;

&lt;p&gt;&#160;&lt;br/&gt;
&lt;tt&gt;Record =&amp;gt;&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;Length =&amp;gt; varint&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;Attributes =&amp;gt; int8&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;TimestampDelta =&amp;gt; varint&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;OffsetDelta =&amp;gt; varint&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;KeyLen =&amp;gt; varint&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;Key =&amp;gt; data&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;ValueLen =&amp;gt; varint&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;Value =&amp;gt; data&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;Headers =&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Header&amp;#93;&lt;/span&gt;&lt;/tt&gt;&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt;&#160;We don&apos;t have to decompress the &quot;Key&quot; and &quot;Value&quot;, and then we can still validate the &quot;Timestamp&quot;, &quot;Key&quot; and &quot;Offset&quot;, we only&#160;decompress the record of &quot;Length&quot;, &quot;Attributes&quot;, &quot;TimestampDelta&quot;, &quot;OffsetDelta&quot;, &quot;KeyLen&quot;,&#160;which already meet the verification requirements.&#160;And I think that decompressing the &quot;Value&quot; field consumes most of the performance, which is not necessary in most cases.&lt;/p&gt;</comment>
                            <comment id="16806337" author="flower.min" created="Mon, 1 Apr 2019 02:43:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hackerwin7&quot; class=&quot;user-hover&quot; rel=&quot;hackerwin7&quot;&gt;hackerwin7&lt;/a&gt;I agree with idea of &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=qiaochao911&quot; class=&quot;user-hover&quot; rel=&quot;qiaochao911&quot;&gt;qiaochao911&lt;/a&gt;&#160;.Maybe we can set a flag to choose whether or not need to decompress record&apos;s key and value.In other cases such as the magic value to use is below 2 ,we also need decompress record&apos;s key and value for validating.&lt;/p&gt;</comment>
                            <comment id="16806352" author="hackerwin7" created="Mon, 1 Apr 2019 03:12:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wlwolf87&quot; class=&quot;user-hover&quot; rel=&quot;wlwolf87&quot;&gt;wlwolf87&lt;/a&gt; Currently the the broker decompress to validate record timestamp, key, offset, uncompressed size bytes, and magic .&lt;/p&gt;

&lt;p&gt;Secondly how can decompress the only fields of `Record`, just because the compressor output stream write the bytes to buffer in low level ?&lt;/p&gt;</comment>
                            <comment id="16806363" author="wlwolf87" created="Mon, 1 Apr 2019 03:45:18 +0000"  >&lt;p&gt;&lt;tt&gt;RecordBatch =&amp;gt;&lt;/tt&gt;&lt;br/&gt;
 &lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;FirstOffset =&amp;gt; int64&lt;/tt&gt;&lt;br/&gt;
 &lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;Length =&amp;gt; int32&lt;/tt&gt;&lt;br/&gt;
 &lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;PartitionLeaderEpoch =&amp;gt; int32&lt;/tt&gt;&lt;br/&gt;
 &lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;Magic =&amp;gt; int8&#160;&lt;/tt&gt;&lt;br/&gt;
 &lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;CRC =&amp;gt; int32&lt;/tt&gt;&lt;br/&gt;
 &lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;Attributes =&amp;gt; int16&lt;/tt&gt;&lt;br/&gt;
 &lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;LastOffsetDelta =&amp;gt; int32&lt;/tt&gt;&lt;br/&gt;
 &lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;FirstTimestamp =&amp;gt; int64&lt;/tt&gt;&lt;br/&gt;
 &lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;MaxTimestamp =&amp;gt; int64&lt;/tt&gt;&lt;br/&gt;
 &lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;ProducerId =&amp;gt; int64&lt;/tt&gt;&lt;br/&gt;
 &lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;ProducerEpoch =&amp;gt; int16&lt;/tt&gt;&lt;br/&gt;
 &lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;FirstSequence =&amp;gt; int32&lt;/tt&gt;&lt;br/&gt;
 &lt;tt&gt;&#160;&#160;&lt;/tt&gt;&lt;tt&gt;Records =&amp;gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Record&amp;#93;&lt;/span&gt;&lt;/tt&gt;&lt;br/&gt;
 &#160;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hackerwin7&quot; class=&quot;user-hover&quot; rel=&quot;hackerwin7&quot;&gt;hackerwin7&lt;/a&gt; The&#160;MaxTimestamp already exists in&#160;RecordBatch&#65292;but it was not used but recalculated once.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;The &quot;uncompressedSizeInBytes&quot; is&#160;Record&apos;s&#160;Length, and the &quot;Magic&quot; is in RecordBatch.&lt;/p&gt;

&lt;p&gt;Decompress the record of &quot;Length&quot;, &quot;Attributes&quot;, &quot;TimestampDelta&quot;, &quot;OffsetDelta&quot;, &quot;KeyLen&quot;, to see the &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Flower.min&quot; class=&quot;user-hover&quot; rel=&quot;Flower.min&quot;&gt;Flower.min&lt;/a&gt; pr&#160;&lt;a href=&quot;https://github.com/apache/kafka/pull/6476&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/6476&lt;/a&gt;&lt;br/&gt;
 &#160;&lt;/p&gt;</comment>
                            <comment id="16806375" author="hackerwin7" created="Mon, 1 Apr 2019 04:35:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wlwolf87&quot; class=&quot;user-hover&quot; rel=&quot;wlwolf87&quot;&gt;wlwolf87&lt;/a&gt; `MaxTimestamp` I think we can not use it to validation because of the trusted issue.&lt;/p&gt;

&lt;p&gt;Thanks for the PR, just review this, it avoid the value and key read to decompress. just like partial decompression&lt;/p&gt;

&lt;p&gt;any ideas to prevent record level operation across this?&lt;/p&gt;</comment>
                            <comment id="16835389" author="githubbot" created="Wed, 8 May 2019 07:22:40 +0000"  >&lt;p&gt;Flowermin commented on pull request #6699: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-8106&quot; title=&quot;Reducing the allocation and copying of ByteBuffer  when logValidator  do validation.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-8106&quot;&gt;&lt;del&gt;KAFKA-8106&lt;/del&gt;&lt;/a&gt;:Reducing the allocation and copying of ByteBuffer when logValidator do validation(target trunk). &lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/6699&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/6699&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   We suggest that reducing the allocation and copying of ByteBuffer when logValidator do validation when magic value to use is above 1 and no format conversion or value overwriting is required for compressed messages.And improved code is as follows.&lt;br/&gt;
   1. Adding a class *&lt;b&gt;SimplifiedDefaultRecord&lt;/b&gt;* implement class Record which define  various attributes of a message. &lt;br/&gt;
   2. Adding Function *&lt;b&gt;simplifiedreadFrom&lt;/b&gt;&lt;b&gt;() at class **DefaultRecord&lt;/b&gt;* .This function will not read data from DataInput to  ByteBuffer which need newly creating .*&lt;b&gt;This will reduce the allocation and copying of ByteBuffer&lt;/b&gt;* when logValidator do validation .This will reduces GC frequency. We offer a simple read function to read data from *&lt;b&gt;DataInput&lt;/b&gt;* whithout create ByteBuffer.Of course this opertion can not avoid deconmpression to data.&lt;br/&gt;
   3. Adding Function *&lt;b&gt;simplifiedIterator&lt;/b&gt;&lt;b&gt;() and **simplifiedCompressedIterator&lt;/b&gt;&lt;b&gt;() at class **DefaultRecordBatch&lt;/b&gt;&lt;b&gt;.This two functions will return iterator of instance belongs to class **SimplifiedDefaultRecord&lt;/b&gt;*.&lt;br/&gt;
   4. Modify code of function *&lt;b&gt;validateMessagesAndAssignOffsetsCompressed&lt;/b&gt;*() at class  LogValidator.&lt;/p&gt;

&lt;p&gt;       *&lt;b&gt;After modifing code wich  reducing the allocation and copying of ByteBuffer&lt;/b&gt;*, the test performance is greatly improved, and the CPU&apos;s stable usage is below 60%. The following is a comparison of different code test performance under the same conditions.&lt;br/&gt;
   *&lt;b&gt;Result of performance testing&lt;/b&gt;*&lt;br/&gt;
   Main config of Kafka: Single Message:1024B;TopicPartitions:200;linger.ms:1000ms,&lt;br/&gt;
   *&lt;b&gt;1.Before modified code(Source code):&lt;/b&gt;*&lt;br/&gt;
   Network inflow rate:600M/s;CPU(%)(97%);production:25,000,000 messages/s&lt;br/&gt;
   *&lt;b&gt;2.After modified code(remove allocation of ByteBuffer):&lt;/b&gt;*&lt;br/&gt;
   Network inflow rate:1G/s;CPU(%)(&amp;lt;60%);production:41,000,000 messages/s&lt;br/&gt;
    *&lt;b&gt;1.Before modified code(Source code) GC:&lt;/b&gt;*&lt;br/&gt;
   ![](&lt;a href=&quot;https://i.loli.net/2019/05/07/5cd16df163ad3.png&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://i.loli.net/2019/05/07/5cd16df163ad3.png&lt;/a&gt;)&lt;br/&gt;
   *&lt;b&gt;2.After modified code(remove allocation of ByteBuffer) GC:&lt;/b&gt;*&lt;br/&gt;
   ![](&lt;a href=&quot;https://i.loli.net/2019/05/07/5cd16dae1dbc2.png&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://i.loli.net/2019/05/07/5cd16dae1dbc2.png&lt;/a&gt;)&lt;/p&gt;


&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on to GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16835563" author="githubbot" created="Wed, 8 May 2019 12:49:38 +0000"  >&lt;p&gt;ijuma commented on pull request #6476: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-8106&quot; title=&quot;Reducing the allocation and copying of ByteBuffer  when logValidator  do validation.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-8106&quot;&gt;&lt;del&gt;KAFKA-8106&lt;/del&gt;&lt;/a&gt;:Reducing the allocation and copying of ByteBuffer  when logValidator  do validation.&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/6476&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/6476&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on to GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16845497" author="githubbot" created="Wed, 22 May 2019 04:17:52 +0000"  >&lt;p&gt;guozhangwang commented on pull request #6785: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-8106&quot; title=&quot;Reducing the allocation and copying of ByteBuffer  when logValidator  do validation.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-8106&quot;&gt;&lt;del&gt;KAFKA-8106&lt;/del&gt;&lt;/a&gt;: Skipping ByteBuffer allocation of key / value / headers in logValidator&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/6785&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/6785&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   This is based on @Flowermin in &lt;a href=&quot;https://github.com/apache/kafka/pull/6699&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/6699&lt;/a&gt; addressing the comments.&lt;/p&gt;

&lt;p&gt;   1. Add skipKeyValueIterator() used in LogValidator; based on wether `isCompressed` and `skipKeyValue` there are four possible iterators now.&lt;br/&gt;
   2. Add SkipKeyValueDefaultRecord which extends DefaultRecord.&lt;/p&gt;

&lt;p&gt;   -------------&lt;/p&gt;

&lt;p&gt;   We suggest that reducing the allocation and copying of ByteBuffer when logValidator do validation when magic value to use is above 1 and no format conversion or value overwriting is required for compressed messages.And improved code is as follows.&lt;br/&gt;
   1. Adding a class *&lt;b&gt;SimplifiedDefaultRecord&lt;/b&gt;* implement class Record which define  various attributes of a message. &lt;br/&gt;
   2. Adding Function *&lt;b&gt;simplifiedreadFrom&lt;/b&gt;&lt;b&gt;() at class **DefaultRecord&lt;/b&gt;* .This function will not read data from DataInput to  ByteBuffer which need newly creating .*&lt;b&gt;This will reduce the allocation and copying of ByteBuffer&lt;/b&gt;* when logValidator do validation .This will reduces GC frequency. We offer a simple read function to read data from *&lt;b&gt;DataInput&lt;/b&gt;* whithout create ByteBuffer.Of course this opertion can not avoid deconmpression to data.&lt;br/&gt;
   3. Adding Function *&lt;b&gt;simplifiedIterator&lt;/b&gt;&lt;b&gt;() and **simplifiedCompressedIterator&lt;/b&gt;&lt;b&gt;() at class **DefaultRecordBatch&lt;/b&gt;&lt;b&gt;.This two functions will return iterator of instance belongs to class **SimplifiedDefaultRecord&lt;/b&gt;*.&lt;br/&gt;
   4. Modify code of function *&lt;b&gt;validateMessagesAndAssignOffsetsCompressed&lt;/b&gt;*() at class  LogValidator.&lt;/p&gt;

&lt;p&gt;       *&lt;b&gt;After modifing code wich  reducing the allocation and copying of ByteBuffer&lt;/b&gt;*, the test performance is greatly improved, and the CPU&apos;s stable usage is below 60%. The following is a comparison of different code test performance under the same conditions.&lt;br/&gt;
   *&lt;b&gt;Result of performance testing&lt;/b&gt;*&lt;br/&gt;
   Main config of Kafka: Single Message:1024B;TopicPartitions:200;linger.ms:1000ms,&lt;br/&gt;
   *&lt;b&gt;1.Before modified code(Source code):&lt;/b&gt;*&lt;br/&gt;
   Network inflow rate:600M/s;CPU(%)(97%);production:25,000,000 messages/s&lt;br/&gt;
   *&lt;b&gt;2.After modified code(remove allocation of ByteBuffer):&lt;/b&gt;*&lt;br/&gt;
   Network inflow rate:1G/s;CPU(%)(&amp;lt;60%);production:41,000,000 messages/s&lt;br/&gt;
    *&lt;b&gt;1.Before modified code(Source code) GC:&lt;/b&gt;*&lt;br/&gt;
   ![](&lt;a href=&quot;https://i.loli.net/2019/05/07/5cd16df163ad3.png&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://i.loli.net/2019/05/07/5cd16df163ad3.png&lt;/a&gt;)&lt;br/&gt;
   *&lt;b&gt;2.After modified code(remove allocation of ByteBuffer) GC:&lt;/b&gt;*&lt;br/&gt;
   ![](&lt;a href=&quot;https://i.loli.net/2019/05/07/5cd16dae1dbc2.png&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://i.loli.net/2019/05/07/5cd16dae1dbc2.png&lt;/a&gt;)&lt;/p&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on to GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16864532" author="guozhang" created="Fri, 14 Jun 2019 23:55:54 +0000"  >&lt;p&gt;Okay guys after some further benchmarks now I think I&apos;ve finally realized the difference in perf:&lt;/p&gt;

&lt;p&gt;1. our current code would allocate a byte buffer for each record deserialized:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
        ByteBuffer recordBuffer = ByteBuffer.allocate(sizeOfBodyInBytes);
        input.readFully(recordBuffer.array(), 0, sizeOfBodyInBytes);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;the byte array size is `sizeOfBodyInBytes`, and it can cause GC pressure;&lt;/p&gt;

&lt;p&gt;2. the skipBytes implementation tries to not allocate such a big byte array; HOWEVER depending on the compressionType the underlying implementation is different:&lt;/p&gt;

&lt;p&gt;2.a. LZ4 used KafkaLZ4BlockInputStream, which has a shared decompressionBuffer, default size 65536. It means, for a batch of records, we will only have a single allocated buffer.&lt;/p&gt;

&lt;p&gt;2.b. All other compressionType used BufferedDataInputStream, whose skipBytes is implemented as&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; size = (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;)&lt;span class=&quot;code-object&quot;&gt;Math&lt;/span&gt;.min(MAX_SKIP_BUFFER_SIZE, remaining);
        &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] skipBuffer = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[size];
        &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (remaining &amp;gt; 0) {
            nr = read(skipBuffer, 0, (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;)&lt;span class=&quot;code-object&quot;&gt;Math&lt;/span&gt;.min(size, remaining));
            &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (nr &amp;lt; 0) {
                &lt;span class=&quot;code-keyword&quot;&gt;break&lt;/span&gt;;
            }
            remaining -= nr;
        }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;I.e. each call will allocate a new byte buffer, which is different from 2.a.&lt;/p&gt;

&lt;p&gt;3. Our current implementation is slightly better than 2.b because we still only allocate one buffer although we need to `skip` three fields (key, value, and array of headers). But it is still inferior to 2.a, which only use a single buffer; current implementation is ONLY beneficial if the record size is larger than 2048, whereas 2.a&apos;s approach, as demonstrated by the original author whose used LZ4, is much better even for 1KB message size. So our perf numbers on other compression types than LZ4 would not show much benefits until record size is much larger than 2048.&lt;/p&gt;

&lt;p&gt;So I think if we want to get the similar performance boost for all compression types as the original PR did for LZ4, we then need to have single shared buffer associated with the `InputStream` object, generated from `wrapForInput`, which can then be used for all the records within a batch. (edited) &lt;/p&gt;</comment>
                            <comment id="16869836" author="githubbot" created="Fri, 21 Jun 2019 19:44:48 +0000"  >&lt;p&gt;guozhangwang commented on pull request #6785: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-8106&quot; title=&quot;Reducing the allocation and copying of ByteBuffer  when logValidator  do validation.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-8106&quot;&gt;&lt;del&gt;KAFKA-8106&lt;/del&gt;&lt;/a&gt;: Skipping ByteBuffer allocation of key / value / headers in logValidator&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/6785&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/6785&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on to GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16869862" author="guozhang" created="Fri, 21 Jun 2019 20:39:17 +0000"  >&lt;p&gt;The merged PR is inspired by the original work of #6699 by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Flower.min&quot; class=&quot;user-hover&quot; rel=&quot;Flower.min&quot;&gt;Flower.min&lt;/a&gt;. It tries to achieve the same CPU savings by reducing unnecessary byte allocation and corresponding GC. Unlike #6699 though, which depends on skipBytes of LZ4 which used a shared byte array, in this PR we create a skip buffer outside of the compressed input stream. The reason is that not all compressed inputstream&apos;s implementation is optimized, more specifically:&lt;/p&gt;

&lt;p&gt;1. GZIP used BufferedInputStream, which has a shared buffer, sized 16KB&lt;br/&gt;
2. SNAPPY used its own SnappyInputStream -&amp;gt; InputStream, which dynamically allocate&lt;br/&gt;
3. LZ4 used its own KafkaLZ4BlockInputStream, which has a shared buffer of 64KB&lt;br/&gt;
4. ZSTD used its own ZstdInputStream, but it&apos;s own overriden skip also dynamically allocate&lt;/p&gt;

&lt;p&gt;The detailed implementation can be summarized as follows:&lt;/p&gt;

&lt;p&gt;1. Add skipKeyValueIterator() into DefaultRecordBatch, used in LogValidator; also added PartialDefaultRecord which extends DefaultRecord.&lt;br/&gt;
1.a. In order make this optimization really effective, we also need to refactor the LogValidator to refactor part of the validation per record into the outer loop so that we do not need to update inPlaceAssigment inside the loop any more. And then based on this boolean we can decide whether or not to use skipKeyValueIterator or not before the loop.&lt;/p&gt;

&lt;p&gt;1.b. Also used streaming iterator instead when skip-iterator cannot be used.&lt;/p&gt;

&lt;p&gt;2. With SkipKeyValueIterator, pre-allocate a skip byte array with fixed size (2KB), and use this array to take the decompressed bytes through each record, validating metadata and key / value / header size, while skipping the key / value bytes.&lt;/p&gt;

&lt;p&gt;3. Also tighten the unit tests of LogValidator to make sure scenarios like mismatched magic bytes / multiple batches per partition / discontinuous offsets / etc are indeed validated.&lt;/p&gt;</comment>
                            <comment id="16878420" author="githubbot" created="Thu, 4 Jul 2019 08:06:50 +0000"  >&lt;p&gt;hachikuji commented on pull request #6699: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-8106&quot; title=&quot;Reducing the allocation and copying of ByteBuffer  when logValidator  do validation.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-8106&quot;&gt;&lt;del&gt;KAFKA-8106&lt;/del&gt;&lt;/a&gt;:Reducing the allocation and copying of ByteBuffer when logValidator do validation(target trunk). &lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/6699&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/6699&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on to GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 19 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z00pu8:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>