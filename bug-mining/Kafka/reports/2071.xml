<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:15:36 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-7483] Streams should allow headers to be passed to Serializer</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-7483</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;We are storing schema metadata for record key and value in the header. Serializer,&#160;includes this metadata&#160;in the record header.&#160;While doing simple record transformation (x transformed to y) in streams, the same&#160;header&#160;that was passed from source, pushed to the sink topic. This leads to error&#160;while reading the sink topic.&lt;/p&gt;

&lt;p&gt;We should call the overloaded `serialize(topic, headers, object)` method in&#160;&lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/streams/src/main/java/org/apache/kafka/streams/processor/internals/RecordCollectorImpl.java#L156&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;RecordCollectorImpl&lt;/a&gt;&#160;which in-turn adds the correct metadata in the record header.&lt;/p&gt;

&lt;p&gt;With this sink topic reader have the option to read all the values for a header key using `Headers#headers`&#160; &lt;span class=&quot;error&quot;&gt;&amp;#91;or&amp;#93;&lt;/span&gt; only the overwritten value using `Headers#lastHeader`&lt;/p&gt;</description>
                <environment></environment>
        <key id="13189646">KAFKA-7483</key>
            <summary>Streams should allow headers to be passed to Serializer</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ckamal">Kamal Chandraprakash</assignee>
                                    <reporter username="ckamal">Kamal Chandraprakash</reporter>
                        <labels>
                    </labels>
                <created>Fri, 5 Oct 2018 05:33:07 +0000</created>
                <updated>Tue, 9 Oct 2018 22:30:48 +0000</updated>
                            <resolved>Tue, 9 Oct 2018 22:30:43 +0000</resolved>
                                                    <fixVersion>2.1.0</fixVersion>
                                    <component>streams</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="16639930" author="vvcephei" created="Fri, 5 Oct 2018 15:02:57 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ckamal&quot; class=&quot;user-hover&quot; rel=&quot;ckamal&quot;&gt;ckamal&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;Thanks for the feature request!&lt;/p&gt;

&lt;p&gt;This was the recent change (2.0) that allowed record headers to flow through the topology:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-244%3A+Add+Record+Header+support+to+Kafka+Streams+Processor+API&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://cwiki.apache.org/confluence/display/KAFKA/KIP-244%3A+Add+Record+Header+support+to+Kafka+Streams+Processor+API&lt;/a&gt;&#160;&lt;/li&gt;
	&lt;li&gt;aka &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6850&quot; title=&quot;KIP-244: Add Record Header support to Kafka Streams Processor API&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6850&quot;&gt;&lt;del&gt;KAFKA-6850&lt;/del&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;It seems like this request is a straightforward extension of that work&lt;/p&gt;

&lt;p&gt;It also doesn&apos;t seem like this would affect any public APIs, thus it would not require a KIP.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Offhand, it does seem like a simple, beneficial change... As you noted, we&apos;d just call the extended serializer method in RecordCollectorImpl.&lt;/p&gt;

&lt;p&gt;It would probably be good to search the Streams codebase for other invocations of `serialize` just to make sure the feature is airtight.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;If you want to, you&apos;re welcome to send a PR with the proposed change!&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Thanks,&lt;/p&gt;

&lt;p&gt;-John&lt;/p&gt;</comment>
                            <comment id="16640073" author="guozhang" created="Fri, 5 Oct 2018 16:55:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ckamal&quot; class=&quot;user-hover&quot; rel=&quot;ckamal&quot;&gt;ckamal&lt;/a&gt; I think this is a good one to add and should be straight-forward as well, compatibility wise I do not seen any obvious issues as we have default impl of `serialize(String topic, Headers headers, T data)` to ignore the header so for users who do not serialize the headers anyways they should not see any surprises.&lt;/p&gt;

&lt;p&gt;Would you like to submit a PR for this, along with some unit test to make sure the logic is added properly?&lt;/p&gt;</comment>
                            <comment id="16640165" author="mjsax" created="Fri, 5 Oct 2018 18:08:40 +0000"  >&lt;p&gt;I don&apos;t understand this ticket.&lt;/p&gt;

&lt;p&gt;1) There is not `RecordCollectorImpl#serializer()` method, thus, what do you want to &quot;overload&quot; ?&lt;/p&gt;

&lt;p&gt;2) Via KIP-244 (as pointed out by John), you can already manipulate the headers: note, that the input record header will be forwarded to the output record, and thus, you can take the input record header (via context.header() and update it to contain the schema information for the output record.&lt;/p&gt;

&lt;p&gt;Thus, I don&apos;t think we need to change anything, but it&apos;s already supported.&lt;/p&gt;</comment>
                            <comment id="16640174" author="guozhang" created="Fri, 5 Oct 2018 18:16:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mjsax&quot; class=&quot;user-hover&quot; rel=&quot;mjsax&quot;&gt;mjsax&lt;/a&gt; I think &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ckamal&quot; class=&quot;user-hover&quot; rel=&quot;ckamal&quot;&gt;ckamal&lt;/a&gt; was referring to `Serializer#serialize(String topic, Headers headers, T data)`, i.e. to let RecordCollectorImpl.send() to call this overload function than `serialize(String topic, T data)`.&lt;/p&gt;</comment>
                            <comment id="16640181" author="mjsax" created="Fri, 5 Oct 2018 18:21:04 +0000"  >&lt;p&gt;I see. So it&apos;s a two line fix? Sure, we can do that. Sorry for the confusion.&lt;/p&gt;</comment>
                            <comment id="16640304" author="githubbot" created="Fri, 5 Oct 2018 20:18:28 +0000"  >&lt;p&gt;kamalcph opened a new pull request #5751: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7483&quot; title=&quot;Streams should allow headers to be passed to Serializer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7483&quot;&gt;&lt;del&gt;KAFKA-7483&lt;/del&gt;&lt;/a&gt;: Allow streams to pass headers through Serializer.&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5751&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5751&lt;/a&gt;&lt;/p&gt;



&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16644173" author="githubbot" created="Tue, 9 Oct 2018 22:29:07 +0000"  >&lt;p&gt;guozhangwang closed pull request #5751: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7483&quot; title=&quot;Streams should allow headers to be passed to Serializer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7483&quot;&gt;&lt;del&gt;KAFKA-7483&lt;/del&gt;&lt;/a&gt;: Allow streams to pass headers through Serializer.&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5751&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5751&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/RecordCollectorImpl.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/RecordCollectorImpl.java&lt;br/&gt;
index 7e192973425..5df14ee2815 100644&lt;br/&gt;
&amp;#8212; a/streams/src/main/java/org/apache/kafka/streams/processor/internals/RecordCollectorImpl.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/RecordCollectorImpl.java&lt;br/&gt;
@@ -153,8 +153,8 @@ private boolean productionExceptionIsFatal(final Exception exception) {&lt;br/&gt;
                             final Serializer&amp;lt;K&amp;gt; keySerializer,&lt;br/&gt;
                             final Serializer&amp;lt;V&amp;gt; valueSerializer) {&lt;br/&gt;
         checkForException();&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final byte[] keyBytes = keySerializer.serialize(topic, key);&lt;/li&gt;
	&lt;li&gt;final byte[] valBytes = valueSerializer.serialize(topic, value);&lt;br/&gt;
+        final byte[] keyBytes = keySerializer.serialize(topic, headers, key);&lt;br/&gt;
+        final byte[] valBytes = valueSerializer.serialize(topic, headers, value);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         final ProducerRecord&amp;lt;byte[], byte[]&amp;gt; serializedRecord = new ProducerRecord&amp;lt;&amp;gt;(topic, partition, timestamp, keyBytes, valBytes, headers);&lt;/p&gt;

&lt;p&gt;diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordCollectorTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordCollectorTest.java&lt;br/&gt;
index 4f89a1e756f..c4e58be7c1f 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordCollectorTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordCollectorTest.java&lt;br/&gt;
@@ -65,17 +65,14 @@&lt;br/&gt;
     );&lt;/p&gt;

&lt;p&gt;     private final Cluster cluster = new Cluster(&quot;cluster&quot;, Collections.singletonList(Node.noNode()), infos,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Collections.&amp;lt;String&amp;gt;emptySet(), Collections.&amp;lt;String&amp;gt;emptySet());&lt;br/&gt;
+        Collections.emptySet(), Collections.emptySet());&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;     private final ByteArraySerializer byteArraySerializer = new ByteArraySerializer();&lt;br/&gt;
     private final StringSerializer stringSerializer = new StringSerializer();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final StreamPartitioner&amp;lt;String, Object&amp;gt; streamPartitioner = new StreamPartitioner&amp;lt;String, Object&amp;gt;() {&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public Integer partition(final String topic, final String key, final Object value, final int numPartitions) 
{
-            return Integer.parseInt(key) % numPartitions;
-        }
&lt;p&gt;+    private final StreamPartitioner&amp;lt;String, Object&amp;gt; streamPartitioner = (topic, key, value, numPartitions) -&amp;gt; &lt;/p&gt;
{
+        return Integer.parseInt(key) % numPartitions;
     }
&lt;p&gt;;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @Test&lt;br/&gt;
@@ -362,4 +359,55 @@ public void shouldThrowIfTopicIsUnknownWithContinueExceptionHandler() {&lt;br/&gt;
         });&lt;br/&gt;
         collector.send(&quot;topic1&quot;, &quot;3&quot;, &quot;0&quot;, null, null, stringSerializer, stringSerializer, streamPartitioner);&lt;br/&gt;
     }&lt;br/&gt;
+&lt;br/&gt;
+    @Test&lt;br/&gt;
+    public void testRecordHeaderPassThroughSerializer() {&lt;br/&gt;
+        final CustomStringSerializer keySerializer = new CustomStringSerializer();&lt;br/&gt;
+        final CustomStringSerializer valueSerializer = new CustomStringSerializer();&lt;br/&gt;
+        keySerializer.configure(Collections.EMPTY_MAP, true);&lt;br/&gt;
+&lt;br/&gt;
+        final RecordCollectorImpl collector = new RecordCollectorImpl(&lt;br/&gt;
+                &quot;test&quot;,&lt;br/&gt;
+                logContext,&lt;br/&gt;
+                new DefaultProductionExceptionHandler(),&lt;br/&gt;
+                new Metrics().sensor(&quot;skipped-records&quot;)&lt;br/&gt;
+        );&lt;br/&gt;
+        final MockProducer&amp;lt;byte[], byte[]&amp;gt; mockProducer = new MockProducer&amp;lt;&amp;gt;(cluster, true, new DefaultPartitioner(),&lt;br/&gt;
+                byteArraySerializer, byteArraySerializer);&lt;br/&gt;
+        collector.init(mockProducer);&lt;br/&gt;
+&lt;br/&gt;
+        collector.send(&quot;topic1&quot;, &quot;3&quot;, &quot;0&quot;, new RecordHeaders(), null, keySerializer, valueSerializer, streamPartitioner);&lt;br/&gt;
+&lt;br/&gt;
+        final List&amp;lt;ProducerRecord&amp;lt;byte[], byte[]&amp;gt;&amp;gt; recordHistory = mockProducer.history();&lt;br/&gt;
+        for (final ProducerRecord&amp;lt;byte[], byte[]&amp;gt; sentRecord : recordHistory) &lt;/p&gt;
{
+            final Headers headers = sentRecord.headers();
+            assertEquals(2, headers.toArray().length);
+            assertEquals(new RecordHeader(&quot;key&quot;, &quot;key&quot;.getBytes()), headers.lastHeader(&quot;key&quot;));
+            assertEquals(new RecordHeader(&quot;value&quot;, &quot;value&quot;.getBytes()), headers.lastHeader(&quot;value&quot;));
+        }
&lt;p&gt;+    }&lt;br/&gt;
+&lt;br/&gt;
+    private static class CustomStringSerializer extends StringSerializer {&lt;br/&gt;
+&lt;br/&gt;
+        private boolean isKey;&lt;br/&gt;
+&lt;br/&gt;
+        private CustomStringSerializer() &lt;/p&gt;
{
+        }
&lt;p&gt;+&lt;br/&gt;
+        @Override&lt;br/&gt;
+        public void configure(final Map&amp;lt;String, ?&amp;gt; configs, final boolean isKey) &lt;/p&gt;
{
+            this.isKey = isKey;
+            super.configure(configs, isKey);
+        }
&lt;p&gt;+&lt;br/&gt;
+        @Override&lt;br/&gt;
+        public byte[] serialize(final String topic, final Headers headers, final String data) {&lt;br/&gt;
+            if (isKey) &lt;/p&gt;
{
+                headers.add(new RecordHeader(&quot;key&quot;, &quot;key&quot;.getBytes()));
+            }
&lt;p&gt; else &lt;/p&gt;
{
+                headers.add(new RecordHeader(&quot;value&quot;, &quot;value&quot;.getBytes()));
+            }
&lt;p&gt;+            return serialize(topic, data);&lt;br/&gt;
+        }&lt;br/&gt;
+    }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/state/KeyValueStoreTestDriver.java b/streams/src/test/java/org/apache/kafka/streams/state/KeyValueStoreTestDriver.java&lt;br/&gt;
index 699963395e9..096f792d78d 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/state/KeyValueStoreTestDriver.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/state/KeyValueStoreTestDriver.java&lt;br/&gt;
@@ -206,8 +206,8 @@ private KeyValueStoreTestDriver(final StateSerdes&amp;lt;K, V&amp;gt; serdes) {&lt;br/&gt;
                                       final Serializer&amp;lt;V1&amp;gt; valueSerializer) &lt;/p&gt;
{
                 // for byte arrays we need to wrap it for comparison
 
-                final K keyTest = serdes.keyFrom(keySerializer.serialize(topic, key));
-                final V valueTest = serdes.valueFrom(valueSerializer.serialize(topic, value));
+                final K keyTest = serdes.keyFrom(keySerializer.serialize(topic, headers, key));
+                final V valueTest = serdes.valueFrom(valueSerializer.serialize(topic, headers, value));
 
                 recordFlushed(keyTest, valueTest);
             }
&lt;p&gt;diff --git a/streams/src/test/java/org/apache/kafka/streams/state/internals/RocksDBWindowStoreTest.java b/streams/src/test/java/org/apache/kafka/streams/state/internals/RocksDBWindowStoreTest.java&lt;br/&gt;
index 08f019feffa..cd0f49a7372 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/state/internals/RocksDBWindowStoreTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/state/internals/RocksDBWindowStoreTest.java&lt;br/&gt;
@@ -96,8 +96,8 @@&lt;br/&gt;
                                   final Serializer&amp;lt;K1&amp;gt; keySerializer,&lt;br/&gt;
                                   final Serializer&amp;lt;V1&amp;gt; valueSerializer) &lt;/p&gt;
{
             changeLog.add(new KeyValue&amp;lt;&amp;gt;(
-                keySerializer.serialize(topic, key),
-                valueSerializer.serialize(topic, value))
+                keySerializer.serialize(topic, headers, key),
+                valueSerializer.serialize(topic, headers, value))
             );
         }
&lt;p&gt;     };&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/test/MockRestoreConsumer.java b/streams/src/test/java/org/apache/kafka/test/MockRestoreConsumer.java&lt;br/&gt;
index bc918ea1b2b..244b35f1465 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/test/MockRestoreConsumer.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/test/MockRestoreConsumer.java&lt;br/&gt;
@@ -61,8 +61,9 @@ public void bufferRecord(final ConsumerRecord&amp;lt;K, V&amp;gt; record) {&lt;br/&gt;
         recordBuffer.add(&lt;br/&gt;
             new ConsumerRecord&amp;lt;&amp;gt;(record.topic(), record.partition(), record.offset(), record.timestamp(),&lt;br/&gt;
                                  record.timestampType(), 0L, 0, 0,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;keySerializer.serialize(record.topic(), record.key()),&lt;/li&gt;
	&lt;li&gt;valueSerializer.serialize(record.topic(), record.value())));&lt;br/&gt;
+                                 keySerializer.serialize(record.topic(), record.headers(), record.key()),&lt;br/&gt;
+                                 valueSerializer.serialize(record.topic(), record.headers(), record.value()),&lt;br/&gt;
+                                 record.headers()));&lt;br/&gt;
         endOffset = record.offset();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         super.updateEndOffsets(Collections.singletonMap(assignedPartition, endOffset));&lt;br/&gt;
diff --git a/streams/test-utils/src/main/java/org/apache/kafka/streams/test/ConsumerRecordFactory.java b/streams/test-utils/src/main/java/org/apache/kafka/streams/test/ConsumerRecordFactory.java&lt;br/&gt;
index 108dafdfdba..87ec7c1fcc3 100644&lt;br/&gt;
&amp;#8212; a/streams/test-utils/src/main/java/org/apache/kafka/streams/test/ConsumerRecordFactory.java&lt;br/&gt;
+++ b/streams/test-utils/src/main/java/org/apache/kafka/streams/test/ConsumerRecordFactory.java&lt;br/&gt;
@@ -180,8 +180,8 @@ public void advanceTimeMs(final long advanceMs) {&lt;br/&gt;
                                                  final long timestampMs) {&lt;br/&gt;
         Objects.requireNonNull(topicName, &quot;topicName cannot be null.&quot;);&lt;br/&gt;
         Objects.requireNonNull(headers, &quot;headers cannot be null.&quot;);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final byte[] serializedKey = keySerializer.serialize(topicName, key);&lt;/li&gt;
	&lt;li&gt;final byte[] serializedValue = valueSerializer.serialize(topicName, value);&lt;br/&gt;
+        final byte[] serializedKey = keySerializer.serialize(topicName, headers, key);&lt;br/&gt;
+        final byte[] serializedValue = valueSerializer.serialize(topicName, headers, value);&lt;br/&gt;
         return new ConsumerRecord&amp;lt;&amp;gt;(&lt;br/&gt;
             topicName,&lt;br/&gt;
             -1,&lt;/li&gt;
&lt;/ul&gt;





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 5 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3yv9r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>