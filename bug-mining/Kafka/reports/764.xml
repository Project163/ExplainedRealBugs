<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:44:38 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-1387] Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of time</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-1387</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Kafka broker re-registers itself in zookeeper every time handleNewSession() callback is invoked.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/kafka/blob/0.8.1/core/src/main/scala/kafka/server/KafkaHealthcheck.scala&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/0.8.1/core/src/main/scala/kafka/server/KafkaHealthcheck.scala&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;Now imagine the following sequence of events.&lt;br/&gt;
1) Zookeeper session reestablishes. handleNewSession() callback is queued by the zkClient, but not invoked yet.&lt;br/&gt;
2) Zookeeper session reestablishes again, queueing callback second time.&lt;br/&gt;
3) First callback is invoked, creating /broker/&lt;span class=&quot;error&quot;&gt;&amp;#91;id&amp;#93;&lt;/span&gt; ephemeral path.&lt;br/&gt;
4) Second callback is invoked and it tries to create /broker/&lt;span class=&quot;error&quot;&gt;&amp;#91;id&amp;#93;&lt;/span&gt; path using createEphemeralPathExpectConflictHandleZKBug() function. But the path is already exists, so createEphemeralPathExpectConflictHandleZKBug() is getting stuck in the infinite loop.&lt;/p&gt;

&lt;p&gt;Seems like controller election code have the same issue.&lt;/p&gt;

&lt;p&gt;I&apos;am able to reproduce this issue on the 0.8.1 branch from github using the following configs.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;zookeeper&lt;br/&gt;
tickTime=10&lt;br/&gt;
dataDir=/tmp/zk/&lt;br/&gt;
clientPort=2101&lt;br/&gt;
maxClientCnxns=0&lt;/li&gt;
&lt;/ol&gt;


&lt;ol&gt;
	&lt;li&gt;kafka&lt;br/&gt;
broker.id=1&lt;br/&gt;
log.dir=/tmp/kafka&lt;br/&gt;
zookeeper.connect=localhost:2101&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;zookeeper.connection.timeout.ms=100&lt;br/&gt;
zookeeper.sessiontimeout.ms=100&lt;/p&gt;

&lt;p&gt;Just start kafka and zookeeper and then pause zookeeper several times using Ctrl-Z.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12707778">KAFKA-1387</key>
            <summary>Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of time</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="fpj">Flavio Paiva Junqueira</assignee>
                                    <reporter username="slon">Fedor Korotkiy</reporter>
                        <labels>
                            <label>newbie</label>
                            <label>patch</label>
                            <label>zkclient-problems</label>
                    </labels>
                <created>Thu, 10 Apr 2014 19:48:32 +0000</created>
                <updated>Thu, 24 Sep 2015 17:15:20 +0000</updated>
                            <resolved>Thu, 24 Sep 2015 17:15:20 +0000</resolved>
                                    <version>0.8.1.1</version>
                                    <fixVersion>0.9.0.0</fixVersion>
                                        <due></due>
                            <votes>12</votes>
                                    <watches>32</watches>
                                                                                                                <comments>
                            <comment id="13966664" author="guozhang" created="Fri, 11 Apr 2014 15:45:48 +0000"  >&lt;p&gt;Hi Fedor, do you think this is caused by the same issue described in &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1382&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/KAFKA-1382&lt;/a&gt; ?&lt;/p&gt;</comment>
                            <comment id="13967841" author="slon" created="Sun, 13 Apr 2014 14:14:24 +0000"  >&lt;p&gt;I think it&apos;s a different issue.&lt;/p&gt;</comment>
                            <comment id="13967928" author="guozhang" created="Sun, 13 Apr 2014 19:54:51 +0000"  >&lt;p&gt;I think the main issue here is when there is a zookeeper session timeout, the zkClient will re-try write the data which could be already committed to ZK and failed. This issue is the same as the one causing &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1382&quot; title=&quot;Update zkVersion on partition state update failures&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1382&quot;&gt;&lt;del&gt;KAFKA-1382&lt;/del&gt;&lt;/a&gt;. But I think their fixes would be different.&lt;/p&gt;</comment>
                            <comment id="14085792" author="joestein" created="Tue, 5 Aug 2014 04:40:37 +0000"  >&lt;p&gt;Here is another way to reproduce this issue.  I have seen it a few times now with folks getting going with their clusters.&lt;/p&gt;

&lt;p&gt;steps to reproduce.  install a 3 node zk ensemble with 3 brokers cluster&lt;/p&gt;

&lt;p&gt;e.g. &lt;/p&gt;

&lt;p&gt;git clone &lt;a href=&quot;https://github.com/stealthly/scala-kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/stealthly/scala-kafka&lt;/a&gt;&lt;br/&gt;
git checkout -b zkbk3 origin/zkbk3&lt;br/&gt;
vagrant up provider=virtualbox&lt;/p&gt;

&lt;p&gt;now setup each node in the cluster as you would broker 1,2,3 and the ensemble&lt;/p&gt;

&lt;p&gt;e.g.&lt;/p&gt;

&lt;p&gt;vagrant ssh zkbkOne&lt;br/&gt;
sudo su&lt;br/&gt;
cd /vagrant/vagrant/ &amp;amp;&amp;amp; ./up.sh&lt;br/&gt;
vagrant ssh zkbkTwo&lt;br/&gt;
sudo su&lt;br/&gt;
cd /vagrant/vagrant/ &amp;amp;&amp;amp; ./up.sh&lt;br/&gt;
vagrant ssh zkbkThree&lt;br/&gt;
sudo su&lt;br/&gt;
cd /vagrant/vagrant/ &amp;amp;&amp;amp; ./up.sh&lt;/p&gt;

&lt;p&gt;start up zookeeper on all 3 nodes&lt;br/&gt;
cd /opt/apache/kafka &amp;amp;&amp;amp; bin/zookeeper-server-start.sh config/zookeeper.properties 1&amp;gt;&amp;gt;/tmp/zk.log 2&amp;gt;&amp;gt;/tmp/zk.log &amp;amp;&lt;/p&gt;

&lt;p&gt;now, start up broker on node 2 only&lt;br/&gt;
cd /opt/apache/kafka &amp;amp;&amp;amp; bin/kafka-server-start.sh config/server.properties 1&amp;gt;&amp;gt;/tmp/bk.log 2&amp;gt;&amp;gt;/tmp/bk.log &amp;amp;&lt;/p&gt;

&lt;p&gt;ok, now here is where it gets wonky&lt;/p&gt;

&lt;p&gt;on server 3 change from broker.id=3 to broker.id=2 &lt;br/&gt;
now you need to start up server 1 and 3 (even though it is broker.id=2) at the same time&lt;/p&gt;

&lt;p&gt;cd /opt/apache/kafka &amp;amp;&amp;amp; bin/kafka-server-start.sh config/server.properties 1&amp;gt;&amp;gt;/tmp/bk.log 2&amp;gt;&amp;gt;/tmp/bk.log &amp;amp;&lt;br/&gt;
cd /opt/apache/kafka &amp;amp;&amp;amp; bin/kafka-server-start.sh config/server.properties 1&amp;gt;&amp;gt;/tmp/bk.log 2&amp;gt;&amp;gt;/tmp/bk.log &amp;amp;&lt;br/&gt;
( you can have two tabs, hit enter in one switch to other tab and hit enter is close enough to same time)&lt;/p&gt;

&lt;p&gt;and you get this looping forever&lt;/p&gt;

&lt;p&gt;2014-08-05 04:34:38,591] INFO I wrote this conflicted ephemeral node [&lt;/p&gt;
{&quot;version&quot;:1,&quot;brokerid&quot;:2,&quot;timestamp&quot;:&quot;1407212148186&quot;}
&lt;p&gt;] at /controller a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2014-08-05 04:34:44,598&amp;#93;&lt;/span&gt; INFO conflict in /controller data: &lt;/p&gt;
{&quot;version&quot;:1,&quot;brokerid&quot;:2,&quot;timestamp&quot;:&quot;1407212148186&quot;}
&lt;p&gt; stored data: &lt;/p&gt;
{&quot;version&quot;:1,&quot;brokerid&quot;:2,&quot;timestamp&quot;:&quot;1407211911014&quot;}
&lt;p&gt; (kafka.utils.ZkUtils$)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2014-08-05 04:34:44,601&amp;#93;&lt;/span&gt; INFO I wrote this conflicted ephemeral node [&lt;/p&gt;
{&quot;version&quot;:1,&quot;brokerid&quot;:2,&quot;timestamp&quot;:&quot;1407212148186&quot;}
&lt;p&gt;] at /controller a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2014-08-05 04:34:50,610&amp;#93;&lt;/span&gt; INFO conflict in /controller data: &lt;/p&gt;
{&quot;version&quot;:1,&quot;brokerid&quot;:2,&quot;timestamp&quot;:&quot;1407212148186&quot;}
&lt;p&gt; stored data: &lt;/p&gt;
{&quot;version&quot;:1,&quot;brokerid&quot;:2,&quot;timestamp&quot;:&quot;1407211911014&quot;}
&lt;p&gt; (kafka.utils.ZkUtils$)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2014-08-05 04:34:50,614&amp;#93;&lt;/span&gt; INFO I wrote this conflicted ephemeral node [&lt;/p&gt;
{&quot;version&quot;:1,&quot;brokerid&quot;:2,&quot;timestamp&quot;:&quot;1407212148186&quot;}
&lt;p&gt;] at /controller a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2014-08-05 04:34:56,621&amp;#93;&lt;/span&gt; INFO conflict in /controller data: &lt;/p&gt;
{&quot;version&quot;:1,&quot;brokerid&quot;:2,&quot;timestamp&quot;:&quot;1407212148186&quot;}
&lt;p&gt; stored data: &lt;/p&gt;
{&quot;version&quot;:1,&quot;brokerid&quot;:2,&quot;timestamp&quot;:&quot;1407211911014&quot;}
&lt;p&gt; (kafka.utils.ZkUtils$)&lt;/p&gt;

&lt;p&gt;the expected result that you get should be&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;2014-08-05 04:07:20,917&amp;#93;&lt;/span&gt; INFO conflict in /brokers/ids/2 data: &lt;/p&gt;
{&quot;jmx_port&quot;:-1,&quot;timestamp&quot;:&quot;1407211640900&quot;,&quot;host&quot;:&quot;192.168.30.3&quot;,&quot;version&quot;:1,&quot;port&quot;:9092}
&lt;p&gt; stored data: &lt;/p&gt;
{&quot;jmx_port&quot;:-1,&quot;timestamp&quot;:&quot;140721119
9464&quot;,&quot;host&quot;:&quot;192.168.30.2&quot;,&quot;version&quot;:1,&quot;port&quot;:9092}
&lt;p&gt; (kafka.utils.ZkUtils$)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2014-08-05 04:07:20,949&amp;#93;&lt;/span&gt; FATAL Fatal error during KafkaServerStable startup. Prepare to shutdown (kafka.server.KafkaServerStartable)&lt;br/&gt;
java.lang.RuntimeException: A broker is already registered on the path /brokers/ids/2. This probably indicates that you either have configured a brokerid that is already in use, or else you have shutdown &lt;br/&gt;
this broker and restarted it faster than the zookeeper timeout so it appears to be re-registering.&lt;br/&gt;
        at kafka.utils.ZkUtils$.registerBrokerInZk(ZkUtils.scala:205)&lt;br/&gt;
        at kafka.server.KafkaHealthcheck.register(KafkaHealthcheck.scala:57)&lt;br/&gt;
        at kafka.server.KafkaHealthcheck.startup(KafkaHealthcheck.scala:44)&lt;br/&gt;
        at kafka.server.KafkaServer.startup(KafkaServer.scala:103)&lt;br/&gt;
        at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:34)&lt;br/&gt;
        at kafka.Kafka$.main(Kafka.scala:46)&lt;br/&gt;
        at kafka.Kafka.main(Kafka.scala)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2014-08-05 04:07:20,952&amp;#93;&lt;/span&gt; INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Kafka Server 2&amp;#93;&lt;/span&gt;, shutting down (kafka.server.KafkaServer)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2014-08-05 04:07:20,954&amp;#93;&lt;/span&gt; INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Socket Server on Broker 2&amp;#93;&lt;/span&gt;, Shutting down (kafka.network.SocketServer)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2014-08-05 04:07:20,959&amp;#93;&lt;/span&gt; INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Socket Server on Broker 2&amp;#93;&lt;/span&gt;, Shutdown completed (kafka.network.SocketServer)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2014-08-05 04:07:20,960&amp;#93;&lt;/span&gt; INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Kafka Request Handler on Broker 2&amp;#93;&lt;/span&gt;, shutting down (kafka.server.KafkaRequestHandlerPool)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2014-08-05 04:07:20,992&amp;#93;&lt;/span&gt; INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Kafka Request Handler on Broker 2&amp;#93;&lt;/span&gt;, shut down completely (kafka.server.KafkaRequestHandlerPool)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2014-08-05 04:07:21,263&amp;#93;&lt;/span&gt; INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Replica Manager on Broker 2&amp;#93;&lt;/span&gt;: Shut down (kafka.server.ReplicaManager)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2014-08-05 04:07:21,263&amp;#93;&lt;/span&gt; INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;ReplicaFetcherManager on broker 2&amp;#93;&lt;/span&gt; shutting down (kafka.server.ReplicaFetcherManager)&lt;/p&gt;

&lt;p&gt;which is what you get if you just start server 3 on its one configured with broker.id=2&lt;/p&gt;

&lt;p&gt;I originally saw this on a 12 node AWS cluster same kafka 0.8.1.1 zk 3.3.4&lt;/p&gt;

&lt;p&gt;I don&apos;t know how very critical this is, someone just brought up something similar but with /brokers/ids/x I don&apos;t know if they are related but something wonky is going on with the ZkUtils.createEphemeralPathExpectConflictHandleZKBug code paths.&lt;/p&gt;

</comment>
                            <comment id="14086398" author="junrao" created="Tue, 5 Aug 2014 15:48:05 +0000"  >&lt;p&gt;Joe,&lt;/p&gt;

&lt;p&gt;The issue that you described is probably fixed in &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1451&quot; title=&quot;Broker stuck due to leader election race &quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1451&quot;&gt;&lt;del&gt;KAFKA-1451&lt;/del&gt;&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="14087063" author="joestein" created="Wed, 6 Aug 2014 01:08:39 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt; I tested on trunk and it is much worse now.&lt;/p&gt;

&lt;p&gt;instead of looping on the /controller node (like it was before) ... node 3 actually overwrote/stole the /brokers/ids/2 (doing a get before had it as 192.168.30.1 and after it is 192.168.30.3)&lt;/p&gt;

&lt;p&gt;so now i have a situation where I have two running broker servers, each with the same broker id running (2), server 3 is the (&quot;active&quot;) broker with all the topics being created on it and failing requests for producing and consuming (because all the data is on server 2 but that is not advertised).... and server 2 is still the controller handling preferred leader election, etc.&lt;/p&gt;

&lt;p&gt;what is weird is broker.id = 2 was running already.  I started up broker.id=1 and another broker.id=2 at the same time&lt;/p&gt;


</comment>
                            <comment id="14088474" author="gwenshap" created="Wed, 6 Aug 2014 23:44:28 +0000"  >&lt;p&gt;Attempted to reproduce with trunk as well.&lt;/p&gt;

&lt;p&gt;I&apos;m not seeing the same behavior as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=joestein&quot; class=&quot;user-hover&quot; rel=&quot;joestein&quot;&gt;joestein&lt;/a&gt;. &lt;br/&gt;
In my experiment the new broker 2 fails with the correct error message. The old broker 2, OTOH, goes into a loop, printing:&lt;br/&gt;
&quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;2014-08-06 16:37:01,884&amp;#93;&lt;/span&gt; INFO Partition &lt;span class=&quot;error&quot;&gt;&amp;#91;test1,0&amp;#93;&lt;/span&gt; on broker 2: Cached zkVersion &lt;span class=&quot;error&quot;&gt;&amp;#91;89&amp;#93;&lt;/span&gt; not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)&quot;&lt;/p&gt;

&lt;p&gt;Not a good behavior either. &lt;/p&gt;</comment>
                            <comment id="14092255" author="junrao" created="Sun, 10 Aug 2014 22:48:31 +0000"  >&lt;p&gt;Hmm, this seems really weird. Not sure why starting two brokers at the same time will affect the ZK registration. Is this reproducible by running multiple brokers on the same machine?&lt;/p&gt;</comment>
                            <comment id="14150883" author="jwlent55" created="Sun, 28 Sep 2014 02:19:00 +0000"  >&lt;p&gt;I have seen the issue reported in the original problem description in our QA environment (3 ZooKeeper, 3 Kafka and several application specific nodes) several times now.  I have not tested any configurations where 2 nodes try to claim the same broker id.  The problem is triggered when the system is under stress (high I/O and CPU load) and the ZooKeeper connections become unstable.  When this happens Kafka threads can get stuck trying to register Brokers nodes and Application threads get stuck trying to register Consumer nodes. One way to recover is to restart the impacted nodes.  As an experiment I aslo tried deleting the blocking ZooKeeper nodes (hours later when the system was under no stress).  When I did so the createEphemeralPathExpectConflictHandleZKBug would finally complete processing the current Expire message (i.e. add the node), break out of its loop, but, then immediately reenter the loop when it tired to process the next expire message.  The few times I tested this approach I had to delete the node dozens of times before the problem would clear itself - in other words there were dozens of Expire messages wating to be processed. Obvoisuly I am looking into this issue from a configuration point of view (avoid the unstable connection issue), but, this Kafka error behavior concerns me.&lt;/p&gt;

&lt;p&gt;I have reproduced it (somewhat artificially) in a dev environment as follows:&lt;/p&gt;

&lt;p&gt;1) Start one ZooKeeper and one Kafka node.&lt;br/&gt;
2) Set a thread breakpoint in KafkaHealthCheck.java. &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;    def handleNewSession() {
      info(&quot;re-registering broker info in ZK for broker &quot; + brokerId)
--&amp;gt;   register()
      info(&quot;done re-registering broker&quot;)
      info(&quot;Subscribing to %s path to watch for new topics&quot;.format(ZkUtils.BrokerTopicsPath))
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;3) Pause Kafka.&lt;br/&gt;
4) Wait for ZooKeeper to expire the first session and drop the ephemeral node.&lt;br/&gt;
5) Unpause Kafka.&lt;br/&gt;
6) Kafka reconnects with ZooKeeper, receives an Expire, and establishes a second session.&lt;br/&gt;
7) Breakpoint hit and event thread paused before handling the first Expire.&lt;br/&gt;
8) Pause Kafka again.&lt;br/&gt;
9) Wait for ZooKeeper to expire the second session and delete the ephemeral node (again).&lt;br/&gt;
10) Remove breakpoint, unpause Kafka, and finally release the event thread.&lt;br/&gt;
11) Kafka reconnects with ZooKeeper, receives a second Expire, and establishes a third session.&lt;br/&gt;
12) Kafka registers an ephemeral triggered by the first expire (which triggerd the second session), but, ZooKeeper associates it with the third Session. &lt;br/&gt;
13) Kafka tries to register an an ephemeral triggered by the second expire, but, ZooKeeper already has a stable node.&lt;br/&gt;
14) Kafka assumes this node will go away soon, sleeps, and then retries.&lt;br/&gt;
15) The node is associcated with a valid session and threfore does not go away so Kafka remains stuck in the retry loop.&lt;/p&gt;

&lt;p&gt;I have tested this with the latest code in trunk and noted the same behavior (the code looks pretty similar).&lt;/p&gt;

&lt;p&gt;I have coded up a potential 0.8.1.1 patch for this issue based on the following principles:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Ensure that when the node starts stale nodes are removed in main
	&lt;ul&gt;
		&lt;li&gt;For Brokers this means remove nodes with the same host name and port otherwise fail to start (the existing checker logic)&lt;/li&gt;
		&lt;li&gt;For Consumer nodes don&apos;t worry about stale nodes - the way they are named should prevent this from ever happening.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;In main add the initial node which should now always work with no looping required - direct call to createEphemeralPath&lt;/li&gt;
	&lt;li&gt;Create a EphemeralNodeMonitor class that contains:
	&lt;ul&gt;
		&lt;li&gt;IZkDataListener&lt;/li&gt;
		&lt;li&gt;IZkStateListener&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;The users of this class provide a path to monitor and a closure that defines what to do when the node is not found&lt;/li&gt;
	&lt;li&gt;When the state listener is notifed about a new session it checks to see if the node is already gone:
	&lt;ul&gt;
		&lt;li&gt;Yes, call the provided function&lt;/li&gt;
		&lt;li&gt;No, ignore the event&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;When the data listener is notified of a deletion it does the same thing&lt;/li&gt;
	&lt;li&gt;Both the Broker and Comsumer registation use this new class in the same way they curently use their individual state listeners.  There only change in behavior is to call createEphemeralPath directly (and avoid the looping code).&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Since all this work should be done in the event thread I don&apos;t think there are any race conditions and no other nodes should be adding these nodes (or we have a serious configuration issue that should have been detected at startup).&lt;/p&gt;

&lt;p&gt;One assumption is that we will always recieve at least one more event (expire and/or delete) after the node is really deleted by ZooKeeper.  I think that is a valid assumption (ZooKeeper can&apos;t send the delete until the node is gone).  If the node was present when when we process the final Expire message then we should get notified of a delete if that node was actually related to a previous session.  I wonder if we could get away with just monitoring node deletions, but, that seems risky.  The only change in behavior should be that if the expire is recieved before the node is actually deleted then event loop is not blocked and could process other messages while waiting for the delete event.&lt;/p&gt;

&lt;p&gt;Note: I have not touched the leader election / contoller node code (the third user of the createEphemeralPathExpectConflictHandleZKBug code).  That still uses the looping code.  I did apply the &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1451&quot; title=&quot;Broker stuck due to leader election race &quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1451&quot;&gt;&lt;del&gt;KAFKA-1451&lt;/del&gt;&lt;/a&gt; patch to our 0.8.1.1 build.&lt;/p&gt;

&lt;p&gt;If there is any interest in the code I can provide a patch of what I have so far.  I would very much like to get feedback.  I was not sure of the protocol for submitting patches for comment.&lt;/p&gt;

</comment>
                            <comment id="14151260" author="junrao" created="Sun, 28 Sep 2014 23:23:50 +0000"  >&lt;p&gt;James,&lt;/p&gt;

&lt;p&gt;Thanks for reporting this. Yes, what you discovered is a real problem. The fix is going to be tricky though. The issue is the following. When a client lose an ephemeral node in ZK due to session expiration, that ephemeral node is not removed exactly at expiration time, but a short time after (&lt;a href=&quot;https://issues.apache.org/jira/browse/ZOOKEEPER-1740&quot; title=&quot;Zookeeper 3.3.4 loses ephemeral nodes under stress&quot; class=&quot;issue-link&quot; data-issue-key=&quot;ZOOKEEPER-1740&quot;&gt;&lt;del&gt;ZOOKEEPER-1740&lt;/del&gt;&lt;/a&gt;). When the client tries to recreate the ephemeral node and get a NodeExistException, one of the two things could happen: (1) the existing node is from the expired session and is on its way to be deleted, (2) the node is actually created on the latest session (The reason is what you discovered:  the client gets multiple handleNewSession() calls due to multiple session expiration events, but the node is created on the latest session). I am not sure if there is an easy way to distinguish the two cases though.&lt;/p&gt;

&lt;p&gt;Overall, it seems to me that there are so many corner cases that one has to deal with during ZK session expiration. The simplest approach is probably to prevent session expiration from happening at all (e.g., set a larger session timeout).&lt;/p&gt;</comment>
                            <comment id="14151264" author="gwenshap" created="Sun, 28 Sep 2014 23:41:30 +0000"  >&lt;p&gt;AFAIK the ZK bug was never reproduced in newer versions of ZK. I&apos;m wondering if at some point we can say that ZK 3.3 is no longer supported and remove the work-around (which is creating few issues of its own).&lt;/p&gt;</comment>
                            <comment id="14151266" author="junrao" created="Sun, 28 Sep 2014 23:48:25 +0000"  >&lt;p&gt;Gwen,&lt;/p&gt;

&lt;p&gt;From &lt;a href=&quot;https://issues.apache.org/jira/browse/ZOOKEEPER-1809&quot; title=&quot;ephemeral node not deleted (or recreated?) after session expiry&quot; class=&quot;issue-link&quot; data-issue-key=&quot;ZOOKEEPER-1809&quot;&gt;&lt;del&gt;ZOOKEEPER-1809&lt;/del&gt;&lt;/a&gt;, it seems the design of not deleting ephemeral node immediately on session expiration still exists on ZK 3.4.x and beyond?&lt;/p&gt;</comment>
                            <comment id="14151275" author="gwenshap" created="Mon, 29 Sep 2014 00:33:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/ZOOKEEPER-1809&quot; title=&quot;ephemeral node not deleted (or recreated?) after session expiry&quot; class=&quot;issue-link&quot; data-issue-key=&quot;ZOOKEEPER-1809&quot;&gt;&lt;del&gt;ZOOKEEPER-1809&lt;/del&gt;&lt;/a&gt; was closed because the re-creation of the issue was buggy (the test app was actually creating two sessions at same time). &lt;/p&gt;

&lt;p&gt;I agree that Flavio indicated that ZNodes can hang around after expiration, but he also indicated the opposite in the email thread for &lt;a href=&quot;https://issues.apache.org/jira/browse/ZOOKEEPER-1740&quot; title=&quot;Zookeeper 3.3.4 loses ephemeral nodes under stress&quot; class=&quot;issue-link&quot; data-issue-key=&quot;ZOOKEEPER-1740&quot;&gt;&lt;del&gt;ZOOKEEPER-1740&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Its important to get this right, so I&apos;ll do more research on the expected ZooKeeper behavior here.&lt;/p&gt;

&lt;p&gt;One thing I&apos;m not sure about is why does createEphemeralPathExpectConflictHandleZKBug loop indefinitely? &lt;br/&gt;
If ZK indeed takes a bit of extra time to clean up, we can loop for specific amount of time (number of retries), like Curator typically does. After few seconds, the probability that the ZNode belongs to an active session and not an expired one is very high.&lt;/p&gt;</comment>
                            <comment id="14151663" author="jwlent55" created="Mon, 29 Sep 2014 13:11:39 +0000"  >&lt;p&gt;As background we are using ZooKeeper 3.4.5.&lt;/p&gt;

&lt;p&gt;When trying to come up with a fix for this I did consider limiting the loop to 2 to 3 tries.  My concerns with this approach were:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Slow to recover if there are lots of Expire messages to process and each of these could trigger redundant rebalance events until you get to the last one.&lt;/li&gt;
	&lt;li&gt;What happens if you don&apos;t loop quite long enough?  You are again stuck in a bad state when the ephemeral does go away.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;I also considered trying to access the Session Id and storing that value instead of (or in addition to) the timestamp in the node&apos;s data.  That appraoch looked difficult to implement, error prone, and had the application doing what I would consider ZooKeeper work.&lt;/p&gt;

&lt;p&gt;I agree there are a lot of corner cases to consider, but, I think we are going to pursue the approach I outlined above.  I would be happy to post the proposed solution for your review, but, again I am not sure about the protocol around patch submission.  I would not want this to be mistaken by someone as any kind of offical patch without a lot more review.&lt;/p&gt;

&lt;p&gt;When working on this appraoch I looked at the curator PersistentEphemeralNode for ideas:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/bazaarvoice/curator-extensions/blob/master/recipes/src/main/java/com/bazaarvoice/curator/recipes/PersistentEphemeralNode.java&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/bazaarvoice/curator-extensions/blob/master/recipes/src/main/java/com/bazaarvoice/curator/recipes/PersistentEphemeralNode.java&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is curator based so does not directly apply to Kafka (yet), but, it also keys off nodeDelete to restore the node.&lt;/p&gt;

&lt;p&gt;In the end I went with the simple idea that:&lt;/p&gt;

&lt;p&gt;&quot;If when we process an Expire event the node still exists then ZooKeeper will inform us if that node later goes away.&quot;&lt;/p&gt;

&lt;p&gt;If we can&apos;t trust ZooKeeper/ZkClient to do that then ...&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;  class StateListener() extends IZkStateListener {

    def handleStateChanged(state: KeeperState) {}

    def handleNewSession() {
      if (zkClient.exists(path)) {
        info(&quot;New session started, but, ephemeral %s already/still exists&quot;.format(path))
      }
      else {
        info(&quot;New session started, recreate ephemeral node %s&quot;.format(path))
        recreateNode()
      }
    }
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14151673" author="jwlent55" created="Mon, 29 Sep 2014 13:20:08 +0000"  >&lt;p&gt;In case anyone is interested in the complete code for the new class I am testing with:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;class EphemeralNodeMonitor(zkClient: ZkClient, path: String, recreateNode: () =&amp;gt; Unit) extends Logging {

  val dataListener = new DataListener()
  val stateListener = new StateListener()
  
  def start() {
    zkClient.subscribeStateChanges(stateListener)
    zkClient.subscribeDataChanges(path, dataListener)
  }
  
  def close() {
    zkClient.unsubscribeStateChanges(stateListener)
    zkClient.unsubscribeDataChanges(path, dataListener)
  }

  class DataListener() extends IZkDataListener {
    
    var oldData: scala.Any = null

    def handleDataChange(dataPath: String, newData: scala.Any) {
      if (newData != oldData) {
        oldData = newData
        info(&quot;Ephemeral node %s has new data [%s]&quot;.format(dataPath, newData))
      }
    }

    def handleDataDeleted(dataPath: String) {
      if (zkClient.exists(path)) {
        info(&quot;Ephemeral node %s was deleted, but, has already been recreated&quot;.format(dataPath))
      }
      else {
        info(&quot;Ephemeral node %s was deleted, recreate it&quot;.format(dataPath))
        recreateNode()
      }
    }
  }

  class StateListener() extends IZkStateListener {

    def handleStateChanged(state: KeeperState) {}

    def handleNewSession() {
      if (zkClient.exists(path)) {
        info(&quot;New session started, but, ephemeral %s already/still exists&quot;.format(path))
      }
      else {
        info(&quot;New session started, recreate ephemeral node %s&quot;.format(path))
        recreateNode()
      }
    }
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14151873" author="junrao" created="Mon, 29 Sep 2014 16:35:07 +0000"  >&lt;p&gt;James,&lt;/p&gt;

&lt;p&gt;Contributing code to Kafka is pretty simple. You just need to attach a patch to the jira.&lt;/p&gt;

&lt;p&gt;As for your solution, we probably need to verify the following: will a watcher fire if it&apos;s registered on a path created by an already expired session and the path will be deleted soon.&lt;/p&gt;</comment>
                            <comment id="14152337" author="jwlent55" created="Mon, 29 Sep 2014 21:37:32 +0000"  >&lt;p&gt;I aplogize in advance for my ignorance, but, I have one newbie question.  My starting point is the 0.8.1.1 tag (really the 0.8.1.1 source distribution).  Would it be OK for me to submit a patch against that baseline or would it be better for me to first merge the code to trunk and then create the patch?&lt;/p&gt;</comment>
                            <comment id="14152453" author="jwlent55" created="Mon, 29 Sep 2014 22:43:52 +0000"  >&lt;p&gt;As for your question (which I agree is one of the key questions) I have the following comments:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;The ZooKeeper documentation states there is one case where a watch may be missed which I do not think applies to the situation I am trying to address:&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&quot;Watches are maintained locally at the ZooKeeper server to which the client is connected. This allows watches to be lightweight to set, maintain, and dispatch. When a client connects to a new server, the watch will be triggered for any session events. Watches will not be received while disconnected from a server. When a client reconnects, any previously registered watches will be reregistered and triggered if needed. In general this all occurs transparently. There is one case where a watch may be missed: a watch for the existence of a znode not yet created will be missed if the znode is created and deleted while disconnected.&quot;&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;In my testing the node is normally gone by the time the New Session event is handled which recreates the node. In that case I do not see a Delete message (I log that arrival of a delete event even if the node is already gone):&lt;/li&gt;
&lt;/ul&gt;


&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[2014-09-29 18:23:43,071] INFO zookeeper state changed (Expired) (org.I0Itec.zkclient.ZkClient)
[2014-09-29 18:23:43,071] INFO Unable to reconnect to ZooKeeper service, session 0x148c36a0a94000f has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2014-09-29 18:23:43,071] INFO Initiating client connection, connectString=localhost:2181/kafka/0.8 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@56404645 (org.apache.zookeeper.ZooKeeper)
[2014-09-29 18:23:43,072] INFO Opening socket connection to server localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2014-09-29 18:23:43,073] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2014-09-29 18:23:43,074] INFO EventThread shut down (org.apache.zookeeper.ClientCnxn)
[2014-09-29 18:23:43,082] INFO Closing socket connection to /10.210.10.165. (kafka.network.Processor)
[2014-09-29 18:23:43,087] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x148c36a0a940010, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2014-09-29 18:23:43,087] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2014-09-29 18:23:43,099] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2014-09-29 18:23:43,143] INFO New session started, recreate ephemeral node /brokers/ids/0 (kafka.utils.EphemeralNodeMonitor)
[2014-09-29 18:23:43,144] INFO Start registering broker 0 in ZooKeeper (kafka.server.KafkaHealthcheck)
[2014-09-29 18:23:43,161] INFO Registered broker 0 at path /brokers/ids/0 with address jlent.digitalsmiths.com:9092. (kafka.utils.ZkUtils$)
[2014-09-29 18:23:43,218] INFO Ephemeral node /brokers/ids/0 has new data [{&quot;jmx_port&quot;:10001,&quot;timestamp&quot;:&quot;1412029423148&quot;,&quot;host&quot;:&quot;jlent.digitalsmiths.com&quot;,&quot;version&quot;:1,&quot;port&quot;:9092}] (kafka.utils.EphemeralNodeMonitor)
[2014-09-29 18:23:43,237] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
	&lt;li&gt;I have seen cases where the node is still present when the New Session is handled and in that case I do see a Delete event a short while later.  I don&apos;t have the logs that document that (don&apos;t ask me why I don&apos;t have logs to document the most important scenario).  I will try to recreate that situation.&lt;/li&gt;
	&lt;li&gt;As an alternative I modified the New Session handling code to do nothing (except log the arrival of the new session event).  In that case I do see the Delete event.  This could perhaps be viewed a more severe test.  In this case we get notified of a Delete that actually occured before we even handled the New Seesion event.  That was actually how I did some of my original testing.&lt;/li&gt;
&lt;/ul&gt;


&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[2014-09-29 18:14:31,414] INFO zookeeper state changed (Expired) (org.I0Itec.zkclient.ZkClient)
[2014-09-29 18:14:31,414] INFO Unable to reconnect to ZooKeeper service, session 0x148c36a0a94000c has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2014-09-29 18:14:31,414] INFO Initiating client connection, connectString=localhost:2181/kafka/0.8 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@15c58840 (org.apache.zookeeper.ZooKeeper)
[2014-09-29 18:14:31,414] INFO Opening socket connection to server localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2014-09-29 18:14:31,415] INFO EventThread shut down (org.apache.zookeeper.ClientCnxn)
[2014-09-29 18:14:31,415] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2014-09-29 18:14:31,420] INFO Closing socket connection to /10.210.10.165. (kafka.network.Processor)
[2014-09-29 18:14:31,459] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x148c36a0a94000d, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2014-09-29 18:14:31,459] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[2014-09-29 18:14:31,587] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2014-09-29 18:14:31,683] INFO New session started, DO NOT recreate ephemeral node /brokers/ids/0 (kafka.utils.EphemeralNodeMonitor)
[2014-09-29 18:14:31,701] INFO Ephemeral node /brokers/ids/0 was deleted, recreate it (kafka.utils.EphemeralNodeMonitor)
[2014-09-29 18:14:31,702] INFO Start registering broker 0 in ZooKeeper (kafka.server.KafkaHealthcheck)
[2014-09-29 18:14:31,722] INFO Registered broker 0 at path /brokers/ids/0 with address jlent.digitalsmiths.com:9092. (kafka.utils.ZkUtils$)
[2014-09-29 18:14:31,744] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2014-09-29 18:14:31,746] INFO Ephemeral node /brokers/ids/0 has new data [{&quot;jmx_port&quot;:10001,&quot;timestamp&quot;:&quot;1412028871704&quot;,&quot;host&quot;:&quot;jlent.digitalsmiths.com&quot;,&quot;version&quot;:1,&quot;port&quot;:9092}] (kafka.utils.EphemeralNodeMonitor)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14153336" author="jwlent55" created="Tue, 30 Sep 2014 16:16:54 +0000"  >&lt;p&gt;Here is what I have so far.  Comments welcomed.&lt;/p&gt;</comment>
                            <comment id="14153370" author="jwlent55" created="Tue, 30 Sep 2014 16:41:11 +0000"  >&lt;p&gt;I have messed things up.  I tried to use the Submit Patch option.  I filled out the fields in the form, but, it never asked me for a file.  I also specifed labels that I assumed were related to the patch, but, instead are associated with the issue itself.  I then directly attached the file to the issue.  That seemed to go OK.  Now the Submit Patch option is gone and the Status is Patch Available.  I don&apos;t think that is correct.  I decided it is best if I stop messing with the issue for now.  I have done enough damage.&lt;/p&gt;

&lt;p&gt;I apologize for my ignorance of the process.&lt;/p&gt;</comment>
                            <comment id="14156635" author="junrao" created="Thu, 2 Oct 2014 14:55:57 +0000"  >&lt;p&gt;James,&lt;/p&gt;

&lt;p&gt;For my question, could you ask the ZK mailing list and get your understanding confirmed by their developers? Thanks,&lt;/p&gt;</comment>
                            <comment id="14156746" author="jwlent55" created="Thu, 2 Oct 2014 16:53:12 +0000"  >&lt;p&gt;Good idea and done:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://mail-archives.apache.org/mod_mbox/zookeeper-user/201410.mbox/browser&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://mail-archives.apache.org/mod_mbox/zookeeper-user/201410.mbox/browser&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14323229" author="twbecker" created="Mon, 16 Feb 2015 20:11:13 +0000"  >&lt;p&gt;Can a project member comment on what it is going to take to get this patch accepted?  We have been running 0.8.1 with it for months, and I guess we&apos;ll have to apply it to 0.8.2 as well, but it would be nice to get it into the official tree...&lt;/p&gt;</comment>
                            <comment id="14516102" author="eggsby" created="Tue, 28 Apr 2015 01:07:49 +0000"  >&lt;p&gt;I am seeing similar behavior in my consumer, using kafka 0.8.2.1 and zookeeper 3.4.6&lt;/p&gt;

&lt;p&gt;In an infinite loop:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;15/04/27 17:44:31 INFO utils.ZkUtils$: conflict in /consumers/******************
15/04/27 17:44:31 INFO utils.ZkUtils$: I wrote &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; conflicted ephemeral node ************** a &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; back in a different session, hence I will backoff &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; node to be deleted by Zookeeper and retry
15/04/27 17:45:01 INFO INFO utils.ZkUtils$: conflict in /consumers/******************
15/04/27 17:45:01 INFO utils.ZkUtils$: I wrote &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; conflicted ephemeral node ************** a &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; back in a different session, hence I will backoff &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; node to be deleted by Zookeeper and retry
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14519189" author="marcusai" created="Wed, 29 Apr 2015 11:57:26 +0000"  >&lt;p&gt;I&apos;ve also encountered this issue running Kafka 0.8.2.0 and Zookeeper 3.4.6 in a three node cluster. The error occured after two zookeeper nodes got restarted at the same time. The error below repeatedly appeared in the Kafka logs. I resolved the issue by restarting Kafka.&lt;/p&gt;

&lt;div class=&quot;panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;panelContent&quot;&gt;
&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;2015-04-27 03:47:03,292&amp;#93;&lt;/span&gt; INFO I wrote this conflicted ephemeral node &lt;span class=&quot;error&quot;&gt;&amp;#91;&amp;quot;jmx_port&amp;quot;:-1,&amp;quot;timestamp&amp;quot;:&amp;quot;1430038275477&amp;quot;,&amp;quot;host&amp;quot;:&amp;quot;ams5mdppdmsbacmq01b.markit.partners&amp;quot;,&amp;quot;version&amp;quot;:1,&amp;quot;port&amp;quot;:9092&amp;#93;&lt;/span&gt; at /brokers/ids/2 a while back in a different session, hence I will backoff for this node to be deleted by Zookeeper and retry (kafka.utils.ZkUtils$)&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14520867" author="eggsby" created="Thu, 30 Apr 2015 05:02:35 +0000"  >&lt;p&gt;It looks like this &quot;infinite retry&quot; behavior is only in kafka to accomodate another strange issue where zookeeper was deleting ephemeral nodes out from under it:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/kafka/blob/0.8.2.1/core/src/main/scala/kafka/utils/ZkUtils.scala#L272&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/0.8.2.1/core/src/main/scala/kafka/utils/ZkUtils.scala#L272&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/ZOOKEEPER-1740&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/ZOOKEEPER-1740&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It seems the simplest thing to do would be to just delete the conflicted node and write the truth about the process environment it knows.&lt;/p&gt;

&lt;p&gt;I see that my issue appeared in the consumer code, where this issue is occurring in the kafka brokers themselves, but the bug appears to be the same:&lt;/p&gt;

&lt;p&gt;There are two exceptional cases in ephemeral nodes that I can see, either the &lt;a href=&quot;https://issues.apache.org/jira/browse/ZOOKEEPER-1740&quot; title=&quot;Zookeeper 3.3.4 loses ephemeral nodes under stress&quot; class=&quot;issue-link&quot; data-issue-key=&quot;ZOOKEEPER-1740&quot;&gt;&lt;del&gt;ZOOKEEPER-1740&lt;/del&gt;&lt;/a&gt; bug was hit in which case our ephemeral node mysteriously was lost out from under us, but our session is still active and we can just create a new one. The other bug I believe we are seeing is that the session is long gone but the ephemeral node is still hanging around until the consumer process exits.&lt;/p&gt;

&lt;p&gt;Currently the first case is handled, but I the second case is not.&lt;/p&gt;</comment>
                            <comment id="14526945" author="nehanarkhede" created="Mon, 4 May 2015 17:58:25 +0000"  >&lt;p&gt;When this happens, there isn&apos;t a way to get out of this without killing the broker. Marking it as a blocker.&lt;/p&gt;</comment>
                            <comment id="14533402" author="anigam" created="Thu, 7 May 2015 21:17:15 +0000"  >&lt;p&gt;I have seen the ephemeral node issue before and the fix made there was exactly what Thomas mentioned:&lt;br/&gt;
&quot;It seems the simplest thing to do would be to just delete the conflicted node and write the truth about the process environment it knows.&quot;&lt;/p&gt;

&lt;p&gt;Is there a reason why the approach outlined by Thomas does not work for kafka?&lt;/p&gt;</comment>
                            <comment id="14648378" author="clarkhaskins" created="Thu, 30 Jul 2015 21:54:43 +0000"  >&lt;p&gt;This patch is listed as a blocker. Can the existing patch be committed? Is anyone actively working on it? &lt;/p&gt;

&lt;p&gt;This has been a problem for us recently and we would like to see this fixed soon.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
-Clark&lt;/p&gt;</comment>
                            <comment id="14682263" author="mgharat" created="Tue, 11 Aug 2015 18:39:38 +0000"  >&lt;p&gt;Can the person who uploaded the patch submit a testcase on how to reproduce this? &lt;br/&gt;
We are hitting this in production but are not able to reproduce this locally.&lt;/p&gt;
</comment>
                            <comment id="14682269" author="slon" created="Tue, 11 Aug 2015 18:43:48 +0000"  >&lt;p&gt;Have you tried steps from issue description?&lt;/p&gt;</comment>
                            <comment id="14682416" author="guozhang" created="Tue, 11 Aug 2015 20:19:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fpj&quot; class=&quot;user-hover&quot; rel=&quot;fpj&quot;&gt;fpj&lt;/a&gt; Could you help taking a look at this issue?&lt;/p&gt;</comment>
                            <comment id="14692595" author="jwlent@gmail.com" created="Wed, 12 Aug 2015 00:07:40 +0000"  >&lt;p&gt;It has been a while since I investigated this issue. I will take another look at it tomorrow and get back to you. &lt;/p&gt;

&lt;p&gt;Sent from my iPhone&lt;/p&gt;
</comment>
                            <comment id="14694052" author="jwlent55" created="Wed, 12 Aug 2015 19:32:22 +0000"  >&lt;p&gt;After refreshing my memory of this issue I was unable to come up with any new ideas for how to create an automated test case for the issue.  I was only able to reproduce this issue in my dev environment using the cumbersome manual process I outlined in my Sept 27 comment.&lt;/p&gt;

&lt;p&gt;My question posted to the zookeeper-user mailing list regarding the validity of the key assumption of the patch logic generated no feedback.&lt;/p&gt;

&lt;p&gt;We have been using the patch I provided with Kafka 0.8.1.1 for almost a year now.  We have not seen a re-occurrence of the hung ephemeral connection issue since then.  Since the problem was intermittent and only triggered when the system was unstable, this may or may not be due to the presence of the patch.&lt;/p&gt;

&lt;p&gt;There was one an NPE issue found during test in March when our application code changed and in certain cases tried to close a Connector that had never been fully started.  That was fixed as follows:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Index: core/src/main/scala/kafka/consumer/ZookeeperConsumerConnector.scala
===================================================================
--- core/src/main/scala/kafka/consumer/ZookeeperConsumerConnector.scala	(revision 73668)
+++ core/src/main/scala/kafka/consumer/ZookeeperConsumerConnector.scala	(revision 73669)
@@ -162,7 +162,9 @@
       if (canShutdown) {
         info(&quot;ZKConsumerConnector shutting down&quot;)
 
-        consumerNodeMonitor.close()
+        if (consumerNodeMonitor != null) {
+          consumerNodeMonitor.close()
+        }
         
         if (wildcardTopicWatcher != null)
           wildcardTopicWatcher.shutdown()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Not sure any of this was of much help, but, I would be happy to try to answer any questions regarding the patch logic and/or update it based on your comments.&lt;/p&gt;</comment>
                            <comment id="14697002" author="fpj" created="Fri, 14 Aug 2015 13:34:40 +0000"  >&lt;p&gt;I&apos;m actually really sorry that this issue has been around for so long, I didn&apos;t realize it was going on and that I was even indirectly participating in it. Let me start by giving a sort of general overview of what to expect.&lt;/p&gt;

&lt;p&gt;If a client has received a session expiration event, it means that the leader has expired the session and has broadcast the closeSession event to the followers. If the same client creates a new session successfully, then the server it connects to must have applied the previous closeSession, which deletes the ephemeral znodes, because ZK guarantees that txns are totally ordered. Consequently, the client shouldn&apos;t observe an ephemeral from an old session of its own. Note that another client could still observe the ephemeral znode after the session expiration if it is connected to a server that is a bit behind, but that&apos;s fine.&lt;/p&gt;

&lt;p&gt;What I&apos;m thinking is that one problem that could happen is that a client creates a new session before receiving the session expiration for an earlier session. In that case the ephemerals will still be there because the session still exists.&lt;/p&gt;

&lt;p&gt;The bottom line is that if the client has seen the session expiration event, then it seems fine to go ahead and create new ephemerals without having to check whether ephemerals are stale or not. If the session creation isn&apos;t clean, then there are a few options like waiting for the timeout period, storing and recovering the session id.&lt;/p&gt;

&lt;p&gt;I&apos;ll dig into the code to see how we can fix this, have a closer look at the patch, and will reopen the associated &lt;a href=&quot;https://issues.apache.org/jira/browse/ZOOKEEPER-1740&quot; title=&quot;Zookeeper 3.3.4 loses ephemeral nodes under stress&quot; class=&quot;issue-link&quot; data-issue-key=&quot;ZOOKEEPER-1740&quot;&gt;&lt;del&gt;ZOOKEEPER-1740&lt;/del&gt;&lt;/a&gt; issue until we sort this out. let me know if the explanation above makes sense in the meanwhile. &lt;/p&gt;</comment>
                            <comment id="14697427" author="anigam" created="Fri, 14 Aug 2015 17:32:40 +0000"  >&lt;p&gt;Thanks a lot for digging into this. Not sure if it helps but in the past&lt;br/&gt;
when I saw this issue it went like this:&lt;br/&gt;
a) Say session time out is 30 seconds.&lt;br/&gt;
b) If we kill the instance which create the zookeeper ephemeral node and&lt;br/&gt;
bring it back up quickly (less than 30 seconds) we would find the previous&lt;br/&gt;
session data (ephemeral node) still exists.&lt;/p&gt;

&lt;p&gt;The solution was to assume the existing data was from an old session,&lt;br/&gt;
delete and re-create it during startup. However, we were processing the&lt;br/&gt;
zookeeper events on a single thread.&lt;/p&gt;

&lt;p&gt;On Fri, Aug 14, 2015 at 6:34 AM, Flavio Junqueira (JIRA) &amp;lt;jira@apache.org&amp;gt;&lt;/p&gt;
</comment>
                            <comment id="14697907" author="guozhang" created="Fri, 14 Aug 2015 22:50:31 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fpj&quot; class=&quot;user-hover&quot; rel=&quot;fpj&quot;&gt;fpj&lt;/a&gt;, this is very helpful.&lt;/p&gt;

&lt;p&gt;Just to add some more context regarding this issue, we have seen issues when ephemeral nodes were not deleted when brokers / consumers try to re-register themselves in ZK upon a session timeout event (details can be found in &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-992&quot; title=&quot;Double Check on Broker Registration to Avoid False NodeExist Exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-992&quot;&gt;&lt;del&gt;KAFKA-992&lt;/del&gt;&lt;/a&gt;). We tried to fix it via adding a registration timestamp into the registration node&apos;s data, and checking if the timestamp is different upon seeing it, and if not backing off to wait for this node to be removed.&lt;/p&gt;

&lt;p&gt;However people have been also reporting a couple of times that the backing-off is never ending, i.e. the node has a different timestamp, but was never deleted. The suspicion was that there were multiple consequent session creation at a very short period of time, and the node with a different timestamp is created by a session that was not actually expired, and hence will never be gone. But no one has validated if this is the case though.&lt;/p&gt;

&lt;p&gt;The logic of re-registration can be found in ZookeeperConsumerConnector.scala and KafkaHealthcheck.scala.&lt;/p&gt;</comment>
                            <comment id="14699514" author="fpj" created="Mon, 17 Aug 2015 13:24:51 +0000"  >&lt;p&gt;There are two problems at a high level described here: zk losing ephemerals and ephemerals not going away. I haven&apos;t been able to reproduce the former, but I&apos;ve been able to find one potential problem that could be causing it.&lt;/p&gt;

&lt;p&gt;I started by finding suspicious that the ZK listeners were not dealing with session events at all:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;def handleStateChanged(state: KeeperState) {
      &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; nothing, since zkclient will &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; reconnect &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; us.
&lt;/span&gt;}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt; It is quite typical with ZK that you wait for the connected event before making progress. Looking at the ZkClient implementation, I realized that it retries operations in the case of connection loss or session expiration until they go through. There is a race here, though. Say you submit a create, but instead of getting OK as a response, you get connection loss. ZkClient in this case will say &quot;well, need to retry&quot; and will get a node exists exception, which the code currently treats as a znode from a previous session. This znode will never go away because it belongs to the current session!&lt;/p&gt;

&lt;p&gt;Now let&apos;s say we get rid of such corner cases. It is still possible that when the client recovers it finds a znode from a previous session. It can happen because the lease (session) corresponding to the znode is still valid, so ZK can&apos;t get rid of it. Revoking leases in general is a bit complicated, but it sounds ok in this case if there is no risky of having multiple incarnations of the same element (a broker) running concurrently.&lt;/p&gt;</comment>
                            <comment id="14700113" author="guozhang" created="Mon, 17 Aug 2015 19:47:12 +0000"  >&lt;p&gt;I thought that when the previous session has ended (e.g. expired), its ephemeral node will be &quot;eventually&quot; removed? Does ZooKeeper itself have a leasing mechanism?&lt;/p&gt;</comment>
                            <comment id="14700187" author="fpj" created="Mon, 17 Aug 2015 20:44:44 +0000"  >&lt;blockquote&gt;&lt;p&gt;I thought that when the previous session has ended (e.g. expired), its ephemeral node will be &quot;eventually&quot; removed?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If the session ends cleanly, by the client submitting a closeSession request, then the session closes and the ephemerals are deleted with the request. But, if the client crashes and the server simply stops hearing from the client, then the session has to time out and expire so it takes some time.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Does ZooKeeper itself have a leasing mechanism?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m referring to the fact that the ephemeral represents a lease that is revoked when the session times out.&lt;/p&gt;

&lt;p&gt;I&apos;m not sure if this is clear, but one of the problems I&apos;m pointing out is that zkclient might end up creating the ephemeral znode in your &lt;b&gt;current&lt;/b&gt; session. In this case, the znode won&apos;t go away. Here is actually another problem I found along the same lines. The createEphemeral call in ZkClient ends up calling retryUntilConnected, which retries even when the session expires:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;            &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
                &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; callable.call();
            } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (ConnectionLossException e) {
                &lt;span class=&quot;code-comment&quot;&gt;// we give the event thread some time to update the status to &lt;span class=&quot;code-quote&quot;&gt;&apos;Disconnected&apos;&lt;/span&gt;
&lt;/span&gt;                &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.yield();
                waitForRetry();
            } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (SessionExpiredException e) {
                &lt;span class=&quot;code-comment&quot;&gt;// we give the event thread some time to update the status to &lt;span class=&quot;code-quote&quot;&gt;&apos;Expired&apos;&lt;/span&gt;
&lt;/span&gt;                &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.yield();
                waitForRetry();
            }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In this case, say that one call to createEphemeral via handleNewSession happens during a given session, but the session expires before the operation goes through. The client will retry with the new session. When the consumer tries again, it will fail because the znode is there and won&apos;t go away. This is another case in which the znode won&apos;t go away because it has been created in the current session.&lt;/p&gt;</comment>
                            <comment id="14700483" author="guozhang" created="Tue, 18 Aug 2015 00:03:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fpj&quot; class=&quot;user-hover&quot; rel=&quot;fpj&quot;&gt;fpj&lt;/a&gt; That makes sense. So it seems the right resolution should be at the ZkClient layer, not on Kafka&apos;s layer?&lt;/p&gt;</comment>
                            <comment id="14701418" author="fpj" created="Tue, 18 Aug 2015 15:19:32 +0000"  >&lt;p&gt;It doesn&apos;t look like it &apos;d be a small change to zkclient to fix this. We essentially need it to expose zk events as they occur. In the way it currently does it, the events are serialized and the operations are retried transparently so I don&apos;t know if the znode already exists because of a connection loss or if the session actually expired and there is a new one now. &lt;/p&gt;

&lt;p&gt;The simplest way around this seems to be to just re-register the consumer directly (delete and create) upon a node exists exception. This should work because of the following argument.&lt;/p&gt;

&lt;p&gt;There are three possibilities when we get a node exists exception:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;The znode exists from a previous session and hasn&apos;t been reclaimed yet&lt;/li&gt;
	&lt;li&gt;The znode exists because of a connection loss event while the znode was being created, so the second time we get an exception (event)&lt;/li&gt;
	&lt;li&gt;The previous session has expired, a new one was created, and the registration was occurring around this transition, so when we execute handleNewSession for the new session, we get a node exists exception.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;In all these three cases, deleting and recreating seems fine. It is clearly conservative and more expensive than necessary, but at least it doesn&apos;t require changes to zkclient. Does it sound a reasonable? Do you see any problem? &lt;/p&gt;

&lt;p&gt;CC &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jwlent%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;jwlent@gmail.com&quot;&gt;jwlent@gmail.com&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14701509" author="guozhang" created="Tue, 18 Aug 2015 16:16:13 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fpj&quot; class=&quot;user-hover&quot; rel=&quot;fpj&quot;&gt;fpj&lt;/a&gt;, that makes sense to me. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jwlent55&quot; class=&quot;user-hover&quot; rel=&quot;jwlent55&quot;&gt;jwlent55&lt;/a&gt; do you want to submit a new patch following this approach?&lt;/p&gt;</comment>
                            <comment id="14701571" author="fpj" created="Tue, 18 Aug 2015 16:51:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt; it looks like &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jwlent%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;jwlent@gmail.com&quot;&gt;jwlent@gmail.com&lt;/a&gt; isn&apos;t in the list of contributors, could you add him so that we can assign the jira to him?&lt;/p&gt;</comment>
                            <comment id="14702992" author="jwlent55" created="Wed, 19 Aug 2015 13:16:05 +0000"  >&lt;p&gt;Your approach sounds much simpler than mine (which I like).  Similar to what I proposed doing only at startup (ensureNodeDoesNotExist method).  I am however not sure I understand the exact change you propose.  As I remember the createEphemeralPathExpectConflictHandleZKBug is called by three code paths:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Register Broker&lt;/li&gt;
	&lt;li&gt;Register Consumer&lt;/li&gt;
	&lt;li&gt;Leadership election&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In my change I specifically tried avoid changing the Leadership election logic.&lt;/p&gt;

&lt;p&gt;Is your change basically to implement your new logic (delete if already exists) instead of calling createEphemeralPathExpectConflictHandleZKBug in the first two cases?  If so I agree it sounds reasonable.  I suppose in a misconfiguration case two nodes might get into a registration war over the Broker node, but, that could (perhaps) be handled at startup (second one fails to start up).&lt;/p&gt;

&lt;p&gt;If your propose replacing the createEphemeralPathExpectConflictHandleZKBug for the Leadership election case too then I am less comfortable making (and testing) that change.  I have never really dug into that logic too much.&lt;/p&gt;

&lt;p&gt;One other factor to consider is that I am a bit backed up a work right now and this will not be issue will not be my highest priority.&lt;/p&gt;</comment>
                            <comment id="14703532" author="guozhang" created="Wed, 19 Aug 2015 18:38:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jwlent55&quot; class=&quot;user-hover&quot; rel=&quot;jwlent55&quot;&gt;jwlent55&lt;/a&gt; I agree that this fix may be just for broker / consumer registration, i.e. ZK should not be used to detect mis-configuration that two brokers / clients use the same Id. Hence for that case, in the new approach they may end-up in a delete-and-write war. We should consider fixing such mis-operation in a different manner which is orthogonal to this JIRA. For leader election, one should not simply delete the path upon conflict, we should leave it as is. In the future, we should either fix the root cause in ZkClient or move on to use a different client as KIP-30 is current discussing about.&lt;/p&gt;

&lt;p&gt;If you do not have time this week and feel it is OK, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fpj&quot; class=&quot;user-hover&quot; rel=&quot;fpj&quot;&gt;fpj&lt;/a&gt; could you help taking it over?&lt;/p&gt;</comment>
                            <comment id="14703767" author="fpj" created="Wed, 19 Aug 2015 21:22:57 +0000"  >&lt;p&gt;I&apos;m indeed proposing to get rid of createEphemeralPathExpectConflictHandleZKBug. I can investigate the impact to leadership election.&lt;/p&gt;</comment>
                            <comment id="14709518" author="fpj" created="Mon, 24 Aug 2015 16:06:54 +0000"  >&lt;p&gt;Given that it isn&apos;t clear that we will be getting curator as a dependency, I started a fix that pretty much relies on the ZK handle that ZkClient creates. Here is a preliminary patch that fixes the issues we have been discussing for the consumer registration by simply not retrying the creation of the registration znode across sessions. Given that I&apos;m not using the ZkClient API, there is a bit of wiring to be done, but I hope it is ok.&lt;/p&gt;</comment>
                            <comment id="14711838" author="guozhang" created="Tue, 25 Aug 2015 19:37:30 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fpj&quot; class=&quot;user-hover&quot; rel=&quot;fpj&quot;&gt;fpj&lt;/a&gt;, thanks for the patch. Here are some high-level comments:&lt;/p&gt;

&lt;p&gt;1. Will the mixing usage of ZK directly and ZkClient together violate ordering? AFAIK ZkClient orders all events fired by watchers and hand them to the user callbacks one-by-one, if we use ZK&apos;s Watcher directly will its callback be called out-of-order with other events?&lt;/p&gt;

&lt;p&gt;2. If we get a Code.OK in CreateCallback, do we still need to trigger a ZooKeeper.exist with ExistsCallback again?&lt;/p&gt;

&lt;p&gt;3. For the consumer / server registration case particularly, we tries to handle parent path creation in ZkUtils.makeSurePersistentPathExists, so I feel we should expose the problem that parent path does not exist yet instead trying to hide it in createRecursive.&lt;/p&gt;</comment>
                            <comment id="14721137" author="githubbot" created="Sat, 29 Aug 2015 15:17:52 +0000"  >&lt;p&gt;GitHub user fpj opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/178&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/178&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1387&quot; title=&quot;Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1387&quot;&gt;&lt;del&gt;KAFKA-1387&lt;/del&gt;&lt;/a&gt;: Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of time&lt;/p&gt;

&lt;p&gt;    This is a patch to get around the problem discussed in the &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1387&quot; title=&quot;Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1387&quot;&gt;&lt;del&gt;KAFKA-1387&lt;/del&gt;&lt;/a&gt; jira. The tests are not passing in my box when I run them all, but they do pass when I run them individually, which indicates that there is something leaking from a test to the next. I still need to work this out and also work on further testing this. I wanted to open this PR now so that it can start getting reviewed.&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/fpj/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/fpj/kafka&lt;/a&gt; 1387&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/178.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/178.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #178&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit f8be8657e649d0490e9ed1f1ef52234b3c31435e&lt;br/&gt;
Author: flavio junqueira &amp;lt;fpj@apache.org&amp;gt;&lt;br/&gt;
Date:   2015-08-23T13:55:11Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1387&quot; title=&quot;Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1387&quot;&gt;&lt;del&gt;KAFKA-1387&lt;/del&gt;&lt;/a&gt;: First cut, node dependency on curator&lt;/p&gt;

&lt;p&gt;commit b8f901b6478d4ac9c961e899d702e6fc11cfee07&lt;br/&gt;
Author: flavio junqueira &amp;lt;fpj@apache.org&amp;gt;&lt;br/&gt;
Date:   2015-08-23T13:55:11Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1387&quot; title=&quot;Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1387&quot;&gt;&lt;del&gt;KAFKA-1387&lt;/del&gt;&lt;/a&gt;: First cut, node dependency on curator&lt;/p&gt;

&lt;p&gt;commit 2369e66921f88b2ee1b24ddeff2bf2d050015447&lt;br/&gt;
Author: flavio junqueira &amp;lt;fpj@apache.org&amp;gt;&lt;br/&gt;
Date:   2015-08-23T14:07:41Z&lt;/p&gt;

&lt;p&gt;    Merge branch &apos;1387&apos; of &lt;a href=&quot;https://github.com/fpj/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/fpj/kafka&lt;/a&gt; into 1387&lt;/p&gt;

&lt;p&gt;commit f03c301d5d919d9c05c6837de508b4f383906fdb&lt;br/&gt;
Author: flavio junqueira &amp;lt;fpj@apache.org&amp;gt;&lt;br/&gt;
Date:   2015-08-23T13:55:11Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1387&quot; title=&quot;Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1387&quot;&gt;&lt;del&gt;KAFKA-1387&lt;/del&gt;&lt;/a&gt;: First cut, node dependency on curator&lt;/p&gt;

&lt;p&gt;commit d8eab9e0f569eaaecb4afda4d486d00600ad1e6f&lt;br/&gt;
Author: flavio junqueira &amp;lt;fpj@apache.org&amp;gt;&lt;br/&gt;
Date:   2015-08-24T14:56:01Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1387&quot; title=&quot;Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1387&quot;&gt;&lt;del&gt;KAFKA-1387&lt;/del&gt;&lt;/a&gt;: Some polishing&lt;/p&gt;

&lt;p&gt;commit b7cbe5dbecbc28a564b99209114f39db785c73dd&lt;br/&gt;
Author: flavio junqueira &amp;lt;fpj@apache.org&amp;gt;&lt;br/&gt;
Date:   2015-08-24T15:50:58Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1387&quot; title=&quot;Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1387&quot;&gt;&lt;del&gt;KAFKA-1387&lt;/del&gt;&lt;/a&gt;: Style fixes&lt;/p&gt;

&lt;p&gt;commit 336f67c641c44b73ac1dbb66cdde4ff97f2fcd9a&lt;br/&gt;
Author: flavio junqueira &amp;lt;fpj@apache.org&amp;gt;&lt;br/&gt;
Date:   2015-08-24T15:53:18Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1387&quot; title=&quot;Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1387&quot;&gt;&lt;del&gt;KAFKA-1387&lt;/del&gt;&lt;/a&gt;: More style fixes&lt;/p&gt;

&lt;p&gt;commit 201ab2dcc33ba10a19c51f7452ce40497d3fcf83&lt;br/&gt;
Author: flavio junqueira &amp;lt;fpj@apache.org&amp;gt;&lt;br/&gt;
Date:   2015-08-24T15:59:32Z&lt;/p&gt;

&lt;p&gt;    Merge branch &apos;1387&apos; of &lt;a href=&quot;https://github.com/fpj/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/fpj/kafka&lt;/a&gt; into 1387&lt;/p&gt;

&lt;p&gt;commit 9961665230e04331f7767d8aa8aaac0a14f46cd8&lt;br/&gt;
Author: flavio junqueira &amp;lt;fpj@apache.org&amp;gt;&lt;br/&gt;
Date:   2015-08-23T13:55:11Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1387&quot; title=&quot;Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1387&quot;&gt;&lt;del&gt;KAFKA-1387&lt;/del&gt;&lt;/a&gt;: First cut, node dependency on curator&lt;/p&gt;

&lt;p&gt;commit b52c12422f7a831137d8659f14779eaad1972217&lt;br/&gt;
Author: flavio junqueira &amp;lt;fpj@apache.org&amp;gt;&lt;br/&gt;
Date:   2015-08-24T14:56:01Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1387&quot; title=&quot;Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1387&quot;&gt;&lt;del&gt;KAFKA-1387&lt;/del&gt;&lt;/a&gt;: Some polishing&lt;/p&gt;

&lt;p&gt;commit b2400a0a37555250d50b1f1abfdda2c4d00b03ac&lt;br/&gt;
Author: flavio junqueira &amp;lt;fpj@apache.org&amp;gt;&lt;br/&gt;
Date:   2015-08-24T15:50:58Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1387&quot; title=&quot;Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1387&quot;&gt;&lt;del&gt;KAFKA-1387&lt;/del&gt;&lt;/a&gt;: Style fixes&lt;/p&gt;

&lt;p&gt;commit 888f6e0cf17d6a3a8d6b8dd46f8099731ba36511&lt;br/&gt;
Author: flavio junqueira &amp;lt;fpj@apache.org&amp;gt;&lt;br/&gt;
Date:   2015-08-24T15:53:18Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1387&quot; title=&quot;Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1387&quot;&gt;&lt;del&gt;KAFKA-1387&lt;/del&gt;&lt;/a&gt;: More style fixes&lt;/p&gt;

&lt;p&gt;commit d675b024b0e8627c4c2c9c113c07527851e81f7a&lt;br/&gt;
Author: flavio junqueira &amp;lt;fpj@apache.org&amp;gt;&lt;br/&gt;
Date:   2015-08-29T15:00:07Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1387&quot; title=&quot;Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1387&quot;&gt;&lt;del&gt;KAFKA-1387&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;commit 4c83ac2609ed29a0f1887bf5087dab50e3e93488&lt;br/&gt;
Author: flavio junqueira &amp;lt;fpj@apache.org&amp;gt;&lt;br/&gt;
Date:   2015-08-29T15:07:23Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1387&quot; title=&quot;Kafka getting stuck creating ephemeral node it has already created when two zookeeper sessions are established in a very short period of time&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1387&quot;&gt;&lt;del&gt;KAFKA-1387&lt;/del&gt;&lt;/a&gt;: Removing whitespaces.&lt;/p&gt;

&lt;p&gt;commit 240b51a77715c53db784d5932702318ff28468c2&lt;br/&gt;
Author: flavio junqueira &amp;lt;fpj@apache.org&amp;gt;&lt;br/&gt;
Date:   2015-08-29T15:11:30Z&lt;/p&gt;

&lt;p&gt;    Merge branch &apos;1387&apos; of &lt;a href=&quot;https://github.com/fpj/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/fpj/kafka&lt;/a&gt; into 1387&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="14903437" author="fpj" created="Tue, 22 Sep 2015 21:09:59 +0000"  >&lt;p&gt;hey &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Will the mixing usage of ZK directly and ZkClient together violate ordering? AFAIK ZkClient orders all events fired by watchers and hand them to the user callbacks one-by-one, if we use ZK&apos;s Watcher directly will its callback be called out-of-order with other events?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;ZkClient indeed handles the processing to a separate thread. To avoid blocking the dispatcher thread, it uses a separate thread to deliver events. This can be a problem if the events here and events handled directly by ZkClient are correlated. I tried to confine the ZK processing for this feature in the same class to avoid ordering issues. I don&apos;t see a problem concretely, but if you do, let me know. Right now it sounds like you&apos;re just speculating that it could be a problem, yes?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;If we get a Code.OK in CreateCallback, do we still need to trigger a ZooKeeper.exist with ExistsCallback again?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right, that exists call is to set a watch.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;For the consumer / server registration case particularly, we tries to handle parent path creation in ZkUtils.makeSurePersistentPathExists, so I feel we should expose the problem that parent path does not exist yet instead trying to hide it in createRecursive.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;ve commented on the PR about this. What&apos;s your specific concern here? If you could elaborate a bit more, I&apos;d appreciate.  &lt;/p&gt;</comment>
                            <comment id="14906672" author="githubbot" created="Thu, 24 Sep 2015 17:14:44 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/178&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/178&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12714147">KAFKA-1451</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                            <outwardlinks description="depends upon">
                                        <issuelink>
            <issuekey id="12663897">ZOOKEEPER-1740</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12752026" name="KAFKA-1387.patch" size="10812" author="fpj" created="Mon, 24 Aug 2015 16:06:54 +0000"/>
                            <attachment id="12672056" name="kafka-1387.patch" size="16226" author="jwlent55" created="Tue, 30 Sep 2014 16:27:29 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>386101</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 8 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1uii7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>386366</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>guozhang</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>