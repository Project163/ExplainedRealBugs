<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:09:39 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6650] The controller should be able to handle a partially deleted topic</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6650</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;A previous controller could have deleted some partitions of a topic from ZK, but not all partitions, and then died.&lt;br/&gt;
In that case, the new controller should be able to handle the partially deleted topic, and finish the deletion.&lt;/p&gt;

&lt;p&gt;In the current code base, if there is no leadership info for a replica&apos;s partition, the transition to OfflineReplica state for the replica will fail. Afterwards the transition to ReplicaDeletionStarted will fail as well since the only valid previous state for ReplicaDeletionStarted is OfflineReplica. Furthermore, it means the topic deletion will never finish.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13144869">KAFKA-6650</key>
            <summary>The controller should be able to handle a partially deleted topic</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="luwang">Lucas Wang</assignee>
                                    <reporter username="luwang">Lucas Wang</reporter>
                        <labels>
                    </labels>
                <created>Tue, 13 Mar 2018 22:16:46 +0000</created>
                <updated>Tue, 17 Apr 2018 00:17:13 +0000</updated>
                            <resolved>Tue, 17 Apr 2018 00:17:13 +0000</resolved>
                                                    <fixVersion>2.0.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16426161" author="githubbot" created="Wed, 4 Apr 2018 21:00:55 +0000"  >&lt;p&gt;gitlw opened a new pull request #4825: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6650&quot; title=&quot;The controller should be able to handle a partially deleted topic&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6650&quot;&gt;&lt;del&gt;KAFKA-6650&lt;/del&gt;&lt;/a&gt;: Allowing transition to OfflineReplica state for replicas without leadership info&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4825&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4825&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   A partially deleted topic can end up with some partitions having no leadership info.&lt;br/&gt;
   For the partially deleted topic, a new controller should be able to finish the topic deletion&lt;br/&gt;
   by transitioning the rogue partition&apos;s replicas to OfflineReplica state.&lt;br/&gt;
   This patch adds logic to transition replicas to OfflineReplica state whose partitions have&lt;br/&gt;
   no leadership info.&lt;/p&gt;

&lt;p&gt;   Added a new test method to cover the partially deleted topic case.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16440195" author="githubbot" created="Tue, 17 Apr 2018 00:16:11 +0000"  >&lt;p&gt;junrao closed pull request #4825: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6650&quot; title=&quot;The controller should be able to handle a partially deleted topic&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6650&quot;&gt;&lt;del&gt;KAFKA-6650&lt;/del&gt;&lt;/a&gt;: Allowing transition to OfflineReplica state for replicas without leadership info&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4825&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4825&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/core/src/main/scala/kafka/controller/ReplicaStateMachine.scala b/core/src/main/scala/kafka/controller/ReplicaStateMachine.scala&lt;br/&gt;
index a2d04e65ae6..5fafcc4fe3f 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/controller/ReplicaStateMachine.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/controller/ReplicaStateMachine.scala&lt;br/&gt;
@@ -202,8 +202,10 @@ class ReplicaStateMachine(config: KafkaConfig,&lt;br/&gt;
           controllerBrokerRequestBatch.addStopReplicaRequestForBrokers(Seq(replicaId), replica.topicPartition,&lt;br/&gt;
             deletePartition = false, (_, _) =&amp;gt; ())&lt;br/&gt;
         }&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val replicasToRemoveFromIsr = validReplicas.filter(replica =&amp;gt; controllerContext.partitionLeadershipInfo.contains(replica.topicPartition))&lt;/li&gt;
	&lt;li&gt;val updatedLeaderIsrAndControllerEpochs = removeReplicasFromIsr(replicaId, replicasToRemoveFromIsr.map(_.topicPartition))&lt;br/&gt;
+        val (replicasWithLeadershipInfo, replicasWithoutLeadershipInfo) = validReplicas.partition 
{ replica =&amp;gt;
+          controllerContext.partitionLeadershipInfo.contains(replica.topicPartition)
+        }
&lt;p&gt;+        val updatedLeaderIsrAndControllerEpochs = removeReplicasFromIsr(replicaId, replicasWithLeadershipInfo.map(_.topicPartition))&lt;br/&gt;
         updatedLeaderIsrAndControllerEpochs.foreach { case (partition, leaderIsrAndControllerEpoch) =&amp;gt;&lt;br/&gt;
           if (!topicDeletionManager.isPartitionToBeDeleted(partition)) &lt;/p&gt;
{
             val recipients = controllerContext.partitionReplicaAssignment(partition).filterNot(_ == replicaId)
@@ -216,6 +218,11 @@ class ReplicaStateMachine(config: KafkaConfig,
           logSuccessfulTransition(replicaId, partition, replicaState(replica), OfflineReplica)
           replicaState.put(replica, OfflineReplica)
         }
&lt;p&gt;+&lt;br/&gt;
+        replicasWithoutLeadershipInfo.foreach &lt;/p&gt;
{ replica =&amp;gt;
+          logSuccessfulTransition(replicaId, replica.topicPartition, replicaState(replica), OfflineReplica)
+          replicaState.put(replica, OfflineReplica)
+        }
&lt;p&gt;       case ReplicaDeletionStarted =&amp;gt;&lt;br/&gt;
         validReplicas.foreach { replica =&amp;gt;&lt;br/&gt;
           logSuccessfulTransition(replicaId, replica.topicPartition, replicaState(replica), ReplicaDeletionStarted)&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/zk/KafkaZkClient.scala b/core/src/main/scala/kafka/zk/KafkaZkClient.scala&lt;br/&gt;
index 9b58fc7cc4b..a65128ad98a 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/main/scala/kafka/zk/KafkaZkClient.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/zk/KafkaZkClient.scala&lt;br/&gt;
@@ -1370,7 +1370,7 @@ class KafkaZkClient private (zooKeeperClient: ZooKeeperClient, isSecure: Boolean&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@return true if path gets deleted successfully, false if root path doesn&apos;t exist&lt;/li&gt;
	&lt;li&gt;@throws KeeperException if there is an error while deleting the znodes&lt;br/&gt;
    */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private&lt;span class=&quot;error&quot;&gt;&amp;#91;zk&amp;#93;&lt;/span&gt; def deleteRecursive(path: String): Boolean = {&lt;br/&gt;
+  def deleteRecursive(path: String): Boolean = {&lt;br/&gt;
     val getChildrenResponse = retryRequestUntilConnected(GetChildrenRequest(path))&lt;br/&gt;
     getChildrenResponse.resultCode match {&lt;br/&gt;
       case Code.OK =&amp;gt;&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/admin/DeleteTopicTest.scala b/core/src/test/scala/unit/kafka/admin/DeleteTopicTest.scala&lt;br/&gt;
index ef455d4457e..4c033c421bb 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/test/scala/unit/kafka/admin/DeleteTopicTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/admin/DeleteTopicTest.scala&lt;br/&gt;
@@ -17,7 +17,7 @@&lt;br/&gt;
 package kafka.admin&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import kafka.log.Log&lt;br/&gt;
-import kafka.zk.ZooKeeperTestHarness&lt;br/&gt;
+import kafka.zk.&lt;/p&gt;
{TopicPartitionZNode, ZooKeeperTestHarness}
&lt;p&gt; import kafka.utils.TestUtils&lt;br/&gt;
 import kafka.server.&lt;/p&gt;
{KafkaConfig, KafkaServer}
&lt;p&gt; import org.junit.Assert._&lt;br/&gt;
@@ -326,7 +326,7 @@ class DeleteTopicTest extends ZooKeeperTestHarness {&lt;br/&gt;
     brokerConfigs.head.setProperty(&quot;log.segment.bytes&quot;,&quot;100&quot;)&lt;br/&gt;
     brokerConfigs.head.setProperty(&quot;log.cleaner.dedupe.buffer.size&quot;,&quot;1048577&quot;)&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;servers = createTestTopicAndCluster(topic,brokerConfigs)&lt;br/&gt;
+    servers = createTestTopicAndCluster(topic, brokerConfigs, expectedReplicaAssignment)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // for simplicity, we are validating cleaner offsets on a single broker&lt;br/&gt;
     val server = servers.head&lt;br/&gt;
@@ -363,18 +363,18 @@ class DeleteTopicTest extends ZooKeeperTestHarness &lt;/p&gt;
{
     TestUtils.verifyTopicDeletion(zkClient, topic, 1, servers)
   }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private def createTestTopicAndCluster(topic: String, deleteTopicEnabled: Boolean = true): Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;KafkaServer&amp;#93;&lt;/span&gt; = {&lt;br/&gt;
+  private def createTestTopicAndCluster(topic: String, deleteTopicEnabled: Boolean = true, replicaAssignment: Map[Int, List&lt;span class=&quot;error&quot;&gt;&amp;#91;Int&amp;#93;&lt;/span&gt;] = expectedReplicaAssignment): Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;KafkaServer&amp;#93;&lt;/span&gt; = 
{
     val brokerConfigs = TestUtils.createBrokerConfigs(3, zkConnect, enableControlledShutdown = false)
     brokerConfigs.foreach(_.setProperty(&quot;delete.topic.enable&quot;, deleteTopicEnabled.toString))
-    createTestTopicAndCluster(topic, brokerConfigs)
+    createTestTopicAndCluster(topic, brokerConfigs, replicaAssignment)
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private def createTestTopicAndCluster(topic: String, brokerConfigs: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;Properties&amp;#93;&lt;/span&gt;): Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;KafkaServer&amp;#93;&lt;/span&gt; = {&lt;br/&gt;
+  private def createTestTopicAndCluster(topic: String, brokerConfigs: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;Properties&amp;#93;&lt;/span&gt;, replicaAssignment: Map[Int, List&lt;span class=&quot;error&quot;&gt;&amp;#91;Int&amp;#93;&lt;/span&gt;]): Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;KafkaServer&amp;#93;&lt;/span&gt; = {&lt;br/&gt;
     val topicPartition = new TopicPartition(topic, 0)&lt;br/&gt;
     // create brokers&lt;br/&gt;
     val servers = brokerConfigs.map(b =&amp;gt; TestUtils.createServer(KafkaConfig.fromProps(b)))&lt;br/&gt;
     // create the topic&lt;/li&gt;
	&lt;li&gt;adminZkClient.createOrUpdateTopicPartitionAssignmentPathInZK(topic, expectedReplicaAssignment)&lt;br/&gt;
+    adminZkClient.createOrUpdateTopicPartitionAssignmentPathInZK(topic, replicaAssignment)&lt;br/&gt;
     // wait until replica log is created on every broker&lt;br/&gt;
     TestUtils.waitUntilTrue(() =&amp;gt; servers.forall(_.getLogManager().getLog(topicPartition).isDefined),&lt;br/&gt;
       &quot;Replicas for topic test not created&quot;)&lt;br/&gt;
@@ -408,4 +408,35 @@ class DeleteTopicTest extends ZooKeeperTestHarness 
{
     val leaderIdOpt = zkClient.getLeaderForPartition(new TopicPartition(topic, 0))
     assertTrue(&quot;Leader should exist for topic test&quot;, leaderIdOpt.isDefined)
   }
&lt;p&gt;+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  def testDeletingPartiallyDeletedTopic() &lt;/p&gt;
{
+    /**
+      * A previous controller could have deleted some partitions of a topic from ZK, but not all partitions, and then crashed.
+      * In that case, the new controller should be able to handle the partially deleted topic, and finish the deletion.
+      */
+
+    val replicaAssignment = Map(0 -&amp;gt; List(0, 1, 2), 1 -&amp;gt; List(0, 1, 2))
+    val topic = &quot;test&quot;
+    servers = createTestTopicAndCluster(topic, true, replicaAssignment)
+
+    /**
+      * shutdown all brokers in order to create a partially deleted topic on ZK
+      */
+    servers.foreach(_.shutdown())
+
+    /**
+      * delete the partition znode at /brokers/topics/test/partition/0
+      * to simulate the case that a previous controller crashed right after deleting the partition znode
+      */
+    zkClient.deleteRecursive(TopicPartitionZNode.path(new TopicPartition(topic, 0)))
+    adminZkClient.deleteTopic(topic)
+
+    /**
+      * start up all brokers and verify that topic deletion eventually finishes.
+      */
+    servers.foreach(_.startup())
+    TestUtils.waitUntilTrue(() =&amp;gt; servers.exists(_.kafkaController.isActive), &quot;No controller is elected&quot;)
+    TestUtils.verifyTopicDeletion(zkClient, topic, 2, servers)
+  }
&lt;p&gt; }&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/controller/ReplicaStateMachineTest.scala b/core/src/test/scala/unit/kafka/controller/ReplicaStateMachineTest.scala&lt;br/&gt;
index 6a961a53157..14d2df2e8f8 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/test/scala/unit/kafka/controller/ReplicaStateMachineTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/controller/ReplicaStateMachineTest.scala&lt;br/&gt;
@@ -119,7 +119,7 @@ class ReplicaStateMachineTest extends JUnitSuite 
{
     EasyMock.replay(mockControllerBrokerRequestBatch)
     replicaStateMachine.handleStateChanges(replicas, OfflineReplica)
     EasyMock.verify(mockControllerBrokerRequestBatch)
-    assertEquals(NewReplica, replicaState(replica))
+    assertEquals(OfflineReplica, replicaState(replica))
   }&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   @Test&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16440197" author="junrao" created="Tue, 17 Apr 2018 00:17:13 +0000"  >&lt;p&gt;merged the PR to trunk.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 31 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3r9bb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>