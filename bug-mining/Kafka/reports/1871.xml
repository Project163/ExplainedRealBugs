<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:08:51 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6739] Down-conversion fails for records with headers</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6739</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;A broker running at 1.0.0 with the following properties&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
log.message.format.version=1.0
inter.broker.protocol.version=1.0
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;receives this ERROR while handling fetch request for a message with a header&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[2018-03-23 01:48:03,093] ERROR [KafkaApi-1] Error when handling request {replica_id=-1,max_wait_time=100,min_bytes=1,topics=[{topic=test=[{partition=11,fetch_offset=20645,max_bytes=1048576}]}]} (kafka.server.KafkaApis) java.lang.IllegalArgumentException: Magic v0 does not support record headers 
at org.apache.kafka.common.record.MemoryRecordsBuilder.appendWithOffset(MemoryRecordsBuilder.java:403) 
at org.apache.kafka.common.record.MemoryRecordsBuilder.append(MemoryRecordsBuilder.java:586) 
at org.apache.kafka.common.record.AbstractRecords.convertRecordBatch(AbstractRecords.java:134) 
at org.apache.kafka.common.record.AbstractRecords.downConvert(AbstractRecords.java:109) 
at org.apache.kafka.common.record.FileRecords.downConvert(FileRecords.java:253) 
at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$convertedPartitionData$1$1$$anonfun$apply$4.apply(KafkaApis.scala:520) 
at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$convertedPartitionData$1$1$$anonfun$apply$4.apply(KafkaApis.scala:518) 
at scala.Option.map(Option.scala:146) 
at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$convertedPartitionData$1$1.apply(KafkaApis.scala:518) 
at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$convertedPartitionData$1$1.apply(KafkaApis.scala:508) 
at scala.Option.flatMap(Option.scala:171) 
at kafka.server.KafkaApis.kafka$server$KafkaApis$$convertedPartitionData$1(KafkaApis.scala:508) 
at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$createResponse$2$1.apply(KafkaApis.scala:556) 
at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$createResponse$2$1.apply(KafkaApis.scala:555) 
at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:891) 
at scala.collection.AbstractIterator.foreach(Iterator.scala:1334) 
at scala.collection.IterableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(IterableLike.scala:72) 
at scala.collection.AbstractIterable.foreach(Iterable.scala:54) 
at kafka.server.KafkaApis.kafka$server$KafkaApis$$createResponse$2(KafkaApis.scala:555) 
at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$fetchResponseCallback$1$1.apply(KafkaApis.scala:569) 
at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$fetchResponseCallback$1$1.apply(KafkaApis.scala:569) 
at kafka.server.KafkaApis$$anonfun$sendResponseMaybeThrottle$1.apply$mcVI$sp(KafkaApis.scala:2034) 
at kafka.server.ClientRequestQuotaManager.maybeRecordAndThrottle(ClientRequestQuotaManager.scala:52) 
at kafka.server.KafkaApis.sendResponseMaybeThrottle(KafkaApis.scala:2033) 
at kafka.server.KafkaApis.kafka$server$KafkaApis$$fetchResponseCallback$1(KafkaApis.scala:569) 
at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$processResponseCallback$1$1.apply$mcVI$sp(KafkaApis.scala:588) 
at kafka.server.ClientQuotaManager.maybeRecordAndThrottle(ClientQuotaManager.scala:175) 
at kafka.server.KafkaApis.kafka$server$KafkaApis$$processResponseCallback$1(KafkaApis.scala:587) 
at kafka.server.KafkaApis$$anonfun$handleFetchRequest$3.apply(KafkaApis.scala:604) 
at kafka.server.KafkaApis$$anonfun$handleFetchRequest$3.apply(KafkaApis.scala:604) 
at kafka.server.ReplicaManager.fetchMessages(ReplicaManager.scala:820) 
at kafka.server.KafkaApis.handleFetchRequest(KafkaApis.scala:596) 
at kafka.server.KafkaApis.handle(KafkaApis.scala:100) 
at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:65) 
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13149547">KAFKA-6739</key>
            <summary>Down-conversion fails for records with headers</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dhruvilshah">Dhruvil Shah</assignee>
                                    <reporter username="Koelli">Koelli Mungee</reporter>
                        <labels>
                    </labels>
                <created>Mon, 2 Apr 2018 18:45:38 +0000</created>
                <updated>Thu, 31 Oct 2019 01:18:58 +0000</updated>
                            <resolved>Tue, 3 Apr 2018 17:54:04 +0000</resolved>
                                    <version>1.0.0</version>
                                    <fixVersion>1.0.2</fixVersion>
                    <fixVersion>1.1.1</fixVersion>
                    <fixVersion>2.0.0</fixVersion>
                                    <component>core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="16423302" author="githubbot" created="Tue, 3 Apr 2018 00:01:40 +0000"  >&lt;p&gt;dhruvilshah3 opened a new pull request #4813: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6739&quot; title=&quot;Down-conversion fails for records with headers&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6739&quot;&gt;&lt;del&gt;KAFKA-6739&lt;/del&gt;&lt;/a&gt;: Ignore the presence of headers when down-converting from V2 to V1/V0&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4813&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4813&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Because V1/V0 message formats do not expect a header, ignore their presence when down-converting V2 messages that contain headers.&lt;br/&gt;
   Added a test-case to verify down-conversion sanity in presence of headers.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16424336" author="githubbot" created="Tue, 3 Apr 2018 17:39:23 +0000"  >&lt;p&gt;hachikuji closed pull request #4813: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6739&quot; title=&quot;Down-conversion fails for records with headers&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6739&quot;&gt;&lt;del&gt;KAFKA-6739&lt;/del&gt;&lt;/a&gt;: Ignore the presence of headers when down-converting from V2 to V1/V0&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4813&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4813&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/clients/src/main/java/org/apache/kafka/common/record/AbstractRecords.java b/clients/src/main/java/org/apache/kafka/common/record/AbstractRecords.java&lt;br/&gt;
index 2452798d485..89a5413e00c 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/common/record/AbstractRecords.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/common/record/AbstractRecords.java&lt;br/&gt;
@@ -130,8 +130,13 @@ private MemoryRecordsBuilder convertRecordBatch(byte magic, ByteBuffer buffer, R&lt;/p&gt;

&lt;p&gt;         MemoryRecordsBuilder builder = MemoryRecords.builder(buffer, magic, batch.compressionType(),&lt;br/&gt;
                 timestampType, recordBatchAndRecords.baseOffset, logAppendTime);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for (Record record : recordBatchAndRecords.records)&lt;/li&gt;
	&lt;li&gt;builder.append(record);&lt;br/&gt;
+        for (Record record : recordBatchAndRecords.records) 
{
+            // Down-convert this record. Ignore headers when down-converting to V0 and V1 since they are not supported
+            if (magic &amp;gt; RecordBatch.MAGIC_VALUE_V1)
+                builder.append(record);
+            else
+                builder.appendWithOffset(record.offset(), record.timestamp(), record.key(), record.value());
+        }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         builder.close();&lt;br/&gt;
         return builder;&lt;br/&gt;
diff --git a/clients/src/test/java/org/apache/kafka/common/record/FileRecordsTest.java b/clients/src/test/java/org/apache/kafka/common/record/FileRecordsTest.java&lt;br/&gt;
index 53ac2003586..fdd3ede16cc 100644&lt;br/&gt;
&amp;#8212; a/clients/src/test/java/org/apache/kafka/common/record/FileRecordsTest.java&lt;br/&gt;
+++ b/clients/src/test/java/org/apache/kafka/common/record/FileRecordsTest.java&lt;br/&gt;
@@ -17,6 +17,8 @@&lt;br/&gt;
 package org.apache.kafka.common.record;&lt;/p&gt;

&lt;p&gt; import org.apache.kafka.common.KafkaException;&lt;br/&gt;
+import org.apache.kafka.common.header.Header;&lt;br/&gt;
+import org.apache.kafka.common.header.internals.RecordHeader;&lt;br/&gt;
 import org.apache.kafka.common.utils.MockTime;&lt;br/&gt;
 import org.apache.kafka.common.utils.Time;&lt;br/&gt;
 import org.apache.kafka.common.utils.Utils;&lt;br/&gt;
@@ -40,6 +42,7 @@&lt;br/&gt;
 import static org.junit.Assert.assertFalse;&lt;br/&gt;
 import static org.junit.Assert.assertTrue;&lt;br/&gt;
 import static org.junit.Assert.fail;&lt;br/&gt;
+import static org.junit.Assert.assertArrayEquals;&lt;/p&gt;

&lt;p&gt; public class FileRecordsTest {&lt;/p&gt;

&lt;p&gt;@@ -358,6 +361,11 @@ public void testConversion() throws IOException {&lt;/p&gt;

&lt;p&gt;     private void doTestConversion(CompressionType compressionType, byte toMagic) throws IOException {&lt;br/&gt;
         List&amp;lt;Long&amp;gt; offsets = asList(0L, 2L, 3L, 9L, 11L, 15L, 16L, 17L, 22L, 24L);&lt;br/&gt;
+&lt;br/&gt;
+        Header[] headers = &lt;/p&gt;
{new RecordHeader(&quot;headerKey1&quot;, &quot;headerValue1&quot;.getBytes()),
+                            new RecordHeader(&quot;headerKey2&quot;, &quot;headerValue2&quot;.getBytes()),
+                            new RecordHeader(&quot;headerKey3&quot;, &quot;headerValue3&quot;.getBytes())}
&lt;p&gt;;&lt;br/&gt;
+&lt;br/&gt;
         List&amp;lt;SimpleRecord&amp;gt; records = asList(&lt;br/&gt;
                 new SimpleRecord(1L, &quot;k1&quot;.getBytes(), &quot;hello&quot;.getBytes()),&lt;br/&gt;
                 new SimpleRecord(2L, &quot;k2&quot;.getBytes(), &quot;goodbye&quot;.getBytes()),&lt;br/&gt;
@@ -366,9 +374,10 @@ private void doTestConversion(CompressionType compressionType, byte toMagic) thr&lt;br/&gt;
                 new SimpleRecord(5L, &quot;k5&quot;.getBytes(), &quot;hello again&quot;.getBytes()),&lt;br/&gt;
                 new SimpleRecord(6L, &quot;k6&quot;.getBytes(), &quot;I sense indecision&quot;.getBytes()),&lt;br/&gt;
                 new SimpleRecord(7L, &quot;k7&quot;.getBytes(), &quot;what now&quot;.getBytes()),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new SimpleRecord(8L, &quot;k8&quot;.getBytes(), &quot;running out&quot;.getBytes()),&lt;br/&gt;
+                new SimpleRecord(8L, &quot;k8&quot;.getBytes(), &quot;running out&quot;.getBytes(), headers),&lt;br/&gt;
                 new SimpleRecord(9L, &quot;k9&quot;.getBytes(), &quot;ok, almost done&quot;.getBytes()),&lt;/li&gt;
	&lt;li&gt;new SimpleRecord(10L, &quot;k10&quot;.getBytes(), &quot;finally&quot;.getBytes()));&lt;br/&gt;
+                new SimpleRecord(10L, &quot;k10&quot;.getBytes(), &quot;finally&quot;.getBytes(), headers));&lt;br/&gt;
+        assertEquals(&quot;incorrect test setup&quot;, offsets.size(), records.size());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         ByteBuffer buffer = ByteBuffer.allocate(1024);&lt;br/&gt;
         MemoryRecordsBuilder builder = MemoryRecords.builder(buffer, RecordBatch.MAGIC_VALUE_V0, compressionType,&lt;br/&gt;
@@ -452,6 +461,7 @@ private void verifyConvertedRecords(List&amp;lt;SimpleRecord&amp;gt; initialRecords,&lt;br/&gt;
                     assertEquals(&quot;Timestamp should not change&quot;, initialRecords.get&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/information.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.timestamp(), record.timestamp());&lt;br/&gt;
                     assertFalse(record.hasTimestampType(TimestampType.CREATE_TIME));&lt;br/&gt;
                     assertFalse(record.hasTimestampType(TimestampType.NO_TIMESTAMP_TYPE));&lt;br/&gt;
+                    assertArrayEquals(&quot;Headers should not change&quot;, initialRecords.get&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/information.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.headers(), record.headers());&lt;br/&gt;
                 }&lt;br/&gt;
                 i += 1;&lt;br/&gt;
             }&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16503516" author="tgbeck" created="Wed, 6 Jun 2018 16:12:14 +0000"  >&lt;p&gt;Is there a way to fix this issue without the patch?&lt;/p&gt;

&lt;p&gt;From my understanding this is caused by the existing segments which still contain the old message format. As this is not an issue for new brokers. Is there a way to upgrade the existing segments?&lt;/p&gt;</comment>
                            <comment id="16503733" author="dhruvilshah" created="Wed, 6 Jun 2018 18:40:33 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tgbeck&quot; class=&quot;user-hover&quot; rel=&quot;tgbeck&quot;&gt;tgbeck&lt;/a&gt; this issue would reproduce when brokers&#160;contain V2 message format with headers, and consumers are on 0.10 or older versions. V2 message format was introduced in 0.11. A possible workaround could be to upgrade the consumers. When consumers understand V2 message format, we do not require any down-conversion on the broker.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13264180">KAFKA-9092</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13006934">KAFKA-4208</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 23 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3s23r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>