<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:10:42 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6937] In-sync replica delayed during fetch if replica throttle is exceeded</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6937</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;When&#160;replication throttling is enabled,&#160;in-sync replica&apos;s traffic should never be throttled. However, in DelayedFetch.tryComplete(), we incorrectly delay the completion of an in-sync replica fetch request if replication throttling is engaged.&#160;&lt;/p&gt;

&lt;p&gt;The impact is that the producer may see increased latency if acks = all. The delivery of the message to the consumer may also be delayed.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13161592">KAFKA-6937</key>
            <summary>In-sync replica delayed during fetch if replica throttle is exceeded</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="junrao">Jun Rao</assignee>
                                    <reporter username="junrao">Jun Rao</reporter>
                        <labels>
                    </labels>
                <created>Wed, 23 May 2018 21:33:55 +0000</created>
                <updated>Fri, 25 May 2018 23:34:30 +0000</updated>
                            <resolved>Fri, 25 May 2018 23:34:30 +0000</resolved>
                                    <version>0.11.0.1</version>
                    <version>1.0.1</version>
                    <version>1.1.0</version>
                                    <fixVersion>1.0.2</fixVersion>
                    <fixVersion>1.1.1</fixVersion>
                    <fixVersion>2.0.0</fixVersion>
                                    <component>core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="16488077" author="githubbot" created="Wed, 23 May 2018 21:39:49 +0000"  >&lt;p&gt;junrao opened a new pull request #5074: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6937&quot; title=&quot;In-sync replica delayed during fetch if replica throttle is exceeded&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6937&quot;&gt;&lt;del&gt;KAFKA-6937&lt;/del&gt;&lt;/a&gt;: In-sync replica delayed during fetch if replica throttle &#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5074&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5074&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   &#8230;is exceeded&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Added a unit test.&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16491364" author="klafferty" created="Fri, 25 May 2018 23:00:21 +0000"  >&lt;p&gt;I was&#160;able to test this patch today, and it looks good:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;I kicked off a full reassignment on a topic with a single partition while running constant produce traffic against the cluster. I started the&#160;reassignment with a throttle smaller than the baseline outgoing replication for the leader, and the outgoing replication was unchanged, starving out the out-of-sync replicas.&lt;/li&gt;
	&lt;li&gt;I then increased the throttle beyond baseline replication, but not high enough for the out-of-sync replicas to catch up, and the out-of-sync replicas were able to start replicating data, while the in-sync replicas&apos; rate was unaffected. The total output was limited to the throttle rate.&lt;/li&gt;
	&lt;li&gt;Increasing the throttle further allowed the out-of-sync replicas to catch up.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;One thing that was slightly unexpected (but which seems to be the intended behavior) is that the in-sync replicas counted against the replication quota, even though they&#160;cannot get throttled.&lt;/p&gt;</comment>
                            <comment id="16491376" author="junrao" created="Fri, 25 May 2018 23:14:46 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=klafferty&quot; class=&quot;user-hover&quot; rel=&quot;klafferty&quot;&gt;klafferty&lt;/a&gt;, thanks for testing this out. Yes, the reason for including the in-sync replica traffic in the quota is to bound the total replication traffic. Otherwise,&#160;the total replication traffic will be in-sync replication traffic + replication quota, which can vary as out of sync replicas become in-sync.&lt;/p&gt;</comment>
                            <comment id="16491384" author="githubbot" created="Fri, 25 May 2018 23:19:15 +0000"  >&lt;p&gt;junrao closed pull request #5074: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6937&quot; title=&quot;In-sync replica delayed during fetch if replica throttle is exceeded&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6937&quot;&gt;&lt;del&gt;KAFKA-6937&lt;/del&gt;&lt;/a&gt;: In-sync replica delayed during fetch if replica throttle &#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5074&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5074&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/core/src/main/scala/kafka/server/DelayedFetch.scala b/core/src/main/scala/kafka/server/DelayedFetch.scala&lt;br/&gt;
index e478053792d..49bea5a6c1b 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/server/DelayedFetch.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/server/DelayedFetch.scala&lt;br/&gt;
@@ -77,7 +77,6 @@ class DelayedFetch(delayMs: Long,&lt;br/&gt;
    */&lt;br/&gt;
   override def tryComplete() : Boolean = {&lt;br/&gt;
     var accumulatedSize = 0&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;var accumulatedThrottledSize = 0&lt;br/&gt;
     fetchMetadata.fetchPartitionStatus.foreach 
{
       case (topicPartition, fetchStatus) =&amp;gt;
         val fetchOffset = fetchStatus.startOffsetMetadata
@@ -110,9 +109,7 @@ class DelayedFetch(delayMs: Long,
               }
&lt;p&gt; else if (fetchOffset.messageOffset &amp;lt; endOffset.messageOffset) &lt;/p&gt;
{
                 // we take the partition fetch size as upper bound when accumulating the bytes (skip if a throttled partition)
                 val bytesAvailable = math.min(endOffset.positionDiff(fetchOffset), fetchStatus.fetchInfo.maxBytes)
-                if (quota.isThrottled(topicPartition))
-                  accumulatedThrottledSize += bytesAvailable
-                else
+                if (!replicaManager.shouldLeaderThrottle(quota, topicPartition, fetchMetadata.replicaId))
                   accumulatedSize += bytesAvailable
               }
&lt;p&gt;             }&lt;br/&gt;
@@ -131,9 +128,8 @@ class DelayedFetch(delayMs: Long,&lt;br/&gt;
     }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // Case D&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (accumulatedSize &amp;gt;= fetchMetadata.fetchMinBytes&lt;/li&gt;
	&lt;li&gt;&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; ((accumulatedSize + accumulatedThrottledSize) &amp;gt;= fetchMetadata.fetchMinBytes &amp;amp;&amp;amp; !quota.isQuotaExceeded()))&lt;/th&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/li&gt;
	&lt;li&gt;forceComplete()&lt;br/&gt;
+    if (accumulatedSize &amp;gt;= fetchMetadata.fetchMinBytes)&lt;br/&gt;
+       forceComplete()&lt;br/&gt;
     else&lt;br/&gt;
       false&lt;br/&gt;
   }&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/server/KafkaApis.scala b/core/src/main/scala/kafka/server/KafkaApis.scala&lt;br/&gt;
index 5532bf1e9a8..8c17a82089d 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/main/scala/kafka/server/KafkaApis.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/server/KafkaApis.scala&lt;br/&gt;
@@ -666,6 +666,8 @@ class KafkaApis(val requestChannel: RequestChannel,&lt;br/&gt;
     override def remove() = throw new UnsupportedOperationException()&lt;br/&gt;
   }&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+  // Traffic from both in-sync and out of sync replicas are accounted for in replication quota to ensure total replication&lt;br/&gt;
+  // traffic doesn&apos;t exceed quota.&lt;br/&gt;
   private def sizeOfThrottledPartitions(versionId: Short,&lt;br/&gt;
                                         unconvertedResponse: FetchResponse,&lt;br/&gt;
                                         quota: ReplicationQuotaManager): Int = {&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala b/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala&lt;br/&gt;
index 6805d77d47f..68fa8734b78 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala&lt;br/&gt;
@@ -126,6 +126,9 @@ class ReplicaFetcherThread(name: String,&lt;br/&gt;
     replica.maybeIncrementLogStartOffset(leaderLogStartOffset)&lt;br/&gt;
     if (isTraceEnabled)&lt;br/&gt;
       trace(s&quot;Follower set replica high watermark for partition $topicPartition to $followerHighWatermark&quot;)&lt;br/&gt;
+&lt;br/&gt;
+    // Traffic from both in-sync and out of sync replicas are accounted for in replication quota to ensure total replication&lt;br/&gt;
+    // traffic doesn&apos;t exceed quota.&lt;br/&gt;
     if (quota.isThrottled(topicPartition))&lt;br/&gt;
       quota.record(records.sizeInBytes)&lt;br/&gt;
     replicaMgr.brokerTopicStats.updateReplicationBytesIn(records.sizeInBytes)&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/server/ReplicaManagerQuotasTest.scala b/core/src/test/scala/unit/kafka/server/ReplicaManagerQuotasTest.scala&lt;br/&gt;
index 334321ae230..c6efca573de 100644&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/server/ReplicaManagerQuotasTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/server/ReplicaManagerQuotasTest.scala&lt;br/&gt;
@@ -148,6 +148,38 @@ class ReplicaManagerQuotasTest &lt;/p&gt;
{
       fetch.find(_._1 == topicPartition2).get._2.info.records.batches.asScala.size)
   }

&lt;p&gt;+  @Test&lt;br/&gt;
+  def testCompleteInDelayedFetchWithReplicaThrottling(): Unit = {&lt;br/&gt;
+    // Set up DelayedFetch where there is data to return to a follower replica, either in-sync or out of sync&lt;br/&gt;
+    def setupDelayedFetch(isReplicaInSync: Boolean): DelayedFetch = {&lt;br/&gt;
+      val logOffsetMetadata = new LogOffsetMetadata(messageOffset = 100L, segmentBaseOffset = 0L, relativePositionInSegment = 500)&lt;br/&gt;
+      val replica = EasyMock.createMock(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;Replica&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+      EasyMock.expect(replica.logEndOffset).andReturn(logOffsetMetadata).anyTimes()&lt;br/&gt;
+      EasyMock.replay(replica)&lt;br/&gt;
+&lt;br/&gt;
+      val replicaManager = EasyMock.createMock(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;ReplicaManager&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+      EasyMock.expect(replicaManager.getLeaderReplicaIfLocal(EasyMock.anyObject&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition&amp;#93;&lt;/span&gt;)).andReturn(replica).anyTimes()&lt;br/&gt;
+      EasyMock.expect(replicaManager.shouldLeaderThrottle(EasyMock.anyObject&lt;span class=&quot;error&quot;&gt;&amp;#91;ReplicaQuota&amp;#93;&lt;/span&gt;, EasyMock.anyObject&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition&amp;#93;&lt;/span&gt;, EasyMock.anyObject&lt;span class=&quot;error&quot;&gt;&amp;#91;Int&amp;#93;&lt;/span&gt;))&lt;br/&gt;
+        .andReturn(!isReplicaInSync).anyTimes()&lt;br/&gt;
+      EasyMock.replay(replicaManager)&lt;br/&gt;
+&lt;br/&gt;
+      val tp = new TopicPartition(&quot;t1&quot;, 0)&lt;br/&gt;
+      val fetchParititonStatus = new FetchPartitionStatus(new LogOffsetMetadata(messageOffset = 50L, segmentBaseOffset = 0L,&lt;br/&gt;
+        relativePositionInSegment = 250), new PartitionData(50, 0, 1))&lt;br/&gt;
+      val fetchMetadata = new FetchMetadata(fetchMinBytes = 1, fetchMaxBytes = 1000, hardMaxBytesLimit = true, fetchOnlyLeader = true,&lt;br/&gt;
+        fetchOnlyCommitted = false, isFromFollower = true, replicaId = 1, fetchPartitionStatus = List((tp, fetchParititonStatus)))&lt;br/&gt;
+      new DelayedFetch(delayMs = 600, fetchMetadata = fetchMetadata, replicaManager = replicaManager,&lt;br/&gt;
+        quota = null, isolationLevel = IsolationLevel.READ_UNCOMMITTED, responseCallback = null) {&lt;br/&gt;
+        override def forceComplete(): Boolean = &lt;/p&gt;
{
+          true
+        }
&lt;p&gt;+      }&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    assertTrue(&quot;In sync replica should complete&quot;, setupDelayedFetch(isReplicaInSync = true).tryComplete())&lt;br/&gt;
+    assertFalse(&quot;Out of sync replica should not complete&quot;, setupDelayedFetch(isReplicaInSync = false).tryComplete())&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
   def setUpMocks(fetchInfo: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;(TopicPartition, PartitionData)&amp;#93;&lt;/span&gt;, record: SimpleRecord = this.record, bothReplicasInSync: Boolean = false) {&lt;br/&gt;
     val zkClient = EasyMock.createMock(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;KafkaZkClient&amp;#93;&lt;/span&gt;)&lt;br/&gt;
     val scheduler = createNiceMock(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;KafkaScheduler&amp;#93;&lt;/span&gt;)&lt;br/&gt;
@@ -208,7 +240,8 @@ class ReplicaManagerQuotasTest {&lt;/p&gt;

&lt;p&gt;   @After&lt;br/&gt;
   def tearDown() &lt;/p&gt;
{
-    replicaManager.shutdown(false)
+    if (replicaManager != null)
+      replicaManager.shutdown(false)
     metrics.close()
   }





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16491399" author="junrao" created="Fri, 25 May 2018 23:34:30 +0000"  >&lt;p&gt;Merged the PR.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 25 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3u39j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>