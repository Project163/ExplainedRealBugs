<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:35:08 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-372] Consumer doesn&apos;t receive all data if there are multiple segment files</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-372</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;This issue happens inconsistently but could be reproduced by following the steps below (repeat step 4 a few times to reproduce it):&lt;/p&gt;

&lt;p&gt;1. Check out 0.8 branch (currently reproducible with rev. 1352634)&lt;/p&gt;

&lt;p&gt;2. Apply kafka-306-v4.patch&lt;/p&gt;

&lt;p&gt;3. Please note that the log.file.size is set to 10000000 in system_test/broker_failure/config/server_*.properties (small enough to trigger multi segment files)&lt;/p&gt;

&lt;p&gt;4. Under the directory &amp;lt;kafka home&amp;gt;/system_test/broker_failure, execute command:&lt;br/&gt;
$ bin/run-test.sh 20 0&lt;/p&gt;

&lt;p&gt;5. After the test is completed, the result will probably look like the following:&lt;/p&gt;

&lt;p&gt;========================================================&lt;br/&gt;
no. of messages published            : 14000&lt;br/&gt;
producer unique msg rec&apos;d            : 14000&lt;br/&gt;
source consumer msg rec&apos;d            : 7271&lt;br/&gt;
source consumer unique msg rec&apos;d     : 7271&lt;br/&gt;
mirror consumer msg rec&apos;d            : 6960&lt;br/&gt;
mirror consumer unique msg rec&apos;d     : 6960&lt;br/&gt;
total source/mirror duplicate msg    : 0&lt;br/&gt;
source/mirror uniq msg count diff    : 311&lt;br/&gt;
========================================================&lt;/p&gt;

&lt;p&gt;6. By checking the kafka log files, the sum of the sizes of the source cluster segments files are equal to those in the target cluster.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;/tmp&amp;#93;&lt;/span&gt; $  find kafka* -name *.kafka -ls&lt;/p&gt;

&lt;p&gt;18620155 9860 &lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung    eng      10096535 Jun 21 11:09 kafka-source3-logs/test01-0/00000000000000000000.kafka&lt;br/&gt;
18620161 9772 &lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung    eng      10004418 Jun 21 11:11 kafka-source3-logs/test01-0/00000000000020105286.kafka&lt;br/&gt;
18620160 9776 &lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung    eng      10008751 Jun 21 11:10 kafka-source3-logs/test01-0/00000000000010096535.kafka&lt;br/&gt;
18620162 4708 &lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung    eng       4819067 Jun 21 11:11 kafka-source3-logs/test01-0/00000000000030109704.kafka&lt;br/&gt;
19406431 9920 &lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung    eng      10157685 Jun 21 11:10 kafka-target2-logs/test01-0/00000000000010335039.kafka&lt;br/&gt;
19406429 10096 &lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung    eng      10335039 Jun 21 11:09 kafka-target2-logs/test01-0/00000000000000000000.kafka&lt;br/&gt;
19406432 10300 &lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung    eng      10544850 Jun 21 11:11 kafka-target2-logs/test01-0/00000000000020492724.kafka&lt;br/&gt;
19406433 3800 &lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung    eng       3891197 Jun 21 11:12 kafka-target2-logs/test01-0/00000000000031037574.kafka&lt;/p&gt;

&lt;p&gt;7. If the log.file.size in target cluster is configured to a very large value such that there is only 1 data file, the result would look like this:&lt;/p&gt;

&lt;p&gt;========================================================&lt;br/&gt;
no. of messages published            : 14000&lt;br/&gt;
producer unique msg rec&apos;d            : 14000&lt;br/&gt;
source consumer msg rec&apos;d            : 7302&lt;br/&gt;
source consumer unique msg rec&apos;d     : 7302&lt;br/&gt;
mirror consumer msg rec&apos;d            : 13750&lt;br/&gt;
mirror consumer unique msg rec&apos;d     : 13750&lt;br/&gt;
total source/mirror duplicate msg    : 0&lt;br/&gt;
source/mirror uniq msg count diff    : -6448&lt;br/&gt;
========================================================&lt;/p&gt;

&lt;p&gt;8. The log files are like these:&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;/tmp&amp;#93;&lt;/span&gt; $ find kafka* -name *.kafka -ls&lt;/p&gt;

&lt;p&gt;18620160 9840 &lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung    eng      10075058 Jun 21 11:24 kafka-source2-logs/test01-0/00000000000010083679.kafka&lt;br/&gt;
18620155 9848 &lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung    eng      10083679 Jun 21 11:23 kafka-source2-logs/test01-0/00000000000000000000.kafka&lt;br/&gt;
18620162 4484 &lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung    eng       4589474 Jun 21 11:26 kafka-source2-logs/test01-0/00000000000030269045.kafka&lt;br/&gt;
18620161 9876 &lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung    eng      10110308 Jun 21 11:25 kafka-source2-logs/test01-0/00000000000020158737.kafka&lt;br/&gt;
19406429 34048 &lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung    eng      34858519 Jun 21 11:26 kafka-target3-logs/test01-0/00000000000000000000.kafka&lt;/p&gt;</description>
                <environment></environment>
        <key id="12595466">KAFKA-372</key>
            <summary>Consumer doesn&apos;t receive all data if there are multiple segment files</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="jfung">John Fung</reporter>
                        <labels>
                    </labels>
                <created>Thu, 21 Jun 2012 18:30:08 +0000</created>
                <updated>Tue, 26 Jun 2012 16:24:14 +0000</updated>
                            <resolved>Tue, 26 Jun 2012 15:47:21 +0000</resolved>
                                    <version>0.8.0</version>
                                                    <component>core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="13400274" author="jfung" created="Mon, 25 Jun 2012 04:11:22 +0000"  >&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;Uploaded a patch with a simplified scenario to reproduce the data loss in multi segment files.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;This patch provides a script &quot;run-test-debug.sh&quot; to do the following:&lt;br/&gt;
1. Start 1 broker&lt;br/&gt;
2. Start a modified version of Producer to send 300 messages with user specified message string length (500 chars will reproduce the issue while 50 chars will not). This producer produces messages with sequence ID and send the messages in sequence starting from 1, 2, 3, &#8230; Etc.&lt;br/&gt;
3. Start ConsoleConsumer to receive data&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;To reproduce the issue, under &amp;lt;kafka home&amp;gt;/system_test/broker_failure, execute the following command:&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;$ bin/run-test-debug.sh 500 (which means each message string is 500 chars long)&lt;/p&gt;

&lt;p&gt;The consumer only receives the first 120 messages. (This is verified by checking kafka.tools.DumpLogSegments.&lt;br/&gt;
========================================================&lt;br/&gt;
no. of messages published            : 300&lt;br/&gt;
producer unique msg rec&apos;d            : 300&lt;br/&gt;
source consumer msg rec&apos;d            : 120&lt;br/&gt;
source consumer unique msg rec&apos;d     : 120&lt;br/&gt;
========================================================&lt;/p&gt;

&lt;p&gt;The number of segment files are &lt;/p&gt;

&lt;p&gt;$ ls -l /tmp/kafka-source1-logs/test01-0/&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung  wheel  10431 Jun 24 20:59:21 2012 00000000000000000000.kafka&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung  wheel  10440 Jun 24 20:59:22 2012 00000000000000010431.kafka&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung  wheel  10440 Jun 24 20:59:23 2012 00000000000000020871.kafka&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung  wheel  10440 Jun 24 20:59:24 2012 00000000000000031311.kafka&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung  wheel  10441 Jun 24 20:59:26 2012 00000000000000041751.kafka&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung  wheel  10460 Jun 24 20:59:27 2012 00000000000000052192.kafka&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung  wheel  10460 Jun 24 20:59:28 2012 00000000000000062652.kafka&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung  wheel  10460 Jun 24 20:59:29 2012 00000000000000073112.kafka&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung  wheel  10460 Jun 24 20:59:31 2012 00000000000000083572.kafka&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung  wheel  10460 Jun 24 20:59:32 2012 00000000000000094032.kafka&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung  wheel  10460 Jun 24 20:59:33 2012 00000000000000104492.kafka&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung  wheel  10460 Jun 24 20:59:34 2012 00000000000000114952.kafka&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung  wheel  10460 Jun 24 20:59:35 2012 00000000000000125412.kafka&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung  wheel  10460 Jun 24 20:59:37 2012 00000000000000135872.kafka&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung  wheel  10460 Jun 24 20:59:38 2012 00000000000000146332.kafka&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung  wheel      0 Jun 24 20:59:38 2012 00000000000000156792.kafka&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 jfung  wheel      8 Jun 24 21:00:08 2012 highwatermark&lt;/p&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;However, if the length of each message string is changed to a lower value 50, the issue won&apos;t be showing:&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;$ bin/run-test-debug.sh 50&lt;/p&gt;

&lt;p&gt;The consumer receives all data:&lt;br/&gt;
========================================================&lt;br/&gt;
no. of messages published            : 300&lt;br/&gt;
producer unique msg rec&apos;d            : 300&lt;br/&gt;
source consumer msg rec&apos;d            : 300&lt;br/&gt;
source consumer unique msg rec&apos;d     : 300&lt;br/&gt;
========================================================&lt;/p&gt;

&lt;p&gt;The number of segment files are&lt;/p&gt;

&lt;p&gt;$  ls -l /tmp/kafka-source1-logs/test01-0&lt;br/&gt;
total 64&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-  1 jfung  wheel  10039 Jun 24 20:29:26 2012 00000000000000000000.kafka&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-  1 jfung  wheel  10001 Jun 24 20:29:34 2012 00000000000000010039.kafka&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-  1 jfung  wheel   1752 Jun 24 20:29:36 2012 00000000000000020040.kafka&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-  1 jfung  wheel      8 Jun 24 20:30:06 2012 highwatermark&lt;/p&gt;</comment>
                            <comment id="13401080" author="junrao" created="Tue, 26 Jun 2012 00:56:03 +0000"  >&lt;p&gt;There were several issues that caused the problem.&lt;/p&gt;

&lt;p&gt;1. Log.nextAppendOffset() calls flush each time. Since this method is called for every produce request, we force a disk flush for every produce request independent of the flush interval in the broker config. This makes producers very slow.&lt;/p&gt;

&lt;p&gt;2. The default value for MaxFetchWaitMs in consumer config is 3 secs, which is too long.&lt;/p&gt;

&lt;p&gt;3. The script runs console consumer in background and only waits for 20 secs, which is too short. What we should do is to run console consumer in foreground and wait until it finishes (since it has consumer timeout).&lt;/p&gt;

&lt;p&gt;Attach patch v1 that fixes items 1 and 2. The test now passes. However, we should address item 3 in the script too.&lt;/p&gt;</comment>
                            <comment id="13401464" author="jfung" created="Tue, 26 Jun 2012 15:47:22 +0000"  >&lt;p&gt;Thanks Jun. It is working correctly after applying kafka-372-v1.patch.&lt;/p&gt;</comment>
                            <comment id="13401491" author="junrao" created="Tue, 26 Jun 2012 16:24:14 +0000"  >&lt;p&gt;Thanks John for reviewing the patch. Committed to 0.8.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12533416" name="kafka-372_v1.patch" size="5565" author="junrao" created="Tue, 26 Jun 2012 00:56:03 +0000"/>
                            <attachment id="12533252" name="multi_seg_files_data_loss_debug.patch" size="15442" author="jfung" created="Mon, 25 Jun 2012 04:11:21 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>248186</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            13 years, 22 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i09m4f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>54017</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>