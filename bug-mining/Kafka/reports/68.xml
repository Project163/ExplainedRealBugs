<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:35:22 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-385] RequestPurgatory enhancements - expire/checkSatisfy issue; add jmx beans</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-385</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;As discussed in &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-353&quot; title=&quot;tie producer-side ack with high watermark and progress of replicas&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-353&quot;&gt;&lt;del&gt;KAFKA-353&lt;/del&gt;&lt;/a&gt;:&lt;br/&gt;
1 - There is potential for a client-side race condition in the implementations of expire and checkSatisfied. We can just synchronize on the DelayedItem.&lt;br/&gt;
2 - Would be good to add jmx beans to facilitate monitoring RequestPurgatory stats.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12596467">KAFKA-385</key>
            <summary>RequestPurgatory enhancements - expire/checkSatisfy issue; add jmx beans</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jjkoshy">Joel Jacob Koshy</assignee>
                                    <reporter username="jjkoshy">Joel Jacob Koshy</reporter>
                        <labels>
                            <label>bugs</label>
                    </labels>
                <created>Fri, 29 Jun 2012 22:40:23 +0000</created>
                <updated>Thu, 16 Aug 2012 23:35:24 +0000</updated>
                            <resolved>Thu, 16 Aug 2012 21:28:56 +0000</resolved>
                                                    <fixVersion>0.8.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="13430739" author="jjkoshy" created="Tue, 7 Aug 2012 23:48:16 +0000"  >&lt;p&gt;Summary of changes and notes:&lt;/p&gt;

&lt;p&gt;1 - Fixed the synchronization issue (raised in &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-353&quot; title=&quot;tie producer-side ack with high watermark and progress of replicas&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-353&quot;&gt;&lt;del&gt;KAFKA-353&lt;/del&gt;&lt;/a&gt;) between&lt;br/&gt;
  checkSatisfied and expire by synchronizing on the DelayedItem.&lt;/p&gt;

&lt;p&gt;2 - Added request purgatory metrics using the metrics-core library. Also&lt;br/&gt;
  added support for csv/ganglia/graphite reporters which I think is useful -&lt;br/&gt;
  e.g., I attached a graphite dashboard that was pretty easy to whip up. It&lt;br/&gt;
  should be a breeze to use metrics-core for other stats in Kafka.&lt;/p&gt;

&lt;p&gt;3 - This brings in dependencies on metrics and slf4j, both with Apache&lt;br/&gt;
  compatible licenses. I don&apos;t know of any specific best-practices in using&lt;br/&gt;
  metrics-core as I have not used it before, so it would be great if people&lt;br/&gt;
  with experience using it glance over this patch.&lt;/p&gt;

&lt;p&gt;4 - It&apos;s a bit hard to tell right now which metrics are useful and which are&lt;br/&gt;
  pointless/redundant.  We can iron that out over time.&lt;/p&gt;

&lt;p&gt;5 - Some metrics are only global and both global and per-key (which I think&lt;br/&gt;
  is useful to have, e.g., to get a quick view of which partitions are&lt;br/&gt;
  slower).  E.g., it helped to see (in the attached screen shots) that fetch&lt;br/&gt;
  requests were all expiring - and it turned out to be a bug in how&lt;br/&gt;
  DelayedFetch requests from followers are checked for satisfaction.  The&lt;br/&gt;
  issue is that maybeUnblockDelayedFetch is only called if required acks is&lt;br/&gt;
  0/1. We need to call it always - in the FetchRequestPurgatory&lt;br/&gt;
  checkSatisfied method, if it is a follower request then we need to use&lt;br/&gt;
  logendoffset to determine the available bytes to the fetch request, and HW&lt;br/&gt;
  if it is a non-follower request. I fixed it to always check&lt;br/&gt;
  availableFetchBytes, but it can be made a little more efficient by having&lt;br/&gt;
  the DelayedFetch request keep track of currently available bytes in each&lt;br/&gt;
  topic-partition key.&lt;/p&gt;

&lt;p&gt;6 - I realized that both the watchersForKey and per-key metrics pools keep&lt;br/&gt;
  growing.  It may be useful to have a simple garbage collector in the Pool&lt;br/&gt;
  class that garbage collects entries that are stale (e.g., due to a&lt;br/&gt;
  leader-change), but this is non-critical.&lt;/p&gt;

&lt;p&gt;7 - I needed to maintain DelayedRequest metrics outside the purgatory:&lt;br/&gt;
  because the purgatory itself is abstract and does not have internal&lt;br/&gt;
  knowledge of delayed requests and their keys. Note that these metrics are&lt;br/&gt;
  for delayed requests - i.e., these metrics are not updated for those&lt;br/&gt;
  requests that are satisfied immediately without going through the&lt;br/&gt;
  purgatory.&lt;/p&gt;

&lt;p&gt;8 - There is one subtlety with producer throughput: I wanted to keep per-key&lt;br/&gt;
  throughput, so the metric is updated on individual key satisfaction. This&lt;br/&gt;
  does not mean that the DelayedProduce itself will be satisfied - i.e,.&lt;br/&gt;
  what the metric reports is an upper-bound since some DelayedProduce&lt;br/&gt;
  requests may have expired.&lt;/p&gt;

&lt;p&gt;9 - I think it is better to wait for Kafka-376 to go in first. In this&lt;br/&gt;
  patch, I hacked a simpler version of that patch - i.e., in&lt;br/&gt;
  availableFetchBytes, I check the logEndOffset instead of the&lt;br/&gt;
  high-watermark. Otherwise, follower fetch requests would see zero&lt;br/&gt;
  available bytes. Of course, this hack now breaks non-follower fetch&lt;br/&gt;
  requests.&lt;/p&gt;

&lt;p&gt;10 - KafkaApis is getting pretty big - I can try and move DelayedMetrics out&lt;br/&gt;
  if that helps although I prefer having it inside since all the&lt;br/&gt;
  DelayedRequests and purgatories are in there.&lt;/p&gt;

&lt;p&gt;11 - There may be some temporary edits to start scripts/log4j that I will&lt;br/&gt;
  revert in the final patch.&lt;/p&gt;

&lt;p&gt;What&apos;s left to do:&lt;/p&gt;

&lt;p&gt;a - This was a rather painful rebase, so I need to review in case I missed&lt;br/&gt;
  something.&lt;/p&gt;

&lt;p&gt;b - Optimization described above: DelayedFetch should keep track of&lt;br/&gt;
  bytesAvailable for each key and FetchRequestPurgatory&apos;s checkSatisfied&lt;br/&gt;
  should take a topic, partition and compute availableBytes for just that&lt;br/&gt;
  key.&lt;/p&gt;

&lt;p&gt;c - The JMX operations to start and stop the reporters are not working&lt;br/&gt;
  properly. I think I understand the issue, but will fix later.&lt;/p&gt;</comment>
                            <comment id="13431475" author="junrao" created="Wed, 8 Aug 2012 22:43:17 +0000"  >&lt;p&gt;Thanks for the patch. Overall, it seems that metrics-core is easy to use. Some comments:&lt;/p&gt;

&lt;p&gt;1. KafkaMetricsGroup.metricName: add a comment on the following statement and explain what it does&lt;br/&gt;
          actualPkg.replaceFirst(&quot;&quot;&quot;\.&quot;&quot;&quot;, &quot;.%s.&quot;.format(ident))&lt;/p&gt;

&lt;p&gt;2. Unused imports: KafkaApis, KafkaConfig&lt;/p&gt;

&lt;p&gt;3. Pool.getAndMaybePut(): This seems to force the caller to create a new value object on each call and in most cases, the new object is not needed.&lt;/p&gt;

&lt;p&gt;4. FetchRequestKey and ProduceRequestKey: can they be shared?&lt;/p&gt;

&lt;p&gt;5. Is it better to put all metrics classes in one package metrics?&lt;/p&gt;

&lt;p&gt;6. It&apos;s useful to have topic level stats. I am wondering if we can just keep stats at the global and the topic level, but not at topic/partition level. &lt;/p&gt;

&lt;p&gt;7. DelayedProducerRequestMetrics,DelayedFetchRequestMetrics : Can we name the stats consistently? Something like FetchSatisfiedTime and ProduceStatisfiedTime,  FetchSatisfiedRequest and ProduceStatisfiedRequest. Also, there is some overlap with the stats in BrokerTopicStat.&lt;/p&gt;

&lt;p&gt;8. ProducerPerformance: Why forcing producer acks to be 2? Shouldn&apos;t that come from the command line?&lt;/p&gt;

&lt;p&gt;9. The changes and the new files in config/: Are they needed?&lt;/p&gt;</comment>
                            <comment id="13431521" author="jjkoshy" created="Thu, 9 Aug 2012 00:57:48 +0000"  >&lt;p&gt;Thanks for the review.&lt;/p&gt;

&lt;p&gt;1. Will do.&lt;/p&gt;

&lt;p&gt;2. Do you remember which class? I can run an optimize imports everywhere, so&lt;br/&gt;
   there may be some noise in the final patch.&lt;/p&gt;

&lt;p&gt;3. Oops - yes that&apos;s true. I&apos;ll fix this to accept a factory method that&lt;br/&gt;
   creates the object if absent.&lt;/p&gt;

&lt;p&gt;4. Yes - I&apos;ll combine them.&lt;/p&gt;

&lt;p&gt;5. I had considered this, but I think it is better to keep only generic    stuff in the metrics package and keep concrete metrics close to where    they are used. I think we can decide this as part of &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-203&quot; title=&quot;Improve Kafka internal metrics&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-203&quot;&gt;&lt;del&gt;KAFKA-203&lt;/del&gt;&lt;/a&gt; since that&lt;br/&gt;
   may result in a more elaborate wrapper around metrics-core than I have&lt;br/&gt;
   now in the kafka.metrics package.&lt;/p&gt;

&lt;p&gt;6/7. The issue is that produce/fetch request stats are asymmetric. E.g.,   per-key expiration stats do not make sense for DelayedFetch requests, but   they do make sense for DelayedProduce requests. Also, the caught-up fetch&lt;br/&gt;
   request rps and duration stats for the producer are updated on a per-key&lt;br/&gt;
   basis so that&apos;s why they are named as such - i.e., it does not exactly   equal the satisfaction time. I can add an additional stat that does track&lt;br/&gt;
   satisfaction time for completely satisfied produce requests. There is&lt;br/&gt;
   &lt;b&gt;some&lt;/b&gt; overlap with BrokerTopicStat but as I mentioned in (7) in my first&lt;br/&gt;
   comment these stats are only account for DelayedRequests. As for topic&lt;br/&gt;
   level stats, throughput stats would help, but are satisfaction/expiration&lt;br/&gt;
   stats (especially with multi-produce) useful since those events occur at&lt;br/&gt;
   the key(partition)-level?&lt;/p&gt;

&lt;p&gt;8. Yes - will revert. This was done before Neha added that option in&lt;br/&gt;
   &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-350&quot; title=&quot;Enable message replication in the presence of controlled failures&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-350&quot;&gt;&lt;del&gt;KAFKA-350&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;9. Not required - I used it for testing only. Will revert.&lt;/p&gt;</comment>
                            <comment id="13431522" author="jjkoshy" created="Thu, 9 Aug 2012 01:00:13 +0000"  >&lt;p&gt;Also, re: my comment concerning the dependency on &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-376&quot; title=&quot;expose different data to fetch requests from the follower replicas and consumer clients&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-376&quot;&gt;&lt;del&gt;KAFKA-376&lt;/del&gt;&lt;/a&gt;: this is not strictly required - &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-350&quot; title=&quot;Enable message replication in the presence of controlled failures&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-350&quot;&gt;&lt;del&gt;KAFKA-350&lt;/del&gt;&lt;/a&gt; actually made a similar temporary fix to use the log end offset instead of hw.&lt;/p&gt;</comment>
                            <comment id="13433337" author="jjkoshy" created="Mon, 13 Aug 2012 17:30:38 +0000"  >
&lt;p&gt;The jira system was down around the time of my last comment and it was not&lt;br/&gt;
sent to the mailing list. That further explains some of these updates.&lt;/p&gt;

&lt;p&gt;1 - Added produce satisfied stats.&lt;br/&gt;
2 - Common request key for fetch/produce.&lt;br/&gt;
3 - Factory method for getAndMaybePut.&lt;br/&gt;
4 - Added doc describing fudged name for KafkaMetricsGroup.&lt;br/&gt;
5 - Fixed the issues with the JMX operations I had earlier.&lt;br/&gt;
6 - Reverted the ProducerPerformance and temporary config changes.&lt;/p&gt;

&lt;p&gt;I decided against doing the optimization for the FetchRequestPurgatory&lt;br/&gt;
checkSatisfied as I don&apos;t think it makes a significant difference, as the&lt;br/&gt;
available bytes computation is pretty much in memory.&lt;/p&gt;

&lt;p&gt;One more comment on the usage of metrics: it is possible to combine&lt;br/&gt;
rate/histogram metrics into a metrics Timer object. I chose not to do this&lt;br/&gt;
because the code turns out a little cleaner by using a meter/histogram, but&lt;br/&gt;
will revisit later.&lt;/p&gt;</comment>
                            <comment id="13434271" author="jjkoshy" created="Tue, 14 Aug 2012 16:54:49 +0000"  >&lt;p&gt;Just want to add a comment on metrics overheads of using histograms, meters&lt;br/&gt;
and gauges.&lt;/p&gt;

&lt;p&gt;Meters use an exponential weighted moving average and don&apos;t need to maintain&lt;br/&gt;
past data.  Histograms are implemented using reservoir sampling and need to&lt;br/&gt;
maintain a sampling array. There is only one per-key histogram - the&lt;br/&gt;
&quot;follower catch-up time&quot; histogram in DelayedProducerRequestMetrics. There&lt;br/&gt;
are four more global histograms.&lt;/p&gt;

&lt;p&gt;The sampling array is 1028 atomic longs by default. So if we have say, 500&lt;br/&gt;
topics with four partitions each, four brokers, assume that leadership is&lt;br/&gt;
evenly spread out, a &lt;b&gt;lower&lt;/b&gt; bound (if we ignore object overheads and the&lt;br/&gt;
global histograms) on memory would be ~ 4MB per broker.&lt;/p&gt;

&lt;p&gt;Also, after looking at the metrics code a little more, I think we should use&lt;br/&gt;
the exponentially decaying sampling option. By default, the histogram uses a&lt;br/&gt;
uniform sample - i.e., it effectively takes a uniform sample from all the&lt;br/&gt;
seen data points. Exponential decaying sampling gives more weight to the&lt;br/&gt;
past five minutes of data - but it would use at least double the memory of&lt;br/&gt;
uniform sampling which pushes memory usage to over 8MB.&lt;/p&gt;</comment>
                            <comment id="13434332" author="nehanarkhede" created="Tue, 14 Aug 2012 17:59:03 +0000"  >&lt;p&gt;Patch v2 doesn&apos;t apply cleanly on a fresh checkout of 0.8 -&lt;/p&gt;

&lt;p&gt;nnarkhed-ld:kafka-385 nnarkhed$ patch -p0 -i ~/Projects/kafka-patches/&lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-385&quot; title=&quot;RequestPurgatory enhancements - expire/checkSatisfy issue; add jmx beans&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-385&quot;&gt;&lt;del&gt;KAFKA-385&lt;/del&gt;&lt;/a&gt;-v2.patch &lt;br/&gt;
patching file core/src/main/scala/kafka/Kafka.scala&lt;br/&gt;
patching file core/src/main/scala/kafka/api/FetchResponse.scala&lt;br/&gt;
patching file core/src/main/scala/kafka/metrics/KafkaMetrics.scala&lt;br/&gt;
patching file core/src/main/scala/kafka/metrics/KafkaMetricsConfigShared.scala&lt;br/&gt;
patching file core/src/main/scala/kafka/metrics/KafkaMetricsGroup.scala&lt;br/&gt;
patching file core/src/main/scala/kafka/server/KafkaApis.scala&lt;br/&gt;
Hunk #4 FAILED at 160.&lt;br/&gt;
Hunk #12 FAILED at 360.&lt;br/&gt;
2 out of 24 hunks FAILED &amp;#8211; saving rejects to file core/src/main/scala/kafka/server/KafkaApis.scala.rej&lt;br/&gt;
patching file core/src/main/scala/kafka/server/KafkaConfig.scala&lt;br/&gt;
Hunk #1 succeeded at 24 with fuzz 2 (offset 2 lines).&lt;br/&gt;
Hunk #2 succeeded at 36 with fuzz 1 (offset 2 lines).&lt;br/&gt;
Hunk #3 succeeded at 139 (offset 2 lines).&lt;br/&gt;
patching file core/src/main/scala/kafka/server/RequestPurgatory.scala&lt;br/&gt;
patching file core/src/main/scala/kafka/utils/Pool.scala&lt;br/&gt;
patching file core/src/main/scala/kafka/utils/Utils.scala&lt;br/&gt;
Hunk #1 succeeded at 502 (offset 1 line).&lt;br/&gt;
patching file core/src/test/scala/unit/kafka/integration/LogCorruptionTest.scala&lt;br/&gt;
patching file core/src/test/scala/unit/kafka/integration/TopicMetadataTest.scala&lt;br/&gt;
patching file core/src/test/scala/unit/kafka/server/RequestPurgatoryTest.scala&lt;br/&gt;
patching file project/build/KafkaProject.scala&lt;/p&gt;</comment>
                            <comment id="13434342" author="jjkoshy" created="Tue, 14 Aug 2012 18:05:03 +0000"  >&lt;p&gt;Yes - looks like &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-369&quot; title=&quot;remove ZK dependency on producer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-369&quot;&gt;&lt;del&gt;KAFKA-369&lt;/del&gt;&lt;/a&gt; went in yesterday. I will need to rebase now.&lt;/p&gt;</comment>
                            <comment id="13434602" author="jkreps" created="Tue, 14 Aug 2012 22:46:24 +0000"  >&lt;p&gt;1. Can we make the reporters pluggable? We shouldn&apos;t hard code those, you should just give something like&lt;br/&gt;
  metrics.reporters=com.xyz.MyReporter, com.xyz.YourReporter&lt;br/&gt;
2. Please remove the reference to scala class names from the logging (e.g. DelayedProduce)&lt;br/&gt;
3. How are you measuring the performance impact of the change you made to synchronization?&lt;br/&gt;
4. It would be good to cut-and-paste the scala timer class they provide in the scala wrapper. That is really nice.&lt;br/&gt;
5. Size.&lt;br/&gt;
I think the overhead is the following:&lt;br/&gt;
8 byte pointer to the value&lt;br/&gt;
12 byte object header&lt;br/&gt;
8 byte value&lt;br/&gt;
Total: 28 bytes&lt;/p&gt;

&lt;p&gt;This is too much memory for something that should just be monitoring. I think we should not do per-key histograms.&lt;/p&gt;
</comment>
                            <comment id="13434655" author="jjkoshy" created="Tue, 14 Aug 2012 23:52:43 +0000"  >&lt;p&gt;I&apos;m about to upload a rebased patch so I&apos;d like to incorporate as much of this as I can.&lt;/p&gt;

&lt;p&gt;&amp;gt; 1. Can we make the reporters pluggable? We shouldn&apos;t hard code those, you should just give something like &lt;br/&gt;
  metrics.reporters=com.xyz.MyReporter, com.xyz.YourReporter &lt;/p&gt;

&lt;p&gt;These (and ConsoleReporter) are the only reporters currently available. It would be good to make it pluggable, but their constructors are different. i.e., I don&apos;t think it is possible to do this without using a spring-like framework.&lt;/p&gt;

&lt;p&gt;&amp;gt; 2. Please remove the reference to scala class names from the logging (e.g. DelayedProduce)&lt;/p&gt;

&lt;p&gt;I don&apos;t follow this comment - can you clarify? Which file are you referring to?&lt;/p&gt;

&lt;p&gt;&amp;gt; 3. How are you measuring the performance impact of the change you made to synchronization?&lt;/p&gt;

&lt;p&gt;I did not - I can measure the satisfaction time with and without the synchronization but I doubt it would add much overhead. Also, we have to add synchronization one way or the other - either inside the purgatory or outside (i.e,. burden the client&apos;s usage).&lt;/p&gt;

&lt;p&gt;&amp;gt; 4. It would be good to cut-and-paste the scala timer class they provide in the scala wrapper. That is really nice. &lt;/p&gt;

&lt;p&gt;They == ? Not clear on this - can you clarify?&lt;/p&gt;

&lt;p&gt;&amp;gt; 5. Size. &lt;br/&gt;
I think the overhead is the following: &lt;br/&gt;
8 byte pointer to the value &lt;br/&gt;
12 byte object header &lt;br/&gt;
8 byte value &lt;br/&gt;
Total: 28 bytes &lt;/p&gt;

&lt;p&gt;&amp;gt; This is too much memory for something that should just be monitoring. I think we should not do per-key histograms. &lt;/p&gt;

&lt;p&gt;This is certainly a concern. So with the scenario I have in my previous comment, this would be &amp;gt; 13MB per broker and &amp;gt; double that if I use exponentially decaying sampling. That said, there is only one per-key histogram (which is the follower catch up time). OTOH since the main use I can think of is to see which followers are slower we can achieve that with grep&apos;s in the log. So I guess the visual benefit comes at a prohibitive memory cost.&lt;/p&gt;</comment>
                            <comment id="13435430" author="jjkoshy" created="Wed, 15 Aug 2012 19:14:01 +0000"  >&lt;p&gt;Changes over v2:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Rebased (twice!)&lt;/li&gt;
	&lt;li&gt;For the remaining (global) histograms switched to biased histograms.&lt;/li&gt;
	&lt;li&gt;Addressed Jay&apos;s comments:&lt;/li&gt;
	&lt;li&gt;1: actually there&apos;s a workaround - basically pass through the properties&lt;br/&gt;
    to the custom reporter. (I provided an example&lt;br/&gt;
    (KafkaCSVMetricsReporter). If JMX operations need to be exposed the&lt;br/&gt;
    custom reporter will need to implement an mbean trait that extends from&lt;br/&gt;
    KafkaMetricsReporterMBean. I did this to avoid having to implement the&lt;br/&gt;
    DynamicMBean interface. Since we now have pluggable reporters I removed&lt;br/&gt;
    the KafkaMetrics class and the dependency on metrics-ganglia and&lt;br/&gt;
    metrics-graphite.&lt;/li&gt;
	&lt;li&gt;2: changed the logging statements in KafkaApis to just say producer&lt;br/&gt;
    requests/fetch requests.&lt;/li&gt;
	&lt;li&gt;3: I did a quick test as described above, but couldn&apos;t see any&lt;br/&gt;
    measurable impact.&lt;/li&gt;
	&lt;li&gt;4: Added KafkaTimer and a unit test (which I&apos;m thinking of removing as&lt;br/&gt;
    it is pretty dumb other than showing how to use it).&lt;/li&gt;
	&lt;li&gt;5: Got rid of the per-key follower catch up time histogram from&lt;br/&gt;
    DelayedProduceMetrics.  Furthemore, meters are inexpensive and the&lt;br/&gt;
    per-key caught up follower request meter should be sufficient.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13435458" author="jkreps" created="Wed, 15 Aug 2012 20:01:00 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13435461" author="jjkoshy" created="Wed, 15 Aug 2012 20:04:21 +0000"  >&lt;p&gt;I forgot to update the running flag in the example reporter - will fix that before check-in.&lt;/p&gt;</comment>
                            <comment id="13435689" author="jjkoshy" created="Thu, 16 Aug 2012 01:44:04 +0000"  >&lt;p&gt;Jun had brought up one more problem - the factory method to getAndMaybePut doesn&apos;t really&lt;br/&gt;
fix the problem of avoiding instantiation of objects if they are already present in the Pool since the&lt;br/&gt;
anonymous function that I use needs to instantiate the object. I tweaked the code to use lazy vals&lt;br/&gt;
and used logging to verify that each object in the Pool is instantiated only once.&lt;/p&gt;

&lt;p&gt;From what I understand, it seems lazy val&apos;s implementation effectively uses a synchronized bitmap&lt;br/&gt;
to keep track of whether a particular val has been created or not. However, I&apos;m not so sure how it works&lt;br/&gt;
if the val involves a parameter. e.g., lazy val factory = new MyClass(param) as opposed to&lt;br/&gt;
lazy val factory = new MyClass The concern is that scala may need to create some internal wrapper&lt;br/&gt;
classes (at runtime). I tried disassembling the bytecode but did not want to spend too much time on&lt;br/&gt;
it - so I thought I&apos;d ask if anyone know details of how lazy vals work when the actual instance is only&lt;br/&gt;
known at runtime?&lt;/p&gt;</comment>
                            <comment id="13435690" author="jjkoshy" created="Thu, 16 Aug 2012 01:44:57 +0000"  >&lt;p&gt;Attached an incremental patch over v3 to illustrate.&lt;/p&gt;</comment>
                            <comment id="13435753" author="junrao" created="Thu, 16 Aug 2012 04:18:41 +0000"  >&lt;p&gt;For the issue with getAndMaybePut(), can we add an optional createValue() method to the constructor of Pool? If an object doesn&apos;t exist for a key, Pool can call createValue() to create a new value object from key.&lt;/p&gt;

&lt;p&gt;A few other comments:&lt;br/&gt;
30. KafkaConfig: brokerid should be a required property. So we shouldn&apos;t put a default value.&lt;/p&gt;

&lt;p&gt;31. satisfiedRequestMeter: Currently, it doesn&apos;t include the time for expired requests. I prefer to have a stat that gives the time for all requests, whether expired or not. &lt;/p&gt;

&lt;p&gt;32. I am not sure how useful the metric CaughtUpFollowerFetchRequestsPerSecond is.&lt;/p&gt;</comment>
                            <comment id="13435782" author="jjkoshy" created="Thu, 16 Aug 2012 06:18:16 +0000"  >&lt;p&gt;That&apos;s a good suggestion, and should work as well. I&apos;ll make that change tomorrow. It would be good to understand the lazy val implementation as well - will try and dig into some toy examples.&lt;/p&gt;

&lt;p&gt;30. Correct - I had reverted that in the last attachment. There was a (temporary I think) reason I needed that default but I don&apos;t remember.&lt;/p&gt;

&lt;p&gt;For 31 and 32 I think we should defer this to a later discussion. I actually had expiration time before but removed it. I&apos;m not sure it makes a lot of sense. It would perhaps be useful to detect producers that are setting a very low expiration period, but even so it is driven by producer configs and would be a mash-up of values from different producers with expiring requests. Stats can be asymmetric between delayed-produce/delayed-fetch and also between expired/satisfied.&lt;/p&gt;</comment>
                            <comment id="13436174" author="jjkoshy" created="Thu, 16 Aug 2012 18:05:27 +0000"  >&lt;p&gt;Moved the valueFactory to Pool&apos;s constructor.&lt;br/&gt;
Unit tests/system tests pass.&lt;/p&gt;</comment>
                            <comment id="13436188" author="junrao" created="Thu, 16 Aug 2012 18:20:56 +0000"  >&lt;p&gt;+1 on patch v4.&lt;/p&gt;</comment>
                            <comment id="13436332" author="jjkoshy" created="Thu, 16 Aug 2012 21:28:56 +0000"  >&lt;p&gt;Thanks for the reviews. Committed to 0.8.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12539746" name="KAFKA-385-v1.patch" size="73890" author="jjkoshy" created="Tue, 7 Aug 2012 23:48:16 +0000"/>
                            <attachment id="12540704" name="KAFKA-385-v2.patch" size="62741" author="jjkoshy" created="Mon, 13 Aug 2012 17:30:38 +0000"/>
                            <attachment id="12541168" name="KAFKA-385-v3-with-lazy-fix.patch" size="7664" author="jjkoshy" created="Thu, 16 Aug 2012 01:44:57 +0000"/>
                            <attachment id="12541114" name="KAFKA-385-v3.patch" size="69587" author="jjkoshy" created="Wed, 15 Aug 2012 19:14:01 +0000"/>
                            <attachment id="12541113" name="KAFKA-385-v3.patch" size="69587" author="jjkoshy" created="Wed, 15 Aug 2012 19:14:01 +0000"/>
                            <attachment id="12541255" name="KAFKA-385-v4.patch" size="70043" author="jjkoshy" created="Thu, 16 Aug 2012 18:05:27 +0000"/>
                            <attachment id="12539744" name="example_dashboard.jpg" size="210733" author="jjkoshy" created="Tue, 7 Aug 2012 23:48:16 +0000"/>
                            <attachment id="12539745" name="graphite_explorer.jpg" size="124422" author="jjkoshy" created="Tue, 7 Aug 2012 23:48:16 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>8.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>299104</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            13 years, 14 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i15zmf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>243071</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>