<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:12:48 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6949] alterReplicaLogDirs() should grab partition lock when accessing log of the future replica</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6949</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;I found this in a failed execution of &lt;br/&gt;
kafka.admin.ReassignPartitionsClusterTest.shouldExpandCluster. Looks like we&apos;re missing some option checking.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[2018-05-25 08:03:53,310] ERROR [ReplicaManager broker=100] Error &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; changing replica dir &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition my-topic-2 (kafka.server.ReplicaManager:76)
java.util.NoSuchElementException: None.get
	at scala.None$.get(Option.scala:347)
	at scala.None$.get(Option.scala:345)
	at kafka.server.ReplicaManager$$anonfun$alterReplicaLogDirs$1.apply(ReplicaManager.scala:584)
	at kafka.server.ReplicaManager$$anonfun$alterReplicaLogDirs$1.apply(ReplicaManager.scala:576)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;map(TraversableLike.scala:234)
	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
	at kafka.server.ReplicaManager.alterReplicaLogDirs(ReplicaManager.scala:576)
	at kafka.server.KafkaApis.handleAlterReplicaLogDirsRequest(KafkaApis.scala:2037)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:138)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:69)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13162107">KAFKA-6949</key>
            <summary>alterReplicaLogDirs() should grab partition lock when accessing log of the future replica</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lindong">Dong Lin</assignee>
                                    <reporter username="hachikuji">Jason Gustafson</reporter>
                        <labels>
                    </labels>
                <created>Fri, 25 May 2018 15:28:42 +0000</created>
                <updated>Fri, 29 Jun 2018 15:05:34 +0000</updated>
                            <resolved>Fri, 29 Jun 2018 15:05:34 +0000</resolved>
                                                    <fixVersion>2.0.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="16490869" author="hachikuji" created="Fri, 25 May 2018 15:29:12 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lindong&quot; class=&quot;user-hover&quot; rel=&quot;lindong&quot;&gt;lindong&lt;/a&gt; If you have time, can you take a look?&lt;/p&gt;</comment>
                            <comment id="16491053" author="lindong" created="Fri, 25 May 2018 17:32:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt; Certainly. I will look into this.&lt;/p&gt;</comment>
                            <comment id="16491438" author="githubbot" created="Sat, 26 May 2018 00:52:42 +0000"  >&lt;p&gt;lindong28 opened a new pull request #5081: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6949&quot; title=&quot;alterReplicaLogDirs() should grab partition lock when accessing log of the future replica&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6949&quot;&gt;&lt;del&gt;KAFKA-6949&lt;/del&gt;&lt;/a&gt;; alterReplicaLogDirs() should grab partition lock when accessing log of the future replica&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5081&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5081&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   NoSuchElementException will be thrown if ReplicaAlterDirThread replaces the current replica with future replica right before the request handler thread executes `futureReplica.log.get.dir.getParent` in the ReplicaManager.alterReplicaLogDirs(). The solution is to grab the partition lock when request handler thread attempts to check the destination log directory of the future replica.&lt;/p&gt;

&lt;p&gt;   *Summary of testing strategy (including rationale)&lt;br/&gt;
   for the feature or bug fix. Unit and/or integration&lt;br/&gt;
   tests are expected for any behaviour change and&lt;br/&gt;
   system tests should be considered for larger changes.*&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16518378" author="rsivaram" created="Wed, 20 Jun 2018 17:26:58 +0000"  >&lt;p&gt;Removed fix version for 2.0.0 RC0, will update for next RC if fix is in.&lt;/p&gt;</comment>
                            <comment id="16523292" author="githubbot" created="Tue, 26 Jun 2018 06:41:16 +0000"  >&lt;p&gt;lindong28 closed pull request #5081: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6949&quot; title=&quot;alterReplicaLogDirs() should grab partition lock when accessing log of the future replica&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6949&quot;&gt;&lt;del&gt;KAFKA-6949&lt;/del&gt;&lt;/a&gt;; alterReplicaLogDirs() should grab partition lock when accessing log of the future replica&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5081&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5081&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/core/src/main/scala/kafka/cluster/Partition.scala b/core/src/main/scala/kafka/cluster/Partition.scala&lt;br/&gt;
index 9ab1ec47af8..b80c34475d3 100755&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/cluster/Partition.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/cluster/Partition.scala&lt;br/&gt;
@@ -149,10 +149,10 @@ class Partition(val topic: String,&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@return true iff the future replica is created&lt;br/&gt;
     */&lt;br/&gt;
   def maybeCreateFutureReplica(logDir: String): Boolean = {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// The readLock is needed to make sure that while the caller checks the log directory of the&lt;br/&gt;
+    // The writeLock is needed to make sure that while the caller checks the log directory of the&lt;br/&gt;
     // current replica and the existence of the future replica, no other thread can update the log directory of the&lt;br/&gt;
     // current replica or remove the future replica.&lt;/li&gt;
	&lt;li&gt;inReadLock(leaderIsrUpdateLock) {&lt;br/&gt;
+    inWriteLock(leaderIsrUpdateLock) 
{
       val currentReplica = getReplica().get
       if (currentReplica.log.get.dir.getParent == logDir)
         false
@@ -207,29 +207,52 @@ class Partition(val topic: String,
     allReplicasMap.remove(replicaId)
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def removeFutureLocalReplica() {&lt;br/&gt;
+  def futureReplicaDirChanged(newDestinationDir: String): Boolean = {&lt;br/&gt;
+    inReadLock(leaderIsrUpdateLock) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+      getReplica(Request.FutureLocalReplicaId) match {
+        case Some(futureReplica) =&amp;gt;
+          if (futureReplica.log.get.dir.getParent != newDestinationDir)
+            true
+          else
+            false
+        case None =&amp;gt; false
+      }+    }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;+  }&lt;br/&gt;
+&lt;br/&gt;
+  def removeFutureLocalReplica(deleteFromLogDir: Boolean = true) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {     inWriteLock(leaderIsrUpdateLock) {
       allReplicasMap.remove(Request.FutureLocalReplicaId)
+      if (deleteFromLogDir)
+        logManager.asyncDelete(topicPartition, isFuture = true)
     }   }&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// Return true iff the future log has caught up with the current log for this partition&lt;br/&gt;
+  // Return true iff the future replica exists and it has caught up with the current replica for this partition&lt;br/&gt;
   // Only ReplicaAlterDirThread will call this method and ReplicaAlterDirThread should remove the partition&lt;br/&gt;
   // from its partitionStates if this method returns true&lt;br/&gt;
   def maybeReplaceCurrentWithFutureReplica(): Boolean = {&lt;br/&gt;
     val replica = getReplica().get&lt;/li&gt;
	&lt;li&gt;val futureReplica = getReplica(Request.FutureLocalReplicaId).get&lt;/li&gt;
	&lt;li&gt;if (replica.logEndOffset == futureReplica.logEndOffset) {&lt;br/&gt;
+    val futureReplicaLEO = getReplica(Request.FutureLocalReplicaId).map(_.logEndOffset)&lt;br/&gt;
+    if (futureReplicaLEO.contains(replica.logEndOffset)) {&lt;br/&gt;
       // The write lock is needed to make sure that while ReplicaAlterDirThread checks the LEO of the&lt;br/&gt;
       // current replica, no other thread can update LEO of the current replica via log truncation or log append operation.&lt;br/&gt;
       inWriteLock(leaderIsrUpdateLock) {&lt;/li&gt;
	&lt;li&gt;if (replica.logEndOffset == futureReplica.logEndOffset) 
{
-          logManager.replaceCurrentWithFutureLog(topicPartition)
-          replica.log = futureReplica.log
-          futureReplica.log = None
-          allReplicasMap.remove(Request.FutureLocalReplicaId)
-          true
-        }
&lt;p&gt; else false&lt;br/&gt;
+        getReplica(Request.FutureLocalReplicaId) match &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+          case Some(futureReplica) =&amp;gt;+            if (replica.logEndOffset == futureReplica.logEndOffset) {
+              logManager.replaceCurrentWithFutureLog(topicPartition)
+              replica.log = futureReplica.log
+              futureReplica.log = None
+              allReplicasMap.remove(Request.FutureLocalReplicaId)
+              true
+            } else false+          case None =&amp;gt;+            // Future replica is removed by a non-ReplicaAlterLogDirsThread before this method is called+            // In this case the partition should have been removed from state of the ReplicaAlterLogDirsThread+            // Return false so that ReplicaAlterLogDirsThread does not have to remove this partition from the state again to avoid race condition+            false+        }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;       }&lt;br/&gt;
     } else false&lt;br/&gt;
   }&lt;br/&gt;
@@ -550,15 +573,22 @@ class Partition(val topic: String,&lt;br/&gt;
   }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   private def doAppendRecordsToFollowerOrFutureReplica(records: MemoryRecords, isFuture: Boolean): Unit = {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (isFuture)&lt;/li&gt;
	&lt;li&gt;getReplicaOrException(Request.FutureLocalReplicaId).log.get.appendAsFollower(records)&lt;/li&gt;
	&lt;li&gt;else {&lt;/li&gt;
	&lt;li&gt;// The read lock is needed to prevent the follower replica from being updated while ReplicaAlterDirThread&lt;/li&gt;
	&lt;li&gt;// is executing maybeDeleteAndSwapFutureReplica() to replace follower replica with the future replica.&lt;br/&gt;
+    inReadLock(leaderIsrUpdateLock) {&lt;br/&gt;
+      if (isFuture) {&lt;br/&gt;
+        // The read lock is needed to handle race condition if request handler thread tries to&lt;br/&gt;
+        // remove future replica after receiving AlterReplicaLogDirsRequest.&lt;br/&gt;
         inReadLock(leaderIsrUpdateLock) {&lt;/li&gt;
	&lt;li&gt;getReplicaOrException().log.get.appendAsFollower(records)&lt;br/&gt;
+          getReplica(Request.FutureLocalReplicaId) match 
{
+            case Some(replica) =&amp;gt; replica.log.get.appendAsFollower(records)
+            case None =&amp;gt; // Future replica is removed by a non-ReplicaAlterLogDirsThread before this method is called
+          }
&lt;p&gt;         }&lt;br/&gt;
+      } else &lt;/p&gt;
{
+        // The read lock is needed to prevent the follower replica from being updated while ReplicaAlterDirThread
+        // is executing maybeDeleteAndSwapFutureReplica() to replace follower replica with the future replica.
+        getReplicaOrException().log.get.appendAsFollower(records)
       }
&lt;p&gt;+    }&lt;br/&gt;
   }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def appendRecordsToFollowerOrFutureReplica(records: MemoryRecords, isFuture: Boolean) {&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/server/ReplicaManager.scala b/core/src/main/scala/kafka/server/ReplicaManager.scala&lt;br/&gt;
index 965595b2c2e..ed9559f856a 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/server/ReplicaManager.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/server/ReplicaManager.scala&lt;br/&gt;
@@ -577,14 +577,17 @@ class ReplicaManager(val config: KafkaConfig,&lt;br/&gt;
           if (!logManager.isLogDirOnline(destinationDir))&lt;br/&gt;
             throw new KafkaStorageException(s&quot;Log directory $destinationDir is offline&quot;)&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// Stop current replica movement if the destinationDir is different from the existing destination log directory&lt;/li&gt;
	&lt;li&gt;getReplica(topicPartition, Request.FutureLocalReplicaId) match {&lt;/li&gt;
	&lt;li&gt;case Some(futureReplica) =&amp;gt;&lt;/li&gt;
	&lt;li&gt;if (futureReplica.log.get.dir.getParent != destinationDir) {&lt;br/&gt;
+          getPartition(topicPartition) match 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+            case Some(partition) =&amp;gt;+              if (partition eq ReplicaManager.OfflinePartition)+                throw new KafkaStorageException(s&amp;quot;Partition $topicPartition is offline&amp;quot;)++              // Stop current replica movement if the destinationDir is different from the existing destination log directory+              if (partition.futureReplicaDirChanged(destinationDir)) {
                 replicaAlterLogDirsManager.removeFetcherForPartitions(Set(topicPartition))
-                getPartition(topicPartition).get.removeFutureLocalReplica()
-                logManager.asyncDelete(topicPartition, isFuture = true)
+                partition.removeFutureLocalReplica()
               }+             case None =&amp;gt;           }&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -1418,7 +1421,7 @@ class ReplicaManager(val config: KafkaConfig,&lt;br/&gt;
       replicaFetcherManager.removeFetcherForPartitions(newOfflinePartitions)&lt;br/&gt;
       replicaAlterLogDirsManager.removeFetcherForPartitions(newOfflinePartitions ++ partitionsWithOfflineFutureReplica.map(_.topicPartition))&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;partitionsWithOfflineFutureReplica.foreach(partition =&amp;gt; partition.removeFutureLocalReplica())&lt;br/&gt;
+      partitionsWithOfflineFutureReplica.foreach(partition =&amp;gt; partition.removeFutureLocalReplica(deleteFromLogDir = false))&lt;br/&gt;
       newOfflinePartitions.foreach { topicPartition =&amp;gt;&lt;br/&gt;
         val partition = allPartitions.put(topicPartition, ReplicaManager.OfflinePartition)&lt;br/&gt;
         partition.removePartitionMetrics()&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/cluster/PartitionTest.scala b/core/src/test/scala/unit/kafka/cluster/PartitionTest.scala&lt;br/&gt;
index fe9038ab255..41bdefddb76 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/test/scala/unit/kafka/cluster/PartitionTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/cluster/PartitionTest.scala&lt;br/&gt;
@@ -19,8 +19,10 @@ package kafka.cluster&lt;br/&gt;
 import java.io.File&lt;br/&gt;
 import java.nio.ByteBuffer&lt;br/&gt;
 import java.util.Properties&lt;br/&gt;
+import java.util.concurrent.CountDownLatch&lt;br/&gt;
 import java.util.concurrent.atomic.AtomicBoolean&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+import kafka.api.Request&lt;br/&gt;
 import kafka.common.UnexpectedAppendOffsetException&lt;br/&gt;
 import kafka.log.&lt;/p&gt;
{LogConfig, LogManager, CleanerConfig}
&lt;p&gt; import kafka.server._&lt;br/&gt;
@@ -44,7 +46,8 @@ class PartitionTest {&lt;br/&gt;
   val metrics = new Metrics&lt;/p&gt;

&lt;p&gt;   var tmpDir: File = _&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;var logDir: File = _&lt;br/&gt;
+  var logDir1: File = _&lt;br/&gt;
+  var logDir2: File = _&lt;br/&gt;
   var replicaManager: ReplicaManager = _&lt;br/&gt;
   var logManager: LogManager = _&lt;br/&gt;
   var logConfig: LogConfig = _&lt;br/&gt;
@@ -58,13 +61,14 @@ class PartitionTest {&lt;br/&gt;
     logConfig = LogConfig(logProps)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     tmpDir = TestUtils.tempDir()&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;logDir = TestUtils.randomPartitionLogDir(tmpDir)&lt;br/&gt;
+    logDir1 = TestUtils.randomPartitionLogDir(tmpDir)&lt;br/&gt;
+    logDir2 = TestUtils.randomPartitionLogDir(tmpDir)&lt;br/&gt;
     logManager = TestUtils.createLogManager(&lt;/li&gt;
	&lt;li&gt;logDirs = Seq(logDir), defaultConfig = logConfig, CleanerConfig(enableCleaner = false), time)&lt;br/&gt;
+      logDirs = Seq(logDir1, logDir2), defaultConfig = logConfig, CleanerConfig(enableCleaner = false), time)&lt;br/&gt;
     logManager.startup()&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val brokerProps = TestUtils.createBrokerConfig(brokerId, TestUtils.MockZkConnect)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;brokerProps.put(&quot;log.dir&quot;, logDir.getAbsolutePath)&lt;br/&gt;
+    brokerProps.put(KafkaConfig.LogDirsProp, Seq(logDir1, logDir2).map(_.getAbsolutePath).mkString(&quot;,&quot;))&lt;br/&gt;
     val brokerConfig = KafkaConfig.fromProps(brokerProps)&lt;br/&gt;
     replicaManager = new ReplicaManager(&lt;br/&gt;
       config = brokerConfig, metrics, time, zkClient = null, new MockScheduler(time),&lt;br/&gt;
@@ -83,6 +87,48 @@ class PartitionTest 
{
     replicaManager.shutdown(checkpointHW = false)
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+  @Test&lt;br/&gt;
+  // Verify that partition.removeFutureLocalReplica() and partition.maybeReplaceCurrentWithFutureReplica() can run concurrently&lt;br/&gt;
+  def testMaybeReplaceCurrentWithFutureReplica(): Unit = {&lt;br/&gt;
+    val latch = new CountDownLatch(1)&lt;br/&gt;
+&lt;br/&gt;
+    logManager.maybeUpdatePreferredLogDir(topicPartition, logDir1.getAbsolutePath)&lt;br/&gt;
+    val log1 = logManager.getOrCreateLog(topicPartition, logConfig)&lt;br/&gt;
+    logManager.maybeUpdatePreferredLogDir(topicPartition, logDir2.getAbsolutePath)&lt;br/&gt;
+    val log2 = logManager.getOrCreateLog(topicPartition, logConfig, isFuture = true)&lt;br/&gt;
+    val currentReplica = new Replica(brokerId, topicPartition, time, log = Some(log1))&lt;br/&gt;
+    val futureReplica = new Replica(Request.FutureLocalReplicaId, topicPartition, time, log = Some(log2))&lt;br/&gt;
+    val partition = new Partition(topicPartition.topic, topicPartition.partition, time, replicaManager)&lt;br/&gt;
+&lt;br/&gt;
+    partition.addReplicaIfNotExists(futureReplica)&lt;br/&gt;
+    partition.addReplicaIfNotExists(currentReplica)&lt;br/&gt;
+    assertEquals(Some(currentReplica), partition.getReplica(brokerId))&lt;br/&gt;
+    assertEquals(Some(futureReplica), partition.getReplica(Request.FutureLocalReplicaId))&lt;br/&gt;
+&lt;br/&gt;
+    val thread1 = new Thread {&lt;br/&gt;
+      override def run(): Unit = &lt;/p&gt;
{
+        latch.await()
+        partition.removeFutureLocalReplica()
+      }
&lt;p&gt;+    }&lt;br/&gt;
+&lt;br/&gt;
+    val thread2 = new Thread {&lt;br/&gt;
+      override def run(): Unit = &lt;/p&gt;
{
+        latch.await()
+        partition.maybeReplaceCurrentWithFutureReplica()
+      }
&lt;p&gt;+    }&lt;br/&gt;
+&lt;br/&gt;
+    thread1.start()&lt;br/&gt;
+    thread2.start()&lt;br/&gt;
+&lt;br/&gt;
+    latch.countDown()&lt;br/&gt;
+    thread1.join()&lt;br/&gt;
+    thread2.join()&lt;br/&gt;
+    assertEquals(None, partition.getReplica(Request.FutureLocalReplicaId))&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
   @Test&lt;br/&gt;
   def testAppendRecordsAsFollowerBelowLogStartOffset(): Unit = {&lt;br/&gt;
     val log = logManager.getOrCreateLog(topicPartition, logConfig)&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/utils/TestUtils.scala b/core/src/test/scala/unit/kafka/utils/TestUtils.scala&lt;br/&gt;
index da87c309dbd..d2aae2c54d7 100755&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/utils/TestUtils.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/utils/TestUtils.scala&lt;br/&gt;
@@ -929,7 +929,7 @@ object TestUtils extends Logging {&lt;br/&gt;
                        defaultConfig: LogConfig = LogConfig(),&lt;br/&gt;
                        cleanerConfig: CleanerConfig = CleanerConfig(enableCleaner = false),&lt;br/&gt;
                        time: MockTime = new MockTime()): LogManager = {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new LogManager(logDirs = logDirs,&lt;br/&gt;
+    new LogManager(logDirs = logDirs.map(_.getAbsoluteFile),&lt;br/&gt;
                    initialOfflineDirs = Array.empty&lt;span class=&quot;error&quot;&gt;&amp;#91;File&amp;#93;&lt;/span&gt;,&lt;br/&gt;
                    topicConfigs = Map(),&lt;br/&gt;
                    initialDefaultConfig = defaultConfig,&lt;/li&gt;
&lt;/ul&gt;





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16523295" author="githubbot" created="Tue, 26 Jun 2018 06:43:32 +0000"  >&lt;p&gt;lindong28 opened a new pull request #5293: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6949&quot; title=&quot;alterReplicaLogDirs() should grab partition lock when accessing log of the future replica&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6949&quot;&gt;&lt;del&gt;KAFKA-6949&lt;/del&gt;&lt;/a&gt;; alterReplicaLogDirs() should grab partition lock when accessing log of the future replica&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5293&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5293&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   NoSuchElementException will be thrown if ReplicaAlterDirThread replaces the current replica with future replica right before the request handler thread executes `futureReplica.log.get.dir.getParent` in the ReplicaManager.alterReplicaLogDirs(). The solution is to grab the partition lock when request handler thread attempts to check the destination log directory of the future replica.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16523297" author="lindong" created="Tue, 26 Jun 2018 06:45:37 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rsivaram&quot; class=&quot;user-hover&quot; rel=&quot;rsivaram&quot;&gt;rsivaram&lt;/a&gt; The patch has been merged into trunk. I opened PR &lt;a href=&quot;https://github.com/apache/kafka/pull/5293&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5293&lt;/a&gt;&#160;to merge it into 2.0. Typically do we need review from another committer in order to cherry-pick patch from trunk into a release branch?&lt;/p&gt;

&lt;p&gt;Also, I added&#160;fix version&#160;2.0.0 in this JIRA. Please feel free to change it as you see appropriate. Thanks.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="16523393" author="rsivaram" created="Tue, 26 Jun 2018 08:13:07 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lindong&quot; class=&quot;user-hover&quot; rel=&quot;lindong&quot;&gt;lindong&lt;/a&gt; You can cherry-pick and push the commit to 2.0 branch without a PR or further reviews if major changes were not required for cherry-picking (I am assuming that is the case here). &lt;/p&gt;

&lt;p&gt;We don&apos;t currently have any blockers for which we need to create a new RC. If this issue is a blocker for 2.0 and we need to create a new RC, then do let me know. Otherwise, I will change the fix version to 2.0.1 for now and change it back to 2.0 if we require another RC. Thanks.&lt;/p&gt;</comment>
                            <comment id="16523970" author="githubbot" created="Tue, 26 Jun 2018 16:50:24 +0000"  >&lt;p&gt;lindong28 closed pull request #5293: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6949&quot; title=&quot;alterReplicaLogDirs() should grab partition lock when accessing log of the future replica&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6949&quot;&gt;&lt;del&gt;KAFKA-6949&lt;/del&gt;&lt;/a&gt;; alterReplicaLogDirs() should grab partition lock when accessing log of the future replica&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5293&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5293&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/core/src/main/scala/kafka/cluster/Partition.scala b/core/src/main/scala/kafka/cluster/Partition.scala&lt;br/&gt;
index 9ab1ec47af8..b80c34475d3 100755&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/cluster/Partition.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/cluster/Partition.scala&lt;br/&gt;
@@ -149,10 +149,10 @@ class Partition(val topic: String,&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@return true iff the future replica is created&lt;br/&gt;
     */&lt;br/&gt;
   def maybeCreateFutureReplica(logDir: String): Boolean = {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// The readLock is needed to make sure that while the caller checks the log directory of the&lt;br/&gt;
+    // The writeLock is needed to make sure that while the caller checks the log directory of the&lt;br/&gt;
     // current replica and the existence of the future replica, no other thread can update the log directory of the&lt;br/&gt;
     // current replica or remove the future replica.&lt;/li&gt;
	&lt;li&gt;inReadLock(leaderIsrUpdateLock) {&lt;br/&gt;
+    inWriteLock(leaderIsrUpdateLock) 
{
       val currentReplica = getReplica().get
       if (currentReplica.log.get.dir.getParent == logDir)
         false
@@ -207,29 +207,52 @@ class Partition(val topic: String,
     allReplicasMap.remove(replicaId)
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def removeFutureLocalReplica() {&lt;br/&gt;
+  def futureReplicaDirChanged(newDestinationDir: String): Boolean = {&lt;br/&gt;
+    inReadLock(leaderIsrUpdateLock) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+      getReplica(Request.FutureLocalReplicaId) match {
+        case Some(futureReplica) =&amp;gt;
+          if (futureReplica.log.get.dir.getParent != newDestinationDir)
+            true
+          else
+            false
+        case None =&amp;gt; false
+      }+    }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;+  }&lt;br/&gt;
+&lt;br/&gt;
+  def removeFutureLocalReplica(deleteFromLogDir: Boolean = true) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {     inWriteLock(leaderIsrUpdateLock) {
       allReplicasMap.remove(Request.FutureLocalReplicaId)
+      if (deleteFromLogDir)
+        logManager.asyncDelete(topicPartition, isFuture = true)
     }   }&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// Return true iff the future log has caught up with the current log for this partition&lt;br/&gt;
+  // Return true iff the future replica exists and it has caught up with the current replica for this partition&lt;br/&gt;
   // Only ReplicaAlterDirThread will call this method and ReplicaAlterDirThread should remove the partition&lt;br/&gt;
   // from its partitionStates if this method returns true&lt;br/&gt;
   def maybeReplaceCurrentWithFutureReplica(): Boolean = {&lt;br/&gt;
     val replica = getReplica().get&lt;/li&gt;
	&lt;li&gt;val futureReplica = getReplica(Request.FutureLocalReplicaId).get&lt;/li&gt;
	&lt;li&gt;if (replica.logEndOffset == futureReplica.logEndOffset) {&lt;br/&gt;
+    val futureReplicaLEO = getReplica(Request.FutureLocalReplicaId).map(_.logEndOffset)&lt;br/&gt;
+    if (futureReplicaLEO.contains(replica.logEndOffset)) {&lt;br/&gt;
       // The write lock is needed to make sure that while ReplicaAlterDirThread checks the LEO of the&lt;br/&gt;
       // current replica, no other thread can update LEO of the current replica via log truncation or log append operation.&lt;br/&gt;
       inWriteLock(leaderIsrUpdateLock) {&lt;/li&gt;
	&lt;li&gt;if (replica.logEndOffset == futureReplica.logEndOffset) 
{
-          logManager.replaceCurrentWithFutureLog(topicPartition)
-          replica.log = futureReplica.log
-          futureReplica.log = None
-          allReplicasMap.remove(Request.FutureLocalReplicaId)
-          true
-        }
&lt;p&gt; else false&lt;br/&gt;
+        getReplica(Request.FutureLocalReplicaId) match &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+          case Some(futureReplica) =&amp;gt;+            if (replica.logEndOffset == futureReplica.logEndOffset) {
+              logManager.replaceCurrentWithFutureLog(topicPartition)
+              replica.log = futureReplica.log
+              futureReplica.log = None
+              allReplicasMap.remove(Request.FutureLocalReplicaId)
+              true
+            } else false+          case None =&amp;gt;+            // Future replica is removed by a non-ReplicaAlterLogDirsThread before this method is called+            // In this case the partition should have been removed from state of the ReplicaAlterLogDirsThread+            // Return false so that ReplicaAlterLogDirsThread does not have to remove this partition from the state again to avoid race condition+            false+        }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;       }&lt;br/&gt;
     } else false&lt;br/&gt;
   }&lt;br/&gt;
@@ -550,15 +573,22 @@ class Partition(val topic: String,&lt;br/&gt;
   }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   private def doAppendRecordsToFollowerOrFutureReplica(records: MemoryRecords, isFuture: Boolean): Unit = {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (isFuture)&lt;/li&gt;
	&lt;li&gt;getReplicaOrException(Request.FutureLocalReplicaId).log.get.appendAsFollower(records)&lt;/li&gt;
	&lt;li&gt;else {&lt;/li&gt;
	&lt;li&gt;// The read lock is needed to prevent the follower replica from being updated while ReplicaAlterDirThread&lt;/li&gt;
	&lt;li&gt;// is executing maybeDeleteAndSwapFutureReplica() to replace follower replica with the future replica.&lt;br/&gt;
+    inReadLock(leaderIsrUpdateLock) {&lt;br/&gt;
+      if (isFuture) {&lt;br/&gt;
+        // The read lock is needed to handle race condition if request handler thread tries to&lt;br/&gt;
+        // remove future replica after receiving AlterReplicaLogDirsRequest.&lt;br/&gt;
         inReadLock(leaderIsrUpdateLock) {&lt;/li&gt;
	&lt;li&gt;getReplicaOrException().log.get.appendAsFollower(records)&lt;br/&gt;
+          getReplica(Request.FutureLocalReplicaId) match 
{
+            case Some(replica) =&amp;gt; replica.log.get.appendAsFollower(records)
+            case None =&amp;gt; // Future replica is removed by a non-ReplicaAlterLogDirsThread before this method is called
+          }
&lt;p&gt;         }&lt;br/&gt;
+      } else &lt;/p&gt;
{
+        // The read lock is needed to prevent the follower replica from being updated while ReplicaAlterDirThread
+        // is executing maybeDeleteAndSwapFutureReplica() to replace follower replica with the future replica.
+        getReplicaOrException().log.get.appendAsFollower(records)
       }
&lt;p&gt;+    }&lt;br/&gt;
   }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def appendRecordsToFollowerOrFutureReplica(records: MemoryRecords, isFuture: Boolean) {&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/server/ReplicaManager.scala b/core/src/main/scala/kafka/server/ReplicaManager.scala&lt;br/&gt;
index 965595b2c2e..ed9559f856a 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/server/ReplicaManager.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/server/ReplicaManager.scala&lt;br/&gt;
@@ -577,14 +577,17 @@ class ReplicaManager(val config: KafkaConfig,&lt;br/&gt;
           if (!logManager.isLogDirOnline(destinationDir))&lt;br/&gt;
             throw new KafkaStorageException(s&quot;Log directory $destinationDir is offline&quot;)&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// Stop current replica movement if the destinationDir is different from the existing destination log directory&lt;/li&gt;
	&lt;li&gt;getReplica(topicPartition, Request.FutureLocalReplicaId) match {&lt;/li&gt;
	&lt;li&gt;case Some(futureReplica) =&amp;gt;&lt;/li&gt;
	&lt;li&gt;if (futureReplica.log.get.dir.getParent != destinationDir) {&lt;br/&gt;
+          getPartition(topicPartition) match 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+            case Some(partition) =&amp;gt;+              if (partition eq ReplicaManager.OfflinePartition)+                throw new KafkaStorageException(s&amp;quot;Partition $topicPartition is offline&amp;quot;)++              // Stop current replica movement if the destinationDir is different from the existing destination log directory+              if (partition.futureReplicaDirChanged(destinationDir)) {
                 replicaAlterLogDirsManager.removeFetcherForPartitions(Set(topicPartition))
-                getPartition(topicPartition).get.removeFutureLocalReplica()
-                logManager.asyncDelete(topicPartition, isFuture = true)
+                partition.removeFutureLocalReplica()
               }+             case None =&amp;gt;           }&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -1418,7 +1421,7 @@ class ReplicaManager(val config: KafkaConfig,&lt;br/&gt;
       replicaFetcherManager.removeFetcherForPartitions(newOfflinePartitions)&lt;br/&gt;
       replicaAlterLogDirsManager.removeFetcherForPartitions(newOfflinePartitions ++ partitionsWithOfflineFutureReplica.map(_.topicPartition))&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;partitionsWithOfflineFutureReplica.foreach(partition =&amp;gt; partition.removeFutureLocalReplica())&lt;br/&gt;
+      partitionsWithOfflineFutureReplica.foreach(partition =&amp;gt; partition.removeFutureLocalReplica(deleteFromLogDir = false))&lt;br/&gt;
       newOfflinePartitions.foreach { topicPartition =&amp;gt;&lt;br/&gt;
         val partition = allPartitions.put(topicPartition, ReplicaManager.OfflinePartition)&lt;br/&gt;
         partition.removePartitionMetrics()&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/cluster/PartitionTest.scala b/core/src/test/scala/unit/kafka/cluster/PartitionTest.scala&lt;br/&gt;
index fe9038ab255..41bdefddb76 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/test/scala/unit/kafka/cluster/PartitionTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/cluster/PartitionTest.scala&lt;br/&gt;
@@ -19,8 +19,10 @@ package kafka.cluster&lt;br/&gt;
 import java.io.File&lt;br/&gt;
 import java.nio.ByteBuffer&lt;br/&gt;
 import java.util.Properties&lt;br/&gt;
+import java.util.concurrent.CountDownLatch&lt;br/&gt;
 import java.util.concurrent.atomic.AtomicBoolean&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+import kafka.api.Request&lt;br/&gt;
 import kafka.common.UnexpectedAppendOffsetException&lt;br/&gt;
 import kafka.log.&lt;/p&gt;
{LogConfig, LogManager, CleanerConfig}
&lt;p&gt; import kafka.server._&lt;br/&gt;
@@ -44,7 +46,8 @@ class PartitionTest {&lt;br/&gt;
   val metrics = new Metrics&lt;/p&gt;

&lt;p&gt;   var tmpDir: File = _&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;var logDir: File = _&lt;br/&gt;
+  var logDir1: File = _&lt;br/&gt;
+  var logDir2: File = _&lt;br/&gt;
   var replicaManager: ReplicaManager = _&lt;br/&gt;
   var logManager: LogManager = _&lt;br/&gt;
   var logConfig: LogConfig = _&lt;br/&gt;
@@ -58,13 +61,14 @@ class PartitionTest {&lt;br/&gt;
     logConfig = LogConfig(logProps)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     tmpDir = TestUtils.tempDir()&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;logDir = TestUtils.randomPartitionLogDir(tmpDir)&lt;br/&gt;
+    logDir1 = TestUtils.randomPartitionLogDir(tmpDir)&lt;br/&gt;
+    logDir2 = TestUtils.randomPartitionLogDir(tmpDir)&lt;br/&gt;
     logManager = TestUtils.createLogManager(&lt;/li&gt;
	&lt;li&gt;logDirs = Seq(logDir), defaultConfig = logConfig, CleanerConfig(enableCleaner = false), time)&lt;br/&gt;
+      logDirs = Seq(logDir1, logDir2), defaultConfig = logConfig, CleanerConfig(enableCleaner = false), time)&lt;br/&gt;
     logManager.startup()&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val brokerProps = TestUtils.createBrokerConfig(brokerId, TestUtils.MockZkConnect)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;brokerProps.put(&quot;log.dir&quot;, logDir.getAbsolutePath)&lt;br/&gt;
+    brokerProps.put(KafkaConfig.LogDirsProp, Seq(logDir1, logDir2).map(_.getAbsolutePath).mkString(&quot;,&quot;))&lt;br/&gt;
     val brokerConfig = KafkaConfig.fromProps(brokerProps)&lt;br/&gt;
     replicaManager = new ReplicaManager(&lt;br/&gt;
       config = brokerConfig, metrics, time, zkClient = null, new MockScheduler(time),&lt;br/&gt;
@@ -83,6 +87,48 @@ class PartitionTest 
{
     replicaManager.shutdown(checkpointHW = false)
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+  @Test&lt;br/&gt;
+  // Verify that partition.removeFutureLocalReplica() and partition.maybeReplaceCurrentWithFutureReplica() can run concurrently&lt;br/&gt;
+  def testMaybeReplaceCurrentWithFutureReplica(): Unit = {&lt;br/&gt;
+    val latch = new CountDownLatch(1)&lt;br/&gt;
+&lt;br/&gt;
+    logManager.maybeUpdatePreferredLogDir(topicPartition, logDir1.getAbsolutePath)&lt;br/&gt;
+    val log1 = logManager.getOrCreateLog(topicPartition, logConfig)&lt;br/&gt;
+    logManager.maybeUpdatePreferredLogDir(topicPartition, logDir2.getAbsolutePath)&lt;br/&gt;
+    val log2 = logManager.getOrCreateLog(topicPartition, logConfig, isFuture = true)&lt;br/&gt;
+    val currentReplica = new Replica(brokerId, topicPartition, time, log = Some(log1))&lt;br/&gt;
+    val futureReplica = new Replica(Request.FutureLocalReplicaId, topicPartition, time, log = Some(log2))&lt;br/&gt;
+    val partition = new Partition(topicPartition.topic, topicPartition.partition, time, replicaManager)&lt;br/&gt;
+&lt;br/&gt;
+    partition.addReplicaIfNotExists(futureReplica)&lt;br/&gt;
+    partition.addReplicaIfNotExists(currentReplica)&lt;br/&gt;
+    assertEquals(Some(currentReplica), partition.getReplica(brokerId))&lt;br/&gt;
+    assertEquals(Some(futureReplica), partition.getReplica(Request.FutureLocalReplicaId))&lt;br/&gt;
+&lt;br/&gt;
+    val thread1 = new Thread {&lt;br/&gt;
+      override def run(): Unit = &lt;/p&gt;
{
+        latch.await()
+        partition.removeFutureLocalReplica()
+      }
&lt;p&gt;+    }&lt;br/&gt;
+&lt;br/&gt;
+    val thread2 = new Thread {&lt;br/&gt;
+      override def run(): Unit = &lt;/p&gt;
{
+        latch.await()
+        partition.maybeReplaceCurrentWithFutureReplica()
+      }
&lt;p&gt;+    }&lt;br/&gt;
+&lt;br/&gt;
+    thread1.start()&lt;br/&gt;
+    thread2.start()&lt;br/&gt;
+&lt;br/&gt;
+    latch.countDown()&lt;br/&gt;
+    thread1.join()&lt;br/&gt;
+    thread2.join()&lt;br/&gt;
+    assertEquals(None, partition.getReplica(Request.FutureLocalReplicaId))&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
   @Test&lt;br/&gt;
   def testAppendRecordsAsFollowerBelowLogStartOffset(): Unit = {&lt;br/&gt;
     val log = logManager.getOrCreateLog(topicPartition, logConfig)&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/utils/TestUtils.scala b/core/src/test/scala/unit/kafka/utils/TestUtils.scala&lt;br/&gt;
index da87c309dbd..d2aae2c54d7 100755&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/utils/TestUtils.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/utils/TestUtils.scala&lt;br/&gt;
@@ -929,7 +929,7 @@ object TestUtils extends Logging {&lt;br/&gt;
                        defaultConfig: LogConfig = LogConfig(),&lt;br/&gt;
                        cleanerConfig: CleanerConfig = CleanerConfig(enableCleaner = false),&lt;br/&gt;
                        time: MockTime = new MockTime()): LogManager = {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new LogManager(logDirs = logDirs,&lt;br/&gt;
+    new LogManager(logDirs = logDirs.map(_.getAbsoluteFile),&lt;br/&gt;
                    initialOfflineDirs = Array.empty&lt;span class=&quot;error&quot;&gt;&amp;#91;File&amp;#93;&lt;/span&gt;,&lt;br/&gt;
                    topicConfigs = Map(),&lt;br/&gt;
                    initialDefaultConfig = defaultConfig,&lt;/li&gt;
&lt;/ul&gt;





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 21 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3u6f3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>junrao</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>