<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:08:41 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6386] Deprecate KafkaStreams constructor taking StreamsConfig parameter</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6386</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Currently, &lt;tt&gt;KafkaStreams&lt;/tt&gt; constructor has overloads that take either &lt;tt&gt;Properties&lt;/tt&gt; or &lt;tt&gt;StreamsConfig&lt;/tt&gt; a parameters.&lt;/p&gt;

&lt;p&gt;Because &lt;tt&gt;StreamsConfig&lt;/tt&gt; is immutable and is created from a &lt;tt&gt;Properties&lt;/tt&gt; object itself, the constructors accepting &lt;tt&gt;StreamsConfig&lt;/tt&gt; are not useful and adds only boiler plate code. Thus, we should deprecate those constructors in order to remove them eventually.&lt;/p&gt;

&lt;p&gt;KIP:&#160;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-245%3A+Use+Properties+instead+of+StreamsConfig+in+KafkaStreams+constructor&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://cwiki.apache.org/confluence/display/KAFKA/KIP-245%3A+Use+Properties+instead+of+StreamsConfig+in+KafkaStreams+constructor&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13125992">KAFKA-6386</key>
            <summary>Deprecate KafkaStreams constructor taking StreamsConfig parameter</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="bchen225242">Boyang Chen</assignee>
                                    <reporter username="mjsax">Matthias J. Sax</reporter>
                        <labels>
                            <label>beginner</label>
                            <label>kip</label>
                            <label>newbie</label>
                    </labels>
                <created>Tue, 19 Dec 2017 18:21:16 +0000</created>
                <updated>Wed, 25 Apr 2018 09:42:39 +0000</updated>
                            <resolved>Tue, 27 Mar 2018 23:10:37 +0000</resolved>
                                    <version>1.0.0</version>
                                    <fixVersion>2.0.0</fixVersion>
                                    <component>streams</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16301556" author="bchen225242" created="Fri, 22 Dec 2017 15:24:39 +0000"  >&lt;p&gt;Hi I&apos;m new to Kafka repo and would like to contribute. Is there a way I could assign this ticket to myself?&lt;/p&gt;</comment>
                            <comment id="16301826" author="guozhang" created="Fri, 22 Dec 2017 19:11:58 +0000"  >&lt;p&gt;Boyang, I just added you to the contributor list, and assigned this ticket to you.&lt;/p&gt;</comment>
                            <comment id="16302157" author="bchen225242" created="Sat, 23 Dec 2017 01:23:09 +0000"  >&lt;p&gt;Thanks a lot Guozhang! &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16328067" author="mjsax" created="Wed, 17 Jan 2018 00:44:03 +0000"  >&lt;p&gt;&lt;a href=&quot;https://github.com/apache/kafka/pull/4354&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4354&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16416444" author="githubbot" created="Tue, 27 Mar 2018 23:11:24 +0000"  >&lt;p&gt;guozhangwang closed pull request #4354: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6386&quot; title=&quot;Deprecate KafkaStreams constructor taking StreamsConfig parameter&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6386&quot;&gt;&lt;del&gt;KAFKA-6386&lt;/del&gt;&lt;/a&gt;:use Properties instead of StreamsConfig in KafkaStreams constructor&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4354&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4354&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/docs/streams/upgrade-guide.html b/docs/streams/upgrade-guide.html&lt;br/&gt;
index baf9633a0c3..464854c57ad 100644&lt;br/&gt;
&amp;#8212; a/docs/streams/upgrade-guide.html&lt;br/&gt;
+++ b/docs/streams/upgrade-guide.html&lt;br/&gt;
@@ -86,7 +86,11 @@ &amp;lt;h3&amp;gt;&amp;lt;a id=&quot;streams_api_changes_120&quot; href=&quot;#streams_api_changes_120&quot;&amp;gt;Streams API&lt;br/&gt;
         to let users specify inner serdes if the default serde classes are windowed serdes.&lt;br/&gt;
         For more details, see &amp;lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-265%3A+Make+Windowed+Serde+to+public+APIs&quot;&amp;gt;KIP-265&amp;lt;/a&amp;gt;.&lt;br/&gt;
     /&amp;lt;p&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;p&gt;+&lt;br/&gt;
+     &amp;lt;p&amp;gt;&lt;br/&gt;
+	We have deprecated &amp;lt;code&amp;gt;StreamsConfig&amp;lt;/code&amp;gt; in &amp;lt;code&amp;gt;KafkaStreams&amp;lt;/code&amp;gt; constructors. Now we only take in &amp;lt;code&amp;gt;java.util.Properties&amp;lt;/code&amp;gt; since &amp;lt;code&amp;gt;StreamsConfig&amp;lt;/code&amp;gt; is immutable and is created from a Properties object itself.&lt;br/&gt;
+        For more details, see &amp;lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-245%3A+Use+Properties+instead+of+StreamsConfig+in+KafkaStreams+constructor&quot;&amp;gt;KIP-245&amp;lt;/a&amp;gt;.&lt;br/&gt;
+    &amp;lt;/p&amp;gt;&lt;br/&gt;
     &amp;lt;p&amp;gt;&lt;br/&gt;
       Kafka 1.2.0 allows to manipulate timestamps of output records using the Processor API (&amp;lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-251%3A+Allow+timestamp+manipulation+in+Processor+API&quot;&amp;gt;KIP-251&amp;lt;/a&amp;gt;).&lt;br/&gt;
       To enable this new feature, &amp;lt;code&amp;gt;ProcessorContext#forward(...)&amp;lt;/code&amp;gt; was modified.&lt;br/&gt;
diff --git a/streams/src/main/java/org/apache/kafka/streams/KafkaClientSupplier.java b/streams/src/main/java/org/apache/kafka/streams/KafkaClientSupplier.java&lt;br/&gt;
index 2ea5218d647..8a6ec05b4ac 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/main/java/org/apache/kafka/streams/KafkaClientSupplier.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/KafkaClientSupplier.java&lt;br/&gt;
@@ -26,7 +26,7 @@&lt;br/&gt;
 /**&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;{@code KafkaClientSupplier}
&lt;p&gt; can be used to provide custom Kafka clients to a &lt;/p&gt;
{@link KafkaStreams}
&lt;p&gt; instance.&lt;br/&gt;
  *&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* @see KafkaStreams#KafkaStreams(org.apache.kafka.streams.Topology, StreamsConfig, KafkaClientSupplier)&lt;br/&gt;
+ * @see KafkaStreams#KafkaStreams(Topology, java.util.Properties, KafkaClientSupplier)&lt;br/&gt;
  */&lt;br/&gt;
 public interface KafkaClientSupplier 
{
     /**
diff --git a/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java b/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java
index 1a70e4638ef..186276c22d8 100644
--- a/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java
+++ b/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java
@@ -515,31 +515,18 @@ public void onRestoreEnd(final TopicPartition topicPartition, final String store
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* @deprecated use 
{@link #KafkaStreams(Topology, Properties)} instead&lt;br/&gt;
+     * Create a {@code KafkaStreams} instance.&lt;br/&gt;
+     * &amp;lt;p&amp;gt;&lt;br/&gt;
+     * Note: even if you never call {@link #start()} on a {@code KafkaStreams} instance,&lt;br/&gt;
+     * you still must {@link #close()} it to avoid resource leaks.&lt;br/&gt;
+     *&lt;br/&gt;
+     * @param topology the topology specifying the computational logic&lt;br/&gt;
+     * @param props    properties for {@link StreamsConfig}&lt;br/&gt;
+     * @throws StreamsException if any fatal error occurs&lt;br/&gt;
      */&lt;br/&gt;
-    @Deprecated&lt;br/&gt;
-    public KafkaStreams(final org.apache.kafka.streams.processor.TopologyBuilder builder,&lt;br/&gt;
+    public KafkaStreams(final Topology topology,&lt;br/&gt;
                         final Properties props) {
-        this(builder.internalTopologyBuilder, new StreamsConfig(props), new DefaultKafkaClientSupplier());
-    }&lt;br/&gt;
-&lt;br/&gt;
-    /**&lt;br/&gt;
-     * @deprecated use {@link #KafkaStreams(Topology, StreamsConfig)} instead&lt;br/&gt;
-     */&lt;br/&gt;
-    @Deprecated&lt;br/&gt;
-    public KafkaStreams(final org.apache.kafka.streams.processor.TopologyBuilder builder,&lt;br/&gt;
-                        final StreamsConfig config) {
-        this(builder.internalTopologyBuilder, config, new DefaultKafkaClientSupplier());
-    }&lt;br/&gt;
-&lt;br/&gt;
-    /**&lt;br/&gt;
-     * @deprecated use {@link #KafkaStreams(Topology, StreamsConfig, KafkaClientSupplier)} instead&lt;br/&gt;
-     */&lt;br/&gt;
-    @Deprecated&lt;br/&gt;
-    public KafkaStreams(final org.apache.kafka.streams.processor.TopologyBuilder builder,&lt;br/&gt;
-                        final StreamsConfig config,&lt;br/&gt;
-                        final KafkaClientSupplier clientSupplier) {
-        this(builder.internalTopologyBuilder, config, clientSupplier);
+        this(topology.internalTopologyBuilder, new StreamsConfig(props), new DefaultKafkaClientSupplier());
     }&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
@@ -548,13 +535,16 @@ public KafkaStreams(final org.apache.kafka.streams.processor.TopologyBuilder bui&lt;br/&gt;
      * Note: even if you never call {@link #start()} on a {@code KafkaStreams} instance,&lt;br/&gt;
      * you still must {@link #close()} it to avoid resource leaks.&lt;br/&gt;
      *&lt;br/&gt;
-     * @param topology the topology specifying the computational logic&lt;br/&gt;
-     * @param props   properties for {@link StreamsConfig}&lt;br/&gt;
+     * @param topology       the topology specifying the computational logic&lt;br/&gt;
+     * @param props          properties for {@link StreamsConfig}&lt;br/&gt;
+     * @param clientSupplier the Kafka clients supplier which provides underlying producer and consumer clients&lt;br/&gt;
+     *                       for the new {@code KafkaStreams} instance&lt;br/&gt;
      * @throws StreamsException if any fatal error occurs&lt;br/&gt;
      */&lt;br/&gt;
     public KafkaStreams(final Topology topology,&lt;br/&gt;
-                        final Properties props) {&lt;br/&gt;
-        this(topology.internalTopologyBuilder, new StreamsConfig(props), new DefaultKafkaClientSupplier());&lt;br/&gt;
+                        final Properties props,&lt;br/&gt;
+                        final KafkaClientSupplier clientSupplier) {
+        this(topology.internalTopologyBuilder, new StreamsConfig(props), clientSupplier, Time.SYSTEM);
     }&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
@@ -563,13 +553,15 @@ public KafkaStreams(final Topology topology,&lt;br/&gt;
      * Note: even if you never call {@link #start()} on a {@code KafkaStreams} instance,&lt;br/&gt;
      * you still must {@link #close()} it to avoid resource leaks.&lt;br/&gt;
      *&lt;br/&gt;
-     * @param topology the topology specifying the computational logic&lt;br/&gt;
-     * @param config  the Kafka Streams configuration&lt;br/&gt;
+     * @param topology       the topology specifying the computational logic&lt;br/&gt;
+     * @param props          properties for {@link StreamsConfig}&lt;br/&gt;
+     * @param time           {@code Time} implementation; cannot be null&lt;br/&gt;
      * @throws StreamsException if any fatal error occurs&lt;br/&gt;
      */&lt;br/&gt;
     public KafkaStreams(final Topology topology,&lt;br/&gt;
-                        final StreamsConfig config) {&lt;br/&gt;
-        this(topology.internalTopologyBuilder, config, new DefaultKafkaClientSupplier());&lt;br/&gt;
+                        final Properties props,&lt;br/&gt;
+                        final Time time) {
+        this(topology.internalTopologyBuilder, new StreamsConfig(props), new DefaultKafkaClientSupplier(), time);
     }&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
@@ -579,11 +571,60 @@ public KafkaStreams(final Topology topology,&lt;br/&gt;
      * you still must {@link #close()} it to avoid resource leaks.&lt;br/&gt;
      *&lt;br/&gt;
      * @param topology       the topology specifying the computational logic&lt;br/&gt;
-     * @param config         the Kafka Streams configuration&lt;br/&gt;
+     * @param props          properties for {@link StreamsConfig}&lt;br/&gt;
      * @param clientSupplier the Kafka clients supplier which provides underlying producer and consumer clients&lt;br/&gt;
      *                       for the new {@code KafkaStreams} instance&lt;br/&gt;
+     * @param time           {@code Time} implementation; cannot be null&lt;br/&gt;
      * @throws StreamsException if any fatal error occurs&lt;br/&gt;
      */&lt;br/&gt;
+    public KafkaStreams(final Topology topology,&lt;br/&gt;
+                        final Properties props,&lt;br/&gt;
+                        final KafkaClientSupplier clientSupplier,&lt;br/&gt;
+                        final Time time) {
+        this(topology.internalTopologyBuilder, new StreamsConfig(props), clientSupplier, time);
+    }&lt;br/&gt;
+&lt;br/&gt;
+    /**&lt;br/&gt;
+     * @deprecated use {@link #KafkaStreams(Topology, Properties)}
&lt;p&gt; instead&lt;br/&gt;
+     */&lt;br/&gt;
+    @Deprecated&lt;br/&gt;
+    public KafkaStreams(final org.apache.kafka.streams.processor.TopologyBuilder builder,&lt;br/&gt;
+                        final Properties props) &lt;/p&gt;
{
+        this(builder.internalTopologyBuilder, new StreamsConfig(props), new DefaultKafkaClientSupplier());
+    }
&lt;p&gt;+&lt;br/&gt;
+    /**&lt;br/&gt;
+     * @deprecated use &lt;/p&gt;
{@link #KafkaStreams(Topology, Properties)} instead&lt;br/&gt;
+     */&lt;br/&gt;
+    @Deprecated&lt;br/&gt;
+    public KafkaStreams(final org.apache.kafka.streams.processor.TopologyBuilder builder,&lt;br/&gt;
+                        final StreamsConfig config) {
+        this(builder.internalTopologyBuilder, config, new DefaultKafkaClientSupplier());
+    }&lt;br/&gt;
+&lt;br/&gt;
+    /**&lt;br/&gt;
+     * @deprecated use {@link #KafkaStreams(Topology, Properties, KafkaClientSupplier)} instead&lt;br/&gt;
+     */&lt;br/&gt;
+    @Deprecated&lt;br/&gt;
+    public KafkaStreams(final org.apache.kafka.streams.processor.TopologyBuilder builder,&lt;br/&gt;
+                        final StreamsConfig config,&lt;br/&gt;
+                        final KafkaClientSupplier clientSupplier) {
+        this(builder.internalTopologyBuilder, config, clientSupplier);
+    }&lt;br/&gt;
+&lt;br/&gt;
+    /**&lt;br/&gt;
+     * @deprecated use {@link #KafkaStreams(Topology, Properties)}
&lt;p&gt; instead&lt;br/&gt;
+     */&lt;br/&gt;
+    @Deprecated&lt;br/&gt;
+    public KafkaStreams(final Topology topology,&lt;br/&gt;
+                        final StreamsConfig config) &lt;/p&gt;
{
+        this(topology.internalTopologyBuilder, config, new DefaultKafkaClientSupplier());
+    }
&lt;p&gt;+&lt;br/&gt;
+    /**&lt;br/&gt;
+     * @deprecated use &lt;/p&gt;
{@link #KafkaStreams(Topology, Properties, KafkaClientSupplier)}
&lt;p&gt; instead&lt;br/&gt;
+     */&lt;br/&gt;
+    @Deprecated&lt;br/&gt;
     public KafkaStreams(final Topology topology,&lt;br/&gt;
                         final StreamsConfig config,&lt;br/&gt;
                         final KafkaClientSupplier clientSupplier) &lt;/p&gt;
{
@@ -591,13 +632,9 @@ public KafkaStreams(final Topology topology,
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Create a 
{@code KafkaStreams}
&lt;p&gt; instance.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param topology       the topology specifying the computational logic&lt;/li&gt;
	&lt;li&gt;* @param config         the Kafka Streams configuration&lt;/li&gt;
	&lt;li&gt;* @param time           
{@code Time}
&lt;p&gt; implementation; cannot be null&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;* @throws StreamsException if any fatal error occurs&lt;br/&gt;
+     * @deprecated use 
{@link #KafkaStreams(Topology, Properties, Time)}
&lt;p&gt; instead&lt;br/&gt;
      */&lt;br/&gt;
+    @Deprecated&lt;br/&gt;
     public KafkaStreams(final Topology topology,&lt;br/&gt;
                         final StreamsConfig config,&lt;br/&gt;
                         final Time time) {&lt;br/&gt;
diff --git a/streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java b/streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java&lt;br/&gt;
index ecfcad80e81..0eaf9ee127d 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java&lt;br/&gt;
@@ -123,7 +123,7 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;&amp;lt;/ul&amp;gt;&lt;br/&gt;
  *&lt;br/&gt;
  *&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* @see KafkaStreams#KafkaStreams(org.apache.kafka.streams.Topology, StreamsConfig)&lt;br/&gt;
+ * @see KafkaStreams#KafkaStreams(org.apache.kafka.streams.Topology, Properties)&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@see ConsumerConfig&lt;/li&gt;
	&lt;li&gt;@see ProducerConfig&lt;br/&gt;
  */&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java b/streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java&lt;br/&gt;
index 9770173f994..1dc8602c280 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java&lt;br/&gt;
@@ -130,7 +130,7 @@ public void shouldCleanupResourcesOnCloseWithoutPreviousStart() throws Exception&lt;br/&gt;
             Collections.&amp;lt;String&amp;gt;emptySet(), nodes.get(0));&lt;br/&gt;
         MockClientSupplier clientSupplier = new MockClientSupplier();&lt;br/&gt;
         clientSupplier.setClusterForAdminClient(cluster);&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final KafkaStreams streams = new KafkaStreams(builder.build(), new StreamsConfig(props), clientSupplier);&lt;br/&gt;
+        final KafkaStreams streams = new KafkaStreams(builder.build(), props, clientSupplier);&lt;br/&gt;
         streams.close();&lt;br/&gt;
         TestUtils.waitForCondition(new TestCondition() {&lt;br/&gt;
             @Override&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/AbstractJoinIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/AbstractJoinIntegrationTest.java&lt;br/&gt;
index 16d2611a8a3..80ab60647ad 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/integration/AbstractJoinIntegrationTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/integration/AbstractJoinIntegrationTest.java&lt;br/&gt;
@@ -193,7 +193,7 @@ void runTest(final List&amp;lt;List&amp;lt;String&amp;gt;&amp;gt; expectedResult, final String storeName) th&lt;br/&gt;
         assert expectedResult.size() == input.size();&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         IntegrationTestUtils.purgeLocalStreamsState(STREAMS_CONFIG);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;streams = new KafkaStreams(builder.build(), new StreamsConfig(STREAMS_CONFIG));&lt;br/&gt;
+        streams = new KafkaStreams(builder.build(), STREAMS_CONFIG);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         String expectedFinalResult = null;&lt;/p&gt;

&lt;p&gt;@@ -234,7 +234,7 @@ void runTest(final String expectedFinalResult) throws Exception {&lt;br/&gt;
      */&lt;br/&gt;
     void runTest(final String expectedFinalResult, final String storeName) throws Exception {&lt;br/&gt;
         IntegrationTestUtils.purgeLocalStreamsState(STREAMS_CONFIG);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;streams = new KafkaStreams(builder.build(), new StreamsConfig(STREAMS_CONFIG));&lt;br/&gt;
+        streams = new KafkaStreams(builder.build(), STREAMS_CONFIG);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         try {&lt;br/&gt;
             streams.start();&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/PurgeRepartitionTopicIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/PurgeRepartitionTopicIntegrationTest.java&lt;br/&gt;
index 4b983cf2da0..9dfb6dda37e 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/integration/PurgeRepartitionTopicIntegrationTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/integration/PurgeRepartitionTopicIntegrationTest.java&lt;br/&gt;
@@ -166,7 +166,7 @@ public void setup() &lt;/p&gt;
{
                .groupBy(MockMapper.selectKeyKeyValueMapper())
                .count();
 
-        kafkaStreams = new KafkaStreams(builder.build(), new StreamsConfig(streamsConfiguration), time);
+        kafkaStreams = new KafkaStreams(builder.build(), streamsConfiguration, time);
     }

&lt;p&gt;     @After&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java&lt;br/&gt;
index 1da4c580104..57ed161b084 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java&lt;br/&gt;
@@ -145,7 +145,7 @@ public void testRegexMatchesTopicsAWhenCreated() throws Exception {&lt;/p&gt;

&lt;p&gt;         pattern1Stream.to(stringSerde, stringSerde, DEFAULT_OUTPUT_TOPIC);&lt;br/&gt;
         final List&amp;lt;String&amp;gt; assignedTopics = new ArrayList&amp;lt;&amp;gt;();&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;streams = new KafkaStreams(builder.build(), streamsConfig, new DefaultKafkaClientSupplier() {&lt;br/&gt;
+        streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {&lt;br/&gt;
             @Override&lt;br/&gt;
             public Consumer&amp;lt;byte[], byte[]&amp;gt; getConsumer(final Map&amp;lt;String, Object&amp;gt; config) {&lt;br/&gt;
                 return new KafkaConsumer&amp;lt;byte[], byte[]&amp;gt;(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {&lt;br/&gt;
@@ -185,8 +185,6 @@ public void testRegexMatchesTopicsAWhenDeleted() throws Exception {&lt;br/&gt;
         final List&amp;lt;String&amp;gt; expectedFirstAssignment = Arrays.asList(&quot;TEST-TOPIC-A&quot;, &quot;TEST-TOPIC-B&quot;);&lt;br/&gt;
         final List&amp;lt;String&amp;gt; expectedSecondAssignment = Arrays.asList(&quot;TEST-TOPIC-B&quot;);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final StreamsConfig streamsConfig = new StreamsConfig(streamsConfiguration);&lt;br/&gt;
-&lt;br/&gt;
         CLUSTER.createTopics(&quot;TEST-TOPIC-A&quot;, &quot;TEST-TOPIC-B&quot;);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         final StreamsBuilder builder = new StreamsBuilder();&lt;br/&gt;
@@ -196,7 +194,7 @@ public void testRegexMatchesTopicsAWhenDeleted() throws Exception {&lt;br/&gt;
         pattern1Stream.to(stringSerde, stringSerde, DEFAULT_OUTPUT_TOPIC);&lt;/p&gt;

&lt;p&gt;         final List&amp;lt;String&amp;gt; assignedTopics = new ArrayList&amp;lt;&amp;gt;();&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;streams = new KafkaStreams(builder.build(), streamsConfig, new DefaultKafkaClientSupplier() {&lt;br/&gt;
+        streams = new KafkaStreams(builder.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {&lt;br/&gt;
             @Override&lt;br/&gt;
             public Consumer&amp;lt;byte[], byte[]&amp;gt; getConsumer(final Map&amp;lt;String, Object&amp;gt; config) {&lt;br/&gt;
                 return new KafkaConsumer&amp;lt;byte[], byte[]&amp;gt;(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {&lt;br/&gt;
@@ -333,9 +331,8 @@ public void testMultipleConsumersCanReadFromPartitionedTopic() throws Exception&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             final List&amp;lt;String&amp;gt; leaderAssignment = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
             final List&amp;lt;String&amp;gt; followerAssignment = new ArrayList&amp;lt;&amp;gt;();&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;StreamsConfig config = new StreamsConfig(streamsConfiguration);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;partitionedStreamsLeader  = new KafkaStreams(builderLeader.build(), config, new DefaultKafkaClientSupplier() {&lt;br/&gt;
+            partitionedStreamsLeader  = new KafkaStreams(builderLeader.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {&lt;br/&gt;
                 @Override&lt;br/&gt;
                 public Consumer&amp;lt;byte[], byte[]&amp;gt; getConsumer(final Map&amp;lt;String, Object&amp;gt; config) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {                     return new KafkaConsumer&amp;lt;byte[], byte[]&amp;gt;(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {
@@ -347,7 +344,7 @@ public void subscribe(final Pattern topics, final ConsumerRebalanceListener list
 
                 }             }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;);&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;partitionedStreamsFollower  = new KafkaStreams(builderFollower.build(), config, new DefaultKafkaClientSupplier() {&lt;br/&gt;
+            partitionedStreamsFollower  = new KafkaStreams(builderFollower.build(), streamsConfiguration, new DefaultKafkaClientSupplier() {&lt;br/&gt;
                 @Override&lt;br/&gt;
                 public Consumer&amp;lt;byte[], byte[]&amp;gt; getConsumer(final Map&amp;lt;String, Object&amp;gt; config) {&lt;br/&gt;
                     return new KafkaConsumer&amp;lt;byte[], byte[]&amp;gt;(config, new ByteArrayDeserializer(), new ByteArrayDeserializer()) {&lt;/li&gt;
&lt;/ul&gt;





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 33 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3o2xr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>