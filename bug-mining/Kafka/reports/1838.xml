<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:07:03 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6573] KafkaController.brokerInfo not updated on dynamic update</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6573</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;KafkaController.brokerInfo is cached in-memory and used to re-register the broker in ZooKeeper if ZK session expires. It should be kept up-to-date if listeners are dynamically updated.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13139735">KAFKA-6573</key>
            <summary>KafkaController.brokerInfo not updated on dynamic update</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rsivaram">Rajini Sivaram</assignee>
                                    <reporter username="rsivaram">Rajini Sivaram</reporter>
                        <labels>
                    </labels>
                <created>Tue, 20 Feb 2018 18:43:52 +0000</created>
                <updated>Wed, 21 Feb 2018 16:59:16 +0000</updated>
                            <resolved>Wed, 21 Feb 2018 16:59:16 +0000</resolved>
                                    <version>1.1.0</version>
                                    <fixVersion>1.1.0</fixVersion>
                                    <component>controller</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="16371644" author="githubbot" created="Wed, 21 Feb 2018 16:43:28 +0000"  >&lt;p&gt;hachikuji closed pull request #4603: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6573&quot; title=&quot;KafkaController.brokerInfo not updated on dynamic update&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6573&quot;&gt;&lt;del&gt;KAFKA-6573&lt;/del&gt;&lt;/a&gt;: Update brokerInfo in KafkaController on listener update&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4603&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4603&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/core/src/main/scala/kafka/controller/KafkaController.scala b/core/src/main/scala/kafka/controller/KafkaController.scala&lt;br/&gt;
index f36fc798ad6..a8707ad887d 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/controller/KafkaController.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/controller/KafkaController.scala&lt;br/&gt;
@@ -190,6 +190,11 @@ class KafkaController(val config: KafkaConfig, zkClient: KafkaZkClient, time: Ti&lt;br/&gt;
     eventManager.put(controlledShutdownEvent)&lt;br/&gt;
   }&lt;/p&gt;

&lt;p&gt;+  private&lt;span class=&quot;error&quot;&gt;&amp;#91;kafka&amp;#93;&lt;/span&gt; def updateBrokerInfo(newBrokerInfo: BrokerInfo): Unit = &lt;/p&gt;
{
+    this.brokerInfo = newBrokerInfo
+    zkClient.updateBrokerInfoInZk(newBrokerInfo)
+  }
&lt;p&gt;+&lt;br/&gt;
   private def state: ControllerState = eventManager.state&lt;/p&gt;

&lt;p&gt;   /**&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/server/DynamicBrokerConfig.scala b/core/src/main/scala/kafka/server/DynamicBrokerConfig.scala&lt;br/&gt;
index ce4b9e75b7c..3236af01bbb 100755&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/server/DynamicBrokerConfig.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/server/DynamicBrokerConfig.scala&lt;br/&gt;
@@ -751,7 +751,7 @@ class DynamicListenerConfig(server: KafkaServer) extends BrokerReconfigurable wi&lt;br/&gt;
     if (listenersAdded.nonEmpty)&lt;br/&gt;
       server.socketServer.addListeners(listenersAdded)&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;server.zkClient.updateBrokerInfoInZk(server.createBrokerInfo)&lt;br/&gt;
+    server.kafkaController.updateBrokerInfo(server.createBrokerInfo)&lt;br/&gt;
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   private def listenersToMap(listeners: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;EndPoint&amp;#93;&lt;/span&gt;): Map&lt;span class=&quot;error&quot;&gt;&amp;#91;ListenerName, EndPoint&amp;#93;&lt;/span&gt; =&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/zk/KafkaZkClient.scala b/core/src/main/scala/kafka/zk/KafkaZkClient.scala&lt;br/&gt;
index afc8202b88a..6545fde30e9 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/zk/KafkaZkClient.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/zk/KafkaZkClient.scala&lt;br/&gt;
@@ -35,7 +35,7 @@ import org.apache.kafka.common.security.token.delegation.{DelegationToken, Token&lt;br/&gt;
 import org.apache.kafka.common.utils.Time&lt;br/&gt;
 import org.apache.zookeeper.KeeperException.&lt;/p&gt;
{Code, NodeExistsException}
&lt;p&gt; import org.apache.zookeeper.data.&lt;/p&gt;
{ACL, Stat}
&lt;p&gt;-import org.apache.zookeeper.&lt;/p&gt;
{CreateMode, KeeperException}
&lt;p&gt;+import org.apache.zookeeper.&lt;/p&gt;
{CreateMode, KeeperException, ZooKeeper}

&lt;p&gt; import scala.collection.mutable.ArrayBuffer&lt;br/&gt;
 import scala.collection.&lt;/p&gt;
{Seq, mutable}
&lt;p&gt;@@ -61,6 +61,9 @@ class KafkaZkClient private (zooKeeperClient: ZooKeeperClient, isSecure: Boolean&lt;/p&gt;

&lt;p&gt;   import KafkaZkClient._&lt;/p&gt;

&lt;p&gt;+  // Only for testing&lt;br/&gt;
+  private&lt;span class=&quot;error&quot;&gt;&amp;#91;kafka&amp;#93;&lt;/span&gt; def currentZooKeeper: ZooKeeper = zooKeeperClient.currentZooKeeper&lt;br/&gt;
+&lt;br/&gt;
   /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Create a sequential persistent path. That is, the znode will not be automatically deleted upon client&apos;s disconnect&lt;/li&gt;
	&lt;li&gt;and a monotonically increasing number will be appended to its name.&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/zookeeper/ZooKeeperClient.scala b/core/src/main/scala/kafka/zookeeper/ZooKeeperClient.scala&lt;br/&gt;
index 3934fd0ad5d..efbd6e898a8 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/main/scala/kafka/zookeeper/ZooKeeperClient.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/zookeeper/ZooKeeperClient.scala&lt;br/&gt;
@@ -317,7 +317,7 @@ class ZooKeeperClient(connectString: String,&lt;br/&gt;
   }&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   // Only for testing&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private&lt;span class=&quot;error&quot;&gt;&amp;#91;zookeeper&amp;#93;&lt;/span&gt; def currentZooKeeper: ZooKeeper = inReadLock(initializationLock) {&lt;br/&gt;
+  private&lt;span class=&quot;error&quot;&gt;&amp;#91;kafka&amp;#93;&lt;/span&gt; def currentZooKeeper: ZooKeeper = inReadLock(initializationLock) 
{
     zooKeeper
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;diff --git a/core/src/test/scala/integration/kafka/server/DynamicBrokerReconfigurationTest.scala b/core/src/test/scala/integration/kafka/server/DynamicBrokerReconfigurationTest.scala&lt;br/&gt;
index ee3876231b7..f0bd61a0ccc 100644&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/integration/kafka/server/DynamicBrokerReconfigurationTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/integration/kafka/server/DynamicBrokerReconfigurationTest.scala&lt;br/&gt;
@@ -599,6 +599,26 @@ class DynamicBrokerReconfigurationTest extends ZooKeeperTestHarness with SaslSet&lt;br/&gt;
     val invalidHost = &quot;192.168.0.1&quot;&lt;br/&gt;
     alterAdvertisedListener(adminClient, externalAdminClient, &quot;localhost&quot;, invalidHost)&lt;/p&gt;

&lt;p&gt;+    def validateEndpointsInZooKeeper(server: KafkaServer, endpointMatcher: String =&amp;gt; Boolean): Unit = &lt;/p&gt;
{
+      val brokerInfo = zkClient.getBroker(server.config.brokerId)
+      assertTrue(&quot;Broker not registered&quot;, brokerInfo.nonEmpty)
+      val endpoints = brokerInfo.get.endPoints.toString
+      assertTrue(s&quot;Endpoint update not saved $endpoints&quot;, endpointMatcher(endpoints))
+    }
&lt;p&gt;+&lt;br/&gt;
+    // Verify that endpoints have been updated in ZK for all brokers&lt;br/&gt;
+    servers.foreach(validateEndpointsInZooKeeper(_, endpoints =&amp;gt; endpoints.contains(invalidHost)))&lt;br/&gt;
+&lt;br/&gt;
+    // Trigger session expiry and ensure that controller registers new advertised listener after expiry&lt;br/&gt;
+    val controllerEpoch = zkClient.getControllerEpoch&lt;br/&gt;
+    val controllerServer = servers(zkClient.getControllerId.getOrElse(throw new IllegalStateException(&quot;No controller&quot;)))&lt;br/&gt;
+    val controllerZkClient = controllerServer.zkClient&lt;br/&gt;
+    val sessionExpiringClient = createZooKeeperClientToTriggerSessionExpiry(controllerZkClient.currentZooKeeper)&lt;br/&gt;
+    sessionExpiringClient.close()&lt;br/&gt;
+    TestUtils.waitUntilTrue(() =&amp;gt; zkClient.getControllerEpoch != controllerEpoch,&lt;br/&gt;
+      &quot;Controller not re-elected after ZK session expiry&quot;)&lt;br/&gt;
+    TestUtils.retry(10000)(validateEndpointsInZooKeeper(controllerServer, endpoints =&amp;gt; endpoints.contains(invalidHost)))&lt;br/&gt;
+&lt;br/&gt;
     // Verify that producer connections fail since advertised listener is invalid&lt;br/&gt;
     val bootstrap = bootstrapServers.replaceAll(invalidHost, &quot;localhost&quot;) // allow bootstrap connection to succeed&lt;br/&gt;
     val producer1 = createProducer(trustStoreFile1, retries = 0, bootstrap = bootstrap)&lt;br/&gt;
@@ -606,6 +626,7 @@ class DynamicBrokerReconfigurationTest extends ZooKeeperTestHarness with SaslSet&lt;br/&gt;
     val sendFuture = verifyConnectionFailure(producer1)&lt;/p&gt;

&lt;p&gt;     alterAdvertisedListener(adminClient, externalAdminClient, invalidHost, &quot;localhost&quot;)&lt;br/&gt;
+    servers.foreach(validateEndpointsInZooKeeper(_, endpoints =&amp;gt; !endpoints.contains(invalidHost)))&lt;/p&gt;

&lt;p&gt;     // Verify that produce/consume work now&lt;br/&gt;
     val producer = createProducer(trustStoreFile1, retries = 0)&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/zk/ZooKeeperTestHarness.scala b/core/src/test/scala/unit/kafka/zk/ZooKeeperTestHarness.scala&lt;br/&gt;
index 9e7258315d8..a1222977751 100755&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/zk/ZooKeeperTestHarness.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/zk/ZooKeeperTestHarness.scala&lt;br/&gt;
@@ -33,6 +33,7 @@ import org.apache.kafka.clients.producer.KafkaProducer&lt;br/&gt;
 import org.apache.kafka.clients.consumer.internals.AbstractCoordinator&lt;br/&gt;
 import kafka.controller.ControllerEventManager&lt;br/&gt;
 import org.apache.kafka.common.utils.Time&lt;br/&gt;
+import org.apache.zookeeper.&lt;/p&gt;
{WatchedEvent, Watcher, ZooKeeper}

&lt;p&gt; @Category(Array(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;IntegrationTest&amp;#93;&lt;/span&gt;))&lt;br/&gt;
 abstract class ZooKeeperTestHarness extends JUnitSuite with Logging {&lt;br/&gt;
@@ -67,6 +68,18 @@ abstract class ZooKeeperTestHarness extends JUnitSuite with Logging &lt;/p&gt;
{
       CoreUtils.swallow(zookeeper.shutdown(), this)
     Configuration.setConfiguration(null)
   }
&lt;p&gt;+&lt;br/&gt;
+  // Trigger session expiry by reusing the session id in another client&lt;br/&gt;
+  def createZooKeeperClientToTriggerSessionExpiry(zooKeeper: ZooKeeper): ZooKeeper = {&lt;br/&gt;
+    val dummyWatcher = new Watcher {&lt;br/&gt;
+      override def process(event: WatchedEvent): Unit = {}&lt;br/&gt;
+    }&lt;br/&gt;
+    val anotherZkClient = new ZooKeeper(zkConnect, 1000, dummyWatcher,&lt;br/&gt;
+      zooKeeper.getSessionId,&lt;br/&gt;
+      zooKeeper.getSessionPasswd)&lt;br/&gt;
+    assertNull(anotherZkClient.exists(&quot;/nonexistent&quot;, false)) // Make sure new client works&lt;br/&gt;
+    anotherZkClient&lt;br/&gt;
+  }&lt;br/&gt;
 }&lt;/p&gt;

&lt;p&gt; object ZooKeeperTestHarness {&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/zookeeper/ZooKeeperClientTest.scala b/core/src/test/scala/unit/kafka/zookeeper/ZooKeeperClientTest.scala&lt;br/&gt;
index f1c09d7308d..2e0651c9991 100644&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/zookeeper/ZooKeeperClientTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/zookeeper/ZooKeeperClientTest.scala&lt;br/&gt;
@@ -29,8 +29,8 @@ import org.apache.kafka.common.utils.Time&lt;br/&gt;
 import org.apache.zookeeper.KeeperException.&lt;/p&gt;
{Code, NoNodeException}
&lt;p&gt; import org.apache.zookeeper.Watcher.Event.&lt;/p&gt;
{EventType, KeeperState}
&lt;p&gt; import org.apache.zookeeper.ZooKeeper.States&lt;br/&gt;
-import org.apache.zookeeper.&lt;/p&gt;
{CreateMode, WatchedEvent, Watcher, ZooDefs, ZooKeeper}
&lt;p&gt;-import org.junit.Assert.&lt;/p&gt;
{assertArrayEquals, assertEquals, assertFalse, assertNull, assertTrue}
&lt;p&gt;+import org.apache.zookeeper.&lt;/p&gt;
{CreateMode, WatchedEvent, ZooDefs}
&lt;p&gt;+import org.junit.Assert.&lt;/p&gt;
{assertArrayEquals, assertEquals, assertFalse, assertTrue}
&lt;p&gt; import org.junit.&lt;/p&gt;
{After, Before, Test}

&lt;p&gt; import scala.collection.JavaConverters._&lt;br/&gt;
@@ -456,14 +456,7 @@ class ZooKeeperClientTest extends ZooKeeperTestHarness {&lt;br/&gt;
       requestThread.start()&lt;br/&gt;
       sendCompleteSemaphore.acquire() // Wait for request thread to start processing requests&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// Trigger session expiry by reusing the session id in another client&lt;/li&gt;
	&lt;li&gt;val dummyWatcher = new Watcher {&lt;/li&gt;
	&lt;li&gt;override def process(event: WatchedEvent): Unit = {}&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;val anotherZkClient = new ZooKeeper(zkConnect, 1000, dummyWatcher,&lt;/li&gt;
	&lt;li&gt;zooKeeperClient.currentZooKeeper.getSessionId,&lt;/li&gt;
	&lt;li&gt;zooKeeperClient.currentZooKeeper.getSessionPasswd)&lt;/li&gt;
	&lt;li&gt;assertNull(anotherZkClient.exists(&quot;/nonexistent&quot;, false)) // Make sure new client works&lt;br/&gt;
+      val anotherZkClient = createZooKeeperClientToTriggerSessionExpiry(zooKeeperClient.currentZooKeeper)&lt;br/&gt;
       sendSemaphore.release(maxInflightRequests) // Resume a few more sends which may fail&lt;br/&gt;
       anotherZkClient.close()&lt;br/&gt;
       sendSemaphore.release(maxInflightRequests) // Resume a few more sends which may fail&lt;/li&gt;
&lt;/ul&gt;





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 38 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3qe4v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>