<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:04:44 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6185] Selector memory leak with high likelihood of OOM in case of down conversion</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6185</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;We are testing 1.0.0 in a couple of environments.&lt;br/&gt;
Both have about 5 brokers, with two 1.0.0 brokers and the rest 0.11.0.1 brokers.&lt;br/&gt;
One is using on disk message format 0.9.0.1, the other 0.11.0.1&lt;br/&gt;
we have 0.9, 0.10, and 0.11 clients connecting.&lt;/p&gt;

&lt;p&gt;The cluster on the 0.9.0.1 format is running fine for a week.&lt;/p&gt;

&lt;p&gt;But the cluster on the 0.11.0.1 format is consistently having memory issues, only on the two upgraded brokers running 1.0.0.&lt;/p&gt;

&lt;p&gt;The first occurrence of the error comes along with this stack trace&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;{&quot;timestamp&quot;:&quot;2017-11-06 14:22:32,402&quot;,&quot;level&quot;:&quot;ERROR&quot;,&quot;logger&quot;:&quot;kafka.server.KafkaApis&quot;,&quot;thread&quot;:&quot;kafka-request-handler-7&quot;,&quot;message&quot;:&quot;[KafkaApi-1] Error when handling request {replica_id=-1,max_wait_time=500,min_bytes=1,topics=[{topic=maxwell.users,partitions=[{partition=0,fetch_offset=227537,max_bytes=11000000},{partition=4,fetch_offset=354468,max_bytes=11000000},{partition=5,fetch_offset=266524,max_bytes=11000000},{partition=8,fetch_offset=324562,max_bytes=11000000},{partition=10,fetch_offset=292931,max_bytes=11000000},{partition=12,fetch_offset=325718,max_bytes=11000000},{partition=15,fetch_offset=229036,max_bytes=11000000}]}]}&quot;}
java.lang.OutOfMemoryError: Java heap space
        at java.nio.HeapByteBuffer.&amp;lt;init&amp;gt;(HeapByteBuffer.java:57)
        at java.nio.ByteBuffer.allocate(ByteBuffer.java:335)
        at org.apache.kafka.common.record.AbstractRecords.downConvert(AbstractRecords.java:101)
        at org.apache.kafka.common.record.FileRecords.downConvert(FileRecords.java:253)
        at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$convertedPartitionData$1$1$$anonfun$apply$4.apply(KafkaApis.scala:520)
        at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$convertedPartitionData$1$1$$anonfun$apply$4.apply(KafkaApis.scala:518)
        at scala.Option.map(Option.scala:146)
        at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$convertedPartitionData$1$1.apply(KafkaApis.scala:518)
        at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$convertedPartitionData$1$1.apply(KafkaApis.scala:508)
        at scala.Option.flatMap(Option.scala:171)
        at kafka.server.KafkaApis.kafka$server$KafkaApis$$convertedPartitionData$1(KafkaApis.scala:508)
        at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$createResponse$2$1.apply(KafkaApis.scala:556)
        at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$createResponse$2$1.apply(KafkaApis.scala:555)
        at scala.collection.Iterator$class.foreach(Iterator.scala:891)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
        at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
        at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
        at kafka.server.KafkaApis.kafka$server$KafkaApis$$createResponse$2(KafkaApis.scala:555)
        at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$fetchResponseCallback$1$1.apply(KafkaApis.scala:569)
        at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$fetchResponseCallback$1$1.apply(KafkaApis.scala:569)
        at kafka.server.KafkaApis$$anonfun$sendResponseMaybeThrottle$1.apply$mcVI$sp(KafkaApis.scala:2034)
        at kafka.server.ClientRequestQuotaManager.maybeRecordAndThrottle(ClientRequestQuotaManager.scala:52)
        at kafka.server.KafkaApis.sendResponseMaybeThrottle(KafkaApis.scala:2033)
        at kafka.server.KafkaApis.kafka$server$KafkaApis$$fetchResponseCallback$1(KafkaApis.scala:569)
        at kafka.server.KafkaApis$$anonfun$kafka$server$KafkaApis$$processResponseCallback$1$1.apply$mcVI$sp(KafkaApis.scala:588)
        at kafka.server.ClientQuotaManager.maybeRecordAndThrottle(ClientQuotaManager.scala:175)
        at kafka.server.KafkaApis.kafka$server$KafkaApis$$processResponseCallback$1(KafkaApis.scala:587)
        at kafka.server.KafkaApis$$anonfun$handleFetchRequest$3.apply(KafkaApis.scala:604)
        at kafka.server.KafkaApis$$anonfun$handleFetchRequest$3.apply(KafkaApis.scala:604)
        at kafka.server.ReplicaManager.fetchMessages(ReplicaManager.scala:820)
        at kafka.server.KafkaApis.handleFetchRequest(KafkaApis.scala:596)
        at kafka.server.KafkaApis.handle(KafkaApis.scala:100)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And then after a few of those it settles into this kind of pattern&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;{&quot;timestamp&quot;:&quot;2017-11-06 15:06:48,114&quot;,&quot;level&quot;:&quot;ERROR&quot;,&quot;logger&quot;:&quot;kafka.server.KafkaApis&quot;,&quot;thread&quot;:&quot;kafka-request-handler-1&quot;,&quot;message&quot;:&quot;[KafkaApi-1] Error when handling request {replica_id=-1,max_wait_time=500,min_bytes=1,topics=[{topic=maxwell.accounts,partitions=[{partition=4,fetch_offset=560631,max_bytes=11000000},{partition=8,fetch_offset=557589,max_bytes=11000000},{partition=12,fetch_offset=551712,max_bytes=11000000}]}]}&quot;}
java.lang.OutOfMemoryError: Java heap space
{&quot;timestamp&quot;:&quot;2017-11-06 15:06:48,811&quot;,&quot;level&quot;:&quot;ERROR&quot;,&quot;logger&quot;:&quot;kafka.server.KafkaApis&quot;,&quot;thread&quot;:&quot;kafka-request-handler-7&quot;,&quot;message&quot;:&quot;[KafkaApi-1] Error when handling request {replica_id=-1,max_wait_time=500,min_bytes=1,topics=[{topic=maxwell.accounts,partitions=[{partition=4,fetch_offset=560631,max_bytes=11000000},{partition=8,fetch_offset=557589,max_bytes=11000000},{partition=12,fetch_offset=551712,max_bytes=11000000}]}]}&quot;}
java.lang.OutOfMemoryError: Java heap space
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;ve attached the heap use graphs. It steadily increases to max at which time the error starts appearing.&lt;/p&gt;

&lt;p&gt;I&apos;ve tripled the heap space for one of the 1.0.0 hosts to see what happens, and it similarly climbs to near 6, then similarly starts having java.lang.OutOfMemoryError errors. I&apos;ve attached those heap space graphs also, where the line that starts climbing from 2gb was when it was restarted with 6gb heap. The out of memory error started right at the peak of the flatline.&lt;/p&gt;

&lt;p&gt;Here&apos;s a snippit from the broker logs: &lt;a href=&quot;https://gist.github.com/brettrann/4bb8041e884a299b7b0b12645a04492d&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://gist.github.com/brettrann/4bb8041e884a299b7b0b12645a04492d&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I&apos;ve redacted some group names because I&apos;d need to check with the teams about making them public. Let me know what more is needed and I can gather it. This is a test cluster and the problem appears reproducible easily enough. Happy to gather as much info as needed.&lt;/p&gt;

&lt;p&gt;Our config is: &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;broker.id=2
delete.topic.enable=true
auto.create.topics.enable=false
auto.leader.rebalance.enable=true
inter.broker.protocol.version=0.11.0.1
log.message.format.version=0.11.0.1
group.max.session.timeout.ms = 300000
port=9092
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
replica.fetch.max.bytes=10485760
log.dirs=/data/kafka/logs
num.partitions=1
num.recovery.threads.per.data.dir=1
log.retention.hours=168
offsets.retention.minutes=10080
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
log.cleaner.enable=true
zookeeper.connect=zoo1:2181,zoo2:2181,zoo3:2181/kafka
zookeeper.connection.timeout.ms=6000
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This was also reported attached to the end of this ticket &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6042&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/KAFKA-6042&lt;/a&gt; which is a broker lockup/FD issue, but a new ticket was requested.&lt;/p&gt;</description>
                <environment>Ubuntu 14.04.5 LTS&lt;br/&gt;
5 brokers: 1&amp;amp;2 on 1.0.0 3,4,5 on 0.11.0.1&lt;br/&gt;
inter.broker.protocol.version=0.11.0.1&lt;br/&gt;
log.message.format.version=0.11.0.1&lt;br/&gt;
clients a mix of 0.9, 0.10, 0.11</environment>
        <key id="13116865">KAFKA-6185</key>
            <summary>Selector memory leak with high likelihood of OOM in case of down conversion</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rsivaram">Rajini Sivaram</assignee>
                                    <reporter username="brettrann">Brett Rann</reporter>
                        <labels>
                            <label>regression</label>
                    </labels>
                <created>Wed, 8 Nov 2017 03:36:32 +0000</created>
                <updated>Thu, 18 Jan 2018 22:55:53 +0000</updated>
                            <resolved>Thu, 9 Nov 2017 16:25:35 +0000</resolved>
                                    <version>1.0.0</version>
                                    <fixVersion>1.0.1</fixVersion>
                    <fixVersion>1.1.0</fixVersion>
                                    <component>core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>14</watches>
                                                                                                                <comments>
                            <comment id="16243434" author="omkreddy" created="Wed, 8 Nov 2017 06:26:57 +0000"  >&lt;p&gt;Can we take periodic output of the below given jmap command?. This may help us to identity the root cause.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;jdk/bin/jmap -histo:live PID&lt;/p&gt;&lt;/blockquote&gt;</comment>
                            <comment id="16243482" author="ijuma" created="Wed, 8 Nov 2017 07:29:13 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brettrann&quot; class=&quot;user-hover&quot; rel=&quot;brettrann&quot;&gt;brettrann&lt;/a&gt;, the 0.11.0.1 brokers don&apos;t have the OOM issues even though they&apos;re also down converting to the old message format?&lt;/p&gt;</comment>
                            <comment id="16243511" author="brettrann" created="Wed, 8 Nov 2017 08:14:37 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt; that&apos;s right, the 0.11.0.1 brokers are the &quot;steady&quot; lines in those heap size graphs and performing fine as far as I can see, as they were when they were just a pure 0.11.0.1 cluster.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=omkreddy&quot; class=&quot;user-hover&quot; rel=&quot;omkreddy&quot;&gt;omkreddy&lt;/a&gt; I&apos;m now running&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;while true; do sudo -u kafka jmap -histo:live 25200 &amp;gt; jmap-$(date --iso-8601=minutes).txt; sleep 900; done
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;on both kafka1 and kafka2.&lt;/p&gt;

&lt;p&gt;I just restarted kafka1 so within a day it should exhibit the first memory issue about translating down.&lt;br/&gt;
kafka2 is the one with the tripled heap space size, and is already past the memory issue and occasionally giving the second style heap error with no mention of translating down.&lt;/p&gt;

&lt;p&gt;Here&apos;s the first result of each:&lt;/p&gt;

&lt;p&gt;kafka1: &lt;a href=&quot;https://gist.github.com/brettrann/8dfce0b8aa0418f32e3e3d0eea86f90a&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://gist.github.com/brettrann/8dfce0b8aa0418f32e3e3d0eea86f90a&lt;/a&gt;&lt;br/&gt;
kafka2: &lt;a href=&quot;https://gist.github.com/brettrann/30198a68ba0ff30d0b526c4af7b68f94&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://gist.github.com/brettrann/30198a68ba0ff30d0b526c4af7b68f94&lt;/a&gt;&lt;/p&gt;
</comment>
                            <comment id="16243580" author="ijuma" created="Wed, 8 Nov 2017 09:24:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brett_s_r&quot; class=&quot;user-hover&quot; rel=&quot;brett_s_r&quot;&gt;brett_s_r&lt;/a&gt;, two questions:&lt;br/&gt;
1. Seems like compression is not being used. Is that correct?&lt;br/&gt;
2. Do you know what is the average message size?&lt;/p&gt;</comment>
                            <comment id="16243630" author="ijuma" created="Wed, 8 Nov 2017 09:55:05 +0000"  >&lt;p&gt;One more question: no quotas are set, right?&lt;/p&gt;</comment>
                            <comment id="16243653" author="rsivaram" created="Wed, 8 Nov 2017 10:11:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brettrann&quot; class=&quot;user-hover&quot; rel=&quot;brettrann&quot;&gt;brettrann&lt;/a&gt; Can you enable heap dump on OOM? It will help to track what objects are leaking and what is holding the reference. Thank you!&lt;/p&gt;</comment>
                            <comment id="16244022" author="ijuma" created="Wed, 8 Nov 2017 14:28:01 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rsivaram&quot; class=&quot;user-hover&quot; rel=&quot;rsivaram&quot;&gt;rsivaram&lt;/a&gt; and I have been looking at this and the current thinking is that it is a regression caused by &lt;a href=&quot;https://github.com/apache/kafka/commit/47ee8e954df62b9a79099e944ec4be29afe046f6#diff-d71b50516bd2143d208c14563842390aR92&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/commit/47ee8e954df62b9a79099e944ec4be29afe046f6#diff-d71b50516bd2143d208c14563842390aR92&lt;/a&gt; (KIP-72). `KafkaChannel` references are retained by `explicitlyMutedChannels` even after the channel is closed. If down conversion is taking place, the whole record batch will be retained by the channel and this can easily lead to an OOM (500 10 MB messages would exhaust a 5 GB heap). Verification of the theory and a fix are in progress.&lt;/p&gt;</comment>
                            <comment id="16244158" author="omkreddy" created="Wed, 8 Nov 2017 15:32:33 +0000"  >&lt;p&gt;@ijuma  Heap histogram is also contains large number of KafkaChannel/SocketChannelImpl live instances.&lt;/p&gt;</comment>
                            <comment id="16244167" author="ijuma" created="Wed, 8 Nov 2017 15:35:05 +0000"  >&lt;p&gt;Yes, a heap dump provided by Brett is how we came to that conclusion.&lt;/p&gt;</comment>
                            <comment id="16244252" author="githubbot" created="Wed, 8 Nov 2017 16:23:30 +0000"  >&lt;p&gt;GitHub user rajinisivaram opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/4193&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4193&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6185&quot; title=&quot;Selector memory leak with high likelihood of OOM in case of down conversion&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6185&quot;&gt;&lt;del&gt;KAFKA-6185&lt;/del&gt;&lt;/a&gt;: Remove channels from explictlyMutedChannels set when closed&lt;/p&gt;



&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/rajinisivaram/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/rajinisivaram/kafka&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6185&quot; title=&quot;Selector memory leak with high likelihood of OOM in case of down conversion&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6185&quot;&gt;&lt;del&gt;KAFKA-6185&lt;/del&gt;&lt;/a&gt;-oom&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/4193.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4193.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #4193&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;</comment>
                            <comment id="16244999" author="brettrann" created="Thu, 9 Nov 2017 00:26:23 +0000"  >&lt;p&gt;Moved this to slack last night to make the most of time. Updating the ticket from our chats:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;1. Seems like compression is not being used. Is that correct?&lt;br/&gt;
2. Do you know what is the average message size?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;1. We for sure have very active producers compressing. And I know there are some that explicitly don&apos;t. We don&apos;t set this at a topic config.&lt;br/&gt;
2. Our busiest topic has a maximum of 2MB messages, but most are well below that. They&apos;d well be on average higher than what is often normal for kafka. Other topics are more &apos;normal&apos;.&lt;br/&gt;
On that test cluster in the last hour peak was 1750 messages at 1100KB.  So about 628 bytes.  The minimum was 370 and 140KB.  So about 380 bytes.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;One more question: no quotas are set, right?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Right.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Can you enable heap dump on OOM? It will help to track what objects are leaking and what is holding the reference. Thank you!&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Done. Will kick in next restart. Still checking status this morning but I&apos;ll restart one of them.&lt;/p&gt;

&lt;p&gt;Also sent you a dump last night also for the affected broker.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;jmap -dump:live,format=b,file=heap.bin &amp;lt;pid&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And added some metrics&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;MBean: kafka.network:type=RequestMetrics,name=RequestBytes,request=&amp;lt;apiKey&amp;gt;
MBean: kafka.network:type=RequestMetrics,name=TemporaryMemoryBytes,request=&amp;lt;apiKey&amp;gt;
MBean: kafka.server:type=BrokerTopicMetrics,name=FetchMessageConversionsPerSec,topic=([-.\w]+)
MBean: kafka.server:type=BrokerTopicMetrics,name=ProduceMessageConversionsPerSec,topic=([-.\w]+)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Where &amp;lt;apiKey&amp;gt; was (Fetch|Produce)&lt;/p&gt;

&lt;p&gt;Let me know when you would like us to build and test your patch. Thanks!&lt;/p&gt;</comment>
                            <comment id="16245005" author="ijuma" created="Thu, 9 Nov 2017 00:31:03 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brettrann&quot; class=&quot;user-hover&quot; rel=&quot;brettrann&quot;&gt;brettrann&lt;/a&gt;, you can either try Rajini&apos;s branch (&lt;a href=&quot;https://github.com/rajinisivaram/kafka/tree/KAFKA-6185-oom&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/rajinisivaram/kafka/tree/KAFKA-6185-oom&lt;/a&gt;) or wait until we merge this to the 1.0 branch (should happen tomorrow morning UK time).&lt;/p&gt;</comment>
                            <comment id="16245918" author="githubbot" created="Thu, 9 Nov 2017 16:08:08 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/4193&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4193&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16247049" author="brettrann" created="Fri, 10 Nov 2017 05:51:29 +0000"  >&lt;p&gt;I have a build ready. Am just waiting for the issue to reoccur after some restarts yesterday, then will deploy it to verify.&lt;/p&gt;</comment>
                            <comment id="16248759" author="brettrann" created="Sun, 12 Nov 2017 01:58:04 +0000"  >&lt;p&gt;and it&apos;s deployed. If it runs without ever diminishing GC reclaims for 2-3 days &amp;#8211; which is the consistent precursor to the sharp spike to OOM &amp;#8211; it&apos;s good.&lt;/p&gt;</comment>
                            <comment id="16248762" author="ijuma" created="Sun, 12 Nov 2017 02:04:02 +0000"  >&lt;p&gt;Thanks for reporting back &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brettrann&quot; class=&quot;user-hover&quot; rel=&quot;brettrann&quot;&gt;brettrann&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="16253043" author="brettrann" created="Wed, 15 Nov 2017 07:01:18 +0000"  >&lt;p&gt;&lt;b&gt;update&lt;/b&gt; the fix ends up in the client jar, so dropping it in like that didn&apos;t work.  Instead I&apos;ve deployed the full kafka_2.11-1.0.1-SNAPSHOT.tgz that gets built and they&apos;re both now running on that.&lt;/p&gt;

&lt;p&gt;Steps I took to build and deploy:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt; $ gradle
------------------------------------------------------------
Gradle 4.3
------------------------------------------------------------

Build time:   2017-10-30 15:43:29 UTC
Revision:     c684c202534c4138b51033b52d871939b8d38d72

Groovy:       2.4.12
Ant:          Apache Ant(TM) version 1.9.6 compiled on June 29 2015
JVM:          1.8.0_152 (Oracle Corporation 25.152-b16)
OS:           Mac OS X 10.12.6 x86_64

java version &quot;1.8.0_152&quot;
Java(TM) SE Runtime Environment (build 1.8.0_152-b16)
Java HotSpot(TM) 64-Bit Server VM (build 25.152-b16, mixed mode)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;git clone git@github.com:apache/kafka.git
git checkout 1.0
git branch -v
* 1.0   1a5a547bb KAFKA-6190: Use consumer.position() instead of record.offset() to advance in GlobalKTable restoration to avoid transactional control messages
trunk d04daf570 MINOR: Exclude Committer Checklist section from commit message
gradle
./gradlew clean releaseTarGz
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&amp;lt;snip&amp;gt;&lt;br/&gt;
note: came back to edit this message later to be more clear of the steps finally taken to deploy.&lt;/p&gt;</comment>
                            <comment id="16257860" author="brettrann" created="Sat, 18 Nov 2017 01:46:41 +0000"  >&lt;p&gt;Confirming this patch fixed our issue. Since it was deployed properly, no more heavy memory leaking.&lt;br/&gt;
&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://www.evernote.com/l/Ah_dUOQiNLhNEaxZ6oNvgAj7KWwHh3xD8q8B/image.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12896565" name="Kafka_Internals___Datadog.png" size="33258" author="brettrann" created="Wed, 8 Nov 2017 03:13:49 +0000"/>
                            <attachment id="12896566" name="Kafka_Internals___Datadog.png" size="28443" author="brettrann" created="Wed, 8 Nov 2017 03:09:06 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3mivj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>