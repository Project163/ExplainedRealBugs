<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:08:49 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6728] Kafka Connect Header Null Pointer Exception</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6728</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;I am trying to use the newly released Kafka Connect that supports headers by using the standalone connector to write to a text file (so in this case I am only using the sink component)&lt;/p&gt;

&lt;p&gt;I am sadly greeted by a NullPointerException :&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;ERROR WorkerSinkTask{id=local-file-sink-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:172)
java.lang.NullPointerException
&#160;&#160; &#160;at org.apache.kafka.connect.runtime.WorkerSinkTask.convertHeadersFor(WorkerSinkTask.java:501)
&#160;&#160; &#160;at org.apache.kafka.connect.runtime.WorkerSinkTask.convertMessages(WorkerSinkTask.java:469)
&#160;&#160; &#160;at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:301)
&#160;&#160; &#160;at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:205)
&#160;&#160; &#160;at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:173)
&#160;&#160; &#160;at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:170)
&#160;&#160; &#160;at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:214)
&#160;&#160; &#160;at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
&#160;&#160; &#160;at java.util.concurrent.FutureTask.run(FutureTask.java:266)
&#160;&#160; &#160;at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
&#160;&#160; &#160;at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
&#160;&#160; &#160;at java.lang.Thread.run(Thread.java:748)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I launched zookeeper and kafka 1.1.0 locally and sent a ProducerRecord[String, Array&lt;span class=&quot;error&quot;&gt;&amp;#91;Byte&amp;#93;&lt;/span&gt;] using a KafkaProducer[String, Array&lt;span class=&quot;error&quot;&gt;&amp;#91;Byte&amp;#93;&lt;/span&gt;] with a header that has a key and value.&lt;/p&gt;

&lt;p&gt;I can read the record with a console consumer as well as using a KafkaConsumer (where in this case I can see the content of the header of the record I sent previously) so no problem here.&lt;/p&gt;

&lt;p&gt;I only made two changes to the kafka configuration:&lt;br/&gt;
 &#160;&#160;&#160; - I used the StringConverter for the key and the ByteArrayConverter for the value. &lt;br/&gt;
 &#160;&#160;&#160; - I also changed the topic where the sink would connect to.&lt;/p&gt;

&lt;p&gt;If I forgot something please tell me so as it is the first time I am creating an issue on Jira.&lt;/p&gt;</description>
                <environment>Linux Mint</environment>
        <key id="13149175">KAFKA-6728</key>
            <summary>Kafka Connect Header Null Pointer Exception</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rhauch">Randall Hauch</assignee>
                                    <reporter username="hwki">Philippe Hong</reporter>
                        <labels>
                    </labels>
                <created>Fri, 30 Mar 2018 14:50:17 +0000</created>
                <updated>Wed, 25 Apr 2018 09:41:47 +0000</updated>
                            <resolved>Tue, 3 Apr 2018 15:48:41 +0000</resolved>
                                    <version>1.1.0</version>
                                    <fixVersion>1.1.1</fixVersion>
                    <fixVersion>2.0.0</fixVersion>
                                    <component>connect</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16420634" author="yuzhihong@gmail.com" created="Fri, 30 Mar 2018 15:44:11 +0000"  >&lt;p&gt;Here is the related line where NPE was thrown:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
               SchemaAndValue schemaAndValue = headerConverter.toConnectHeader(topic, recordHeader.key(), recordHeader.value());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Looks like recordHeader was null.&lt;/p&gt;</comment>
                            <comment id="16420783" author="githubbot" created="Fri, 30 Mar 2018 18:00:24 +0000"  >&lt;p&gt;tedyu opened a new pull request #4800: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6728&quot; title=&quot;Kafka Connect Header Null Pointer Exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6728&quot;&gt;&lt;del&gt;KAFKA-6728&lt;/del&gt;&lt;/a&gt; Kafka Connect Header Null Pointer Exception&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4800&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4800&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Guard against potential null recordHeader in WorkerSinkTask#convertHeadersFor&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16423358" author="githubbot" created="Tue, 3 Apr 2018 01:37:29 +0000"  >&lt;p&gt;rhauch opened a new pull request #4815: &lt;span class=&quot;error&quot;&gt;&amp;#91;WIP&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6728&quot; title=&quot;Kafka Connect Header Null Pointer Exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6728&quot;&gt;&lt;del&gt;KAFKA-6728&lt;/del&gt;&lt;/a&gt;: Corrected the worker&#8217;s instantiation of the HeaderConverter&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4815&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4815&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   &lt;b&gt;DO NOT MERGE: This is a work in progress, and will need to be changed to the `trunk` branch before this can be merged. This is still undergoing testing.&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;   When the `header.converter` is not specified in the worker config or the connector config, a bug in the `Plugins` test causes it to never instantiate the `HeaderConverter` instance, even though there is a default value.&lt;/p&gt;

&lt;p&gt;   This is a problem as soon as the connector deals with headers, either in records created by a source connector or in messages on the Kafka topics consumed by a sink connector. As soon as that happens, a NPE occurs.&lt;/p&gt;

&lt;p&gt;   A workaround is to explicitly set the `header.converter` configuration property, but this was added in AK 1.1 and thus means that upgrading to AK 1.1 will not be backward compatible and will require this configuration change.&lt;/p&gt;

&lt;p&gt;   *Summary of testing strategy (including rationale)&lt;br/&gt;
   for the feature or bug fix. Unit and/or integration&lt;br/&gt;
   tests are expected for any behaviour change and&lt;br/&gt;
   system tests should be considered for larger changes.*&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16423380" author="rhauch" created="Tue, 3 Apr 2018 02:06:08 +0000"  >&lt;p&gt;Added a second PR (see previous message) that attempts to fix the NPE that results from the Connect worker not instantiating a HeaderConverter when the worker configuration (or connector configuration) does not specify a &lt;tt&gt;header.converter&lt;/tt&gt; value and the default is to be used. In this case, the &lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/isolation/Plugins.java#L198-L201&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Plugins.newHeaderConverter(...)&lt;/a&gt; method appears to be an issue: when no &lt;tt&gt;header.converter&lt;/tt&gt; is specified, the original properties will not contain the &lt;tt&gt;header.converter&lt;/tt&gt; key, so the method will always return null.&lt;/p&gt;</comment>
                            <comment id="16423452" author="rhauch" created="Tue, 3 Apr 2018 04:19:55 +0000"  >&lt;p&gt;Testing with a test source connector reveals the same problem:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[2018-04-02 21:59:28,357] INFO Record: SourceRecord{sourcePartition={my-source=0}, sourceOffset={offset=1}} ConnectRecord{topic=&apos;my-topic&apos;, kafkaPartition=null, key=key-1, value=value-1, timestamp=null, headers=ConnectHeaders(headers=[ConnectHeader(key=my.header, value=MyHeaderValue, schema=Schema{STRING})])} (com.mycompany.examples.MySourceTask:79)
[2018-04-02 21:59:28,358] INFO MySourceTask.poll() - returning 1 record (com.mycompany.examples.MySourceTask:54)
[2018-04-02 21:59:28,359] INFO WorkerSourceTask{id=my-test-source-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:328)
[2018-04-02 21:59:28,359] INFO WorkerSourceTask{id=my-test-source-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:345)
[2018-04-02 21:59:28,360] ERROR WorkerSourceTask{id=my-test-source-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:172)
java.lang.NullPointerException
	at org.apache.kafka.connect.runtime.WorkerSourceTask.convertHeaderFor(WorkerSourceTask.java:296)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.sendRecords(WorkerSourceTask.java:226)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.execute(WorkerSourceTask.java:194)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:170)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:214)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[2018-04-02 21:59:28,361] ERROR WorkerSourceTask{id=my-test-source-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:173)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Adding the following to the connector configuration results in a successful run:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
header.converter=org.apache.kafka.connect.storage.SimpleHeaderConverter
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This demonstrates that the problem is not with the message headers (since this test connector is writing headers correctly using the Connect API), but instead that the NPE results from the Worker not properly instantiating the HeaderConverter.&lt;/p&gt;

&lt;p&gt;Removing the &lt;tt&gt;header.converter&lt;/tt&gt; property from the connector configuration and temporarily replacing the &lt;tt&gt;connect-runtime-1.1.0.jar&lt;/tt&gt; with one built with my aforementioned PR tested manually using a custom source connector that outputs header values with 8 different combinations for the &lt;tt&gt;header.converter&lt;/tt&gt; configuration settings:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;default value&lt;/li&gt;
	&lt;li&gt;worker configuration has &lt;tt&gt;header.converter&lt;/tt&gt; explicitly set to the default&lt;/li&gt;
	&lt;li&gt;worker configuration has &lt;tt&gt;header.converter&lt;/tt&gt; set to a custom{{HeaderConverter}} implementation in the same plugin&lt;/li&gt;
	&lt;li&gt;worker configuration has &lt;tt&gt;header.converter&lt;/tt&gt; set to a custom &lt;tt&gt;HeaderConverter&lt;/tt&gt; implementation in a &lt;em&gt;different&lt;/em&gt; plugin&lt;/li&gt;
	&lt;li&gt;connector configuration has &lt;tt&gt;header.converter&lt;/tt&gt; explicitly set to the default&lt;/li&gt;
	&lt;li&gt;connector configuration has &lt;tt&gt;header.converter&lt;/tt&gt; set to a custom &lt;tt&gt;HeaderConverter&lt;/tt&gt; implementation in the same plugin&lt;/li&gt;
	&lt;li&gt;connector configuration has &lt;tt&gt;header.converter&lt;/tt&gt; set to a custom &lt;tt&gt;HeaderConverter&lt;/tt&gt; implementation in a &lt;em&gt;different&lt;/em&gt; plugin&lt;/li&gt;
	&lt;li&gt;worker configuration has &lt;tt&gt;header.converter&lt;/tt&gt; explicitly set to the default, and the connector configuration has &lt;tt&gt;header.converter&lt;/tt&gt; set to a custom &lt;tt&gt;HeaderConverter&lt;/tt&gt; implementation in a &lt;em&gt;different&lt;/em&gt; plugin&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;The worker created the correct &lt;tt&gt;HeaderConverter&lt;/tt&gt; implementation with the correct configuration in all of these tests.&lt;/p&gt;

&lt;p&gt;Finally, the default configuration was used with the aforementioned custom source connector that generated records with headers, and an S3 connector that consumes the records with headers (but didn&apos;t do anything with them). This test also passed.&lt;/p&gt;</comment>
                            <comment id="16423455" author="githubbot" created="Tue, 3 Apr 2018 04:25:27 +0000"  >&lt;p&gt;tedyu closed pull request #4800: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6728&quot; title=&quot;Kafka Connect Header Null Pointer Exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6728&quot;&gt;&lt;del&gt;KAFKA-6728&lt;/del&gt;&lt;/a&gt; Kafka Connect Header Null Pointer Exception&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4800&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4800&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java&lt;br/&gt;
index 2ba785c4668..fe103af4a07 100644&lt;br/&gt;
&amp;#8212; a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java&lt;br/&gt;
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java&lt;br/&gt;
@@ -498,6 +498,7 @@ private Headers convertHeadersFor(ConsumerRecord&amp;lt;byte[], byte[]&amp;gt; record) {&lt;br/&gt;
         if (recordHeaders != null) {&lt;br/&gt;
             String topic = record.topic();&lt;br/&gt;
             for (org.apache.kafka.common.header.Header recordHeader : recordHeaders) &lt;/p&gt;
{
+                if (recordHeader == null) continue;
                 SchemaAndValue schemaAndValue = headerConverter.toConnectHeader(topic, recordHeader.key(), recordHeader.value());
                 result.add(recordHeader.key(), schemaAndValue);
             }
&lt;p&gt;diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSourceTask.java b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSourceTask.java&lt;br/&gt;
index 6ef5ae3201c..fb712c7aeda 100644&lt;br/&gt;
&amp;#8212; a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSourceTask.java&lt;br/&gt;
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSourceTask.java&lt;br/&gt;
@@ -292,6 +292,7 @@ private RecordHeaders convertHeaderFor(SourceRecord record) {&lt;br/&gt;
         if (headers != null) {&lt;br/&gt;
             String topic = record.topic();&lt;br/&gt;
             for (Header header : headers) {&lt;br/&gt;
+                if (header == null) continue;&lt;br/&gt;
                 String key = header.key();&lt;br/&gt;
                 byte[] rawHeader = headerConverter.fromConnectHeader(topic, key, header.schema(), header.value());&lt;br/&gt;
                 result.add(key, rawHeader);&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16423740" author="hwki" created="Tue, 3 Apr 2018 09:34:16 +0000"  >&lt;p&gt;Thank you, adding header.converter=org.apache.kafka.connect.storage.SimpleHeaderConverter solved my issue as you mentioned. &lt;br/&gt;
Good job on implementing a more convenient and lasting fix.&lt;/p&gt;</comment>
                            <comment id="16424194" author="ewencp" created="Tue, 3 Apr 2018 15:48:41 +0000"  >&lt;p&gt;Issue resolved by pull request 4815&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/pull/4815&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4815&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16424197" author="githubbot" created="Tue, 3 Apr 2018 15:49:59 +0000"  >&lt;p&gt;ewencp closed pull request #4815: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6728&quot; title=&quot;Kafka Connect Header Null Pointer Exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6728&quot;&gt;&lt;del&gt;KAFKA-6728&lt;/del&gt;&lt;/a&gt;: Corrected the worker&#8217;s instantiation of the HeaderConverter&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4815&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4815&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/ConnectorConfig.java b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/ConnectorConfig.java&lt;br/&gt;
index 0a895f67cf8..fd05af57a64 100644&lt;br/&gt;
&amp;#8212; a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/ConnectorConfig.java&lt;br/&gt;
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/ConnectorConfig.java&lt;br/&gt;
@@ -76,7 +76,9 @@&lt;br/&gt;
     public static final String HEADER_CONVERTER_CLASS_CONFIG = WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG;&lt;br/&gt;
     public static final String HEADER_CONVERTER_CLASS_DOC = WorkerConfig.HEADER_CONVERTER_CLASS_DOC;&lt;br/&gt;
     public static final String HEADER_CONVERTER_CLASS_DISPLAY = &quot;Header converter class&quot;;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public static final String HEADER_CONVERTER_CLASS_DEFAULT = WorkerConfig.HEADER_CONVERTER_CLASS_DEFAULT;&lt;br/&gt;
+    // The Connector config should not have a default for the header converter, since the absence of a config property means that&lt;br/&gt;
+    // the worker config settings should be used. Thus, we set the default to null here.&lt;br/&gt;
+    public static final String HEADER_CONVERTER_CLASS_DEFAULT = null;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     public static final String TASKS_MAX_CONFIG = &quot;tasks.max&quot;;&lt;br/&gt;
     private static final String TASKS_MAX_DOC = &quot;Maximum number of tasks to use for this connector.&quot;;&lt;br/&gt;
diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java&lt;br/&gt;
index e3d9cf45901..1c6465855ff 100644&lt;br/&gt;
&amp;#8212; a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java&lt;br/&gt;
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java&lt;br/&gt;
@@ -397,12 +397,21 @@ public boolean startTask(&lt;br/&gt;
             );&lt;br/&gt;
             if (keyConverter == null) {&lt;br/&gt;
                 keyConverter = plugins.newConverter(config, WorkerConfig.KEY_CONVERTER_CLASS_CONFIG, ClassLoaderUsage.PLUGINS);&lt;br/&gt;
+                log.info(&quot;Set up the key converter {} for task {} using the worker config&quot;, keyConverter.getClass(), id);&lt;br/&gt;
+            } else {&lt;br/&gt;
+                log.info(&quot;Set up the key converter {} for task {} using the connector config&quot;, keyConverter.getClass(), id);&lt;br/&gt;
             }&lt;br/&gt;
             if (valueConverter == null) {&lt;br/&gt;
                 valueConverter = plugins.newConverter(config, WorkerConfig.VALUE_CONVERTER_CLASS_CONFIG, ClassLoaderUsage.PLUGINS);&lt;br/&gt;
+                log.info(&quot;Set up the value converter {} for task {} using the worker config&quot;, valueConverter.getClass(), id);&lt;br/&gt;
+            } else {&lt;br/&gt;
+                log.info(&quot;Set up the value converter {} for task {} using the connector config&quot;, valueConverter.getClass(), id);&lt;br/&gt;
             }&lt;br/&gt;
             if (headerConverter == null) {&lt;br/&gt;
                 headerConverter = plugins.newHeaderConverter(config, WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG, ClassLoaderUsage.PLUGINS);&lt;br/&gt;
+                log.info(&quot;Set up the header converter {} for task {} using the worker config&quot;, headerConverter.getClass(), id);&lt;br/&gt;
+            } else {&lt;br/&gt;
+                log.info(&quot;Set up the header converter {} for task {} using the connector config&quot;, headerConverter.getClass(), id);&lt;br/&gt;
             }&lt;/p&gt;

&lt;p&gt;             workerTask = buildWorkerTask(connConfig, id, task, statusListener, initialState, keyConverter, valueConverter, headerConverter, connectorLoader);&lt;br/&gt;
diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/isolation/Plugins.java b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/isolation/Plugins.java&lt;br/&gt;
index 94f27717080..f4cd2ba14b0 100644&lt;br/&gt;
&amp;#8212; a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/isolation/Plugins.java&lt;br/&gt;
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/isolation/Plugins.java&lt;br/&gt;
@@ -234,6 +234,8 @@ public Converter newConverter(AbstractConfig config, String classPropertyName, C&lt;br/&gt;
         // Configure the Converter using only the old configuration mechanism ...&lt;br/&gt;
         String configPrefix = classPropertyName + &quot;.&quot;;&lt;br/&gt;
         Map&amp;lt;String, Object&amp;gt; converterConfig = config.originalsWithPrefix(configPrefix);&lt;br/&gt;
+        log.debug(&quot;Configuring the {} converter with configuration:{}{}&quot;,&lt;br/&gt;
+                  isKeyConverter ? &quot;key&quot; : &quot;value&quot;, System.lineSeparator(), converterConfig);&lt;br/&gt;
         plugin.configure(converterConfig, isKeyConverter);&lt;br/&gt;
         return plugin;&lt;br/&gt;
     }&lt;br/&gt;
@@ -249,20 +251,21 @@ public Converter newConverter(AbstractConfig config, String classPropertyName, C&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@throws ConnectException if the 
{@link HeaderConverter}
&lt;p&gt; implementation class could not be found&lt;br/&gt;
      */&lt;br/&gt;
     public HeaderConverter newHeaderConverter(AbstractConfig config, String classPropertyName, ClassLoaderUsage classLoaderUsage) {&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (!config.originals().containsKey(classPropertyName)) 
{
-            // This configuration does not define the header converter via the specified property name
-            return null;
-        }
&lt;p&gt;         HeaderConverter plugin = null;&lt;br/&gt;
         switch (classLoaderUsage) {&lt;br/&gt;
             case CURRENT_CLASSLOADER:&lt;br/&gt;
+                if (!config.originals().containsKey(classPropertyName)) &lt;/p&gt;
{
+                    // This connector configuration does not define the header converter via the specified property name
+                    return null;
+                }
&lt;p&gt;                 // Attempt to load first with the current classloader, and plugins as a fallback.&lt;br/&gt;
                 // Note: we can&apos;t use config.getConfiguredInstance because we have to remove the property prefixes&lt;br/&gt;
                 // before calling config(...)&lt;br/&gt;
                 plugin = getInstance(config, classPropertyName, HeaderConverter.class);&lt;br/&gt;
                 break;&lt;br/&gt;
             case PLUGINS:&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;// Attempt to load with the plugin class loader, which uses the current classloader as a fallback&lt;br/&gt;
+                // Attempt to load with the plugin class loader, which uses the current classloader as a fallback.&lt;br/&gt;
+                // Note that there will always be at least a default header converter for the worker&lt;br/&gt;
                 String converterClassOrAlias = config.getClass(classPropertyName).getName();&lt;br/&gt;
                 Class&amp;lt;? extends HeaderConverter&amp;gt; klass;&lt;br/&gt;
                 try {&lt;br/&gt;
@@ -288,6 +291,7 @@ public HeaderConverter newHeaderConverter(AbstractConfig config, String classPro&lt;br/&gt;
         String configPrefix = classPropertyName + &quot;.&quot;;&lt;br/&gt;
         Map&amp;lt;String, Object&amp;gt; converterConfig = config.originalsWithPrefix(configPrefix);&lt;br/&gt;
         converterConfig.put(ConverterConfig.TYPE_CONFIG, ConverterType.HEADER.getName());&lt;br/&gt;
+        log.debug(&quot;Configuring the header converter with configuration:{}{}&quot;, System.lineSeparator(), converterConfig);&lt;br/&gt;
         plugin.configure(converterConfig);&lt;br/&gt;
         return plugin;&lt;br/&gt;
     }&lt;br/&gt;
diff --git a/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/isolation/PluginsTest.java b/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/isolation/PluginsTest.java&lt;br/&gt;
index 6de92eedd34..a9a944fa360 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/isolation/PluginsTest.java&lt;br/&gt;
+++ b/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/isolation/PluginsTest.java&lt;br/&gt;
@@ -29,6 +29,7 @@&lt;br/&gt;
 import org.apache.kafka.connect.storage.ConverterConfig;&lt;br/&gt;
 import org.apache.kafka.connect.storage.ConverterType;&lt;br/&gt;
 import org.apache.kafka.connect.storage.HeaderConverter;&lt;br/&gt;
+import org.apache.kafka.connect.storage.SimpleHeaderConverter;&lt;br/&gt;
 import org.junit.Before;&lt;br/&gt;
 import org.junit.BeforeClass;&lt;br/&gt;
 import org.junit.Test;&lt;br/&gt;
@@ -39,18 +40,31 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import static org.junit.Assert.assertEquals;&lt;br/&gt;
 import static org.junit.Assert.assertNotNull;&lt;br/&gt;
+import static org.junit.Assert.assertNull;&lt;br/&gt;
+import static org.junit.Assert.assertTrue;&lt;/p&gt;

&lt;p&gt; public class PluginsTest {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static Map&amp;lt;String, String&amp;gt; props;&lt;br/&gt;
+    private static Map&amp;lt;String, String&amp;gt; pluginProps;&lt;br/&gt;
     private static Plugins plugins;&lt;br/&gt;
+    private Map&amp;lt;String, String&amp;gt; props;&lt;br/&gt;
     private AbstractConfig config;&lt;br/&gt;
     private TestConverter converter;&lt;br/&gt;
     private TestHeaderConverter headerConverter;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @BeforeClass&lt;br/&gt;
     public static void beforeAll() &lt;/p&gt;
{
-        props = new HashMap&amp;lt;&amp;gt;();
+        pluginProps = new HashMap&amp;lt;&amp;gt;();
+
+        // Set up the plugins to have no additional plugin directories.
+        // This won&apos;t allow us to test classpath isolation, but it will allow us to test some of the utility methods.
+        pluginProps.put(WorkerConfig.PLUGIN_PATH_CONFIG, &quot;&quot;);
+        plugins = new Plugins(pluginProps);
+    }
&lt;p&gt;+&lt;br/&gt;
+    @Before&lt;br/&gt;
+    public void setup() {&lt;br/&gt;
+        props = new HashMap&amp;lt;&amp;gt;(pluginProps);&lt;br/&gt;
         props.put(WorkerConfig.KEY_CONVERTER_CLASS_CONFIG, TestConverter.class.getName());&lt;br/&gt;
         props.put(WorkerConfig.VALUE_CONVERTER_CLASS_CONFIG, TestConverter.class.getName());&lt;br/&gt;
         props.put(&quot;key.converter.&quot; + JsonConverterConfig.SCHEMAS_ENABLE_CONFIG, &quot;true&quot;);&lt;br/&gt;
@@ -66,14 +80,10 @@ public static void beforeAll() &lt;/p&gt;
{
         props.put(WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG, TestHeaderConverter.class.getName());
         props.put(&quot;header.converter.extra.config&quot;, &quot;baz&quot;);
 
-        // Set up the plugins to have no additional plugin directories.
-        // This won&apos;t allow us to test classpath isolation, but it will allow us to test some of the utility methods.
-        props.put(WorkerConfig.PLUGIN_PATH_CONFIG, &quot;&quot;);
-        plugins = new Plugins(props);
+        createConfig();
     }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Before&lt;/li&gt;
	&lt;li&gt;public void setup() {&lt;br/&gt;
+    protected void createConfig() 
{
         this.config = new TestableWorkerConfig(props);
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -104,11 +114,48 @@ public void shouldInstantiateAndConfigureInternalConverters() {&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;     @Test&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void shouldInstantiateAndConfigureHeaderConverter() {&lt;/li&gt;
	&lt;li&gt;instantiateAndConfigureHeaderConverter(WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG);&lt;br/&gt;
+    public void shouldInstantiateAndConfigureExplicitlySetHeaderConverterWithCurrentClassLoader() 
{
+        assertNotNull(props.get(WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG));
+        HeaderConverter headerConverter = plugins.newHeaderConverter(config,
+                                                                     WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG,
+                                                                     ClassLoaderUsage.CURRENT_CLASSLOADER);
+        assertNotNull(headerConverter);
+        assertTrue(headerConverter instanceof TestHeaderConverter);
+        this.headerConverter = (TestHeaderConverter) headerConverter;
+
+        // Validate extra configs got passed through to overridden converters
+        assertConverterType(ConverterType.HEADER, this.headerConverter.configs);
+        assertEquals(&quot;baz&quot;, this.headerConverter.configs.get(&quot;extra.config&quot;));
+
+        headerConverter = plugins.newHeaderConverter(config,
+                                                     WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG,
+                                                     ClassLoaderUsage.PLUGINS);
+        assertNotNull(headerConverter);
+        assertTrue(headerConverter instanceof TestHeaderConverter);
+        this.headerConverter = (TestHeaderConverter) headerConverter;
+
         // Validate extra configs got passed through to overridden converters
-        assertConverterType(ConverterType.HEADER, headerConverter.configs);
-        assertEquals(&quot;baz&quot;, headerConverter.configs.get(&quot;extra.config&quot;));
+        assertConverterType(ConverterType.HEADER, this.headerConverter.configs);
+        assertEquals(&quot;baz&quot;, this.headerConverter.configs.get(&quot;extra.config&quot;));
+    }
&lt;p&gt;+&lt;br/&gt;
+    @Test&lt;br/&gt;
+    public void shouldInstantiateAndConfigureDefaultHeaderConverter() &lt;/p&gt;
{
+        props.remove(WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG);
+        createConfig();
+
+        // Because it&apos;s not explicitly set on the supplied configuration, the logic to use the current classloader for the connector
+        // will exit immediately, and so this method always returns null
+        HeaderConverter headerConverter = plugins.newHeaderConverter(config,
+                                                                     WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG,
+                                                                     ClassLoaderUsage.CURRENT_CLASSLOADER);
+        assertNull(headerConverter);
+        // But we should always find it (or the worker&apos;s default) when using the plugins classloader ...
+        headerConverter = plugins.newHeaderConverter(config,
+                                                     WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG,
+                                                     ClassLoaderUsage.PLUGINS);
+        assertNotNull(headerConverter);
+        assertTrue(headerConverter instanceof SimpleHeaderConverter);
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     protected void instantiateAndConfigureConverter(String configPropName, ClassLoaderUsage classLoaderUsage) &lt;/p&gt;
{
@@ -116,11 +163,6 @@ protected void instantiateAndConfigureConverter(String configPropName, ClassLoad
         assertNotNull(converter);
     }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;protected void instantiateAndConfigureHeaderConverter(String configPropName) 
{
-        headerConverter = (TestHeaderConverter) plugins.newHeaderConverter(config, configPropName, ClassLoaderUsage.CURRENT_CLASSLOADER);
-        assertNotNull(headerConverter);
-    }
&lt;p&gt;-&lt;br/&gt;
     protected void assertConverterType(ConverterType type, Map&amp;lt;String, ?&amp;gt; props) &lt;/p&gt;
{
         assertEquals(type.getName(), props.get(ConverterConfig.TYPE_CONFIG));
     }&lt;/li&gt;
&lt;/ul&gt;





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13149668">KAFKA-6740</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 33 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3rzt3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>