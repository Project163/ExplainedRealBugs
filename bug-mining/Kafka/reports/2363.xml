<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:19:55 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-8755] Stand-by Task of an Optimized Source Table Does Not Write Anything to its State Store</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-8755</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;With the following topology:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
builder.table(
    INPUT_TOPIC, 
    Consumed.with(Serdes.&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;(), Serdes.&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;()), 
    Materialized.&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;, KeyValueStore&amp;lt;Bytes, &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[]&amp;gt;&amp;gt;as(stateName)
)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and with topology optimization turned on, Kafka Streams uses the input topic &lt;tt&gt;INPUT_TOPIC&lt;/tt&gt; as the change log topic for state store &lt;tt&gt;stateName&lt;/tt&gt;. A stand-by task for such a topology should read from &lt;tt&gt;INPUT_TOPIC&lt;/tt&gt; and should write the records to its state store so that the streams client that runs the stand-by task can take over the execution of the topology in case of a failure with an up-to-date replica of the state.&lt;/p&gt;

&lt;p&gt;Currently, the stand-by task described above reads from the input topic but does not write the records to its state store. Thus, after a failure the stand-by task cannot provide any up-to-date state store and the streams client needs to construct the state from scratch before it can take over the execution.&lt;/p&gt;

&lt;p&gt;The described behaviour can be reproduced with the attached test.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13248971">KAFKA-8755</key>
            <summary>Stand-by Task of an Optimized Source Table Does Not Write Anything to its State Store</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cpettitt-confluent">Chris Pettitt</assignee>
                                    <reporter username="cadonna">Bruno Cadonna</reporter>
                        <labels>
                            <label>newbie</label>
                    </labels>
                <created>Mon, 5 Aug 2019 22:05:44 +0000</created>
                <updated>Fri, 13 Sep 2019 22:46:24 +0000</updated>
                            <resolved>Fri, 13 Sep 2019 22:46:24 +0000</resolved>
                                    <version>2.4.0</version>
                                    <fixVersion>2.4.0</fixVersion>
                                    <component>streams</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="16900693" author="cadonna" created="Tue, 6 Aug 2019 06:47:19 +0000"  >&lt;p&gt;In a first analysis, I narrowed down the issue to the setting of the offset limits in the following two code snippets.&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;AbstractTask#updateOffsetLimits()&lt;/tt&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; OffsetAndMetadata metadata = consumer.committed(partition);
&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; offset = metadata != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; ? metadata.offset() : 0L;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;tt&gt;ProcessorStateManager#offsetLimit&lt;/tt&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; limit = offsetLimits.get(partition);
&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; limit != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; ? limit : &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;.MAX_VALUE;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Currently, my guess is that &lt;tt&gt;AbstractTask#updateOffsetLimits()&lt;/tt&gt; is called during initialization and closing of the stand-by task but it is not called during normal processing. The reason is that during normal processing &lt;tt&gt;StandByTask#commit()&lt;/tt&gt; is never called because the flag &lt;tt&gt;commitNeeded&lt;/tt&gt; is never set to true. This occurs only for stand-by tasks for optimized source tables. Further investigation is needed to confirm my guess. &lt;/p&gt;</comment>
                            <comment id="16909242" author="cpettitt-confluent" created="Fri, 16 Aug 2019 17:24:30 +0000"  >&lt;p&gt;Digging into this a bit. One initial observation is that the end offset in the non optimized case is just the offset up to which we&apos;ve added data to the store. Since the optimized case is apparently using the input topic itself as a sort of changelog, the end offset seems to be the last written offset. So it seems that even if we get the checkpoint offset fixed in the restore consumer that we&apos;re going to have to do a lot of catch up on failover that we would not have had to do in the non optimized case. Is this expected behavior?&lt;/p&gt;</comment>
                            <comment id="16909249" author="cpettitt-confluent" created="Fri, 16 Aug 2019 17:28:59 +0000"  >&lt;p&gt;Also, I&apos;ll fix up the test a bit. It fails in the non optimized case too because we happen to be completely caught up and no restore occurs (thus, the start offset is not touched in the test). Also, the start offset needs to be volatile because it is being written from one thread and read from another with no obvious synchronization between the two.&lt;/p&gt;</comment>
                            <comment id="16909398" author="cpettitt-confluent" created="Fri, 16 Aug 2019 21:11:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt; Finding what looks to be a few odd bugs as I get into the system. Would be great to have someone to bounce questions off of. For example, it seems unlikely that we intend to update the record collector with a random offset that we&apos;ve consumed from an input stream in stream task, but that is what&apos;s happening today. In optimized mode since we&apos;re using the input topic as the changelog, we&apos;re actually checkpointing with this random first offset we&apos;ve found in the stream task. It would be great to get some validation that we have multiple bugs in play and not that I&apos;m misunderstanding the intended behavior of the system.&lt;/p&gt;</comment>
                            <comment id="16909401" author="cpettitt-confluent" created="Fri, 16 Aug 2019 21:17:33 +0000"  >&lt;p&gt;Fixing the above bug, we at least are getting sane looking checkpoints on the active task. Now to dig into the standby task...&lt;/p&gt;</comment>
                            <comment id="16909450" author="cpettitt-confluent" created="Fri, 16 Aug 2019 22:35:05 +0000"  >&lt;p&gt;Wrapping up for today.&lt;/p&gt;

&lt;p&gt;I suspect this is due to overloading the input topic as both a regular topic and a changelog. It seems that when we start up the tasks they set an offset limit to 0 for all topic partitions, presumably because we haven&apos;t read anything yet. For the changelog we start with Long.MAX_VALUE as the offset limit. In optimized standby since we use the topic in both contexts the limit gets set back to 0 and we don&apos;t seem to make any progress. Forcing the offset to Long.MAX_VALUE when running in optimized topology does&#160;allow things to move and the test passes, but it is not at all clear that that is the right thing to do.&lt;/p&gt;

&lt;p&gt;Do we have a design doc on this feature?&lt;/p&gt;</comment>
                            <comment id="16909457" author="cpettitt-confluent" created="Fri, 16 Aug 2019 22:44:08 +0000"  >&lt;p&gt;One last note:&#160;A huge thanks to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cadonna&quot; class=&quot;user-hover&quot; rel=&quot;cadonna&quot;&gt;cadonna&lt;/a&gt; who has a super simple test case to repro this! Given my limited exposure to Kafka Streams this gave me a massive head start.&lt;/p&gt;</comment>
                            <comment id="16910000" author="cadonna" created="Sun, 18 Aug 2019 16:20:20 +0000"  >&lt;blockquote&gt;&lt;p&gt;So it seems that even if we get the checkpoint offset fixed in the restore consumer that we&apos;re going to have to do a lot of catch up on failover that we would not have had to do in the non optimized case. Is this expected behavior?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The catchup on failover in the optimized and not optimized case should be the same, because the data read until the last written offset from the input topic in the optimized case should be equal to the data we&apos;ve added to the store. That is basically what the above topology does. It reads from the input topic, writes to the store, commits (i.e., writes) the offset of the input topic. Then it repeats those actions.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;It fails in the non optimized case too because we happen to be completely caught up and no restore occurs (thus, the start offset is not touched in the test).&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;My fault. The assertion should be something like &lt;tt&gt;assertThat(start, is(anyOf(greaterThan(0L), equalTo(-1L))));&lt;/tt&gt;. My point was to show that in the optimized case the resoration always starts at 0.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Also, the start offset needs to be volatile because it is being written from one thread and read from another with no obvious synchronization between the two.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I am not sure if you really need volatile here, because when the variable is read, the restoration should have been already done. But since it is just a repro code it does not harm to declare it &lt;tt&gt;volatile&lt;/tt&gt;. &lt;/p&gt;</comment>
                            <comment id="16911121" author="cadonna" created="Tue, 20 Aug 2019 08:53:16 +0000"  >&lt;blockquote&gt;&lt;p&gt;In optimized standby since we use the topic in both contexts the limit gets set back to 0 and we don&apos;t seem to make any progress.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That was also my conclusion. See my &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-8755?focusedCommentId=16900693&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16900693&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;first comment on this ticket&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Forcing the offset to Long.MAX_VALUE when running in optimized topology does allow things to move and the test passes, but it is not at all clear that that is the right thing to do.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That is definitely not the right thing to do for an optimized topology because in that case the stand-by task could overtake the active task. Afterwards when the stand-by task is &quot;promoted&quot; to an active task it could have a much newer state than the active task it is supposed to replace. &lt;/p&gt;

&lt;p&gt;I was verifying wether the stand-by task of an optimized topology overtakes the active task when I stumbled over this bug.&lt;/p&gt;

&lt;p&gt;For a non-optimized topology it is OK to have an offset limit of &lt;tt&gt;Long.MAX_VALUE&lt;/tt&gt; for the changelog because the changelog contains exactly the content of the state store. Overtaking is impossible. &lt;/p&gt;</comment>
                            <comment id="16912529" author="cpettitt-confluent" created="Wed, 21 Aug 2019 17:19:25 +0000"  >&lt;p&gt;Quick update (for my own sanity):&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Kafka Streams team was a huge help yesterday when we discussed expected behavior and some ideas on how to achieve it.&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-8816&quot; title=&quot;RecordCollector offsets updated indirectly by StreamTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-8816&quot;&gt;&lt;del&gt;KAFKA-8816&lt;/del&gt;&lt;/a&gt; is definitely required for this because we end up checkpointing the same offset over and over&lt;/li&gt;
	&lt;li&gt;I made the proposed change of updating the offset limit for standby tasks when commit is called, which does get the standby task moving
	&lt;ol&gt;
		&lt;li&gt;BUG 1: Unfortunately we appear to need update offset limit for the active task or we get &quot;WARN Detected out-of-order KTable update for source-table at offset 0, partition 0.&quot;. It is sufficient to call update offset limit once for the active task.&lt;/li&gt;
		&lt;li&gt;BUG 2: We seem to call update offset limits in a pretty tight loop during failure / re-assignment.&lt;/li&gt;
		&lt;li&gt;BUG 3: We&apos;re updating the changelog offset on the standby task just fine until we hit the active task failure, then we immediately write a checkpoint for offset 0 &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. So we&apos;re still back to square 1 at the moment.&lt;/li&gt;
		&lt;li&gt;BUG 4 &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;: Maybe an issue: during restore we claim we&apos;re going to restore to the end offset, which is ahead of the committed offset. Somewhere in the call chain this gets fixed though. Still the logging is misleading.&lt;/li&gt;
		&lt;li&gt;Cleanup: We have a few tests relying on updateOffsetLimit to trigger a side-effect that throws an exception. Need to rework those tests to trigger the exception in another way.&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="16912565" author="cpettitt-confluent" created="Wed, 21 Aug 2019 17:58:48 +0000"  >&lt;p&gt;BUG 3 was caused by a call to `StandbyTask.update` with no records that are below the `offsetLimit`. When this happens `stateMgr.updateStandbyStates` resets the checkpoint to 0. I&apos;ve fixed this by only calling `stateMgr.updateStandbyStates` when there are one or more records restored.&lt;/p&gt;

&lt;p&gt;This introduces one more bug (BUG 5), which is that we still call restore after failover, but with start and end offsets both set to the last correctly checkpointed value. The non-optimized case does not go into restore at all. I suspect this has to do with the end offset for the topic being larger than the checkpointed value, which is not the case for the non-optimized case.&lt;/p&gt;</comment>
                            <comment id="16912566" author="cpettitt-confluent" created="Wed, 21 Aug 2019 17:59:36 +0000"  >&lt;p&gt;I forgot to mention that with BUG 3 fixed the original test case finally passes!!!!! But still more work to be done to address the other issues.&lt;/p&gt;</comment>
                            <comment id="16912586" author="cpettitt-confluent" created="Wed, 21 Aug 2019 18:25:10 +0000"  >&lt;p&gt;BUG 5 and BUG 4 are related. There is an assumption baked into `StoreChangelogReader` that the end offset is what we want to catch up to, but in the case of an optimized topology we actually want to catch up to the last consumer committed offset. Relevant code is in `StoreChangelogReader.initialize`. This appears to be more of a design issue rather than a bug - the current design would never have handled optimized topology correctly. This will probably get pushed to another ticket.&lt;/p&gt;</comment>
                            <comment id="16912642" author="cpettitt-confluent" created="Wed, 21 Aug 2019 19:59:21 +0000"  >&lt;p&gt;BUG 2: not a bug. It was updating at the commit interval, no faster. But I now have it only doing an update if the task is blocked on a newer consumer commit, which reduces ~100 `consumer.committed` calls down to 1 during failover for non-optimized topology. Optimized topology continues to do the update offset call because it is &quot;blocked&quot; - that is the consumer committed offset prevents any new records from playing and we have a backlog of records ready to go.&lt;/p&gt;</comment>
                            <comment id="16912669" author="cpettitt-confluent" created="Wed, 21 Aug 2019 20:50:46 +0000"  >&lt;p&gt;BUG 1 is interesting. The state restorer actually &quot;restores&quot; the changelog for the DB, which is the input topic in the optimized case. Thus we actually have all of the entries in the DB before we start and when we try to put our first record we detect that the DB is actually ahead of the input topic.&lt;/p&gt;</comment>
                            <comment id="16912819" author="mjsax" created="Thu, 22 Aug 2019 00:17:31 +0000"  >&lt;p&gt;Thanks for the details &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cpettitt-confluent&quot; class=&quot;user-hover&quot; rel=&quot;cpettitt-confluent&quot;&gt;cpettitt-confluent&lt;/a&gt; &#8211; I would recommend to open a PR and we can discuss there. That seems easier as we can relate comments to code in a straight forward way.&lt;/p&gt;

&lt;p&gt;Also, for &quot;BUG 5&quot; I don&apos;t think we need a new ticket, but it can/should be included in this one IMHO.&lt;/p&gt;</comment>
                            <comment id="16913523" author="githubbot" created="Thu, 22 Aug 2019 17:21:38 +0000"  >&lt;p&gt;cpettitt-confluent commented on pull request #7238: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-8755&quot; title=&quot;Stand-by Task of an Optimized Source Table Does Not Write Anything to its State Store&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-8755&quot;&gt;&lt;del&gt;KAFKA-8755&lt;/del&gt;&lt;/a&gt;: Fix state restore for standby tasks with optimized topology&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/7238&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/7238&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Key changes include:&lt;/p&gt;

&lt;p&gt;   1. Moves general offset limit updates down to StandbyTask.&lt;br/&gt;
   2. Updates offsets for StandbyTask at most once per commit and only when&lt;br/&gt;
   we need and updated offset limit to make progress.&lt;br/&gt;
   3. Avoids writing an 0 checkpoint when StandbyTask.update is called but&lt;br/&gt;
   we cannot apply any of the records.&lt;br/&gt;
   4. Avoids going into a restoring state in the case that the last&lt;br/&gt;
   checkpoint is greater or equal to the offset limit (consumer committed&lt;br/&gt;
   offset). This needs special attention please. Code is in&lt;br/&gt;
   StoreChangelogReader.&lt;br/&gt;
   5. Does update offset limits initially for StreamTask because it&lt;br/&gt;
   provides a way to prevent playing to many records from the changelog&lt;br/&gt;
   (also the input topic with optimized topology).&lt;/p&gt;

&lt;p&gt;   NOTE: this PR depends on &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-8816&quot; title=&quot;RecordCollector offsets updated indirectly by StreamTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-8816&quot;&gt;&lt;del&gt;KAFKA-8816&lt;/del&gt;&lt;/a&gt;, which is under review separately. Fortunately the changes involved are few. You can focus just on the &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-8755&quot; title=&quot;Stand-by Task of an Optimized Source Table Does Not Write Anything to its State Store&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-8755&quot;&gt;&lt;del&gt;KAFKA-8755&lt;/del&gt;&lt;/a&gt; commit if you prefer.&lt;/p&gt;

&lt;p&gt;   @guozhangwang @mjsax @cadonna &lt;/p&gt;

&lt;p&gt;   *More detailed description of your change,&lt;br/&gt;
   if necessary. The PR title and PR message become&lt;br/&gt;
   the squashed commit message, so use a separate&lt;br/&gt;
   comment to ping reviewers.*&lt;/p&gt;

&lt;p&gt;   *Summary of testing strategy (including rationale)&lt;br/&gt;
   for the feature or bug fix. Unit and/or integration&lt;br/&gt;
   tests are expected for any behaviour change and&lt;br/&gt;
   system tests should be considered for larger changes.*&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on to GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16929576" author="githubbot" created="Fri, 13 Sep 2019 22:45:34 +0000"  >&lt;p&gt;guozhangwang commented on pull request #7238: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-8755&quot; title=&quot;Stand-by Task of an Optimized Source Table Does Not Write Anything to its State Store&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-8755&quot;&gt;&lt;del&gt;KAFKA-8755&lt;/del&gt;&lt;/a&gt;: Fix state restore for standby tasks with optimized topology&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/7238&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/7238&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on to GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12976760" name="StandbyTaskTest.java" size="9722" author="cadonna" created="Mon, 5 Aug 2019 22:01:47 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 9 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z05clc:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>