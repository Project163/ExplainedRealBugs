<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:57:23 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-4311] Multi layer cache eviction causes forwarding to incorrect ProcessorNode </title>
                <link>https://issues.apache.org/jira/browse/KAFKA-4311</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;The two exceptions below were reported by Frank on the dev mailing list. After investigation, the root cause is multiple cache evictions happening in the same topology. &lt;/p&gt;

&lt;p&gt;Given a topology like the one below. If a record arriving in `tableOne` causes a cache eviction, it will trigger the `leftJoin` that will do a `get` from `reducer-store`. If the key is not currently cached in `reducer-store`, but is in the backing store, it will be put into the cache, and it may also trigger an eviction. If it does trigger an eviction and the eldest entry is dirty it will flush the dirty keys. It is at this point that the exception in the comment happens (ClassCastException). This occurs because the ProcessorContext is still set to the context of the `leftJoin` and the next child in the topology is `mapValues`.&lt;/p&gt;

&lt;p&gt;We need to set the correct `ProcessorNode`, on the context,  in the `ForwardingCacheFlushListener` prior to calling `context.forward`. We also need to set remember to reset the `ProcessorNode` to the previous node once `context.forward` has completed.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;        &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; KTable&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; one = builder.table(Serdes.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;(), Serdes.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;(), tableOne, tableOne);
        &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; KTable&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; two = builder.table(Serdes.&lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;(), Serdes.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;(), tableTwo, tableTwo);
        &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; KTable&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;&amp;gt; reduce = two.groupBy(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KeyValueMapper&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, KeyValue&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;&amp;gt;&amp;gt;() {
            @Override
            &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; KeyValue&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;&amp;gt; apply(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; key, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; value) {
                &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KeyValue&amp;lt;&amp;gt;(value, key);
            }
        }, Serdes.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;(), Serdes.&lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;())
                .reduce(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Reducer&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;&amp;gt;() {
                    @Override
                    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; apply(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; value1, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; value2) {
                        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; value1 + value2;
                    }
                }, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Reducer&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;&amp;gt;() {
                    @Override
                    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; apply(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; value1, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; value2) {
                        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; value1 - value2;
                    }
                }, &lt;span class=&quot;code-quote&quot;&gt;&quot;reducer-store&quot;&lt;/span&gt;);
    one.leftJoin(reduce, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ValueJoiner&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt;() {
            @Override
            &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; apply(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; value1, &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; value2) {
                &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; value1 + &lt;span class=&quot;code-quote&quot;&gt;&quot;:&quot;&lt;/span&gt; + value2;
            }
        })
        .mapValues(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ValueMapper&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt;() {
                    @Override
                    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; apply(&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; value) {
                        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; value;
                    }
                });
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;This exception is actually a symptom of the exception reported below in the comment. After the first exception is thrown, the StreamThread triggers a shutdown that then throws this exception.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;StreamThread-1&amp;#93;&lt;/span&gt; ERROR&lt;br/&gt;
org.apache.kafka.streams.processor.internals.StreamThread - stream-thread&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;StreamThread-1&amp;#93;&lt;/span&gt; Failed to close state manager for StreamTask 0_0:&lt;br/&gt;
org.apache.kafka.streams.errors.ProcessorStateException: task &lt;span class=&quot;error&quot;&gt;&amp;#91;0_0&amp;#93;&lt;/span&gt; Failed&lt;br/&gt;
to close state store addr-organization&lt;/p&gt;

&lt;p&gt;at&lt;br/&gt;
org.apache.kafka.streams.processor.internals.ProcessorStateManager.close(ProcessorStateManager.java:342)&lt;br/&gt;
at&lt;br/&gt;
org.apache.kafka.streams.processor.internals.AbstractTask.closeStateManager(AbstractTask.java:121)&lt;br/&gt;
at&lt;br/&gt;
org.apache.kafka.streams.processor.internals.StreamThread$2.apply(StreamThread.java:341)&lt;br/&gt;
at&lt;br/&gt;
org.apache.kafka.streams.processor.internals.StreamThread.performOnAllTasks(StreamThread.java:322)&lt;br/&gt;
at&lt;br/&gt;
org.apache.kafka.streams.processor.internals.StreamThread.closeAllStateManagers(StreamThread.java:338)&lt;br/&gt;
at&lt;br/&gt;
org.apache.kafka.streams.processor.internals.StreamThread.shutdownTasksAndState(StreamThread.java:299)&lt;br/&gt;
at&lt;br/&gt;
org.apache.kafka.streams.processor.internals.StreamThread.shutdown(StreamThread.java:262)&lt;/p&gt;

&lt;p&gt;at&lt;br/&gt;
org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:245)&lt;br/&gt;
Caused by: java.lang.IllegalStateException: Key found in dirty key set, but&lt;br/&gt;
entry is null&lt;/p&gt;

&lt;p&gt;at&lt;br/&gt;
org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:112)&lt;br/&gt;
at&lt;br/&gt;
org.apache.kafka.streams.state.internals.ThreadCache.flush(ThreadCache.java:100)&lt;br/&gt;
at&lt;br/&gt;
org.apache.kafka.streams.state.internals.CachingKeyValueStore.flush(CachingKeyValueStore.java:111)&lt;br/&gt;
at&lt;br/&gt;
org.apache.kafka.streams.state.internals.CachingKeyValueStore.close(CachingKeyValueStore.java:117)&lt;br/&gt;
at&lt;br/&gt;
org.apache.kafka.streams.processor.internals.ProcessorStateManager.close(ProcessorStateManager.java:340)&lt;/p&gt;

&lt;p&gt;... 7 more&lt;/p&gt;</description>
                <environment></environment>
        <key id="13013222">KAFKA-4311</key>
            <summary>Multi layer cache eviction causes forwarding to incorrect ProcessorNode </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="damianguy">Damian Guy</assignee>
                                    <reporter username="damianguy">Damian Guy</reporter>
                        <labels>
                    </labels>
                <created>Tue, 18 Oct 2016 15:09:33 +0000</created>
                <updated>Wed, 23 Nov 2016 15:03:34 +0000</updated>
                            <resolved>Wed, 9 Nov 2016 18:43:40 +0000</resolved>
                                    <version>0.10.1.0</version>
                                    <fixVersion>0.10.1.1</fixVersion>
                    <fixVersion>0.10.2.0</fixVersion>
                                    <component>streams</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="15585901" author="flyaruu" created="Tue, 18 Oct 2016 16:24:42 +0000"  >&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Which version of kafka are you running?&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;I was running a slightly obsolete 0.10.1. I also added a lot of debug data in RecordCollector.&lt;/p&gt;

&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Also, it&apos;d be great if you could share your streams topology.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;I&apos;m only using KTables, I have one &apos;main&apos; KTable (about 2000 messages) onto which I left-join several other KTables. They&apos;re all JSON messages, and I&apos;ve written some code to merge the messages. I&apos;ve tried to isolate the part where it fails, but if I merge just one it always works, with two sometimes, and with more it always fails, it seems to be related to the total number of messages.&lt;/p&gt;




</comment>
                            <comment id="15585912" author="flyaruu" created="Tue, 18 Oct 2016 16:29:18 +0000"  >&lt;p&gt;I see another stacktrace:&lt;/p&gt;

&lt;p&gt;java.lang.ClassCastException: java.util.Collections$UnmodifiableList cannot be cast to com.dexels.replication.api.ReplicationMessage&lt;br/&gt;
	at org.apache.kafka.streams.kstream.internals.KTableKTableLeftJoin$KTableKTableLeftJoinProcessor.process(KTableKTableLeftJoin.java:80)&lt;br/&gt;
	at org.apache.kafka.streams.kstream.internals.KTableKTableLeftJoin$KTableKTableLeftJoinProcessor.process(KTableKTableLeftJoin.java:48)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:82)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:204)&lt;br/&gt;
	at org.apache.kafka.streams.kstream.internals.KTableKTableJoinMerger$KTableKTableJoinMergeProcessor.process(KTableKTableJoinMerger.java:52)&lt;br/&gt;
	at org.apache.kafka.streams.kstream.internals.KTableKTableJoinMerger$KTableKTableJoinMergeProcessor.process(KTableKTableJoinMerger.java:49)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:82)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:204)&lt;br/&gt;
	at org.apache.kafka.streams.kstream.internals.ForwardingCacheFlushListener.apply(ForwardingCacheFlushListener.java:35)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.maybeForward(CachingKeyValueStore.java:97)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.access$000(CachingKeyValueStore.java:34)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore$1.apply(CachingKeyValueStore.java:84)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:117)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.NamedCache.evict(NamedCache.java:199)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.ThreadCache.maybeEvict(ThreadCache.java:190)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.ThreadCache.put(ThreadCache.java:121)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.get(CachingKeyValueStore.java:147)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.get(CachingKeyValueStore.java:134)&lt;br/&gt;
	at org.apache.kafka.streams.kstream.internals.KTableReduce$KTableAggregateValueGetter.get(KTableReduce.java:121)&lt;br/&gt;
	at org.apache.kafka.streams.kstream.internals.KTableKTableLeftJoin$KTableKTableLeftJoinProcessor.process(KTableKTableLeftJoin.java:77)&lt;br/&gt;
	at org.apache.kafka.streams.kstream.internals.KTableKTableLeftJoin$KTableKTableLeftJoinProcessor.process(KTableKTableLeftJoin.java:48)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:82)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:204)&lt;br/&gt;
	at org.apache.kafka.streams.kstream.internals.KTableKTableJoinMerger$KTableKTableJoinMergeProcessor.process(KTableKTableJoinMerger.java:52)&lt;br/&gt;
	at org.apache.kafka.streams.kstream.internals.KTableKTableJoinMerger$KTableKTableJoinMergeProcessor.process(KTableKTableJoinMerger.java:49)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:82)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:204)&lt;br/&gt;
	at org.apache.kafka.streams.kstream.internals.KTableKTableRightJoin$KTableKTableRightJoinProcessor.process(KTableKTableRightJoin.java:83)&lt;br/&gt;
	at org.apache.kafka.streams.kstream.internals.KTableKTableRightJoin$KTableKTableRightJoinProcessor.process(KTableKTableRightJoin.java:49)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:82)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:204)&lt;br/&gt;
	at org.apache.kafka.streams.kstream.internals.ForwardingCacheFlushListener.apply(ForwardingCacheFlushListener.java:35)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.maybeForward(CachingKeyValueStore.java:97)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.access$000(CachingKeyValueStore.java:34)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore$1.apply(CachingKeyValueStore.java:84)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:117)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.NamedCache.evict(NamedCache.java:199)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.ThreadCache.maybeEvict(ThreadCache.java:190)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.ThreadCache.put(ThreadCache.java:121)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.put(CachingKeyValueStore.java:187)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.put(CachingKeyValueStore.java:182)&lt;br/&gt;
	at org.apache.kafka.streams.kstream.internals.KTableReduce$KTableReduceProcessor.process(KTableReduce.java:92)&lt;br/&gt;
	at org.apache.kafka.streams.kstream.internals.KTableReduce$KTableReduceProcessor.process(KTableReduce.java:52)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:82)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:204)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:66)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:181)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:436)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:242)&lt;/p&gt;

&lt;p&gt;I see one or the other, but not both as far as I can recall. It seems to lose track of the right serde, I use both types during processing (ReplicationMessage and List&amp;lt;ReplicationMessage&amp;gt;) but somehow it ends up using the wrong one.&lt;/p&gt;

&lt;p&gt;I found that I can &apos;solve&apos; this issue by setting StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG to 0.&lt;/p&gt;</comment>
                            <comment id="15585914" author="damianguy" created="Tue, 18 Oct 2016 16:29:46 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=flyaruu&quot; class=&quot;user-hover&quot; rel=&quot;flyaruu&quot;&gt;flyaruu&lt;/a&gt;&lt;br/&gt;
by merge do you mean join? Is it possible for you to share some code for the topology? Obviously omit anything unnecessary. I&apos;m just trying to understand what is happening.&lt;/p&gt;</comment>
                            <comment id="15588096" author="damianguy" created="Wed, 19 Oct 2016 08:53:31 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=flyaruu&quot; class=&quot;user-hover&quot; rel=&quot;flyaruu&quot;&gt;flyaruu&lt;/a&gt;&lt;br/&gt;
We are unable to reproduce or find the problem you are seeing. If you could provide us with some sample code that can reproduce the problem it would help us to investigate.&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Damian&lt;/p&gt;</comment>
                            <comment id="15589074" author="flyaruu" created="Wed, 19 Oct 2016 15:41:34 +0000"  >&lt;p&gt;I&apos;m working on it, and frankly I&apos;m at a loss.&lt;/p&gt;

&lt;p&gt;I&apos;ve made a repository here: &lt;a href=&quot;https://github.com/flyaruu/kafka4311.git&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/flyaruu/kafka4311.git&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I&apos;ve isolated the code that does the joining. If I run this against my customer data (which is person data I&apos;m afraid I cannot share) I run into this bug pretty quickly, especially when I increase the number of threads. If I set the CACHE_MAX_BYTES_BUFFERING_CONFIG to 0, I don&apos;t see it.&lt;/p&gt;

&lt;p&gt;I&apos;ve tried to create a synthetic dataset (The code is in the GenerateTestData class), but I&apos;ve been unable to reproduce the bug with that dataset.&lt;/p&gt;

&lt;p&gt;It seems to be data related, but at the same time the cache and threading settings seem to have influence.&lt;/p&gt;

&lt;p&gt;So either there is a bug that only manifests with very specific data, or there is a bug in my code that somehow gets sidestepped when the cache is off.&lt;/p&gt;

&lt;p&gt;Any ideas? Is there something obvious I&apos;m doing wrong?&lt;/p&gt;

&lt;p&gt;regards, Frank&lt;/p&gt;</comment>
                            <comment id="15589089" author="damianguy" created="Wed, 19 Oct 2016 15:46:34 +0000"  >&lt;p&gt;Thanks - i&apos;ll take a look at it what your repository and get back to you. Appreciate your help&lt;/p&gt;</comment>
                            <comment id="15591271" author="damianguy" created="Thu, 20 Oct 2016 08:59:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=flyaruu&quot; class=&quot;user-hover&quot; rel=&quot;flyaruu&quot;&gt;flyaruu&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanks for the sample code. I&apos;ve tried running this multiple times with different scenarios, i.e, running multiple instances of the streams app, killing them etc, and I&apos;ve not once seen any of the issues reported. It has all been running fine.&lt;br/&gt;
What is different about your customer data to the generated data in the test? Are the messages larger?&lt;br/&gt;
Thanks,&lt;br/&gt;
Damian&lt;/p&gt;</comment>
                            <comment id="15591373" author="flyaruu" created="Thu, 20 Oct 2016 09:50:51 +0000"  >&lt;p&gt;No, not at all, I added the random fields to get a bit meatier messages, but it does not seem to matter at all.&lt;/p&gt;

&lt;p&gt;I&apos;ll try to anonymize my data, and see if I can create a dataset I can reproduce the problem with which I can pass to you.&lt;/p&gt;</comment>
                            <comment id="15591453" author="flyaruu" created="Thu, 20 Oct 2016 10:31:38 +0000"  >&lt;p&gt;Ok, I seem to have created an anonymized version of my data, contained in a Kafka Topic, and I see the bug immediately.&lt;br/&gt;
What would be a good way to get this data set to you?&lt;/p&gt;

&lt;p&gt;It looks like it will be ~40MB&lt;/p&gt;</comment>
                            <comment id="15591478" author="damianguy" created="Thu, 20 Oct 2016 10:44:44 +0000"  >&lt;p&gt;Can you commit it to the github repo? &lt;/p&gt;</comment>
                            <comment id="15591527" author="flyaruu" created="Thu, 20 Oct 2016 11:07:56 +0000"  >&lt;p&gt;Ok, I tar/gzipped the contents of the kafka partition folders, and added them as dataset.tgz&lt;/p&gt;</comment>
                            <comment id="15591605" author="damianguy" created="Thu, 20 Oct 2016 11:49:21 +0000"  >&lt;p&gt;thanks - i&apos;ll take a look&lt;/p&gt;</comment>
                            <comment id="15591675" author="damianguy" created="Thu, 20 Oct 2016 12:24:38 +0000"  >&lt;p&gt;Unfortunately that isn&apos;t working. We probably need the zookeeper directory, too. Also the server.properties used to start the broker.&lt;/p&gt;

&lt;p&gt;Alternatively, is there a way you can dump the data out to a file that i can read back in and produce to kafka myself?&lt;/p&gt;

&lt;p&gt;I also noticed that in your KafkaTest class the processData method was still reading from the REPLICATION-NHV* topics.&lt;/p&gt;
</comment>
                            <comment id="15591872" author="damianguy" created="Thu, 20 Oct 2016 13:54:54 +0000"  >&lt;p&gt;Ok  - i&apos;ve been to reproduce the issue with the test data. It has happened twice now, so i hope i can get to the bottom of it. &lt;/p&gt;</comment>
                            <comment id="15591887" author="flyaruu" created="Thu, 20 Oct 2016 13:59:41 +0000"  >&lt;p&gt;Excellent! I was starting to doubt every part of my system&lt;/p&gt;</comment>
                            <comment id="15592060" author="damianguy" created="Thu, 20 Oct 2016 15:03:37 +0000"  >&lt;p&gt;when you are running it are you running a single instance of your Streams app? &lt;/p&gt;</comment>
                            <comment id="15592166" author="flyaruu" created="Thu, 20 Oct 2016 15:40:59 +0000"  >&lt;p&gt;Yeah, that&apos;s correct&lt;/p&gt;</comment>
                            <comment id="15594852" author="damianguy" created="Fri, 21 Oct 2016 11:32:23 +0000"  >&lt;p&gt;Hi Frank, &lt;br/&gt;
if you have the time, would you mind trying to run your real data against this &lt;a href=&quot;https://github.com/dguy/kafka/tree/kafka-4311&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/dguy/kafka/tree/kafka-4311&lt;/a&gt; ?&lt;/p&gt;

&lt;p&gt;I think i&apos;ve found the problem, but i&apos;ve yet to create a reliable test to reproduce it. However, hopefully that is not too far away. Anway, it&apos;d be great if you could try it out and let me know how you get on. &lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Damian&lt;/p&gt;</comment>
                            <comment id="15595401" author="githubbot" created="Fri, 21 Oct 2016 15:19:51 +0000"  >&lt;p&gt;GitHub user dguy opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/2051&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/2051&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-4311&quot; title=&quot;Multi layer cache eviction causes forwarding to incorrect ProcessorNode &quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-4311&quot;&gt;&lt;del&gt;KAFKA-4311&lt;/del&gt;&lt;/a&gt;: Multi layer cache eviction causes forwarding to incorrect ProcessorNode&lt;/p&gt;

&lt;p&gt;    Given a topology like the one below. If a record arriving in `tableOne` causes a cache eviction, it will trigger the `leftJoin` that will do a `get` from `reducer-store`. If the key is not currently cached in `reducer-store`, but is in the backing store, it will be put into the cache, and it may also trigger an eviction. If it does trigger an eviction and the eldest entry is dirty it will flush the dirty keys. It is at this point that a ClassCastException is thrown. This occurs because the ProcessorContext is still set to the context of the `leftJoin` and the next child in the topology is `mapValues`.&lt;br/&gt;
    We need to set the correct `ProcessorNode`, on the context, in the `ForwardingCacheFlushListener` prior to calling `context.forward`. We also need to set remember to reset the `ProcessorNode` to the previous node once `context.forward` has completed.&lt;/p&gt;

&lt;p&gt;    ```&lt;br/&gt;
           final KTable&amp;lt;String, String&amp;gt; one = builder.table(Serdes.String(), Serdes.String(), tableOne, tableOne);&lt;br/&gt;
            final KTable&amp;lt;Long, String&amp;gt; two = builder.table(Serdes.Long(), Serdes.String(), tableTwo, tableTwo);&lt;br/&gt;
            final KTable&amp;lt;String, Long&amp;gt; reduce = two.groupBy(new KeyValueMapper&amp;lt;Long, String, KeyValue&amp;lt;String, Long&amp;gt;&amp;gt;() {&lt;br/&gt;
                @Override&lt;br/&gt;
                public KeyValue&amp;lt;String, Long&amp;gt; apply(final Long key, final String value) &lt;/p&gt;
{
                    return new KeyValue&amp;lt;&amp;gt;(value, key);
                }
&lt;p&gt;            }, Serdes.String(), Serdes.Long())&lt;br/&gt;
                    .reduce(new Reducer&amp;lt;Long&amp;gt;() &lt;/p&gt;
{..}, new Reducer&amp;lt;Long&amp;gt;() {..}
&lt;p&gt;, &quot;reducer-store&quot;);&lt;/p&gt;

&lt;p&gt;        one.leftJoin(reduce, new ValueJoiner&amp;lt;String, Long, String&amp;gt;() &lt;/p&gt;
{..})&lt;br/&gt;
            .mapValues(new ValueMapper&amp;lt;String, String&amp;gt;() {..}
&lt;p&gt;);&lt;/p&gt;

&lt;p&gt;    ```&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/dguy/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/dguy/kafka&lt;/a&gt; kafka-4311&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/2051.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/2051.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #2051&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 5c8896a9d2aaca6bf5b9fb8de4de8140919fb280&lt;br/&gt;
Author: Damian Guy &amp;lt;damian.guy@gmail.com&amp;gt;&lt;br/&gt;
Date:   2016-10-21T11:27:17Z&lt;/p&gt;

&lt;p&gt;    Save and set the current processor node in FlushingCacheListener.&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15595593" author="flyaruu" created="Fri, 21 Oct 2016 16:29:10 +0000"  >&lt;p&gt;The ClassCast exception is gone, but I still see the Illegal state exception:&lt;/p&gt;

&lt;p&gt;java.lang.IllegalStateException: Key found in dirty key set, but entry is null&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:112)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.NamedCache.evict(NamedCache.java:199)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.ThreadCache.maybeEvict(ThreadCache.java:198)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.ThreadCache.put(ThreadCache.java:121)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.get(CachingKeyValueStore.java:147)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.get(CachingKeyValueStore.java:134)&lt;br/&gt;
	at org.apache.kafka.streams.kstream.internals.KTableReduce$KTableReduceProcessor.process(KTableReduce.java:74)&lt;br/&gt;
	at org.apache.kafka.streams.kstream.internals.KTableReduce$KTableReduceProcessor.process(KTableReduce.java:52)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:82)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:200)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:66)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:180)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:439)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:245)&lt;/p&gt;

&lt;p&gt;and: &lt;/p&gt;

&lt;p&gt;org.apache.kafka.streams.errors.ProcessorStateException: task &lt;span class=&quot;error&quot;&gt;&amp;#91;0_0&amp;#93;&lt;/span&gt; Failed to flush state store develop2_personsperteam3-personsperteam-person-develop2&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flush(ProcessorStateManager.java:331)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.AbstractTask.flushState(AbstractTask.java:180)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.StreamThread$4.apply(StreamThread.java:372)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.StreamThread.performOnAllTasks(StreamThread.java:331)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.StreamThread.flushAllState(StreamThread.java:368)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.StreamThread.shutdownTasksAndState(StreamThread.java:304)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.StreamThread.shutdown(StreamThread.java:272)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:255)&lt;br/&gt;
Caused by: java.lang.IllegalStateException: Key found in dirty key set, but entry is null&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:112)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.ThreadCache.flush(ThreadCache.java:100)&lt;br/&gt;
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.flush(CachingKeyValueStore.java:111)&lt;br/&gt;
	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flush(ProcessorStateManager.java:329)&lt;/p&gt;

&lt;p&gt;Again, when I set CACHE_MAX_BYTES_BUFFERING_CONFIG to 0, it runs fine.&lt;/p&gt;</comment>
                            <comment id="15597385" author="damianguy" created="Sat, 22 Oct 2016 07:52:42 +0000"  >&lt;p&gt;Frank, thanks for testing this for me. I just pushed another minor changing fixing a potential reason this could happen. I&apos;m not sure it is the reason it is happening in your case as i&apos;m unable to reproduce this specific issue. If you wouldn&apos;t mind trying out &lt;a href=&quot;https://github.com/dguy/kafka/tree/kafka-4311&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/dguy/kafka/tree/kafka-4311&lt;/a&gt; again, it would be really appreciated.&lt;br/&gt;
I&apos;m going to be out for the next week, but hopefully someone else will be able to look into into it further.&lt;/p&gt;

&lt;p&gt;Thanks for your help so far.&lt;/p&gt;

&lt;p&gt;Regards,&lt;br/&gt;
Damian&lt;/p&gt;</comment>
                            <comment id="15601431" author="flyaruu" created="Mon, 24 Oct 2016 09:19:50 +0000"  >&lt;p&gt;I&apos;m also out at a conference most of this week. If I can find reliable WiFi, I&apos;ll have a look, otherwise it will be next week.&lt;/p&gt;</comment>
                            <comment id="15617788" author="flyaruu" created="Sat, 29 Oct 2016 09:10:50 +0000"  >&lt;p&gt;I couldn&apos;t reproduce the problems from the (pretty slow) networks  while travelling, but now I&apos;m back and I see the problem again (with the old code)&lt;/p&gt;

&lt;p&gt;Your latest changes seem to solve the problem and I don&apos;t see the IllegalStateExceptions any more. So with that I think this issue can be closed!&lt;/p&gt;</comment>
                            <comment id="15621909" author="damianguy" created="Mon, 31 Oct 2016 11:23:25 +0000"  >&lt;p&gt;Thanks for confirming&lt;/p&gt;</comment>
                            <comment id="15651700" author="guozhang" created="Wed, 9 Nov 2016 18:43:41 +0000"  >&lt;p&gt;Issue resolved by pull request 2051&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/pull/2051&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/2051&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15651702" author="githubbot" created="Wed, 9 Nov 2016 18:44:11 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/2051&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/2051&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 1 week, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i351jz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>