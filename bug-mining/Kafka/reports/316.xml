<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:38:42 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-989] Race condition shutting down high-level consumer results in spinning background thread</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-989</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Running an application that uses the Kafka client under load, can often hit this issue within a few hours.&lt;/p&gt;

&lt;p&gt;High-level consumers come and go over this application&apos;s lifecycle, but there are a variety of defenses that ensure each high-level consumer lasts several seconds before being shutdown.  Nevertheless, some race is causing this background thread to continue long after the ZKClient it is using has been disconnected.  Since the thread was spawned by a consumer that has already been shutdown, the application has no way to find this thread and stop it.&lt;/p&gt;

&lt;p&gt;Reported on the users-kafka mailing list 6/25 as &quot;0.8 throwing exception &apos;Failed to find leader&apos; and high-level consumer fails to make progress&quot;. &lt;/p&gt;

&lt;p&gt;The only remedy is to shutdown the application and restart it.  Externally detecting that this state has occurred is not pleasant: need to grep log for repeated occurrences of the same exception.&lt;/p&gt;

&lt;p&gt;Stack trace:&lt;/p&gt;

&lt;p&gt;Failed to find leader for Set(&lt;span class=&quot;error&quot;&gt;&amp;#91;topic6,0&amp;#93;&lt;/span&gt;): java.lang.NullPointerException&lt;br/&gt;
	at org.I0Itec.zkclient.ZkClient$2.call(ZkClient.java:416)&lt;br/&gt;
	at org.I0Itec.zkclient.ZkClient$2.call(ZkClient.java:413)&lt;br/&gt;
	at org.I0Itec.zkclient.ZkClient.retryUntilConnected(ZkClient.java:675)&lt;br/&gt;
	at org.I0Itec.zkclient.ZkClient.getChildren(ZkClient.java:413)&lt;br/&gt;
	at org.I0Itec.zkclient.ZkClient.getChildren(ZkClient.java:409)&lt;br/&gt;
	at kafka.utils.ZkUtils$.getChildrenParentMayNotExist(ZkUtils.scala:438)&lt;br/&gt;
	at kafka.utils.ZkUtils$.getAllBrokersInCluster(ZkUtils.scala:75)&lt;br/&gt;
	at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:63)&lt;br/&gt;
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:51)&lt;/p&gt;</description>
                <environment>Ubuntu Linux x64</environment>
        <key id="12660099">KAFKA-989</key>
            <summary>Race condition shutting down high-level consumer results in spinning background thread</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="phargett">Phil Hargett</assignee>
                                    <reporter username="phargett">Phil Hargett</reporter>
                        <labels>
                    </labels>
                <created>Fri, 26 Jul 2013 16:50:48 +0000</created>
                <updated>Tue, 6 Aug 2013 14:13:48 +0000</updated>
                            <resolved>Tue, 6 Aug 2013 02:04:18 +0000</resolved>
                                    <version>0.8.0</version>
                                    <fixVersion>0.8.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="13727843" author="phargett" created="Fri, 2 Aug 2013 17:31:49 +0000"  >&lt;p&gt;This patch may minimize the issue, as there does seem to be a race between startConnections / stopConnections in ConsumerFetcherManager &lt;b&gt;and&lt;/b&gt; the doWork method of the inner LeaderFinderThread class.&lt;/p&gt;

&lt;p&gt;It seems that a thread could be started (from startConnections) but shutdown could happen (from stopConnections) even before the leader thread actually even started to do work.&lt;/p&gt;</comment>
                            <comment id="13727844" author="phargett" created="Fri, 2 Aug 2013 17:32:29 +0000"  >&lt;p&gt;Here&apos;s the patch: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-989&quot; title=&quot;Race condition shutting down high-level consumer results in spinning background thread&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-989&quot;&gt;&lt;del&gt;KAFKA-989&lt;/del&gt;&lt;/a&gt;-failed-to-find-leader.patch.&lt;/p&gt;</comment>
                            <comment id="13728023" author="phargett" created="Fri, 2 Aug 2013 19:57:15 +0000"  >&lt;p&gt;Not good enough.  Deadlocks because ShutdownableThread.shutdown grabs another lock.&lt;/p&gt;</comment>
                            <comment id="13729537" author="phargett" created="Mon, 5 Aug 2013 14:26:39 +0000"  >&lt;p&gt;When in doubt about how to fix a locking issue...add another lock. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;While the real race here involves startConnections / stopConnections in ConsumerFetcherManager, the real trigger for such races appears to be the lack of protection in the shutdown and rebalance operations on ZookeeperConsumerConnector.  There is nothing to prevent a rebalance while a shutdown is in progress, and it would appear that could trigger the race in ConsumerFetcherManager.&lt;/p&gt;

&lt;p&gt;The patch I&apos;m attaching (see &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-989&quot; title=&quot;Race condition shutting down high-level consumer results in spinning background thread&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-989&quot;&gt;&lt;del&gt;KAFKA-989&lt;/del&gt;&lt;/a&gt;-failed-to-find-leader-patch2.patch) adds a shutdown lock grabbed first in both shutdown() and in the run method of the ZKRebalancerListener.  This should prevent a rebalance from happening on a consumer that has already shutdown.  This prevents the fetcher or the zkclient from being in intermediate states, and thus should prevent the race.&lt;/p&gt;</comment>
                            <comment id="13729625" author="junrao" created="Mon, 5 Aug 2013 16:33:04 +0000"  >&lt;p&gt;Thanks for the patch. I think it addresses one particular issue: When the consumer connector is shut down, there could still be an outstanding rebalance that uses zkclient which is already set to null. I am not sure if it addresses the problem that you hit though. Some comments:&lt;/p&gt;

&lt;p&gt;1. Since syncedRebalance() is called in multiple places, so the shutdown lock should be checked inside syncedRebalance(). Since there is already a rebalanceLock in syncedRebalance(), perhaps shutdown() can just synchronize on that.&lt;/p&gt;
</comment>
                            <comment id="13729635" author="phargett" created="Mon, 5 Aug 2013 16:48:19 +0000"  >&lt;p&gt;Thanks for the feedback! Working on a patch that incorporates your suggestions now.&lt;/p&gt;

&lt;p&gt;FWIW, I think this will indirectly address my original situation.  I think the reason the original stack trace has occurred is because a rebalance has started a fetcher with a LeaderFinderThread while the consumer itself is in the process of being shutdown.  The LeaderFinderThread is left with a stale ZkClient, and has no other way to know that it&apos;s should shutdown.  Since the fetcher has already set its reference to null its reference to the LeaderFinderThread, the running state of the thread will never be changed to shut the thread off.&lt;/p&gt;

&lt;p&gt;I&apos;m stuck trying to find an acceptable solution in LeaderFinderThread; this change in ZooKeeperConsumerConnector may have to do until then.&lt;/p&gt;

&lt;p&gt;Will post new patch once I have it coded and tested.&lt;/p&gt;</comment>
                            <comment id="13729666" author="junrao" created="Mon, 5 Aug 2013 17:18:16 +0000"  >&lt;p&gt;Hmm, in the shutdown logic of consumer connector, we set zkclient to null the last. So, all fetchers and the leader finder thread should have been stopped when zkclient is null.&lt;/p&gt;</comment>
                            <comment id="13729682" author="phargett" created="Mon, 5 Aug 2013 17:27:15 +0000"  >&lt;p&gt;Yes, but my working hypothesis is that because there are at least 2 sets of races (in consumer connector syncedRebalance/shutdown, then in ConsumerFetcherManager startConnections/stopConnections), it is actually possible to have a LeaderFinderThread still running that has not been shutdown, even though its consumer has--because a stopConnections call completed before a startConnections call finished.  So there&apos;s a started leader finder thread, but its ZkClient has been closed.&lt;/p&gt;

&lt;p&gt;The key, I think, is that there is no guarantee that while the consumer connector is shutting down a rebalance event won&apos;t actually startup another leader finder thread (by starting fetchers again).&lt;/p&gt;

&lt;p&gt;I believe the race in ConsumerFetcherManager is not likely to happen, if the race in ZookeeperConsumerConnector is fixed instead. Thus I avoid fixing the harder race by fixing an easier one that may be its only trigger (at present). &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13729836" author="phargett" created="Mon, 5 Aug 2013 19:13:54 +0000"  >&lt;p&gt;Changed to reuse the existing rebalanceLock in shutdown() rather than add in yet another lock.  Modified both shutdown and syncedRebalance accordingly.&lt;/p&gt;</comment>
                            <comment id="13729842" author="phargett" created="Mon, 5 Aug 2013 19:15:52 +0000"  >&lt;p&gt;I also think I&apos;ve convinced myself that while the race in ConsumerFetcherManager is not ideal, the real resource to protect is not the leader finder thread but the shared ZkClient instance--which is managed by ZookeeperConsumerConnector, where these fixes are made.&lt;/p&gt;

&lt;p&gt;By reducing the races in the consumer connector, then we&apos;re less likely to mismanage the ZkClient.&lt;/p&gt;</comment>
                            <comment id="13730262" author="junrao" created="Tue, 6 Aug 2013 02:04:18 +0000"  >&lt;p&gt;Thanks for patch v3. Committed to 0.8.&lt;/p&gt;</comment>
                            <comment id="13730787" author="phargett" created="Tue, 6 Aug 2013 14:13:48 +0000"  >&lt;p&gt;Thank you!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12596121" name="KAFKA-989-failed-to-find-leader-patch2.patch" size="3130" author="phargett" created="Mon, 5 Aug 2013 14:27:03 +0000"/>
                            <attachment id="12596189" name="KAFKA-989-failed-to-find-leader-patch3.patch" size="5068" author="phargett" created="Mon, 5 Aug 2013 19:13:54 +0000"/>
                            <attachment id="12595635" name="KAFKA-989-failed-to-find-leader.patch" size="1464" author="phargett" created="Fri, 2 Aug 2013 17:32:29 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>340291</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            12 years, 16 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1mowf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>340609</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>