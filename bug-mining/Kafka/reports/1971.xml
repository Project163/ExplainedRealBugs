<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:12:51 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-7104] ReplicaFetcher thread may die because of inconsistent log start offset in fetch response</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-7104</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;What we saw:&lt;/p&gt;

&lt;p&gt;The follower fetches offset&#160;116617, which it was able successfully append. However,&#160;leader&apos;s log start offset in fetch request was&#160;116753, which was higher than fetched offset 116617. When replica fetcher thread tried to increment log start offset to leader&apos;s log start offset, it failed with&#160;OffsetOutOfRangeException:&#160;&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;2018-06-23 00:45:37,409&amp;#93;&lt;/span&gt; ERROR &#160;Error due to (kafka.server.ReplicaFetcherThread)&#160;&lt;br/&gt;
 kafka.common.KafkaException: Error processing data for partition X-N offset 116617&#160;&lt;/p&gt;

&lt;p&gt;Caused by: org.apache.kafka.common.errors.OffsetOutOfRangeException: Cannot increment the log start offset to 116753 of partition&#160;X-N since it is larger than the high watermark 116619&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;In leader&apos;s log, we see that log start offset was incremented almost at the same time (within one 100 ms or so).&#160;&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;2018-06-23 00:45:37,339&amp;#93;&lt;/span&gt; INFO Incrementing log start offset of partition X-N to 116753&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;In leader&apos;s logic: ReplicaManager#ReplicaManager first calls readFromLocalLog() that reads from local log and returns&#160;LogReadResult that contains fetched data and leader&apos;s log start offset and HW. However, it then calls&#160;ReplicaManager#updateFollowerLogReadResults()&#160;which may move leader&apos;s log start offset and update leader&apos;s log start offset and HW in fetch response. If deleteRecords() happens in between, it is possible that log start offset may move&#160;beyond fetched offset. Or possibly, the leader moves log start offset because of deleting old log segments. Basically, the issue is that log start offset can move between records are read from the log and LogReadResult is updated with new log start offset. As a result, fetch response&#160;may contain fetched data but leader&apos;s log start offset&#160;in the response could be set beyond fetched offset (and indicate the state on leader that fetched data does not actually exist anymore on leader).&#160;&lt;/p&gt;

&lt;p&gt;When a follower receives such fetch response, it will first append, then move it&apos;s HW no further than its LEO, which maybe less than leader&apos;s log start offset in fetch response, and then call `replica.maybeIncrementLogStartOffset(leaderLogStartOffset)` which will throw&#160;OffsetOutOfRangeException exception causing the fetcher thread to stop.&#160;&lt;/p&gt;

&lt;p&gt;Note that this can happen if the follower is not in ISR, otherwise the leader will not move its log start offsets beyond follower&apos;s HW.&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Suggested fix:&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;1) Since ReplicaFetcher bounds follower&apos;s HW to follower&apos;s LEO, we should also bound follower&apos;s log start offset to its LEO. In this situation, the follower&apos;s log start offset will be updated to LEO.&lt;/p&gt;

&lt;p&gt;2) In addition to #1, we could try to make sure that leader builds fetch response based on the state of the log as of time of reading data from replica (but including moving leader&apos;s HW based on the follower&apos;s fetch). That could be another&#160;JIRA potentially, since&#160;the fix could be more involved.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13168459">KAFKA-7104</key>
            <summary>ReplicaFetcher thread may die because of inconsistent log start offset in fetch response</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="apovzner">Anna Povzner</assignee>
                                    <reporter username="apovzner">Anna Povzner</reporter>
                        <labels>
                    </labels>
                <created>Tue, 26 Jun 2018 20:37:47 +0000</created>
                <updated>Fri, 29 Jun 2018 21:39:51 +0000</updated>
                            <resolved>Thu, 28 Jun 2018 04:25:51 +0000</resolved>
                                    <version>1.0.0</version>
                    <version>1.1.0</version>
                                    <fixVersion>1.0.2</fixVersion>
                    <fixVersion>1.1.1</fixVersion>
                    <fixVersion>2.0.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="16525195" author="githubbot" created="Wed, 27 Jun 2018 15:21:33 +0000"  >&lt;p&gt;apovzner opened a new pull request #5302: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7104&quot; title=&quot;ReplicaFetcher thread may die because of inconsistent log start offset in fetch response&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7104&quot;&gt;&lt;del&gt;KAFKA-7104&lt;/del&gt;&lt;/a&gt;: Handle leader&apos;s log start offset beyond last fetched offset&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5302&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5302&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Leader replica may return log start offset in the fetch response that is higher then last fetched offset. This may happen if the log start offset on the leader moves while the fetch response is being build (eg., due to rolling and deleting old segments, or deleting records). This PR limits setting log start offset on the follower to its LEO. &lt;/p&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16525756" author="githubbot" created="Thu, 28 Jun 2018 00:16:34 +0000"  >&lt;p&gt;apovzner opened a new pull request #5305: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7104&quot; title=&quot;ReplicaFetcher thread may die because of inconsistent log start offset in fetch response&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7104&quot;&gt;&lt;del&gt;KAFKA-7104&lt;/del&gt;&lt;/a&gt;: More consistent leader&apos;s state in fetch response&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5305&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5305&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Do not update LogReadResult after it is initially populated. This was done in &lt;a href=&quot;https://github.com/apache/kafka/pull/3954&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3954&lt;/a&gt; as optimization so that followers get most recent high watermark and log start offset. However, since many things can happen (like deleting old segments and advancing log start offset) between initial creation of LogReadResult and the update, we can hit issues like log start offset in fetch response being higher than the last offset in fetched records. &lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16525759" author="githubbot" created="Thu, 28 Jun 2018 00:17:16 +0000"  >&lt;p&gt;apovzner closed pull request #5302: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7104&quot; title=&quot;ReplicaFetcher thread may die because of inconsistent log start offset in fetch response&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7104&quot;&gt;&lt;del&gt;KAFKA-7104&lt;/del&gt;&lt;/a&gt;: Handle leader&apos;s log start offset beyond last fetched offset&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5302&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5302&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/core/src/main/scala/kafka/server/ReplicaAlterLogDirsThread.scala b/core/src/main/scala/kafka/server/ReplicaAlterLogDirsThread.scala&lt;br/&gt;
index e46473b69e9..55bc384fa53 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/server/ReplicaAlterLogDirsThread.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/server/ReplicaAlterLogDirsThread.scala&lt;br/&gt;
@@ -100,8 +100,9 @@ class ReplicaAlterLogDirsThread(name: String,&lt;/p&gt;

&lt;p&gt;     partition.appendRecordsToFollowerOrFutureReplica(records, isFuture = true)&lt;br/&gt;
     val futureReplicaHighWatermark = futureReplica.logEndOffset.messageOffset.min(partitionData.highWatermark)&lt;br/&gt;
+    val newLogStartOffset = futureReplica.logEndOffset.messageOffset.min(partitionData.logStartOffset)&lt;br/&gt;
     futureReplica.highWatermark = new LogOffsetMetadata(futureReplicaHighWatermark)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;futureReplica.maybeIncrementLogStartOffset(partitionData.logStartOffset)&lt;br/&gt;
+    futureReplica.maybeIncrementLogStartOffset(newLogStartOffset)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     if (partition.maybeReplaceCurrentWithFutureReplica())&lt;br/&gt;
       removePartitions(Set(topicPartition))&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala b/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala&lt;br/&gt;
index ce6e350d0bd..eb906c1f133 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala&lt;br/&gt;
@@ -118,12 +118,15 @@ class ReplicaFetcherThread(name: String,&lt;br/&gt;
       trace(&quot;Follower has replica log end offset %d after appending %d bytes of messages for partition %s&quot;&lt;br/&gt;
         .format(replica.logEndOffset.messageOffset, records.sizeInBytes, topicPartition))&lt;br/&gt;
     val followerHighWatermark = replica.logEndOffset.messageOffset.min(partitionData.highWatermark)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val leaderLogStartOffset = partitionData.logStartOffset&lt;br/&gt;
+    // the fetch response from the leader may contain log start offset beyond end offset of the&lt;br/&gt;
+    // fetched records, because log start offset may change on the leader while the fetch&lt;br/&gt;
+    // response is being built. We don&apos;t move log start offset beyond LEO on the follower,&lt;br/&gt;
+    val newLogStartOffset = replica.logEndOffset.messageOffset.min(partitionData.logStartOffset)&lt;br/&gt;
     // for the follower replica, we do not need to keep&lt;br/&gt;
     // its segment base offset the physical position,&lt;br/&gt;
     // these values will be computed upon making the leader&lt;br/&gt;
     replica.highWatermark = new LogOffsetMetadata(followerHighWatermark)&lt;/li&gt;
	&lt;li&gt;replica.maybeIncrementLogStartOffset(leaderLogStartOffset)&lt;br/&gt;
+    replica.maybeIncrementLogStartOffset(newLogStartOffset)&lt;br/&gt;
     if (isTraceEnabled)&lt;br/&gt;
       trace(s&quot;Follower set replica high watermark for partition $topicPartition to $followerHighWatermark&quot;)&lt;/li&gt;
&lt;/ul&gt;






&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16525893" author="githubbot" created="Thu, 28 Jun 2018 04:15:23 +0000"  >&lt;p&gt;ijuma closed pull request #5305: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7104&quot; title=&quot;ReplicaFetcher thread may die because of inconsistent log start offset in fetch response&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7104&quot;&gt;&lt;del&gt;KAFKA-7104&lt;/del&gt;&lt;/a&gt;: Consistent leader&apos;s state in fetch response&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5305&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5305&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/core/src/main/scala/kafka/server/ReplicaManager.scala b/core/src/main/scala/kafka/server/ReplicaManager.scala&lt;br/&gt;
index ed9559f856a..9658f1a33a5 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/server/ReplicaManager.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/server/ReplicaManager.scala&lt;br/&gt;
@@ -90,11 +90,6 @@ case class LogReadResult(info: FetchDataInfo,&lt;br/&gt;
     case Some(e) =&amp;gt; Errors.forException(e)&lt;br/&gt;
   }&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def updateLeaderReplicaInfo(leaderReplica: Replica): LogReadResult =&lt;/li&gt;
	&lt;li&gt;copy(highWatermark = leaderReplica.highWatermark.messageOffset,&lt;/li&gt;
	&lt;li&gt;leaderLogStartOffset = leaderReplica.logStartOffset,&lt;/li&gt;
	&lt;li&gt;leaderLogEndOffset = leaderReplica.logEndOffset.messageOffset)&lt;br/&gt;
-&lt;br/&gt;
   def withEmptyFetchInfo: LogReadResult =&lt;br/&gt;
     copy(info = FetchDataInfo(LogOffsetMetadata.UnknownOffsetMetadata, MemoryRecords.EMPTY))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -1340,7 +1335,12 @@ class ReplicaManager(val config: KafkaConfig,&lt;/p&gt;

&lt;p&gt;   /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Update the follower&apos;s fetch state in the leader based on the last fetch request and update `readResult`,&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* if necessary.&lt;br/&gt;
+   * if the follower replica is not recognized to be one of the assigned replicas. Do not update&lt;br/&gt;
+   * `readResult` otherwise, so that log start/end offset and high watermark is consistent with&lt;br/&gt;
+   * records in fetch response. Log start/end offset and high watermark may change not only due to&lt;br/&gt;
+   * this fetch request, e.g., rolling new log segment and removing old log segment may move log&lt;br/&gt;
+   * start offset further than the last offset in the fetched records. The followers will get the&lt;br/&gt;
+   * updated leader&apos;s state in the next fetch response.&lt;br/&gt;
    */&lt;br/&gt;
   private def updateFollowerLogReadResults(replicaId: Int,&lt;br/&gt;
                                            readResults: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;(TopicPartition, LogReadResult)&amp;#93;&lt;/span&gt;): Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;(TopicPartition, LogReadResult)&amp;#93;&lt;/span&gt; = {&lt;br/&gt;
@@ -1351,10 +1351,7 @@ class ReplicaManager(val config: KafkaConfig,&lt;br/&gt;
         case Some(partition) =&amp;gt;&lt;br/&gt;
           partition.getReplica(replicaId) match {&lt;br/&gt;
             case Some(replica) =&amp;gt;&lt;/li&gt;
	&lt;li&gt;if (partition.updateReplicaLogReadResult(replica, readResult))&lt;/li&gt;
	&lt;li&gt;partition.leaderReplicaIfLocal.foreach 
{ leaderReplica =&amp;gt;
-                  updatedReadResult = readResult.updateLeaderReplicaInfo(leaderReplica)
-                }
&lt;p&gt;+              partition.updateReplicaLogReadResult(replica, readResult)&lt;br/&gt;
             case None =&amp;gt;&lt;br/&gt;
               warn(s&quot;Leader $localBrokerId failed to record follower $replicaId&apos;s position &quot; +&lt;br/&gt;
                 s&quot;${readResult.info.fetchOffsetMetadata.messageOffset} since the replica is not recognized to be &quot; +&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/server/ReplicaManagerTest.scala b/core/src/test/scala/unit/kafka/server/ReplicaManagerTest.scala&lt;br/&gt;
index ce8868861f7..56d4b7919e4 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/test/scala/unit/kafka/server/ReplicaManagerTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/server/ReplicaManagerTest.scala&lt;br/&gt;
@@ -463,7 +463,9 @@ class ReplicaManagerTest {&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         val tp0Status = responseStatusMap.get(tp0)&lt;br/&gt;
         assertTrue(tp0Status.isDefined)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertEquals(1, tp0Status.get.highWatermark)&lt;br/&gt;
+        // the response contains high watermark on the leader before it is updated based&lt;br/&gt;
+        // on this fetch request&lt;br/&gt;
+        assertEquals(0, tp0Status.get.highWatermark)&lt;br/&gt;
         assertEquals(None, tp0Status.get.lastStableOffset)&lt;br/&gt;
         assertEquals(Errors.NONE, tp0Status.get.error)&lt;br/&gt;
         assertTrue(tp0Status.get.records.batches.iterator.hasNext)&lt;/li&gt;
&lt;/ul&gt;





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 20 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3v9lr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>