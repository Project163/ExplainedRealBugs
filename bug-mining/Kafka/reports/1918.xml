<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:10:35 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6729] KTable should use user source topics if possible and not create changelog topic</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6729</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;With KIP-182 we reworked Streams API largely and introduced a regression into 1.0 code base. If a KTable is populated from a source topic, ie, StreamsBuilder.table() &amp;#8211; the KTable does create its own changelog topic. However, in older releases (0.11 or older), we don&apos;t create a changelog topic but use the user specified source topic instead.&lt;/p&gt;

&lt;p&gt;We want to reintroduce this optimization to reduce the load (storage and write) on the broker side for this case.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13149254">KAFKA-6729</key>
            <summary>KTable should use user source topics if possible and not create changelog topic</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="guozhang">Guozhang Wang</assignee>
                                    <reporter username="mjsax">Matthias J. Sax</reporter>
                        <labels>
                    </labels>
                <created>Fri, 30 Mar 2018 22:58:25 +0000</created>
                <updated>Fri, 18 Oct 2019 17:19:49 +0000</updated>
                            <resolved>Thu, 17 May 2018 18:29:10 +0000</resolved>
                                    <version>1.0.0</version>
                                    <fixVersion>2.0.0</fixVersion>
                                    <component>streams</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16422576" author="vvcephei" created="Mon, 2 Apr 2018 14:45:01 +0000"  >&lt;p&gt;Maybe worth clarifying, this is a performance regression, not a correctness one.&lt;/p&gt;</comment>
                            <comment id="16474793" author="xvrl" created="Mon, 14 May 2018 20:58:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vvcephei&quot; class=&quot;user-hover&quot; rel=&quot;vvcephei&quot;&gt;vvcephei&lt;/a&gt; it&apos;s not just a performance regression, this is a change in behavior, it now creates an additional topic, which is not backwards compatible for people that pre-created topics with specific topic configurations or need to set ACLs beforehand.&lt;/p&gt;</comment>
                            <comment id="16475285" author="githubbot" created="Tue, 15 May 2018 04:57:14 +0000"  >&lt;p&gt;guozhangwang opened a new pull request #5017: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6729&quot; title=&quot;KTable should use user source topics if possible and not create changelog topic&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6729&quot;&gt;&lt;del&gt;KAFKA-6729&lt;/del&gt;&lt;/a&gt;: Reuse source topics for source KTable&apos;s materialized store&apos;s changelog&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5017&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5017&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   1. In InternalTopologyBuilder#topicGroups, which is used in StreamsPartitionAssignor, look for book-kept `storeToChangelogTopic` map before creating a new internal changelog topics. In this way if the source KTable is created, its source topic stored in `storeToChangelogTopic` will be used.&lt;/p&gt;

&lt;p&gt;   2. Added unit test (confirmed that without 1) it will fail).&lt;/p&gt;

&lt;p&gt;   3. MINOR: removed TODOs that are related to removed KStreamBuilder.&lt;/p&gt;

&lt;p&gt;   4. MINOR: removed TODOs in StreamsBuilderTest util functions and replaced with TopologyWrapper.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16479521" author="githubbot" created="Thu, 17 May 2018 18:28:48 +0000"  >&lt;p&gt;guozhangwang closed pull request #5017: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6729&quot; title=&quot;KTable should use user source topics if possible and not create changelog topic&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6729&quot;&gt;&lt;del&gt;KAFKA-6729&lt;/del&gt;&lt;/a&gt;: Reuse source topics for source KTable&apos;s materialized store&apos;s changelog&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5017&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5017&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KStreamImpl.java b/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KStreamImpl.java&lt;br/&gt;
index b8195a03b9a..5331a958ac0 100644&lt;br/&gt;
&amp;#8212; a/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KStreamImpl.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KStreamImpl.java&lt;br/&gt;
@@ -53,8 +53,7 @@&lt;/p&gt;

&lt;p&gt; public class KStreamImpl&amp;lt;K, V&amp;gt; extends AbstractStream&amp;lt;K&amp;gt; implements KStream&amp;lt;K, V&amp;gt; {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// TODO: change to package-private after removing KStreamBuilder&lt;/li&gt;
	&lt;li&gt;public static final String SOURCE_NAME = &quot;KSTREAM-SOURCE-&quot;;&lt;br/&gt;
+    static final String SOURCE_NAME = &quot;KSTREAM-SOURCE-&quot;;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     static final String SINK_NAME = &quot;KSTREAM-SINK-&quot;;&lt;/p&gt;

&lt;p&gt;diff --git a/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KTableImpl.java b/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KTableImpl.java&lt;br/&gt;
index 1c5ad4d19c9..c1f0f7ac3fe 100644&lt;br/&gt;
&amp;#8212; a/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KTableImpl.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KTableImpl.java&lt;br/&gt;
@@ -45,10 +45,9 @@&lt;br/&gt;
  */&lt;br/&gt;
 public class KTableImpl&amp;lt;K, S, V&amp;gt; extends AbstractStream&amp;lt;K&amp;gt; implements KTable&amp;lt;K, V&amp;gt; &lt;/p&gt;
{
 
-    // TODO: these two fields can be package-private after KStreamBuilder is removed
-    public static final String SOURCE_NAME = &quot;KTABLE-SOURCE-&quot;;
+    static final String SOURCE_NAME = &quot;KTABLE-SOURCE-&quot;;
 
-    public static final String STATE_STORE_NAME = &quot;STATE-STORE-&quot;;
+    static final String STATE_STORE_NAME = &quot;STATE-STORE-&quot;;
 
     private static final String FILTER_NAME = &quot;KTABLE-FILTER-&quot;;
 
diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java
index 70437e91592..575ac012bf5 100644
--- a/streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java
+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java
@@ -96,8 +96,7 @@
     // are connected to these state stores
     private final Map&amp;lt;String, Set&amp;lt;Pattern&amp;gt;&amp;gt; stateStoreNameToSourceRegex = new HashMap&amp;lt;&amp;gt;();
 
-    // map from state store names to this state store&apos;s corresponding changelog topic if possible,
-    // this is used in the extended KStreamBuilder.
+    // map from state store names to this state store&apos;s corresponding changelog topic if possible
     private final Map&amp;lt;String, String&amp;gt; storeToChangelogTopic = new HashMap&amp;lt;&amp;gt;();
 
     // all global topics
@@ -1013,12 +1012,16 @@ private void buildProcessorNode(final Map&amp;lt;String, ProcessorNode&amp;gt; processorMap,
                     }
&lt;p&gt;                 }&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// if the node is connected to a state, add to the state topics&lt;br/&gt;
+                // if the node is connected to a state store whose changelog topics are not predefined, add to the changelog topics&lt;br/&gt;
                 for (final StateStoreFactory stateFactory : stateFactories.values()) {&lt;br/&gt;
                     if (stateFactory.loggingEnabled() &amp;amp;&amp;amp; stateFactory.users().contains(node)) {&lt;/li&gt;
	&lt;li&gt;final String name = ProcessorStateManager.storeChangelogTopic(applicationId, stateFactory.name());&lt;/li&gt;
	&lt;li&gt;final InternalTopicConfig internalTopicConfig = createChangelogTopicConfig(stateFactory, name);&lt;/li&gt;
	&lt;li&gt;stateChangelogTopics.put(name, internalTopicConfig);&lt;br/&gt;
+                        final String topicName = storeToChangelogTopic.containsKey(stateFactory.name()) ?&lt;br/&gt;
+                                storeToChangelogTopic.get(stateFactory.name()) :&lt;br/&gt;
+                                ProcessorStateManager.storeChangelogTopic(applicationId, stateFactory.name());&lt;br/&gt;
+                        if (!stateChangelogTopics.containsKey(topicName)) 
{
+                            final InternalTopicConfig internalTopicConfig = createChangelogTopicConfig(stateFactory, topicName);
+                            stateChangelogTopics.put(topicName, internalTopicConfig);
+                        }
&lt;p&gt;                     }&lt;br/&gt;
                 }&lt;br/&gt;
             }&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/StreamsBuilderTest.java b/streams/src/test/java/org/apache/kafka/streams/StreamsBuilderTest.java&lt;br/&gt;
index 7c2bfa6b16a..0a1e6df3622 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/StreamsBuilderTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/StreamsBuilderTest.java&lt;br/&gt;
@@ -26,7 +26,6 @@&lt;br/&gt;
 import org.apache.kafka.streams.kstream.KStream;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.KTable;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.Materialized;&lt;br/&gt;
-import org.apache.kafka.streams.kstream.internals.KStreamImpl;&lt;br/&gt;
 import org.apache.kafka.streams.processor.internals.InternalTopologyBuilder;&lt;br/&gt;
 import org.apache.kafka.streams.processor.internals.ProcessorTopology;&lt;br/&gt;
 import org.apache.kafka.streams.state.KeyValueStore;&lt;br/&gt;
@@ -39,13 +38,11 @@&lt;br/&gt;
 import org.junit.Test;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import java.util.Arrays;&lt;br/&gt;
-import java.util.Collection;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
 import java.util.HashMap;&lt;br/&gt;
 import java.util.Iterator;&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
 import java.util.Properties;&lt;br/&gt;
-import java.util.Set;&lt;/p&gt;

&lt;p&gt; import static org.hamcrest.CoreMatchers.equalTo;&lt;br/&gt;
 import static org.hamcrest.CoreMatchers.is;&lt;br/&gt;
@@ -58,13 +55,6 @@&lt;br/&gt;
     private final StreamsBuilder builder = new StreamsBuilder();&lt;br/&gt;
     private final Properties props = StreamsTestUtils.topologyTestConfig(Serdes.String(), Serdes.String());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test(expected = TopologyException.class)&lt;/li&gt;
	&lt;li&gt;public void testFrom() 
{
-        builder.stream(Arrays.asList(&quot;topic-1&quot;, &quot;topic-2&quot;));
-
-        builder.build().addSource(KStreamImpl.SOURCE_NAME + &quot;0000000000&quot;, &quot;topic-3&quot;);
-    }
&lt;p&gt;-&lt;br/&gt;
     @Test&lt;br/&gt;
     public void shouldAllowJoinUnmaterializedFilteredKTable() {&lt;br/&gt;
         final KTable&amp;lt;Bytes, String&amp;gt; filteredKTable = builder.&amp;lt;Bytes, String&amp;gt;table(&quot;table-topic&quot;).filter(MockPredicate.&amp;lt;Bytes, String&amp;gt;allGoodPredicate());&lt;br/&gt;
@@ -192,7 +182,7 @@ public void shouldProcessViaThroughTopic() {&lt;br/&gt;
     }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @Test&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void testMerge() {&lt;br/&gt;
+    public void shouldMergeStreams() {&lt;br/&gt;
         final String topic1 = &quot;topic-1&quot;;&lt;br/&gt;
         final String topic2 = &quot;topic-2&quot;;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -281,6 +271,16 @@ public void shouldUseDefaultNodeAndStoreNames() &lt;/p&gt;
{
         assertFalse(stores.hasNext());
         assertFalse(subtopologies.hasNext());
     }
&lt;p&gt;+&lt;br/&gt;
+    @Test&lt;br/&gt;
+    public void shouldReuseSourceTopicAsChangelogs() &lt;/p&gt;
{
+        final String topic = &quot;topic&quot;;
+        builder.table(topic, Materialized.&amp;lt;Long, String, KeyValueStore&amp;lt;Bytes, byte[]&amp;gt;&amp;gt;as(&quot;store&quot;));
+
+        final InternalTopologyBuilder internalTopologyBuilder = TopologyWrapper.getInternalTopologyBuilder(builder.build());
+
+        assertThat(internalTopologyBuilder.topicGroups().get(0).stateChangelogTopics.keySet(), equalTo(Collections.singleton(&quot;topic&quot;)));
+    }

&lt;p&gt;     @Test(expected = TopologyException.class)&lt;br/&gt;
     public void shouldThrowExceptionWhenNoTopicPresent() {&lt;br/&gt;
@@ -291,14 +291,4 @@ public void shouldThrowExceptionWhenNoTopicPresent() {&lt;br/&gt;
     public void shouldThrowExceptionWhenTopicNamesAreNull() &lt;/p&gt;
{
         builder.stream(Arrays.&amp;lt;String&amp;gt;asList(null, null));
     }
&lt;p&gt;-&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// TODO: these two static functions are added because some non-TopologyBuilder unit tests need to access the internal topology builder,&lt;/li&gt;
	&lt;li&gt;//       which is usually a bad sign of design patterns between TopologyBuilder and StreamThread. We need to consider getting rid of them later&lt;/li&gt;
	&lt;li&gt;public static InternalTopologyBuilder internalTopologyBuilder(final StreamsBuilder builder) 
{
-        return builder.internalTopologyBuilder;
-    }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;public static Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; getCopartitionedGroups(final StreamsBuilder builder) 
{
-        return builder.internalTopologyBuilder.copartitionGroups();
-    }
&lt;p&gt;-}&lt;br/&gt;
\ No newline at end of file&lt;br/&gt;
+}&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamGlobalKTableJoinTest.java b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamGlobalKTableJoinTest.java&lt;br/&gt;
index c37e8a954ea..7a65c4a1156 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamGlobalKTableJoinTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamGlobalKTableJoinTest.java&lt;br/&gt;
@@ -21,8 +21,8 @@&lt;br/&gt;
 import org.apache.kafka.common.serialization.StringSerializer;&lt;br/&gt;
 import org.apache.kafka.streams.Consumed;&lt;br/&gt;
 import org.apache.kafka.streams.StreamsBuilder;&lt;br/&gt;
-import org.apache.kafka.streams.StreamsBuilderTest;&lt;br/&gt;
 import org.apache.kafka.streams.TopologyTestDriver;&lt;br/&gt;
+import org.apache.kafka.streams.TopologyWrapper;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.GlobalKTable;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.KStream;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.KeyValueMapper;&lt;br/&gt;
@@ -112,7 +112,7 @@ private void pushNullValueToGlobalTable(final int messageCount) {&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @Test&lt;br/&gt;
     public void shouldNotRequireCopartitioning() &lt;/p&gt;
{
-        final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);
+        final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();
 
         assertEquals(&quot;KStream-GlobalKTable joins do not need to be co-partitioned&quot;, 0, copartitionGroups.size());
     }&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamGlobalKTableLeftJoinTest.java b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamGlobalKTableLeftJoinTest.java&lt;br/&gt;
index eb0775a0847..d6196c5e864 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamGlobalKTableLeftJoinTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamGlobalKTableLeftJoinTest.java&lt;br/&gt;
@@ -21,8 +21,8 @@&lt;br/&gt;
 import org.apache.kafka.common.serialization.StringSerializer;&lt;br/&gt;
 import org.apache.kafka.streams.Consumed;&lt;br/&gt;
 import org.apache.kafka.streams.StreamsBuilder;&lt;br/&gt;
-import org.apache.kafka.streams.StreamsBuilderTest;&lt;br/&gt;
 import org.apache.kafka.streams.TopologyTestDriver;&lt;br/&gt;
+import org.apache.kafka.streams.TopologyWrapper;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.GlobalKTable;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.KStream;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.KeyValueMapper;&lt;br/&gt;
@@ -114,7 +114,7 @@ private void pushNullValueToGlobalTable(final int messageCount) {&lt;br/&gt;
 &lt;br/&gt;
     @Test&lt;br/&gt;
     public void shouldNotRequireCopartitioning() {-        final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);+        final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();          assertEquals(&quot;KStream-GlobalKTable joins do not need to be co-partitioned&quot;, 0, copartitionGroups.size());     }
&lt;p&gt;diff --git a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamImplTest.java b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamImplTest.java&lt;br/&gt;
index 463afb86d85..ebf3f36d1f9 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamImplTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamImplTest.java&lt;br/&gt;
@@ -22,7 +22,6 @@&lt;br/&gt;
 import org.apache.kafka.streams.Consumed;&lt;br/&gt;
 import org.apache.kafka.streams.KeyValue;&lt;br/&gt;
 import org.apache.kafka.streams.StreamsBuilder;&lt;br/&gt;
-import org.apache.kafka.streams.StreamsBuilderTest;&lt;br/&gt;
 import org.apache.kafka.streams.TopologyTestDriver;&lt;br/&gt;
 import org.apache.kafka.streams.TopologyWrapper;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.GlobalKTable;&lt;br/&gt;
@@ -174,7 +173,7 @@ public Integer apply(Integer value1, Integer value2) &lt;/p&gt;
{
             1 + // to
             2 + // through
             1, // process
-            StreamsBuilderTest.internalTopologyBuilder(builder).setApplicationId(&quot;X&quot;).build(null).processors().size());
+            TopologyWrapper.getInternalTopologyBuilder(builder.build()).setApplicationId(&quot;X&quot;).build(null).processors().size());
     }

&lt;p&gt;     @Test&lt;br/&gt;
@@ -186,7 +185,7 @@ public void shouldUseRecordMetadataTimestampExtractorWithThrough() {&lt;br/&gt;
         stream1.to(&quot;topic-5&quot;);&lt;br/&gt;
         stream2.through(&quot;topic-6&quot;);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ProcessorTopology processorTopology = StreamsBuilderTest.internalTopologyBuilder(builder).setApplicationId(&quot;X&quot;).build(null);&lt;br/&gt;
+        ProcessorTopology processorTopology = TopologyWrapper.getInternalTopologyBuilder(builder.build()).setApplicationId(&quot;X&quot;).build(null);&lt;br/&gt;
         assertThat(processorTopology.source(&quot;topic-6&quot;).getTimestampExtractor(), instanceOf(FailOnInvalidTimestamp.class));&lt;br/&gt;
         assertEquals(processorTopology.source(&quot;topic-4&quot;).getTimestampExtractor(), null);&lt;br/&gt;
         assertEquals(processorTopology.source(&quot;topic-3&quot;).getTimestampExtractor(), null);&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java&lt;br/&gt;
index de3446c1a08..59f09530ca7 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java&lt;br/&gt;
@@ -21,8 +21,8 @@&lt;br/&gt;
 import org.apache.kafka.common.serialization.StringSerializer;&lt;br/&gt;
 import org.apache.kafka.streams.Consumed;&lt;br/&gt;
 import org.apache.kafka.streams.StreamsBuilder;&lt;br/&gt;
-import org.apache.kafka.streams.StreamsBuilderTest;&lt;br/&gt;
 import org.apache.kafka.streams.TopologyTestDriver;&lt;br/&gt;
+import org.apache.kafka.streams.TopologyWrapper;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.JoinWindows;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.Joined;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.KStream;&lt;br/&gt;
@@ -105,7 +105,7 @@ public void testJoin() {&lt;br/&gt;
             Joined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));&lt;br/&gt;
         joined.process(supplier);&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);&lt;br/&gt;
+        final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertEquals(1, copartitionGroups.size());&lt;br/&gt;
         assertEquals(new HashSet&amp;lt;&amp;gt;(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());&lt;br/&gt;
@@ -207,7 +207,7 @@ public void testOuterJoin() {&lt;br/&gt;
             JoinWindows.of(100),&lt;br/&gt;
             Joined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));&lt;br/&gt;
         joined.process(supplier);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);&lt;br/&gt;
+        final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertEquals(1, copartitionGroups.size());&lt;br/&gt;
         assertEquals(new HashSet&amp;lt;&amp;gt;(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());&lt;br/&gt;
@@ -312,7 +312,7 @@ public void testWindowing() {&lt;br/&gt;
             Joined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));&lt;br/&gt;
         joined.process(supplier);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);&lt;br/&gt;
+        final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertEquals(1, copartitionGroups.size());&lt;br/&gt;
         assertEquals(new HashSet&amp;lt;&amp;gt;(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());&lt;br/&gt;
@@ -535,7 +535,7 @@ public void testAsymmetricWindowingAfter() {&lt;br/&gt;
                 Serdes.String()));&lt;br/&gt;
         joined.process(supplier);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);&lt;br/&gt;
+        final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertEquals(1, copartitionGroups.size());&lt;br/&gt;
         assertEquals(new HashSet&amp;lt;&amp;gt;(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());&lt;br/&gt;
@@ -644,7 +644,7 @@ public void testAsymmetricWindowingBefore() {&lt;br/&gt;
             Joined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));&lt;br/&gt;
         joined.process(supplier);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);&lt;br/&gt;
+        final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertEquals(1, copartitionGroups.size());&lt;br/&gt;
         assertEquals(new HashSet&amp;lt;&amp;gt;(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamLeftJoinTest.java b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamLeftJoinTest.java&lt;br/&gt;
index 11c5c5b9852..8535a040a33 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamLeftJoinTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamLeftJoinTest.java&lt;br/&gt;
@@ -21,8 +21,8 @@&lt;br/&gt;
 import org.apache.kafka.common.serialization.StringSerializer;&lt;br/&gt;
 import org.apache.kafka.streams.Consumed;&lt;br/&gt;
 import org.apache.kafka.streams.StreamsBuilder;&lt;br/&gt;
-import org.apache.kafka.streams.StreamsBuilderTest;&lt;br/&gt;
 import org.apache.kafka.streams.TopologyTestDriver;&lt;br/&gt;
+import org.apache.kafka.streams.TopologyWrapper;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.JoinWindows;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.Joined;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.KStream;&lt;br/&gt;
@@ -69,7 +69,7 @@ public void testLeftJoin() {&lt;br/&gt;
                                   Joined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));&lt;br/&gt;
         joined.process(supplier);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);&lt;br/&gt;
+        final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertEquals(1, copartitionGroups.size());&lt;br/&gt;
         assertEquals(new HashSet&amp;lt;&amp;gt;(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());&lt;br/&gt;
@@ -155,7 +155,7 @@ public void testWindowing() {&lt;br/&gt;
                                   Joined.with(Serdes.Integer(), Serdes.String(), Serdes.String()));&lt;br/&gt;
         joined.process(supplier);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);&lt;br/&gt;
+        final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertEquals(1, copartitionGroups.size());&lt;br/&gt;
         assertEquals(new HashSet&amp;lt;&amp;gt;(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableJoinTest.java b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableJoinTest.java&lt;br/&gt;
index 0ce27ab51cb..55635fa6517 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableJoinTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableJoinTest.java&lt;br/&gt;
@@ -21,8 +21,8 @@&lt;br/&gt;
 import org.apache.kafka.common.serialization.StringSerializer;&lt;br/&gt;
 import org.apache.kafka.streams.Consumed;&lt;br/&gt;
 import org.apache.kafka.streams.StreamsBuilder;&lt;br/&gt;
-import org.apache.kafka.streams.StreamsBuilderTest;&lt;br/&gt;
 import org.apache.kafka.streams.TopologyTestDriver;&lt;br/&gt;
+import org.apache.kafka.streams.TopologyWrapper;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.KStream;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.KTable;&lt;br/&gt;
 import org.apache.kafka.streams.processor.internals.testutil.LogCaptureAppender;&lt;br/&gt;
@@ -104,7 +104,7 @@ private void pushNullValueToTable() {&lt;br/&gt;
     @Test&lt;br/&gt;
     public void shouldRequireCopartitionedStreams() {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);&lt;br/&gt;
+        final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertEquals(1, copartitionGroups.size());&lt;br/&gt;
         assertEquals(new HashSet&amp;lt;&amp;gt;(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableLeftJoinTest.java b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableLeftJoinTest.java&lt;br/&gt;
index eedda074a41..98fc5001789 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableLeftJoinTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKTableLeftJoinTest.java&lt;br/&gt;
@@ -21,8 +21,8 @@&lt;br/&gt;
 import org.apache.kafka.common.serialization.StringSerializer;&lt;br/&gt;
 import org.apache.kafka.streams.Consumed;&lt;br/&gt;
 import org.apache.kafka.streams.StreamsBuilder;&lt;br/&gt;
-import org.apache.kafka.streams.StreamsBuilderTest;&lt;br/&gt;
 import org.apache.kafka.streams.TopologyTestDriver;&lt;br/&gt;
+import org.apache.kafka.streams.TopologyWrapper;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.KStream;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.KTable;&lt;br/&gt;
 import org.apache.kafka.streams.test.ConsumerRecordFactory;&lt;br/&gt;
@@ -100,7 +100,7 @@ private void pushNullValueToTable(final int messageCount) {&lt;br/&gt;
     @Test&lt;br/&gt;
     public void shouldRequireCopartitionedStreams() {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);&lt;br/&gt;
+        final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertEquals(1, copartitionGroups.size());&lt;br/&gt;
         assertEquals(new HashSet&amp;lt;&amp;gt;(Arrays.asList(streamTopic, tableTopic)), copartitionGroups.iterator().next());&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KTableKTableInnerJoinTest.java b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KTableKTableInnerJoinTest.java&lt;br/&gt;
index 7ed8b6aeeef..2efdd8523f0 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KTableKTableInnerJoinTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KTableKTableInnerJoinTest.java&lt;br/&gt;
@@ -22,7 +22,7 @@&lt;br/&gt;
 import org.apache.kafka.streams.Consumed;&lt;br/&gt;
 import org.apache.kafka.streams.KeyValue;&lt;br/&gt;
 import org.apache.kafka.streams.StreamsBuilder;&lt;br/&gt;
-import org.apache.kafka.streams.StreamsBuilderTest;&lt;br/&gt;
+import org.apache.kafka.streams.TopologyWrapper;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.KTable;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.Materialized;&lt;br/&gt;
 import org.apache.kafka.streams.state.KeyValueStore;&lt;br/&gt;
@@ -75,7 +75,7 @@ private void doTestJoin(final StreamsBuilder builder,&lt;br/&gt;
                             final int[] expectedKeys,&lt;br/&gt;
                             final MockProcessorSupplier&amp;lt;Integer, String&amp;gt; supplier,&lt;br/&gt;
                             final KTable&amp;lt;Integer, String&amp;gt; joined) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);&lt;br/&gt;
+        final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertEquals(1, copartitionGroups.size());&lt;br/&gt;
         assertEquals(new HashSet&amp;lt;&amp;gt;(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KTableKTableLeftJoinTest.java b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KTableKTableLeftJoinTest.java&lt;br/&gt;
index 51fd8390241..79e5f0e2d89 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KTableKTableLeftJoinTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KTableKTableLeftJoinTest.java&lt;br/&gt;
@@ -22,7 +22,7 @@&lt;br/&gt;
 import org.apache.kafka.streams.Consumed;&lt;br/&gt;
 import org.apache.kafka.streams.KeyValue;&lt;br/&gt;
 import org.apache.kafka.streams.StreamsBuilder;&lt;br/&gt;
-import org.apache.kafka.streams.StreamsBuilderTest;&lt;br/&gt;
+import org.apache.kafka.streams.TopologyWrapper;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.KTable;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.KeyValueMapper;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.Materialized;&lt;br/&gt;
@@ -87,7 +87,7 @@ public void testJoin() {&lt;br/&gt;
         final MockProcessorSupplier&amp;lt;Integer, String&amp;gt; supplier = new MockProcessorSupplier&amp;lt;&amp;gt;();&lt;br/&gt;
         joined.toStream().process(supplier);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);&lt;br/&gt;
+        final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertEquals(1, copartitionGroups.size());&lt;br/&gt;
         assertEquals(new HashSet&amp;lt;&amp;gt;(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KTableKTableOuterJoinTest.java b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KTableKTableOuterJoinTest.java&lt;br/&gt;
index cf3321f8f4b..8cee72ffc7b 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KTableKTableOuterJoinTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/kstream/internals/KTableKTableOuterJoinTest.java&lt;br/&gt;
@@ -21,7 +21,7 @@&lt;br/&gt;
 import org.apache.kafka.streams.Consumed;&lt;br/&gt;
 import org.apache.kafka.streams.KeyValue;&lt;br/&gt;
 import org.apache.kafka.streams.StreamsBuilder;&lt;br/&gt;
-import org.apache.kafka.streams.StreamsBuilderTest;&lt;br/&gt;
+import org.apache.kafka.streams.TopologyWrapper;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.KTable;&lt;br/&gt;
 import org.apache.kafka.streams.processor.MockProcessorContext;&lt;br/&gt;
 import org.apache.kafka.streams.processor.Processor;&lt;br/&gt;
@@ -83,7 +83,7 @@ public void testJoin() {&lt;br/&gt;
         joined = table1.outerJoin(table2, MockValueJoiner.TOSTRING_JOINER);&lt;br/&gt;
         joined.toStream().process(supplier);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = StreamsBuilderTest.getCopartitionedGroups(builder);&lt;br/&gt;
+        final Collection&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; copartitionGroups = TopologyWrapper.getInternalTopologyBuilder(builder.build()).copartitionGroups();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertEquals(1, copartitionGroups.size());&lt;br/&gt;
         assertEquals(new HashSet&amp;lt;&amp;gt;(Arrays.asList(topic1, topic2)), copartitionGroups.iterator().next());&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsMetadataStateTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsMetadataStateTest.java&lt;br/&gt;
index e9bb2a396ea..39f848f0dc9 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsMetadataStateTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsMetadataStateTest.java&lt;br/&gt;
@@ -26,7 +26,7 @@&lt;br/&gt;
 import org.apache.kafka.common.utils.Utils;&lt;br/&gt;
 import org.apache.kafka.streams.Consumed;&lt;br/&gt;
 import org.apache.kafka.streams.StreamsBuilder;&lt;br/&gt;
-import org.apache.kafka.streams.StreamsBuilderTest;&lt;br/&gt;
+import org.apache.kafka.streams.TopologyWrapper;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.KStream;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.Materialized;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.Predicate;&lt;br/&gt;
@@ -96,7 +96,7 @@ public Object apply(final Object value) {&lt;br/&gt;
                             Consumed.with(null, null),&lt;br/&gt;
                             Materialized.&amp;lt;Object, Object, KeyValueStore&amp;lt;Bytes, byte[]&amp;gt;&amp;gt;as(globalTable));&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;StreamsBuilderTest.internalTopologyBuilder(builder).setApplicationId(&quot;appId&quot;);&lt;br/&gt;
+        TopologyWrapper.getInternalTopologyBuilder(builder.build()).setApplicationId(&quot;appId&quot;);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         topic1P0 = new TopicPartition(&quot;topic-one&quot;, 0);&lt;br/&gt;
         topic1P1 = new TopicPartition(&quot;topic-one&quot;, 1);&lt;br/&gt;
@@ -122,7 +122,7 @@ public Object apply(final Object value) {&lt;br/&gt;
                 new PartitionInfo(&quot;topic-four&quot;, 0, null, null, null));&lt;/p&gt;

&lt;p&gt;         cluster = new Cluster(null, Collections.&amp;lt;Node&amp;gt;emptyList(), partitionInfos, Collections.&amp;lt;String&amp;gt;emptySet(), Collections.&amp;lt;String&amp;gt;emptySet());&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;discovery = new StreamsMetadataState(StreamsBuilderTest.internalTopologyBuilder(builder), hostOne);&lt;br/&gt;
+        discovery = new StreamsMetadataState(TopologyWrapper.getInternalTopologyBuilder(builder.build()), hostOne);&lt;br/&gt;
         discovery.onChange(hostToPartitions, cluster);&lt;br/&gt;
         partitioner = new StreamPartitioner&amp;lt;String, Object&amp;gt;() {&lt;br/&gt;
             @Override&lt;br/&gt;
@@ -134,7 +134,7 @@ public Integer partition(final String key, final Object value, final int numPart&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @Test&lt;br/&gt;
     public void shouldNotThrowNPEWhenOnChangeNotCalled() &lt;/p&gt;
{
-        new StreamsMetadataState(StreamsBuilderTest.internalTopologyBuilder(builder), hostOne).getAllMetadataForStore(&quot;store&quot;);
+        new StreamsMetadataState(TopologyWrapper.getInternalTopologyBuilder(builder.build()), hostOne).getAllMetadataForStore(&quot;store&quot;);
     }

&lt;p&gt;     @Test&lt;br/&gt;
@@ -301,7 +301,7 @@ public void shouldGetMyMetadataForGlobalStoreWithKey() {&lt;/p&gt;

&lt;p&gt;     @Test&lt;br/&gt;
     public void shouldGetAnyHostForGlobalStoreByKeyIfMyHostUnknown() &lt;/p&gt;
{
-        final StreamsMetadataState streamsMetadataState = new StreamsMetadataState(StreamsBuilderTest.internalTopologyBuilder(builder), StreamsMetadataState.UNKNOWN_HOST);
+        final StreamsMetadataState streamsMetadataState = new StreamsMetadataState(TopologyWrapper.getInternalTopologyBuilder(builder.build()), StreamsMetadataState.UNKNOWN_HOST);
         streamsMetadataState.onChange(hostToPartitions, cluster);
         assertNotNull(streamsMetadataState.getMetadataWithKey(globalTable, &quot;key&quot;, Serdes.String().serializer()));
     }
&lt;p&gt;@@ -314,7 +314,7 @@ public void shouldGetMyMetadataForGlobalStoreWithKeyAndPartitioner() {&lt;/p&gt;

&lt;p&gt;     @Test&lt;br/&gt;
     public void shouldGetAnyHostForGlobalStoreByKeyAndPartitionerIfMyHostUnknown() &lt;/p&gt;
{
-        final StreamsMetadataState streamsMetadataState = new StreamsMetadataState(StreamsBuilderTest.internalTopologyBuilder(builder), StreamsMetadataState.UNKNOWN_HOST);
+        final StreamsMetadataState streamsMetadataState = new StreamsMetadataState(TopologyWrapper.getInternalTopologyBuilder(builder.build()), StreamsMetadataState.UNKNOWN_HOST);
         streamsMetadataState.onChange(hostToPartitions, cluster);
         assertNotNull(streamsMetadataState.getMetadataWithKey(globalTable, &quot;key&quot;, partitioner));
     }
&lt;p&gt;diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignorTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignorTest.java&lt;br/&gt;
index 981215839e4..cc507d60ca5 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignorTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignorTest.java&lt;br/&gt;
@@ -27,8 +27,8 @@&lt;br/&gt;
 import org.apache.kafka.common.utils.Utils;&lt;br/&gt;
 import org.apache.kafka.streams.KeyValue;&lt;br/&gt;
 import org.apache.kafka.streams.StreamsBuilder;&lt;br/&gt;
-import org.apache.kafka.streams.StreamsBuilderTest;&lt;br/&gt;
 import org.apache.kafka.streams.StreamsConfig;&lt;br/&gt;
+import org.apache.kafka.streams.TopologyWrapper;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.JoinWindows;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.KStream;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.KTable;&lt;br/&gt;
@@ -727,7 +727,7 @@ public void testAssignWithInternalTopicThatsSourceIsAnotherInternalTopic() {&lt;br/&gt;
     public void shouldGenerateTasksForAllCreatedPartitions() {&lt;br/&gt;
         final StreamsBuilder builder = new StreamsBuilder();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final InternalTopologyBuilder internalTopologyBuilder = StreamsBuilderTest.internalTopologyBuilder(builder);&lt;br/&gt;
+        final InternalTopologyBuilder internalTopologyBuilder = TopologyWrapper.getInternalTopologyBuilder(builder.build());&lt;br/&gt;
         internalTopologyBuilder.setApplicationId(applicationId);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // KStream with 3 partitions&lt;br/&gt;
@@ -796,7 +796,7 @@ public Object apply(final Object value1, final Object value2) {&lt;br/&gt;
         expectedCreatedInternalTopics.put(applicationId + &quot;-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition&quot;, 4);&lt;br/&gt;
         expectedCreatedInternalTopics.put(applicationId + &quot;-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog&quot;, 4);&lt;br/&gt;
         expectedCreatedInternalTopics.put(applicationId + &quot;-KSTREAM-MAP-0000000001-repartition&quot;, 4);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;expectedCreatedInternalTopics.put(applicationId + &quot;-topic3-STATE-STORE-0000000002-changelog&quot;, 4);&lt;br/&gt;
+        expectedCreatedInternalTopics.put(&quot;topic3&quot;, 4);     // the source topic is reused as changelog topics&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // check if all internal topics were created as expected&lt;br/&gt;
         assertThat(mockInternalTopicManager.readyTopics, equalTo(expectedCreatedInternalTopics));&lt;br/&gt;
@@ -906,7 +906,7 @@ public void shouldThrowExceptionIfApplicationServerConfigPortIsNotAnInteger() {&lt;br/&gt;
     public void shouldNotLoopInfinitelyOnMissingMetadataAndShouldNotCreateRelatedTasks() {&lt;br/&gt;
         final StreamsBuilder builder = new StreamsBuilder();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final InternalTopologyBuilder internalTopologyBuilder = StreamsBuilderTest.internalTopologyBuilder(builder);&lt;br/&gt;
+        final InternalTopologyBuilder internalTopologyBuilder = TopologyWrapper.getInternalTopologyBuilder(builder.build());&lt;br/&gt;
         internalTopologyBuilder.setApplicationId(applicationId);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         KStream&amp;lt;Object, Object&amp;gt; stream1 = builder&lt;br/&gt;
@@ -1026,7 +1026,7 @@ public void shouldUpdateClusterMetadataAndHostInfoOnAssignment() {&lt;br/&gt;
     public void shouldNotAddStandbyTaskPartitionsToPartitionsForHost() {&lt;br/&gt;
         final StreamsBuilder builder = new StreamsBuilder();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final InternalTopologyBuilder internalTopologyBuilder = StreamsBuilderTest.internalTopologyBuilder(builder);&lt;br/&gt;
+        final InternalTopologyBuilder internalTopologyBuilder = TopologyWrapper.getInternalTopologyBuilder(builder.build());&lt;br/&gt;
         internalTopologyBuilder.setApplicationId(applicationId);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         builder.stream(&quot;topic1&quot;).groupByKey().count();&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/test/KStreamTestDriver.java b/streams/src/test/java/org/apache/kafka/test/KStreamTestDriver.java&lt;br/&gt;
index 033b68d3cc0..2c3461a8ad4 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/test/KStreamTestDriver.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/test/KStreamTestDriver.java&lt;br/&gt;
@@ -22,7 +22,7 @@&lt;br/&gt;
 import org.apache.kafka.common.serialization.Serializer;&lt;br/&gt;
 import org.apache.kafka.common.utils.LogContext;&lt;br/&gt;
 import org.apache.kafka.streams.StreamsBuilder;&lt;br/&gt;
-import org.apache.kafka.streams.StreamsBuilderTest;&lt;br/&gt;
+import org.apache.kafka.streams.TopologyWrapper;&lt;br/&gt;
 import org.apache.kafka.streams.errors.DefaultProductionExceptionHandler;&lt;br/&gt;
 import org.apache.kafka.streams.processor.ProcessorContext;&lt;br/&gt;
 import org.apache.kafka.streams.processor.StateStore;&lt;br/&gt;
@@ -82,7 +82,7 @@ public void setUp(final StreamsBuilder builder,&lt;br/&gt;
                       final Serde&amp;lt;?&amp;gt; keySerde,&lt;br/&gt;
                       final Serde&amp;lt;?&amp;gt; valSerde,&lt;br/&gt;
                       final long cacheSize) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final InternalTopologyBuilder internalTopologyBuilder = StreamsBuilderTest.internalTopologyBuilder(builder);&lt;br/&gt;
+        final InternalTopologyBuilder internalTopologyBuilder = TopologyWrapper.getInternalTopologyBuilder(builder.build());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         internalTopologyBuilder.setApplicationId(&quot;TestDriver&quot;);&lt;br/&gt;
         topology = internalTopologyBuilder.build(null);&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16481305" author="githubbot" created="Fri, 18 May 2018 22:50:32 +0000"  >&lt;p&gt;guozhangwang opened a new pull request #5038: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6729&quot; title=&quot;KTable should use user source topics if possible and not create changelog topic&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6729&quot;&gt;&lt;del&gt;KAFKA-6729&lt;/del&gt;&lt;/a&gt;: Follow up; disable logging for source KTable.&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5038&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5038&lt;/a&gt;&lt;/p&gt;




&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16481999" author="githubbot" created="Sun, 20 May 2018 17:24:10 +0000"  >&lt;p&gt;guozhangwang closed pull request #5038: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6729&quot; title=&quot;KTable should use user source topics if possible and not create changelog topic&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6729&quot;&gt;&lt;del&gt;KAFKA-6729&lt;/del&gt;&lt;/a&gt;: Follow up; disable logging for source KTable.&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5038&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5038&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/streams/src/main/java/org/apache/kafka/streams/kstream/internals/InternalStreamsBuilder.java b/streams/src/main/java/org/apache/kafka/streams/kstream/internals/InternalStreamsBuilder.java&lt;br/&gt;
index 480794c5955..0a19b4eb0c0 100644&lt;br/&gt;
&amp;#8212; a/streams/src/main/java/org/apache/kafka/streams/kstream/internals/InternalStreamsBuilder.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/kstream/internals/InternalStreamsBuilder.java&lt;br/&gt;
@@ -72,6 +72,9 @@ public InternalStreamsBuilder(final InternalTopologyBuilder internalTopologyBuil&lt;br/&gt;
     public &amp;lt;K, V&amp;gt; KTable&amp;lt;K, V&amp;gt; table(final String topic,&lt;br/&gt;
                                      final ConsumedInternal&amp;lt;K, V&amp;gt; consumed,&lt;br/&gt;
                                      final MaterializedInternal&amp;lt;K, V, KeyValueStore&amp;lt;Bytes, byte[]&amp;gt;&amp;gt; materialized) {&lt;br/&gt;
+        // explicitly disable logging for source table materialized stores&lt;br/&gt;
+        materialized.withLoggingDisabled();&lt;br/&gt;
+&lt;br/&gt;
         final StoreBuilder&amp;lt;KeyValueStore&amp;lt;K, V&amp;gt;&amp;gt; storeBuilder = new KeyValueStoreMaterializer&amp;lt;&amp;gt;(materialized)&lt;br/&gt;
                 .materialize();&lt;/p&gt;

&lt;p&gt;diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java&lt;br/&gt;
index 575ac012bf5..1651bbd90b3 100644&lt;br/&gt;
&amp;#8212; a/streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java&lt;br/&gt;
@@ -120,7 +120,7 @@&lt;/p&gt;

&lt;p&gt;     private Map&amp;lt;Integer, Set&amp;lt;String&amp;gt;&amp;gt; nodeGroups = null;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;interface StateStoreFactory {&lt;br/&gt;
+    public interface StateStoreFactory 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {         Set&amp;lt;String&amp;gt; users();         boolean loggingEnabled();         StateStore build();@@ -1799,4 +1799,8 @@ public void updateSubscribedTopics(final Set&amp;lt;String&amp;gt; topics, final String logPre     public synchronized Set&amp;lt;String&amp;gt; getSourceTopicNames() {
         return sourceTopicNames;
     }++    public synchronized Map&amp;lt;String, StateStoreFactory&amp;gt; getStateStores() {
+        return stateFactories;
+    } }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;diff --git a/streams/src/test/java/org/apache/kafka/streams/StreamsBuilderTest.java b/streams/src/test/java/org/apache/kafka/streams/StreamsBuilderTest.java&lt;br/&gt;
index 0a1e6df3622..37101de344a 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/StreamsBuilderTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/StreamsBuilderTest.java&lt;br/&gt;
@@ -279,7 +279,11 @@ public void shouldReuseSourceTopicAsChangelogs() 
{
 
         final InternalTopologyBuilder internalTopologyBuilder = TopologyWrapper.getInternalTopologyBuilder(builder.build());
 
-        assertThat(internalTopologyBuilder.topicGroups().get(0).stateChangelogTopics.keySet(), equalTo(Collections.singleton(&quot;topic&quot;)));
+        assertThat(internalTopologyBuilder.getStateStores().keySet(), equalTo(Collections.singleton(&quot;store&quot;)));
+
+        assertThat(internalTopologyBuilder.getStateStores().get(&quot;store&quot;).loggingEnabled(), equalTo(false));
+
+        assertThat(internalTopologyBuilder.topicGroups().get(0).stateChangelogTopics.isEmpty(), equalTo(true));
     }&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @Test(expected = TopologyException.class)&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignorTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignorTest.java&lt;br/&gt;
index cc507d60ca5..37b03fa3418 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignorTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignorTest.java&lt;br/&gt;
@@ -796,7 +796,6 @@ public Object apply(final Object value1, final Object value2) {&lt;br/&gt;
         expectedCreatedInternalTopics.put(applicationId + &quot;-KTABLE-AGGREGATE-STATE-STORE-0000000006-repartition&quot;, 4);&lt;br/&gt;
         expectedCreatedInternalTopics.put(applicationId + &quot;-KTABLE-AGGREGATE-STATE-STORE-0000000006-changelog&quot;, 4);&lt;br/&gt;
         expectedCreatedInternalTopics.put(applicationId + &quot;-KSTREAM-MAP-0000000001-repartition&quot;, 4);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;expectedCreatedInternalTopics.put(&quot;topic3&quot;, 4);     // the source topic is reused as changelog topics&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // check if all internal topics were created as expected&lt;br/&gt;
         assertThat(mockInternalTopicManager.readyTopics, equalTo(expectedCreatedInternalTopics));&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310060">
                    <name>Container</name>
                                            <outwardlinks description="contains">
                                        <issuelink>
            <issuekey id="13186300">KAFKA-7424</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 26 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3s0an:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>