<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:11:56 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6782] GlobalKTable GlobalStateStore never finishes restoring when consuming aborted messages</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6782</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Same problem with &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6190&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/KAFKA-6190&lt;/a&gt;, but his solution which is below, works for the succeed transactional messages. But when there are aborted messages, it will be in infinite loop.&#160;Here is his proposition :&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (offset &amp;lt; highWatermark) {
 &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; ConsumerRecords&amp;lt;&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[], &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[]&amp;gt; records = consumer.poll(100);
 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (ConsumerRecord&amp;lt;&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[], &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[]&amp;gt; record : records) {
 &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (record.key() != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
   stateRestoreCallback.restore(record.key(), record.value());
 }
 offset = consumer.position(topicPartition);
 }
 }&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Concretely, when the consumer consume a set of aborted messages,&#160;it polls&#160;0 records, and the code&#160;&apos;offset = consumer.position(topicPartition)&apos; doesn&apos;t have any opportunity to execute.&lt;/p&gt;

&lt;p&gt;&#160;So I propose to move the code &apos;offset = consumer.position(topicPartition)&apos; outside of the cycle to guarantee that event if no records are polled, the offset can always be updated.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (offset &amp;lt; highWatermark) {
 &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; ConsumerRecords&amp;lt;&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[], &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[]&amp;gt; records = consumer.poll(100);
 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (ConsumerRecord&amp;lt;&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[], &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[]&amp;gt; record : records) {
 &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (record.key() != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
   stateRestoreCallback.restore(record.key(), record.value());
 }
 }
 offset = consumer.position(topicPartition);
 }&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13151871">KAFKA-6782</key>
            <summary>GlobalKTable GlobalStateStore never finishes restoring when consuming aborted messages</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="Gitomain">Lingxiao WANG</assignee>
                                    <reporter username="Lingxiao WANG">Lingxiao WANG</reporter>
                        <labels>
                    </labels>
                <created>Thu, 12 Apr 2018 07:13:51 +0000</created>
                <updated>Tue, 12 Jun 2018 20:30:53 +0000</updated>
                            <resolved>Tue, 12 Jun 2018 20:30:53 +0000</resolved>
                                    <version>1.0.1</version>
                    <version>1.1.0</version>
                                    <fixVersion>0.11.0.3</fixVersion>
                    <fixVersion>1.0.2</fixVersion>
                    <fixVersion>1.1.1</fixVersion>
                    <fixVersion>2.0.0</fixVersion>
                                    <component>streams</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16436252" author="mjsax" created="Thu, 12 Apr 2018 20:19:17 +0000"  >&lt;p&gt;Thanks for reporting this issue. Make sense to me &amp;#8211; feel free to open an PR. I would assume that it affects GlobalKTables, too? Thus, we should add tests for both cases.&lt;/p&gt;</comment>
                            <comment id="16437018" author="lingxiao wang" created="Fri, 13 Apr 2018 08:43:38 +0000"  >&lt;p&gt;Yes, I think GlobalKTables will have the same problem. I&apos;m trying to add PR and test for it.&lt;/p&gt;</comment>
                            <comment id="16444331" author="githubbot" created="Thu, 19 Apr 2018 16:19:23 +0000"  >&lt;p&gt;Gitomain opened a new pull request #4900: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6782&quot; title=&quot;GlobalKTable GlobalStateStore never finishes restoring when consuming aborted messages&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6782&quot;&gt;&lt;del&gt;KAFKA-6782&lt;/del&gt;&lt;/a&gt;: solved the bug of restoration of aborted messages for GlobalStateStore and KGlobalTable&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4900&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4900&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16510029" author="githubbot" created="Tue, 12 Jun 2018 18:54:10 +0000"  >&lt;p&gt;mjsax closed pull request #4900: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6782&quot; title=&quot;GlobalKTable GlobalStateStore never finishes restoring when consuming aborted messages&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6782&quot;&gt;&lt;del&gt;KAFKA-6782&lt;/del&gt;&lt;/a&gt;: solved the bug of restoration of aborted messages for GlobalStateStore and KGlobalTable&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4900&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4900&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/.gitignore b/.gitignore&lt;br/&gt;
index 04f8feed0ad..fe191eed44b 100644&lt;br/&gt;
&amp;#8212; a/.gitignore&lt;br/&gt;
+++ b/.gitignore&lt;br/&gt;
@@ -1,5 +1,6 @@&lt;br/&gt;
 dist&lt;br/&gt;
 *classes&lt;br/&gt;
+*.class&lt;br/&gt;
 target/&lt;br/&gt;
 build/&lt;br/&gt;
 build_eclipse/&lt;br/&gt;
diff --git a/kafka b/kafka&lt;br/&gt;
new file mode 160000&lt;br/&gt;
index 00000000000..cc43e77bbbf&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/kafka&lt;br/&gt;
@@ -0,0 +1 @@&lt;br/&gt;
+Subproject commit cc43e77bbbfad71883011186de55603c936cbcd1&lt;br/&gt;
diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java&lt;br/&gt;
index e8ec5e9fe5f..96064b6d4ad 100644&lt;br/&gt;
&amp;#8212; a/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java&lt;br/&gt;
@@ -268,8 +268,8 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,&lt;br/&gt;
                         if (record.key() != null) &lt;/p&gt;
{
                             restoreRecords.add(KeyValue.pair(record.key(), record.value()));
                         }
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;offset = globalConsumer.position(topicPartition);&lt;br/&gt;
                     }&lt;br/&gt;
+                    offset = globalConsumer.position(topicPartition);&lt;br/&gt;
                     stateRestoreAdapter.restoreAll(restoreRecords);&lt;br/&gt;
                     stateRestoreListener.onBatchRestored(topicPartition, storeName, offset, restoreRecords.size());&lt;br/&gt;
                     restoreCount += restoreRecords.size();&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/GlobalKTableEOSIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/GlobalKTableEOSIntegrationTest.java&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..f7c0e55c05e
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;/dev/null&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/integration/GlobalKTableEOSIntegrationTest.java&lt;br/&gt;
@@ -0,0 +1,390 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one or more&lt;br/&gt;
+ * contributor license agreements. See the NOTICE file distributed with&lt;br/&gt;
+ * this work for additional information regarding copyright ownership.&lt;br/&gt;
+ * The ASF licenses this file to You under the Apache License, Version 2.0&lt;br/&gt;
+ * (the &quot;License&quot;); you may not use this file except in compliance with&lt;br/&gt;
+ * the License. You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+package org.apache.kafka.streams.integration;&lt;br/&gt;
+&lt;br/&gt;
+import kafka.utils.MockTime;&lt;br/&gt;
+import org.apache.kafka.clients.consumer.ConsumerConfig;&lt;br/&gt;
+import org.apache.kafka.clients.producer.ProducerConfig;&lt;br/&gt;
+import org.apache.kafka.common.serialization.LongSerializer;&lt;br/&gt;
+import org.apache.kafka.common.serialization.Serdes;&lt;br/&gt;
+import org.apache.kafka.common.serialization.StringSerializer;&lt;br/&gt;
+import org.apache.kafka.common.utils.Bytes;&lt;br/&gt;
+import org.apache.kafka.streams.kstream.Consumed;&lt;br/&gt;
+import org.apache.kafka.streams.KafkaStreams;&lt;br/&gt;
+import org.apache.kafka.streams.KeyValue;&lt;br/&gt;
+import org.apache.kafka.streams.StreamsBuilder;&lt;br/&gt;
+import org.apache.kafka.streams.StreamsConfig;&lt;br/&gt;
+import org.apache.kafka.streams.errors.InvalidStateStoreException;&lt;br/&gt;
+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;&lt;br/&gt;
+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;&lt;br/&gt;
+import org.apache.kafka.streams.kstream.ForeachAction;&lt;br/&gt;
+import org.apache.kafka.streams.kstream.GlobalKTable;&lt;br/&gt;
+import org.apache.kafka.streams.kstream.KStream;&lt;br/&gt;
+import org.apache.kafka.streams.kstream.KeyValueMapper;&lt;br/&gt;
+import org.apache.kafka.streams.kstream.Materialized;&lt;br/&gt;
+import org.apache.kafka.streams.kstream.ValueJoiner;&lt;br/&gt;
+import org.apache.kafka.streams.state.KeyValueStore;&lt;br/&gt;
+import org.apache.kafka.streams.state.QueryableStoreTypes;&lt;br/&gt;
+import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;&lt;br/&gt;
+import org.apache.kafka.test.IntegrationTest;&lt;br/&gt;
+import org.apache.kafka.test.TestCondition;&lt;br/&gt;
+import org.apache.kafka.test.TestUtils;&lt;br/&gt;
+import org.junit.After;&lt;br/&gt;
+import org.junit.Before;&lt;br/&gt;
+import org.junit.ClassRule;&lt;br/&gt;
+import org.junit.Test;&lt;br/&gt;
+import org.junit.experimental.categories.Category;&lt;br/&gt;
+&lt;br/&gt;
+import java.io.IOException;&lt;br/&gt;
+import java.util.Arrays;&lt;br/&gt;
+import java.util.HashMap;&lt;br/&gt;
+import java.util.Iterator;&lt;br/&gt;
+import java.util.Map;&lt;br/&gt;
+import java.util.Properties;&lt;br/&gt;
+&lt;br/&gt;
+@Category(
{IntegrationTest.class})&lt;br/&gt;
+public class GlobalKTableEOSIntegrationTest {&lt;br/&gt;
+    private static final int NUM_BROKERS = 1;&lt;br/&gt;
+    private static final Properties BROKER_CONFIG;&lt;br/&gt;
+    static {
+        BROKER_CONFIG = new Properties();
+        BROKER_CONFIG.put(&quot;transaction.state.log.replication.factor&quot;, (short) 1);
+        BROKER_CONFIG.put(&quot;transaction.state.log.min.isr&quot;, 1);
+    }&lt;br/&gt;
+&lt;br/&gt;
+    @ClassRule&lt;br/&gt;
+    public static final EmbeddedKafkaCluster CLUSTER =&lt;br/&gt;
+            new EmbeddedKafkaCluster(NUM_BROKERS, BROKER_CONFIG);&lt;br/&gt;
+&lt;br/&gt;
+    private static volatile int testNo = 0;&lt;br/&gt;
+    private final MockTime mockTime = CLUSTER.time;&lt;br/&gt;
+    private final KeyValueMapper&amp;lt;String, Long, Long&amp;gt; keyMapper = new KeyValueMapper&amp;lt;String, Long, Long&amp;gt;() {&lt;br/&gt;
+        @Override&lt;br/&gt;
+        public Long apply(final String key, final Long value) {
+            return value;
+        }&lt;br/&gt;
+    };&lt;br/&gt;
+    private final ValueJoiner&amp;lt;Long, String, String&amp;gt; joiner = new ValueJoiner&amp;lt;Long, String, String&amp;gt;() {&lt;br/&gt;
+        @Override&lt;br/&gt;
+        public String apply(final Long value1, final String value2) {
+            return value1 + &quot;+&quot; + value2;
+        }&lt;br/&gt;
+    };&lt;br/&gt;
+    private final String globalStore = &quot;globalStore&quot;;&lt;br/&gt;
+    private final Map&amp;lt;String, String&amp;gt; results = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
+    private StreamsBuilder builder;&lt;br/&gt;
+    private Properties streamsConfiguration;&lt;br/&gt;
+    private KafkaStreams kafkaStreams;&lt;br/&gt;
+    private String globalTableTopic;&lt;br/&gt;
+    private String streamTopic;&lt;br/&gt;
+    private GlobalKTable&amp;lt;Long, String&amp;gt; globalTable;&lt;br/&gt;
+    private KStream&amp;lt;String, Long&amp;gt; stream;&lt;br/&gt;
+    private ForeachAction&amp;lt;String, String&amp;gt; foreachAction;&lt;br/&gt;
+&lt;br/&gt;
+    @Before&lt;br/&gt;
+    public void before() throws InterruptedException {&lt;br/&gt;
+        testNo++;&lt;br/&gt;
+        builder = new StreamsBuilder();&lt;br/&gt;
+        createTopics();&lt;br/&gt;
+        streamsConfiguration = new Properties();&lt;br/&gt;
+        final String applicationId = &quot;globalTableTopic-table-eos-test-&quot; + testNo;&lt;br/&gt;
+        streamsConfiguration.put(StreamsConfig.APPLICATION_ID_CONFIG, applicationId);&lt;br/&gt;
+        streamsConfiguration.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers());&lt;br/&gt;
+        streamsConfiguration.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;);&lt;br/&gt;
+        streamsConfiguration.put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());&lt;br/&gt;
+        streamsConfiguration.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);&lt;br/&gt;
+        streamsConfiguration.put(IntegrationTestUtils.INTERNAL_LEAVE_GROUP_ON_CLOSE, true);&lt;br/&gt;
+        streamsConfiguration.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 100);&lt;br/&gt;
+        streamsConfiguration.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, &quot;exactly_once&quot;);&lt;br/&gt;
+        globalTable = builder.globalTable(globalTableTopic, Consumed.with(Serdes.Long(), Serdes.String()),&lt;br/&gt;
+                                          Materialized.&amp;lt;Long, String, KeyValueStore&amp;lt;Bytes, byte[]&amp;gt;&amp;gt;as(globalStore)&lt;br/&gt;
+                                                  .withKeySerde(Serdes.Long())&lt;br/&gt;
+                                                  .withValueSerde(Serdes.String()));&lt;br/&gt;
+        final Consumed&amp;lt;String, Long&amp;gt; stringLongConsumed = Consumed.with(Serdes.String(), Serdes.Long());&lt;br/&gt;
+        stream = builder.stream(streamTopic, stringLongConsumed);&lt;br/&gt;
+        foreachAction = new ForeachAction&amp;lt;String, String&amp;gt;() {&lt;br/&gt;
+            @Override&lt;br/&gt;
+            public void apply(final String key, final String value) {
+                results.put(key, value);
+            }&lt;br/&gt;
+        };&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    @After&lt;br/&gt;
+    public void whenShuttingDown() throws IOException {&lt;br/&gt;
+        if (kafkaStreams != null) {
+            kafkaStreams.close();
+        }&lt;br/&gt;
+        IntegrationTestUtils.purgeLocalStreamsState(streamsConfiguration);&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    @Test&lt;br/&gt;
+    public void shouldKStreamGlobalKTableLeftJoin() throws Exception {&lt;br/&gt;
+        final KStream&amp;lt;String, String&amp;gt; streamTableJoin = stream.leftJoin(globalTable, keyMapper, joiner);&lt;br/&gt;
+        streamTableJoin.foreach(foreachAction);&lt;br/&gt;
+        produceInitialGlobalTableValues();&lt;br/&gt;
+        startStreams();&lt;br/&gt;
+        produceTopicValues(streamTopic);&lt;br/&gt;
+&lt;br/&gt;
+        final Map&amp;lt;String, String&amp;gt; expected = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
+        expected.put(&quot;a&quot;, &quot;1+A&quot;);&lt;br/&gt;
+        expected.put(&quot;b&quot;, &quot;2+B&quot;);&lt;br/&gt;
+        expected.put(&quot;c&quot;, &quot;3+C&quot;);&lt;br/&gt;
+        expected.put(&quot;d&quot;, &quot;4+D&quot;);&lt;br/&gt;
+        expected.put(&quot;e&quot;, &quot;5+null&quot;);&lt;br/&gt;
+&lt;br/&gt;
+        TestUtils.waitForCondition(new TestCondition() {&lt;br/&gt;
+            @Override&lt;br/&gt;
+            public boolean conditionMet() {
+                return results.equals(expected);
+            }&lt;br/&gt;
+        }, 30000L, &quot;waiting for initial values&quot;);&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
+        produceGlobalTableValues();&lt;br/&gt;
+&lt;br/&gt;
+        final ReadOnlyKeyValueStore&amp;lt;Long, String&amp;gt; replicatedStore = kafkaStreams.store(globalStore, QueryableStoreTypes.&amp;lt;Long, String&amp;gt;keyValueStore());&lt;br/&gt;
+&lt;br/&gt;
+        TestUtils.waitForCondition(new TestCondition() {&lt;br/&gt;
+            @Override&lt;br/&gt;
+            public boolean conditionMet() {
+                return &quot;J&quot;.equals(replicatedStore.get(5L));
+            }&lt;br/&gt;
+        }, 30000, &quot;waiting for data in replicated store&quot;);&lt;br/&gt;
+        produceTopicValues(streamTopic);&lt;br/&gt;
+&lt;br/&gt;
+        expected.put(&quot;a&quot;, &quot;1+F&quot;);&lt;br/&gt;
+        expected.put(&quot;b&quot;, &quot;2+G&quot;);&lt;br/&gt;
+        expected.put(&quot;c&quot;, &quot;3+H&quot;);&lt;br/&gt;
+        expected.put(&quot;d&quot;, &quot;4+I&quot;);&lt;br/&gt;
+        expected.put(&quot;e&quot;, &quot;5+J&quot;);&lt;br/&gt;
+&lt;br/&gt;
+        TestUtils.waitForCondition(new TestCondition() {&lt;br/&gt;
+            @Override&lt;br/&gt;
+            public boolean conditionMet() {+                return results.equals(expected);+            }&lt;br/&gt;
+        }, 30000L, &quot;waiting for final values&quot;);&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    @Test&lt;br/&gt;
+    public void shouldKStreamGlobalKTableJoin() throws Exception {&lt;br/&gt;
+        final KStream&amp;lt;String, String&amp;gt; streamTableJoin = stream.join(globalTable, keyMapper, joiner);&lt;br/&gt;
+        streamTableJoin.foreach(foreachAction);&lt;br/&gt;
+        produceInitialGlobalTableValues();&lt;br/&gt;
+        startStreams();&lt;br/&gt;
+        produceTopicValues(streamTopic);&lt;br/&gt;
+&lt;br/&gt;
+        final Map&amp;lt;String, String&amp;gt; expected = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
+        expected.put(&quot;a&quot;, &quot;1+A&quot;);&lt;br/&gt;
+        expected.put(&quot;b&quot;, &quot;2+B&quot;);&lt;br/&gt;
+        expected.put(&quot;c&quot;, &quot;3+C&quot;);&lt;br/&gt;
+        expected.put(&quot;d&quot;, &quot;4+D&quot;);&lt;br/&gt;
+&lt;br/&gt;
+        TestUtils.waitForCondition(new TestCondition() {&lt;br/&gt;
+            @Override&lt;br/&gt;
+            public boolean conditionMet() {
+                return results.equals(expected);
+            }&lt;br/&gt;
+        }, 30000L, &quot;waiting for initial values&quot;);&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
+        produceGlobalTableValues();&lt;br/&gt;
+&lt;br/&gt;
+        final ReadOnlyKeyValueStore&amp;lt;Long, String&amp;gt; replicatedStore = kafkaStreams.store(globalStore, QueryableStoreTypes.&amp;lt;Long, String&amp;gt;keyValueStore());&lt;br/&gt;
+&lt;br/&gt;
+        TestUtils.waitForCondition(new TestCondition() {&lt;br/&gt;
+            @Override&lt;br/&gt;
+            public boolean conditionMet() {
+                return &quot;J&quot;.equals(replicatedStore.get(5L));
+            }&lt;br/&gt;
+        }, 30000, &quot;waiting for data in replicated store&quot;);&lt;br/&gt;
+&lt;br/&gt;
+        produceTopicValues(streamTopic);&lt;br/&gt;
+&lt;br/&gt;
+        expected.put(&quot;a&quot;, &quot;1+F&quot;);&lt;br/&gt;
+        expected.put(&quot;b&quot;, &quot;2+G&quot;);&lt;br/&gt;
+        expected.put(&quot;c&quot;, &quot;3+H&quot;);&lt;br/&gt;
+        expected.put(&quot;d&quot;, &quot;4+I&quot;);&lt;br/&gt;
+        expected.put(&quot;e&quot;, &quot;5+J&quot;);&lt;br/&gt;
+&lt;br/&gt;
+        TestUtils.waitForCondition(new TestCondition() {&lt;br/&gt;
+            @Override&lt;br/&gt;
+            public boolean conditionMet() {+                return results.equals(expected);+            }&lt;br/&gt;
+        }, 30000L, &quot;waiting for final values&quot;);&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    @Test&lt;br/&gt;
+    public void shouldRestoreTransactionalMessages() throws Exception {&lt;br/&gt;
+        produceInitialGlobalTableValues();&lt;br/&gt;
+&lt;br/&gt;
+        startStreams();&lt;br/&gt;
+&lt;br/&gt;
+        final Map&amp;lt;Long, String&amp;gt; expected = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
+        expected.put(1L, &quot;A&quot;);&lt;br/&gt;
+        expected.put(2L, &quot;B&quot;);&lt;br/&gt;
+        expected.put(3L, &quot;C&quot;);&lt;br/&gt;
+        expected.put(4L, &quot;D&quot;);&lt;br/&gt;
+&lt;br/&gt;
+        TestUtils.waitForCondition(new TestCondition() {&lt;br/&gt;
+            @Override&lt;br/&gt;
+            public boolean conditionMet() {&lt;br/&gt;
+                ReadOnlyKeyValueStore&amp;lt;Long, String&amp;gt; store = null;&lt;br/&gt;
+                try {
+                    store = kafkaStreams.store(globalStore, QueryableStoreTypes.&amp;lt;Long, String&amp;gt;keyValueStore());
+                } catch (InvalidStateStoreException ex) {
+                    return false;
+                }&lt;br/&gt;
+                Map&amp;lt;Long, String&amp;gt; result = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
+                Iterator&amp;lt;KeyValue&amp;lt;Long, String&amp;gt;&amp;gt; it = store.all();&lt;br/&gt;
+                while (it.hasNext()) {
+                    KeyValue&amp;lt;Long, String&amp;gt; kv = it.next();
+                    result.put(kv.key, kv.value);
+                }&lt;br/&gt;
+                return result.equals(expected);&lt;br/&gt;
+            }&lt;br/&gt;
+        }, 30000L, &quot;waiting for initial values&quot;);&lt;br/&gt;
+    }&lt;br/&gt;
+    &lt;br/&gt;
+    @Test&lt;br/&gt;
+    public void shouldNotRestoreAbortedMessages() throws Exception {&lt;br/&gt;
+        produceAbortedMessages();&lt;br/&gt;
+        produceInitialGlobalTableValues();&lt;br/&gt;
+        produceAbortedMessages();&lt;br/&gt;
+&lt;br/&gt;
+        startStreams();&lt;br/&gt;
+        &lt;br/&gt;
+        final Map&amp;lt;Long, String&amp;gt; expected = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
+        expected.put(1L, &quot;A&quot;);&lt;br/&gt;
+        expected.put(2L, &quot;B&quot;);&lt;br/&gt;
+        expected.put(3L, &quot;C&quot;);&lt;br/&gt;
+        expected.put(4L, &quot;D&quot;);&lt;br/&gt;
+&lt;br/&gt;
+        TestUtils.waitForCondition(new TestCondition() {&lt;br/&gt;
+            @Override&lt;br/&gt;
+            public boolean conditionMet() {&lt;br/&gt;
+                ReadOnlyKeyValueStore&amp;lt;Long, String&amp;gt; store = null;&lt;br/&gt;
+                try {+                    store = kafkaStreams.store(globalStore, QueryableStoreTypes.&amp;lt;Long, String&amp;gt;keyValueStore());+                } catch (InvalidStateStoreException ex) {
+                    return false;
+                }&lt;br/&gt;
+                Map&amp;lt;Long, String&amp;gt; result = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
+                Iterator&amp;lt;KeyValue&amp;lt;Long, String&amp;gt;&amp;gt; it = store.all();&lt;br/&gt;
+                while (it.hasNext()) {
+                    KeyValue&amp;lt;Long, String&amp;gt; kv = it.next();
+                    result.put(kv.key, kv.value);
+                }&lt;br/&gt;
+                return result.equals(expected);&lt;br/&gt;
+            }&lt;br/&gt;
+        }, 30000L, &quot;waiting for initial values&quot;);&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    private void createTopics() throws InterruptedException {
+        streamTopic = &quot;stream-&quot; + testNo;
+        globalTableTopic = &quot;globalTable-&quot; + testNo;
+        CLUSTER.createTopics(streamTopic);
+        CLUSTER.createTopic(globalTableTopic, 2, 1);
+    }&lt;br/&gt;
+    &lt;br/&gt;
+    private void startStreams() {
+        kafkaStreams = new KafkaStreams(builder.build(), streamsConfiguration);
+        kafkaStreams.start();
+    }&lt;br/&gt;
+&lt;br/&gt;
+    private void produceTopicValues(final String topic) throws Exception {
+        IntegrationTestUtils.produceKeyValuesSynchronously(
+                topic,
+                Arrays.asList(
+                        new KeyValue&amp;lt;&amp;gt;(&quot;a&quot;, 1L),
+                        new KeyValue&amp;lt;&amp;gt;(&quot;b&quot;, 2L),
+                        new KeyValue&amp;lt;&amp;gt;(&quot;c&quot;, 3L),
+                        new KeyValue&amp;lt;&amp;gt;(&quot;d&quot;, 4L),
+                        new KeyValue&amp;lt;&amp;gt;(&quot;e&quot;, 5L)),
+                TestUtils.producerConfig(
+                        CLUSTER.bootstrapServers(),
+                        StringSerializer.class,
+                        LongSerializer.class,
+                        new Properties()),
+                mockTime);
+    }&lt;br/&gt;
+&lt;br/&gt;
+    private void produceAbortedMessages() throws Exception {
+        final Properties properties = new Properties();
+        properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, &quot;someid&quot;);
+        properties.put(ProducerConfig.RETRIES_CONFIG, 1);
+        IntegrationTestUtils.produceAbortedKeyValuesSynchronouslyWithTimestamp(
+                globalTableTopic, Arrays.asList(
+                        new KeyValue&amp;lt;&amp;gt;(1L, &quot;A&quot;),
+                        new KeyValue&amp;lt;&amp;gt;(2L, &quot;B&quot;),
+                        new KeyValue&amp;lt;&amp;gt;(3L, &quot;C&quot;),
+                        new KeyValue&amp;lt;&amp;gt;(4L, &quot;D&quot;)
+                        ), 
+                TestUtils.producerConfig(
+                                CLUSTER.bootstrapServers(),
+                                LongSerializer.class,
+                                StringSerializer.class,
+                                properties),
+                mockTime.milliseconds());
+    }&lt;br/&gt;
+&lt;br/&gt;
+    private void produceInitialGlobalTableValues() throws Exception {
+        produceInitialGlobalTableValues(true);
+    }&lt;br/&gt;
+&lt;br/&gt;
+    private void produceInitialGlobalTableValues(final boolean enableTransactions) throws Exception {&lt;br/&gt;
+        final Properties properties = new Properties();&lt;br/&gt;
+        if (enableTransactions) {
+            properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, &quot;someid&quot;);
+            properties.put(ProducerConfig.RETRIES_CONFIG, 1);
+        }&lt;br/&gt;
+        IntegrationTestUtils.produceKeyValuesSynchronously(&lt;br/&gt;
+                globalTableTopic,&lt;br/&gt;
+                Arrays.asList(&lt;br/&gt;
+                        new KeyValue&amp;lt;&amp;gt;(1L, &quot;A&quot;),&lt;br/&gt;
+                        new KeyValue&amp;lt;&amp;gt;(2L, &quot;B&quot;),&lt;br/&gt;
+                        new KeyValue&amp;lt;&amp;gt;(3L, &quot;C&quot;),&lt;br/&gt;
+                        new KeyValue&amp;lt;&amp;gt;(4L, &quot;D&quot;)&lt;br/&gt;
+                        ),&lt;br/&gt;
+                TestUtils.producerConfig(&lt;br/&gt;
+                        CLUSTER.bootstrapServers(),&lt;br/&gt;
+                        LongSerializer.class,&lt;br/&gt;
+                        StringSerializer.class,&lt;br/&gt;
+                        properties),&lt;br/&gt;
+                mockTime,&lt;br/&gt;
+                enableTransactions);&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    private void produceGlobalTableValues() throws Exception {
+        IntegrationTestUtils.produceKeyValuesSynchronously(
+                globalTableTopic,
+                Arrays.asList(
+                        new KeyValue&amp;lt;&amp;gt;(1L, &quot;F&quot;),
+                        new KeyValue&amp;lt;&amp;gt;(2L, &quot;G&quot;),
+                        new KeyValue&amp;lt;&amp;gt;(3L, &quot;H&quot;),
+                        new KeyValue&amp;lt;&amp;gt;(4L, &quot;I&quot;),
+                        new KeyValue&amp;lt;&amp;gt;(5L, &quot;J&quot;)),
+                TestUtils.producerConfig(
+                        CLUSTER.bootstrapServers(),
+                        LongSerializer.class,
+                        StringSerializer.class,
+                        new Properties()),
+                mockTime);
+    }&lt;br/&gt;
+}&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/GlobalKTableIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/GlobalKTableIntegrationTest.java&lt;br/&gt;
index 8c6a30a5972..900e65276ee 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/integration/GlobalKTableIntegrationTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/integration/GlobalKTableIntegrationTest.java&lt;br/&gt;
@@ -18,7 +18,6 @@&lt;br/&gt;
 &lt;br/&gt;
 import kafka.utils.MockTime;&lt;br/&gt;
 import org.apache.kafka.clients.consumer.ConsumerConfig;&lt;br/&gt;
-import org.apache.kafka.clients.producer.ProducerConfig;&lt;br/&gt;
 import org.apache.kafka.common.serialization.LongSerializer;&lt;br/&gt;
 import org.apache.kafka.common.serialization.Serdes;&lt;br/&gt;
 import org.apache.kafka.common.serialization.StringSerializer;&lt;br/&gt;
@@ -28,7 +27,6 @@&lt;br/&gt;
 import org.apache.kafka.streams.KeyValue;&lt;br/&gt;
 import org.apache.kafka.streams.StreamsBuilder;&lt;br/&gt;
 import org.apache.kafka.streams.StreamsConfig;&lt;br/&gt;
-import org.apache.kafka.streams.errors.InvalidStateStoreException;&lt;br/&gt;
 import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;&lt;br/&gt;
 import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.ForeachAction;&lt;br/&gt;
@@ -52,23 +50,16 @@&lt;br/&gt;
 import java.io.IOException;&lt;br/&gt;
 import java.util.Arrays;&lt;br/&gt;
 import java.util.HashMap;&lt;br/&gt;
-import java.util.Iterator;&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
 import java.util.Properties;&lt;br/&gt;
 &lt;br/&gt;
 @Category({IntegrationTest.class}
&lt;p&gt;)&lt;br/&gt;
 public class GlobalKTableIntegrationTest {&lt;br/&gt;
     private static final int NUM_BROKERS = 1;&lt;/p&gt;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;private static final Properties BROKER_CONFIG;&lt;/li&gt;
	&lt;li&gt;static 
{
-        BROKER_CONFIG = new Properties();
-        BROKER_CONFIG.put(&quot;transaction.state.log.replication.factor&quot;, (short) 1);
-        BROKER_CONFIG.put(&quot;transaction.state.log.min.isr&quot;, 1);
-    }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @ClassRule&lt;br/&gt;
     public static final EmbeddedKafkaCluster CLUSTER =&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new EmbeddedKafkaCluster(NUM_BROKERS, BROKER_CONFIG);&lt;br/&gt;
+            new EmbeddedKafkaCluster(NUM_BROKERS);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     private static volatile int testNo = 0;&lt;br/&gt;
     private final MockTime mockTime = CLUSTER.time;&lt;br/&gt;
@@ -229,46 +220,14 @@ public boolean conditionMet() {&lt;br/&gt;
             }&lt;br/&gt;
         }, 30000L, &quot;waiting for final values&quot;);&lt;br/&gt;
     }&lt;br/&gt;
-&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test&lt;/li&gt;
	&lt;li&gt;public void shouldRestoreTransactionalMessages() throws Exception {&lt;/li&gt;
	&lt;li&gt;produceInitialGlobalTableValues(true);&lt;/li&gt;
	&lt;li&gt;startStreams();&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;final Map&amp;lt;Long, String&amp;gt; expected = new HashMap&amp;lt;&amp;gt;();&lt;/li&gt;
	&lt;li&gt;expected.put(1L, &quot;A&quot;);&lt;/li&gt;
	&lt;li&gt;expected.put(2L, &quot;B&quot;);&lt;/li&gt;
	&lt;li&gt;expected.put(3L, &quot;C&quot;);&lt;/li&gt;
	&lt;li&gt;expected.put(4L, &quot;D&quot;);&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;TestUtils.waitForCondition(new TestCondition() {&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public boolean conditionMet() {&lt;/li&gt;
	&lt;li&gt;ReadOnlyKeyValueStore&amp;lt;Long, String&amp;gt; store = null;&lt;/li&gt;
	&lt;li&gt;try 
{
-                    store = kafkaStreams.store(globalStore, QueryableStoreTypes.&amp;lt;Long, String&amp;gt;keyValueStore());
-                }
&lt;p&gt; catch (InvalidStateStoreException ex) &lt;/p&gt;
{
-                    return false;
-                }&lt;/li&gt;
	&lt;li&gt;Map&amp;lt;Long, String&amp;gt; result = new HashMap&amp;lt;&amp;gt;();&lt;/li&gt;
	&lt;li&gt;Iterator&amp;lt;KeyValue&amp;lt;Long, String&amp;gt;&amp;gt; it = store.all();&lt;/li&gt;
	&lt;li&gt;while (it.hasNext()) 
{
-                    KeyValue&amp;lt;Long, String&amp;gt; kv = it.next();
-                    result.put(kv.key, kv.value);
-                }&lt;/li&gt;
	&lt;li&gt;return result.equals(expected);&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;}, 30000L, &quot;waiting for initial values&quot;);&lt;/li&gt;
	&lt;li&gt;System.out.println(&quot;no failed test&quot;);&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;br/&gt;
+    &lt;br/&gt;
     private void createTopics() throws InterruptedException 
{
         streamTopic = &quot;stream-&quot; + testNo;
         globalTableTopic = &quot;globalTable-&quot; + testNo;
         CLUSTER.createTopics(streamTopic);
         CLUSTER.createTopic(globalTableTopic, 2, 1);
     }
&lt;p&gt;-&lt;br/&gt;
+    &lt;br/&gt;
     private void startStreams() {&lt;br/&gt;
         kafkaStreams = new KafkaStreams(builder.build(), streamsConfiguration);&lt;br/&gt;
         kafkaStreams.start();&lt;br/&gt;
@@ -292,29 +251,20 @@ private void produceTopicValues(final String topic) throws Exception {&lt;br/&gt;
     }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     private void produceInitialGlobalTableValues() throws Exception &lt;/p&gt;
{
-        produceInitialGlobalTableValues(false);
-    }
&lt;p&gt;-&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private void produceInitialGlobalTableValues(final boolean enableTransactions) throws Exception {&lt;/li&gt;
	&lt;li&gt;Properties properties = new Properties();&lt;/li&gt;
	&lt;li&gt;if (enableTransactions) 
{
-            properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, &quot;someid&quot;);
-            properties.put(ProducerConfig.RETRIES_CONFIG, 1);
-        }
&lt;p&gt;         IntegrationTestUtils.produceKeyValuesSynchronously(&lt;br/&gt;
                 globalTableTopic,&lt;br/&gt;
                 Arrays.asList(&lt;br/&gt;
                         new KeyValue&amp;lt;&amp;gt;(1L, &quot;A&quot;),&lt;br/&gt;
                         new KeyValue&amp;lt;&amp;gt;(2L, &quot;B&quot;),&lt;br/&gt;
                         new KeyValue&amp;lt;&amp;gt;(3L, &quot;C&quot;),&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;new KeyValue&amp;lt;&amp;gt;(4L, &quot;D&quot;)),&lt;br/&gt;
+                        new KeyValue&amp;lt;&amp;gt;(4L, &quot;D&quot;)&lt;br/&gt;
+                        ),&lt;br/&gt;
                 TestUtils.producerConfig(&lt;br/&gt;
                         CLUSTER.bootstrapServers(),&lt;br/&gt;
                         LongSerializer.class,&lt;/li&gt;
	&lt;li&gt;StringSerializer.class,&lt;/li&gt;
	&lt;li&gt;properties),&lt;/li&gt;
	&lt;li&gt;mockTime,&lt;/li&gt;
	&lt;li&gt;enableTransactions);&lt;br/&gt;
+                        StringSerializer.class&lt;br/&gt;
+                        ),&lt;br/&gt;
+                mockTime);&lt;br/&gt;
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     private void produceGlobalTableValues() throws Exception &lt;/p&gt;
{
diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java b/streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java
index fe897c7ac30..441549dca77 100644
--- a/streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java
+++ b/streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java
@@ -179,16 +179,38 @@ public static void purgeLocalStreamsState(final Properties streamsConfiguration)
             producer.flush();
         }
&lt;p&gt;     }&lt;br/&gt;
+    &lt;br/&gt;
+    public static &amp;lt;K, V&amp;gt; void produceAbortedKeyValuesSynchronouslyWithTimestamp(final String topic,&lt;br/&gt;
+                                                                                final Collection&amp;lt;KeyValue&amp;lt;K, V&amp;gt;&amp;gt; records,&lt;br/&gt;
+                                                                                final Properties producerConfig,&lt;br/&gt;
+                                                                                final Long timestamp)&lt;br/&gt;
+        throws ExecutionException, InterruptedException {&lt;br/&gt;
+        try (final Producer&amp;lt;K, V&amp;gt; producer = new KafkaProducer&amp;lt;&amp;gt;(producerConfig)) {&lt;br/&gt;
+            producer.initTransactions();&lt;br/&gt;
+            for (final KeyValue&amp;lt;K, V&amp;gt; record : records) &lt;/p&gt;
{
+                producer.beginTransaction();
+                final Future&amp;lt;RecordMetadata&amp;gt; f = producer
+                        .send(new ProducerRecord&amp;lt;&amp;gt;(topic, null, timestamp, record.key, record.value));
+                f.get();
+                producer.abortTransaction();
+            }
&lt;p&gt;+        }    &lt;br/&gt;
+    }&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public static &amp;lt;V&amp;gt; void produceValuesSynchronously(&lt;/li&gt;
	&lt;li&gt;final String topic, final Collection&amp;lt;V&amp;gt; records, final Properties producerConfig, final Time time)&lt;br/&gt;
+    public static &amp;lt;V&amp;gt; void produceValuesSynchronously(final String topic,&lt;br/&gt;
+                                                      final Collection&amp;lt;V&amp;gt; records,&lt;br/&gt;
+                                                      final Properties producerConfig,&lt;br/&gt;
+                                                      final Time time)&lt;br/&gt;
         throws ExecutionException, InterruptedException 
{
         IntegrationTestUtils.produceValuesSynchronously(topic, records, producerConfig, time, false);
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public static &amp;lt;V&amp;gt; void produceValuesSynchronously(&lt;/li&gt;
	&lt;li&gt;final String topic, final Collection&amp;lt;V&amp;gt; records, final Properties producerConfig, final Time time, final boolean enableTransactions)&lt;/li&gt;
	&lt;li&gt;throws ExecutionException, InterruptedException {&lt;br/&gt;
+    public static &amp;lt;V&amp;gt; void produceValuesSynchronously(final String topic,&lt;br/&gt;
+                                                      final Collection&amp;lt;V&amp;gt; records,&lt;br/&gt;
+                                                      final Properties producerConfig,&lt;br/&gt;
+                                                      final Time time,&lt;br/&gt;
+                                                      final boolean enableTransactions)&lt;br/&gt;
+            throws ExecutionException, InterruptedException {&lt;br/&gt;
         final Collection&amp;lt;KeyValue&amp;lt;Object, V&amp;gt;&amp;gt; keyedRecords = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
         for (final V value : records) {&lt;br/&gt;
             final KeyValue&amp;lt;Object, V&amp;gt; kv = new KeyValue&amp;lt;&amp;gt;(null, value);&lt;br/&gt;
@@ -240,10 +262,9 @@ public static void waitForCompletion(final KafkaStreams streams,&lt;br/&gt;
     public static &amp;lt;K, V&amp;gt; List&amp;lt;KeyValue&amp;lt;K, V&amp;gt;&amp;gt; waitUntilMinKeyValueRecordsReceived(final Properties consumerConfig,&lt;br/&gt;
                                                                                   final String topic,&lt;br/&gt;
                                                                                   final int expectedNumRecords) throws InterruptedException 
{
-
         return waitUntilMinKeyValueRecordsReceived(consumerConfig, topic, expectedNumRecords, DEFAULT_TIMEOUT);
     }
&lt;p&gt;-&lt;br/&gt;
+    &lt;br/&gt;
     /**&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;Wait until enough data (key-value records) has been consumed.&lt;br/&gt;
      *&lt;/li&gt;
&lt;/ul&gt;





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12311020" key="com.atlassian.jira.plugin.system.customfieldtypes:url">
                        <customfieldname>External issue URL</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[https://github.com/apache/kafka/pull/4900]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 22 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3sgdb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>