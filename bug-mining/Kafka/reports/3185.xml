<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:29:50 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-13727] Edge case in cleaner can result in premature removal of ABORT marker</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-13727</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;The log cleaner works by first building a map of the active keys beginning from the dirty offset, and then scanning forward from the beginning of the log to decide which records should be retained based on whether they are included in the map. The map of keys has a limited size. As soon as it fills up, we stop building it. The offset corresponding to the last record that was included in the map becomes the next dirty offset. Then when we are cleaning, we stop scanning forward at the dirty offset. Or to be more precise, we continue scanning until the end of the segment which includes the dirty offset, but all records above that offset are coped as is without checking the map of active keys.&#160;&lt;/p&gt;

&lt;p&gt;Compaction is complicated by the presence of transactions. The cleaner must keep track of which transactions have data remaining so that it can tell when it is safe to remove the respective markers. It works a bit like the consumer. Before scanning a segment, the cleaner consults the aborted transaction index to figure out which transactions have been aborted. All other transactions are considered committed.&lt;/p&gt;

&lt;p&gt;The problem we have found is that the cleaner does not take into account the range of offsets between the dirty offset and the end offset of the segment containing it when querying ahead for aborted transactions. This means that when the cleaner is scanning forward from the dirty offset, it does not have the complete set of aborted transactions. The main consequence of this is that abort markers associated with transactions which start within this range of offsets become eligible for deletion even before the corresponding data has been removed from the log.&lt;/p&gt;

&lt;p&gt;Here is an example. Suppose that the log contains the following entries:&lt;/p&gt;

&lt;p&gt;offset=0, key=a&lt;/p&gt;

&lt;p&gt;offset=1, key=b&lt;/p&gt;

&lt;p&gt;offset=2, COMMIT&lt;/p&gt;

&lt;p&gt;offset=3, key=c&lt;/p&gt;

&lt;p&gt;offset=4, key=d&lt;/p&gt;

&lt;p&gt;offset=5, COMMIT&lt;/p&gt;

&lt;p&gt;offset=6, key=b&lt;/p&gt;

&lt;p&gt;offset=7, ABORT&lt;/p&gt;

&lt;p&gt;Suppose we have an offset map which can only contain 2 keys and the dirty offset starts at 0. The first time we scan forward, we will build a map with keys a and b, which will allow us to move the dirty offset up to 3. Due to the issue documented here, we will not detect the aborted transaction starting at offset 6. But it will not be eligible for deletion on this round of cleaning because it is bound by `delete.retention.ms`. Instead, our new logic will set the deletion horizon for this batch based to the current time plus the configured `delete.retention.ms`.&lt;/p&gt;

&lt;p&gt;offset=0, key=a&lt;/p&gt;

&lt;p&gt;offset=1, key=b&lt;/p&gt;

&lt;p&gt;offset=2, COMMIT&lt;/p&gt;

&lt;p&gt;offset=3, key=c&lt;/p&gt;

&lt;p&gt;offset=4, key=d&lt;/p&gt;

&lt;p&gt;offset=5, COMMIT&lt;/p&gt;

&lt;p&gt;offset=6, key=b&lt;/p&gt;

&lt;p&gt;offset=7, ABORT (deleteHorizon: N)&lt;/p&gt;

&lt;p&gt;Suppose that the time reaches N+1 before the next cleaning. We will begin from the dirty offset of 3 and collect keys c and d before stopping at offset 6. Again, we will not detect the aborted transaction beginning at offset 6 since it is out of the range. This time when we scan, the marker at offset 7 will be deleted because the transaction will be seen as empty and now the deletion horizon has passed. So we end up with this state:&lt;/p&gt;

&lt;p&gt;offset=0, key=a&lt;/p&gt;

&lt;p&gt;offset=1, key=b&lt;/p&gt;

&lt;p&gt;offset=2, COMMIT&lt;/p&gt;

&lt;p&gt;offset=3, key=c&lt;/p&gt;

&lt;p&gt;offset=4, key=d&lt;/p&gt;

&lt;p&gt;offset=5, COMMIT&lt;/p&gt;

&lt;p&gt;offset=6, key=b&lt;/p&gt;

&lt;p&gt;Effectively it becomes a hanging transaction. The interesting thing is that we might not even detect it. As far as the leader is concerned, it had already completed that transaction, so it is not expecting any additional markers. The transaction index would have been rewritten without the aborted transaction when the log was cleaned, so any consumer fetching the data would see the transaction as committed. On the other hand, if we did a reassignment to a new replica, or if we had to rebuild the full log state during recovery, then we would suddenly detect it.&lt;/p&gt;

&lt;p&gt;I am not sure how likely this scenario is in practice. I think it&apos;s fair to say it is an extremely rare case. The cleaner has to fail to clean a full segment at least two times and you still need enough time to pass for the marker&apos;s deletion horizon to be reached. Perhaps it is possible if the cardinality of keys is very high and the configured memory limit for the cleaner is low.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13433240">KAFKA-13727</key>
            <summary>Edge case in cleaner can result in premature removal of ABORT marker</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hachikuji">Jason Gustafson</assignee>
                                    <reporter username="hachikuji">Jason Gustafson</reporter>
                        <labels>
                    </labels>
                <created>Fri, 11 Mar 2022 01:03:17 +0000</created>
                <updated>Tue, 15 Mar 2022 20:17:09 +0000</updated>
                            <resolved>Tue, 15 Mar 2022 20:17:09 +0000</resolved>
                                                    <fixVersion>2.8.2</fixVersion>
                    <fixVersion>3.0.2</fixVersion>
                    <fixVersion>3.1.1</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="17505107" author="hachikuji" created="Fri, 11 Mar 2022 20:34:12 +0000"  >&lt;p&gt;I realized that this bug is more likely to occur than I first suspected. In fact, it only requires one incomplete cleaner pass over a segment. The problem is that the first pass fails to recreate the transaction index correctly since the aborted transactions are incomplete. Effectively the data from the aborted transaction becomes &quot;disconnected&quot; from the marker after the first pass because it is no longer present in the index. So any subsequent pass (whether complete or not) will preserve that incompleteness, which means the marker can be removed on any subsequent pass even if the data is still present. What is arguably worse than losing the marker, the data from this transaction effectively becomes committed.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 35 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z10e08:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>