<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:18:25 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-8335] Log cleaner skips Transactional mark and batch record, causing unlimited growth of __consumer_offsets</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-8335</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;My Colleague Weichu already sent out a mail to kafka user mailing list regarding this issue, but we think it&apos;s worth having a ticket tracking it.&lt;/p&gt;

&lt;p&gt;We are using Kafka Streams with exactly-once enabled on a Kafka cluster for&lt;br/&gt;
a while.&lt;/p&gt;

&lt;p&gt;Recently we found that the size of __consumer_offsets partitions grew huge.&lt;br/&gt;
Some partition went over 30G. This caused Kafka to take quite long to load&lt;br/&gt;
&quot;__consumer_offsets&quot; topic on startup (it loads the topic in order to&lt;br/&gt;
become group coordinator).&lt;/p&gt;

&lt;p&gt;We dumped the __consumer_offsets segments and found that while normal&lt;br/&gt;
offset commits are nicely compacted, transaction records (COMMIT, etc) are&lt;br/&gt;
all preserved. Looks like that since these messages don&apos;t have a key, the&lt;br/&gt;
LogCleaner is keeping them all:&lt;/p&gt;

&lt;p&gt;----------&lt;br/&gt;
$ bin/kafka-run-class.sh kafka.tools.DumpLogSegments --files&lt;br/&gt;
..../00000000003484332061.log --key-decoder-class&lt;br/&gt;
kafka.serializer.StringDecoder 2&amp;gt;/dev/null | cat -v | head&lt;br/&gt;
Dumping 00000000003484332061.log&lt;br/&gt;
Starting offset: 3484332061&lt;br/&gt;
offset: 3484332089 position: 549 CreateTime: 1556003706952 isvalid: true&lt;br/&gt;
keysize: 4 valuesize: 6 magic: 2 compresscodec: NONE producerId: 1006&lt;br/&gt;
producerEpoch: 2530 sequence: -1 isTransactional: true headerKeys: []&lt;br/&gt;
endTxnMarker: COMMIT coordinatorEpoch: 81&lt;br/&gt;
offset: 3484332090 position: 627 CreateTime: 1556003706952 isvalid: true&lt;br/&gt;
keysize: 4 valuesize: 6 magic: 2 compresscodec: NONE producerId: 4005&lt;br/&gt;
producerEpoch: 2520 sequence: -1 isTransactional: true headerKeys: []&lt;br/&gt;
endTxnMarker: COMMIT coordinatorEpoch: 84&lt;br/&gt;
...&lt;br/&gt;
----------&lt;/p&gt;

&lt;p&gt;Streams is doing transaction commits per 100ms (commit.interval.ms=100 when&lt;br/&gt;
exactly-once) so the __consumer_offsets is growing really fast.&lt;/p&gt;

&lt;p&gt;Is this (to keep all transactions) by design, or is that a bug for&lt;br/&gt;
LogCleaner?  What would be the way to clean up the topic?&lt;/p&gt;
</description>
                <environment></environment>
        <key id="13232170">KAFKA-8335</key>
            <summary>Log cleaner skips Transactional mark and batch record, causing unlimited growth of __consumer_offsets</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hachikuji">Jason Gustafson</assignee>
                                    <reporter username="boquan">Boquan Tang</reporter>
                        <labels>
                    </labels>
                <created>Wed, 8 May 2019 07:34:17 +0000</created>
                <updated>Thu, 10 Jun 2021 08:37:20 +0000</updated>
                            <resolved>Mon, 13 May 2019 15:57:56 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>2.0.2</fixVersion>
                    <fixVersion>2.1.2</fixVersion>
                    <fixVersion>2.2.1</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>13</watches>
                                                                                                                <comments>
                            <comment id="16835720" author="hachikuji" created="Wed, 8 May 2019 16:12:07 +0000"  >&lt;p&gt;Thanks for the report. Can you provide your broker configuration? COMMIT markers should be cleaned as soon as all the data from the transaction has also been deleted. It can be delayed by as long as `delete.retention.ms` though. It might be helpful if you provide the full dump of the segment.&lt;/p&gt;</comment>
                            <comment id="16836061" author="weichu" created="Thu, 9 May 2019 03:34:40 +0000"  >&lt;p&gt;Hi, I uploaded a sample segment here:&#160;&lt;span class=&quot;nobr&quot;&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12968255/12968255_segment.zip&quot; title=&quot;segment.zip attached to KAFKA-8335&quot;&gt;segment.zip&lt;sup&gt;&lt;img class=&quot;rendericon&quot; src=&quot;https://issues.apache.org/jira/images/icons/link_attachment_7.gif&quot; height=&quot;7&quot; width=&quot;7&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/sup&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;And here is the broker setting on our Kafka&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[2019-05-07 02:00:50,472] INFO KafkaConfig values:
        advertised.host.name = null
        advertised.listeners = null
        advertised.port = null
        alter.config.policy.class.name = null
        alter.log.dirs.replication.quota.window.num = 11
        alter.log.dirs.replication.quota.window.size.seconds = 1
        authorizer.class.name =
        auto.create.topics.enable = true
        auto.leader.rebalance.enable = true
        background.threads = 10
        broker.id = 1
        broker.id.generation.enable = true
        broker.rack = null
        client.quota.callback.class = null
        compression.type = producer
        connection.failed.authentication.delay.ms = 100
        connections.max.idle.ms = 600000
        connections.max.reauth.ms = 0
        control.plane.listener.name = null
        controlled.shutdown.enable = true
        controlled.shutdown.max.retries = 3
        controlled.shutdown.retry.backoff.ms = 5000
        controller.socket.timeout.ms = 30000
        create.topic.policy.class.name = null
        default.replication.factor = 3
        delegation.token.expiry.check.interval.ms = 3600000
        delegation.token.expiry.time.ms = 86400000
        delegation.token.master.key = null
        delegation.token.max.lifetime.ms = 604800000
        delete.records.purgatory.purge.interval.requests = 1
        delete.topic.enable = true
        fetch.purgatory.purge.interval.requests = 1000
        group.initial.rebalance.delay.ms = 3000
        group.max.session.timeout.ms = 300000
        group.max.size = 2147483647
        group.min.session.timeout.ms = 6000
        host.name =
        inter.broker.listener.name = null
        inter.broker.protocol.version = 2.2-IV1
        kafka.metrics.polling.interval.secs = 10
        kafka.metrics.reporters = []
        leader.imbalance.check.interval.seconds = 300
        leader.imbalance.per.broker.percentage = 10
        listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
        listeners = PLAINTEXT://:9092,SSL://:9093
        log.cleaner.backoff.ms = 15000
        log.cleaner.dedupe.buffer.size = 134217728
        log.cleaner.delete.retention.ms = 86400000
        log.cleaner.enable = true
        log.cleaner.io.buffer.load.factor = 0.9
        log.cleaner.io.buffer.size = 524288
        log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
        log.cleaner.min.cleanable.ratio = 0.5
        log.cleaner.min.compaction.lag.ms = 0
        log.cleaner.threads = 1
        log.cleanup.policy = [delete]
        log.dir = /tmp/kafka-logs
        log.dirs = /var/lib/kafka/data
        log.flush.interval.messages = 9223372036854775807
        log.flush.interval.ms = null
        log.flush.offset.checkpoint.interval.ms = 60000
        log.flush.scheduler.interval.ms = 9223372036854775807
        log.flush.start.offset.checkpoint.interval.ms = 60000
        log.index.interval.bytes = 4096
        log.index.size.max.bytes = 10485760
        log.message.downconversion.enable = true
        log.message.format.version = 2.2-IV1
        log.message.timestamp.difference.max.ms = 9223372036854775807
        log.message.timestamp.type = CreateTime
        log.preallocate = false
        log.retention.bytes = -1
        log.retention.check.interval.ms = 300000
        log.retention.hours = 168
        log.retention.minutes = null
        log.retention.ms = null
        log.roll.hours = 168
        log.roll.jitter.hours = 0
        log.roll.jitter.ms = null
        log.roll.ms = null
        log.segment.bytes = 1073741824
        log.segment.delete.delay.ms = 60000
        max.connections.per.ip = 2147483647
        max.connections.per.ip.overrides =
        max.incremental.fetch.session.cache.slots = 1000
        message.max.bytes = 2097152
        metric.reporters = []
        metrics.num.samples = 2
        metrics.recording.level = INFO
        metrics.sample.window.ms = 30000
        min.insync.replicas = 1
        num.io.threads = 8
        num.network.threads = 3
        num.partitions = 5
        num.recovery.threads.per.data.dir = 1
        num.replica.alter.log.dirs.threads = null
        num.replica.fetchers = 1
        offset.metadata.max.bytes = 4096
        offsets.commit.required.acks = -1
        offsets.commit.timeout.ms = 5000
        offsets.load.buffer.size = 5242880
        offsets.retention.check.interval.ms = 600000
        offsets.retention.minutes = 10080
        offsets.topic.compression.codec = 0
        offsets.topic.num.partitions = 50
        offsets.topic.replication.factor = 3
        offsets.topic.segment.bytes = 104857600
        password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
        password.encoder.iterations = 4096
        password.encoder.key.length = 128
        password.encoder.keyfactory.algorithm = null
        password.encoder.old.secret = null
        password.encoder.secret = null
        port = 9092
        principal.builder.class = null
        producer.purgatory.purge.interval.requests = 1000
        queued.max.request.bytes = -1
        queued.max.requests = 500
        quota.consumer.default = 9223372036854775807
        quota.producer.default = 9223372036854775807
        quota.window.num = 11
        quota.window.size.seconds = 1
        replica.fetch.backoff.ms = 1000
        replica.fetch.max.bytes = 1048576
        replica.fetch.min.bytes = 1
        replica.fetch.response.max.bytes = 10485760
        replica.fetch.wait.max.ms = 500
        replica.high.watermark.checkpoint.interval.ms = 5000
        replica.lag.time.max.ms = 10000
        replica.socket.receive.buffer.bytes = 65536
        replica.socket.timeout.ms = 30000
        replication.quota.window.num = 11
        replication.quota.window.size.seconds = 1
        request.timeout.ms = 30000
        reserved.broker.max.id = 1000
        sasl.client.callback.handler.class = null
        sasl.enabled.mechanisms = [GSSAPI]
        sasl.jaas.config = null
        sasl.kerberos.kinit.cmd = /usr/bin/kinit
        sasl.kerberos.min.time.before.relogin = 60000
        sasl.kerberos.principal.to.local.rules = [DEFAULT]
        sasl.kerberos.service.name = null
        sasl.kerberos.ticket.renew.jitter = 0.05
        sasl.kerberos.ticket.renew.window.factor = 0.8
        sasl.login.callback.handler.class = null
        sasl.login.class = null
        sasl.login.refresh.buffer.seconds = 300
        sasl.login.refresh.min.period.seconds = 60
        sasl.login.refresh.window.factor = 0.8
        sasl.login.refresh.window.jitter = 0.05
        sasl.mechanism.inter.broker.protocol = GSSAPI
        sasl.server.callback.handler.class = null
        security.inter.broker.protocol = PLAINTEXT
        socket.receive.buffer.bytes = 102400
        socket.request.max.bytes = 104857600
        socket.send.buffer.bytes = 102400
        ssl.cipher.suites = []
        ssl.client.auth = none
        ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
        ssl.endpoint.identification.algorithm = https
        ssl.key.password = [hidden]
        ssl.keymanager.algorithm = SunX509
        ssl.keystore.location = /etc/kafka/server.keystore.jks
        ssl.keystore.password = [hidden]
        ssl.keystore.type = JKS
        ssl.principal.mapping.rules = [DEFAULT]
        ssl.protocol = TLS
        ssl.provider = null
        ssl.secure.random.implementation = null
        ssl.trustmanager.algorithm = PKIX
        ssl.truststore.location = /etc/kafka/server.truststore.jks
        ssl.truststore.password = [hidden]
        ssl.truststore.type = JKS
        transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
        transaction.max.timeout.ms = 900000
        transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
        transaction.state.log.load.buffer.size = 5242880
        transaction.state.log.min.isr = 2
        transaction.state.log.num.partitions = 50
        transaction.state.log.replication.factor = 3
        transaction.state.log.segment.bytes = 104857600
        transactional.id.expiration.ms = 604800000
        unclean.leader.election.enable = false
        zookeeper.connect = kafka1:2181,kafka2:2181,kafka3:2181
        zookeeper.connection.timeout.ms = 6000
        zookeeper.max.in.flight.requests = 10
        zookeeper.session.timeout.ms = 6000
        zookeeper.set.acl = false
        zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="16836075" author="boquan" created="Thu, 9 May 2019 04:46:53 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt; thanks for replying.&lt;br/&gt;
 As Weichu commented we have log.cleaner.delete.retention.ms = 86400000 which is one day. To better illustrate the suspected issue, I uploaded the full segment from April 25 &lt;span class=&quot;nobr&quot;&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12968257/12968257_seg_april_25.zip&quot; title=&quot;seg_april_25.zip attached to KAFKA-8335&quot;&gt;seg_april_25.zip&lt;sup&gt;&lt;img class=&quot;rendericon&quot; src=&quot;https://issues.apache.org/jira/images/icons/link_attachment_7.gif&quot; height=&quot;7&quot; width=&quot;7&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/sup&gt;&lt;/a&gt;&lt;/span&gt;, which is 2 weeks ago from the time it was retrieved.&lt;br/&gt;
 log dump shows not only endTxnMarker is not deleted, the record batch metadata is also retained:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Dumping /home/boquan/Downloads/Users/boquan/Documents/00000000003530931566.log
Starting offset: 3530931566
baseOffset: 3530931566 lastOffset: 3530931567 count: 0 baseSequence: 0 lastSequence: 1 producerId: 4001 producerEpoch: 2539 partitionLeaderEpoch: 94 isTransactional: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; isControl: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; position: 0 CreateTime: 1556161832882 size: 61 magic: 2 compresscodec: NONE crc: 1683579819 isvalid: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
baseOffset: 3530931575 lastOffset: 3530931575 count: 1 baseSequence: -1 lastSequence: -1 producerId: 4001 producerEpoch: 2539 partitionLeaderEpoch: 94 isTransactional: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; isControl: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; position: 61 CreateTime: 1556161832899 size: 78 magic: 2 compresscodec: NONE crc: 535474521 isvalid: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
| offset: 3530931575 CreateTime: 1556161832899 keysize: 4 valuesize: 6 sequence: -1 headerKeys: [] endTxnMarker: COMMIT coordinatorEpoch: 84
baseOffset: 3530931576 lastOffset: 3530931577 count: 0 baseSequence: 0 lastSequence: 1 producerId: 3007 producerEpoch: 2516 partitionLeaderEpoch: 94 isTransactional: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; isControl: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; position: 139 CreateTime: 1556161832997 size: 61 magic: 2 compresscodec: NONE crc: 3760382141 isvalid: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
baseOffset: 3530931578 lastOffset: 3530931579 count: 0 baseSequence: 0 lastSequence: 1 producerId: 1004 producerEpoch: 2576 partitionLeaderEpoch: 94 isTransactional: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; isControl: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; position: 200 CreateTime: 1556161832998 size: 61 magic: 2 compresscodec: NONE crc: 3285369041 isvalid: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
baseOffset: 3530931580 lastOffset: 3530931581 count: 0 baseSequence: 0 lastSequence: 1 producerId: 1005 producerEpoch: 2545 partitionLeaderEpoch: 94 isTransactional: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; isControl: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; position: 261 CreateTime: 1556161832998 size: 61 magic: 2 compresscodec: NONE crc: 1698037918 isvalid: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
baseOffset: 3530931582 lastOffset: 3530931583 count: 0 baseSequence: 0 lastSequence: 1 producerId: 3003 producerEpoch: 2529 partitionLeaderEpoch: 94 isTransactional: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; isControl: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; position: 322 CreateTime: 1556161832998 size: 61 magic: 2 compresscodec: NONE crc: 3446788505 isvalid: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
baseOffset: 3530931584 lastOffset: 3530931585 count: 0 baseSequence: 0 lastSequence: 1 producerId: 3001 producerEpoch: 2486 partitionLeaderEpoch: 94 isTransactional: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; isControl: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; position: 383 CreateTime: 1556161832998 size: 61 magic: 2 compresscodec: NONE crc: 2245471394 isvalid: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
baseOffset: 3530931586 lastOffset: 3530931587 count: 0 baseSequence: 0 lastSequence: 1 producerId: 3006 producerEpoch: 2503 partitionLeaderEpoch: 94 isTransactional: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; isControl: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; position: 444 CreateTime: 1556161832999 size: 61 magic: 2 compresscodec: NONE crc: 1819109301 isvalid: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
baseOffset: 3530931588 lastOffset: 3530931588 count: 1 baseSequence: -1 lastSequence: -1 producerId: 3007 producerEpoch: 2516 partitionLeaderEpoch: 94 isTransactional: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; isControl: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; position: 505 CreateTime: 1556161833001 size: 78 magic: 2 compresscodec: NONE crc: 2403915653 isvalid: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
| offset: 3530931588 CreateTime: 1556161833001 keysize: 4 valuesize: 6 sequence: -1 headerKeys: [] endTxnMarker: COMMIT coordinatorEpoch: 95
baseOffset: 3530931589 lastOffset: 3530931589 count: 1 baseSequence: -1 lastSequence: -1 producerId: 3003 producerEpoch: 2529 partitionLeaderEpoch: 94 isTransactional: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; isControl: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; position: 583 CreateTime: 1556161833004 size: 78 magic: 2 compresscodec: NONE crc: 4184380477 isvalid: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
| offset: 3530931589 CreateTime: 1556161833004 keysize: 4 valuesize: 6 sequence: -1 headerKeys: [] endTxnMarker: COMMIT coordinatorEpoch: 95

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Is this intended? If so will all compact topic grow unlimited in the end?&lt;/p&gt;</comment>
                            <comment id="16836811" author="hachikuji" created="Fri, 10 May 2019 00:45:31 +0000"  >&lt;p&gt;Thanks for the additional information. This is looking like a bug to me. The cleaner will leave around empty batches in order to preserve producer state, but these should eventually be cleaned as long as there are newer entries for the same producerIds. That doesn&apos;t appear to be working correctly though. I will investigate further.&lt;/p&gt;</comment>
                            <comment id="16837653" author="guozhang" created="Fri, 10 May 2019 22:15:10 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=boquan&quot; class=&quot;user-hover&quot; rel=&quot;boquan&quot;&gt;boquan&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=weichu&quot; class=&quot;user-hover&quot; rel=&quot;weichu&quot;&gt;weichu&lt;/a&gt; Thanks for reporting this issue. Jason and I have talked about this issue and Jason has proposed a solution which we&apos;d try to get in to the upcoming 2.3.0 release.&lt;/p&gt;</comment>
                            <comment id="16837664" author="githubbot" created="Fri, 10 May 2019 22:26:32 +0000"  >&lt;p&gt;hachikuji commented on pull request #6715: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-8335&quot; title=&quot;Log cleaner skips Transactional mark and batch record, causing unlimited growth of __consumer_offsets&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-8335&quot;&gt;&lt;del&gt;KAFKA-8335&lt;/del&gt;&lt;/a&gt;; Clean empty batches when sequence numbers are reused&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/6715&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/6715&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   The log cleaner attempts to preserve the last entry for each producerId in order to ensure that sequence/epoch state is not lost. The current validation checks only the last sequence number for each producerId in order to decide whether a batch should be retained. There are two problems with this:&lt;/p&gt;

&lt;p&gt;   1. Sequence numbers are not unique alone. It is the tuple of sequence number and epoch which is uniquely defined.&lt;br/&gt;
   2. The group coordinator always writes batches beginning with sequence number 0, which means there could be many batches which have the same sequence number.&lt;/p&gt;

&lt;p&gt;   The complete fix for the second issue is probably to do the proper sequence number bookkeeping in the coordinator. For now, I have left the coordinator implementation unchanged and changed the cleaner logic to use the last offset written by a producer instead of the last sequence number. &lt;/p&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on to GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16838636" author="githubbot" created="Mon, 13 May 2019 15:48:00 +0000"  >&lt;p&gt;hachikuji commented on pull request #6715: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-8335&quot; title=&quot;Log cleaner skips Transactional mark and batch record, causing unlimited growth of __consumer_offsets&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-8335&quot;&gt;&lt;del&gt;KAFKA-8335&lt;/del&gt;&lt;/a&gt;; Clean empty batches when sequence numbers are reused&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/6715&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/6715&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on to GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16866665" author="francisco.juan" created="Tue, 18 Jun 2019 14:45:00 +0000"  >&lt;p&gt;Hello, we have recently updated a Kafka cluster with this same problem from version 1.1 to version 2.2.1, without updating the&#160;inter.broker.protocol.version yet, still set as 1.1.&lt;/p&gt;

&lt;p&gt;We were expecting this update to reduce the size on some partitions of __consumer_offsets that keep growing. The observed behaviour is that there&apos;s still many segments with full of only &quot;isTransactional: true&quot; kind of messages.&lt;/p&gt;

&lt;p&gt;This is a sample of the kafka-dump-log.sh:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
/usr/kafka/bin/kafka-dump-log.sh --files 00000000004107011120.log --value-decoder-class &lt;span class=&quot;code-quote&quot;&gt;&quot;kafka.serializer.StringDecoder&quot;&lt;/span&gt; | head -n 20
Dumping 00000000004107011120.log
Starting offset: 4107011120
baseOffset: 4107011154 lastOffset: 4107011154 count: 1 baseSequence: -1 lastSequence: -1 producerId: 558010 producerEpoch: 0 partitionLeaderEpoch: 490 isTransactional: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; isControl: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; position: 0 CreateTime: 1556123964832 size: 78 magic: 2 compresscodec: NONE crc: 1007341472 isvalid: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
| offset: 4107011154 CreateTime: 1556123964832 keysize: 4 valuesize: 6 sequence: -1 headerKeys: [] endTxnMarker: COMMIT coordinatorEpoch: 84
baseOffset: 4107011178 lastOffset: 4107011178 count: 1 baseSequence: -1 lastSequence: -1 producerId: 559002 producerEpoch: 0 partitionLeaderEpoch: 490 isTransactional: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; isControl: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; position: 78 CreateTime: 1556123964895 size: 78 magic: 2 compresscodec: NONE crc: 470005994 isvalid: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
| offset: 4107011178 CreateTime: 1556123964895 keysize: 4 valuesize: 6 sequence: -1 headerKeys: [] endTxnMarker: COMMIT coordinatorEpoch: 84
baseOffset: 4107011180 lastOffset: 4107011180 count: 1 baseSequence: -1 lastSequence: -1 producerId: 559002 producerEpoch: 0 partitionLeaderEpoch: 490 isTransactional: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; isControl: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; position: 156 CreateTime: 1556123964916 size: 78 magic: 2 compresscodec: NONE crc: 681157535 isvalid: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
| offset: 4107011180 CreateTime: 1556123964916 keysize: 4 valuesize: 6 sequence: -1 headerKeys: [] endTxnMarker: COMMIT coordinatorEpoch: 84&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This command is executed on Jun 18th.&lt;/p&gt;

&lt;p&gt;The `offsets.retention.minutes` is set to 40 days.&lt;/p&gt;

&lt;p&gt;The timestamps shown on this dump are way beyond the retention period.&lt;/p&gt;

&lt;p&gt;The LogCleaner DEBUG log is next:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
DEBUG Finding range of cleanable offsets &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; log=__consumer_offsets-6 topicPartition=__consumer_offsets-6. Last clean offset=Some(5006278217) now=1560855479531 =&amp;gt; firstDirtyOffset=5006278217 firstUncleanableOffset=5069232666 activeSegment.baseOffset=5069232666 (kafka.log.LogCleanerManager$)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Offsets shown on the dump are not on the active segment and are way below the firstUncleanbleOffset&lt;/p&gt;</comment>
                            <comment id="16867181" author="boquan" created="Wed, 19 Jun 2019 02:50:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=francisco.juan&quot; class=&quot;user-hover&quot; rel=&quot;francisco.juan&quot;&gt;francisco.juan&lt;/a&gt; This patch worked for us. &lt;br/&gt;
I have a suspicion on why this is still happening to you, you may find some offset in &lt;tt&gt;/your/kafka/data/directory/cleaner-offset-checkpoint&lt;/tt&gt; that is corresponding to a recent offset (5006278217 in your case). This is invalid because the log before that offset is not really cleaned up due to this bug.&lt;br/&gt;
However, since the LogCleanerManager yields (5069232666,5069232666) as dirty portion, which may be extremely small compare to the log size, log cleaner won&apos;t treat it as &apos;filthiest&apos;, also I doubt the dirty ratio will be over 50%, which is the default min.cleanable.dirty.ratio.&lt;/p&gt;

&lt;p&gt;To solve it, you can either stop the server and manually clean up cleaner-offset-checkpoint, or temporarily apply a rentention.ms that is longer enough (so you won&apos;t end up clean up any needed consumer offset) to help chop off a large part of old segment, thus increase the dirty ratio so this topic partition can be picked up by log cleaner.&lt;/p&gt;

&lt;p&gt;FYI we once configured retention.ms=1209600000 (two weeks) and min.cleanable.dirty.ratio=0.2&lt;/p&gt;</comment>
                            <comment id="16868545" author="francisco.juan" created="Thu, 20 Jun 2019 13:56:56 +0000"  >&lt;p&gt;Hi Boquan&lt;/p&gt;

&lt;p&gt;Cleaning up&#160;the &lt;tt&gt;cleaner-offset-checkpoint&lt;/tt&gt; seems to be solving the issue.&lt;/p&gt;

&lt;p&gt;Thanks a lot for the quick reply!&lt;/p&gt;</comment>
                            <comment id="16870892" author="francisco.juan" created="Mon, 24 Jun 2019 07:44:24 +0000"  >&lt;p&gt;Hello &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=boquan&quot; class=&quot;user-hover&quot; rel=&quot;boquan&quot;&gt;boquan&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I have applied your suggestion but seems to not be able to solve the issue for 2 out of 50 partitions.&lt;/p&gt;

&lt;p&gt;The biggest offender in my case would be partition 6 of __consumer_offsets which is now at 22GB.&lt;/p&gt;

&lt;p&gt;This is what the new state after I have cleaned up the cleaner-offset-checkpoint:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[2019-06-24 06:18:05,968] DEBUG Finding range of cleanable offsets &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; log=__consumer_offsets-6 topicPartition=__consumer_offsets-6. Last clean offset=Some(0) now=1561357085930 =&amp;gt; firstDirtyOffset=0 firstUncleanableOffset=5149534913 activeSegment.baseOffset=5149534913 (kafka.log.LogCleanerManager$)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and this is the outcome of the cleaner:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[2019-06-24 06:25:48,969] INFO [kafka-log-cleaner-thread-0]: Log cleaner thread 0 cleaned log __consumer_offsets-6 (dirty section = [0, 0]) 25,096.6 MB of log processed in 463.0 seconds (54.2 MB/sec). Indexed 25,096.6 MB in 177.6 seconds (141.3 Mb/sec, 38.4% of total time) Buffer utilization: 0.0% Cleaned 25,096.6 MB in 285.4 seconds (87.9 Mb/sec, 61.6% of total time) Start size: 25,096.6 MB (313,976,723 messages) End size: 21,674.0 MB (291,368,805 messages) 13.6% size reduction (7.2% fewer messages) (kafka.log.LogCleaner)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The partition currently has 226 log files and takes 22G of disk space.&lt;/p&gt;

&lt;p&gt;When sampling one of the earliest file in the partition, these are my results:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$&amp;gt; kafka-dump-log.sh --files 00000000004114035438.log | head -n 5
Dumping 00000000004114035438.log
Starting offset: 4114035438
baseOffset: 4114035438 lastOffset: 4114035438 count: 1 baseSequence: -1 lastSequence: -1 producerId: 547022 producerEpoch: 0 partitionLeaderEpoch: 490 isTransactional: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; isControl: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; position: 0 CreateTime: 1556176906520 size: 78 magic: 2 compresscodec: NONE crc: 3444550803 isvalid: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
baseOffset: 4114035439 lastOffset: 4114035439 count: 1 baseSequence: -1 lastSequence: -1 producerId: 551003 producerEpoch: 0 partitionLeaderEpoch: 490 isTransactional: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; isControl: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; position: 78 CreateTime: 1556176906524 size: 78 magic: 2 compresscodec: NONE crc: 517398751 isvalid: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
baseOffset: 4114035442 lastOffset: 4114035442 count: 1 baseSequence: -1 lastSequence: -1 producerId: 556020 producerEpoch: 0 partitionLeaderEpoch: 490 isTransactional: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; isControl: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; position: 156 CreateTime: 1556176906560 size: 78 magic: 2 compresscodec: NONE crc: 174729981 isvalid: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
$&amp;gt; kafka-dump-log.sh --files 00000000004114035438.log | grep &lt;span class=&quot;code-quote&quot;&gt;&quot;isTransactional: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt; | wc -l
1340521
$&amp;gt; kafka-dump-log.sh --files 00000000004114035438.log | grep -v &lt;span class=&quot;code-quote&quot;&gt;&quot;isTransactional: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt; | wc -l
2&#160;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The timestamp shown here is from &lt;tt&gt;Thu Apr 25 07:21:46 UTC 2019&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;What I think are relevant settings for my cluster are:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;kafka cluster version: 2.2.1&lt;/li&gt;
	&lt;li&gt;inter.broker.protocol.version: 1.1&lt;/li&gt;
	&lt;li&gt;offsets.retention.minutes=20160&lt;/li&gt;
	&lt;li&gt;__consumer_offsets settings: segment.bytes=104857600,cleanup.policy=compact&lt;/li&gt;
	&lt;li&gt;I&apos;ve applied temporarily the suggestion from above:&#160;&#160;retention.ms=1209600000 (two weeks) and min.cleanable.dirty.ratio=0.2&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;What additional information could be useful to try and dig up the issue?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="16870907" author="weichu" created="Mon, 24 Jun 2019 08:06:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=francisco.juan&quot; class=&quot;user-hover&quot; rel=&quot;francisco.juan&quot;&gt;francisco.juan&lt;/a&gt; On our cluster, after upgrading, the logs shrunk but still has several gigs for the biggest partition.&lt;br/&gt;
The contents of remained logs are quite the same as what you&apos;ve posted.&lt;/p&gt;

&lt;p&gt;From reading &lt;a href=&quot;https://github.com/apache/kafka/pull/6715&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/6715&lt;/a&gt; description, there seems to be 2 different causes of empty batch to be retained.&lt;br/&gt;
The first was addressed by the PR but the second was not. Could that be the reason why __consumer_offsets is still big? &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16872013" author="francisco.juan" created="Tue, 25 Jun 2019 05:18:56 +0000"  >&lt;p&gt;I&apos;m seeing this problem only in some partitions, check below partitions sorted by disk size:&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
| Topic              | P  | Disk (MB) |
| __consumer_offsets | 6  | 23599     |
| __consumer_offsets | 8  | 12285     |
| __consumer_offsets | 43 | 4725   &#160;  |
| __consumer_offsets | 23 | 875.86    |
| __consumer_offsets | 31 | 443.35    |
| __consumer_offsets | 16 | 433.02    |
| __consumer_offsets | 18 | 418.52    |
| __consumer_offsets | 11 | 385.40    |
| __consumer_offsets | 14 | 308.03    |
| __consumer_offsets | 47 | 268.80    |
| __consumer_offsets | 13 | 254.77    |
| __consumer_offsets | 29 | 250.02    |
| __consumer_offsets | 30 | 233.38    |
| __consumer_offsets | 12 | 148.13    |
| __consumer_offsets | 46 | 116.77    |
| __consumer_offsets | 26 | 114.36    |
| __consumer_offsets | 3  | 101.09    |
...
| __consumer_offsets | 24 | 7.09      |&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Our topic is using 50 partitions.&lt;/p&gt;</comment>
                            <comment id="17360281" author="victorgp" created="Wed, 9 Jun 2021 18:47:28 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=francisco.juan&quot; class=&quot;user-hover&quot; rel=&quot;francisco.juan&quot;&gt;francisco.juan&lt;/a&gt; we are having the exact same problem as you had. Did you find a way to fix this? We upgraded to 2.3 but like in your case, we have a few big partitions with tons of &quot;isTransactional: true&quot; messages.&lt;/p&gt;

&lt;p&gt;Any help would be really appreciated. Thanks&lt;/p&gt;</comment>
                            <comment id="17360656" author="francisco.juan" created="Thu, 10 Jun 2021 08:37:20 +0000"  >&lt;p&gt;We solved the issue by updating to version 2.5.1, then the &lt;a href=&quot;https://kafka.apache.org/documentation/#brokerconfigs_offsets.retention.minutes&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;offsets.retention.minutes&lt;/a&gt; kicked in and the problem disappeared.&#160;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12968257" name="seg_april_25.zip" size="20911160" author="boquan" created="Thu, 9 May 2019 04:28:28 +0000"/>
                            <attachment id="12968255" name="segment.zip" size="10677730" author="weichu" created="Thu, 9 May 2019 03:27:57 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 22 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z02hpc:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>