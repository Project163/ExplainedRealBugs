<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:43:47 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-2308] New producer + Snappy face un-compression errors after broker restart</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-2308</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Looks like the new producer, when used with Snappy, following a broker restart is sending messages the brokers can&apos;t decompress. This issue was discussed at few mailing lists thread, but I don&apos;t think we ever resolved it.&lt;/p&gt;

&lt;p&gt;I can reproduce with trunk and Snappy 1.1.1.7. &lt;/p&gt;

&lt;p&gt;To reproduce:&lt;br/&gt;
1. Start 3 brokers&lt;br/&gt;
2. Create a topic with 3 partitions and 3 replicas each.&lt;br/&gt;
2. Start performance producer with --new-producer --compression-codec 2 (and set the number of messages to fairly high, to give you time. I went with 10M)&lt;br/&gt;
3. Bounce one of the brokers&lt;br/&gt;
4. The log of one of the surviving nodes should contain errors like:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;2015-07-02 13:45:59,300 ERROR kafka.server.ReplicaManager: [Replica Manager on Broker 66]: Error processing append operation on partition [t3,0]
kafka.common.KafkaException:
        at kafka.message.ByteBufferMessageSet$$anon$1.makeNext(ByteBufferMessageSet.scala:94)
        at kafka.message.ByteBufferMessageSet$$anon$1.makeNext(ByteBufferMessageSet.scala:64)
        at kafka.utils.IteratorTemplate.maybeComputeNext(IteratorTemplate.scala:66)
        at kafka.utils.IteratorTemplate.hasNext(IteratorTemplate.scala:58)
        at kafka.message.ByteBufferMessageSet$$anon$2.innerDone(ByteBufferMessageSet.scala:177)
        at kafka.message.ByteBufferMessageSet$$anon$2.makeNext(ByteBufferMessageSet.scala:218)
        at kafka.message.ByteBufferMessageSet$$anon$2.makeNext(ByteBufferMessageSet.scala:173)
        at kafka.utils.IteratorTemplate.maybeComputeNext(IteratorTemplate.scala:66)
        at kafka.utils.IteratorTemplate.hasNext(IteratorTemplate.scala:58)
        at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
        at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
        at scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:48)
        at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
        at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
        at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:273)
        at scala.collection.AbstractIterator.to(Iterator.scala:1157)
        at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:265)
        at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
        at kafka.message.ByteBufferMessageSet.validateMessagesAndAssignOffsets(ByteBufferMessageSet.scala:267)
        at kafka.log.Log.liftedTree1$1(Log.scala:327)
        at kafka.log.Log.append(Log.scala:326)
        at kafka.cluster.Partition$$anonfun$appendMessagesToLeader$1.apply(Partition.scala:423)
        at kafka.cluster.Partition$$anonfun$appendMessagesToLeader$1.apply(Partition.scala:409)
        at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
        at kafka.utils.CoreUtils$.inReadLock(CoreUtils.scala:268)
        at kafka.cluster.Partition.appendMessagesToLeader(Partition.scala:409)
        at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$2.apply(ReplicaManager.scala:365)
        at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$2.apply(ReplicaManager.scala:350)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
        at scala.collection.mutable.HashTable$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreachEntry(HashTable.scala:226)
        at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)
        at scala.collection.mutable.HashMap.foreach(HashMap.scala:98)
        at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;map(TraversableLike.scala:244)
        at scala.collection.AbstractTraversable.map(Traversable.scala:105)
        at kafka.server.ReplicaManager.appendToLocalLog(ReplicaManager.scala:350)
        at kafka.server.ReplicaManager.appendMessages(ReplicaManager.scala:286)
        at kafka.server.KafkaApis.handleProducerRequest(KafkaApis.scala:270)
        at kafka.server.KafkaApis.handle(KafkaApis.scala:57)
        at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: java.io.IOException: PARSING_ERROR(2)
        at org.xerial.snappy.SnappyNative.throw_error(SnappyNative.java:84)
        at org.xerial.snappy.SnappyNative.uncompressedLength(Native Method)
        at org.xerial.snappy.Snappy.uncompressedLength(Snappy.java:594)
        at org.xerial.snappy.SnappyInputStream.hasNextChunk(SnappyInputStream.java:358)
        at org.xerial.snappy.SnappyInputStream.rawRead(SnappyInputStream.java:167)
        at org.xerial.snappy.SnappyInputStream.read(SnappyInputStream.java:150)
        at java.io.DataInputStream.readFully(DataInputStream.java:195)
        at kafka.message.ByteBufferMessageSet$$anon$1.makeNext(ByteBufferMessageSet.scala:82)
        ... 43 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The client has the following messages:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[2015-07-02 13:46:00,478] ERROR Error when sending message to topic t3 with key: 4 bytes, value: 100 bytes with error: The server experienced an unexpected error when processing the request (org.apache.kafka.clients.producer.internals.ErrorLoggingCallback)
java: target/snappy-1.1.1/snappy.cc:423: &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;* snappy::internal::CompressFragment(&lt;span class=&quot;code-keyword&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;*, size_t, &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;*, snappy::uint16*, &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;): Assertion `0 == memcmp(base, candidate, matched)&apos; failed.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12842442">KAFKA-2308</key>
            <summary>New producer + Snappy face un-compression errors after broker restart</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gwenshap">Gwen Shapira</assignee>
                                    <reporter username="gwenshap">Gwen Shapira</reporter>
                        <labels>
                    </labels>
                <created>Thu, 2 Jul 2015 21:02:30 +0000</created>
                <updated>Thu, 3 Dec 2015 04:07:03 +0000</updated>
                            <resolved>Wed, 8 Jul 2015 16:58:01 +0000</resolved>
                                                    <fixVersion>0.8.2.2</fixVersion>
                    <fixVersion>0.9.0.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="14617096" author="gwenshap" created="Tue, 7 Jul 2015 18:03:56 +0000"  >&lt;p&gt;I kinda know why it happens, a patch will take a bit of time since I can&apos;t reproduce the error in a unit test (although it reproduces nicely in a test environment). I&apos;ll put a preliminary patch without unit tests up in a sec, so people suffering from this issue can validate. Here&apos;s what I found:&lt;/p&gt;

&lt;p&gt;When we get a retriable error in the producer (NETWORK_EXCEPTION for instance), the current record batch gets put first in its topic-partition message batch queue by completeBatch().&lt;br/&gt;
Next time Sender runs, it drains the queue and one of the things it does is to take the first batch from the queue and close() it. But if a batch was re-queued, it was already closed. Calling close() twice should be safe, and for un-compressed messages, it is. However, for compressed messages the logic in close() is rather complex, and I believe closing a batch twice messes up the record. I can&apos;t tell exactly where the close() logic becomes unsafe, but there&apos;s really no need to close a batch twice. MemoryRecords.close() can check if it is writable before closing, and only close() the record if it is writable. This guarantees closing will happen just once. &lt;/p&gt;

&lt;p&gt;Fixing this resolved the problem on my system.&lt;/p&gt;
</comment>
                            <comment id="14617206" author="guozhang" created="Tue, 7 Jul 2015 19:10:08 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gwenshap&quot; class=&quot;user-hover&quot; rel=&quot;gwenshap&quot;&gt;gwenshap&lt;/a&gt; thanks for the findings. Yes for compressed message set the close call will trigger Compressor.close() which:&lt;/p&gt;

&lt;p&gt;1. close the compression input stream, which will likely write the left-over cached bytes to the underlying buffer.&lt;br/&gt;
2. set the wrapper message header accordingly, such as offset (as the number of compressed messages - 1), length, and crc.&lt;/p&gt;

&lt;p&gt;For the second step I think it should be OK to execute twice, plus if not then gzip should also have the similar issue; but it seems for the first step calling stream.close() multiple times on snappy may be problematic. To verify that we can write some simple test code:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;stream = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; org.xerial.snappy.SnappyOutputStream(buffer-size);
&lt;span class=&quot;code-comment&quot;&gt;// write some bytes to stream
&lt;/span&gt;stream.close();
stream.close(); &lt;span class=&quot;code-comment&quot;&gt;// again&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14617878" author="gwenshap" created="Wed, 8 Jul 2015 02:43:53 +0000"  >&lt;p&gt;Thanks for your comments, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Closing multiple times on Snappy is not an issue. Actually, even draining, requeueing and draining again is not an issue by itself.&lt;br/&gt;
That is, I&apos;m still unable to create a test that replicates this error, even though it reproduces nicely in a real cluster with the performance producer.&lt;/p&gt;

&lt;p&gt;I have a patch that I&apos;m fairly certain fixes the problem (although I cannot say why). I&apos;ll attach it here, because someone may need it, and continue digging into when and why does double-close corrupt messages.&lt;/p&gt;

&lt;p&gt;Here&apos;s a link to a test that should have caused an issue, but doesn&apos;t:&lt;br/&gt;
&lt;a href=&quot;https://gist.github.com/gwenshap/1ec9cb55d704a82477d8&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://gist.github.com/gwenshap/1ec9cb55d704a82477d8&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14617887" author="gwenshap" created="Wed, 8 Jul 2015 02:47:51 +0000"  >&lt;p&gt;Created reviewboard &lt;a href=&quot;https://reviews.apache.org/r/36290/diff/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.apache.org/r/36290/diff/&lt;/a&gt;&lt;br/&gt;
 against branch trunk&lt;/p&gt;</comment>
                            <comment id="14617949" author="gwenshap" created="Wed, 8 Jul 2015 04:26:30 +0000"  >&lt;p&gt;Actually, looks likely that it is Snappy (even though I can&apos;t reproduce):&lt;br/&gt;
&lt;a href=&quot;https://github.com/xerial/snappy-java/pull/108&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/xerial/snappy-java/pull/108&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Note that this is not in 1.1.1.7 (which we are using).&lt;/p&gt;

&lt;p&gt;I suggest pushing our simple work-around (since its simple and nothing bad can happen from only closing once).&lt;/p&gt;</comment>
                            <comment id="14618867" author="ewencp" created="Wed, 8 Jul 2015 16:25:28 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gwenshap&quot; class=&quot;user-hover&quot; rel=&quot;gwenshap&quot;&gt;gwenshap&lt;/a&gt; The test case you gave doesn&apos;t quite do enough to trigger the bug. It releases the same buffer twice, but doesn&apos;t reuse it. I think you&apos;d need to get the test to do something more like:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Fill first record batch (batch 1) with records and drain (causing buffer to be released).&lt;/li&gt;
	&lt;li&gt;At least start creating another batch (batch 2). This allocates the buffer to that batch.&lt;/li&gt;
	&lt;li&gt;Reenqueue batch 1 and drain (causing buffer to be released second time).&lt;/li&gt;
	&lt;li&gt;Continue enqueuing until it creates &lt;b&gt;another&lt;/b&gt; batch (batch 3), which allocates the buffer yet again.&lt;/li&gt;
	&lt;li&gt;Drain batches 2 and 3 and validate their contents.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14618873" author="gwenshap" created="Wed, 8 Jul 2015 16:29:18 +0000"  >&lt;p&gt;yes, I saw the Snappy test case too &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Since its a confirmed Snappy bug, I don&apos;t think we need a Kafka test-case. We can just protect that call, right?&lt;/p&gt;</comment>
                            <comment id="14618888" author="guozhang" created="Wed, 8 Jul 2015 16:38:46 +0000"  >&lt;p&gt;Agree, we do not need a test case inside Kafka code.&lt;/p&gt;</comment>
                            <comment id="14618901" author="gwenshap" created="Wed, 8 Jul 2015 16:43:56 +0000"  >&lt;p&gt;Was that a &quot;ship it&quot;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt;? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14618921" author="guozhang" created="Wed, 8 Jul 2015 16:55:08 +0000"  >&lt;p&gt;I was unit testing the patch while writing the last comment &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Just shipped it and committed to trunk.&lt;/p&gt;</comment>
                            <comment id="14618981" author="gwenshap" created="Wed, 8 Jul 2015 17:25:51 +0000"  >&lt;p&gt;Thanks &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15034439" author="allenxwang" created="Tue, 1 Dec 2015 19:39:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gwenshap&quot; class=&quot;user-hover&quot; rel=&quot;gwenshap&quot;&gt;gwenshap&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt; Is the fix in producer only? If I take 0.8.2.2 producer, do I also need to have broker/consumer upgraded to 0.8.2.2 or a later snappy version in order to avoid this bug? Currently our broker is on 0.8.2.1 and snappy 1.1.1.6. &lt;/p&gt;</comment>
                            <comment id="15034497" author="guozhang" created="Tue, 1 Dec 2015 20:14:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=allenxwang&quot; class=&quot;user-hover&quot; rel=&quot;allenxwang&quot;&gt;allenxwang&lt;/a&gt; This bug should be only in the producer due to its use patterns of snappy.&lt;/p&gt;</comment>
                            <comment id="15037210" author="githubbot" created="Thu, 3 Dec 2015 04:07:03 +0000"  >&lt;p&gt;Github user darionyaphet commented on the pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/storm/pull/801#issuecomment-161509467&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/storm/pull/801#issuecomment-161509467&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Hi @knusbaum @revans2 I read `Kafka Release Notes Version 0.8.2.2`  and found a bug fixed (&lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-2308&quot; title=&quot;New producer + Snappy face un-compression errors after broker restart&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-2308&quot;&gt;&lt;del&gt;KAFKA-2308&lt;/del&gt;&lt;/a&gt;(&lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-2308&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/KAFKA-2308&lt;/a&gt;)) about New producer and Snappy un-compression errors when Kafka Broker restart . So I think this is maybe useful .&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12744120" name="KAFKA-2308.patch" size="1182" author="gwenshap" created="Wed, 8 Jul 2015 02:47:51 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 50 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2gt9b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>