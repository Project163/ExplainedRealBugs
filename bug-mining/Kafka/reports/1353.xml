<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:59:07 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-3959] KIP-115: __consumer_offsets wrong number of replicas at startup</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-3959</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;When creating a stack of 3 kafka brokers, the consumer is starting faster than kafka nodes and when trying to read a topic, only one kafka node is available.&lt;br/&gt;
So the __consumer_offsets is created with a replication factor set to 1 (instead of configured 3) :&lt;/p&gt;

&lt;p&gt;offsets.topic.replication.factor=3&lt;br/&gt;
default.replication.factor=3&lt;br/&gt;
min.insync.replicas=2&lt;/p&gt;

&lt;p&gt;Then, other kafka nodes go up and we have exceptions because the replicas # for __consumer_offsets is 1 and min insync is 2. So exceptions are thrown.&lt;/p&gt;

&lt;p&gt;What I missed is : Why the __consumer_offsets is created with replication to 1 (when 1 broker is running) whereas in server.properties it is set to 3 ?&lt;/p&gt;

&lt;p&gt;To reproduce : &lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Prepare 3 kafka nodes with the 3 lines above added to servers.properties.&lt;/li&gt;
	&lt;li&gt;Run one kafka,&lt;/li&gt;
	&lt;li&gt;Run one consumer (the __consumer_offsets is created with replicas =1)&lt;/li&gt;
	&lt;li&gt;Run 2 more kafka nodes&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment>Brokers of 3 kafka nodes running Red Hat Enterprise Linux Server release 7.2 (Maipo)</environment>
        <key id="12989057">KAFKA-3959</key>
            <summary>KIP-115: __consumer_offsets wrong number of replicas at startup</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="onurkaraman">Onur Karaman</assignee>
                                    <reporter username="hurtauda">Alban Hurtaud</reporter>
                        <labels>
                            <label>needs-kip</label>
                            <label>reliability</label>
                    </labels>
                <created>Wed, 13 Jul 2016 09:12:48 +0000</created>
                <updated>Fri, 12 May 2017 04:03:20 +0000</updated>
                            <resolved>Tue, 28 Feb 2017 03:00:36 +0000</resolved>
                                    <version>0.9.0.1</version>
                    <version>0.10.0.0</version>
                    <version>0.10.0.1</version>
                    <version>0.10.0.2</version>
                    <version>0.10.1.0</version>
                    <version>0.10.1.1</version>
                    <version>0.10.1.2</version>
                                    <fixVersion>0.11.0.0</fixVersion>
                                    <component>consumer</component>
                    <component>offset manager</component>
                    <component>replication</component>
                        <due></due>
                            <votes>4</votes>
                                    <watches>14</watches>
                                                                                                                <comments>
                            <comment id="15418751" author="omkreddy" created="Fri, 12 Aug 2016 12:19:30 +0000"  >&lt;p&gt;looks like this is done on purpose.  While creating  __consumer_offsets topic, it takes minimum of (available brokers, offsets.topic.replication) as replication factor.  Since this important internal topic, we may be creating with available replications.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/server/KafkaApis.scala#L655&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/server/KafkaApis.scala#L655&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;but __consumer_offsets append still will fail complaining  available replicas less than min.insync.replicas.&lt;/p&gt;

&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt; &lt;/p&gt;</comment>
                            <comment id="15418819" author="ijuma" created="Fri, 12 Aug 2016 13:24:21 +0000"  >&lt;p&gt;The current behaviour &quot;minimum of (available brokers, offsets.topic.replication) as replication factor&quot; doesn&apos;t seem like a great idea. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt;, do you have the context?&lt;/p&gt;</comment>
                            <comment id="15419057" author="onurkaraman" created="Fri, 12 Aug 2016 16:01:24 +0000"  >&lt;p&gt;Perfect timing! &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=toddpalino&quot; class=&quot;user-hover&quot; rel=&quot;toddpalino&quot;&gt;toddpalino&lt;/a&gt; and I hit this behavior again on Wednesday after reset one of our test clusters. The current behavior came from &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1864&quot; title=&quot;Revisit defaults for the internal offsets topic&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1864&quot;&gt;&lt;del&gt;KAFKA-1864&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The current behavior is pretty surprising when you have clients or tooling running as the cluster is getting setup. Even if your cluster ends up being huge, you&apos;ll find out much later that __consumer_offsets was setup with no replication.&lt;/p&gt;

&lt;p&gt;I think the right behavior should be for __consumer_offsets topic creation to fail with &lt;tt&gt;GROUP_COORDINATOR_NOT_AVAILABLE&lt;/tt&gt; until there are at least &lt;tt&gt;KafkaConfig.offsetsTopicReplicationFactor&lt;/tt&gt; brokers up in the cluster.&lt;/p&gt;</comment>
                            <comment id="15419066" author="wushujames" created="Fri, 12 Aug 2016 16:10:21 +0000"  >&lt;p&gt;You mentioned&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;but __consumer_offsets append still will fail complaining  replicas less than min.insync.replicas.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We&apos;ve had clusters with single replica __consumer_offsets but we have definitely been able to save offsets to them, even though they were less than min.isr.&lt;/p&gt;

&lt;p&gt;Is min.isr set on the __consumer_offsets topic? I&apos;ve never checked. &lt;/p&gt;</comment>
                            <comment id="15419108" author="ijuma" created="Fri, 12 Aug 2016 16:50:38 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=onurkaraman&quot; class=&quot;user-hover&quot; rel=&quot;onurkaraman&quot;&gt;onurkaraman&lt;/a&gt;, I would agree. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt; proposed something similar in &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1864?focusedCommentId=14335345&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14335345&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/KAFKA-1864?focusedCommentId=14335345&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14335345&lt;/a&gt;. Thoughts &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="15419124" author="onurkaraman" created="Fri, 12 Aug 2016 16:58:11 +0000"  >&lt;p&gt;Another options is to offload the responsibility of __consumer_offsets topic creation to the controller. We can do the check in KafkaController.onBrokerStartup.&lt;/p&gt;</comment>
                            <comment id="15419140" author="omkreddy" created="Fri, 12 Aug 2016 17:07:48 +0000"  >&lt;p&gt;Yes,  min.insync.replicas  applicable to internal topics also. We can override with topic level configs&lt;/p&gt;</comment>
                            <comment id="15419365" author="toddpalino" created="Fri, 12 Aug 2016 19:57:29 +0000"  >&lt;p&gt;Agree with Onur 100% here. We&apos;ve been running into this a lot lately, and we never know about it until we do a rolling restart of the cluster and consumers break when the topic goes offline.&lt;/p&gt;</comment>
                            <comment id="15419441" author="onurkaraman" created="Fri, 12 Aug 2016 20:42:10 +0000"  >&lt;p&gt;btw I can pick this one up once we agree on the fix.&lt;/p&gt;</comment>
                            <comment id="15419471" author="granthenke" created="Fri, 12 Aug 2016 21:00:41 +0000"  >&lt;p&gt;I would like to present an alternative option. This problem exists with any topic created using default.replication.factor &amp;gt; 1 as well. That prevents using 2 or 3 as the configuration default because we want to support single nodes clusters without changing the defaults. &lt;/p&gt;

&lt;p&gt;Instead of preventing topics from being created with a low replication factor (unless min.isr is set). Instead it would be really nice if we tracked a &quot;target replication factor&quot; in the topic metadata. This is an improvement over assuming the target replication factor based on the actual replicas as is done today and can actually result in a more accurate under replicated count. &lt;/p&gt;

&lt;p&gt;This change would also help support any ability to automatically maintain the desired replication factor as nodes are started, stopped, etc. Some related KIPs for that are:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-73+Replication+Quotas&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;KIP-73 Replication Quotas&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-46%3A+Self+Healing+Kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;KIP-46: Self Healing Kafka&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Would that be a viable option?&lt;/p&gt;</comment>
                            <comment id="15419587" author="onurkaraman" created="Fri, 12 Aug 2016 22:08:46 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=granthenke&quot; class=&quot;user-hover&quot; rel=&quot;granthenke&quot;&gt;granthenke&lt;/a&gt; maybe in the long term. But honestly I would prefer the simple, quick fix for this edge case behavior without complicating the conversation with KIP-73 and KIP-46. To me, the cluster not meeting replication factor requirements on an internal topic is another way of saying the cluster isn&apos;t fully setup yet.&lt;/p&gt;</comment>
                            <comment id="15419992" author="granthenke" created="Sat, 13 Aug 2016 16:38:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=onurkaraman&quot; class=&quot;user-hover&quot; rel=&quot;onurkaraman&quot;&gt;onurkaraman&lt;/a&gt; I understand the need for a quick fix and that automatically maintaining a given replication factor will take some time to implement. I wasn&apos;t proposing all of that KIP work for this fix. I was thinking just changing the tracked metadata to contain the &quot;target replication factor&quot; and leveraging it to report under replicated partitions would provide an admin enough to diagnose and fix the problem quickly. I referenced the KIPs to show that the change also supports an ultimate fix down the road.&lt;/p&gt;

&lt;p&gt;I am worried about __consumer_offsets topic creation failing with GROUP_COORDINATOR_NOT_AVAILABLE until there is at least KafkaConfig.offsetsTopicReplicationFactor brokers because the default for KafkaConfig.offsetsTopicReplicationFactor is 3. That change means any cluster with &amp;lt; 3 brokers will need to change defaults before starting. Including all of the embedded clusters in our tests and likely many users and frameworks development clusters and tests as well. &lt;/p&gt;</comment>
                            <comment id="15420091" author="toddpalino" created="Sat, 13 Aug 2016 21:44:54 +0000"  >&lt;p&gt;If that&apos;s the case, then the default should be set to 1. As least having that as the default, and returning an error if the RF cannot be satisfied, is a reasonable and expected outcome. But having it set up to not enforce the configured RF leads to unintended behavior, even if it&apos;s documented here.&lt;/p&gt;</comment>
                            <comment id="15662738" author="ewencp" created="Mon, 14 Nov 2016 04:36:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=granthenke&quot; class=&quot;user-hover&quot; rel=&quot;granthenke&quot;&gt;granthenke&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=onurkaraman&quot; class=&quot;user-hover&quot; rel=&quot;onurkaraman&quot;&gt;onurkaraman&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=toddpalino&quot; class=&quot;user-hover&quot; rel=&quot;toddpalino&quot;&gt;toddpalino&lt;/a&gt; Any more thoughts on this? I think the main use case for handling &amp;lt; 3 brokers by default is when we start up a &quot;cluster&quot; locally for test purposes. Any real use case that wanted a lower replication factor could set it explicitly. This is pretty important and we don&apos;t really want to have users jump through hoops to do so; that said, a dramatic warning wouldn&apos;t be the end of the world. Maybe even some combination of a low setting plus a setting that gives unsafe warnings but allows unsafely low replication factors for this topic?&lt;/p&gt;</comment>
                            <comment id="15668010" author="toddpalino" created="Tue, 15 Nov 2016 19:24:09 +0000"  >&lt;p&gt;As noted, I just want the config enforced. If RF=3 is configured, that&apos;s what we should get. If you need RF=1 for testing, or for specific use cases, set it. Even make the default 1 if that&apos;s really what we want. But if I explicitly set RF=3, that&apos;s what I should get. And if it causes errors, and I&apos;ve explicitly set it, that&apos;s on me as the user.&lt;/p&gt;</comment>
                            <comment id="15698985" author="ewencp" created="Sun, 27 Nov 2016 03:54:38 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=toddpalino&quot; class=&quot;user-hover&quot; rel=&quot;toddpalino&quot;&gt;toddpalino&lt;/a&gt; That&apos;s fair, I think the tension is between trivial quickstart mode working and production settings. Then again, there are other things (even really simple things like the log.dirs) which presumably will differ between the two. Maybe the fix here is to both enforce it and update all quickstarts to use a config/quickstart-server.properties that has offsets.topic.replication.factor=1 and default.replication.factor=1.&lt;/p&gt;</comment>
                            <comment id="15700662" author="hachikuji" created="Mon, 28 Nov 2016 01:45:48 +0000"  >&lt;p&gt;Could we leave the default at RF=3, but override it to RF=1 in config/server.properties (with some comments for why you shouldn&apos;t use that setting in practice). People should already expect to override some settings anyway (unless they want their data stored in /tmp) and this would ensure that anyone who is already maintaining their own config will continue to see the same behavior.&lt;/p&gt;</comment>
                            <comment id="15700935" author="onurkaraman" created="Mon, 28 Nov 2016 05:10:55 +0000"  >&lt;p&gt;+1. I was thinking about this approach too (assuming &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt; is also supporting the enforcement of &quot;offsets.topic.replication.factor&quot;).&lt;/p&gt;

&lt;p&gt;As &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt; said, the /tmp log.dirs does give the impression that config/server.properties was for quickstart anyway, so I think this is fine.&lt;/p&gt;</comment>
                            <comment id="15700938" author="toddpalino" created="Mon, 28 Nov 2016 05:12:32 +0000"  >&lt;p&gt;+1 as well. I think keeping the config/server.properties file as a quickstart that gets you going with a standalone broker is a good plan.&lt;/p&gt;</comment>
                            <comment id="15700945" author="onurkaraman" created="Mon, 28 Nov 2016 05:17:18 +0000"  >&lt;p&gt;Awesome. I think we&apos;re in agreement? I can implement it if nobody&apos;s done it yet.&lt;/p&gt;</comment>
                            <comment id="15701044" author="githubbot" created="Mon, 28 Nov 2016 06:09:08 +0000"  >&lt;p&gt;GitHub user onurkaraman opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/2177&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/2177&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3959&quot; title=&quot;KIP-115: __consumer_offsets wrong number of replicas at startup&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3959&quot;&gt;&lt;del&gt;KAFKA-3959&lt;/del&gt;&lt;/a&gt;: enforce offsets.topic.replication.factor&lt;/p&gt;

&lt;p&gt;    Kafka brokers have a config called &quot;offsets.topic.replication.factor&quot; that specify the replication factor for the &quot;__consumer_offsets&quot; topic. The problem is that this config isn&apos;t being enforced. If an attempt to create the internal topic is made when there are fewer brokers than &quot;offsets.topic.replication.factor&quot;, the topic ends up getting created anyway with the current number of live brokers. The current behavior is pretty surprising when you have clients or tooling running as the cluster is getting setup. Even if your cluster ends up being huge, you&apos;ll find out much later that __consumer_offsets was setup with no replication.&lt;/p&gt;

&lt;p&gt;    The cluster not meeting the &quot;offsets.topic.replication.factor&quot; requirement on the internal topic is another way of saying the cluster isn&apos;t fully setup yet.&lt;/p&gt;

&lt;p&gt;    The right behavior should be for &quot;offsets.topic.replication.factor&quot; to be enforced. Topic creation of the internal topic should fail with GROUP_COORDINATOR_NOT_AVAILABLE until the &quot;offsets.topic.replication.factor&quot; requirement is met. This closely resembles the behavior of regular topic creation when the requested replication factor exceeds the current size of the cluster, as the request fails with error INVALID_REPLICATION_FACTOR.&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/onurkaraman/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/onurkaraman/kafka&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3959&quot; title=&quot;KIP-115: __consumer_offsets wrong number of replicas at startup&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3959&quot;&gt;&lt;del&gt;KAFKA-3959&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/2177.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/2177.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #2177&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit ef8558215ff049f0787ae6df688fd25194b7aae2&lt;br/&gt;
Author: Onur Karaman &amp;lt;okaraman@linkedin.com&amp;gt;&lt;br/&gt;
Date:   2016-11-28T05:29:28Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3959&quot; title=&quot;KIP-115: __consumer_offsets wrong number of replicas at startup&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3959&quot;&gt;&lt;del&gt;KAFKA-3959&lt;/del&gt;&lt;/a&gt;: enforce offsets.topic.replication.factor&lt;/p&gt;

&lt;p&gt;    Kafka brokers have a config called &quot;offsets.topic.replication.factor&quot; that specify the replication factor for the &quot;__consumer_offsets&quot; topic. The problem is that this config isn&apos;t being enforced. If an attempt to create the internal topic is made when there are fewer brokers than &quot;offsets.topic.replication.factor&quot;, the topic ends up getting created anyway with the current number of live brokers. The current behavior is pretty surprising when you have clients or tooling running as the cluster is getting setup. Even if your cluster ends up being huge, you&apos;ll find out much later that __consumer_offsets was setup with no replication.&lt;/p&gt;

&lt;p&gt;    The cluster not meeting the &quot;offsets.topic.replication.factor&quot; requirement on the internal topic is another way of saying the cluster isn&apos;t fully setup yet.&lt;/p&gt;

&lt;p&gt;    The right behavior should be for &quot;offsets.topic.replication.factor&quot; to be enforced. Topic creation of the internal topic should fail with GROUP_COORDINATOR_NOT_AVAILABLE until the &quot;offsets.topic.replication.factor&quot; requirement is met. This closely resembles the behavior of regular topic creation when the requested replication factor exceeds the current size of the cluster, as the request fails with error INVALID_REPLICATION_FACTOR.&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15793433" author="ewencp" created="Mon, 2 Jan 2017 20:19:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=onurkaraman&quot; class=&quot;user-hover&quot; rel=&quot;onurkaraman&quot;&gt;onurkaraman&lt;/a&gt; Marked for 0.10.2.0 as this seems like an important fix, but given the new behavior could be considered a breaking change, we might need to defer until 0.11.0.0. Thoughts?&lt;/p&gt;</comment>
                            <comment id="15837994" author="ijuma" created="Wed, 25 Jan 2017 16:11:45 +0000"  >&lt;p&gt;Either way, it&apos;s too late for 0.10.2.0. I&apos;ll move it to 0.10.3.0 for now as it is indeed an important fix.&lt;/p&gt;</comment>
                            <comment id="15849361" author="ewencp" created="Thu, 2 Feb 2017 03:55:30 +0000"  >&lt;p&gt;Issue resolved by pull request 2177&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/pull/2177&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/2177&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15849363" author="githubbot" created="Thu, 2 Feb 2017 03:56:05 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/2177&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/2177&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15849503" author="githubbot" created="Thu, 2 Feb 2017 06:30:13 +0000"  >&lt;p&gt;GitHub user ewencp opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/2484&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/2484&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3959&quot; title=&quot;KIP-115: __consumer_offsets wrong number of replicas at startup&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3959&quot;&gt;&lt;del&gt;KAFKA-3959&lt;/del&gt;&lt;/a&gt;: Follow-up; move upgrade notes to 0.10.3 upgrade section.&lt;/p&gt;



&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/ewencp/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/ewencp/kafka&lt;/a&gt; kafka-3959-followup-upgrade-docs&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/2484.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/2484.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #2484&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 49b8972220249932570a33610655af89878da7cd&lt;br/&gt;
Author: Ewen Cheslack-Postava &amp;lt;me@ewencp.org&amp;gt;&lt;br/&gt;
Date:   2017-02-02T06:29:48Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3959&quot; title=&quot;KIP-115: __consumer_offsets wrong number of replicas at startup&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3959&quot;&gt;&lt;del&gt;KAFKA-3959&lt;/del&gt;&lt;/a&gt;: Follow-up; move upgrade notes to 0.10.3 upgrade section.&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15888757" author="githubbot" created="Tue, 28 Feb 2017 19:50:12 +0000"  >&lt;p&gt;Github user ewencp closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/2484&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/2484&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="13046545">KAFKA-4807</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13023381">KAFKA-4446</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 37 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i30won:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>ewencp</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>