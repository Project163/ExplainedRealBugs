<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:10:11 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6292] KafkaConsumer ran into Unknown error fetching data for topic-partition caused by integer overflow in FileLogInputStream </title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6292</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Steps to reproduce:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Broker config to reproduce this bug:&lt;/li&gt;
&lt;/ul&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  # The maximum size of a log segment file. When &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; size is reached a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; log segment will be created.
#2G
log.segment.bytes=2147483647
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
	&lt;li&gt;Setups:&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    producer sends messages constantly. &lt;br/&gt;
    consumer polling&lt;br/&gt;
    topic has 1 partitions and replication factor 1.&lt;br/&gt;
    min.insync.replicas=1&lt;br/&gt;
    producer has &quot;acks=all&quot;&lt;br/&gt;
    consumer has default &quot;enable.auto.commit=false&quot;&lt;br/&gt;
    consumer manually commitSync offsets after handling messages.&lt;br/&gt;
    kafka in standalone&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Observe log in consumer side(for me running 12 hours)&lt;/li&gt;
&lt;/ul&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2017-12-18 07:11:01.013 WARN sep105v1 [app-consumer-subscription-pool-4-thread-20] org.apache.kafka.clients.consumer.internals.Fetcher {} Unknown error fetching data &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; topic-partition DDI.DISPATCHER.P_TVIN.W_SL.P_appx.P_ul.P_pos-0
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
	&lt;li&gt;Observe server.log in Kafka/logs&lt;/li&gt;
&lt;/ul&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[2017-12-14 04:52:21,144] ERROR [Replica Manager on Broker 3]: Error processing fetch operation on partition DDI.DISPATCHER.P_TVIN.W_SL.P_appx.P_ul.P_pos-0, offset 4043314339 (kafka.server.ReplicaManager)
org.apache.kafka.common.KafkaException: java.io.EOFException: Failed to read `log header` from file channel `sun.nio.ch.FileChannelImpl@5604ea91`. Expected to read 17 bytes, but reached end of file after reading 0 bytes. Started read from position 2147483643.
        at org.apache.kafka.common.record.RecordBatchIterator.makeNext(RecordBatchIterator.java:40)
        at org.apache.kafka.common.record.RecordBatchIterator.makeNext(RecordBatchIterator.java:24)
        at org.apache.kafka.common.utils.AbstractIterator.maybeComputeNext(AbstractIterator.java:79)
        at org.apache.kafka.common.utils.AbstractIterator.hasNext(AbstractIterator.java:45)
        at org.apache.kafka.common.record.FileRecords.searchForOffsetWithSize(FileRecords.java:279)
        at kafka.log.LogSegment.translateOffset(LogSegment.scala:176)
        at kafka.log.LogSegment.read(LogSegment.scala:228)
        at kafka.log.Log.read(Log.scala:938)
        at kafka.server.ReplicaManager.read$1(ReplicaManager.scala:719)
        at kafka.server.ReplicaManager.$anonfun$readFromLocalLog$6(ReplicaManager.scala:780)
        at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:59)
        at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:52)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
        at kafka.server.ReplicaManager.readFromLocalLog(ReplicaManager.scala:779)
        at kafka.server.ReplicaManager.fetchMessages(ReplicaManager.scala:617)
        at kafka.server.KafkaApis.handleFetchRequest(KafkaApis.scala:615)
        at kafka.server.KafkaApis.handle(KafkaApis.scala:98)
        at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:66)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: java.io.EOFException: Failed to read `log header` from file channel `sun.nio.ch.FileChannelImpl@5604ea91`. Expected to read 17 bytes, but reached end of file after reading 0 bytes. Started read from position 2147483643.
        at org.apache.kafka.common.utils.Utils.readFullyOrFail(Utils.java:751)
        at org.apache.kafka.common.record.FileLogInputStream.nextBatch(FileLogInputStream.java:66)
        at org.apache.kafka.common.record.FileLogInputStream.nextBatch(FileLogInputStream.java:40)
        at org.apache.kafka.common.record.RecordBatchIterator.makeNext(RecordBatchIterator.java:35)
        ... 18 more

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
	&lt;li&gt;Impact:&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
	&lt;li&gt;After EOF exception occurs, the consumer will failed to consume the remain message&lt;/li&gt;
	&lt;li&gt;After the segments log files which cause the EOF exception has been deleted by the log Cleaner thread. Consumer recovered to consumer message.&lt;/li&gt;
	&lt;li&gt;Have no impact from the view of producer&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
	&lt;li&gt;Analysis:&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
	&lt;li&gt;Kafka log file list:
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
ls /ssd/kafka-logs/DDI.DISPATCHER.P_TVIN.W_SL.P_appx.P_ul.P_pos-0/*.log
-rw-r--r-- 1 root root 2147481479 Dec 27 14:15 000000000004043314387.log
-rw-r--r-- 1 root root 2147483647 Dec 27 14:15 000000000004039884900.log
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;ol&gt;
	&lt;li&gt;use tools to check the log: /bin/kafka-run-class.sh kafka.tools.DumpLogSegments --deep-iteration --print-data-log --files /ssd/kafka-logs/DDI.DISPATCHER.P_TVIN.W_SL.P_appx.P_ul.P_pos-0/00000000004039884900.log&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Exception print in console is the same in the server.log:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
bin/kafka-run-&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;sh kafka.tools.DumpLogSegments --deep-iteration --print-data-log --files 00000000004039884900.log &amp;gt; tmp.log
Exception in thread &lt;span class=&quot;code-quote&quot;&gt;&quot;main&quot;&lt;/span&gt; org.apache.kafka.common.KafkaException: java.io.EOFException: Failed to read `log header` from file channel `sun.nio.ch.FileChannelImpl@4e41089d`. Expected to read 17 bytes, but reached end of file after reading 0 bytes. Started read from position 2147483637.
  at org.apache.kafka.common.record.RecordBatchIterator.makeNext(RecordBatchIterator.java:40)
  at org.apache.kafka.common.record.RecordBatchIterator.makeNext(RecordBatchIterator.java:24)
  at org.apache.kafka.common.utils.AbstractIterator.maybeComputeNext(AbstractIterator.java:79)
  at org.apache.kafka.common.utils.AbstractIterator.hasNext(AbstractIterator.java:45)
  at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:39)
  at scala.collection.Iterator.foreach(Iterator.scala:929)
  at scala.collection.Iterator.foreach$(Iterator.scala:929)
  at scala.collection.AbstractIterator.foreach(Iterator.scala:1417)
  at scala.collection.IterableLike.foreach(IterableLike.scala:71)
  at scala.collection.IterableLike.foreach$(IterableLike.scala:70)
  at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
  at kafka.tools.DumpLogSegments$.dumpLog(DumpLogSegments.scala:375)
  at kafka.tools.DumpLogSegments$.$anonfun$main$1(DumpLogSegments.scala:112)
  at kafka.tools.DumpLogSegments$.$anonfun$main$1$adapted(DumpLogSegments.scala:104)
  at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
  at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
  at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:191)
  at kafka.tools.DumpLogSegments$.main(DumpLogSegments.scala:104)
  at kafka.tools.DumpLogSegments.main(DumpLogSegments.scala)
Caused by: java.io.EOFException: Failed to read `log header` from file channel `sun.nio.ch.FileChannelImpl@4e41089d`. Expected to read 17 bytes, but reached end of file after reading 0 bytes. Started read from position 2147483637.
  at org.apache.kafka.common.utils.Utils.readFullyOrFail(Utils.java:791)
  at org.apache.kafka.common.record.FileLogInputStream.nextBatch(FileLogInputStream.java:66)
  at org.apache.kafka.common.record.FileLogInputStream.nextBatch(FileLogInputStream.java:40)
  at org.apache.kafka.common.record.RecordBatchIterator.makeNext(RecordBatchIterator.java:35)
  ... 18 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
	&lt;li&gt;Root Cause:&lt;br/&gt;
  In org.apache.kafka.common.record.FileLogInputStream.java:&lt;/li&gt;
&lt;/ul&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
60    @Override
61    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; FileChannelRecordBatch nextBatch() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
62        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (position + HEADER_SIZE_UP_TO_MAGIC &amp;gt;= end)
63            &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
64
65        logHeaderBuffer.rewind();
66        Utils.readFullyOrFail(channel, logHeaderBuffer, position, &lt;span class=&quot;code-quote&quot;&gt;&quot;log header&quot;&lt;/span&gt;);
.....
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;    EOFException is raised at line 66, which expected to read next batch records from the log segment, but current position is reached the end of segment file. Check the code in line 62, if the position is 2147483647, then (position + HEADER_SIZE_UP_TO_MAGIC) is overflow and will be a negative.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Workaround:&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
	&lt;li&gt;lower down the log.segment.bytes&lt;/li&gt;
&lt;/ol&gt;





</description>
                <environment>OS:Red Hat Enterprise Linux Server release 7.3 (Maipo)&lt;br/&gt;
Kafka: kafka_2.12-0.11.0.0&lt;br/&gt;
JDK: jdk1.8.0_121&lt;br/&gt;
&lt;br/&gt;
</environment>
        <key id="13122121">KAFKA-6292</key>
            <summary>KafkaConsumer ran into Unknown error fetching data for topic-partition caused by integer overflow in FileLogInputStream </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="terence.yi">Terence Yi</reporter>
                        <labels>
                            <label>easyfix</label>
                            <label>reliability</label>
                    </labels>
                <created>Fri, 1 Dec 2017 08:18:35 +0000</created>
                <updated>Fri, 6 Jul 2018 23:22:56 +0000</updated>
                            <resolved>Wed, 9 May 2018 00:08:36 +0000</resolved>
                                    <version>0.11.0.0</version>
                    <version>0.11.0.1</version>
                    <version>0.11.0.2</version>
                    <version>1.0.0</version>
                                    <fixVersion>1.0.3</fixVersion>
                    <fixVersion>1.1.2</fixVersion>
                    <fixVersion>2.0.0</fixVersion>
                                    <component>log</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="16274116" author="ijuma" created="Fri, 1 Dec 2017 08:40:04 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16274130" author="huxi_2b" created="Fri, 1 Dec 2017 08:57:09 +0000"  >&lt;p&gt;Is it possible that the underlying segment file got shrank so `readFully` read nothing at the given position `2147483635 `, therefore causing this problem? Could you check if the server log printed &quot;Truncating log %s to offset %d&quot; around that time?&lt;/p&gt;</comment>
                            <comment id="16274136" author="terence.yi" created="Fri, 1 Dec 2017 09:09:03 +0000"  >&lt;p&gt;The time EOFException occurs, no log printed with &quot;Truncating log...), but i do got this log in other log files at differ time with different partition&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2017-11-27 09:44:48,099&amp;#93;&lt;/span&gt; INFO Truncating DDI.DISPATCHER.MESSAGE_FORWARD_d694b9fa-d99a-4f4d-9062-b75e73b466a0-1 to 0 has no effect as the largest offset in the log is -1. (kafka.log.Log)&lt;/p&gt;
</comment>
                            <comment id="16304301" author="terence.yi" created="Wed, 27 Dec 2017 07:49:23 +0000"  >&lt;p&gt;Log description updated according to latest test and analysis&lt;/p&gt;</comment>
                            <comment id="16451844" author="suppierk" created="Wed, 25 Apr 2018 08:11:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=terence.yi&quot; class=&quot;user-hover&quot; rel=&quot;terence.yi&quot;&gt;terence.yi&lt;/a&gt; hi, I would like to work with this issue, if you don&apos;t mind&lt;/p&gt;</comment>
                            <comment id="16452199" author="githubbot" created="Wed, 25 Apr 2018 12:51:33 +0000"  >&lt;p&gt;SuppieRK opened a new pull request #4928: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6292&quot; title=&quot;KafkaConsumer ran into Unknown error fetching data for topic-partition caused by integer overflow in FileLogInputStream &quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6292&quot;&gt;&lt;del&gt;KAFKA-6292&lt;/del&gt;&lt;/a&gt;: Improved FileLogInputStream batch position checks in order to avoid type overflow related errors&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4928&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4928&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Basically, my change was very simple - switch from sum operations to subtraction to avoid type casting in checks and type overflow during FlieLogInputStream work, especially in cases where property `log.segment.bytes` was set close to the `Integer.MAX_VALUE` and used as a `position` inside `nextBatch()` function.&lt;/p&gt;

&lt;p&gt;   All related Unit tests are working as intended. No new tests (probably) required.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16468133" author="githubbot" created="Wed, 9 May 2018 00:07:53 +0000"  >&lt;p&gt;hachikuji closed pull request #4928: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6292&quot; title=&quot;KafkaConsumer ran into Unknown error fetching data for topic-partition caused by integer overflow in FileLogInputStream &quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6292&quot;&gt;&lt;del&gt;KAFKA-6292&lt;/del&gt;&lt;/a&gt;: Improved FileLogInputStream batch position checks in order to avoid type overflow related errors&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4928&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4928&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/clients/src/main/java/org/apache/kafka/common/record/FileLogInputStream.java b/clients/src/main/java/org/apache/kafka/common/record/FileLogInputStream.java&lt;br/&gt;
index a1e3a2f6541..92e8864a183 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/common/record/FileLogInputStream.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/common/record/FileLogInputStream.java&lt;br/&gt;
@@ -60,7 +60,7 @@&lt;br/&gt;
     @Override&lt;br/&gt;
     public FileChannelRecordBatch nextBatch() throws IOException {&lt;br/&gt;
         FileChannel channel = fileRecords.channel();&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (position + HEADER_SIZE_UP_TO_MAGIC &amp;gt;= end)&lt;br/&gt;
+        if (position &amp;gt;= end - HEADER_SIZE_UP_TO_MAGIC)&lt;br/&gt;
             return null;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         logHeaderBuffer.rewind();&lt;br/&gt;
@@ -75,7 +75,7 @@ public FileChannelRecordBatch nextBatch() throws IOException {&lt;br/&gt;
             throw new CorruptRecordException(String.format(&quot;Found record size %d smaller than minimum record &quot; +&lt;br/&gt;
                             &quot;overhead (%d) in file %s.&quot;, size, LegacyRecord.RECORD_OVERHEAD_V0, fileRecords.file()));&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (position + LOG_OVERHEAD + size &amp;gt; end)&lt;br/&gt;
+        if (position &amp;gt; end - LOG_OVERHEAD - size)&lt;br/&gt;
             return null;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         byte magic = logHeaderBuffer.get(MAGIC_OFFSET);&lt;br/&gt;
diff --git a/clients/src/test/java/org/apache/kafka/common/record/FileLogInputStreamTest.java b/clients/src/test/java/org/apache/kafka/common/record/FileLogInputStreamTest.java&lt;br/&gt;
index 95b2a0c89c6..77aaae86f5f 100644&lt;br/&gt;
&amp;#8212; a/clients/src/test/java/org/apache/kafka/common/record/FileLogInputStreamTest.java&lt;br/&gt;
+++ b/clients/src/test/java/org/apache/kafka/common/record/FileLogInputStreamTest.java&lt;br/&gt;
@@ -112,8 +112,8 @@ public void testBatchIterationWithMultipleRecordsPerBatch() throws IOException {&lt;br/&gt;
             SimpleRecord[] firstBatchRecords = new SimpleRecord[]&lt;/p&gt;
{
                 new SimpleRecord(3241324L, &quot;a&quot;.getBytes(), &quot;1&quot;.getBytes()),
                 new SimpleRecord(234280L, &quot;b&quot;.getBytes(), &quot;2&quot;.getBytes())
-
             };&lt;br/&gt;
+&lt;br/&gt;
             SimpleRecord[] secondBatchRecords = new SimpleRecord[]{&lt;br/&gt;
                 new SimpleRecord(238423489L, &quot;c&quot;.getBytes(), &quot;3&quot;.getBytes()),&lt;br/&gt;
                 new SimpleRecord(897839L, null, &quot;4&quot;.getBytes()),&lt;br/&gt;
@@ -152,8 +152,8 @@ public void testBatchIterationV2() throws IOException {&lt;br/&gt;
             SimpleRecord[] firstBatchRecords = new SimpleRecord[]{                 new SimpleRecord(3241324L, &quot;a&quot;.getBytes(), &quot;1&quot;.getBytes()),                 new SimpleRecord(234280L, &quot;b&quot;.getBytes(), &quot;2&quot;.getBytes())-             }
&lt;p&gt;;&lt;br/&gt;
+&lt;br/&gt;
             SimpleRecord[] secondBatchRecords = new SimpleRecord[]{&lt;br/&gt;
                 new SimpleRecord(238423489L, &quot;c&quot;.getBytes(), &quot;3&quot;.getBytes()),&lt;br/&gt;
                 new SimpleRecord(897839L, null, &quot;4&quot;.getBytes()),&lt;br/&gt;
@@ -204,6 +204,22 @@ public void testBatchIterationIncompleteBatch() throws IOException {&lt;br/&gt;
         }&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;+    @Test&lt;br/&gt;
+    public void testNextBatchSelectionWithMaxedParams() throws IOException {&lt;br/&gt;
+        try (FileRecords fileRecords = FileRecords.open(tempFile())) &lt;/p&gt;
{
+            FileLogInputStream logInputStream = new FileLogInputStream(fileRecords, Integer.MAX_VALUE, Integer.MAX_VALUE);
+            assertNull(logInputStream.nextBatch());
+        }
&lt;p&gt;+    }&lt;br/&gt;
+&lt;br/&gt;
+    @Test&lt;br/&gt;
+    public void testNextBatchSelectionWithZeroedParams() throws IOException {&lt;br/&gt;
+        try (FileRecords fileRecords = FileRecords.open(tempFile())) &lt;/p&gt;
{
+            FileLogInputStream logInputStream = new FileLogInputStream(fileRecords, 0, 0);
+            assertNull(logInputStream.nextBatch());
+        }
&lt;p&gt;+    }&lt;br/&gt;
+&lt;br/&gt;
     private void assertProducerData(RecordBatch batch, long producerId, short producerEpoch, int baseSequence,&lt;br/&gt;
                                     boolean isTransactional, SimpleRecord ... records) {&lt;br/&gt;
         assertEquals(producerId, batch.producerId());&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13169767">KAFKA-7130</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310250" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10431"><![CDATA[Important]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 27 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3nf87:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>