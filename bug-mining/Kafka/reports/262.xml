<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:38:01 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-860] Replica fetcher thread errors out and dies during rolling bounce of cluster</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-860</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;2013/04/10 20:04:32.071 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;ReplicaFetcherThread&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;ReplicaFetcherThread-0-272&amp;#93;&lt;/span&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka&amp;#93;&lt;/span&gt; [] &lt;span class=&quot;error&quot;&gt;&amp;#91;ReplicaFetcherThread-0-272&amp;#93;&lt;/span&gt;, Error due to &lt;br/&gt;
kafka.common.KafkaException: error processing data for topic PageViewEvent partititon 3 offset 2482625623&lt;br/&gt;
        at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$4.apply(AbstractFetcherThread.scala:135)&lt;br/&gt;
        at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$4.apply(AbstractFetcherThread.scala:113)&lt;br/&gt;
        at scala.collection.immutable.Map$Map1.foreach(Map.scala:105)&lt;br/&gt;
        at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:113)&lt;br/&gt;
        at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:89)&lt;br/&gt;
        at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:51)&lt;br/&gt;
Caused by: java.lang.RuntimeException: Offset mismatch: fetched offset = 2482625623, log end offset = 2482625631.&lt;br/&gt;
        at kafka.server.ReplicaFetcherThread.processPartitionData(ReplicaFetcherThread.scala:49)&lt;br/&gt;
        at kafka.server.AbstractFetcherThread$$anonfun$processFetchRequest$4.apply(AbstractFetcherThread.scala:132)&lt;br/&gt;
        ... 5 more&lt;/p&gt;

&lt;p&gt;This causes replica fetcher thread to shut down&lt;/p&gt;</description>
                <environment></environment>
        <key id="12641921">KAFKA-860</key>
            <summary>Replica fetcher thread errors out and dies during rolling bounce of cluster</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="nehanarkhede">Neha Narkhede</assignee>
                                    <reporter username="nehanarkhede">Neha Narkhede</reporter>
                        <labels>
                            <label>kafka-0.8</label>
                            <label>p1</label>
                    </labels>
                <created>Wed, 10 Apr 2013 21:12:48 +0000</created>
                <updated>Tue, 30 Apr 2013 17:14:21 +0000</updated>
                            <resolved>Tue, 30 Apr 2013 17:14:17 +0000</resolved>
                                    <version>0.8.0</version>
                                                    <component>replication</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="13628376" author="nehanarkhede" created="Wed, 10 Apr 2013 22:40:31 +0000"  >&lt;p&gt;This is caused by a race condition between the old leader&apos;s local append to the log and the new follower&apos;s log truncation. Specifically, the following causes the bug-&lt;/p&gt;

&lt;p&gt;1. Current leader receives a produce request.&lt;br/&gt;
2. Broker receives leader and isr request making it a follower now&lt;br/&gt;
3. Broker starts become follower and truncates log &lt;br/&gt;
4. Broker, not knowing it is not the leader anymore, continues with the produce request and appends some data to the log&lt;br/&gt;
5. Become follower starts a fetcher with the old log end offset&lt;/p&gt;

&lt;p&gt;At step 5, it runs into the error&lt;/p&gt;</comment>
                            <comment id="13628509" author="nehanarkhede" created="Thu, 11 Apr 2013 00:46:02 +0000"  >&lt;p&gt;The root cause is that during produce request handling, we acquire different locks to check if the broker is a leader and then append messages atomically. The fix is to move the append to Partition, so that either it is the leader and it finishes the append or it rejects the produce request since it is becoming a follower. No interleaving should happen.&lt;/p&gt;</comment>
                            <comment id="13628557" author="nehanarkhede" created="Thu, 11 Apr 2013 01:42:59 +0000"  >&lt;p&gt;Jun made a good point when we discussed this offline. The solution is correct but there is a performance hit. Basically, the only requirement is to have become-leader/become-follower/update-isr block the appends. But we shouldn&apos;t let 2 appends block each other. Implemented that using a read-write lock&lt;/p&gt;</comment>
                            <comment id="13628674" author="junrao" created="Thu, 11 Apr 2013 05:10:31 +0000"  >&lt;p&gt;Thanks for patch v2. This turns out to be a bit more tricky.&lt;/p&gt;

&lt;p&gt;1. First of all, instead of using &quot;leaderIsrReadLock synchronized&quot;, we should do &quot;leaderIsrReadLock.lock()&quot;.&lt;/p&gt;

&lt;p&gt;2. Second, we should use a fair readWriteLock. Otherwise, some threads may be indefinitely postponed. &lt;/p&gt;

&lt;p&gt;3. Third, from java doc, ReentrantReadWriteLock doesn&apos;t support upgrading from read lock to write loc.&lt;br/&gt;
&quot; Lock downgrading&lt;br/&gt;
Reentrancy also allows downgrading from the write lock to a read lock, by acquiring the write lock, then the read lock and then releasing the write lock. However, upgrading from a read lock to the write lock is not possible. &quot;&lt;/p&gt;

&lt;p&gt;This means that if we need to call updateIsr(), we have to first release the read lock and require the read lock again when done. See the following example. However, this means that we are still vulnerable to the issue in maybeIncrementLeaderHW() (kafka-862). We probably can change the logic in maybeIncrementLeaderHW() so that it can handle empty set. We will need to think a bit more how to write the logic in a clean way.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://codereview.stackexchange.com/questions/12939/reentrantreadwritelock-lock-upgrade-method&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://codereview.stackexchange.com/questions/12939/reentrantreadwritelock-lock-upgrade-method&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Another possibility is to just take v1 patch. All producers to the same log will sync on the leaderIsrUpdateLock. In log.append(), the only code outside the log lock are analyzeAndValidateMessageSet() and maybeFlush(). The former is cheap since it does shallow iteration. The latter re-requires the log lock if flush if needed.&lt;/p&gt;</comment>
                            <comment id="13628697" author="nehanarkhede" created="Thu, 11 Apr 2013 05:50:09 +0000"  >&lt;p&gt;I like the option of picking a simpler solution for now and filing a performance improvement bug to come back and do it properly. &lt;/p&gt;</comment>
                            <comment id="13629069" author="jkreps" created="Thu, 11 Apr 2013 16:22:18 +0000"  >&lt;p&gt;The reason for the more granular locking in Log was to avoid locking around the flush. However we since learned that the flush effectively locks the log no matter what, so it doesn&apos;t make any difference. So I am not sure that V1 will be a performance hit. What would be really nice would be automated perf tests that checked this kind of thing so we could spot regressions.&lt;/p&gt;</comment>
                            <comment id="13629225" author="nehanarkhede" created="Thu, 11 Apr 2013 18:54:16 +0000"  >&lt;p&gt;I checked in patch v1 and will see how that goes.&lt;/p&gt;</comment>
                            <comment id="13645738" author="nehanarkhede" created="Tue, 30 Apr 2013 17:14:17 +0000"  >&lt;p&gt;v1 fixes the issue&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310060">
                    <name>Container</name>
                                            <outwardlinks description="contains">
                                        <issuelink>
            <issuekey id="12641931">KAFKA-862</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12578121" name="kafka-860-v1.patch" size="4617" author="nehanarkhede" created="Thu, 11 Apr 2013 00:46:02 +0000"/>
                            <attachment id="12578131" name="kafka-860-v2.patch" size="10332" author="nehanarkhede" created="Thu, 11 Apr 2013 01:42:59 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>322336</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            12 years, 29 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1jm4v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>322681</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>