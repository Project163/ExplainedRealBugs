<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:13:24 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-7194] Error deserializing assignment after rebalance</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-7194</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;A simple sink connector task is failing in a test with the following exception:&#160;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[2018-07-02 12:31:13,200] ERROR WorkerSinkTask{id=verifiable-sink-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask)

org.apache.kafka.common.protocol.types.SchemaException: Error reading field &apos;version&apos;: java.nio.BufferUnderflowException

&#160; &#160; &#160; &#160; at org.apache.kafka.common.protocol.types.Schema.read(Schema.java:77)

&#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.internals.ConsumerProtocol.deserializeAssignment(ConsumerProtocol.java:105)

&#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinComplete(ConsumerCoordinator.java:243)

&#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.joinGroupIfNeeded(AbstractCoordinator.java:421)

&#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureActiveGroup(AbstractCoordinator.java:353)

&#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureActiveGroup(AbstractCoordinator.java:338)

&#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:333)

&#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1218)

&#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1181)

&#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1115)

&#160; &#160; &#160; &#160; at org.apache.kafka.connect.runtime.WorkerSinkTask.pollConsumer(WorkerSinkTask.java:444)

&#160; &#160; &#160; &#160; at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:317)

&#160; &#160; &#160; &#160; at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:225)

&#160; &#160; &#160; &#160; at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:193)

&#160; &#160; &#160; &#160; at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:175)

&#160; &#160; &#160; &#160; at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:219)

&#160; &#160; &#160; &#160; at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)

&#160; &#160; &#160; &#160; at java.util.concurrent.FutureTask.run(FutureTask.java:266)

&#160; &#160; &#160; &#160; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)

&#160; &#160; &#160; &#160; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)

&#160; &#160; &#160; &#160; at java.lang.Thread.run(Thread.java:748)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;After dumping the consumer offsets on the partition that this consumer group is writing with:&#160;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;bin/kafka-dump-log.sh --offsets-decoder --files ./00000000000000000000.log &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;we get:&#160;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Dumping ./00000000000000000000.log

Starting offset: 0

offset: 0 position: 0 CreateTime: 1530534673177 isvalid: true keysize: 27 valuesize: 217 magic: 2 compresscodec: NONE producerId: -1 producerEpoch: -1 sequence: -1 isTransactional: false headerKeys: [] key: {&quot;metadata&quot;:&quot;connect-verifiable-sink&quot;} payload: {&quot;protocolType&quot;:&quot;consumer&quot;,&quot;protocol&quot;:&quot;range&quot;,&quot;generationId&quot;:1,&quot;assignment&quot;:&quot;{consumer-4-bad84955-e702-44fe-a018-677bd3b3a9d4=[test-0]}&quot;}

offset: 1 position: 314 CreateTime: 1530534673206 isvalid: true keysize: 27 valuesize: 32 magic: 2 compresscodec: NONE producerId: -1 producerEpoch: -1 sequence: -1 isTransactional: false headerKeys: [] key: {&quot;metadata&quot;:&quot;connect-verifiable-sink&quot;} payload: {&quot;protocolType&quot;:&quot;consumer&quot;,&quot;protocol&quot;:null,&quot;generationId&quot;:2,&quot;assignment&quot;:&quot;{}&quot;}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Since the broker seems to send a non-empty response to the consumer, there&apos;s a chance that the response buffer is consumed more than once at some point when parsing the response in the client.&#160;&lt;/p&gt;

&lt;p&gt;Here&apos;s what the kafka-request.log shows it sends to the client with the `SYNC_GROUP` response that throws the error:&#160;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[2018-07-02 12:31:13,185] DEBUG Completed request:RequestHeader(apiKey=SYNC_GROUP, apiVersion=2, clientId=consumer-4, correlationId=5) -- {group_id=connect-verifiable-sink,generation_id=1,member_id=consumer-4-bad84955-e702-44fe-a018-677bd3b3a9d4,group_assignment=[{member_id=consumer-4-bad84955-e702-44fe-a018-677bd3b3a9d4,member_assignment=java.nio.HeapByteBuffer[pos=0 lim=24 cap=24]}]},response:{throttle_time_ms=0,error_code=0,member_assignment=java.nio.HeapByteBuffer[pos=0 lim=24 cap=24]} from connection 172.31.40.44:9092-172.31.35.189:49191-25;totalTime:8.904,requestQueueTime:0.063,localTime:8.558,remoteTime:0.0,throttleTime:0.03,responseQueueTime:0.037,sendTime:0.245,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT (kafka.request.logger)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13173874">KAFKA-7194</key>
            <summary>Error deserializing assignment after rebalance</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hachikuji">Jason Gustafson</assignee>
                                    <reporter username="kkonstantine">Konstantine Karantasis</reporter>
                        <labels>
                    </labels>
                <created>Mon, 23 Jul 2018 17:37:02 +0000</created>
                <updated>Tue, 24 Jul 2018 08:29:59 +0000</updated>
                            <resolved>Tue, 24 Jul 2018 08:29:59 +0000</resolved>
                                                    <fixVersion>2.0.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16553531" author="githubbot" created="Mon, 23 Jul 2018 23:14:24 +0000"  >&lt;p&gt;hachikuji opened a new pull request #5417: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7194&quot; title=&quot;Error deserializing assignment after rebalance&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7194&quot;&gt;&lt;del&gt;KAFKA-7194&lt;/del&gt;&lt;/a&gt;; Fix buffer underflow if onJoinComplete is retried after failure&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5417&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5417&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   An untimely wakeup can cause `ConsumerCoordinator.onJoinComplete` to throw a `WakeupException` before completion. On the next `poll()`, it will be retried, but this leads to an underflow error because the buffer containing the assignment data will already have been advanced. The solution is to duplicate the buffer passed to `onJoinComplete`. &lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16553954" author="githubbot" created="Tue, 24 Jul 2018 08:25:22 +0000"  >&lt;p&gt;rajinisivaram closed pull request #5417: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7194&quot; title=&quot;Error deserializing assignment after rebalance&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7194&quot;&gt;&lt;del&gt;KAFKA-7194&lt;/del&gt;&lt;/a&gt;; Fix buffer underflow if onJoinComplete is retried after failure&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5417&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5417&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/AbstractCoordinator.java b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/AbstractCoordinator.java&lt;br/&gt;
index b5c7a66e100..53834fb81df 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/AbstractCoordinator.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/AbstractCoordinator.java&lt;br/&gt;
@@ -200,9 +200,8 @@ public AbstractCoordinator(LogContext logContext,&lt;br/&gt;
                                                                  Map&amp;lt;String, ByteBuffer&amp;gt; allMemberMetadata);&lt;/p&gt;

&lt;p&gt;     /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Invoked when a group member has successfully joined a group. If this call is woken up (i.e.&lt;/li&gt;
	&lt;li&gt;* if the invocation raises 
{@link org.apache.kafka.common.errors.WakeupException}
&lt;p&gt;), then it&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;* will be retried on the next call to 
{@link #ensureActiveGroup()}.&lt;br/&gt;
+     * Invoked when a group member has successfully joined a group. If this call fails with an exception,&lt;br/&gt;
+     * then it will be retried using the same assignment state on the next call to {@link #ensureActiveGroup()}
&lt;p&gt;.&lt;br/&gt;
      *&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param generation The generation that was joined&lt;/li&gt;
	&lt;li&gt;@param memberId The identifier for the local member in the group&lt;br/&gt;
@@ -418,7 +417,9 @@ boolean joinGroupIfNeeded(final long timeoutMs, final long startTimeMs) {&lt;br/&gt;
             }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             if (future.succeeded()) &lt;/p&gt;
{
-                onJoinComplete(generation.generationId, generation.memberId, generation.protocol, future.value());
+                // Duplicate the buffer in case `onJoinComplete` does not complete and needs to be retried.
+                ByteBuffer memberAssignment = future.value().duplicate();
+                onJoinComplete(generation.generationId, generation.memberId, generation.protocol, memberAssignment);
 
                 // We reset the join group future only after the completion callback returns. This ensures
                 // that if the callback is woken up, we will retry it on the next joinGroupIfNeeded.
diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java
index ea6d47249eb..f9b77e921cd 100644
--- a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java
@@ -269,10 +269,10 @@ protected void onJoinComplete(int generation,
             this.joinedSubscription = newJoinedSubscription;
         }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// update the metadata and enforce a refresh to make sure the fetcher can start&lt;/li&gt;
	&lt;li&gt;// fetching data in the next iteration&lt;br/&gt;
+        // Update the metadata to include the full group subscription. The leader will trigger a rebalance&lt;br/&gt;
+        // if there are any metadata changes affecting any of the consumed partitions (whether or not this&lt;br/&gt;
+        // instance is subscribed to the topics).&lt;br/&gt;
         this.metadata.setTopics(subscriptions.groupSubscription());&lt;/li&gt;
	&lt;li&gt;if (!client.ensureFreshMetadata(Long.MAX_VALUE)) throw new TimeoutException();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // give the assignor a chance to update internal state based on the received assignment&lt;br/&gt;
         assignor.onAssignment(assignment);&lt;br/&gt;
diff --git a/clients/src/test/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinatorTest.java b/clients/src/test/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinatorTest.java&lt;br/&gt;
index 7c2638cf012..ba392c6f4cb 100644&lt;br/&gt;
&amp;#8212; a/clients/src/test/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinatorTest.java&lt;br/&gt;
+++ b/clients/src/test/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinatorTest.java&lt;br/&gt;
@@ -874,6 +874,57 @@ public boolean matches(AbstractRequest body) &lt;/p&gt;
{
         assertEquals(new HashSet&amp;lt;&amp;gt;(Arrays.asList(tp1, tp2)), subscriptions.assignedPartitions());
     }

&lt;p&gt;+    @Test&lt;br/&gt;
+    public void testWakeupFromAssignmentCallback() {&lt;br/&gt;
+        ConsumerCoordinator coordinator = buildCoordinator(new Metrics(), assignors,&lt;br/&gt;
+                ConsumerConfig.DEFAULT_EXCLUDE_INTERNAL_TOPICS, false, true);&lt;br/&gt;
+&lt;br/&gt;
+        final String topic = &quot;topic1&quot;;&lt;br/&gt;
+        TopicPartition partition = new TopicPartition(topic, 0);&lt;br/&gt;
+        final String consumerId = &quot;follower&quot;;&lt;br/&gt;
+        Set&amp;lt;String&amp;gt; topics = Collections.singleton(topic);&lt;br/&gt;
+        MockRebalanceListener rebalanceListener = new MockRebalanceListener() {&lt;br/&gt;
+            @Override&lt;br/&gt;
+            public void onPartitionsAssigned(Collection&amp;lt;TopicPartition&amp;gt; partitions) &lt;/p&gt;
{
+                boolean raiseWakeup = this.assignedCount == 0;
+                super.onPartitionsAssigned(partitions);
+
+                if (raiseWakeup)
+                    throw new WakeupException();
+            }
&lt;p&gt;+        };&lt;br/&gt;
+&lt;br/&gt;
+        subscriptions.subscribe(topics, rebalanceListener);&lt;br/&gt;
+        metadata.setTopics(topics);&lt;br/&gt;
+&lt;br/&gt;
+        // we only have metadata for one topic initially&lt;br/&gt;
+        metadata.update(TestUtils.singletonCluster(topic, 1), Collections.emptySet(), time.milliseconds());&lt;br/&gt;
+&lt;br/&gt;
+        client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;br/&gt;
+&lt;br/&gt;
+        // prepare initial rebalance&lt;br/&gt;
+        partitionAssignor.prepare(singletonMap(consumerId, Collections.singletonList(partition)));&lt;br/&gt;
+&lt;br/&gt;
+        client.prepareResponse(joinGroupFollowerResponse(1, consumerId, &quot;leader&quot;, Errors.NONE));&lt;br/&gt;
+        client.prepareResponse(syncGroupResponse(Collections.singletonList(partition), Errors.NONE));&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
+        // The first call to poll should raise the exception from the rebalance listener&lt;br/&gt;
+        try &lt;/p&gt;
{
+            coordinator.poll(Long.MAX_VALUE);
+            fail(&quot;Expected exception thrown from assignment callback&quot;);
+        }
&lt;p&gt; catch (WakeupException e) &lt;/p&gt;
{
+        }
&lt;p&gt;+&lt;br/&gt;
+        // The second call should retry the assignment callback and succeed&lt;br/&gt;
+        coordinator.poll(Long.MAX_VALUE);&lt;br/&gt;
+&lt;br/&gt;
+        assertFalse(coordinator.rejoinNeededOrPending());&lt;br/&gt;
+        assertEquals(1, rebalanceListener.revokedCount);&lt;br/&gt;
+        assertEquals(2, rebalanceListener.assignedCount);&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testRebalanceAfterTopicUnavailableWithSubscribe() {&lt;br/&gt;
         unavailableTopicTest(false, false, Collections.&amp;lt;String&amp;gt;emptySet());&lt;br/&gt;
@@ -1901,7 +1952,7 @@ private JoinGroupResponse joinGroupLeaderResponse(int generationId,&lt;/p&gt;

&lt;p&gt;     private JoinGroupResponse joinGroupFollowerResponse(int generationId, String memberId, String leaderId, Errors error) &lt;/p&gt;
{
         return new JoinGroupResponse(error, generationId, partitionAssignor.name(), memberId, leaderId,
-                Collections.&amp;lt;String, ByteBuffer&amp;gt;emptyMap());
+                Collections.emptyMap());
     }

&lt;p&gt;     private SyncGroupResponse syncGroupResponse(List&amp;lt;TopicPartition&amp;gt; partitions, Errors error) &lt;/p&gt;
{
@@ -1914,7 +1965,7 @@ private OffsetCommitResponse offsetCommitResponse(Map&amp;lt;TopicPartition, Errors&amp;gt; re
     }

&lt;p&gt;     private OffsetFetchResponse offsetFetchResponse(Errors topLevelError) &lt;/p&gt;
{
-        return new OffsetFetchResponse(topLevelError, Collections.&amp;lt;TopicPartition, OffsetFetchResponse.PartitionData&amp;gt;emptyMap());
+        return new OffsetFetchResponse(topLevelError, Collections.emptyMap());
     }

&lt;p&gt;     private OffsetFetchResponse offsetFetchResponse(TopicPartition tp, Errors partitionLevelError, String metadata, long offset) {&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 17 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3w6p3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>kkonstantine</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>