<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:37:18 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-15388] Handle topics that were having compaction as retention earlier are changed to delete only retention policy and onboarded to tiered storage. </title>
                <link>https://issues.apache.org/jira/browse/KAFKA-15388</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Context: &lt;a href=&quot;https://github.com/apache/kafka/pull/13561#discussion_r1300055517&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/13561#discussion_r1300055517&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;br/&gt;
There are 3 paths I looked at:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;When data is moved to remote storage (1)&lt;/li&gt;
	&lt;li&gt;When data is read from remote storage (2)&lt;/li&gt;
	&lt;li&gt;When data is deleted from remote storage (3)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;(1) Does not have a problem with compacted topics. Compacted segments are uploaded and their metadata claims they contain offset from the baseOffset of the segment until the next segment&apos;s baseOffset. There are no gaps in offsets.&lt;br/&gt;
(2) Does not have a problem if a customer is querying offsets which do not exist within a segment, but there are offset after the queried offset within the same segment.&#160;&lt;b&gt;However, it does have a problem when the next available offset is in a subsequent segment.&lt;/b&gt;&lt;br/&gt;
(3) For data deleted via DeleteRecords there is no problem. For data deleted via retention there is no problem.&lt;br/&gt;
&#160;&lt;br/&gt;
&lt;b&gt;I believe the proper solution to (2) is to make tiered storage continue looking for the next greater offset in subsequent segments.&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Steps to reproduce the issue:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// TODO (christo)&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13548083">KAFKA-15388</key>
            <summary>Handle topics that were having compaction as retention earlier are changed to delete only retention policy and onboarded to tiered storage. </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png" description="A patch for this issue has been uploaded to JIRA by a contributor.">Patch Available</status>
                    <statusCategory id="4" key="indeterminate" colorName="yellow"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="goyarpit">Arpit Goyal</assignee>
                                    <reporter username="satish.duggana">Satish Duggana</reporter>
                        <labels>
                    </labels>
                <created>Mon, 21 Aug 2023 14:14:01 +0000</created>
                <updated>Thu, 9 Jan 2025 14:12:33 +0000</updated>
                                                                                <due></due>
                            <votes>0</votes>
                                    <watches>11</watches>
                                                                                                                <comments>
                            <comment id="17757487" author="christo_lolov" created="Tue, 22 Aug 2023 14:04:08 +0000"  >&lt;p&gt;I would like to contribute to this ticket once the above pull request has been merged by providing the solution for correctly setting the logStartOffset!&lt;/p&gt;</comment>
                            <comment id="17761859" author="divijvaidya" created="Mon, 4 Sep 2023 15:32:30 +0000"  >&lt;p&gt;Hey &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=satish.duggana&quot; class=&quot;user-hover&quot; rel=&quot;satish.duggana&quot;&gt;satish.duggana&lt;/a&gt;&#160;&lt;br/&gt;
If supporting TS on historically compacted topics is not in scope for 3.6 (blocked by this ticket) then we should update the &lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Tiered+Storage+Early+Access+Release+Notes&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Tiered+Storage+Early+Access+Release+Notes&lt;/a&gt; with this information. What do you think?&lt;/p&gt;

&lt;p&gt;Also, note that other that delete, other paths (read) is impacted by it as well. For example, this line of code has an assumption that offsets are contiguous &lt;a href=&quot;https://github.com/apache/kafka/blob/5785796f985aa294c12e670da221d086a7fa887c/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L1326C4-L1326C4&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/5785796f985aa294c12e670da221d086a7fa887c/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L1326C4-L1326C4&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17762057" author="satish.duggana" created="Tue, 5 Sep 2023 11:50:47 +0000"  >&lt;p&gt;Yes, we will update the 3.6.0 release notes with the current limitation. We can address these in 3.7.0.&lt;/p&gt;</comment>
                            <comment id="17774288" author="JIRAUSER300327" created="Thu, 12 Oct 2023 01:28:30 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=christo_lolov&quot; class=&quot;user-hover&quot; rel=&quot;christo_lolov&quot;&gt;christo_lolov&lt;/a&gt;&#160;&lt;/p&gt;

&lt;p&gt;I hope you&apos;re doing well. I wanted to ask if the open issue I&apos;m interested in has been started or not. If it hasn&apos;t been started yet, would it be possible for me to work on it?&lt;/p&gt;

&lt;p&gt;Thank you!&lt;/p&gt;</comment>
                            <comment id="17777739" author="christo_lolov" created="Fri, 20 Oct 2023 12:47:55 +0000"  >&lt;p&gt;Heya &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jimmywang611&quot; class=&quot;user-hover&quot; rel=&quot;jimmywang611&quot;&gt;jimmywang611&lt;/a&gt;, apologies for the delay. I am actively working on this, I was just gathering data, which I will share now.&lt;/p&gt;</comment>
                            <comment id="17778675" author="divijvaidya" created="Mon, 23 Oct 2023 13:45:03 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jimmywang611&quot; class=&quot;user-hover&quot; rel=&quot;jimmywang611&quot;&gt;jimmywang611&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=goyarpit&quot; class=&quot;user-hover&quot; rel=&quot;goyarpit&quot;&gt;goyarpit&lt;/a&gt; would you like to pick this for implementation?&lt;/p&gt;</comment>
                            <comment id="17778884" author="JIRAUSER301926" created="Tue, 24 Oct 2023 01:37:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=divijvaidya&quot; class=&quot;user-hover&quot; rel=&quot;divijvaidya&quot;&gt;divijvaidya&lt;/a&gt; Sure I am picking it up.&lt;/p&gt;</comment>
                            <comment id="17779426" author="divijvaidya" created="Wed, 25 Oct 2023 09:28:32 +0000"  >&lt;p&gt;Hey &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=goyarpit&quot; class=&quot;user-hover&quot; rel=&quot;goyarpit&quot;&gt;goyarpit&lt;/a&gt;&#160;&lt;/p&gt;

&lt;p&gt;I would suggest the following steps for you to handle this ticket.&lt;/p&gt;

&lt;p&gt;1. Understand how Kafka handles historically compacted without Tiered Storage (i.e. compacting was turned on, it compacted some data and then compaction was turned off, but the data remains) data for fetch request. The behaviour should be, if 10 is an offset which has been compacted away, and next available offset is 12, Kafka should return 12.&lt;br/&gt;
2. Write a test to mimic the situation described in description i.e. the last offset in a segment gets compacted away. Observe that the test fails.&lt;br/&gt;
3. Fix TS fetch part of the code to continue fetching data beyond the end of segment if offset is not present.&lt;/p&gt;

&lt;p&gt;Let me know if you have questions. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=christo_lolov&quot; class=&quot;user-hover&quot; rel=&quot;christo_lolov&quot;&gt;christo_lolov&lt;/a&gt; has also done some research on it and we will be happy to answer your questions.&lt;/p&gt;</comment>
                            <comment id="17779623" author="JIRAUSER301926" created="Wed, 25 Oct 2023 18:28:40 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=divijvaidya&quot; class=&quot;user-hover&quot; rel=&quot;divijvaidya&quot;&gt;divijvaidya&lt;/a&gt; for providing the initial steps  required to work on this. I will go through it.Do you remember any KIP created in past related to compacting feature ?&lt;/p&gt;</comment>
                            <comment id="17781616" author="JIRAUSER301926" created="Wed, 1 Nov 2023 06:41:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=divijvaidya&quot; class=&quot;user-hover&quot; rel=&quot;divijvaidya&quot;&gt;divijvaidya&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=satish.duggana&quot; class=&quot;user-hover&quot; rel=&quot;satish.duggana&quot;&gt;satish.duggana&lt;/a&gt; Correct me  here , We need to fix this also while executing copying segment &lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/blob/5785796f985aa294c12e670da221d086a7fa887c/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L693&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/5785796f985aa294c12e670da221d086a7fa887c/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L693&lt;/a&gt;&lt;br/&gt;
This also assumes endoffset of a given segment would be ( nextOffsetSegment - 1), which can&apos;t be true if it is a historically compacted segment. &lt;/p&gt;</comment>
                            <comment id="17781703" author="divijvaidya" created="Wed, 1 Nov 2023 11:28:13 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=goyarpit&quot; class=&quot;user-hover&quot; rel=&quot;goyarpit&quot;&gt;goyarpit&lt;/a&gt; That is an good observation but I think it doesn&apos;t impact the archive functionality. In TS, we assume that the end offset of a segment is nextSegmentBaseOffset -1. Now it might the be the case that this end offset doesn&apos;t exist in the segment because it has been removed by compaction but that is ok from an archive perspective. As long as entire code works with the assumption that the endOffset stored in RLMM may not actually exist in the segment and is just a pointer to where the segment should have ended in prior to compaction, then we should be good. As Christo mentioned in description, the only place in the code where this assumption is violated is on the read path. Hence, we can assume that the line you pointed to is correct and sets the contract, and we can make a change in read path to honor that contract.&lt;/p&gt;</comment>
                            <comment id="17781751" author="JIRAUSER301926" created="Wed, 1 Nov 2023 14:15:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=divijvaidya&quot; class=&quot;user-hover&quot; rel=&quot;divijvaidya&quot;&gt;divijvaidya&lt;/a&gt; I am not getting the archival functionality , From archival you mean once the segments has been expired because of retention mechanism ?&lt;/p&gt;

&lt;p&gt;Do you mean If we takes care of the endoffset value while reading it from the remote storage i.e. read offset from the next segment base offset instead of manipulating using endoffset. I found two usages where we are using it &lt;br/&gt;
1. One while  updating the logStartOffset  during cleanup of the log segment based on retention &lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/blob/5785796f985aa294c12e670da221d086a7fa887c/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L827&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/5785796f985aa294c12e670da221d086a7fa887c/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L827&lt;/a&gt;&lt;br/&gt;
2. During read path of the remote storage &lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/blob/5785796f985aa294c12e670da221d086a7fa887c/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L1263&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/5785796f985aa294c12e670da221d086a7fa887c/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L1263&lt;/a&gt;&lt;br/&gt;
We need to correct at both places ?&lt;/p&gt;</comment>
                            <comment id="17782492" author="JIRAUSER301926" created="Fri, 3 Nov 2023 09:44:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=divijvaidya&quot; class=&quot;user-hover&quot; rel=&quot;divijvaidya&quot;&gt;divijvaidya&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=christo_lolov&quot; class=&quot;user-hover&quot; rel=&quot;christo_lolov&quot;&gt;christo_lolov&lt;/a&gt; Need more help in understanding the use case here on this line &lt;br/&gt;
&lt;a href=&quot;https://github.com/satishd/kafka/blob/46c96f4868d51c84b43003bbb80bc07297016912/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L1339&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/satishd/kafka/blob/46c96f4868d51c84b43003bbb80bc07297016912/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L1339&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Let&apos;s say we are fetching the data for offset k &lt;/p&gt;

&lt;p&gt;1. We try to find leaderEpoch for the requested offset k &lt;br/&gt;
2. Using leader epoch and offset k , we try to find out the corresponding RemoteLogSegmentMetadata &lt;br/&gt;
3.  Using  RemoteLogSegmentMetadata  and offsetIndex we try to find the  position of the  highest possible entry less than the requested offset k. &lt;br/&gt;
4. Using the startposition fetched from 3rd step , we fetched remotesegInputStream  from RemoteStorageManager. &lt;br/&gt;
Now here we try to find the right record batch where our offset  lies within the corresponding batch. &lt;br/&gt;
But here IMP same use case arises. If it is a historically compacted topic and the record batch last offset  is a compacted one , then we should return the ideal batch instead of empty ?&lt;/p&gt;</comment>
                            <comment id="17782860" author="JIRAUSER301926" created="Sat, 4 Nov 2023 11:44:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=divijvaidya&quot; class=&quot;user-hover&quot; rel=&quot;divijvaidya&quot;&gt;divijvaidya&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=satish.duggana&quot; class=&quot;user-hover&quot; rel=&quot;satish.duggana&quot;&gt;satish.duggana&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=christo_lolov&quot; class=&quot;user-hover&quot; rel=&quot;christo_lolov&quot;&gt;christo_lolov&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=showuon&quot; class=&quot;user-hover&quot; rel=&quot;showuon&quot;&gt;showuon&lt;/a&gt; can anyone help me with the above query ?  &lt;br/&gt;
This would help me to proceed further. &lt;br/&gt;
&lt;b&gt;Summary&lt;/b&gt; &lt;br/&gt;
In a given segment we are trying to find the right record batch for the requested offset , but it may be possible the end offset of a given batch is already compacted  , for example &lt;br/&gt;
Lets say we ar looking to fetch data for offset 50 &lt;br/&gt;
A segments contain record batch with start and end offset in the following format, but 50th offset is historically compacted. &lt;br/&gt;
RB1&lt;span class=&quot;error&quot;&gt;&amp;#91;33-38&amp;#93;&lt;/span&gt;&lt;br/&gt;
RB2&lt;span class=&quot;error&quot;&gt;&amp;#91;42-49&amp;#93;&lt;/span&gt;&lt;br/&gt;
RB3&lt;span class=&quot;error&quot;&gt;&amp;#91;51-56&amp;#93;&lt;/span&gt;&lt;br/&gt;
Now if we try to fetch data  for 50th offset  it would return null. Is it something expected or a bug ?  If it is how would we identify which record batch needs to be returned ?&lt;br/&gt;
&lt;a href=&quot;https://github.com/satishd/kafka/blob/46c96f4868d51c84b43003bbb80bc07297016912/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L1339&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/satishd/kafka/blob/46c96f4868d51c84b43003bbb80bc07297016912/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L1339&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17782907" author="JIRAUSER301926" created="Sat, 4 Nov 2023 16:37:39 +0000"  >&lt;p&gt;I  just found the answer for the above query &lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/blob/5785796f985aa294c12e670da221d086a7fa887c/clients/src/main/java/org/apache/kafka/common/record/RecordBatch.java#L118&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/5785796f985aa294c12e670da221d086a7fa887c/clients/src/main/java/org/apache/kafka/common/record/RecordBatch.java#L118&lt;/a&gt;&lt;br/&gt;
Last offset of record batch will always be equal to the value before compaction. &lt;/p&gt;</comment>
                            <comment id="17783559" author="divijvaidya" created="Tue, 7 Nov 2023 10:08:13 +0000"  >&lt;p&gt;Hey &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=goyarpit&quot; class=&quot;user-hover&quot; rel=&quot;goyarpit&quot;&gt;goyarpit&lt;/a&gt; - apologies for the delay. I will intermittently respond to this ticket in the next few weeks as I am going on a vacation. Let me try to answer your pending queries:&lt;/p&gt;

&lt;p&gt;&amp;gt; Last offset of record batch will always be equal to the value before compaction.&lt;/p&gt;

&lt;p&gt;Correct. When compaction creates a new merged segment, it keeps the base and end offset same as previous non-compacted segments. Which means that segment base and last offset will always be continuous even if the data inside has been removed/compacted.&lt;/p&gt;


&lt;p&gt;&amp;gt; Now if we try to fetch data for 50th offset it would return null. Is it something expected or a bug ?&lt;/p&gt;

&lt;p&gt;It&apos;s a bug. You can check how local storage handles it at &lt;a href=&quot;https://github.com/apache/kafka/blob/317f61dfd9a7f1443cf75b6a32568d1c81984d08/core/src/main/scala/kafka/log/LocalLog.scala#L425&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/317f61dfd9a7f1443cf75b6a32568d1c81984d08/core/src/main/scala/kafka/log/LocalLog.scala#L425&lt;/a&gt; We look into the next higher segment i.e. in this case we will look into RB3 and offsets starting from 51. Note that read() calls translateOffset() which returns the first message with offset &amp;gt;= the requested offset. Note the &amp;gt; here. That is how 51 will be returned.&lt;br/&gt;
We need to ensure that RemoteLogManager.read() behaves the same way.&lt;/p&gt;


&lt;p&gt;I would suggest that you try the following and this should fail:&lt;br/&gt;
1. Create multiple segments&lt;br/&gt;
2. Compact away (the last offsets in a few of these segments)&lt;br/&gt;
3. disable compaction. Turn on Tiered Storage.&lt;br/&gt;
4. These segments should get uploaded successfully.&lt;br/&gt;
5. Try to read the last offset which was compacted away. As per the read contract of offsets which are removed during compaction, you should get available offset after that offset. i.e. if you are asking for 3 and 3 has been removed by compaction, you will get 4 assuming 4 is available.&#160;&lt;/p&gt;

&lt;p&gt;This should work for TS when we are reading 3 from TS.&lt;/p&gt;</comment>
                            <comment id="17786299" author="JIRAUSER301926" created="Wed, 15 Nov 2023 10:34:21 +0000"  >&lt;p&gt;Hey &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=divijvaidya&quot; class=&quot;user-hover&quot; rel=&quot;divijvaidya&quot;&gt;divijvaidya&lt;/a&gt; I am successfully able to reproduce the issue locally. &lt;br/&gt;
&lt;b&gt;Configuration&lt;/b&gt; &lt;br/&gt;
1. Create Topic name - test20 partition 0 &lt;br/&gt;
2. add segment.bytes as 100 for quicker roll of segments &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
bin/kafka-configs.sh --bootstrap-server localhost:9092 --alter --entity-type topics --entity-name test20  --add-config segment.bytes=100
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;3. Enable clean up compact policy &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
bin/kafka-configs.sh --bootstrap-server localhost:9092 --alter --entity-type topics --entity-name test20  --add-config cleanup.policy=compact
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 
&lt;p&gt;4. *Produce some messages *&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test20 --property &lt;span class=&quot;code-quote&quot;&gt;&quot;parse.key=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt; --property &lt;span class=&quot;code-quote&quot;&gt;&quot;key.separator=:&quot;&lt;/span&gt;
&amp;gt;1:1
&amp;gt;1:2
&amp;gt;1:3
&amp;gt;1:4
&amp;gt;1:5
&amp;gt;1:6
&amp;gt;1:7
&amp;gt;1:8
&amp;gt;1:9
&amp;gt;1:10
&amp;gt;1:11
&amp;gt;1:12
&amp;gt;1:13
&amp;gt;1:14
&amp;gt;1:15
&amp;gt;1:16
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;5. When we try to consume message from the topic without remote storage enable &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
(base) &#10140;  kafka git:(trunk) &#10007; bin/kafka-console-consumer.sh  --bootstrap-server localhost:9092 --topic test20  --offset 0 --partition 0 --property print.offset=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
Offset:14	15
Offset:15	16
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;6. Disable the compact policy &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
bin/kafka-configs.sh --bootstrap-server localhost:9092 --alter --entity-type topics --entity-name test20  --delete-config cleanup.policy
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;7. Enable remote storage for the required topic &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
bin/kafka-configs.sh --bootstrap-server localhost:9092 --alter --entity-type topics --entity-name test20  --add-config remote.storage.enable=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;8. The rolled over segments has been moved to tiered storage topic. Attached screenshot for the reference. (tieredtopicconfiglist)&lt;br/&gt;
9. While executing consumer.sh for the topic , it return nothing. &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
bin/kafka-console-consumer.sh  --bootstrap-server localhost:9092 --topic test20  --offset 0 --partition 0 --property print.offset=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;10. As it was a historically compacted topic with only key 1 , most of the log segments had zero bytes.Please refer (tieredtopicconfiglist) screenshot.Only 14.log and 15.log has some data. &lt;br/&gt;
11. When we try fetching it from the remote storage , it looks for the first batch assuming it would always exist , but in this case 0.log has zero bytes and  batch value would be  null because segment is empty.&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/record/FileLogInputStream.java#L65((&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/record/FileLogInputStream.java#L65((&lt;/a&gt;  0 &amp;gt;= 0 -11))&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L1411&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/trunk/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L1411&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L1277&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/trunk/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L1277&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;12. This seems to be a critical bug , and it should be inline with the local log fetch mechanism , ie if batch is null , it should fetch the higher segment and continue till the end offset. &lt;/p&gt;

&lt;p&gt;Should i create a different bug for this ?  The functionality is broken here.&lt;/p&gt;




</comment>
                            <comment id="17786456" author="divijvaidya" created="Wed, 15 Nov 2023 18:02:07 +0000"  >&lt;p&gt;Nice work on having a reproducer Arpit! &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/thumbs_up.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&#160;&lt;/p&gt;

&lt;p&gt;From a criticality perspective, we are treating all compaction related bugs for 3.7.0 and aren&apos;t backporting to 3.6.1. Currently it&apos;s marked as blocker but IMO it&apos;s a blocker for TS production launch instead of a blocker for 3.7.0. Let&apos;s fix it as part of this Jira itself. We can create new ones if we find more bugs on fetch path related to compaction. One request I would have for you is to add exhaustive unit tests for such historically compacted cases. I am on vacation for next one month so my responses may not be fast, but other folks in the community who are familiar with TS will provide code review here. cc: &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=showuon&quot; class=&quot;user-hover&quot; rel=&quot;showuon&quot;&gt;showuon&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=satish.duggana&quot; class=&quot;user-hover&quot; rel=&quot;satish.duggana&quot;&gt;satish.duggana&lt;/a&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17788496" author="JIRAUSER301926" created="Tue, 21 Nov 2023 18:08:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=divijvaidya&quot; class=&quot;user-hover&quot; rel=&quot;divijvaidya&quot;&gt;divijvaidya&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=satish.duggana&quot; class=&quot;user-hover&quot; rel=&quot;satish.duggana&quot;&gt;satish.duggana&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=showuon&quot; class=&quot;user-hover&quot; rel=&quot;showuon&quot;&gt;showuon&lt;/a&gt; Any suggestion on how to fetch remotelogsegment metadata of a segment with the smallest offset strictly greater than the given offset. As of now I see the only option to list all remotelogsegment metadata and filter it out.&lt;/p&gt;

&lt;p&gt;Should we introduce another method  in RemoteLogMetadataManager to fetch higher segment for a given offset and leader epoch ?&lt;/p&gt;</comment>
                            <comment id="17798962" author="enether" created="Wed, 20 Dec 2023 12:12:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=satish.duggana&quot; class=&quot;user-hover&quot; rel=&quot;satish.duggana&quot;&gt;satish.duggana&lt;/a&gt; should we consider this as a blocker for the 3.7 release? Seems like it&apos;s been marked as such for a while, but I don&apos;t necessarily see high priority action into alleviating it.&lt;/p&gt;</comment>
                            <comment id="17799399" author="JIRAUSER301926" created="Thu, 21 Dec 2023 12:11:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enether&quot; class=&quot;user-hover&quot; rel=&quot;enether&quot;&gt;enether&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=satish.duggana&quot; class=&quot;user-hover&quot; rel=&quot;satish.duggana&quot;&gt;satish.duggana&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=divijvaidya&quot; class=&quot;user-hover&quot; rel=&quot;divijvaidya&quot;&gt;divijvaidya&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enether&quot; class=&quot;user-hover&quot; rel=&quot;enether&quot;&gt;enether&lt;/a&gt; I am currently working on the fix. Hopefully will create a PR by EOD.&lt;/p&gt;</comment>
                            <comment id="17799416" author="divijvaidya" created="Thu, 21 Dec 2023 12:54:25 +0000"  >&lt;p&gt;Hey &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enether&quot; class=&quot;user-hover&quot; rel=&quot;enether&quot;&gt;enether&lt;/a&gt;&#160;&lt;br/&gt;
I will not consider this as a blocker for 3.7.0 since Tiered Storage is not production ready in 3.7.0. We will continue to carry this bug (as we did in 3.6) until it is fixed. If we are able to fix this in timeline for 3.7, well and good but if not, we will ship this in 3.8.&lt;/p&gt;

&lt;p&gt;This is a blocker for TS production ready status but that will be captured somewhere else.&lt;/p&gt;</comment>
                            <comment id="17799532" author="JIRAUSER301926" created="Thu, 21 Dec 2023 18:11:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=divijvaidya&quot; class=&quot;user-hover&quot; rel=&quot;divijvaidya&quot;&gt;divijvaidya&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=satish.duggana&quot; class=&quot;user-hover&quot; rel=&quot;satish.duggana&quot;&gt;satish.duggana&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=showuon&quot; class=&quot;user-hover&quot; rel=&quot;showuon&quot;&gt;showuon&lt;/a&gt; Pr for review &lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/pull/15060&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/15060&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17806413" author="satish.duggana" created="Sun, 14 Jan 2024 00:52:46 +0000"  >&lt;p&gt;&lt;a href=&quot;https://github.com/apache/kafka/pull/15060&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;PR-15060&lt;/a&gt; addresses this issue partially and we have a followup &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-16088&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;KAFKA-16088&lt;/a&gt; on the remaining cases.&lt;/p&gt;</comment>
                            <comment id="17877795" author="cmccabe" created="Thu, 29 Aug 2024 17:20:14 +0000"  >&lt;p&gt;Since this didn&apos;t block the 3.6, 3.7, or 3.8 releases it seems like a safe bet that it won&apos;t block 3.9. I changed the target version on this JIRA and &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-16088&quot; title=&quot; Not reading active segments  when RemoteFetch return Empty Records.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-16088&quot;&gt;KAFKA-16088&lt;/a&gt; to 4.0. Hopefully we can address it in that release.&lt;/p&gt;</comment>
                            <comment id="17911536" author="dajac" created="Thu, 9 Jan 2025 14:12:33 +0000"  >&lt;p&gt;Removed the fix version as this work is not planned in 4.0.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="13563789">KAFKA-16088</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310460">
                    <name>Child-Issue</name>
                                                                <inwardlinks description="is a child of">
                                        <issuelink>
            <issuekey id="13582462">KAFKA-16947</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13545980">KAFKA-15301</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="13064413" name="Screenshot 2023-11-15 at 3.47.54 PM.png" size="99377" author="goyarpit" created="Wed, 15 Nov 2023 10:18:09 +0000"/>
                            <attachment id="13064415" name="tieredtopicloglist.png" size="994248" author="goyarpit" created="Wed, 15 Nov 2023 10:25:07 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            43 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1jwxk:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>