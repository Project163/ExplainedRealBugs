<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:04:32 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6119] Silent Data Loss in Kafka011 Transactional Producer</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6119</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Kafka can lose data published by a transactional &lt;tt&gt;KafkaProducer&lt;/tt&gt; under some circumstances, i.e., data that should be committed atomically may not be fully visible from a consumer with &lt;tt&gt;read_committed&lt;/tt&gt; isolation level.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Steps to reproduce:&lt;/b&gt;&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Set &lt;tt&gt;transaction.timeout.ms&lt;/tt&gt; to a low value such as &lt;tt&gt;100&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;Publish two messages in one transaction to different partitions of a topic with a sufficiently long time in-between the messages (e.g., 70 s).&lt;/li&gt;
	&lt;li&gt;Only the second message is visible with &lt;tt&gt;read_committed&lt;/tt&gt; isolation level.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;See &lt;br/&gt;
&lt;a href=&quot;https://github.com/GJL/kafka011-transactional-producer-bug-demo/blob/master/src/main/java/com/garyyao/App.java&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/GJL/kafka011-transactional-producer-bug-demo/blob/master/src/main/java/com/garyyao/App.java&lt;/a&gt; for a full example. Detailed instructions can be found in the &lt;tt&gt;README.md&lt;/tt&gt;: &lt;a href=&quot;https://github.com/GJL/kafka011-transactional-producer-bug-demo&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/GJL/kafka011-transactional-producer-bug-demo&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Why is this possible?&lt;/b&gt;&lt;br/&gt;
Because the transaction timeout is set to a low value, the transaction will be rolled back quickly after the first message is sent. Indeed, in the broker the following logs could be found:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[2017-10-25 22:54:58,224] INFO [Transaction Coordinator 0]: Initialized transactionalId test-producer-1508964897483 with producerId 5 and producer epoch 0 on partition __transaction_state-10 (kafka.coordinator.transaction.TransactionCoordinator)
[2017-10-25 22:55:24,260] INFO [Transaction Coordinator 0]: Completed rollback ongoing transaction of transactionalId: test-producer-1508964897483 due to timeout (kafka.coordinator.transaction.TransactionCoordinator)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After rollback, the second message is sent to a different partition than the first message. &lt;br/&gt;
Upon, transaction commit, &lt;tt&gt;org.apache.kafka.clients.producer.internals.TransactionManager&lt;/tt&gt; may enqueue the request &lt;tt&gt;addPartitionsToTransactionHandler&lt;/tt&gt;:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; TransactionalRequestResult beginCompletingTransaction(TransactionResult transactionResult) {
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!newPartitionsInTransaction.isEmpty())
            enqueueRequest(addPartitionsToTransactionHandler());
        EndTxnRequest.Builder builder = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; EndTxnRequest.Builder(transactionalId, producerIdAndEpoch.producerId,
                producerIdAndEpoch.epoch, transactionResult);
        EndTxnHandler handler = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; EndTxnHandler(builder);
        enqueueRequest(handler);
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; handler.result;
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As can be seen, the condition is fulfilled if &lt;tt&gt;newPartitionsInTransaction&lt;/tt&gt; is non-empty. I suspect because the second message goes to a different partition, this condition is satisfied.&lt;/p&gt;

&lt;p&gt;In &lt;tt&gt;KafkaApis.scala&lt;/tt&gt;, I can see that &lt;tt&gt;handleAddPartitionToTxnRequest&lt;/tt&gt; may eventually call &lt;tt&gt;TransactionMetadata#prepareAddPartitions&lt;/tt&gt;:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 def prepareAddPartitions(addedTopicPartitions: immutable.Set[TopicPartition], updateTimestamp: &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;): TxnTransitMetadata = {
    val newTxnStartTimestamp = state match {
      &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; Empty | CompleteAbort | CompleteCommit =&amp;gt; updateTimestamp
      &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; _ =&amp;gt; txnStartTimestamp
    }

    prepareTransitionTo(Ongoing, producerId, producerEpoch, txnTimeoutMs, (topicPartitions ++ addedTopicPartitions).toSet,
      newTxnStartTimestamp, updateTimestamp)
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that the method&apos;s first argument &lt;tt&gt;newState&lt;/tt&gt; of is always &lt;b&gt;Ongoing&lt;/b&gt; here. I suspect that this puts the transaction, which should be aborted, to &lt;em&gt;Ongoing&lt;/em&gt; again.&lt;/p&gt;
</description>
                <environment>openjdk version &amp;quot;1.8.0_144&amp;quot;&lt;br/&gt;
OpenJDK Runtime Environment (Zulu 8.23.0.3-macosx) (build 1.8.0_144-b01)&lt;br/&gt;
OpenJDK 64-Bit Server VM (Zulu 8.23.0.3-macosx) (build 25.144-b01, mixed mode)</environment>
        <key id="13112102">KAFKA-6119</key>
            <summary>Silent Data Loss in Kafka011 Transactional Producer</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="apurva">Apurva Mehta</assignee>
                                    <reporter username="gyao">Gary Y.</reporter>
                        <labels>
                            <label>reliability</label>
                    </labels>
                <created>Wed, 25 Oct 2017 21:12:09 +0000</created>
                <updated>Tue, 31 Oct 2017 15:52:24 +0000</updated>
                            <resolved>Fri, 27 Oct 2017 06:27:07 +0000</resolved>
                                    <version>0.11.0.0</version>
                    <version>0.11.0.1</version>
                                    <fixVersion>0.11.0.2</fixVersion>
                    <fixVersion>1.0.0</fixVersion>
                                    <component>core</component>
                    <component>producer </component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="16219534" author="ijuma" created="Wed, 25 Oct 2017 21:15:35 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurva&quot; class=&quot;user-hover&quot; rel=&quot;apurva&quot;&gt;apurva&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16219548" author="apurva" created="Wed, 25 Oct 2017 21:26:31 +0000"  >&lt;p&gt;Thanks for the report.&lt;/p&gt;

&lt;p&gt;Can you share the actual kafka data logs for the partitions in question? Could you also share the TRACE level logging for the producer? &lt;/p&gt;

&lt;p&gt;The producer epoch is bumped on a transaction timeout, so any future messages from the producer with the old epoch should result in a &lt;tt&gt;ProducerFencedException&lt;/tt&gt;.  So in your program, the second send should result in a &lt;tt&gt;ProducerFencedException&lt;/tt&gt; and no further operations should be allowed on the producer. &lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
Apurva&lt;/p&gt;</comment>
                            <comment id="16219557" author="gyao" created="Wed, 25 Oct 2017 21:32:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurva&quot; class=&quot;user-hover&quot; rel=&quot;apurva&quot;&gt;apurva&lt;/a&gt; I have included a link to the runnable sources in the ticket. Can you run the program and verify the behaviour? If you still need the logs, I can provide them tomorrow as it is very late now in my time zone.&lt;/p&gt;</comment>
                            <comment id="16219689" author="apurva" created="Wed, 25 Oct 2017 22:44:27 +0000"  >&lt;p&gt;Thanks Gary. This indeed looks like a bug. I downloaded your program and ran it. Here are the kafka data logs for the two partitions:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;amehta-macbook-pro:kafka-logs apurva$ ~/workspace/confluent/kafka/bin/kafka-run-class.sh kafka.tools.DumpLogSegments --files producer-test-1/00000000000000000000.log  --deep-iteration
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/Users/apurva/workspace/confluent/kafka/core/build/dependant-libs-2.11.11/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/apurva/workspace/confluent/kafka/tools/build/dependant-libs-2.11.11/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/apurva/workspace/confluent/kafka/connect/api/build/dependant-libs/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/apurva/workspace/confluent/kafka/connect/transforms/build/dependant-libs/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/apurva/workspace/confluent/kafka/connect/runtime/build/dependant-libs/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/apurva/workspace/confluent/kafka/connect/file/build/dependant-libs/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/apurva/workspace/confluent/kafka/connect/json/build/dependant-libs/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Dumping producer-test-1/00000000000000000000.log
Starting offset: 0
offset: 0 position: 0 CreateTime: 1508970707070 isvalid: true keysize: -1 valuesize: 23 magic: 2 compresscodec: NONE producerId: 0 sequence: 0 isTransactional: true headerKeys: []
offset: 1 position: 91 CreateTime: 1508970707085 isvalid: true keysize: 4 valuesize: 6 magic: 2 compresscodec: NONE producerId: 0 sequence: -1 isTransactional: true headerKeys: [] endTxnMarker: COMMIT coordinatorEpoch: 0
amehta-macbook-pro:kafka-logs apurva$ ~/workspace/confluent/kafka/bin/kafka-run-class.sh kafka.tools.DumpLogSegments --files producer-test-0/00000000000000000000.log  --deep-iterati
on
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/Users/apurva/workspace/confluent/kafka/core/build/dependant-libs-2.11.11/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/apurva/workspace/confluent/kafka/tools/build/dependant-libs-2.11.11/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/apurva/workspace/confluent/kafka/connect/api/build/dependant-libs/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/apurva/workspace/confluent/kafka/connect/transforms/build/dependant-libs/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/apurva/workspace/confluent/kafka/connect/runtime/build/dependant-libs/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/apurva/workspace/confluent/kafka/connect/file/build/dependant-libs/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/apurva/workspace/confluent/kafka/connect/json/build/dependant-libs/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Dumping producer-test-0/00000000000000000000.log
Starting offset: 0
offset: 0 position: 0 CreateTime: 1508970637066 isvalid: true keysize: -1 valuesize: 23 magic: 2 compresscodec: NONE producerId: 0 sequence: 0 isTransactional: true headerKeys: []
offset: 1 position: 91 CreateTime: 1508970666872 isvalid: true keysize: 4 valuesize: 6 magic: 2 compresscodec: NONE producerId: 0 sequence: -1 isTransactional: true headerKeys: [] endTxnMarker: ABORT coordinatorEpoch: 0
amehta-macbook-pro:kafka-logs apurva$
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And here is the trace level output from the kafka producer: &lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;5:30:36.041 [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.11.0.1
15:30:36.041 [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c2a0d5f9b1f45bf5
15:30:36.041 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer with client id producer-1 created
15:30:36.042 [main] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] Transition from state UNINITIALIZED to INITIALIZING
15:30:36.042 [main] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] ProducerId set to -1 with epoch -1
15:30:36.048 [main] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] Enqueuing transactional request (type=InitProducerIdRequest, transactionalId=test-producer-1508970635810, transactionTimeoutMs=100)
15:30:36.051 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] Enqueuing transactional request (type=FindCoordinatorRequest, coordinatorKey=test-producer-1508970635810, coordinatorType=TRANSACTION)
15:30:36.051 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] Enqueuing transactional request (type=InitProducerIdRequest, transactionalId=test-producer-1508970635810, transactionTimeoutMs=100)
15:30:36.154 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node localhost:9092 (id: -1 rack: null)
15:30:36.211 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
15:30:36.211 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
15:30:36.212 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
15:30:36.214 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 326640, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node -1
15:30:36.215 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1. Fetching API versions.
15:30:36.215 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node -1.
15:30:36.286 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node -1: (Produce(0): 0 to 5 [usable: 3], Fetch(1): 0 to 6 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 5 [usable: 4], LeaderAndIsr(4): 0 to 1 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 3], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0], UNKNOWN(34): 0, UNKNOWN(35): 0, UNKNOWN(36): 0, UNKNOWN(37): 0)
15:30:36.287 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - [TransactionalId test-producer-1508970635810] Sending transactional request (type=FindCoordinatorRequest, coordinatorKey=test-producer-1508970635810, coordinatorType=TRANSACTION) to node localhost:9092 (id: -1 rack: null)
15:30:36.323 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] Enqueuing transactional request (type=FindCoordinatorRequest, coordinatorKey=test-producer-1508970635810, coordinatorType=TRANSACTION)
15:30:36.426 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - [TransactionalId test-producer-1508970635810] Sending transactional request (type=FindCoordinatorRequest, coordinatorKey=test-producer-1508970635810, coordinatorType=TRANSACTION) to node localhost:9092 (id: -1 rack: null)
15:30:36.430 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] Enqueuing transactional request (type=FindCoordinatorRequest, coordinatorKey=test-producer-1508970635810, coordinatorType=TRANSACTION)
15:30:36.535 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - [TransactionalId test-producer-1508970635810] Sending transactional request (type=FindCoordinatorRequest, coordinatorKey=test-producer-1508970635810, coordinatorType=TRANSACTION) to node localhost:9092 (id: -1 rack: null)
15:30:36.538 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] Enqueuing transactional request (type=FindCoordinatorRequest, coordinatorKey=test-producer-1508970635810, coordinatorType=TRANSACTION)
15:30:36.642 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - [TransactionalId test-producer-1508970635810] Sending transactional request (type=FindCoordinatorRequest, coordinatorKey=test-producer-1508970635810, coordinatorType=TRANSACTION) to node localhost:9092 (id: -1 rack: null)
15:30:36.648 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] Enqueuing transactional request (type=FindCoordinatorRequest, coordinatorKey=test-producer-1508970635810, coordinatorType=TRANSACTION)
15:30:36.751 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - [TransactionalId test-producer-1508970635810] Sending transactional request (type=FindCoordinatorRequest, coordinatorKey=test-producer-1508970635810, coordinatorType=TRANSACTION) to node localhost:9092 (id: -1 rack: null)
15:30:36.755 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] Enqueuing transactional request (type=FindCoordinatorRequest, coordinatorKey=test-producer-1508970635810, coordinatorType=TRANSACTION)
15:30:36.859 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - [TransactionalId test-producer-1508970635810] Sending transactional request (type=FindCoordinatorRequest, coordinatorKey=test-producer-1508970635810, coordinatorType=TRANSACTION) to node localhost:9092 (id: -1 rack: null)
15:30:36.871 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 10.200.6.85:9092 (id: 0 rack: null)
15:30:36.871 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
15:30:36.872 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
15:30:36.872 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
15:30:36.872 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 310308, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node 0
15:30:36.872 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0. Fetching API versions.
15:30:36.872 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating API versions fetch from node 0.
15:30:36.873 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Recorded API versions for node 0: (Produce(0): 0 to 5 [usable: 3], Fetch(1): 0 to 6 [usable: 5], Offsets(2): 0 to 2 [usable: 2], Metadata(3): 0 to 5 [usable: 4], LeaderAndIsr(4): 0 to 1 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 3], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 3 [usable: 3], OffsetFetch(9): 0 to 3 [usable: 3], FindCoordinator(10): 0 to 1 [usable: 1], JoinGroup(11): 0 to 2 [usable: 2], Heartbeat(12): 0 to 1 [usable: 1], LeaveGroup(13): 0 to 1 [usable: 1], SyncGroup(14): 0 to 1 [usable: 1], DescribeGroups(15): 0 to 1 [usable: 1], ListGroups(16): 0 to 1 [usable: 1], SaslHandshake(17): 0 to 1 [usable: 0], ApiVersions(18): 0 to 1 [usable: 1], CreateTopics(19): 0 to 2 [usable: 2], DeleteTopics(20): 0 to 1 [usable: 1], DeleteRecords(21): 0 [usable: 0], InitProducerId(22): 0 [usable: 0], OffsetForLeaderEpoch(23): 0 [usable: 0], AddPartitionsToTxn(24): 0 [usable: 0], AddOffsetsToTxn(25): 0 [usable: 0], EndTxn(26): 0 [usable: 0], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 [usable: 0], DescribeAcls(29): 0 [usable: 0], CreateAcls(30): 0 [usable: 0], DeleteAcls(31): 0 [usable: 0], DescribeConfigs(32): 0 [usable: 0], AlterConfigs(33): 0 [usable: 0], UNKNOWN(34): 0, UNKNOWN(35): 0, UNKNOWN(36): 0, UNKNOWN(37): 0)
15:30:36.978 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - [TransactionalId test-producer-1508970635810] Sending transactional request (type=InitProducerIdRequest, transactionalId=test-producer-1508970635810, transactionTimeoutMs=100) to node 10.200.6.85:9092 (id: 0 rack: null)
15:30:37.052 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] ProducerId set to 0 with epoch 0
15:30:37.052 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] Transition from state INITIALIZING to READY
15:30:37.052 [main] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] Transition from state READY to IN_TRANSACTION
15:30:37.053 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request (type=MetadataRequest, topics=producer-test) to node localhost:9092 (id: -1 rack: null)
15:30:37.061 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = MWSsYEsXSIKPeqPAE1C9rg, nodes = [10.200.6.85:9092 (id: 0 rack: null)], partitions = [Partition(topic = producer-test, partition = 1, leader = 0, replicas = [0], isr = [0]), Partition(topic = producer-test, partition = 0, leader = 0, replicas = [0], isr = [0])])
15:30:37.066 [main] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] Begin adding new partition producer-test-0 to transaction
15:30:37.071 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] Enqueuing transactional request (type=AddPartitionsToTxnRequest, transactionalId=test-producer-1508970635810, producerId=0, producerEpoch=0, partitions=[producer-test-0])
15:30:37.072 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - [TransactionalId test-producer-1508970635810] Sending transactional request (type=AddPartitionsToTxnRequest, transactionalId=test-producer-1508970635810, producerId=0, producerEpoch=0, partitions=[producer-test-0]) to node 10.200.6.85:9092 (id: 0 rack: null)
15:30:37.081 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] Successfully added partitions [producer-test-0] to transaction
15:30:37.081 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - Assigning sequence number 0 from producer (producerId=0, epoch=0) to dequeued batch from partition producer-test-0 bound for 10.200.6.85:9092 (id: 0 rack: null).
15:30:37.083 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.producer-test.records-per-batch
15:30:37.084 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.producer-test.bytes
15:30:37.084 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.producer-test.compression-rate
15:30:37.084 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.producer-test.record-retries
15:30:37.084 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.producer-test.record-errors
15:30:37.110 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Incremented sequence number for topic-partition producer-test-0 to 1
15:31:47.070 [main] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] Begin adding new partition producer-test-1 to transaction
15:31:47.071 [main] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] Transition from state IN_TRANSACTION to COMMITTING_TRANSACTION
15:31:47.072 [main] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] Enqueuing transactional request (type=AddPartitionsToTxnRequest, transactionalId=test-producer-1508970635810, producerId=0, producerEpoch=0, partitions=[producer-test-1])
15:31:47.073 [main] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] Enqueuing transactional request (type=EndTxnRequest, transactionalId=test-producer-1508970635810, producerId=0, producerEpoch=0, result=COMMIT)
15:31:47.073 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - [TransactionalId test-producer-1508970635810] Sending transactional request (type=AddPartitionsToTxnRequest, transactionalId=test-producer-1508970635810, producerId=0, producerEpoch=0, partitions=[producer-test-1]) to node 10.200.6.85:9092 (id: 0 rack: null)
15:31:47.078 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] Successfully added partitions [producer-test-1] to transaction
15:31:47.078 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - Assigning sequence number 0 from producer (producerId=0, epoch=0) to dequeued batch from partition producer-test-1 bound for 10.200.6.85:9092 (id: 0 rack: null).
15:31:47.081 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Incremented sequence number for topic-partition producer-test-1 to 1
15:31:47.082 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - [TransactionalId test-producer-1508970635810] Sending transactional request (type=EndTxnRequest, transactionalId=test-producer-1508970635810, producerId=0, producerEpoch=0, result=COMMIT) to node 10.200.6.85:9092 (id: 0 rack: null)
15:31:47.085 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [TransactionalId test-producer-1508970635810] Transition from state COMMITTING_TRANSACTION to READY
15:31:47.085 [main] INFO org.apache.kafka.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
15:31:47.085 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Beginning shutdown of Kafka producer I/O thread, sending remaining records.
15:31:47.088 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
15:31:47.088 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
15:31:47.088 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
15:31:47.088 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
15:31:47.088 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
15:31:47.088 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
15:31:47.088 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
15:31:47.089 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
15:31:47.089 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
15:31:47.089 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
15:31:47.089 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-0.bytes-sent
15:31:47.089 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-0.bytes-received
15:31:47.089 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-0.latency
15:31:47.089 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Shutdown of Kafka producer I/O thread has completed.
15:31:47.089 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer with client id producer-1 has been closed
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As we can see, the message to partition 0 is aborted, but the second one is erroneously committed. Fencing isn&apos;t working as it should here. This can be seen from the dump of the transaction log: &lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;amehta-macbook-pro:__transaction_state-35 apurva$ ~/workspace/confluent/kafka/bin/kafka-run-class.sh kafka.tools.DumpLogSegments --transaction-log-decoder --files 00000000000000000000.log --deep-iteration
Dumping 00000000000000000000.log
Starting offset: 0
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/Users/apurva/workspace/confluent/kafka/core/build/dependant-libs-2.11.11/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/apurva/workspace/confluent/kafka/tools/build/dependant-libs-2.11.11/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/apurva/workspace/confluent/kafka/connect/api/build/dependant-libs/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/apurva/workspace/confluent/kafka/connect/transforms/build/dependant-libs/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/apurva/workspace/confluent/kafka/connect/runtime/build/dependant-libs/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/apurva/workspace/confluent/kafka/connect/file/build/dependant-libs/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/Users/apurva/workspace/confluent/kafka/connect/json/build/dependant-libs/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
offset: 0 position: 0 CreateTime: 1508970637004 isvalid: true keysize: 31 valuesize: 37 magic: 2 compresscodec: NONE producerId: -1 sequence: -1 isTransactional: false headerKeys: [] key: transactionalId=test-producer-1508970635810 payload: producerId:0,producerEpoch:0,state=Empty,partitions=Set(),txnLastUpdateTimestamp=1508970636999,txnTimeoutMs=100
offset: 1 position: 137 CreateTime: 1508970637077 isvalid: true keysize: 31 valuesize: 60 magic: 2 compresscodec: NONE producerId: -1 sequence: -1 isTransactional: false headerKeys: [] key: transactionalId=test-producer-1508970635810 payload: producerId:0,producerEpoch:0,state=Ongoing,partitions=Set(producer-test-0),txnLastUpdateTimestamp=1508970637076,txnTimeoutMs=100
offset: 2 position: 297 CreateTime: 1508970666849 isvalid: true keysize: 31 valuesize: 60 magic: 2 compresscodec: NONE producerId: -1 sequence: -1 isTransactional: false headerKeys: [] key: transactionalId=test-producer-1508970635810 payload: producerId:0,producerEpoch:0,state=PrepareAbort,partitions=Set(producer-test-0),txnLastUpdateTimestamp=1508970666848,txnTimeoutMs=100
offset: 3 position: 457 CreateTime: 1508970666884 isvalid: true keysize: 31 valuesize: 37 magic: 2 compresscodec: NONE producerId: -1 sequence: -1 isTransactional: false headerKeys: [] key: transactionalId=test-producer-1508970635810 payload: producerId:0,producerEpoch:0,state=CompleteAbort,partitions=Set(),txnLastUpdateTimestamp=1508970666852,txnTimeoutMs=100
offset: 4 position: 594 CreateTime: 1508970707075 isvalid: true keysize: 31 valuesize: 60 magic: 2 compresscodec: NONE producerId: -1 sequence: -1 isTransactional: false headerKeys: [] key: transactionalId=test-producer-1508970635810 payload: producerId:0,producerEpoch:0,state=Ongoing,partitions=Set(producer-test-1),txnLastUpdateTimestamp=1508970707074,txnTimeoutMs=100
offset: 5 position: 754 CreateTime: 1508970707083 isvalid: true keysize: 31 valuesize: 60 magic: 2 compresscodec: NONE producerId: -1 sequence: -1 isTransactional: false headerKeys: [] key: transactionalId=test-producer-1508970635810 payload: producerId:0,producerEpoch:0,state=PrepareCommit,partitions=Set(producer-test-1),txnLastUpdateTimestamp=1508970707083,txnTimeoutMs=100
offset: 6 position: 914 CreateTime: 1508970707086 isvalid: true keysize: 31 valuesize: 37 magic: 2 compresscodec: NONE producerId: -1 sequence: -1 isTransactional: false headerKeys: [] key: transactionalId=test-producer-1508970635810 payload: producerId:0,producerEpoch:0,state=CompleteCommit,partitions=Set(),txnLastUpdateTimestamp=1508970707084,txnTimeoutMs=100
amehta-macbook-pro:__transaction_state-35 apurva$

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The transaction state doesn&apos;t have an epoch bump. Hence the second send succeeded.&lt;/p&gt;</comment>
                            <comment id="16219697" author="ijuma" created="Wed, 25 Oct 2017 22:57:42 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurva&quot; class=&quot;user-hover&quot; rel=&quot;apurva&quot;&gt;apurva&lt;/a&gt;, does this affect trunk and the 1.0 branches as well? And is it a blocker for 1.0.0? cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16219698" author="apurva" created="Wed, 25 Oct 2017 23:00:37 +0000"  >&lt;p&gt;Yes, this affects transactions from the beginning. I tested against a broker running on trunk. I think it is a blocker for 1.0.0 and am discussing with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt; offline.&lt;/p&gt;</comment>
                            <comment id="16219765" author="guozhang" created="Thu, 26 Oct 2017 00:01:20 +0000"  >&lt;p&gt;Thanks for reporting the issue &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gyao&quot; class=&quot;user-hover&quot; rel=&quot;gyao&quot;&gt;gyao&lt;/a&gt;. We looked into the source code and found that it is indeed a bug, such that when expiring a transaction due to timeout we should force bumping up the producer epoch as well when calling &lt;tt&gt;handleEndTransactionhandleEndTransaction&lt;/tt&gt;. Lines within &lt;tt&gt;prepareAddPartitions&lt;/tt&gt; is actually fine as they are already guarded by the producer epoch check.&lt;/p&gt;

&lt;p&gt;Apurva will submit a PR for fixing this issue. I&apos;m going to mark it as a blocker (hopefully the last one) for 1.0.0&lt;/p&gt;</comment>
                            <comment id="16219806" author="githubbot" created="Thu, 26 Oct 2017 01:07:34 +0000"  >&lt;p&gt;GitHub user apurvam opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/4137&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4137&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6119&quot; title=&quot;Silent Data Loss in Kafka011 Transactional Producer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6119&quot;&gt;&lt;del&gt;KAFKA-6119&lt;/del&gt;&lt;/a&gt;: Bump epoch when expiring transactions in the TransactionCoordinator&lt;/p&gt;

&lt;p&gt;    A description of the problem is in the JIRA. I have added an integration test which reproduces the original scenario, and also added unit test cases.&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/apurvam/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apurvam/kafka&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6119&quot; title=&quot;Silent Data Loss in Kafka011 Transactional Producer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6119&quot;&gt;&lt;del&gt;KAFKA-6119&lt;/del&gt;&lt;/a&gt;-bump-epoch-when-expiring-transactions&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/4137.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4137.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #4137&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 4405e4f9c30e82864417fdbafe3817ee4acee661&lt;br/&gt;
Author: Apurva Mehta &amp;lt;apurva@confluent.io&amp;gt;&lt;br/&gt;
Date:   2017-10-26T00:58:44Z&lt;/p&gt;

&lt;p&gt;    Bump the epoch when we abort a transaction on the coordinator&lt;/p&gt;

&lt;p&gt;commit 9945b4f8315dc8c82aaeb003c07458a6231ee96c&lt;br/&gt;
Author: Apurva Mehta &amp;lt;apurva@confluent.io&amp;gt;&lt;br/&gt;
Date:   2017-10-26T01:06:04Z&lt;/p&gt;

&lt;p&gt;    Lock the transaction metadata before fencing the epoch. Make the case matching exhaustive&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="16219812" author="apurva" created="Thu, 26 Oct 2017 01:15:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gyao&quot; class=&quot;user-hover&quot; rel=&quot;gyao&quot;&gt;gyao&lt;/a&gt;, thanks for the excellent bug report which enabled very easy reproduction. I have filed a patch for this issue, please try it out and let me know if it doesn&apos;t work for you. I tried your program with my patch, and the producer does raise a &lt;tt&gt;ProducerFencedException&lt;/tt&gt; now.&lt;/p&gt;</comment>
                            <comment id="16221790" author="guozhang" created="Fri, 27 Oct 2017 06:27:07 +0000"  >&lt;p&gt;Issue resolved by pull request 4137&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/pull/4137&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4137&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16221794" author="githubbot" created="Fri, 27 Oct 2017 06:28:10 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/4137&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4137&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16224052" author="gyao" created="Sun, 29 Oct 2017 15:49:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apurva&quot; class=&quot;user-hover&quot; rel=&quot;apurva&quot;&gt;apurva&lt;/a&gt; Happy to see that the issue is already resolved. Will this only be included in Kafka 1.0.0, or will there be also a backport to 0.11.0.2?&lt;/p&gt;</comment>
                            <comment id="16224372" author="apurva" created="Mon, 30 Oct 2017 04:29:44 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt; can confirm, but I think the patch was merged onto the 0.11.0 branch. So it will be part of the 0.11.0.2 release. However there is no date for the latter at the moment.&lt;/p&gt;</comment>
                            <comment id="16225152" author="guozhang" created="Mon, 30 Oct 2017 15:33:49 +0000"  >&lt;p&gt;It is merged into 0.11.0 branch, but like Apurva said we do not have a concrete date if ever we will have a 0.11.0.2 release.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 3 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3lpjb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>