<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:38:49 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-15804] Broker leaks ServerSocketChannel when exception is thrown from ZkConfigManager during startup</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-15804</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;This exception is thrown during the RemoteTopicCrudTest.testClusterWideDisablementOfTieredStorageWithEnabledTieredTopic test in zk mode:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.kafka.common.config.ConfigException: You have to delete all topics with the property remote.storage.enable=true before disabling tiered storage cluster-wide
        at org.apache.kafka.storage.internals.log.LogConfig.validateRemoteStorageOnlyIfSystemEnabled(LogConfig.java:566)
 &#160; &#160; &#160; &#160;at kafka.log.LogManager.updateTopicConfig(LogManager.scala:956)
 &#160; &#160; &#160; &#160;at kafka.server.TopicConfigHandler.updateLogConfig(ConfigHandler.scala:73)
        at kafka.server.TopicConfigHandler.processConfigChanges(ConfigHandler.scala:94)
        at kafka.server.ZkConfigManager.$anonfun$startup$4(ZkConfigManager.scala:176)
        at kafka.server.ZkConfigManager.$anonfun$startup$4$adapted(ZkConfigManager.scala:175)
        at scala.collection.immutable.Map$Map2.foreach(Map.scala:360)
        at kafka.server.ZkConfigManager.$anonfun$startup$1(ZkConfigManager.scala:175)
        at kafka.server.ZkConfigManager.$anonfun$startup$1$adapted(ZkConfigManager.scala:166)
        at scala.collection.immutable.HashMap.foreach(HashMap.scala:1115)
        at kafka.server.ZkConfigManager.startup(ZkConfigManager.scala:166)
        at kafka.server.KafkaServer.startup(KafkaServer.scala:575)
        at kafka.integration.KafkaServerTestHarness.$anonfun$createBrokers$1(KafkaServerTestHarness.scala:356)
        at kafka.integration.KafkaServerTestHarness.$anonfun$createBrokers$1$adapted(KafkaServerTestHarness.scala:352)
        at scala.collection.immutable.List.foreach(List.scala:333)
        at kafka.integration.KafkaServerTestHarness.createBrokers(KafkaServerTestHarness.scala:352)
        at kafka.integration.KafkaServerTestHarness.recreateBrokers(KafkaServerTestHarness.scala:146)
        at kafka.admin.RemoteTopicCrudTest.$anonfun$testClusterWideDisablementOfTieredStorageWithEnabledTieredTopic$1(RemoteTopicCrudTest.scala:319)
        at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:53)
        at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:35)
        at org.junit.jupiter.api.Assertions.assertThrows(Assertions.java:3111)
        at kafka.admin.RemoteTopicCrudTest.testClusterWideDisablementOfTieredStorageWithEnabledTieredTopic(RemoteTopicCrudTest.scala:319)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This leak only occurs for this one test in the RemoteTopicCrudTest; all other tests including the kraft-mode version do not exhibit a leaked socket.&lt;/p&gt;

&lt;p&gt;Here is where the ServerSocket is instantiated:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;        at java.base/java.nio.channels.ServerSocketChannel.open(ServerSocketChannel.java:113)
&#160; &#160; &#160; &#160; at kafka.network.Acceptor.openServerSocket(SocketServer.scala:724)
&#160; &#160; &#160; &#160; at kafka.network.Acceptor.&amp;lt;init&amp;gt;(SocketServer.scala:608)
&#160; &#160; &#160; &#160; at kafka.network.DataPlaneAcceptor.&amp;lt;init&amp;gt;(SocketServer.scala:454)
&#160; &#160; &#160; &#160; at kafka.network.SocketServer.createDataPlaneAcceptor(SocketServer.scala:270)
&#160; &#160; &#160; &#160; at kafka.network.SocketServer.createDataPlaneAcceptorAndProcessors(SocketServer.scala:249)
&#160; &#160; &#160; &#160; at kafka.network.SocketServer.$anonfun$new$31(SocketServer.scala:175)
&#160; &#160; &#160; &#160; at kafka.network.SocketServer.$anonfun$new$31$adapted(SocketServer.scala:175)
&#160; &#160; &#160; &#160; at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:576)
&#160; &#160; &#160; &#160; at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:574)
&#160; &#160; &#160; &#160; at scala.collection.AbstractIterable.foreach(Iterable.scala:933)
&#160; &#160; &#160; &#160; at kafka.network.SocketServer.&amp;lt;init&amp;gt;(SocketServer.scala:175)
&#160; &#160; &#160; &#160; at kafka.server.KafkaServer.startup(KafkaServer.scala:344)
&#160; &#160; &#160; &#160; at kafka.integration.KafkaServerTestHarness.$anonfun$createBrokers$1(KafkaServerTestHarness.scala:356)
&#160; &#160; &#160; &#160; at kafka.integration.KafkaServerTestHarness.$anonfun$createBrokers$1$adapted(KafkaServerTestHarness.scala:352)
&#160; &#160; &#160; &#160; at scala.collection.immutable.List.foreach(List.scala:333)
&#160; &#160; &#160; &#160; at kafka.integration.KafkaServerTestHarness.createBrokers(KafkaServerTestHarness.scala:352)
&#160; &#160; &#160; &#160; at kafka.integration.KafkaServerTestHarness.recreateBrokers(KafkaServerTestHarness.scala:146)
&#160; &#160; &#160; &#160; at kafka.admin.RemoteTopicCrudTest.$anonfun$testClusterWideDisablementOfTieredStorageWithEnabledTieredTopic$1(RemoteTopicCrudTest.scala:319)
&#160; &#160; &#160; &#160; at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:53)
&#160; &#160; &#160; &#160; at org.junit.jupiter.api.AssertThrows.assertThrows(AssertThrows.java:35)
&#160; &#160; &#160; &#160; at org.junit.jupiter.api.Assertions.assertThrows(Assertions.java:3111)
&#160; &#160; &#160; &#160; at kafka.admin.RemoteTopicCrudTest.testClusterWideDisablementOfTieredStorageWithEnabledTieredTopic(RemoteTopicCrudTest.scala:319)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;And the associated DataPlaneAcceptor:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;  &#160; &#160; &#160;  at java.base/java.nio.channels.Selector.open(Selector.java:295)
 &#160; &#160; &#160; &#160; at kafka.network.Acceptor.&amp;lt;init&amp;gt;(SocketServer.scala:598)
 &#160; &#160; &#160; &#160; at kafka.network.DataPlaneAcceptor.&amp;lt;init&amp;gt;(SocketServer.scala:454)
 &#160; &#160; &#160; &#160; at kafka.network.SocketServer.createDataPlaneAcceptor(SocketServer.scala:270)
 &#160; &#160; &#160; &#160; at kafka.network.SocketServer.createDataPlaneAcceptorAndProcessors(SocketServer.scala:249)
 &#160; &#160; &#160; &#160; at kafka.network.SocketServer.$anonfun$new$31(SocketServer.scala:175)
 &#160; &#160; &#160; &#160; at kafka.network.SocketServer.$anonfun$new$31$adapted(SocketServer.scala:175)
 &#160; &#160; &#160; &#160; at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:576)
 &#160; &#160; &#160; &#160; at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:574)
 &#160; &#160; &#160; &#160; at scala.collection.AbstractIterable.foreach(Iterable.scala:933)
 &#160; &#160; &#160; &#160; at kafka.network.SocketServer.&amp;lt;init&amp;gt;(SocketServer.scala:175)
 &#160; &#160; &#160; &#160; at kafka.server.KafkaServer.startup(KafkaServer.scala:344)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;And two Processors:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;        at java.base/java.nio.channels.Selector.open(Selector.java:295)
&#160; &#160; &#160; &#160; at org.apache.kafka.common.network.Selector.&amp;lt;init&amp;gt;(Selector.java:159)
&#160; &#160; &#160; &#160; at kafka.network.Processor.createSelector(SocketServer.scala:995)
&#160; &#160; &#160; &#160; at kafka.network.Processor.&amp;lt;init&amp;gt;(SocketServer.scala:973)
&#160; &#160; &#160; &#160; at kafka.network.Acceptor.newProcessor(SocketServer.scala:879)
&#160; &#160; &#160; &#160; at kafka.network.Acceptor.$anonfun$addProcessors$1(SocketServer.scala:849)
&#160; &#160; &#160; &#160; at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:190)
&#160; &#160; &#160; &#160; at kafka.network.Acceptor.addProcessors(SocketServer.scala:848)
&#160; &#160; &#160; &#160; at kafka.network.DataPlaneAcceptor.configure(SocketServer.scala:523)
&#160; &#160; &#160; &#160; at kafka.network.SocketServer.createDataPlaneAcceptorAndProcessors(SocketServer.scala:251)
&#160; &#160; &#160; &#160; at kafka.network.SocketServer.$anonfun$new$31(SocketServer.scala:175)
&#160; &#160; &#160; &#160; at kafka.network.SocketServer.$anonfun$new$31$adapted(SocketServer.scala:175)
&#160; &#160; &#160; &#160; at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:576)
&#160; &#160; &#160; &#160; at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:574)
&#160; &#160; &#160; &#160; at scala.collection.AbstractIterable.foreach(Iterable.scala:933)
&#160; &#160; &#160; &#160; at kafka.network.SocketServer.&amp;lt;init&amp;gt;(SocketServer.scala:175)
&#160; &#160; &#160; &#160; at kafka.server.KafkaServer.startup(KafkaServer.scala:344)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I found this while investigating the causes of recent build failures where Gradle is unable to connect to the test runners. I don&apos;t believe this bug has any impact on end-users, but may have an impact on users running an embedded kafka in a test environment with a long-lived JVM.&lt;br/&gt;
I have seen other tests leaking sockets/leaving files open, so the RemoteTopicCrudTest is not unique. It just happens to be the first test i&apos;ve looked into.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13557400">KAFKA-15804</key>
            <summary>Broker leaks ServerSocketChannel when exception is thrown from ZkConfigManager during startup</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gharris1727">Greg Harris</assignee>
                                    <reporter username="gharris1727">Greg Harris</reporter>
                        <labels>
                    </labels>
                <created>Thu, 9 Nov 2023 23:27:53 +0000</created>
                <updated>Mon, 5 Aug 2024 18:08:37 +0000</updated>
                            <resolved>Fri, 10 May 2024 20:57:15 +0000</resolved>
                                    <version>3.6.0</version>
                                    <fixVersion>3.8.0</fixVersion>
                                    <component>core</component>
                    <component>unit tests</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                                                                <comments>
                            <comment id="17784630" author="gharris1727" created="Fri, 10 Nov 2023 00:03:56 +0000"  >&lt;p&gt;I believe what is happening is:&lt;/p&gt;

&lt;p&gt;1. The SocketServer is created&lt;br/&gt;
2. The exception is thrown from the dynamicConfigManager&lt;br/&gt;
3. SocketServer.enableRequestProcessing is never called, so the SocketServer is never started&lt;br/&gt;
4. Because the SocketServer is never started, the SocketServer main runnable never exits, and so the SocketServerChannel is never closed.&lt;/p&gt;

&lt;p&gt;I think that when the SocketServer beginShutdown()/shutdown() is called without calling enableRequestProcessing() first, the SocketServer should still close these resources.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310560">
                    <name>Problem/Incident</name>
                                            <outwardlinks description="causes">
                                        <issuelink>
            <issuekey id="13587924">KAFKA-17268</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310760">
                    <name>Testing</name>
                                                                <inwardlinks description="Discovered while testing">
                                        <issuelink>
            <issuekey id="13558285">KAFKA-15845</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1lids:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>