<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:32:20 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-12468] Initial offsets are copied from source to target cluster</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-12468</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;We have an active-passive setup where&#160; the 3 connectors from mirror maker 2 (heartbeat, checkpoint and source) are running on a dedicated Kafka connect cluster on the target cluster.&lt;/p&gt;

&lt;p&gt;Offset syncing is enabled as specified by KIP-545. But when activated, it seems the offsets from the source cluster are initially copied to the target cluster without translation. This causes a negative lag for all synced consumer groups. Only when we reset the offsets for each topic/partition on the target cluster and produce a record on the topic/partition in the source, the sync starts working correctly.&#160;&lt;/p&gt;

&lt;p&gt;I would expect that the consumer groups are synced but that the current offsets of the source cluster are not copied to the target cluster.&lt;/p&gt;

&lt;p&gt;This is the configuration we are currently using:&lt;/p&gt;

&lt;p&gt;Heartbeat connector&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-xml&quot;&gt;
{
  &lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;mm2-mirror-heartbeat&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;config&quot;&lt;/span&gt;: {
    &lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;mm2-mirror-heartbeat&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;connector.class&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.kafka.connect.mirror.MirrorHeartbeatConnector&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;source.cluster.alias&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;eventador&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;target.cluster.alias&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;msk&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;source.cluster.bootstrap.servers&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;SOURCE_CLUSTER&amp;gt;&lt;/span&gt;&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;target.cluster.bootstrap.servers&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;TARGET_CLUSTER&amp;gt;&lt;/span&gt;&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;topics&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;.*&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;groups&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;.*&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;tasks.max&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;1&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;replication.policy.class&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;CustomReplicationPolicy&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;sync.group.offsets.enabled&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;true&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;sync.group.offsets.interval.seconds&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;5&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;emit.checkpoints.enabled&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;true&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;emit.checkpoints.interval.seconds&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;30&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;emit.heartbeats.interval.seconds&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;30&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;key.converter&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot; org.apache.kafka.connect.converters.ByteArrayConverter&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;value.converter&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.kafka.connect.converters.ByteArrayConverter&quot;&lt;/span&gt;
  }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Checkpoint connector:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-xml&quot;&gt;
{
  &lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;mm2-mirror-checkpoint&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;config&quot;&lt;/span&gt;: {
    &lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;mm2-mirror-checkpoint&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;connector.class&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.kafka.connect.mirror.MirrorCheckpointConnector&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;source.cluster.alias&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;eventador&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;target.cluster.alias&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;msk&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;source.cluster.bootstrap.servers&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;SOURCE_CLUSTER&amp;gt;&lt;/span&gt;&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;target.cluster.bootstrap.servers&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;TARGET_CLUSTER&amp;gt;&lt;/span&gt;&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;topics&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;.*&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;groups&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;.*&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;tasks.max&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;40&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;replication.policy.class&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;CustomReplicationPolicy&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;sync.group.offsets.enabled&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;true&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;sync.group.offsets.interval.seconds&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;5&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;emit.checkpoints.enabled&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;true&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;emit.checkpoints.interval.seconds&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;30&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;emit.heartbeats.interval.seconds&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;30&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;key.converter&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot; org.apache.kafka.connect.converters.ByteArrayConverter&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;value.converter&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.kafka.connect.converters.ByteArrayConverter&quot;&lt;/span&gt;
  }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;Source connector:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-xml&quot;&gt;
{
  &lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;mm2-mirror-source&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;config&quot;&lt;/span&gt;: {
    &lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;mm2-mirror-source&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;connector.class&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.kafka.connect.mirror.MirrorSourceConnector&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;source.cluster.alias&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;eventador&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;target.cluster.alias&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;msk&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;source.cluster.bootstrap.servers&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;SOURCE_CLUSTER&amp;gt;&lt;/span&gt;&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;target.cluster.bootstrap.servers&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;TARGET_CLUSTER&amp;gt;&lt;/span&gt;&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;topics&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;.*&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;groups&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;.*&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;tasks.max&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;40&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;replication.policy.class&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;CustomReplicationPolicy&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;sync.group.offsets.enabled&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;true&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;sync.group.offsets.interval.seconds&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;5&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;emit.checkpoints.enabled&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;true&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;emit.checkpoints.interval.seconds&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;30&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;emit.heartbeats.interval.seconds&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;30&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;key.converter&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot; org.apache.kafka.connect.converters.ByteArrayConverter&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;value.converter&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.kafka.connect.converters.ByteArrayConverter&quot;&lt;/span&gt;
  }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13365345">KAFKA-12468</key>
            <summary>Initial offsets are copied from source to target cluster</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gharris1727">Greg Harris</assignee>
                                    <reporter username="bdeneuter">Bart De Neuter</reporter>
                        <labels>
                    </labels>
                <created>Mon, 15 Mar 2021 20:48:09 +0000</created>
                <updated>Fri, 23 Feb 2024 01:17:29 +0000</updated>
                            <resolved>Fri, 17 Feb 2023 22:26:27 +0000</resolved>
                                    <version>2.7.0</version>
                                    <fixVersion>3.3.3</fixVersion>
                    <fixVersion>3.4.1</fixVersion>
                    <fixVersion>3.5.0</fixVersion>
                                    <component>mirrormaker</component>
                        <due></due>
                            <votes>3</votes>
                                    <watches>12</watches>
                                                                                                                <comments>
                            <comment id="17306229" author="dragotic" created="Mon, 22 Mar 2021 14:18:31 +0000"  >&lt;p&gt;We are facing the same issue with MirrorMaker2 that comes with Kafka 2.7.0&lt;/p&gt;</comment>
                            <comment id="17307208" author="bdeneuter" created="Tue, 23 Mar 2021 16:30:26 +0000"  >&lt;p&gt;I forgot to mention that we use a custom replication policy to keep the topic names the same in both source and target cluster.&#160;&lt;/p&gt;</comment>
                            <comment id="17308308" author="askldjd" created="Thu, 25 Mar 2021 02:42:53 +0000"  >&lt;p&gt;I am seeing similar issue as well. I am also using a custom replication policy to preserve topic name. I would mirror hundreds of topics and CGs. Most of them will mirror correctly except for a few CG:partition.&lt;/p&gt;

&lt;p&gt;In this example,&#160;group topic 1 has a lag of -16201970 and the offset is determined to be&#160;16764337. This is wrong. The offset&#160;16764337 is copied the original cluster and not translated.&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;GROUP TOPIC PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID
group topic 20         390239          390239          0               -               -               -
group topic 22         494366          494366          0               -               -               -
group topic 16         147241          147241          0               -               -               -
group topic 18         469795          469795          0               -               -               -
group topic 24         835689          835689          0               -               -               -
group topic 3          391505          391505          0               -               -               -
group topic 5          194327          194327          0               -               -               -
group topic 1          16764337        562367          -16201970       -               -               -
group topic 11         913398          913398          0               -               -               -
group topic 13         1245835         1245835         0               -               -               -
group topic 7          52007           52007           0               -               -               -
group topic 9          1001964         1001964         0               -               -               -
group topic 19         1035791         1035791         0               -               -               -
group topic 21         456149          456149          0               -               -               -
group topic 15         696             696             0               -               -               -
group topic 17         225085          225085          0               -               -               -
group topic 23         622744          622744          0               -               -               -
group topic 4          777787          777787          0               -               -               -
group topic 6          286576          286576          0               -               -               -
group topic 0          1233042         1233042         0               -               -               -
group topic 2          1118624         1118624         0               -               -               -
group topic 12         693             693             0               -               -               -
group topic 14         283294          283294          0               -               -               -
group topic 8          924899          924899          0               -               -               -
group topic 10         494636          494636          0               -               -               -
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17308965" author="askldjd" created="Thu, 25 Mar 2021 20:47:37 +0000"  >&lt;p&gt;I found a race condition in MirrorSourceTask. Referencing here in case this is related.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-12558&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/KAFKA-12558&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17312259" author="akaltsikis" created="Wed, 31 Mar 2021 10:27:46 +0000"  >&lt;p&gt;Hey &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=askldjd&quot; class=&quot;user-hover&quot; rel=&quot;askldjd&quot;&gt;askldjd&lt;/a&gt;,&lt;br/&gt;
I have checked also the race condition you mention.&lt;br/&gt;
Using the workaround you mention have you seen the same behavior as in&#160;&lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-12468?focusedCommentId=17308308&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17308308&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;your previous comment&lt;/a&gt;?&lt;br/&gt;
Or it fixed the problem?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
For those who are experiencing &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; issue, the workaround is to make sure you have less than or equal to 10 partitions per task. Set your `tasks.max` value accordingly.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17312826" author="askldjd" created="Thu, 1 Apr 2021 03:38:25 +0000"  >&lt;p&gt;Hey Angelos,&lt;/p&gt;

&lt;p&gt;By limiting to less than 10 partitions per task, I was able to run 10 consecutive full mirror without any issues. Previously, it would fail almost every time.&lt;/p&gt;

&lt;p&gt;The test cluster has about 4500 partitions, and my tasks.max is set to 500.&lt;/p&gt;

&lt;p&gt;... Alan&lt;/p&gt;</comment>
                            <comment id="17313235" author="akaltsikis" created="Thu, 1 Apr 2021 15:17:03 +0000"  >&lt;p&gt;Hey &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=askldjd&quot; class=&quot;user-hover&quot; rel=&quot;askldjd&quot;&gt;askldjd&lt;/a&gt;,&lt;br/&gt;
Thanks for your useful comment.&lt;br/&gt;
According to the above and due to the fact that I am trying to migrate around 2500 partitions which means that i need around 300 tasks to achieve it.&lt;br/&gt;
May i ask where did you run your MM2 (Strimzi MM2, EC2?) and about how much CPU power did the above required?&lt;/p&gt;</comment>
                            <comment id="17313268" author="akaltsikis" created="Thu, 1 Apr 2021 16:01:15 +0000"  >&lt;p&gt;By the way, may i ask how you were able to validate that both the data and the consumer offsets have been mirrored correctly in such a big number of partitions (and i guess big number of consumer groups) ?&lt;/p&gt;</comment>
                            <comment id="17313426" author="askldjd" created="Thu, 1 Apr 2021 20:20:41 +0000"  >&lt;p&gt;&amp;gt; May i ask where did you run your MM2 (Strimzi MM2, EC2?) and about how much CPU power did the above required?&lt;br/&gt;
I am running connect-mirror-maker.sh (standalone mode) on a C5.16xl. It is probably overkill, I am doing a lift-and-shift migration, so MM2 cost isn&apos;t a great concern since it is a one-time exercise. If you are doing continuous mirroring (e.g. HA purposes), I would consider running kafka-connect in distributed mode with more smaller nodes.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&amp;gt; By the way, may i ask how you were able to validate that both the data and the consumer offsets have been mirrored correctly in such a big number of partitions (and i guess big number of consumer groups) ?&lt;/p&gt;

&lt;p&gt;Good question. I can&apos;t possibly verify every partition, so I ended up doing a best effort spotcheck&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Make hello world topic with test consumer in the source cluster to make sure the topic and consumer offset are mirrored correctly in the target cluster&lt;/li&gt;
	&lt;li&gt;Use `kafka-consumer-group.sh`, verify that
	&lt;ol&gt;
		&lt;li&gt;CURRENT-OFFSET in the target cluster are all positive&lt;/li&gt;
		&lt;li&gt;LAG are all zero, or very close to near zero&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Just with the basic spotcheck, I was able to find &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-12558&quot; title=&quot;MM2 may not sync partition offsets correctly&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-12558&quot;&gt;&lt;del&gt;KAFKA-12558&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17313793" author="ducminhle" created="Fri, 2 Apr 2021 10:53:24 +0000"  >&lt;p&gt;I got the same issue with Mirror Maker 2.7, consumer group lag &amp;lt; 0, offset can not translate. With topic have retention is delete, old messages are deleted, messages in the topic are 0, lags is always &amp;lt; 0.&lt;/p&gt;

&lt;p&gt;I try to work around as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=askldjd&quot; class=&quot;user-hover&quot; rel=&quot;askldjd&quot;&gt;askldjd&lt;/a&gt; suggested, but it not work with topic have message = 0.&lt;/p&gt;</comment>
                            <comment id="17316380" author="akaltsikis" created="Wed, 7 Apr 2021 14:25:35 +0000"  >&lt;p&gt;Hello again,&lt;/p&gt;

&lt;p&gt;We have managed to set Mirrormaker2 properly considering &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-12558&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;KAFKA-12558 bug&lt;/a&gt; which requires the SourceConnector tasks.max to be a number that the division of total partition number / tasks.max &amp;lt; 10.&lt;br/&gt;
 Also, we have introduced some configurations which offer performance optimizations according to this &lt;a href=&quot;https://wmclane.medium.com/how-to-optimize-mirrormaker2-for-high-performance-apache-kafka-replication-697bc5089c64&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;blog&lt;/a&gt;.&lt;br/&gt;
 We were trying to prove that the MM2 successfully has copied all the data (every topic message &amp;amp; correct consumer group offsets) from the source cluster to the target, but without great success.&lt;br/&gt;
 We tried to compare between source &amp;amp; target clusters the following metrics:&lt;br/&gt;
 Log Size per partition on the 2 different clusters but on most of the partitions is different&lt;br/&gt;
 Consumer Lag for each Consumer group- topic - partition combination but still all of them have a negative consumer lag. Only when we reset the offsets (as mentioned in this ticket&apos;s description) the consumer group lag in the target cluster start being in a better state (not being negative)&lt;br/&gt;
 LogEndOffset - LogStartOffset . For topics with cleanup.policy delete the subtraction gives pretty much the same numbers on the different clusters.&lt;/p&gt;

&lt;p&gt;Is there &lt;b&gt;any better way&lt;/b&gt; to verify that MM2 has caught up &amp;amp; continues the mirroring correctly?&lt;/p&gt;

&lt;p&gt;What worries us most is that for some topics we observed that in the target cluster for some partitions we have a much smaller log size. We compared the messages in some of those partitions and indeed it seems that they were fewer messages in the target cluster&#8217;s topic partition. Our main question is does MM2 offer at least once guarantee = no messages lost?&lt;/p&gt;</comment>
                            <comment id="17316388" author="akaltsikis" created="Wed, 7 Apr 2021 14:34:58 +0000"  >&lt;p&gt;We were also considering to add the following configuration in order to enable idempotence from producer side&lt;/p&gt;

&lt;p&gt;source-test.producer.enable.idempotence = true&lt;br/&gt;
source-test.producer.acks=all&lt;br/&gt;
source-test.producer.max.in.flight.requests.per.connection=5&lt;br/&gt;
source-test.producer.retries=2147483647&lt;br/&gt;
source-test.consumer.isolation.level=read_committed&lt;br/&gt;
target-test.producer.enable.idempotence = true&lt;br/&gt;
target-test.producer.acks=all&lt;br/&gt;
target-test.producer.max.in.flight.requests.per.connection=5&lt;br/&gt;
target-test.producer.retries=2147483647&lt;br/&gt;
target-test.consumer.isolation.level=read_committed&lt;/p&gt;

&lt;p&gt;As it is also mentioned &lt;a href=&quot;https://stackoverflow.com/a/66917494/2927926&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17322537" author="jitesh88" created="Thu, 15 Apr 2021 23:50:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=askldjd&quot; class=&quot;user-hover&quot; rel=&quot;askldjd&quot;&gt;askldjd&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&#160;what do you mean by run 10 consecutive full mirror ? 10 separate processes on the same box?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-12468?focusedCommentId=17312826&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17312826&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/KAFKA-12468?focusedCommentId=17312826&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17312826&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17360131" author="ajosephides" created="Wed, 9 Jun 2021 14:42:59 +0000"  >&lt;p&gt;We are also seeing this issue despite having &amp;lt;10 partitions per task.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=askldjd&quot; class=&quot;user-hover&quot; rel=&quot;askldjd&quot;&gt;askldjd&lt;/a&gt;&#160;looking at your original configuration you have the `tasks.max` for both the Source and Checkpoint connector to be equal. When you increased the tasks on the Source connector to 500 to overcome the race condition did you find any starvation issues that resulted in a similar effect? Or, did you also increase the `tasks.max` on the Checkpoint connector too?&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17360866" author="askldjd" created="Thu, 10 Jun 2021 12:50:19 +0000"  >&lt;p&gt;I am running standalone mode, so I am not sure if tasks.max propagate to all connectors. I think it does. Which mode are you running in? If you are in distributed mode, I would consider setting tasks.max on each connector.&lt;/p&gt;</comment>
                            <comment id="17360912" author="ajosephides" created="Thu, 10 Jun 2021 13:39:38 +0000"  >&lt;p&gt;We are running in distributed mode and are stipulating a `tasks.max` on each connector (Source, Checkpoint and Heartbeat, 500, 50 and 1 respectively).&lt;br/&gt;
We are still seeing this issue with negative offsets on our target cluster.&lt;/p&gt;</comment>
                            <comment id="17361084" author="aaamber" created="Thu, 10 Jun 2021 16:54:53 +0000"  >&lt;p&gt;I was using standalone mode with active-passive setup and saw negative offsets in the past as well. One of the reasons I found was due to consumer request timeout, e.g. org.apache.kafka.common.errors.DisconnectException. I increased the request timeout and tasks.max and the offsets are synced correctly now.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
# consumer, need to set higher timeout
source.admin.request.timeout.ms = 180000
source.consumer.request.timeout.ms = 180000&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17392914" author="ajosephides" created="Wed, 4 Aug 2021 09:28:23 +0000"  >&lt;p&gt;Thanks for the suggestions and apologies for the delay in updating how we handled this issue in the end.&lt;br/&gt;
Should say from the outset that we did not completely remove this issue but we minimised the occurrences, fixed some and in the remainder - lived with it.&lt;br/&gt;
The first step was minimisation. We achieved this via the phasing of turning on our connectors. The first connector we applied was the `Source` connector. For our setup we had a number of source connectors - some set to replicate from `latest` and others from `earliest`. We let this connector run and replicate until we hit a steady state and all replication was confirmed to be at the head of their relevant topic. This soak could be a few days depending on your data volumes, throughputs (client limits) etc.....&lt;br/&gt;
Once the soak has completed we then turned on the Checkpoint connector.&lt;/p&gt;

&lt;p&gt;If there are negative offsets after this first step we then took steps to manage them. There are 2 categories here. Partitions that have data on them and partitions that have no data on them.&lt;br/&gt;
In the first instance (data on partitions) the first thing we try is to `delete` the affected consumer group. This is absolutely fine to do as a) no consumers on the target cluster yet, b) the group is replicated again by MM2.&lt;br/&gt;
In 90% of instances the negative offset was corrected.&lt;/p&gt;

&lt;p&gt;In the second instance (no data on partitions) the first thing we examined is whether we could publish data (on source cluster) onto the topic to put data onto the partition. This was then followed by a refresh (delete) of the affected consumer group. This was possible only if the downstream consumer handled either dummy garbage messages ok or was fine with a small number of duplicate messages.&lt;/p&gt;

&lt;p&gt;What if following the above a negative offset remained?&lt;br/&gt;
In the instance where there was zero data on a partition and no new data could be published to it we let the consumer migrate onto the target cluster without much worry. The Kafka consumer behaviour at this point would look at a negative offset and throw a warning that it was out of range. It would then reset it&apos;s offset on the cluster to its default setting - either consumer from `latest` or `earliest`. Since there is 0 data on that partition this is one and the same thing.&lt;/p&gt;

&lt;p&gt;For instances (rare but did occur) where there remained a negative offset and data on the partition we still migrated and relied on the consumer behaviour to reset its offset to either `earliest` or `latest`. Depending on the consumer and it&apos;s use case we picked whichever best suited the scenario.&lt;/p&gt;

&lt;p&gt;Hope this is helpful in some way to others that might be experiencing these issues.&lt;/p&gt;</comment>
                            <comment id="17489716" author="gsavinov" created="Wed, 9 Feb 2022 18:03:07 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=bdeneuter&quot; class=&quot;user-hover&quot; rel=&quot;bdeneuter&quot;&gt;bdeneuter&lt;/a&gt; there is IdentityReplicationPolicy which can be used to preserve topic names, maybe you don&apos;t need to implement your CustomReplicationPolicy.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-9726&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/KAFKA-9726&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310560">
                    <name>Problem/Incident</name>
                                            <outwardlinks description="causes">
                                        <issuelink>
            <issuekey id="13527709">KAFKA-14797</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13569311">KAFKA-16291</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13543849">KAFKA-15202</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13559599">KAFKA-15905</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13559604">KAFKA-15906</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13569571">KAFKA-16303</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13446522">KAFKA-13932</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13542320">KAFKA-15144</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13418902">KAFKA-13562</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13522292">KAFKA-14666</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310760">
                    <name>Testing</name>
                                            <outwardlinks description="Testing discovered">
                                        <issuelink>
            <issuekey id="13522138">KAFKA-14663</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13525066">KAFKA-14727</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 39 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0ot40:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>