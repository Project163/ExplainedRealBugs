<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:19:57 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-7994] Improve Partition-Time for rebalances and restarts</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-7994</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;We compute a per-partition partition-time as the maximum timestamp over all records processed so far. Before 2.3 this was used to determine the logical stream-time used to make decisions about processing out-of-order records or drop them if they are late (ie, timestamp &amp;lt; stream-time - grace-period). Preserving the stream-time is necessary to ensure deterministic results (see &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-9368&quot; title=&quot;Preserve stream-time across rebalances/restarts&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-9368&quot;&gt;KAFKA-9368&lt;/a&gt;), and although the processor-time is now used instead of partition-time, preserving the partition-time is a first step towards improving the overall stream-time semantics.&lt;/p&gt;

&lt;p&gt;The partition-time is also used by the TimestampExtractor. It gets passed in to #extract and can be used to determine a rough timestamp estimate if the actual timestamp is missing, corrupt, etc. This means in the corner case where the next record to be processed after a rebalance/restart cannot have its actual timestamp determined, we have no idea way of coming up with a reasonable guess and the record will likely have to be dropped.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;A potential fix would be, to store latest observed partition-time in the metadata of committed offsets. This way, on restart/rebalance we can re-initialize partition-time correctly.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13217691">KAFKA-7994</key>
            <summary>Improve Partition-Time for rebalances and restarts</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="Yohan123">Richard Yu</assignee>
                                    <reporter username="mjsax">Matthias J. Sax</reporter>
                        <labels>
                    </labels>
                <created>Sun, 24 Feb 2019 19:33:59 +0000</created>
                <updated>Fri, 15 May 2020 05:21:55 +0000</updated>
                            <resolved>Tue, 31 Dec 2019 20:23:33 +0000</resolved>
                                                    <fixVersion>2.4.0</fixVersion>
                                    <component>streams</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>12</watches>
                                                                                                                <comments>
                            <comment id="16778460" author="guozhang" created="Tue, 26 Feb 2019 18:50:36 +0000"  >&lt;p&gt;Thanks for brining this up! I&apos;ve also thought about this lately, and another semi-related issue is that the inferred partition/stream time is inconsistency across sub-topologies today because each task independently infer that based on its own incoming records&apos; timestamp. As of today this is sorta by-design since each task is executed independently, but still there are shortcomings like inter-state-store consistency and global-consistent savepoints. Take your example in the desciprtion, when we&apos;ve processed up to r4 our current inferred stream time is 11 already, but imagine this sub-topology will eventually have a filter processor followed by a sink sending to an intermediate topic, and r2 and r3 are filtered, then in the down stream sub-topology we will only see the the processed results of r1 and r4 (and their inherited record timestamp) and then infer the stream time as 2.&lt;/p&gt;

&lt;p&gt;So I&apos;m feeling that if we can tackle those issues within a single solution, then maybe we can consider propagating the stream time inferred at the &quot;head&quot; sub-topologies, plus storing it at the offset metadata.&lt;/p&gt;</comment>
                            <comment id="16778810" author="mjsax" created="Wed, 27 Feb 2019 02:48:56 +0000"  >&lt;blockquote&gt;&lt;p&gt;So I&apos;m feeling that if we can tackle those issues within a single solution, then maybe we can consider propagating the stream time inferred at the &quot;head&quot; sub-topologies, plus storing it at the offset metadata.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This might be helpful. I actually believe, that `suppress()` might face a similar issue atm. \cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vvcephei&quot; class=&quot;user-hover&quot; rel=&quot;vvcephei&quot;&gt;vvcephei&lt;/a&gt; What is the impact on `suppress()` on restarts? Could it be that we emit incorrectly for this case?&lt;/p&gt;</comment>
                            <comment id="16782178" author="vvcephei" created="Fri, 1 Mar 2019 22:46:41 +0000"  >&lt;p&gt;I did some mental math when I made that last change to stream time. It&apos;s funny, I keep proving the math to myself, but I can&apos;t shake the feeling that there might be something wrong with it... Thanks for bringing this up, the more we go over it, the better.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;It&apos;s always possible I&apos;ve made an arithmetic error, but I don&apos;t think we&apos;ll ever emit earlier than necessary, and we shouldn&apos;t emit later than necessary either.&lt;/p&gt;

&lt;p&gt;The stream-time variable is initialized to -1, which is smaller than any record timestamp (because we&apos;re not considering negative timestamps yet), so it&apos;s also smaller than any &quot;real&quot; stream time.&lt;/p&gt;

&lt;p&gt;Records are only emitted from the suppression when a certain time passes &lt;b&gt;after&lt;/b&gt; the record time. I.e., (ST is stream time, BR is a buffered record, D is suppression duration) when ST &amp;gt;= BR.time + D . Neither BR.time nor D can be negative, so that expression is never true for ST = -1 (the initial, &quot;unknown time&quot;, value). Therefore, resetting stream time to -1 at any point is safe, in that it can never cause premature evictions.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;It wouldn&apos;t be terrible if we sometimes held on to records a little longer than necessary, but actually, I think this won&apos;t happen either.&lt;/p&gt;

&lt;p&gt;Stream time advances when we process new records through the Suppress processor, and the processing of&#160;a new record isn&apos;t complete until we emit all of the buffered records that should be emitted as a result of the stream time advancement that record causes. Therefore, we have an invariant that, if the processing of record R is complete, ST &amp;gt;= R.time and the buffer contains only buffered records BR such that BR.time &amp;gt;&#160;ST&#160;- D .&lt;/p&gt;

&lt;p&gt;Now, if we restart after processing R, we&apos;ll forget all about that prior stream time, and just take the next record&apos;s (NR) timestamp as the new stream time. NR.time can either be larger or smaller than the previous ST. If it&apos;s larger, it&apos;s equivalent to a normal increment of stream time, and all the normal logic applies. The unusual situation is that if NR.time is smaller than the previous ST. This means the new stream time ST&apos; is smaller than the prior stream time. If we hadn&apos;t had the &quot;reset&quot;, what would have happened? Since ST&apos; = max(ST, NR.time) and NR.time &amp;lt; ST, we get ST&apos; = ST. The stream time doesn&apos;t advance at all, and we should not emit anything.&lt;/p&gt;

&lt;p&gt;So whether we reset the stream time to -1 or preserve the prior ST, the exact same records will be emitted or not.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;I wrote the above out long form to try and eliminate any hand-waving from my thinking about this. Is there any problem with the reasoning? If not, then we have a proof that resetting the stream time to -1 has no impact on suppress.&#160;&lt;/p&gt;</comment>
                            <comment id="16782206" author="mjsax" created="Fri, 1 Mar 2019 23:33:30 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vvcephei&quot; class=&quot;user-hover&quot; rel=&quot;vvcephei&quot;&gt;vvcephei&lt;/a&gt;. Sounds convincing! Glad that suppress() is not subject to this issue.&lt;/p&gt;</comment>
                            <comment id="16785144" author="guozhang" created="Wed, 6 Mar 2019 01:38:51 +0000"  >&lt;p&gt;Just to add: even in the KIP to add negative timestamp support, we will still preserve -1 for special meanings and trade that we cannot represent that specific ms in history &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="16785150" author="guozhang" created="Wed, 6 Mar 2019 01:51:22 +0000"  >&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; It wouldn&apos;t be terrible if we sometimes held on to records a little longer than necessary, but actually, I think this won&apos;t happen either.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;Hmm I think there&apos;s still a risk for this, depending on how users think of suppression semantics: back to my example in the first comment, and consider a windowed count with length 10 and grace 0, users would expect that a final result of window (0,10) be sent when r3 is processed with value 2, but they would not see the result even after r4&apos;s processed since the ST is only 2 at that sub-topology, right?&lt;/p&gt;</comment>
                            <comment id="16822327" author="yohan123" created="Sat, 20 Apr 2019 03:07:34 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mjsax&quot; class=&quot;user-hover&quot; rel=&quot;mjsax&quot;&gt;mjsax&lt;/a&gt; Do you think it would be fine if I took this issue?&lt;/p&gt;</comment>
                            <comment id="16822535" author="mjsax" created="Sat, 20 Apr 2019 18:13:10 +0000"  >&lt;p&gt;It&apos;s a little unclear how to tackle the issue atm, and it might turn out to be rather complex...&#160;&lt;/p&gt;</comment>
                            <comment id="16822589" author="yohan123" created="Sun, 21 Apr 2019 00:11:17 +0000"  >&lt;p&gt;Oh, I&apos;m fine doing some digging though. I might try to take a hack at it, but thanks for the heads up!&lt;/p&gt;</comment>
                            <comment id="16833952" author="yohan123" created="Mon, 6 May 2019 15:59:55 +0000"  >&lt;p&gt;Alright, so I&#160;posted a small patch which might help resolve this issue. Will open a PR soon as well.&lt;/p&gt;</comment>
                            <comment id="16835192" author="githubbot" created="Tue, 7 May 2019 23:23:13 +0000"  >&lt;p&gt;ConcurrencyPractitioner commented on pull request #6694: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7994&quot; title=&quot;Improve Partition-Time for rebalances and restarts&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7994&quot;&gt;&lt;del&gt;KAFKA-7994&lt;/del&gt;&lt;/a&gt; Improve Stream time accuracy for restarts and rebalances &lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/6694&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/6694&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   The issue for this PR could be found here:&lt;br/&gt;
   &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7994?jql=project%20%3D%20KAFKA%20AND%20status%20in%20(Open%2C%20%22In%20Progress%22%2C%20Reopened%2C%20%22Patch%20Available%22&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/KAFKA-7994?jql=project%20%3D%20KAFKA%20AND%20status%20in%20(Open%2C%20%22In%20Progress%22%2C%20Reopened%2C%20%22Patch%20Available%22&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;   As noted in the JIRA description, stream time is incorrectly set to -1 after rebalances and restarts. To help resolve this issue, a straightforward approach is to commit the individual partition time with last message processed for each RecordQueue. Hence, after a restart, we could set the partition time to the last committed partition time. &lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on to GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16843223" author="yohan123" created="Sat, 18 May 2019 18:08:16 +0000"  >&lt;p&gt;Ok, I&#160;did some thinking about how to propagate the timestamp down a topology and here is one idea. Whenever we forward a record to the next&#160;node for evaluation, we update the ProcessorRecordContext of the next node as well. It is in this&#160;record context&#160;that we can attach the&#160;partition time information. In this approach,&#160;ProcessorRecordContext would include a new field which tracks the partition time of a particular&#160;partition. So when a record is forwarded and is received, the next node/StreamTask will also have their ProcessorContext updated with its partition time as well by the upstream processor.&lt;/p&gt;

&lt;p&gt;These steps&#160;would be repeated as partitions make their way downstream starting from the head of the DAG. It doesn&apos;t matter if some records are filtered out before they make it into the lower sub-topologies. The records which do get passed in&#160;would also trigger an automatic update of the downstream node&apos;s partition time.&lt;/p&gt;</comment>
                            <comment id="16843402" author="mjsax" created="Sun, 19 May 2019 11:37:13 +0000"  >&lt;p&gt;Adding partition time to the context might be a good idea. I was thinking about this in the past already. We might want to extend public interface `RecordContext` to add partition and/or stream time. (This would require a KIP though.) It would be good information for users at PAPI level.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;So when a record is forwarded and is received, the next node/StreamTask will also have their ProcessorContext updated with its partition time as well by the upstream processor.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;How would that work? Atm, the context&apos;s life-cycle is limited to a single task and not forwarded through topics.&lt;/p&gt;

&lt;p&gt;What is also unclear: how would a downstream task process this information? A single task may have multiple upstream tasks, and those upstream tasks, could report different partition times (also not necessarily monotonically increasing). It&apos;s unclear to me, how this should be handled?&lt;/p&gt;

&lt;p&gt;Thinking about all this, I am wondering if it might make sense to start a wiki page (new sub page in &lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams&lt;/a&gt;) to discuss this issue? It would be a great way to document the semantics and internals for users? \cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vvcephei&quot; class=&quot;user-hover&quot; rel=&quot;vvcephei&quot;&gt;vvcephei&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16843517" author="mjsax" created="Sun, 19 May 2019 18:14:32 +0000"  >&lt;p&gt;&amp;gt;&#160;So this might handle how partition time is transmitted.&lt;/p&gt;

&lt;p&gt;Not sure what you mean by this? Tasks can exchange data only via repartition topics. To me, it&apos;s still unclear how an upstream task forwards it&apos;s partition time to a downstream task?&lt;/p&gt;</comment>
                            <comment id="16843534" author="yohan123" created="Sun, 19 May 2019 20:07:38 +0000"  >&lt;p&gt;Oh, just realized what was wrong with my approach. You are right:&#160;The headers stored in RecordContext&#160;is probably the only way to get the partition time sent over&#160;to the next task. I will look into it.&lt;/p&gt;</comment>
                            <comment id="16843540" author="yohan123" created="Sun, 19 May 2019 20:38:18 +0000"  >&lt;p&gt;Ok, after digging around, I figured this much out:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Headers are also stored in ProducerRecords when they are sent over. The headers that are sent in the SinkNode are RecordContext&apos;s headers.&lt;/li&gt;
	&lt;li&gt;However, that does not mean the headers before they are serialized and put into a ProducerRecord, that we cannot append more headers. What we can do is add an extra header to the headers we already have (i.e. on top of RecordContext&apos;s headers, add a &lt;tt&gt;new RecordHeader(&quot;partition time&quot;, Long.toByteArray(timestamp))&lt;/tt&gt;).&lt;/li&gt;
	&lt;li&gt;When StreamThread polls for ConsumerRecords to process, from the ConsumerRecords received, we would simply request for the header with the &lt;tt&gt;&quot;partition time&quot;&lt;/tt&gt; string key. The value stored along side the key is our needed partition timestamp.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;In effect, this does not require us to modify RecordContext, and also allows a quick, cheap way of delivering partition times across tasks. Please note that this new header we are adding is completely separate from RecordContext&apos;s headers.&#160;&lt;/p&gt;</comment>
                            <comment id="16843739" author="mjsax" created="Mon, 20 May 2019 07:48:05 +0000"  >&lt;p&gt;I am personally not convinced, that using headers is the best approach. For internal repartition topics it might be ok, but what about user topics (eg, `through()`)? For PAPI users, all topic are considered user topics and we might &quot;pollute&quot; the&#160;stream by adding headers.&lt;/p&gt;

&lt;p&gt;Would be good&#160;to hear what other think about this issue?&lt;/p&gt;</comment>
                            <comment id="16845338" author="yohan123" created="Tue, 21 May 2019 23:00:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mjsax&quot; class=&quot;user-hover&quot; rel=&quot;mjsax&quot;&gt;mjsax&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vvcephei&quot; class=&quot;user-hover&quot; rel=&quot;vvcephei&quot;&gt;vvcephei&lt;/a&gt; I created a KIP for this issue so we could discuss this more in detail. Below is the link.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/KIP-472%3A+%5BSTREAMS%5D+Add+partition+time+field+to+RecordContext&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://cwiki.apache.org/confluence/display/KAFKA/KIP-472%3A+%5BSTREAMS%5D+Add+partition+time+field+to+RecordContext&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Hope this could facilitate the process! &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="16845381" author="ableegoldman" created="Wed, 22 May 2019 00:50:43 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Yohan123&quot; class=&quot;user-hover&quot; rel=&quot;Yohan123&quot;&gt;Yohan123&lt;/a&gt;, I think we need to be careful&#160;in assuming a singular view of streamtime across&#160;tasks or even within a single task. Rather than it being an obstacle that different subtopologies can&apos;t &quot;talk&quot; to one another and pass along a single stream time, I think this actually enforces correctness &#8211; each node has its own sense of time and it doesn&apos;t make sense for them to look upstream for the time&#160;as seen by a different node. See&#160;&lt;a href=&quot;https://github.com/apache/kafka/pull/6278&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/6278#&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16846857" author="mjsax" created="Thu, 23 May 2019 16:50:44 +0000"  >&lt;p&gt;I think it might actually be worth to split the two issues into two tickets. One ticket to just preserve partition time over restarts (the original issue of this ticket), and do a new ticket for global stream time. There are still many open question what global stream time actually means and it will be a difficult and long design phase until we can merge any code. Hence, I would like to unblock the original issue of this ticket.&lt;/p&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;</comment>
                            <comment id="16848534" author="yohan123" created="Sun, 26 May 2019 21:20:21 +0000"  >&lt;p&gt;Sure &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mjsax&quot; class=&quot;user-hover&quot; rel=&quot;mjsax&quot;&gt;mjsax&lt;/a&gt; I&apos;m all for it, since it looks like the global stream time will be hard to define. So should I rebase my PR to only cover this issue?&lt;/p&gt;</comment>
                            <comment id="16848607" author="mjsax" created="Mon, 27 May 2019 04:27:14 +0000"  >&lt;p&gt;Yes. Please rebase the PR to only&#160;include&#160;the &quot;preserve partition time&quot; fix. This helps to make progress. Thanks a lot.&lt;/p&gt;</comment>
                            <comment id="16848610" author="yohan123" created="Mon, 27 May 2019 04:43:33 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mjsax&quot; class=&quot;user-hover&quot; rel=&quot;mjsax&quot;&gt;mjsax&lt;/a&gt; Made the change.&lt;/p&gt;</comment>
                            <comment id="16848791" author="cadonna" created="Mon, 27 May 2019 10:04:16 +0000"  >&lt;p&gt;I run into a case where the reset of the stream time to -1 after a restart resulted in incorrect results. More specifically, an event that should have been dropped because the grace period was exceeded opened a window.&lt;/p&gt;

&lt;p&gt;Suppose the following application:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
builder
   .stream(INPUT_TOPIC, Consumed.with(Serdes.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;(), Serdes.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;()))
   .groupByKey()
   .windowedBy(TimeWindows.of(Duration.ofMinutes(60)).grace(Duration.ofMinutes(30)))
   ...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;with the following input (numbers are timestamps)&lt;br/&gt;
m1, m2, m3, m61, m4, m90, m5 &lt;br/&gt;
application restart&lt;br/&gt;
m6, m150&lt;/p&gt;

&lt;p&gt;With the reset of the stream time to -1 after restart, the application will create the following windows:&lt;br/&gt;
[0, 60), &lt;/p&gt;
{m1, m2, m3, m4}
&lt;p&gt;[0, 60), &lt;/p&gt;
{m6}&lt;br/&gt;
[60, 120), {m61, m90}&lt;br/&gt;
&lt;br/&gt;
Window [0, 60), {m6}
&lt;p&gt; is wrong because if there had not be a restart, stream time would be at 90 when m6 reaches the processor. Stream time 90 is outside the grace period and m6 should be dropped. However, with the restart stream time is reset to -1 and m6 is not dropped because the condition to drop events timestamp &amp;lt; stream-time - grace-period is not satisfied, i.e., 6 &amp;lt; -1 - 30. Hence, a second window [0, 60) is incorrectly opened.&lt;/p&gt;</comment>
                            <comment id="16849022" author="yohan123" created="Mon, 27 May 2019 15:29:08 +0000"  >&lt;p&gt;Hi Bruno. I think this one of the cases which this issue is working to fix. I think if my PR is merged, then this example you mentioned should no longer be a problem (time is reset correctly after restarts).&#160;&lt;/p&gt;</comment>
                            <comment id="16853118" author="nijo" created="Fri, 31 May 2019 15:29:52 +0000"  >&lt;p&gt;Bruno&apos;s example above indicates it actually does affect `suppress` operator in terms of producing only &apos;final window result&apos;. For me the keyword &apos;final&apos; suggests that one and only one result will be produced, whereas one simple rebalancing may cause multiple results of the same window.&lt;/p&gt;

&lt;p&gt;Only recently I&apos;ve been using `suppress` operator in my application and found out this behavior, so I&apos;ve&#160;created a pull request for my Kafka Streams example repository describing the steps to simply reproduce multiple `suppress` results:&lt;br/&gt;
&lt;a href=&quot;https://github.com/mowczare/kafka-streams-scala/pull/1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/mowczare/kafka-streams-scala/pull/1&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16853388" author="mjsax" created="Fri, 31 May 2019 20:11:30 +0000"  >&lt;p&gt;Well. `suppress()` in not &quot;affected&quot; because `suppress()` itself does not have a bug &#8211; but you are correct, that if the bug hit, `suppress()` will emit duplicates (with this regard, is is affected &#8211; however, indirectly, because the lost partition time information itself does not break `suppress()` because suppress never uses this information). The upstream `aggregation()` uses the partition time information, thus, only `aggregate()` is affected directly (while `suppress()` issue is an indirect one). Does this make sense?&lt;/p&gt;</comment>
                            <comment id="16923359" author="cadonna" created="Thu, 5 Sep 2019 12:22:49 +0000"  >&lt;p&gt;I applied PR #6694 on the example I presented in my comment above. Unfortunately, it does not solve the issue, because the stream time handling is a bit intricate. Additionally to partition time, also a local processor time that depends on the partition time needs to be kept and made fail-safe to solve the issue. Although &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Yohan123&quot; class=&quot;user-hover&quot; rel=&quot;Yohan123&quot;&gt;Yohan123&lt;/a&gt;&apos;s PR does not fix the issue, it is the important first step to get it fixed.&lt;/p&gt;</comment>
                            <comment id="16933680" author="githubbot" created="Thu, 19 Sep 2019 18:50:30 +0000"  >&lt;p&gt;mjsax commented on pull request #6694: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7994&quot; title=&quot;Improve Partition-Time for rebalances and restarts&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7994&quot;&gt;&lt;del&gt;KAFKA-7994&lt;/del&gt;&lt;/a&gt; Improve Stream time accuracy for restarts and rebalances &lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/6694&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/6694&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on to GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="17005915" author="ableegoldman" created="Tue, 31 Dec 2019 03:19:47 +0000"  >&lt;p&gt;I&apos;m not sure we should close this yet, it seems like we still have more work to do for time to be accurately tracked for all operations&lt;/p&gt;</comment>
                            <comment id="17006224" author="mjsax" created="Tue, 31 Dec 2019 20:24:24 +0000"  >&lt;p&gt;This particular issue about stream time is resolved. We should create new tickets if there are other issues.&lt;/p&gt;</comment>
                            <comment id="17007124" author="ableegoldman" created="Thu, 2 Jan 2020 23:14:45 +0000"  >&lt;p&gt;The gist of this ticket is &quot;Partition-time, the max timestamp by partition, is not saved after a rebalance/restart. This partition-time is used to determine when to drop late records. Therefore, a rebalance/restart can cause non-deterministic results.&quot;&lt;/p&gt;

&lt;p&gt;Only the first sentence of that was true and has been fixed. I&apos;m fine with opening a new ticket to address the actual problem: that records are dropped based on the local processor-time, which is not saved after a rebalance/restart. But if we leave this closed we should at least update the ticket&apos;s description to reflect what has/hasn&apos;t been fixed, so it won&apos;t mislead users.&lt;/p&gt;</comment>
                            <comment id="17007697" author="mjsax" created="Fri, 3 Jan 2020 19:01:38 +0000"  >&lt;p&gt;Feel free to update the ticket &#8211; but we should create new tickets instead &#8211; this feature is shipped in 2.4 and for tracking purpose we should not reopen.&lt;/p&gt;</comment>
                            <comment id="17009128" author="ableegoldman" created="Mon, 6 Jan 2020 19:49:29 +0000"  >&lt;p&gt;Since we fixed part of this issue but not the full scope since partition-time is no longer used to determine stream-time, I&apos;ve updated the description to cover only the preservation of partition-time (which was fixed for 2.4). The remaining work w.r.t preserving stream-time was broken out into a new ticket so we can track that separately. See &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-9368&quot; title=&quot;Preserve stream-time across rebalances/restarts&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-9368&quot;&gt;KAFKA-9368&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13277771">KAFKA-9368</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12967945" name="possible-patch.diff" size="5535" author="Yohan123" created="Mon, 6 May 2019 15:59:16 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 45 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0010g:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>