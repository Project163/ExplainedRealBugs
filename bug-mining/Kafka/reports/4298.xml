<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:43:55 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-19479] at_least_once mode in Kafka Streams silently drops messages when the producer fails with MESSAGE_TOO_LARGE, violating delivery guarantees</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-19479</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;&lt;b&gt;Description&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;It appears there is a scenario where Kafka Streams running with &lt;tt&gt;processing.guarantee=at_least_once&lt;/tt&gt; does &lt;b&gt;not uphold its delivery guarantees&lt;/b&gt;, resulting in &lt;b&gt;message loss.&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Reproduction Details&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;We run a simple Kafka Streams topology like the following:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
props[StreamsConfig.APPLICATION_ID_CONFIG] = &lt;span class=&quot;code-quote&quot;&gt;&quot;poc-at-least-once&quot;&lt;/span&gt;
props[StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG] = Serdes.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;().javaClass.name
props[StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG] = Serdes.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;().javaClass.name
props[StreamsConfig.PROCESSING_GUARANTEE_CONFIG] = StreamsConfig.AT_LEAST_ONCE
&lt;span class=&quot;code-comment&quot;&gt;// Large producer batch size to induce MESSAGE_TOO_LARGE
&lt;/span&gt;props[ProducerConfig.LINGER_MS_CONFIG] = &lt;span class=&quot;code-quote&quot;&gt;&quot;300000&quot;&lt;/span&gt;
props[ProducerConfig.BATCH_SIZE_CONFIG] = &lt;span class=&quot;code-quote&quot;&gt;&quot;33554432&quot;&lt;/span&gt;
/** &#160; &#160; &#160; &#160; 
* a custom ProductionExceptionHandler is registered to demonstrate that it is not triggered in &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; scenario. 
* in fact, neither the ProductionExceptionHandler nor the StreamsUncaughtExceptionHandler are invoked during &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; failure &#160; &#160; &#160;  
*/ props[StreamsConfig.PRODUCTION_EXCEPTION_HANDLER_CLASS_CONFIG] = &lt;span class=&quot;code-quote&quot;&gt;&quot;poc.MyProductionExceptionHandler&quot;&lt;/span&gt;

val stream = streamsBuilder.stream&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt;(&lt;span class=&quot;code-quote&quot;&gt;&quot;input.topic&quot;&lt;/span&gt;)
stream.peek { key, value -&amp;gt; println(&lt;span class=&quot;code-quote&quot;&gt;&quot;$key:$value&quot;&lt;/span&gt;) }
&#160; &#160; &#160; .to(&lt;span class=&quot;code-quote&quot;&gt;&quot;output.topic&quot;&lt;/span&gt;)*
&#160;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;What we observe:&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Records from &lt;tt&gt;input.topic&lt;/tt&gt; are consumed and buffered at producer side&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;After some time (likely based on &lt;tt&gt;commit.interval.ms&lt;/tt&gt;), the &lt;b&gt;consumer offset is committed&lt;/b&gt;&lt;/li&gt;
	&lt;li&gt;Producer records &lt;b&gt;flush&lt;/b&gt; is triggered&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;The sendind of records to kafka broker fails with &lt;tt&gt;MESSAGE_TOO_LARGE&lt;/tt&gt;&lt;b&gt;{&lt;/b&gt;}&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;As a result, the application &lt;b&gt;commits offsets without actually producing the records&lt;/b&gt;, which leads to &lt;b&gt;silent message loss&lt;/b&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Steps to Reproduce&lt;/b&gt;&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Generate ~50,000 records (sized similarly to the sample project) in &lt;tt&gt;input.topic to induce MESSAGE_TOO_LARGE&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;Start the topology with the configuration above&lt;/li&gt;
	&lt;li&gt;Wait for all messages to be consumed&lt;/li&gt;
	&lt;li&gt;Observe:&lt;/li&gt;
&lt;/ol&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;Offsets are committed&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;Output topic receives no messages&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;Log shows repeated &lt;tt&gt;MESSAGE_TOO_LARGE&lt;/tt&gt; error:&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
11:50:30.695 [kafka-producer-network-thread | kstreams-poc-v1-37858c2e-7584-4489-8081-0111f710c431-StreamThread-1-producer] WARN &#160;o.a.k.c.producer.internals.Sender - [Producer clientId=kstreams-poc-v1-37858c2e-7584-4489-8081-0111f710c431-StreamThread-1-producer] Got error produce response in correlation id 255 on topic-partition output.topic-0, splitting and retrying (2147483647 attempts left). Error: MESSAGE_TOO_LARGE &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Reproduced&lt;/b&gt;&#160;with :&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;kafka-client-3.7.0, kafka-streams-3.7.0&lt;/li&gt;
	&lt;li&gt;kafka-client-4.-.0, kafka-streams-4.0.0&lt;/li&gt;
	&lt;li&gt;kafka-client-7.9.2-ccs, kafka-streams-7.9.2-ccs&lt;/li&gt;
	&lt;li&gt;kafka-client-8.0.0-ccs, kafka-streams-8.0.0-ccs&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Expected Behavior&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;In &lt;tt&gt;at_least_once&lt;/tt&gt; mode, Kafka Streams should &lt;b&gt;not commit offsets&lt;/b&gt; unless records are &lt;b&gt;successfully produced&lt;/b&gt;.&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Attached&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;configs for stream, producer, consumer&lt;/li&gt;
	&lt;li&gt;sample project used to replicate the issue&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment>Micronaut 4.5.4&lt;br/&gt;
&lt;br/&gt;
Java 21&lt;br/&gt;
&lt;br/&gt;
Kotlin 1.9.3&lt;br/&gt;
&lt;br/&gt;
Kafka clients/streams:&lt;br/&gt;
&lt;br/&gt;
Apache Kafka 3.7.0, 4.0.0&lt;br/&gt;
&lt;br/&gt;
Confluent: 7.9.2-ccs, 8.0.0-ccs&lt;br/&gt;
&lt;br/&gt;
Kafka running in Docker (local test environment)</environment>
        <key id="13622789">KAFKA-19479</key>
            <summary>at_least_once mode in Kafka Streams silently drops messages when the producer fails with MESSAGE_TOO_LARGE, violating delivery guarantees</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="shashankhs">Shashank</assignee>
                                    <reporter username="lucimihai">Mihai Lucian</reporter>
                        <labels>
                    </labels>
                <created>Tue, 8 Jul 2025 09:23:07 +0000</created>
                <updated>Fri, 7 Nov 2025 00:38:29 +0000</updated>
                            <resolved>Thu, 16 Oct 2025 22:28:00 +0000</resolved>
                                                    <fixVersion>3.9.2</fixVersion>
                    <fixVersion>4.2.0</fixVersion>
                    <fixVersion>4.0.2</fixVersion>
                    <fixVersion>4.1.1</fixVersion>
                                    <component>streams</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="18003734" author="JIRAUSER310237" created="Tue, 8 Jul 2025 10:57:58 +0000"  >&lt;p&gt;&lt;b&gt;Clarification&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;The configuration settings described above are not used in any of our actual projects, and the issue demonstrated in this example is not the root cause of the original problem we encountered.&lt;/p&gt;

&lt;p&gt;Our real concern involves message loss during the scaling of stateful Kafka Streams applications. In the process of investigating whether there are scenarios in which at_least_once processing might fail to uphold its delivery guarantees, we developed this proof of concept to explore and replicate such edge cases.&lt;/p&gt;</comment>
                            <comment id="18005514" author="JIRAUSER310237" created="Tue, 15 Jul 2025 07:04:24 +0000"  >&lt;p&gt;Additional comments on the delivery.timeout,ms:&lt;/p&gt;

&lt;p&gt;Upon reviewing the streamsd-config.txt, it can be observed the following log entry, which indicates that the Kafka producer is intelligent enough to automatically adjust the&#160;&lt;a href=&quot;http://delivery.timeout.ms/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;delivery.timeout.ms&lt;/a&gt;&#160;setting to ensure it aligns with the expected behavior:&lt;br/&gt;
11:47:50.649 &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; WARN&#160; o.a.k.clients.producer.KafkaProducer - &lt;span class=&quot;error&quot;&gt;&amp;#91;Producer clientId=kstreams-poc-v1-37858c2e-7584-4489-8081-0111f710c431-StreamThread-1-producer&amp;#93;&lt;/span&gt;&#160;&lt;a href=&quot;http://delivery.timeout.ms/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;delivery.timeout.ms&lt;/a&gt;&#160;should be equal to or larger than&#160;&lt;a href=&quot;http://linger.ms/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;linger.ms&lt;/a&gt;&#160;&#160;&lt;ins&gt;&lt;a href=&quot;http://request.timeout.ms/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;request.timeout.ms&lt;/a&gt;. Setting it to 330000.&lt;/ins&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;ins&gt;Subsequently, I conducted additional tests in which I explicitly set&#160;&lt;a href=&quot;http://delivery.timeout.ms/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;delivery.timeout.ms&lt;/a&gt;&#160;to 400000 (i.e., greater than&#160;&lt;a href=&quot;http://linger.ms/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;linger.ms&lt;/a&gt;&lt;/ins&gt;&#160;&#160;&lt;a href=&quot;http://request.timeout.ms/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;request.timeout.ms&lt;/a&gt;) and also disabled the ProductionExceptionHandler. Despite these changes, the issue continues to persist.&lt;/p&gt;</comment>
                            <comment id="18007671" author="mjsax" created="Wed, 16 Jul 2025 23:05:49 +0000"  >&lt;p&gt;Thanks for following up with details... I hope we find time quickly to look into this. Sounds concerning.&lt;/p&gt;</comment>
                            <comment id="18008811" author="JIRAUSER310276" created="Mon, 21 Jul 2025 21:12:56 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mjsax&quot; class=&quot;user-hover&quot; rel=&quot;mjsax&quot;&gt;mjsax&lt;/a&gt;, I would like to start working on this issue. I have reviewed this issue and was able to reproduce the behaviour locally with the attached poc. My initial plan is to create an integration test that reproduces the issue within streams and fails accordingly.&lt;/p&gt;

&lt;p&gt;I don&apos;t yet have a fix in mind, but do you think it would be wise for me to start by writing the failing integration test and then opening a PR with this failing test? That way, you can review it to confirm whether this is indeed a bug. Would opening such a PR affect any existing workflows, or is that approach okay? Once we align on that and confirm that this is a bug, I can proceed with the investigation and work on a possible solution.&lt;/p&gt;</comment>
                            <comment id="18010229" author="mjsax" created="Sun, 27 Jul 2025 22:32:17 +0000"  >&lt;p&gt;Thanks a lot &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shashankhs&quot; class=&quot;user-hover&quot; rel=&quot;shashankhs&quot;&gt;shashankhs&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;My initial plan is to create an integration test that reproduces the issue within streams and fails accordingly.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This sounds like an excellent idea. I like the idea to start with a PR, that only adds this test (and let the test fail during initial review, and disable it before we merge the PR). If we can merge a test PR, it&apos;s easier for others to help looking into the issue, by enabling the test in a local branch.&lt;/p&gt;</comment>
                            <comment id="18010534" author="JIRAUSER310276" created="Tue, 29 Jul 2025 01:10:09 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mjsax&quot; class=&quot;user-hover&quot; rel=&quot;mjsax&quot;&gt;mjsax&lt;/a&gt;, I pushed the integration test and is ready to be reviewed here - &lt;a href=&quot;https://github.com/apache/kafka/pull/20254&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;#20254&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="18010746" author="mjsax" created="Tue, 29 Jul 2025 21:32:46 +0000"  >&lt;p&gt;Thanks for the test case. I believe it&apos;s actually a bug in the producer: &lt;a href=&quot;https://github.com/apache/kafka/pull/20254#issuecomment-3134139853&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/20254#issuecomment-3134139853&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="18010788" author="JIRAUSER310276" created="Wed, 30 Jul 2025 02:50:42 +0000"  >&lt;p&gt;Thank you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mjsax&quot; class=&quot;user-hover&quot; rel=&quot;mjsax&quot;&gt;mjsax&lt;/a&gt;. Since you confirmed that it is indeed a bug in KafkaProducer, should we go ahead and disable the test case and merge the testcase, like you mentioned earlier, so that anyone can help looking into this issue? &lt;/p&gt;

&lt;p&gt;Next, I am planning on tracing the bug and understanding it better, so that I can write more specific failing tests.&lt;/p&gt;</comment>
                            <comment id="18030485" author="junrao" created="Thu, 16 Oct 2025 22:28:00 +0000"  >&lt;p&gt;Merged &lt;a href=&quot;https://github.com/apache/kafka/pull/20285&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/20285&lt;/a&gt; to trunk.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13232602">KAFKA-8350</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="13077346" name="poc-kafka-streams-al-least-once-proj.zip" size="246870" author="lucimihai" created="Tue, 8 Jul 2025 09:34:24 +0000"/>
                            <attachment id="13077347" name="stream-configs.txt" size="20398" author="lucimihai" created="Tue, 8 Jul 2025 09:37:34 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1wnio:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>mjsax</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>