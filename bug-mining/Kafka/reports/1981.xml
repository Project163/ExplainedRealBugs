<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:13:00 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-5098] KafkaProducer.send() blocks and generates TimeoutException if topic name has illegal char</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-5098</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;The server is running with auto create enabled. If we try to publish to a topic with a forward slash in the name, the call blocks and we get a TimeoutException in the Callback. I would expect it to return immediately with an InvalidTopicException.&lt;/p&gt;

&lt;p&gt;There are other blocking issues that have been reported which may be related to some degree, but this particular cause seems unrelated.&lt;/p&gt;

&lt;p&gt;Sample code:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.kafka.clients.producer.*;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.util.*;

&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;KafkaProducerUnexpectedBlockingAndTimeoutException {

  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; void main(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] args) {
    Properties props = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Properties();
    props.put(&lt;span class=&quot;code-quote&quot;&gt;&quot;bootstrap.servers&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;kafka.example.com:9092&quot;&lt;/span&gt;);
    props.put(&lt;span class=&quot;code-quote&quot;&gt;&quot;key.serializer&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.kafka.common.serialization.StringSerializer&quot;&lt;/span&gt;);
    props.put(&lt;span class=&quot;code-quote&quot;&gt;&quot;value.serializer&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.kafka.common.serialization.StringSerializer&quot;&lt;/span&gt;);
    props.put(&lt;span class=&quot;code-quote&quot;&gt;&quot;max.block.ms&quot;&lt;/span&gt;, 10000); &lt;span class=&quot;code-comment&quot;&gt;// 10 seconds should illustrate our point
&lt;/span&gt;
    &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; separator = &lt;span class=&quot;code-quote&quot;&gt;&quot;/&quot;&lt;/span&gt;;
    &lt;span class=&quot;code-comment&quot;&gt;//&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; separator = &lt;span class=&quot;code-quote&quot;&gt;&quot;_&quot;&lt;/span&gt;;
&lt;/span&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; (Producer&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; producer = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KafkaProducer&amp;lt;&amp;gt;(props)) {

      &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;Calling KafkaProducer.send() at &quot;&lt;/span&gt; + &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Date());
      producer.send(
          &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ProducerRecord&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt;(&lt;span class=&quot;code-quote&quot;&gt;&quot;abc&quot;&lt;/span&gt; + separator + &lt;span class=&quot;code-quote&quot;&gt;&quot;someStreamName&quot;&lt;/span&gt;,
              &lt;span class=&quot;code-quote&quot;&gt;&quot;Not expecting a TimeoutException here&quot;&lt;/span&gt;),
          &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Callback() {
            @Override
            &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void onCompletion(RecordMetadata metadata, Exception e) {
              &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (e != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
                &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(e.toString());
              }
            }
          });
      &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;KafkaProducer.send() completed at &quot;&lt;/span&gt; + &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Date());
    }


  }

}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Switching to the underscore separator in the above example works as expected.&lt;/p&gt;

&lt;p&gt;Mea culpa: We neglected to research allowed chars in a topic name, but the TimeoutException we encountered did not help point us in the right direction.&lt;/p&gt;
</description>
                <environment>Java client running against server using wurstmeister/kafka Docker image.</environment>
        <key id="13065691">KAFKA-5098</key>
            <summary>KafkaProducer.send() blocks and generates TimeoutException if topic name has illegal char</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ahmeda">Ahmed Al-Mehdi</assignee>
                                    <reporter username="jlar310">Jeff Larsen</reporter>
                        <labels>
                    </labels>
                <created>Thu, 20 Apr 2017 22:12:42 +0000</created>
                <updated>Tue, 17 Jul 2018 23:39:22 +0000</updated>
                            <resolved>Tue, 17 Jul 2018 23:39:22 +0000</resolved>
                                    <version>0.10.2.0</version>
                                    <fixVersion>2.1.0</fixVersion>
                                    <component>producer </component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="15979910" author="umesh9794@gmail.com" created="Sat, 22 Apr 2017 12:45:08 +0000"  >&lt;p&gt;I will reproduce and work on this. &lt;/p&gt;</comment>
                            <comment id="16035873" author="githubbot" created="Sat, 3 Jun 2017 06:51:58 +0000"  >&lt;p&gt;GitHub user huxihx opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/3223&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3223&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5098&quot; title=&quot;KafkaProducer.send() blocks and generates TimeoutException if topic name has illegal char&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5098&quot;&gt;&lt;del&gt;KAFKA-5098&lt;/del&gt;&lt;/a&gt;: KafkaProducer.send() should validate topic name before sending&lt;/p&gt;

&lt;p&gt;    KafkaProducer.send() should check topic name before sending the record.&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/huxihx/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/huxihx/kafka&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5098&quot; title=&quot;KafkaProducer.send() blocks and generates TimeoutException if topic name has illegal char&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5098&quot;&gt;&lt;del&gt;KAFKA-5098&lt;/del&gt;&lt;/a&gt;_Does_not_check_topic_name_before_sending&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/3223.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3223.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #3223&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit b457518b55f8f7c32ca5e6849fa4052b596c98e1&lt;br/&gt;
Author: huxihx &amp;lt;huxi_2b@hotmail.com&amp;gt;&lt;br/&gt;
Date:   2017-06-03T06:50:05Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5098&quot; title=&quot;KafkaProducer.send() blocks and generates TimeoutException if topic name has illegal char&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5098&quot;&gt;&lt;del&gt;KAFKA-5098&lt;/del&gt;&lt;/a&gt;: KafkaProducer.send() blocks and generates TimeoutException if topic name has illegal char&lt;/p&gt;

&lt;p&gt;    Validate topic name before sending the record&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="16035909" author="ijuma" created="Sat, 3 Jun 2017 09:41:12 +0000"  >&lt;p&gt;Issue resolved by pull request 3223&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/pull/3223&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3223&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16035910" author="githubbot" created="Sat, 3 Jun 2017 09:41:45 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/3223&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3223&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16036327" author="ijuma" created="Sun, 4 Jun 2017 16:34:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=onurkaraman&quot; class=&quot;user-hover&quot; rel=&quot;onurkaraman&quot;&gt;onurkaraman&lt;/a&gt; correctly asked about the potential performance impact of doing this check for each producer record. I did some micro-benchmarking and it could be significant (particularly if the topic name is long). I reverted the change for now until we have a chance to verify its impact via `ProducerPerformance`.&lt;/p&gt;

&lt;p&gt;I also submitted a PR that improves the performance of `Topic.validate()`:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/kafka/pull/3234&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3234&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16500755" author="jjkoshy" created="Mon, 4 Jun 2018 19:34:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=huxi_2b&quot; class=&quot;user-hover&quot; rel=&quot;huxi_2b&quot;&gt;huxi_2b&lt;/a&gt; are you&#160;still working on this? If not, someone on our team at LinkedIn can&#160;help with picking this up.&lt;/p&gt;

&lt;p&gt;Here is an alternate approach that avoids the performance concerns with the earlier one:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;The producer&apos;s metadata cache could save the set of invalid topics (since the broker already indicates this in the metadata response).&lt;/li&gt;
	&lt;li&gt;On&#160;metadata response, update the metatadata cache&apos;s set of invalid topics if the metadata response carries errors due to invalid topics. In any subsequent send to invalid topics, the &lt;tt&gt;waitOnMetadata&lt;/tt&gt;&#160;call would throw back the &lt;tt&gt;InvalidTopicException&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;This is pretty much similar to how we currently&#160;handle authorization exceptions.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="16512064" author="rsivaram" created="Thu, 14 Jun 2018 07:21:06 +0000"  >&lt;p&gt;Moving this out to 2.1.0 since it is not ready for 2.0.0&lt;/p&gt;</comment>
                            <comment id="16513059" author="ahmeda" created="Thu, 14 Jun 2018 22:08:27 +0000"  >&lt;p&gt;Since there was no response from the current Jira owner, I went ahead and created a PR for this issue.&lt;/p&gt;</comment>
                            <comment id="16516039" author="githubbot" created="Mon, 18 Jun 2018 17:20:08 +0000"  >&lt;p&gt;ahmedha closed pull request #5209: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5098&quot; title=&quot;KafkaProducer.send() blocks and generates TimeoutException if topic name has illegal char&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5098&quot;&gt;&lt;del&gt;KAFKA-5098&lt;/del&gt;&lt;/a&gt;: KafkaProducer.send() dose not block if topic name has illegal char an&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5209&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5209&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/clients/src/main/java/org/apache/kafka/clients/Metadata.java b/clients/src/main/java/org/apache/kafka/clients/Metadata.java&lt;br/&gt;
index b1da9de8ac1..91b15875cd0 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/Metadata.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/Metadata.java&lt;br/&gt;
@@ -353,6 +353,7 @@ private synchronized void requestUpdateForNewTopics() {&lt;/p&gt;

&lt;p&gt;     private Cluster getClusterForCurrentTopics(Cluster cluster) {&lt;br/&gt;
         Set&amp;lt;String&amp;gt; unauthorizedTopics = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
+        Set&amp;lt;String&amp;gt; invalidTopics = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
         Collection&amp;lt;PartitionInfo&amp;gt; partitionInfos = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
         List&amp;lt;Node&amp;gt; nodes = Collections.emptyList();&lt;br/&gt;
         Set&amp;lt;String&amp;gt; internalTopics = Collections.emptySet();&lt;br/&gt;
@@ -364,6 +365,9 @@ private Cluster getClusterForCurrentTopics(Cluster cluster) {&lt;br/&gt;
             unauthorizedTopics.addAll(cluster.unauthorizedTopics());&lt;br/&gt;
             unauthorizedTopics.retainAll(this.topics.keySet());&lt;/p&gt;

&lt;p&gt;+            invalidTopics.addAll(cluster.invalidTopics());&lt;br/&gt;
+            invalidTopics.addAll(this.cluster.invalidTopics());&lt;br/&gt;
+&lt;br/&gt;
             for (String topic : this.topics.keySet()) {&lt;br/&gt;
                 List&amp;lt;PartitionInfo&amp;gt; partitionInfoList = cluster.partitionsForTopic(topic);&lt;br/&gt;
                 if (!partitionInfoList.isEmpty()) {&lt;br/&gt;
@@ -373,6 +377,6 @@ private Cluster getClusterForCurrentTopics(Cluster cluster) &lt;/p&gt;
{
             nodes = cluster.nodes();
             controller  = cluster.controller();
         }
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return new Cluster(clusterId, nodes, partitionInfos, unauthorizedTopics, internalTopics, controller);&lt;br/&gt;
+        return new Cluster(clusterId, nodes, partitionInfos, unauthorizedTopics, invalidTopics, internalTopics, controller);&lt;br/&gt;
     }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java&lt;br/&gt;
index 9c19af17037..59686b9336c 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java&lt;br/&gt;
@@ -30,6 +30,7 @@&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition;&lt;br/&gt;
 import org.apache.kafka.common.errors.GroupAuthorizationException;&lt;br/&gt;
 import org.apache.kafka.common.errors.InterruptException;&lt;br/&gt;
+import org.apache.kafka.common.errors.InvalidTopicException;&lt;br/&gt;
 import org.apache.kafka.common.errors.RetriableException;&lt;br/&gt;
 import org.apache.kafka.common.errors.TimeoutException;&lt;br/&gt;
 import org.apache.kafka.common.errors.TopicAuthorizationException;&lt;br/&gt;
@@ -203,6 +204,10 @@ public void onMetadataUpdate(Cluster cluster, Set&amp;lt;String&amp;gt; unavailableTopics) 
{
                 if (!cluster.unauthorizedTopics().isEmpty())
                     throw new TopicAuthorizationException(new HashSet&amp;lt;&amp;gt;(cluster.unauthorizedTopics()));
 
+                // if we encounter any invalid topics, raise an exception to the user
+                if (!cluster.invalidTopics().isEmpty())
+                    throw new InvalidTopicException();
+
                 if (subscriptions.hasPatternSubscription())
                     updatePatternSubscription(cluster);
 
diff --git a/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java b/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java
index a5af5b60093..3ec73ea0afb 100644
--- a/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java
+++ b/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java
@@ -41,6 +41,7 @@
 import org.apache.kafka.common.errors.AuthenticationException;
 import org.apache.kafka.common.errors.AuthorizationException;
 import org.apache.kafka.common.errors.InterruptException;
+import org.apache.kafka.common.errors.InvalidTopicException;
 import org.apache.kafka.common.errors.ProducerFencedException;
 import org.apache.kafka.common.errors.RecordTooLargeException;
 import org.apache.kafka.common.errors.SerializationException;
@@ -900,6 +901,10 @@ private ClusterAndWaitTime waitOnMetadata(String topic, Integer partition, long
         // add topic to metadata topic list if it is not there already and reset expiry
         metadata.add(topic);
         Cluster cluster = metadata.fetch();
+
+        if (cluster.invalidTopics().contains(topic))
+            throw new InvalidTopicException(topic);
+
         Integer partitionsCount = cluster.partitionCountForTopic(topic);
         // Return cached metadata if we have it, and if the record&apos;s partition is either undefined
         // or within the known partition range
@@ -930,6 +935,8 @@ private ClusterAndWaitTime waitOnMetadata(String topic, Integer partition, long
                 throw new TimeoutException(&quot;Failed to update metadata after &quot; + maxWaitMs + &quot; ms.&quot;);
             if (cluster.unauthorizedTopics().contains(topic))
                 throw new TopicAuthorizationException(topic);
+            if (cluster.invalidTopics().contains(topic))
+                throw new InvalidTopicException(topic);
             remainingWaitMs = maxWaitMs - elapsed;
             partitionsCount = cluster.partitionCountForTopic(topic);
         }
&lt;p&gt; while (partitionsCount == null);&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/common/Cluster.java b/clients/src/main/java/org/apache/kafka/common/Cluster.java&lt;br/&gt;
index ccbaa306d48..33d37494bf5 100644&lt;/p&gt;&lt;/li&gt;
			&lt;li&gt;a/clients/src/main/java/org/apache/kafka/common/Cluster.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/common/Cluster.java&lt;br/&gt;
@@ -36,6 +36,7 @@&lt;br/&gt;
     private final boolean isBootstrapConfigured;&lt;br/&gt;
     private final List&amp;lt;Node&amp;gt; nodes;&lt;br/&gt;
     private final Set&amp;lt;String&amp;gt; unauthorizedTopics;&lt;br/&gt;
+    private final Set&amp;lt;String&amp;gt; invalidTopics;&lt;br/&gt;
     private final Set&amp;lt;String&amp;gt; internalTopics;&lt;br/&gt;
     private final Node controller;&lt;br/&gt;
     private final Map&amp;lt;TopicPartition, PartitionInfo&amp;gt; partitionsByTopicPartition;&lt;br/&gt;
@@ -55,7 +56,7 @@ public Cluster(String clusterId,&lt;br/&gt;
                    Collection&amp;lt;PartitionInfo&amp;gt; partitions,&lt;br/&gt;
                    Set&amp;lt;String&amp;gt; unauthorizedTopics,&lt;br/&gt;
                    Set&amp;lt;String&amp;gt; internalTopics) 
{
-        this(clusterId, false, nodes, partitions, unauthorizedTopics, internalTopics, null);
+        this(clusterId, false, nodes, partitions, unauthorizedTopics, Collections.&amp;lt;String&amp;gt;emptySet(), internalTopics, null);
     }&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;br/&gt;
@@ -69,7 +70,22 @@ public Cluster(String clusterId,&lt;br/&gt;
                    Set&amp;lt;String&amp;gt; unauthorizedTopics,&lt;br/&gt;
                    Set&amp;lt;String&amp;gt; internalTopics,&lt;br/&gt;
                    Node controller) &lt;/p&gt;
{
-        this(clusterId, false, nodes, partitions, unauthorizedTopics, internalTopics, controller);
+        this(clusterId, false, nodes, partitions, unauthorizedTopics, Collections.&amp;lt;String&amp;gt;emptySet(), internalTopics, controller);
+    }
&lt;p&gt;+&lt;br/&gt;
+    /**&lt;br/&gt;
+     * Create a new cluster with the given id, nodes and partitions&lt;br/&gt;
+     * @param nodes The nodes in the cluster&lt;br/&gt;
+     * @param partitions Information about a subset of the topic-partitions this cluster hosts&lt;br/&gt;
+     */&lt;br/&gt;
+    public Cluster(String clusterId,&lt;br/&gt;
+        Collection&amp;lt;Node&amp;gt; nodes,&lt;br/&gt;
+        Collection&amp;lt;PartitionInfo&amp;gt; partitions,&lt;br/&gt;
+        Set&amp;lt;String&amp;gt; unauthorizedTopics,&lt;br/&gt;
+        Set&amp;lt;String&amp;gt; invalidTopics,&lt;br/&gt;
+        Set&amp;lt;String&amp;gt; internalTopics,&lt;br/&gt;
+        Node controller) &lt;/p&gt;
{
+        this(clusterId, false, nodes, partitions, unauthorizedTopics, invalidTopics, internalTopics, controller);
     }

&lt;p&gt;     private Cluster(String clusterId,&lt;br/&gt;
@@ -77,6 +93,7 @@ private Cluster(String clusterId,&lt;br/&gt;
                     Collection&amp;lt;Node&amp;gt; nodes,&lt;br/&gt;
                     Collection&amp;lt;PartitionInfo&amp;gt; partitions,&lt;br/&gt;
                     Set&amp;lt;String&amp;gt; unauthorizedTopics,&lt;br/&gt;
+                    Set&amp;lt;String&amp;gt; invalidTopics,&lt;br/&gt;
                     Set&amp;lt;String&amp;gt; internalTopics,&lt;br/&gt;
                     Node controller) &lt;/p&gt;
{
         this.isBootstrapConfigured = isBootstrapConfigured;
@@ -131,6 +148,7 @@ private Cluster(String clusterId,
             this.partitionsByNode.put(entry.getKey(), Collections.unmodifiableList(entry.getValue()));
 
         this.unauthorizedTopics = Collections.unmodifiableSet(unauthorizedTopics);
+        this.invalidTopics = Collections.unmodifiableSet(invalidTopics);
         this.internalTopics = Collections.unmodifiableSet(internalTopics);
         this.controller = controller;
     }
&lt;p&gt;@@ -153,7 +171,8 @@ public static Cluster bootstrap(List&amp;lt;InetSocketAddress&amp;gt; addresses) &lt;/p&gt;
{
         int nodeId = -1;
         for (InetSocketAddress address : addresses)
             nodes.add(new Node(nodeId--, address.getHostString(), address.getPort()));
-        return new Cluster(null, true, nodes, new ArrayList&amp;lt;PartitionInfo&amp;gt;(0), Collections.&amp;lt;String&amp;gt;emptySet(), Collections.&amp;lt;String&amp;gt;emptySet(), null);
+        return new Cluster(null, true, nodes, new ArrayList&amp;lt;PartitionInfo&amp;gt;(0),
+                            Collections.&amp;lt;String&amp;gt;emptySet(), Collections.&amp;lt;String&amp;gt;emptySet(), Collections.&amp;lt;String&amp;gt;emptySet(), null);
     }

&lt;p&gt;     /**&lt;br/&gt;
@@ -163,7 +182,8 @@ public Cluster withPartitions(Map&amp;lt;TopicPartition, PartitionInfo&amp;gt; partitions) &lt;/p&gt;
{
         Map&amp;lt;TopicPartition, PartitionInfo&amp;gt; combinedPartitions = new HashMap&amp;lt;&amp;gt;(this.partitionsByTopicPartition);
         combinedPartitions.putAll(partitions);
         return new Cluster(clusterResource.clusterId(), this.nodes, combinedPartitions.values(),
-                new HashSet&amp;lt;&amp;gt;(this.unauthorizedTopics), new HashSet&amp;lt;&amp;gt;(this.internalTopics), this.controller);
+                new HashSet&amp;lt;&amp;gt;(this.unauthorizedTopics), new HashSet&amp;lt;&amp;gt;(this.invalidTopics),
+                new HashSet&amp;lt;&amp;gt;(this.internalTopics), this.controller);
     }

&lt;p&gt;     /**&lt;br/&gt;
@@ -172,7 +192,7 @@ public Cluster withPartitions(Map&amp;lt;TopicPartition, PartitionInfo&amp;gt; partitions) {&lt;br/&gt;
     public List&amp;lt;Node&amp;gt; nodes() &lt;/p&gt;
{
         return this.nodes;
     }
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;p&gt;+&lt;br/&gt;
     /**&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;Get the node by the node id (or null if no such node exists)&lt;/li&gt;
	&lt;li&gt;@param id The id of the node&lt;br/&gt;
@@ -256,6 +276,10 @@ public Integer partitionCountForTopic(String topic) 
{
         return unauthorizedTopics;
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+    public Set&amp;lt;String&amp;gt; invalidTopics() &lt;/p&gt;
{
+        return invalidTopics;
+    }
&lt;p&gt;+&lt;br/&gt;
     public Set&amp;lt;String&amp;gt; internalTopics() &lt;/p&gt;
{
         return internalTopics;
     }
&lt;p&gt;diff --git a/clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java b/clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java&lt;br/&gt;
index 28a412df800..09a04e55603 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java&lt;br/&gt;
@@ -366,7 +366,7 @@ public Cluster cluster() {&lt;br/&gt;
         }&lt;/p&gt;

&lt;p&gt;         return new Cluster(this.clusterId, this.brokers, partitions, topicsByError(Errors.TOPIC_AUTHORIZATION_FAILED),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;internalTopics, this.controller);&lt;br/&gt;
+                topicsByError(Errors.INVALID_TOPIC_EXCEPTION), internalTopics, this.controller);&lt;br/&gt;
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;br/&gt;
diff --git a/clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java b/clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java&lt;br/&gt;
index 8bfc5e7d28a..1354ea30ba2 100644&lt;br/&gt;
&amp;#8212; a/clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java&lt;br/&gt;
+++ b/clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java&lt;br/&gt;
@@ -16,6 +16,10 @@&lt;br/&gt;
  */&lt;br/&gt;
 package org.apache.kafka.clients.producer;&lt;/p&gt;

&lt;p&gt;+import java.util.ArrayList;&lt;br/&gt;
+import java.util.HashSet;&lt;br/&gt;
+import java.util.Set;&lt;br/&gt;
+import java.util.concurrent.ExecutionException;&lt;br/&gt;
 import org.apache.kafka.clients.CommonClientConfigs;&lt;br/&gt;
 import org.apache.kafka.clients.Metadata;&lt;br/&gt;
 import org.apache.kafka.clients.MockClient;&lt;br/&gt;
@@ -27,6 +31,7 @@&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition;&lt;br/&gt;
 import org.apache.kafka.common.config.ConfigException;&lt;br/&gt;
 import org.apache.kafka.common.errors.InterruptException;&lt;br/&gt;
+import org.apache.kafka.common.errors.InvalidTopicException;&lt;br/&gt;
 import org.apache.kafka.common.errors.TimeoutException;&lt;br/&gt;
 import org.apache.kafka.common.header.internals.RecordHeader;&lt;br/&gt;
 import org.apache.kafka.common.internals.ClusterResourceListeners;&lt;br/&gt;
@@ -68,6 +73,7 @@&lt;br/&gt;
 import static org.junit.Assert.assertEquals;&lt;br/&gt;
 import static org.junit.Assert.assertTrue;&lt;br/&gt;
 import static org.junit.Assert.fail;&lt;br/&gt;
+import static org.junit.Assert.assertNull;&lt;/p&gt;

&lt;p&gt; @RunWith(PowerMockRunner.class)&lt;br/&gt;
 @PowerMockIgnore(&quot;javax.management.*&quot;)&lt;br/&gt;
@@ -609,4 +615,51 @@ public void testOnlyCanExecuteCloseAfterInitTransactionsTimeout() &lt;/p&gt;
{
             producer.close(0, TimeUnit.MILLISECONDS);
         }
&lt;p&gt;     }&lt;br/&gt;
+&lt;br/&gt;
+    @Test&lt;br/&gt;
+    public void testInvalidTopicName() throws Exception {&lt;br/&gt;
+&lt;br/&gt;
+        Properties props = new Properties();&lt;br/&gt;
+        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9000&quot;);&lt;br/&gt;
+        props.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, &quot;15000&quot;);&lt;br/&gt;
+&lt;br/&gt;
+        Time time = new MockTime();&lt;br/&gt;
+        Cluster cluster = TestUtils.singletonCluster();&lt;br/&gt;
+        Node node = cluster.nodes().get(0);&lt;br/&gt;
+&lt;br/&gt;
+        Metadata metadata = new Metadata(0, Long.MAX_VALUE, true);&lt;br/&gt;
+        metadata.update(cluster, Collections.&amp;lt;String&amp;gt;emptySet(), time.milliseconds());&lt;br/&gt;
+&lt;br/&gt;
+        MockClient client = new MockClient(time, metadata);&lt;br/&gt;
+        client.setNode(node);&lt;br/&gt;
+&lt;br/&gt;
+        Producer&amp;lt;String, String&amp;gt; producer = new KafkaProducer&amp;lt;&amp;gt;(new ProducerConfig(&lt;br/&gt;
+            ProducerConfig.addSerializerToConfig(props, new StringSerializer(), new StringSerializer())),&lt;br/&gt;
+            new StringSerializer(), new StringSerializer(), metadata, client);&lt;br/&gt;
+&lt;br/&gt;
+        String topic = &quot;topic 10&quot;;&lt;br/&gt;
+        ProducerRecord&amp;lt;String, String&amp;gt; record = new ProducerRecord&amp;lt;&amp;gt;(topic, &quot;HelloKafka&quot;);&lt;br/&gt;
+&lt;br/&gt;
+        Set&amp;lt;String&amp;gt; invalidTopic = new HashSet&amp;lt;String&amp;gt;();&lt;br/&gt;
+        invalidTopic.add(topic);&lt;br/&gt;
+        Cluster metaDataUpdateResponseCluster = new Cluster(cluster.clusterResource().clusterId(),&lt;br/&gt;
+                                                            cluster.nodes(),&lt;br/&gt;
+                                                            new ArrayList&amp;lt;PartitionInfo&amp;gt;(0),&lt;br/&gt;
+                                                            Collections.&amp;lt;String&amp;gt;emptySet(),&lt;br/&gt;
+                                                            invalidTopic,&lt;br/&gt;
+                                                            cluster.internalTopics(),&lt;br/&gt;
+                                                            cluster.controller());&lt;br/&gt;
+        client.prepareMetadataUpdate(metaDataUpdateResponseCluster, Collections.&amp;lt;String&amp;gt;emptySet());&lt;br/&gt;
+&lt;br/&gt;
+        Future&amp;lt;RecordMetadata&amp;gt; future = producer.send(record);&lt;br/&gt;
+&lt;br/&gt;
+        assertEquals(&quot;Cluster has incorrect invalid topic list.&quot;, metaDataUpdateResponseCluster.invalidTopics(), metadata.fetch().invalidTopics());&lt;br/&gt;
+        try &lt;/p&gt;
{
+            future.get(0, TimeUnit.MILLISECONDS);
+            fail(&quot;Expected InvalidTopicException to be raised&quot;);
+        }
&lt;p&gt; catch (ExecutionException e) &lt;/p&gt;
{
+            // expected
+            assertEquals(&quot;Expected InvalidTopicException.&quot;, e.getCause().getClass(), InvalidTopicException.class);
+        }
&lt;p&gt;+    }&lt;br/&gt;
 }&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16516040" author="githubbot" created="Mon, 18 Jun 2018 17:20:14 +0000"  >&lt;p&gt;ahmedha opened a new pull request #5209: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5098&quot; title=&quot;KafkaProducer.send() blocks and generates TimeoutException if topic name has illegal char&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5098&quot;&gt;&lt;del&gt;KAFKA-5098&lt;/del&gt;&lt;/a&gt;: KafkaProducer.send() dose not block if topic name has illegal char an&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5209&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5209&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   &#8230;d generates InvalidTopicException&lt;/p&gt;

&lt;p&gt;   *KafkaProducer.send() dose not block if topic name has illegal char&lt;br/&gt;
   or invalid.  The producer caches the invalid topic name to avoid&lt;br/&gt;
   getting metadata from broker in the future.  The call generates&lt;br/&gt;
   an InvalidTopicException when invalid topic name is encountered.*&lt;/p&gt;

&lt;p&gt;   *Wrote a unit test that verifies the appropriate exception&lt;br/&gt;
   is passed to the Callback function passed to KafkaProducer.send(), &lt;br/&gt;
   and the returned future has the correct exception message.*&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16516041" author="githubbot" created="Mon, 18 Jun 2018 17:20:22 +0000"  >&lt;p&gt;ahmedha closed pull request #5209: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5098&quot; title=&quot;KafkaProducer.send() blocks and generates TimeoutException if topic name has illegal char&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5098&quot;&gt;&lt;del&gt;KAFKA-5098&lt;/del&gt;&lt;/a&gt;: KafkaProducer.send() dose not block if topic name has illegal char an&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5209&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5209&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/clients/src/main/java/org/apache/kafka/clients/Metadata.java b/clients/src/main/java/org/apache/kafka/clients/Metadata.java&lt;br/&gt;
index b1da9de8ac1..91b15875cd0 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/Metadata.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/Metadata.java&lt;br/&gt;
@@ -353,6 +353,7 @@ private synchronized void requestUpdateForNewTopics() {&lt;/p&gt;

&lt;p&gt;     private Cluster getClusterForCurrentTopics(Cluster cluster) {&lt;br/&gt;
         Set&amp;lt;String&amp;gt; unauthorizedTopics = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
+        Set&amp;lt;String&amp;gt; invalidTopics = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
         Collection&amp;lt;PartitionInfo&amp;gt; partitionInfos = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
         List&amp;lt;Node&amp;gt; nodes = Collections.emptyList();&lt;br/&gt;
         Set&amp;lt;String&amp;gt; internalTopics = Collections.emptySet();&lt;br/&gt;
@@ -364,6 +365,9 @@ private Cluster getClusterForCurrentTopics(Cluster cluster) {&lt;br/&gt;
             unauthorizedTopics.addAll(cluster.unauthorizedTopics());&lt;br/&gt;
             unauthorizedTopics.retainAll(this.topics.keySet());&lt;/p&gt;

&lt;p&gt;+            invalidTopics.addAll(cluster.invalidTopics());&lt;br/&gt;
+            invalidTopics.addAll(this.cluster.invalidTopics());&lt;br/&gt;
+&lt;br/&gt;
             for (String topic : this.topics.keySet()) {&lt;br/&gt;
                 List&amp;lt;PartitionInfo&amp;gt; partitionInfoList = cluster.partitionsForTopic(topic);&lt;br/&gt;
                 if (!partitionInfoList.isEmpty()) {&lt;br/&gt;
@@ -373,6 +377,6 @@ private Cluster getClusterForCurrentTopics(Cluster cluster) &lt;/p&gt;
{
             nodes = cluster.nodes();
             controller  = cluster.controller();
         }
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return new Cluster(clusterId, nodes, partitionInfos, unauthorizedTopics, internalTopics, controller);&lt;br/&gt;
+        return new Cluster(clusterId, nodes, partitionInfos, unauthorizedTopics, invalidTopics, internalTopics, controller);&lt;br/&gt;
     }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java&lt;br/&gt;
index 9c19af17037..59686b9336c 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java&lt;br/&gt;
@@ -30,6 +30,7 @@&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition;&lt;br/&gt;
 import org.apache.kafka.common.errors.GroupAuthorizationException;&lt;br/&gt;
 import org.apache.kafka.common.errors.InterruptException;&lt;br/&gt;
+import org.apache.kafka.common.errors.InvalidTopicException;&lt;br/&gt;
 import org.apache.kafka.common.errors.RetriableException;&lt;br/&gt;
 import org.apache.kafka.common.errors.TimeoutException;&lt;br/&gt;
 import org.apache.kafka.common.errors.TopicAuthorizationException;&lt;br/&gt;
@@ -203,6 +204,10 @@ public void onMetadataUpdate(Cluster cluster, Set&amp;lt;String&amp;gt; unavailableTopics) 
{
                 if (!cluster.unauthorizedTopics().isEmpty())
                     throw new TopicAuthorizationException(new HashSet&amp;lt;&amp;gt;(cluster.unauthorizedTopics()));
 
+                // if we encounter any invalid topics, raise an exception to the user
+                if (!cluster.invalidTopics().isEmpty())
+                    throw new InvalidTopicException();
+
                 if (subscriptions.hasPatternSubscription())
                     updatePatternSubscription(cluster);
 
diff --git a/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java b/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java
index a5af5b60093..3ec73ea0afb 100644
--- a/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java
+++ b/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java
@@ -41,6 +41,7 @@
 import org.apache.kafka.common.errors.AuthenticationException;
 import org.apache.kafka.common.errors.AuthorizationException;
 import org.apache.kafka.common.errors.InterruptException;
+import org.apache.kafka.common.errors.InvalidTopicException;
 import org.apache.kafka.common.errors.ProducerFencedException;
 import org.apache.kafka.common.errors.RecordTooLargeException;
 import org.apache.kafka.common.errors.SerializationException;
@@ -900,6 +901,10 @@ private ClusterAndWaitTime waitOnMetadata(String topic, Integer partition, long
         // add topic to metadata topic list if it is not there already and reset expiry
         metadata.add(topic);
         Cluster cluster = metadata.fetch();
+
+        if (cluster.invalidTopics().contains(topic))
+            throw new InvalidTopicException(topic);
+
         Integer partitionsCount = cluster.partitionCountForTopic(topic);
         // Return cached metadata if we have it, and if the record&apos;s partition is either undefined
         // or within the known partition range
@@ -930,6 +935,8 @@ private ClusterAndWaitTime waitOnMetadata(String topic, Integer partition, long
                 throw new TimeoutException(&quot;Failed to update metadata after &quot; + maxWaitMs + &quot; ms.&quot;);
             if (cluster.unauthorizedTopics().contains(topic))
                 throw new TopicAuthorizationException(topic);
+            if (cluster.invalidTopics().contains(topic))
+                throw new InvalidTopicException(topic);
             remainingWaitMs = maxWaitMs - elapsed;
             partitionsCount = cluster.partitionCountForTopic(topic);
         }
&lt;p&gt; while (partitionsCount == null);&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/common/Cluster.java b/clients/src/main/java/org/apache/kafka/common/Cluster.java&lt;br/&gt;
index ccbaa306d48..33d37494bf5 100644&lt;/p&gt;&lt;/li&gt;
			&lt;li&gt;a/clients/src/main/java/org/apache/kafka/common/Cluster.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/common/Cluster.java&lt;br/&gt;
@@ -36,6 +36,7 @@&lt;br/&gt;
     private final boolean isBootstrapConfigured;&lt;br/&gt;
     private final List&amp;lt;Node&amp;gt; nodes;&lt;br/&gt;
     private final Set&amp;lt;String&amp;gt; unauthorizedTopics;&lt;br/&gt;
+    private final Set&amp;lt;String&amp;gt; invalidTopics;&lt;br/&gt;
     private final Set&amp;lt;String&amp;gt; internalTopics;&lt;br/&gt;
     private final Node controller;&lt;br/&gt;
     private final Map&amp;lt;TopicPartition, PartitionInfo&amp;gt; partitionsByTopicPartition;&lt;br/&gt;
@@ -55,7 +56,7 @@ public Cluster(String clusterId,&lt;br/&gt;
                    Collection&amp;lt;PartitionInfo&amp;gt; partitions,&lt;br/&gt;
                    Set&amp;lt;String&amp;gt; unauthorizedTopics,&lt;br/&gt;
                    Set&amp;lt;String&amp;gt; internalTopics) 
{
-        this(clusterId, false, nodes, partitions, unauthorizedTopics, internalTopics, null);
+        this(clusterId, false, nodes, partitions, unauthorizedTopics, Collections.&amp;lt;String&amp;gt;emptySet(), internalTopics, null);
     }&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;br/&gt;
@@ -69,7 +70,22 @@ public Cluster(String clusterId,&lt;br/&gt;
                    Set&amp;lt;String&amp;gt; unauthorizedTopics,&lt;br/&gt;
                    Set&amp;lt;String&amp;gt; internalTopics,&lt;br/&gt;
                    Node controller) &lt;/p&gt;
{
-        this(clusterId, false, nodes, partitions, unauthorizedTopics, internalTopics, controller);
+        this(clusterId, false, nodes, partitions, unauthorizedTopics, Collections.&amp;lt;String&amp;gt;emptySet(), internalTopics, controller);
+    }
&lt;p&gt;+&lt;br/&gt;
+    /**&lt;br/&gt;
+     * Create a new cluster with the given id, nodes and partitions&lt;br/&gt;
+     * @param nodes The nodes in the cluster&lt;br/&gt;
+     * @param partitions Information about a subset of the topic-partitions this cluster hosts&lt;br/&gt;
+     */&lt;br/&gt;
+    public Cluster(String clusterId,&lt;br/&gt;
+        Collection&amp;lt;Node&amp;gt; nodes,&lt;br/&gt;
+        Collection&amp;lt;PartitionInfo&amp;gt; partitions,&lt;br/&gt;
+        Set&amp;lt;String&amp;gt; unauthorizedTopics,&lt;br/&gt;
+        Set&amp;lt;String&amp;gt; invalidTopics,&lt;br/&gt;
+        Set&amp;lt;String&amp;gt; internalTopics,&lt;br/&gt;
+        Node controller) &lt;/p&gt;
{
+        this(clusterId, false, nodes, partitions, unauthorizedTopics, invalidTopics, internalTopics, controller);
     }

&lt;p&gt;     private Cluster(String clusterId,&lt;br/&gt;
@@ -77,6 +93,7 @@ private Cluster(String clusterId,&lt;br/&gt;
                     Collection&amp;lt;Node&amp;gt; nodes,&lt;br/&gt;
                     Collection&amp;lt;PartitionInfo&amp;gt; partitions,&lt;br/&gt;
                     Set&amp;lt;String&amp;gt; unauthorizedTopics,&lt;br/&gt;
+                    Set&amp;lt;String&amp;gt; invalidTopics,&lt;br/&gt;
                     Set&amp;lt;String&amp;gt; internalTopics,&lt;br/&gt;
                     Node controller) &lt;/p&gt;
{
         this.isBootstrapConfigured = isBootstrapConfigured;
@@ -131,6 +148,7 @@ private Cluster(String clusterId,
             this.partitionsByNode.put(entry.getKey(), Collections.unmodifiableList(entry.getValue()));
 
         this.unauthorizedTopics = Collections.unmodifiableSet(unauthorizedTopics);
+        this.invalidTopics = Collections.unmodifiableSet(invalidTopics);
         this.internalTopics = Collections.unmodifiableSet(internalTopics);
         this.controller = controller;
     }
&lt;p&gt;@@ -153,7 +171,8 @@ public static Cluster bootstrap(List&amp;lt;InetSocketAddress&amp;gt; addresses) &lt;/p&gt;
{
         int nodeId = -1;
         for (InetSocketAddress address : addresses)
             nodes.add(new Node(nodeId--, address.getHostString(), address.getPort()));
-        return new Cluster(null, true, nodes, new ArrayList&amp;lt;PartitionInfo&amp;gt;(0), Collections.&amp;lt;String&amp;gt;emptySet(), Collections.&amp;lt;String&amp;gt;emptySet(), null);
+        return new Cluster(null, true, nodes, new ArrayList&amp;lt;PartitionInfo&amp;gt;(0),
+                            Collections.&amp;lt;String&amp;gt;emptySet(), Collections.&amp;lt;String&amp;gt;emptySet(), Collections.&amp;lt;String&amp;gt;emptySet(), null);
     }

&lt;p&gt;     /**&lt;br/&gt;
@@ -163,7 +182,8 @@ public Cluster withPartitions(Map&amp;lt;TopicPartition, PartitionInfo&amp;gt; partitions) &lt;/p&gt;
{
         Map&amp;lt;TopicPartition, PartitionInfo&amp;gt; combinedPartitions = new HashMap&amp;lt;&amp;gt;(this.partitionsByTopicPartition);
         combinedPartitions.putAll(partitions);
         return new Cluster(clusterResource.clusterId(), this.nodes, combinedPartitions.values(),
-                new HashSet&amp;lt;&amp;gt;(this.unauthorizedTopics), new HashSet&amp;lt;&amp;gt;(this.internalTopics), this.controller);
+                new HashSet&amp;lt;&amp;gt;(this.unauthorizedTopics), new HashSet&amp;lt;&amp;gt;(this.invalidTopics),
+                new HashSet&amp;lt;&amp;gt;(this.internalTopics), this.controller);
     }

&lt;p&gt;     /**&lt;br/&gt;
@@ -172,7 +192,7 @@ public Cluster withPartitions(Map&amp;lt;TopicPartition, PartitionInfo&amp;gt; partitions) {&lt;br/&gt;
     public List&amp;lt;Node&amp;gt; nodes() &lt;/p&gt;
{
         return this.nodes;
     }
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;p&gt;+&lt;br/&gt;
     /**&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;Get the node by the node id (or null if no such node exists)&lt;/li&gt;
	&lt;li&gt;@param id The id of the node&lt;br/&gt;
@@ -256,6 +276,10 @@ public Integer partitionCountForTopic(String topic) 
{
         return unauthorizedTopics;
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+    public Set&amp;lt;String&amp;gt; invalidTopics() &lt;/p&gt;
{
+        return invalidTopics;
+    }
&lt;p&gt;+&lt;br/&gt;
     public Set&amp;lt;String&amp;gt; internalTopics() &lt;/p&gt;
{
         return internalTopics;
     }
&lt;p&gt;diff --git a/clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java b/clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java&lt;br/&gt;
index 28a412df800..09a04e55603 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java&lt;br/&gt;
@@ -366,7 +366,7 @@ public Cluster cluster() {&lt;br/&gt;
         }&lt;/p&gt;

&lt;p&gt;         return new Cluster(this.clusterId, this.brokers, partitions, topicsByError(Errors.TOPIC_AUTHORIZATION_FAILED),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;internalTopics, this.controller);&lt;br/&gt;
+                topicsByError(Errors.INVALID_TOPIC_EXCEPTION), internalTopics, this.controller);&lt;br/&gt;
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;br/&gt;
diff --git a/clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java b/clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java&lt;br/&gt;
index 8bfc5e7d28a..1354ea30ba2 100644&lt;br/&gt;
&amp;#8212; a/clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java&lt;br/&gt;
+++ b/clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java&lt;br/&gt;
@@ -16,6 +16,10 @@&lt;br/&gt;
  */&lt;br/&gt;
 package org.apache.kafka.clients.producer;&lt;/p&gt;

&lt;p&gt;+import java.util.ArrayList;&lt;br/&gt;
+import java.util.HashSet;&lt;br/&gt;
+import java.util.Set;&lt;br/&gt;
+import java.util.concurrent.ExecutionException;&lt;br/&gt;
 import org.apache.kafka.clients.CommonClientConfigs;&lt;br/&gt;
 import org.apache.kafka.clients.Metadata;&lt;br/&gt;
 import org.apache.kafka.clients.MockClient;&lt;br/&gt;
@@ -27,6 +31,7 @@&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition;&lt;br/&gt;
 import org.apache.kafka.common.config.ConfigException;&lt;br/&gt;
 import org.apache.kafka.common.errors.InterruptException;&lt;br/&gt;
+import org.apache.kafka.common.errors.InvalidTopicException;&lt;br/&gt;
 import org.apache.kafka.common.errors.TimeoutException;&lt;br/&gt;
 import org.apache.kafka.common.header.internals.RecordHeader;&lt;br/&gt;
 import org.apache.kafka.common.internals.ClusterResourceListeners;&lt;br/&gt;
@@ -68,6 +73,7 @@&lt;br/&gt;
 import static org.junit.Assert.assertEquals;&lt;br/&gt;
 import static org.junit.Assert.assertTrue;&lt;br/&gt;
 import static org.junit.Assert.fail;&lt;br/&gt;
+import static org.junit.Assert.assertNull;&lt;/p&gt;

&lt;p&gt; @RunWith(PowerMockRunner.class)&lt;br/&gt;
 @PowerMockIgnore(&quot;javax.management.*&quot;)&lt;br/&gt;
@@ -609,4 +615,51 @@ public void testOnlyCanExecuteCloseAfterInitTransactionsTimeout() &lt;/p&gt;
{
             producer.close(0, TimeUnit.MILLISECONDS);
         }
&lt;p&gt;     }&lt;br/&gt;
+&lt;br/&gt;
+    @Test&lt;br/&gt;
+    public void testInvalidTopicName() throws Exception {&lt;br/&gt;
+&lt;br/&gt;
+        Properties props = new Properties();&lt;br/&gt;
+        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9000&quot;);&lt;br/&gt;
+        props.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, &quot;15000&quot;);&lt;br/&gt;
+&lt;br/&gt;
+        Time time = new MockTime();&lt;br/&gt;
+        Cluster cluster = TestUtils.singletonCluster();&lt;br/&gt;
+        Node node = cluster.nodes().get(0);&lt;br/&gt;
+&lt;br/&gt;
+        Metadata metadata = new Metadata(0, Long.MAX_VALUE, true);&lt;br/&gt;
+        metadata.update(cluster, Collections.&amp;lt;String&amp;gt;emptySet(), time.milliseconds());&lt;br/&gt;
+&lt;br/&gt;
+        MockClient client = new MockClient(time, metadata);&lt;br/&gt;
+        client.setNode(node);&lt;br/&gt;
+&lt;br/&gt;
+        Producer&amp;lt;String, String&amp;gt; producer = new KafkaProducer&amp;lt;&amp;gt;(new ProducerConfig(&lt;br/&gt;
+            ProducerConfig.addSerializerToConfig(props, new StringSerializer(), new StringSerializer())),&lt;br/&gt;
+            new StringSerializer(), new StringSerializer(), metadata, client);&lt;br/&gt;
+&lt;br/&gt;
+        String topic = &quot;topic 10&quot;;&lt;br/&gt;
+        ProducerRecord&amp;lt;String, String&amp;gt; record = new ProducerRecord&amp;lt;&amp;gt;(topic, &quot;HelloKafka&quot;);&lt;br/&gt;
+&lt;br/&gt;
+        Set&amp;lt;String&amp;gt; invalidTopic = new HashSet&amp;lt;String&amp;gt;();&lt;br/&gt;
+        invalidTopic.add(topic);&lt;br/&gt;
+        Cluster metaDataUpdateResponseCluster = new Cluster(cluster.clusterResource().clusterId(),&lt;br/&gt;
+                                                            cluster.nodes(),&lt;br/&gt;
+                                                            new ArrayList&amp;lt;PartitionInfo&amp;gt;(0),&lt;br/&gt;
+                                                            Collections.&amp;lt;String&amp;gt;emptySet(),&lt;br/&gt;
+                                                            invalidTopic,&lt;br/&gt;
+                                                            cluster.internalTopics(),&lt;br/&gt;
+                                                            cluster.controller());&lt;br/&gt;
+        client.prepareMetadataUpdate(metaDataUpdateResponseCluster, Collections.&amp;lt;String&amp;gt;emptySet());&lt;br/&gt;
+&lt;br/&gt;
+        Future&amp;lt;RecordMetadata&amp;gt; future = producer.send(record);&lt;br/&gt;
+&lt;br/&gt;
+        assertEquals(&quot;Cluster has incorrect invalid topic list.&quot;, metaDataUpdateResponseCluster.invalidTopics(), metadata.fetch().invalidTopics());&lt;br/&gt;
+        try &lt;/p&gt;
{
+            future.get(0, TimeUnit.MILLISECONDS);
+            fail(&quot;Expected InvalidTopicException to be raised&quot;);
+        }
&lt;p&gt; catch (ExecutionException e) &lt;/p&gt;
{
+            // expected
+            assertEquals(&quot;Expected InvalidTopicException.&quot;, e.getCause().getClass(), InvalidTopicException.class);
+        }
&lt;p&gt;+    }&lt;br/&gt;
 }&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16516171" author="githubbot" created="Mon, 18 Jun 2018 19:04:42 +0000"  >&lt;p&gt;ahmedha opened a new pull request #5247: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5098&quot; title=&quot;KafkaProducer.send() blocks and generates TimeoutException if topic name has illegal char&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5098&quot;&gt;&lt;del&gt;KAFKA-5098&lt;/del&gt;&lt;/a&gt;: KafkaProducer.send() dose not block if topic name has ill&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5247&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5247&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   &#8230;egal char and generates InvalidTopicException&lt;/p&gt;

&lt;p&gt;   If config parameter max.block.ms config parameter is set to a non-zero value,&lt;br/&gt;
   KafkaProducer.send() blocks for the max.block.ms time if topic name has illegal&lt;br/&gt;
   char or is invalid.&lt;/p&gt;

&lt;p&gt;   Wrote a unit test that verifies the appropriate exception is returned when&lt;br/&gt;
   performing a get on the returned future by KafkaProducer.send().&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16547183" author="githubbot" created="Tue, 17 Jul 2018 22:47:24 +0000"  >&lt;p&gt;jjkoshy closed pull request #5247: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5098&quot; title=&quot;KafkaProducer.send() blocks and generates TimeoutException if topic name has illegal char&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5098&quot;&gt;&lt;del&gt;KAFKA-5098&lt;/del&gt;&lt;/a&gt;: KafkaProducer.send() dose not block if topic name has ill&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5247&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5247&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/clients/src/main/java/org/apache/kafka/clients/Metadata.java b/clients/src/main/java/org/apache/kafka/clients/Metadata.java&lt;br/&gt;
index b1da9de8ac1..91b15875cd0 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/Metadata.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/Metadata.java&lt;br/&gt;
@@ -353,6 +353,7 @@ private synchronized void requestUpdateForNewTopics() {&lt;/p&gt;

&lt;p&gt;     private Cluster getClusterForCurrentTopics(Cluster cluster) {&lt;br/&gt;
         Set&amp;lt;String&amp;gt; unauthorizedTopics = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
+        Set&amp;lt;String&amp;gt; invalidTopics = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
         Collection&amp;lt;PartitionInfo&amp;gt; partitionInfos = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
         List&amp;lt;Node&amp;gt; nodes = Collections.emptyList();&lt;br/&gt;
         Set&amp;lt;String&amp;gt; internalTopics = Collections.emptySet();&lt;br/&gt;
@@ -364,6 +365,9 @@ private Cluster getClusterForCurrentTopics(Cluster cluster) {&lt;br/&gt;
             unauthorizedTopics.addAll(cluster.unauthorizedTopics());&lt;br/&gt;
             unauthorizedTopics.retainAll(this.topics.keySet());&lt;/p&gt;

&lt;p&gt;+            invalidTopics.addAll(cluster.invalidTopics());&lt;br/&gt;
+            invalidTopics.addAll(this.cluster.invalidTopics());&lt;br/&gt;
+&lt;br/&gt;
             for (String topic : this.topics.keySet()) {&lt;br/&gt;
                 List&amp;lt;PartitionInfo&amp;gt; partitionInfoList = cluster.partitionsForTopic(topic);&lt;br/&gt;
                 if (!partitionInfoList.isEmpty()) {&lt;br/&gt;
@@ -373,6 +377,6 @@ private Cluster getClusterForCurrentTopics(Cluster cluster) &lt;/p&gt;
{
             nodes = cluster.nodes();
             controller  = cluster.controller();
         }
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return new Cluster(clusterId, nodes, partitionInfos, unauthorizedTopics, internalTopics, controller);&lt;br/&gt;
+        return new Cluster(clusterId, nodes, partitionInfos, unauthorizedTopics, invalidTopics, internalTopics, controller);&lt;br/&gt;
     }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/KafkaConsumer.java b/clients/src/main/java/org/apache/kafka/clients/consumer/KafkaConsumer.java&lt;br/&gt;
index f722408fdbf..fb37feea9f1 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/clients/src/main/java/org/apache/kafka/clients/consumer/KafkaConsumer.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/KafkaConsumer.java&lt;br/&gt;
@@ -1148,6 +1148,8 @@ public void assign(Collection&amp;lt;TopicPartition&amp;gt; partitions) {&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@throws java.lang.IllegalStateException if the consumer is not subscribed to any topics or manually assigned any&lt;/li&gt;
	&lt;li&gt;partitions to consume from&lt;/li&gt;
	&lt;li&gt;@throws java.lang.ArithmeticException if the timeout is greater than 
{@link Long#MAX_VALUE}
&lt;p&gt; milliseconds.&lt;br/&gt;
+     * @throws org.apache.kafka.common.errors.InvalidTopicException if the current subscription contains any invalid&lt;br/&gt;
+     *             topic (per &lt;/p&gt;
{@link org.apache.kafka.common.internals.Topic#validate(String)}
&lt;p&gt;)&lt;br/&gt;
      */&lt;br/&gt;
     @Override&lt;br/&gt;
     public ConsumerRecords&amp;lt;K, V&amp;gt; poll(final Duration timeout) {&lt;br/&gt;
@@ -1595,7 +1597,7 @@ public long position(TopicPartition partition) {&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Get the offset of the &amp;lt;i&amp;gt;next record&amp;lt;/i&amp;gt; that will be fetched (if a record with that offset exists).&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* This method may issue a remote call to the server if there is no current position&lt;br/&gt;
+     * This method may issue a remote call to the server if there is no current position&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;for the given partition.&lt;/li&gt;
	&lt;li&gt;&amp;lt;p&amp;gt;&lt;/li&gt;
	&lt;li&gt;This call will block until the position can be determined, an unrecoverable error is&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java&lt;br/&gt;
index 060e404ef0c..ea6d47249eb 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java&lt;br/&gt;
@@ -30,6 +30,7 @@&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition;&lt;br/&gt;
 import org.apache.kafka.common.errors.GroupAuthorizationException;&lt;br/&gt;
 import org.apache.kafka.common.errors.InterruptException;&lt;br/&gt;
+import org.apache.kafka.common.errors.InvalidTopicException;&lt;br/&gt;
 import org.apache.kafka.common.errors.RetriableException;&lt;br/&gt;
 import org.apache.kafka.common.errors.TimeoutException;&lt;br/&gt;
 import org.apache.kafka.common.errors.TopicAuthorizationException;&lt;br/&gt;
@@ -203,6 +204,10 @@ public void onMetadataUpdate(Cluster cluster, Set&amp;lt;String&amp;gt; unavailableTopics) {&lt;br/&gt;
                 if (!cluster.unauthorizedTopics().isEmpty())&lt;br/&gt;
                     throw new TopicAuthorizationException(new HashSet&amp;lt;&amp;gt;(cluster.unauthorizedTopics()));&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+                // if we encounter any invalid topics, raise an exception to the user&lt;br/&gt;
+                if (!cluster.invalidTopics().isEmpty())&lt;br/&gt;
+                    throw new InvalidTopicException(cluster.invalidTopics());&lt;br/&gt;
+&lt;br/&gt;
                 if (subscriptions.hasPatternSubscription())&lt;br/&gt;
                     updatePatternSubscription(cluster);&lt;/p&gt;

&lt;p&gt;diff --git a/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java b/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java&lt;br/&gt;
index a5af5b60093..3a6717b7676 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java&lt;br/&gt;
@@ -41,6 +41,7 @@&lt;br/&gt;
 import org.apache.kafka.common.errors.AuthenticationException;&lt;br/&gt;
 import org.apache.kafka.common.errors.AuthorizationException;&lt;br/&gt;
 import org.apache.kafka.common.errors.InterruptException;&lt;br/&gt;
+import org.apache.kafka.common.errors.InvalidTopicException;&lt;br/&gt;
 import org.apache.kafka.common.errors.ProducerFencedException;&lt;br/&gt;
 import org.apache.kafka.common.errors.RecordTooLargeException;&lt;br/&gt;
 import org.apache.kafka.common.errors.SerializationException;&lt;br/&gt;
@@ -898,8 +899,13 @@ private void setReadOnly(Headers headers) {&lt;br/&gt;
      */&lt;br/&gt;
     private ClusterAndWaitTime waitOnMetadata(String topic, Integer partition, long maxWaitMs) throws InterruptedException &lt;/p&gt;
{
         // add topic to metadata topic list if it is not there already and reset expiry
-        metadata.add(topic);
         Cluster cluster = metadata.fetch();
+
+        if (cluster.invalidTopics().contains(topic))
+            throw new InvalidTopicException(topic);
+
+        metadata.add(topic);
+
         Integer partitionsCount = cluster.partitionCountForTopic(topic);
         // Return cached metadata if we have it, and if the record&apos;s partition is either undefined
         // or within the known partition range
@@ -930,6 +936,8 @@ private ClusterAndWaitTime waitOnMetadata(String topic, Integer partition, long
                 throw new TimeoutException(&quot;Failed to update metadata after &quot; + maxWaitMs + &quot; ms.&quot;);
             if (cluster.unauthorizedTopics().contains(topic))
                 throw new TopicAuthorizationException(topic);
+            if (cluster.invalidTopics().contains(topic))
+                throw new InvalidTopicException(topic);
             remainingWaitMs = maxWaitMs - elapsed;
             partitionsCount = cluster.partitionCountForTopic(topic);
         }
&lt;p&gt; while (partitionsCount == null);&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/common/Cluster.java b/clients/src/main/java/org/apache/kafka/common/Cluster.java&lt;br/&gt;
index ccbaa306d48..33d37494bf5 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/common/Cluster.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/common/Cluster.java&lt;br/&gt;
@@ -36,6 +36,7 @@&lt;br/&gt;
     private final boolean isBootstrapConfigured;&lt;br/&gt;
     private final List&amp;lt;Node&amp;gt; nodes;&lt;br/&gt;
     private final Set&amp;lt;String&amp;gt; unauthorizedTopics;&lt;br/&gt;
+    private final Set&amp;lt;String&amp;gt; invalidTopics;&lt;br/&gt;
     private final Set&amp;lt;String&amp;gt; internalTopics;&lt;br/&gt;
     private final Node controller;&lt;br/&gt;
     private final Map&amp;lt;TopicPartition, PartitionInfo&amp;gt; partitionsByTopicPartition;&lt;br/&gt;
@@ -55,7 +56,7 @@ public Cluster(String clusterId,&lt;br/&gt;
                    Collection&amp;lt;PartitionInfo&amp;gt; partitions,&lt;br/&gt;
                    Set&amp;lt;String&amp;gt; unauthorizedTopics,&lt;br/&gt;
                    Set&amp;lt;String&amp;gt; internalTopics) &lt;/p&gt;
{
-        this(clusterId, false, nodes, partitions, unauthorizedTopics, internalTopics, null);
+        this(clusterId, false, nodes, partitions, unauthorizedTopics, Collections.&amp;lt;String&amp;gt;emptySet(), internalTopics, null);
     }

&lt;p&gt;     /**&lt;br/&gt;
@@ -69,7 +70,22 @@ public Cluster(String clusterId,&lt;br/&gt;
                    Set&amp;lt;String&amp;gt; unauthorizedTopics,&lt;br/&gt;
                    Set&amp;lt;String&amp;gt; internalTopics,&lt;br/&gt;
                    Node controller) &lt;/p&gt;
{
-        this(clusterId, false, nodes, partitions, unauthorizedTopics, internalTopics, controller);
+        this(clusterId, false, nodes, partitions, unauthorizedTopics, Collections.&amp;lt;String&amp;gt;emptySet(), internalTopics, controller);
+    }
&lt;p&gt;+&lt;br/&gt;
+    /**&lt;br/&gt;
+     * Create a new cluster with the given id, nodes and partitions&lt;br/&gt;
+     * @param nodes The nodes in the cluster&lt;br/&gt;
+     * @param partitions Information about a subset of the topic-partitions this cluster hosts&lt;br/&gt;
+     */&lt;br/&gt;
+    public Cluster(String clusterId,&lt;br/&gt;
+        Collection&amp;lt;Node&amp;gt; nodes,&lt;br/&gt;
+        Collection&amp;lt;PartitionInfo&amp;gt; partitions,&lt;br/&gt;
+        Set&amp;lt;String&amp;gt; unauthorizedTopics,&lt;br/&gt;
+        Set&amp;lt;String&amp;gt; invalidTopics,&lt;br/&gt;
+        Set&amp;lt;String&amp;gt; internalTopics,&lt;br/&gt;
+        Node controller) &lt;/p&gt;
{
+        this(clusterId, false, nodes, partitions, unauthorizedTopics, invalidTopics, internalTopics, controller);
     }

&lt;p&gt;     private Cluster(String clusterId,&lt;br/&gt;
@@ -77,6 +93,7 @@ private Cluster(String clusterId,&lt;br/&gt;
                     Collection&amp;lt;Node&amp;gt; nodes,&lt;br/&gt;
                     Collection&amp;lt;PartitionInfo&amp;gt; partitions,&lt;br/&gt;
                     Set&amp;lt;String&amp;gt; unauthorizedTopics,&lt;br/&gt;
+                    Set&amp;lt;String&amp;gt; invalidTopics,&lt;br/&gt;
                     Set&amp;lt;String&amp;gt; internalTopics,&lt;br/&gt;
                     Node controller) &lt;/p&gt;
{
         this.isBootstrapConfigured = isBootstrapConfigured;
@@ -131,6 +148,7 @@ private Cluster(String clusterId,
             this.partitionsByNode.put(entry.getKey(), Collections.unmodifiableList(entry.getValue()));
 
         this.unauthorizedTopics = Collections.unmodifiableSet(unauthorizedTopics);
+        this.invalidTopics = Collections.unmodifiableSet(invalidTopics);
         this.internalTopics = Collections.unmodifiableSet(internalTopics);
         this.controller = controller;
     }
&lt;p&gt;@@ -153,7 +171,8 @@ public static Cluster bootstrap(List&amp;lt;InetSocketAddress&amp;gt; addresses) &lt;/p&gt;
{
         int nodeId = -1;
         for (InetSocketAddress address : addresses)
             nodes.add(new Node(nodeId--, address.getHostString(), address.getPort()));
-        return new Cluster(null, true, nodes, new ArrayList&amp;lt;PartitionInfo&amp;gt;(0), Collections.&amp;lt;String&amp;gt;emptySet(), Collections.&amp;lt;String&amp;gt;emptySet(), null);
+        return new Cluster(null, true, nodes, new ArrayList&amp;lt;PartitionInfo&amp;gt;(0),
+                            Collections.&amp;lt;String&amp;gt;emptySet(), Collections.&amp;lt;String&amp;gt;emptySet(), Collections.&amp;lt;String&amp;gt;emptySet(), null);
     }

&lt;p&gt;     /**&lt;br/&gt;
@@ -163,7 +182,8 @@ public Cluster withPartitions(Map&amp;lt;TopicPartition, PartitionInfo&amp;gt; partitions) &lt;/p&gt;
{
         Map&amp;lt;TopicPartition, PartitionInfo&amp;gt; combinedPartitions = new HashMap&amp;lt;&amp;gt;(this.partitionsByTopicPartition);
         combinedPartitions.putAll(partitions);
         return new Cluster(clusterResource.clusterId(), this.nodes, combinedPartitions.values(),
-                new HashSet&amp;lt;&amp;gt;(this.unauthorizedTopics), new HashSet&amp;lt;&amp;gt;(this.internalTopics), this.controller);
+                new HashSet&amp;lt;&amp;gt;(this.unauthorizedTopics), new HashSet&amp;lt;&amp;gt;(this.invalidTopics),
+                new HashSet&amp;lt;&amp;gt;(this.internalTopics), this.controller);
     }

&lt;p&gt;     /**&lt;br/&gt;
@@ -172,7 +192,7 @@ public Cluster withPartitions(Map&amp;lt;TopicPartition, PartitionInfo&amp;gt; partitions) {&lt;br/&gt;
     public List&amp;lt;Node&amp;gt; nodes() &lt;/p&gt;
{
         return this.nodes;
     }
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;p&gt;+&lt;br/&gt;
     /**&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;Get the node by the node id (or null if no such node exists)&lt;/li&gt;
	&lt;li&gt;@param id The id of the node&lt;br/&gt;
@@ -256,6 +276,10 @@ public Integer partitionCountForTopic(String topic) 
{
         return unauthorizedTopics;
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+    public Set&amp;lt;String&amp;gt; invalidTopics() &lt;/p&gt;
{
+        return invalidTopics;
+    }&lt;br/&gt;
+&lt;br/&gt;
     public Set&amp;lt;String&amp;gt; internalTopics() {
         return internalTopics;
     }&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/common/errors/InvalidTopicException.java b/clients/src/main/java/org/apache/kafka/common/errors/InvalidTopicException.java&lt;br/&gt;
index f79e9a7b067..729ebba8a6f 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/common/errors/InvalidTopicException.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/common/errors/InvalidTopicException.java&lt;br/&gt;
@@ -16,6 +16,10 @@&lt;br/&gt;
  */&lt;br/&gt;
 package org.apache.kafka.common.errors;&lt;br/&gt;
 &lt;br/&gt;
+import java.util.HashSet;&lt;br/&gt;
+import java.util.Set;&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
 /**&lt;br/&gt;
  * The client has attempted to perform an operation on an invalid topic.&lt;br/&gt;
  * For example the topic name is too long, contains invalid characters etc.&lt;br/&gt;
@@ -24,23 +28,36 @@&lt;br/&gt;
  * @see UnknownTopicOrPartitionException&lt;br/&gt;
  */&lt;br/&gt;
 public class InvalidTopicException extends ApiException {&lt;br/&gt;
-&lt;br/&gt;
     private static final long serialVersionUID = 1L;&lt;br/&gt;
 &lt;br/&gt;
+    private final Set&amp;lt;String&amp;gt; invalidTopics;&lt;br/&gt;
+&lt;br/&gt;
     public InvalidTopicException() {
         super();
+        invalidTopics = new HashSet&amp;lt;&amp;gt;();
     }&lt;br/&gt;
 &lt;br/&gt;
     public InvalidTopicException(String message, Throwable cause) {
         super(message, cause);
+        invalidTopics = new HashSet&amp;lt;&amp;gt;();
     }&lt;br/&gt;
 &lt;br/&gt;
     public InvalidTopicException(String message) {
         super(message);
+        invalidTopics = new HashSet&amp;lt;&amp;gt;();
     }&lt;br/&gt;
 &lt;br/&gt;
     public InvalidTopicException(Throwable cause) {
         super(cause);
+        invalidTopics = new HashSet&amp;lt;&amp;gt;();
     }&lt;br/&gt;
 &lt;br/&gt;
+    public InvalidTopicException(Set&amp;lt;String&amp;gt; invalidTopics) {
+        super(&quot;Invalid topics: &quot; + invalidTopics);
+        this.invalidTopics = invalidTopics;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    public Set&amp;lt;String&amp;gt; invalidTopics() {+        return invalidTopics;+    }
&lt;p&gt; }&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java b/clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java&lt;br/&gt;
index 28a412df800..09a04e55603 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java&lt;br/&gt;
@@ -366,7 +366,7 @@ public Cluster cluster() {&lt;br/&gt;
         }&lt;/p&gt;

&lt;p&gt;         return new Cluster(this.clusterId, this.brokers, partitions, topicsByError(Errors.TOPIC_AUTHORIZATION_FAILED),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;internalTopics, this.controller);&lt;br/&gt;
+                topicsByError(Errors.INVALID_TOPIC_EXCEPTION), internalTopics, this.controller);&lt;br/&gt;
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;br/&gt;
diff --git a/clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java b/clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java&lt;br/&gt;
index 836307902f4..70794714026 100644&lt;br/&gt;
&amp;#8212; a/clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java&lt;br/&gt;
+++ b/clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java&lt;br/&gt;
@@ -93,7 +93,6 @@&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
 import java.util.Set;&lt;br/&gt;
 import java.util.concurrent.ExecutionException;&lt;br/&gt;
-import java.util.concurrent.Future;&lt;br/&gt;
 import java.util.concurrent.TimeUnit;&lt;br/&gt;
 import java.util.concurrent.atomic.AtomicLong;&lt;/p&gt;

&lt;p&gt;@@ -197,19 +196,6 @@ public void testCloseAdminClient() {&lt;br/&gt;
         }&lt;br/&gt;
     }&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static void assertFutureError(Future&amp;lt;?&amp;gt; future, Class&amp;lt;? extends Throwable&amp;gt; exceptionClass)&lt;/li&gt;
	&lt;li&gt;throws InterruptedException {&lt;/li&gt;
	&lt;li&gt;try 
{
-            future.get();
-            fail(&quot;Expected a &quot; + exceptionClass.getSimpleName() + &quot; exception, but got success.&quot;);
-        }
&lt;p&gt; catch (ExecutionException ee) &lt;/p&gt;
{
-            Throwable cause = ee.getCause();
-            assertEquals(&quot;Expected a &quot; + exceptionClass.getSimpleName() + &quot; exception, but got &quot; +
-                            cause.getClass().getSimpleName(),
-                    exceptionClass, cause.getClass());
-        }&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;br/&gt;
     /**&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;Test that the client properly times out when we don&apos;t receive any metadata.&lt;br/&gt;
      */&lt;br/&gt;
@@ -228,7 +214,7 @@ public void testTimeoutWithoutMetadata() throws Exception 
{
             KafkaFuture&amp;lt;Void&amp;gt; future = env.adminClient().createTopics(
                     Collections.singleton(new NewTopic(&quot;myTopic&quot;, Collections.singletonMap(0, asList(0, 1, 2)))),
                     new CreateTopicsOptions().timeoutMs(1000)).all();
-            assertFutureError(future, TimeoutException.class);
+            TestUtils.assertFutureError(future, TimeoutException.class);
         }
&lt;p&gt;     }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -306,7 +292,7 @@ public void testPropagatedMetadataFetchException() throws Exception &lt;/p&gt;
{
             KafkaFuture&amp;lt;Void&amp;gt; future = env.adminClient().createTopics(
                 Collections.singleton(new NewTopic(&quot;myTopic&quot;, Collections.singletonMap(0, asList(0, 1, 2)))),
                 new CreateTopicsOptions().timeoutMs(1000)).all();
-            assertFutureError(future, SaslAuthenticationException.class);
+            TestUtils.assertFutureError(future, SaslAuthenticationException.class);
         }
&lt;p&gt;     }&lt;/p&gt;

&lt;p&gt;@@ -401,14 +387,14 @@ public void testInvalidTopicNames() throws Exception {&lt;br/&gt;
             List&amp;lt;String&amp;gt; sillyTopicNames = asList(&quot;&quot;, null);&lt;br/&gt;
             Map&amp;lt;String, KafkaFuture&amp;lt;Void&amp;gt;&amp;gt; deleteFutures = env.adminClient().deleteTopics(sillyTopicNames).values();&lt;br/&gt;
             for (String sillyTopicName : sillyTopicNames) &lt;/p&gt;
{
-                assertFutureError(deleteFutures.get(sillyTopicName), InvalidTopicException.class);
+                TestUtils.assertFutureError(deleteFutures.get(sillyTopicName), InvalidTopicException.class);
             }
&lt;p&gt;             assertEquals(0, env.kafkaClient().inFlightRequestCount());&lt;/p&gt;

&lt;p&gt;             Map&amp;lt;String, KafkaFuture&amp;lt;TopicDescription&amp;gt;&amp;gt; describeFutures =&lt;br/&gt;
                     env.adminClient().describeTopics(sillyTopicNames).values();&lt;br/&gt;
             for (String sillyTopicName : sillyTopicNames) &lt;/p&gt;
{
-                assertFutureError(describeFutures.get(sillyTopicName), InvalidTopicException.class);
+                TestUtils.assertFutureError(describeFutures.get(sillyTopicName), InvalidTopicException.class);
             }
&lt;p&gt;             assertEquals(0, env.kafkaClient().inFlightRequestCount());&lt;/p&gt;

&lt;p&gt;@@ -419,7 +405,7 @@ public void testInvalidTopicNames() throws Exception {&lt;/p&gt;

&lt;p&gt;             Map&amp;lt;String, KafkaFuture&amp;lt;Void&amp;gt;&amp;gt; createFutures = env.adminClient().createTopics(newTopics).values();&lt;br/&gt;
             for (String sillyTopicName : sillyTopicNames) &lt;/p&gt;
{
-                assertFutureError(createFutures .get(sillyTopicName), InvalidTopicException.class);
+                TestUtils.assertFutureError(createFutures .get(sillyTopicName), InvalidTopicException.class);
             }
&lt;p&gt;             assertEquals(0, env.kafkaClient().inFlightRequestCount());&lt;br/&gt;
         }&lt;br/&gt;
@@ -564,7 +550,7 @@ public void testDescribeAcls() throws Exception &lt;/p&gt;
{
             // Test a call where we get back an error.
             env.kafkaClient().prepareResponse(new DescribeAclsResponse(0,
                 new ApiError(Errors.SECURITY_DISABLED, &quot;Security is disabled&quot;), Collections.&amp;lt;AclBinding&amp;gt;emptySet()));
-            assertFutureError(env.adminClient().describeAcls(FILTER2).values(), SecurityDisabledException.class);
+            TestUtils.assertFutureError(env.adminClient().describeAcls(FILTER2).values(), SecurityDisabledException.class);
         }
&lt;p&gt;     }&lt;/p&gt;

&lt;p&gt;@@ -590,9 +576,9 @@ public void testCreateAcls() throws Exception &lt;/p&gt;
{
             ));
             results = env.adminClient().createAcls(asList(ACL1, ACL2));
             assertCollectionIs(results.values().keySet(), ACL1, ACL2);
-            assertFutureError(results.values().get(ACL1), SecurityDisabledException.class);
+            TestUtils.assertFutureError(results.values().get(ACL1), SecurityDisabledException.class);
             results.values().get(ACL2).get();
-            assertFutureError(results.all(), SecurityDisabledException.class);
+            TestUtils.assertFutureError(results.all(), SecurityDisabledException.class);
         }
&lt;p&gt;     }&lt;/p&gt;

&lt;p&gt;@@ -614,8 +600,8 @@ public void testDeleteAcls() throws Exception {&lt;br/&gt;
             assertEquals(ACL1, filter1Results.values().get(0).binding());&lt;br/&gt;
             assertEquals(null, filter1Results.values().get(1).exception());&lt;br/&gt;
             assertEquals(ACL2, filter1Results.values().get(1).binding());&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertFutureError(filterResults.get(FILTER2), SecurityDisabledException.class);&lt;/li&gt;
	&lt;li&gt;assertFutureError(results.all(), SecurityDisabledException.class);&lt;br/&gt;
+            TestUtils.assertFutureError(filterResults.get(FILTER2), SecurityDisabledException.class);&lt;br/&gt;
+            TestUtils.assertFutureError(results.all(), SecurityDisabledException.class);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             // Test a call where one deletion result has an error.&lt;br/&gt;
             env.kafkaClient().prepareResponse(new DeleteAclsResponse(0, asList(&lt;br/&gt;
@@ -624,7 +610,7 @@ public void testDeleteAcls() throws Exception {&lt;br/&gt;
                     new AclFilterResponse(Collections.&amp;lt;AclDeletionResult&amp;gt;emptySet()))));&lt;br/&gt;
             results = env.adminClient().deleteAcls(asList(FILTER1, FILTER2));&lt;br/&gt;
             assertTrue(results.values().get(FILTER2).get().values().isEmpty());&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertFutureError(results.all(), SecurityDisabledException.class);&lt;br/&gt;
+            TestUtils.assertFutureError(results.all(), SecurityDisabledException.class);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             // Test a call where there are no errors.&lt;br/&gt;
             env.kafkaClient().prepareResponse(new DeleteAclsResponse(0, asList(&lt;br/&gt;
@@ -673,7 +659,7 @@ public boolean conditionMet() &lt;/p&gt;
{
                     return result.listings().isDone();
                 }
&lt;p&gt;             }, &quot;Timed out waiting for listTopics to complete&quot;);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertFutureError(result.listings(), TimeoutException.class);&lt;br/&gt;
+            TestUtils.assertFutureError(result.listings(), TimeoutException.class);&lt;br/&gt;
             log.info(&quot;Verified the error result of AdminClient#listTopics&quot;);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             // The next request should succeed.&lt;br/&gt;
@@ -904,7 +890,7 @@ public void testListConsumerGroups() throws Exception {&lt;br/&gt;
                     node2);&lt;/p&gt;

&lt;p&gt;             final ListConsumerGroupsResult result = env.adminClient().listConsumerGroups();&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertFutureError(result.all(), CoordinatorNotAvailableException.class);&lt;br/&gt;
+            TestUtils.assertFutureError(result.all(), CoordinatorNotAvailableException.class);&lt;br/&gt;
             Collection&amp;lt;ConsumerGroupListing&amp;gt; listings = result.valid().get();&lt;br/&gt;
             assertEquals(2, listings.size());&lt;br/&gt;
             for (ConsumerGroupListing listing : listings) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {@@ -947,7 +933,7 @@ public void testListConsumerGroupsMetadataFailure() throws Exception {
                             Collections.emptyList()));
 
             final ListConsumerGroupsResult result = env.adminClient().listConsumerGroups();
-            assertFutureError(result.all(), KafkaException.class);
+            TestUtils.assertFutureError(result.all(), KafkaException.class);
         }     }&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -1091,7 +1077,7 @@ public void testDeleteConsumerGroups() throws Exception &lt;/p&gt;
{
             env.kafkaClient().prepareResponse(new FindCoordinatorResponse(Errors.GROUP_AUTHORIZATION_FAILED,  Node.noNode()));
 
             final DeleteConsumerGroupsResult errorResult = env.adminClient().deleteConsumerGroups(groupIds);
-            assertFutureError(errorResult.deletedGroups().get(&quot;group-0&quot;), GroupAuthorizationException.class);
+            TestUtils.assertFutureError(errorResult.deletedGroups().get(&quot;group-0&quot;), GroupAuthorizationException.class);
 
         }
&lt;p&gt;     }&lt;br/&gt;
diff --git a/clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java b/clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java&lt;br/&gt;
index c7cfeb05bbd..c83fe06ebd0 100644&lt;br/&gt;
&amp;#8212; a/clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java&lt;br/&gt;
+++ b/clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java&lt;br/&gt;
@@ -16,6 +16,7 @@&lt;br/&gt;
  */&lt;br/&gt;
 package org.apache.kafka.clients.consumer;&lt;/p&gt;

&lt;p&gt;+import java.util.ArrayList;&lt;br/&gt;
 import org.apache.kafka.clients.ClientRequest;&lt;br/&gt;
 import org.apache.kafka.clients.KafkaClient;&lt;br/&gt;
 import org.apache.kafka.clients.Metadata;&lt;br/&gt;
@@ -32,9 +33,11 @@&lt;br/&gt;
 import org.apache.kafka.common.Cluster;&lt;br/&gt;
 import org.apache.kafka.common.KafkaException;&lt;br/&gt;
 import org.apache.kafka.common.Node;&lt;br/&gt;
+import org.apache.kafka.common.PartitionInfo;&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition;&lt;br/&gt;
 import org.apache.kafka.common.errors.AuthenticationException;&lt;br/&gt;
 import org.apache.kafka.common.errors.InterruptException;&lt;br/&gt;
+import org.apache.kafka.common.errors.InvalidTopicException;&lt;br/&gt;
 import org.apache.kafka.common.errors.WakeupException;&lt;br/&gt;
 import org.apache.kafka.common.metrics.Metrics;&lt;br/&gt;
 import org.apache.kafka.common.metrics.Sensor;&lt;br/&gt;
@@ -1759,7 +1762,7 @@ private FetchResponse fetchResponse(TopicPartition partition, long fetchOffset,&lt;br/&gt;
         int maxPollRecords = Integer.MAX_VALUE;&lt;br/&gt;
         boolean checkCrcs = true;&lt;br/&gt;
         int rebalanceTimeoutMs = 60000;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;p&gt;+&lt;br/&gt;
         Deserializer&amp;lt;String&amp;gt; keyDeserializer = new StringDeserializer();&lt;br/&gt;
         Deserializer&amp;lt;String&amp;gt; valueDeserializer = new StringDeserializer();&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -1854,4 +1857,37 @@ public void testCloseWithTimeUnit() &lt;/p&gt;
{
         consumer.close(1, TimeUnit.SECONDS);
         EasyMock.verify(consumer);
     }
&lt;p&gt;+&lt;br/&gt;
+    @Test(expected = InvalidTopicException.class)&lt;br/&gt;
+    public void testSubscriptionOnInvalidTopic() throws Exception &lt;/p&gt;
{
+        Time time = new MockTime();
+        Cluster cluster = TestUtils.singletonCluster();
+        Node node = cluster.nodes().get(0);
+
+        Metadata metadata = createMetadata();
+        metadata.update(cluster, Collections.&amp;lt;String&amp;gt;emptySet(), time.milliseconds());
+
+        MockClient client = new MockClient(time, metadata);
+        client.setNode(node);
+        PartitionAssignor assignor = new RoundRobinAssignor();
+
+        String invalidTopicName = &quot;topic abc&quot;;  // Invalid topic name due to space
+
+        Set&amp;lt;String&amp;gt; invalidTopic = new HashSet&amp;lt;String&amp;gt;();
+        invalidTopic.add(invalidTopicName);
+        Cluster metadataUpdateResponseCluster = new Cluster(cluster.clusterResource().clusterId(),
+                                                            cluster.nodes(),
+                                                            new ArrayList&amp;lt;PartitionInfo&amp;gt;(0),
+                                                            Collections.&amp;lt;String&amp;gt;emptySet(),
+                                                            invalidTopic,
+                                                            cluster.internalTopics(),
+                                                            cluster.controller());
+        client.prepareMetadataUpdate(metadataUpdateResponseCluster, Collections.&amp;lt;String&amp;gt;emptySet());
+
+
+        KafkaConsumer&amp;lt;String, String&amp;gt; consumer = newConsumer(time, client, metadata, assignor, true);
+        consumer.subscribe(singleton(invalidTopicName), getConsumerRebalanceListener(consumer));
+
+        consumer.poll(Duration.ZERO);
+    }
&lt;p&gt; }&lt;br/&gt;
diff --git a/clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java b/clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java&lt;br/&gt;
index 8bfc5e7d28a..bf03e46ec08 100644&lt;br/&gt;
&amp;#8212; a/clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java&lt;br/&gt;
+++ b/clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java&lt;br/&gt;
@@ -16,6 +16,9 @@&lt;br/&gt;
  */&lt;br/&gt;
 package org.apache.kafka.clients.producer;&lt;/p&gt;

&lt;p&gt;+import java.util.ArrayList;&lt;br/&gt;
+import java.util.HashSet;&lt;br/&gt;
+import java.util.Set;&lt;br/&gt;
 import org.apache.kafka.clients.CommonClientConfigs;&lt;br/&gt;
 import org.apache.kafka.clients.Metadata;&lt;br/&gt;
 import org.apache.kafka.clients.MockClient;&lt;br/&gt;
@@ -27,6 +30,7 @@&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition;&lt;br/&gt;
 import org.apache.kafka.common.config.ConfigException;&lt;br/&gt;
 import org.apache.kafka.common.errors.InterruptException;&lt;br/&gt;
+import org.apache.kafka.common.errors.InvalidTopicException;&lt;br/&gt;
 import org.apache.kafka.common.errors.TimeoutException;&lt;br/&gt;
 import org.apache.kafka.common.header.internals.RecordHeader;&lt;br/&gt;
 import org.apache.kafka.common.internals.ClusterResourceListeners;&lt;br/&gt;
@@ -609,4 +613,45 @@ public void testOnlyCanExecuteCloseAfterInitTransactionsTimeout() &lt;/p&gt;
{
             producer.close(0, TimeUnit.MILLISECONDS);
         }
&lt;p&gt;     }&lt;br/&gt;
+&lt;br/&gt;
+    @Test&lt;br/&gt;
+    public void testSendToInvalidTopic() throws Exception &lt;/p&gt;
{
+
+        Properties props = new Properties();
+        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9000&quot;);
+        props.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, &quot;15000&quot;);
+
+        Time time = new MockTime();
+        Cluster cluster = TestUtils.singletonCluster();
+        Node node = cluster.nodes().get(0);
+
+        Metadata metadata = new Metadata(0, Long.MAX_VALUE, true);
+        metadata.update(cluster, Collections.&amp;lt;String&amp;gt;emptySet(), time.milliseconds());
+
+        MockClient client = new MockClient(time, metadata);
+        client.setNode(node);
+
+        Producer&amp;lt;String, String&amp;gt; producer = new KafkaProducer&amp;lt;&amp;gt;(new ProducerConfig(
+            ProducerConfig.addSerializerToConfig(props, new StringSerializer(), new StringSerializer())),
+            new StringSerializer(), new StringSerializer(), metadata, client);
+
+        String invalidTopicName = &quot;topic abc&quot;;          // Invalid topic name due to space
+        ProducerRecord&amp;lt;String, String&amp;gt; record = new ProducerRecord&amp;lt;&amp;gt;(invalidTopicName, &quot;HelloKafka&quot;);
+
+        Set&amp;lt;String&amp;gt; invalidTopic = new HashSet&amp;lt;String&amp;gt;();
+        invalidTopic.add(invalidTopicName);
+        Cluster metaDataUpdateResponseCluster = new Cluster(cluster.clusterResource().clusterId(),
+                                                            cluster.nodes(),
+                                                            new ArrayList&amp;lt;PartitionInfo&amp;gt;(0),
+                                                            Collections.&amp;lt;String&amp;gt;emptySet(),
+                                                            invalidTopic,
+                                                            cluster.internalTopics(),
+                                                            cluster.controller());
+        client.prepareMetadataUpdate(metaDataUpdateResponseCluster, Collections.&amp;lt;String&amp;gt;emptySet());
+
+        Future&amp;lt;RecordMetadata&amp;gt; future = producer.send(record);
+
+        assertEquals(&quot;Cluster has incorrect invalid topic list.&quot;, metaDataUpdateResponseCluster.invalidTopics(), metadata.fetch().invalidTopics());
+        TestUtils.assertFutureError(future, InvalidTopicException.class);
+    }
&lt;p&gt; }&lt;br/&gt;
diff --git a/clients/src/test/java/org/apache/kafka/test/TestUtils.java b/clients/src/test/java/org/apache/kafka/test/TestUtils.java&lt;br/&gt;
index ef9e5416abe..3ab2bce8f73 100644&lt;br/&gt;
&amp;#8212; a/clients/src/test/java/org/apache/kafka/test/TestUtils.java&lt;br/&gt;
+++ b/clients/src/test/java/org/apache/kafka/test/TestUtils.java&lt;br/&gt;
@@ -45,6 +45,8 @@&lt;br/&gt;
 import java.util.UUID;&lt;br/&gt;
 import java.util.regex.Matcher;&lt;br/&gt;
 import java.util.regex.Pattern;&lt;br/&gt;
+import java.util.concurrent.Future;&lt;br/&gt;
+import java.util.concurrent.ExecutionException;&lt;/p&gt;

&lt;p&gt; import static java.util.Arrays.asList;&lt;br/&gt;
 import static org.junit.Assert.assertEquals;&lt;br/&gt;
@@ -341,4 +343,17 @@ public static ByteBuffer toBuffer(Struct struct) &lt;/p&gt;
{
         buffer.rewind();
         return buffer;
     }
&lt;p&gt;+&lt;br/&gt;
+    public static void assertFutureError(Future&amp;lt;?&amp;gt; future, Class&amp;lt;? extends Throwable&amp;gt; exceptionClass)&lt;br/&gt;
+        throws InterruptedException {&lt;br/&gt;
+        try &lt;/p&gt;
{
+            future.get();
+            fail(&quot;Expected a &quot; + exceptionClass.getSimpleName() + &quot; exception, but got success.&quot;);
+        }
&lt;p&gt; catch (ExecutionException ee) &lt;/p&gt;
{
+            Throwable cause = ee.getCause();
+            assertEquals(&quot;Expected a &quot; + exceptionClass.getSimpleName() + &quot; exception, but got &quot; +
+                    cause.getClass().getSimpleName(),
+                exceptionClass, cause.getClass());
+        }
&lt;p&gt;+    }&lt;br/&gt;
 }&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12923359">KAFKA-3018</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 17 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3dwbz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>