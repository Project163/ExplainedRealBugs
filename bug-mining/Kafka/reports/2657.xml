<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:24:09 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-9724] Consumer wrongly ignores fetched records &quot;since it no longer has valid position&quot;</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-9724</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;After upgrading kafka-client to 2.4.0 (while brokers are still at 2.2.0) consumers in a consumer group intermittently stop progressing on assigned partitions, even when there are messages to consume. This is not a permanent condition, as they progress from time to time, but become slower with time, and catch up after restart.&lt;/p&gt;

&lt;p&gt;Here is a sample of 3 consecutive ignored fetches:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2020-03-15 12:08:58,440 DEBUG [Thread-6] o.a.k.c.c.i.ConsumerCoordinator - Committed offset 538065584 for partition mrt-rrc10-6
2020-03-15 12:08:58,541 DEBUG [Thread-6] o.a.k.c.consumer.internals.Fetcher - Skipping validation of fetch offsets for partitions [mrt-rrc10-1, mrt-rrc10-6, mrt-rrc22-7] since the broker does not support the required protocol version (introduced in Kafka 2.3)
2020-03-15 12:08:58,549 DEBUG [Thread-6] org.apache.kafka.clients.Metadata - Updating last seen epoch from null to 62 for partition mrt-rrc10-6
2020-03-15 12:08:58,557 DEBUG [Thread-6] o.a.k.c.c.i.ConsumerCoordinator - Committed offset 538065584 for partition mrt-rrc10-6
2020-03-15 12:08:58,652 DEBUG [Thread-6] o.a.k.c.consumer.internals.Fetcher - Skipping validation of fetch offsets for partitions [mrt-rrc10-1, mrt-rrc10-6, mrt-rrc22-7] since the broker does not support the required protocol version (introduced in Kafka 2.3)
2020-03-15 12:08:58,659 DEBUG [Thread-6] org.apache.kafka.clients.Metadata - Updating last seen epoch from null to 62 for partition mrt-rrc10-6
2020-03-15 12:08:58,659 DEBUG [Thread-6] o.a.k.c.consumer.internals.Fetcher - Fetch READ_UNCOMMITTED at offset 538065584 for partition mrt-rrc10-6 returned fetch data (error=NONE, highWaterMark=538065631, lastStableOffset = 538065631, logStartOffset = 485284547, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=16380)
2020-03-15 12:08:58,659 DEBUG [Thread-6] o.a.k.c.consumer.internals.Fetcher - Ignoring fetched records for partition mrt-rrc10-6 since it no longer has valid position
2020-03-15 12:08:58,665 DEBUG [Thread-6] o.a.k.c.c.i.ConsumerCoordinator - Committed offset 538065584 for partition mrt-rrc10-6
2020-03-15 12:08:58,761 DEBUG [Thread-6] o.a.k.c.consumer.internals.Fetcher - Skipping validation of fetch offsets for partitions [mrt-rrc10-1, mrt-rrc10-6, mrt-rrc22-7] since the broker does not support the required protocol version (introduced in Kafka 2.3)
2020-03-15 12:08:58,761 DEBUG [Thread-6] o.a.k.c.consumer.internals.Fetcher - Added READ_UNCOMMITTED fetch request for partition mrt-rrc10-6 at position FetchPosition{offset=538065584, offsetEpoch=Optional[62], currentLeader=LeaderAndEpoch{leader=node03.kafka:9092 (id: 3 rack: null), epoch=-1}} to node node03.kafka:9092 (id: 3 rack: null)
2020-03-15 12:08:58,761 DEBUG [Thread-6] o.a.k.c.consumer.internals.Fetcher - Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(mrt-rrc10-6, mrt-rrc22-7, mrt-rrc10-1)) to broker node03.kafka:9092 (id: 3 rack: null)
2020-03-15 12:08:58,770 DEBUG [Thread-6] org.apache.kafka.clients.Metadata - Updating last seen epoch from null to 62 for partition mrt-rrc10-6
2020-03-15 12:08:58,770 DEBUG [Thread-6] o.a.k.c.consumer.internals.Fetcher - Fetch READ_UNCOMMITTED at offset 538065584 for partition mrt-rrc10-6 returned fetch data (error=NONE, highWaterMark=538065727, lastStableOffset = 538065727, logStartOffset = 485284547, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=51864)
2020-03-15 12:08:58,770 DEBUG [Thread-6] o.a.k.c.consumer.internals.Fetcher - Ignoring fetched records for partition mrt-rrc10-6 since it no longer has valid position
2020-03-15 12:08:58,808 DEBUG [Thread-6] o.a.k.c.c.i.ConsumerCoordinator - Committed offset 538065584 for partition mrt-rrc10-6
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After which consumer makes progress:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2020-03-15 12:08:58,871 DEBUG [Thread-6] o.a.k.c.consumer.internals.Fetcher - Skipping validation of fetch offsets for partitions [mrt-rrc10-1, mrt-rrc10-6, mrt-rrc22-7] since the broker does not support the required protocol version (introduced in Kafka 2.3)
2020-03-15 12:08:58,871 DEBUG [Thread-6] o.a.k.c.consumer.internals.Fetcher - Added READ_UNCOMMITTED fetch request for partition mrt-rrc10-6 at position FetchPosition{offset=538065584, offsetEpoch=Optional[62], currentLeader=LeaderAndEpoch{leader=node03.kafka:9092 (id: 3 rack: null), epoch=-1}} to node node03.kafka:9092 (id: 3 rack: null)
2020-03-15 12:08:58,871 DEBUG [Thread-6] o.a.k.c.consumer.internals.Fetcher - Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(mrt-rrc10-6, mrt-rrc22-7, mrt-rrc10-1)) to broker node03.kafka:9092 (id: 3 rack: null)
2020-03-15 12:08:58,872 DEBUG [Thread-6] o.a.k.c.consumer.internals.Fetcher - Fetch READ_UNCOMMITTED at offset 538065584 for partition mrt-rrc10-6 returned fetch data (error=NONE, highWaterMark=538065744, lastStableOffset = 538065744, logStartOffset = 485284547, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=58293)
2020-03-15 12:08:58,872 DEBUG [Thread-6] o.a.k.c.consumer.internals.Fetcher - Added READ_UNCOMMITTED fetch request for partition mrt-rrc10-6 at position FetchPosition{offset=538065744, offsetEpoch=Optional[62], currentLeader=LeaderAndEpoch{leader=node03.kafka:9092 (id: 3 rack: null), epoch=-1}} to node node03.kafka:9092 (id: 3 rack: null)
2020-03-15 12:08:58,872 DEBUG [Thread-6] o.a.k.c.consumer.internals.Fetcher - Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(mrt-rrc10-6), toForget=(), implied=(mrt-rrc22-7, mrt-rrc10-1)) to broker node03.kafka:9092 (id: 3 rack: null)
2020-03-15 12:08:58,880 DEBUG [Thread-6] org.apache.kafka.clients.Metadata - Updating last seen epoch from null to 62 for partition mrt-rrc10-6
2020-03-15 12:08:58,885 DEBUG [Thread-6] o.a.k.c.c.i.ConsumerCoordinator - Committed offset 538065744 for partition mrt-rrc10-6
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But it could be stuck for quite a long time.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13291804">KAFKA-9724</key>
            <summary>Consumer wrongly ignores fetched records &quot;since it no longer has valid position&quot;</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mumrah">David Arthur</assignee>
                                    <reporter username="o.muravskiy">Oleg Muravskiy</reporter>
                        <labels>
                    </labels>
                <created>Sun, 15 Mar 2020 12:39:32 +0000</created>
                <updated>Tue, 21 Jul 2020 08:22:12 +0000</updated>
                            <resolved>Tue, 9 Jun 2020 13:48:53 +0000</resolved>
                                    <version>2.4.0</version>
                                    <fixVersion>2.5.1</fixVersion>
                    <fixVersion>2.6.0</fixVersion>
                                    <component>clients</component>
                    <component>consumer</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="17062748" author="ijuma" created="Thu, 19 Mar 2020 16:31:05 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=bchen225242&quot; class=&quot;user-hover&quot; rel=&quot;bchen225242&quot;&gt;bchen225242&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17062787" author="hachikuji" created="Thu, 19 Mar 2020 17:25:34 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=o.muravskiy&quot; class=&quot;user-hover&quot; rel=&quot;o.muravskiy&quot;&gt;o.muravskiy&lt;/a&gt; Thanks for the report. Could you include your consumer configuration?&lt;/p&gt;</comment>
                            <comment id="17063333" author="o.muravskiy" created="Fri, 20 Mar 2020 12:38:39 +0000"  >&lt;p&gt;Sure &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt;: &lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;        allow.auto.create.topics = true
        auto.commit.interval.ms = 5000
        auto.offset.reset = earliest
        check.crcs = true
        client.dns.lookup = default
        client.id = ris-updates-to-hbase-ristest
        client.rack = 
        connections.max.idle.ms = 540000
        default.api.timeout.ms = 60000
        enable.auto.commit = false
        exclude.internal.topics = true
        fetch.max.bytes = 5000000
        fetch.max.wait.ms = 8000
        fetch.min.bytes = 1
        group.id = ris-updates-to-hbase-ristest
        group.instance.id = null
        heartbeat.interval.ms = 3000
        interceptor.classes = []
        internal.leave.group.on.close = true
        isolation.level = read_uncommitted
        max.partition.fetch.bytes = 4000000
        max.poll.interval.ms = 300000
        max.poll.records = 500000
        metadata.max.age.ms = 300000
        metric.reporters = []
        metrics.num.samples = 2
        metrics.recording.level = INFO
        metrics.sample.window.ms = 30000
        partition.assignment.strategy = [org.apache.kafka.clients.consumer.StickyAssignor]
        receive.buffer.bytes = 65536
        reconnect.backoff.max.ms = 1000
        reconnect.backoff.ms = 50
        request.timeout.ms = 30000
        retry.backoff.ms = 100
        sasl.client.callback.handler.class = null
        sasl.jaas.config = null
        sasl.kerberos.kinit.cmd = /usr/bin/kinit
        sasl.kerberos.min.time.before.relogin = 60000
        sasl.kerberos.service.name = null
        sasl.kerberos.ticket.renew.jitter = 0.05
        sasl.kerberos.ticket.renew.window.factor = 0.8
        sasl.login.callback.handler.class = null
        sasl.login.class = null
        sasl.login.refresh.buffer.seconds = 300
        sasl.login.refresh.min.period.seconds = 60
        sasl.login.refresh.window.factor = 0.8
        sasl.login.refresh.window.jitter = 0.05
        sasl.mechanism = GSSAPI
        security.protocol = PLAINTEXT
        security.providers = null
        send.buffer.bytes = 65536
        session.timeout.ms = 300000
        ssl.cipher.suites = null
        ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
        ssl.endpoint.identification.algorithm = https
        ssl.key.password = null
        ssl.keymanager.algorithm = SunX509
        ssl.keystore.location = null
        ssl.keystore.password = null
        ssl.keystore.type = JKS
        ssl.protocol = TLS
        ssl.provider = null
        ssl.secure.random.implementation = null
        ssl.trustmanager.algorithm = PKIX
        ssl.truststore.location = null
        ssl.truststore.password = null
        ssl.truststore.type = JKS
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17069028" author="githubbot" created="Fri, 27 Mar 2020 20:25:30 +0000"  >&lt;p&gt;mumrah commented on pull request #8376: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-9724&quot; title=&quot;Consumer wrongly ignores fetched records &amp;quot;since it no longer has valid position&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-9724&quot;&gt;&lt;del&gt;KAFKA-9724&lt;/del&gt;&lt;/a&gt; Newer clients not always sending fetch request to older brokers&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/8376&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/8376&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   We had a similar case previously with &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-8422&quot; title=&quot;Client should not use old versions of OffsetsForLeaderEpoch&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-8422&quot;&gt;&lt;del&gt;KAFKA-8422&lt;/del&gt;&lt;/a&gt; (#6806) where we would skip the validation step if the broker was on a version older than 2.3. &lt;/p&gt;

&lt;p&gt;   This PR makes a similar change on the `prepareFetchRequest` side. If the broker is older than 2.3, we will skip the transition to AWAITING_VALIDATION but also we will clear that state if it had been set by a call to `seekUnvalidated`.&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on to GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="17071219" author="mumrah" created="Mon, 30 Mar 2020 19:33:21 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=o.muravskiy&quot; class=&quot;user-hover&quot; rel=&quot;o.muravskiy&quot;&gt;o.muravskiy&lt;/a&gt; could you attach a larger log snippet? I&apos;m having trouble reproducing this with 2.4 client and 2.2 broker. I see you have &lt;tt&gt;enable.auto.commit&lt;/tt&gt; turned off. Can you describe the application a little?&lt;/p&gt;</comment>
                            <comment id="17071369" author="hachikuji" created="Tue, 31 Mar 2020 01:07:04 +0000"  >&lt;p&gt;The interesting thing in the log snippet is the frequency of offset commits. Is that expected? I was speculating that we might be entering a loop like the following:&lt;/p&gt;

&lt;p&gt;1. user commits offset with `commitSync` (or similar) which updates Metadata.lastSeenLeaderEpochs&lt;br/&gt;
2. in prepareFetch, Metadata.currentLeader then would return no leader and the last seen epoch&lt;br/&gt;
3. we trigger a metadata update because we have no leader&lt;br/&gt;
4. we get the metadata update without epoch information and reset Metadata.lastSeenLeaderEpochs&lt;br/&gt;
5. now we can fetch, but if we get another offset commit first, we would go back to 1&lt;/p&gt;

&lt;p&gt;I tried to reproduce this issue locally, but can&apos;t say I fully succeeded. I did notice some pauses, but they were very brief. I definitely did notice the unnecessary metadata updates from step 3) though, so I think this is worth fixing even if it does not turn out to be the root cause of this issue. A potential fix is to skip updating `lastSeenLeaderEpochs` in step 1 if we have a current leader, but the epoch is not known.&lt;/p&gt;</comment>
                            <comment id="17071586" author="o.muravskiy" created="Tue, 31 Mar 2020 08:25:49 +0000"  >&lt;p&gt;Here&apos;s the bigger fragment of a log:&lt;br/&gt;
 &lt;span class=&quot;nobr&quot;&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12998307/12998307_consumer.log.xz&quot; title=&quot;consumer.log.xz attached to KAFKA-9724&quot;&gt;consumer.log.xz&lt;sup&gt;&lt;img class=&quot;rendericon&quot; src=&quot;https://issues.apache.org/jira/images/icons/link_attachment_7.gif&quot; height=&quot;7&quot; width=&quot;7&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/sup&gt;&lt;/a&gt;&lt;/span&gt;  &lt;/p&gt;</comment>
                            <comment id="17071643" author="o.muravskiy" created="Tue, 31 Mar 2020 10:13:00 +0000"  >&lt;p&gt;The algorithm of a consumer is fairly simple:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;subscribe to a number of topics with pattern subscription&lt;/li&gt;
	&lt;li&gt;poll&lt;/li&gt;
	&lt;li&gt;process the batch (insert to HBase)&lt;/li&gt;
	&lt;li&gt;produce a record to another topic (status info)&lt;/li&gt;
	&lt;li&gt;async commit consumed offsets&lt;/li&gt;
	&lt;li&gt;loop to poll&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;But looking at &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt;&apos;s reply, I want to add that I&apos;m using an OffsetCommitCallback which in essence is &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; void onComplete(Map&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt; offsets, Exception exception) {
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (exception &lt;span class=&quot;code-keyword&quot;&gt;instanceof&lt;/span&gt; RetriableCommitFailedException) {
            &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (++failureCount &amp;lt; ignoranceLevel) {
                log.warn(&lt;span class=&quot;code-quote&quot;&gt;&quot;Non-fatally failed to commit offsets, will keep going on. &quot;&lt;/span&gt;, exception);
            } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
                &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
                    &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.sleep((&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) (&lt;span class=&quot;code-object&quot;&gt;Math&lt;/span&gt;.random() * TimeUnit.SECONDS.toMillis(10)));
                    consumer.commitSync(offsets);
                    failureCount = 0;
                } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (Exception e) {
                    onComplete(offsets, e);
                }
            }
        } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (exception != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
            log.error(&lt;span class=&quot;code-quote&quot;&gt;&quot;Can&apos;t commit offsets, starting shutdown: &quot;&lt;/span&gt;, exception);
            &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.exit(-1);
        }
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17078417" author="mumrah" created="Wed, 8 Apr 2020 15:53:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=o.muravskiy&quot; class=&quot;user-hover&quot; rel=&quot;o.muravskiy&quot;&gt;o.muravskiy&lt;/a&gt;, I have a patch available here &lt;a href=&quot;https://github.com/apache/kafka/pull/8376&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/8376&lt;/a&gt;. Would you be willing to try it out and see if you continue to see hanging in the consumer? &lt;/p&gt;</comment>
                            <comment id="17084045" author="ijuma" created="Wed, 15 Apr 2020 12:32:03 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=o.muravskiy&quot; class=&quot;user-hover&quot; rel=&quot;o.muravskiy&quot;&gt;o.muravskiy&lt;/a&gt;&#160;any chance you can test the patch above?&lt;/p&gt;</comment>
                            <comment id="17084341" author="o.muravskiy" created="Wed, 15 Apr 2020 19:50:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt; Sorry &#8211;&#160;I deployed it, wanted to run for a longer time and kind of forgot.&lt;/p&gt;

&lt;p&gt;I could confirm the issue have disappeared.&lt;/p&gt;</comment>
                            <comment id="17084417" author="ijuma" created="Wed, 15 Apr 2020 22:21:06 +0000"  >&lt;p&gt;That&apos;s great to hear!&lt;/p&gt;</comment>
                            <comment id="17161857" author="zgw" created="Tue, 21 Jul 2020 08:22:12 +0000"  >&lt;p&gt;When merge this to Kafka 2.4.x?&#160; Have any plan?&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12998307" name="consumer.log.xz" size="49832" author="o.muravskiy" created="Tue, 31 Mar 2020 08:25:05 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 17 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0cjo0:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>