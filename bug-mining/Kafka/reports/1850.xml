<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:07:47 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-3978] Cannot truncate to a negative offset (-1) exception at broker startup</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-3978</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;During broker startup sequence the broker server.log has this exception. Problem persists after multiple restarts and also on another broker in the cluster.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;INFO [Socket Server on Broker 1002], Started 1 acceptor threads (kafka.network.SocketServer)
INFO [Socket Server on Broker 1002], Started 1 acceptor threads (kafka.network.SocketServer)
INFO [ExpirationReaper-1002], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
INFO [ExpirationReaper-1002], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
INFO [ExpirationReaper-1002], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
INFO [ExpirationReaper-1002], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
INFO [ExpirationReaper-1002], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
INFO [ExpirationReaper-1002], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
INFO [ExpirationReaper-1002], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
INFO [ExpirationReaper-1002], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
INFO [GroupCoordinator 1002]: Starting up. (kafka.coordinator.GroupCoordinator)
INFO [GroupCoordinator 1002]: Starting up. (kafka.coordinator.GroupCoordinator)
INFO [GroupCoordinator 1002]: Startup complete. (kafka.coordinator.GroupCoordinator)
INFO [GroupCoordinator 1002]: Startup complete. (kafka.coordinator.GroupCoordinator)
INFO [Group Metadata Manager on Broker 1002]: Removed 0 expired offsets in 9 milliseconds. (kafka.coordinator.GroupMetadataManager)
INFO [Group Metadata Manager on Broker 1002]: Removed 0 expired offsets in 9 milliseconds. (kafka.coordinator.GroupMetadataManager)
INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
INFO Creating /brokers/ids/1002 (is it secure? &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;) (kafka.utils.ZKCheckedEphemeral)
INFO Creating /brokers/ids/1002 (is it secure? &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;) (kafka.utils.ZKCheckedEphemeral)
INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
INFO Registered broker 1002 at path /brokers/ids/1002 with addresses: PLAINTEXT -&amp;gt; EndPoint(172.16.2.22,9092,PLAINTEXT) (kafka.utils.ZkUtils)
INFO Registered broker 1002 at path /brokers/ids/1002 with addresses: PLAINTEXT -&amp;gt; EndPoint(172.16.2.22,9092,PLAINTEXT) (kafka.utils.ZkUtils)
INFO Kafka version : 0.10.0.0 (org.apache.kafka.common.utils.AppInfoParser)
INFO Kafka commitId : b8642491e78c5a13 (org.apache.kafka.common.utils.AppInfoParser)
INFO [Kafka Server 1002], started (kafka.server.KafkaServer)
INFO [Kafka Server 1002], started (kafka.server.KafkaServer)
Error when handling request {controller_id=1004,controller_epoch=1,partition_states=[..REALLY LONG OUTPUT SNIPPED AWAY..], live_leaders=[{id=1004,host=172.16.6.187,port=9092},{id=1003,host=172.16.2.21,port=9092}]} (kafka.server.KafkaApis)
ERROR java.lang.IllegalArgumentException: Cannot truncate to a negative offset (-1).
        at kafka.log.Log.truncateTo(Log.scala:731)
        at kafka.log.LogManager$$anonfun$truncateTo$2.apply(LogManager.scala:288)
        at kafka.log.LogManager$$anonfun$truncateTo$2.apply(LogManager.scala:280)
        at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
        at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221)
        at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428)
        at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428)
        at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428)
        at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
        at kafka.log.LogManager.truncateTo(LogManager.scala:280)
        at kafka.server.ReplicaManager.makeFollowers(ReplicaManager.scala:802)
        at kafka.server.ReplicaManager.becomeLeaderOrFollower(ReplicaManager.scala:648)
        at kafka.server.KafkaApis.handleLeaderAndIsrRequest(KafkaApis.scala:144)
        at kafka.server.KafkaApis.handle(KafkaApis.scala:80)
        at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment>3.13.0-87-generic </environment>
        <key id="12991107">KAFKA-3978</key>
            <summary>Cannot truncate to a negative offset (-1) exception at broker startup</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lindong">Dong Lin</assignee>
                                    <reporter username="garo5">Juho M&#228;kinen</reporter>
                        <labels>
                            <label>reliability</label>
                            <label>startup</label>
                    </labels>
                <created>Wed, 20 Jul 2016 13:02:32 +0000</created>
                <updated>Wed, 17 Jul 2019 00:16:25 +0000</updated>
                            <resolved>Wed, 14 Mar 2018 06:01:59 +0000</resolved>
                                    <version>0.10.0.0</version>
                                    <fixVersion>1.1.0</fixVersion>
                                        <due></due>
                            <votes>1</votes>
                                    <watches>10</watches>
                                                                                                                <comments>
                            <comment id="15444241" author="ceracm" created="Sun, 28 Aug 2016 22:36:42 +0000"  >&lt;p&gt;I encountered the same error message with 0.9.01.&lt;br/&gt;
Unfortunately, the logs were lost.&lt;br/&gt;
The problem persisted across restarts.&lt;br/&gt;
Ultimately, I fixed the problem by deleting the logs and restarting.&lt;/p&gt;</comment>
                            <comment id="16047111" author="ijuma" created="Mon, 12 Jun 2017 21:42:58 +0000"  >&lt;p&gt;This is the root cause of &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3123&quot; title=&quot;Follower Broker cannot start if offsets are already out of range&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3123&quot;&gt;&lt;del&gt;KAFKA-3123&lt;/del&gt;&lt;/a&gt; as well, see &lt;a href=&quot;https://github.com/apache/kafka/pull/1716#discussion_r112000498&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1716#discussion_r112000498&lt;/a&gt; . We fixed &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3123&quot; title=&quot;Follower Broker cannot start if offsets are already out of range&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3123&quot;&gt;&lt;del&gt;KAFKA-3123&lt;/del&gt;&lt;/a&gt; so that the cleaner resumes even if truncateTo fails in this way. However, it would still be good to fix this JIRA.&lt;/p&gt;</comment>
                            <comment id="16096887" author="dnwe" created="Fri, 21 Jul 2017 21:17:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt; we actually hit this issue the other day on 0.10.2 and it seemed to have more serious repercussions than initially suggested here.&lt;/p&gt;

&lt;p&gt;Because the truncateTo exception causes kafka.server.ReplicaManager.makeFollowers to exit, having removed any fetchers for the set of partitions passed in, we seem to end up with the broker never following/replicating those partitions again unless the &quot;bad&quot; partition (seemingly with an unknown checkpoint offset) is manually removed from ZK and the broker is restarted. &lt;/p&gt;

&lt;p&gt;I know that KIP-101 reworked this area, so it may no longer be possible under 0.11 onwards. I also wasn&apos;t entirely sure how we got into the state and was unable to reproduce it by manually fiddling with replication-offset-checkpoint or otherwise.&lt;/p&gt;</comment>
                            <comment id="16387076" author="hachikuji" created="Tue, 6 Mar 2018 01:01:13 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt; We&apos;re still not sure the cause of this, but it should be easy to either 1) add an assertion when writing the checkpoint that offsets are not negative, and 2) detect the problem at startup and just use the log start offset. Since this problem has persisted for some time, shall we go ahead and do either of&#160;these?&lt;/p&gt;</comment>
                            <comment id="16387125" author="junrao" created="Tue, 6 Mar 2018 01:41:29 +0000"  >&lt;p&gt;Agreed. For 1) we could add an assertion. For 2), if we detect that we are truncating to -1, we could log a warn and just truncate the whole local log.&lt;/p&gt;</comment>
                            <comment id="16391698" author="lindong" created="Thu, 8 Mar 2018 18:32:21 +0000"  >&lt;p&gt;I also encountered this issue and I have been looking at this all day yesterday. Still no clue how leader can sender FetchResponse with error=None and hw=-1&lt;/p&gt;</comment>
                            <comment id="16391863" author="lindong" created="Thu, 8 Mar 2018 20:11:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt; I have a good theory now. I will submit a patch to fix it.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Broker A is leader for partition P1 and broker B is follower for partition P1.&lt;br/&gt;
&#160;&lt;/li&gt;
	&lt;li&gt;Broker C receives LeaderAndIsrRequest to become follower for P1. In broker C&apos;s memory, P1&apos;s highWatermarkMetadata =&#160;LogOffsetMetadata(hw=0, segmentBaseOffset=-1). Local replica&apos;s LEO for P1 is 0.&lt;br/&gt;
&#160;&lt;/li&gt;
	&lt;li&gt;Broker C&apos;s ReplicaFetchRequest sends leader epoch request to broker A and then truncates its local replica&apos;s LEO to 100.&lt;br/&gt;
&#160;&lt;/li&gt;
	&lt;li&gt;Broker C receives LeaderAndIsrRequest to become leader for P1 with ISR=(A,B,C). In broker C&apos;s memory, P1&apos;s highWatermarkMetadata =&#160;LogOffsetMetadata(hw=0, segmentBaseOffset=-1). And in broker C&apos;s memory, according to partition.makeLeader(), replica A&apos;s logEndOffsetMetadata is initialized to be LogOffsetMetadata.UnknownOffsetMetadata, which has HW= - 1 and&#160;segmentBaseOffset = 0.&lt;br/&gt;
&#160;&lt;/li&gt;
	&lt;li&gt;Broker C receives FetchRequest from broker B. In Partition.maybeIncrementLeaderHW(), new highWaterMark will be derived with min(logEndOffset metadata of all replicas), which will be&#160;LogOffsetMetadata(HW=-1, segmentBaseOffset=0) because A&apos;s logEndOffset metadata is smallest. Because new hw&apos;s segmentBaseOffset &amp;gt; old hw&apos;s segmentBaseOffset, the high watermark is updated to be LogOffsetMetadata(hw=-1, segmentBaseOffset=100L).&lt;br/&gt;
&#160;&lt;/li&gt;
	&lt;li&gt;Now we have a partition whose HW is negative, which cause problem for broker B when it fetches from broker C.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="16394103" author="lindong" created="Sat, 10 Mar 2018 08:33:52 +0000"  >&lt;p&gt;Finally confirmed the root cause and is able to reproduce this using a test:&lt;/p&gt;

&lt;p&gt;1) Partition P1 has replica set size 1. Broker A is the leader. The segment is empty and log start offset is 100&lt;/p&gt;

&lt;p&gt;2)&#160;User executes partition reassignment to change replica set from {A} to {B, C}&lt;/p&gt;

&lt;p&gt;3) Broker B starts ReplicaFetcherThread, which triggers handleOffsetOutOfRange(), truncates the log fully and start at offset 100. At this moment its high watermark is still 0 (or -1).&#160;Same for broker C.&lt;/p&gt;

&lt;p&gt;4) Broker B sends FetchRequest to A at offset 100, broker A immediately adds broker B to ISR set, and controller moves leadership to broker B.&lt;/p&gt;

&lt;p&gt;5) Broker B handles LeaderAndIsrRequest to become leader. It calls `leaderReplica.convertHWToLocalOffsetMetadata()` to initialize its HW. Since its HW was smaller than logStartOffset=100, now its HW will be overridden to&#160;LogOffsetMetadata.UnknownOffsetMetadata, i.e. -1.&lt;/p&gt;

&lt;p&gt;6) Broker C handles LeaderAndIsrRequest to fetch from broker B. Broker C updates its HW to the FetchRequest&apos;s HW, i.e. -1. Then broker C calls&#160;replica.maybeIncrementLogStartOffset(leaderLogStartOffset) where&#160;leaderLogStartOffset=100. This cause exception because&#160;leaderLogStartOffset &amp;gt; HW.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="16394107" author="lindong" created="Sat, 10 Mar 2018 09:00:19 +0000"  >&lt;p&gt;Just realized that the problem I have been investigating is different from this Jira ticket. But they may be related in the sensor that both issues are due to the use of hw -1.&lt;/p&gt;

&lt;p&gt;As shown in the previous comment, a new leader may instantiate leader replica&#160;with hw=-1. And this negative hw can also be passed to follower. This causes problem either when we truncate log to the hw, or&#160;when we try to increase log start offset to a positive offset.&lt;/p&gt;</comment>
                            <comment id="16396305" author="githubbot" created="Tue, 13 Mar 2018 00:28:53 +0000"  >&lt;p&gt;lindong28 opened a new pull request #4695: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3978&quot; title=&quot;Cannot truncate to a negative offset (-1) exception at broker startup&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3978&quot;&gt;&lt;del&gt;KAFKA-3978&lt;/del&gt;&lt;/a&gt;; highwatermark should always be positive&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4695&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4695&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Partition highwatermark may become -1 during partition reassignment. The bug was fixed and validated with unit test in this patch.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16398124" author="githubbot" created="Wed, 14 Mar 2018 05:53:02 +0000"  >&lt;p&gt;hachikuji closed pull request #4695: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3978&quot; title=&quot;Cannot truncate to a negative offset (-1) exception at broker startup&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3978&quot;&gt;&lt;del&gt;KAFKA-3978&lt;/del&gt;&lt;/a&gt;; highwatermark should always be positive&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4695&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4695&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/core/src/main/scala/kafka/cluster/Partition.scala b/core/src/main/scala/kafka/cluster/Partition.scala&lt;br/&gt;
index 3b97671524d..68faf00c079 100755&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/cluster/Partition.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/cluster/Partition.scala&lt;br/&gt;
@@ -460,7 +460,11 @@ class Partition(val topic: String,&lt;br/&gt;
     }.map(_.logEndOffset)&lt;br/&gt;
     val newHighWatermark = allLogEndOffsets.min(new LogOffsetMetadata.OffsetOrdering)&lt;br/&gt;
     val oldHighWatermark = leaderReplica.highWatermark&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (oldHighWatermark.messageOffset &amp;lt; newHighWatermark.messageOffset || oldHighWatermark.onOlderSegment(newHighWatermark)) {&lt;br/&gt;
+&lt;br/&gt;
+    // Ensure that the high watermark increases monotonically. We also update the high watermark when the new&lt;br/&gt;
+    // offset metadata is on a newer segment, which occurs whenever the log is rolled to a new segment.&lt;br/&gt;
+    if (oldHighWatermark.messageOffset &amp;lt; newHighWatermark.messageOffset ||&lt;br/&gt;
+      (oldHighWatermark.messageOffset == newHighWatermark.messageOffset &amp;amp;&amp;amp; oldHighWatermark.onOlderSegment(newHighWatermark))) {&lt;br/&gt;
       leaderReplica.highWatermark = newHighWatermark&lt;br/&gt;
       debug(s&quot;High watermark updated to $newHighWatermark&quot;)&lt;br/&gt;
       true&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/cluster/Replica.scala b/core/src/main/scala/kafka/cluster/Replica.scala&lt;br/&gt;
index e41e389e22d..030e5b7eb58 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/main/scala/kafka/cluster/Replica.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/cluster/Replica.scala&lt;br/&gt;
@@ -138,6 +138,9 @@ class Replica(val brokerId: Int,&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def highWatermark_=(newHighWatermark: LogOffsetMetadata) {&lt;br/&gt;
     if (isLocal) &lt;/p&gt;
{
+      if (newHighWatermark.messageOffset &amp;lt; 0)
+        throw new IllegalArgumentException(&quot;High watermark offset should be non-negative&quot;)
+
       highWatermarkMetadata = newHighWatermark
       log.foreach(_.onHighWatermarkIncremented(newHighWatermark.messageOffset))
       trace(s&quot;Setting high watermark for replica $brokerId partition $topicPartition to [$newHighWatermark]&quot;)
@@ -165,9 +168,16 @@ class Replica(val brokerId: Int,
       s&quot;non-local replica $brokerId&quot;))
   }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def convertHWToLocalOffsetMetadata() = {&lt;br/&gt;
+  /*&lt;br/&gt;
+   * Convert hw to local offset metadata by reading the log at the hw offset.&lt;br/&gt;
+   * If the hw offset is out of range, return the first offset of the first log segment as the offset metadata.&lt;br/&gt;
+   */&lt;br/&gt;
+  def convertHWToLocalOffsetMetadata() {&lt;br/&gt;
     if (isLocal) {&lt;/li&gt;
	&lt;li&gt;highWatermarkMetadata = log.get.convertToOffsetMetadata(highWatermarkMetadata.messageOffset)&lt;br/&gt;
+      highWatermarkMetadata = log.get.convertToOffsetMetadata(highWatermarkMetadata.messageOffset).getOrElse 
{
+        val firstOffset = log.get.logSegments.head.baseOffset
+        new LogOffsetMetadata(firstOffset, firstOffset, 0)
+      }
&lt;p&gt;     } else &lt;/p&gt;
{
       throw new KafkaException(s&quot;Should not construct complete high watermark on partition $topicPartition&apos;s non-local replica $brokerId&quot;)
     }
&lt;p&gt;diff --git a/core/src/main/scala/kafka/log/Log.scala b/core/src/main/scala/kafka/log/Log.scala&lt;br/&gt;
index 257dd8f9ba4..f0050f54aef 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/main/scala/kafka/log/Log.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/log/Log.scala&lt;br/&gt;
@@ -1126,14 +1126,14 @@ class Log(@volatile var dir: File,&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Given a message offset, find its corresponding offset metadata in the log.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* If the message offset is out of range, return unknown offset metadata&lt;br/&gt;
+   * If the message offset is out of range, return None to the caller.&lt;br/&gt;
    */&lt;/li&gt;
	&lt;li&gt;def convertToOffsetMetadata(offset: Long): LogOffsetMetadata = {&lt;br/&gt;
+  def convertToOffsetMetadata(offset: Long): Option&lt;span class=&quot;error&quot;&gt;&amp;#91;LogOffsetMetadata&amp;#93;&lt;/span&gt; = 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {     try {
       val fetchDataInfo = readUncommitted(offset, 1)
-      fetchDataInfo.fetchOffsetMetadata
+      Some(fetchDataInfo.fetchOffsetMetadata)
     } catch {
-      case _: OffsetOutOfRangeException =&amp;gt; LogOffsetMetadata.UnknownOffsetMetadata
+      case _: OffsetOutOfRangeException =&amp;gt; None
     }   }&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;diff --git a/core/src/test/scala/unit/kafka/admin/ReassignPartitionsClusterTest.scala b/core/src/test/scala/unit/kafka/admin/ReassignPartitionsClusterTest.scala&lt;br/&gt;
index 2a24a37f151..0c41519d211 100644&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/admin/ReassignPartitionsClusterTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/admin/ReassignPartitionsClusterTest.scala&lt;br/&gt;
@@ -76,6 +76,32 @@ class ReassignPartitionsClusterTest extends ZooKeeperTestHarness with Logging &lt;/p&gt;
{
     super.tearDown()
   }

&lt;p&gt;+  @Test&lt;br/&gt;
+  def testHwAfterPartitionReassignment(): Unit = {&lt;br/&gt;
+    //Given a single replica on server 100&lt;br/&gt;
+    startBrokers(Seq(100, 101, 102))&lt;br/&gt;
+    adminClient = createAdminClient(servers)&lt;br/&gt;
+    createTopic(zkClient, topicName, Map(0 -&amp;gt; Seq(100)), servers = servers)&lt;br/&gt;
+&lt;br/&gt;
+    val topicPartition = new TopicPartition(topicName, 0)&lt;br/&gt;
+    val leaderServer = servers.find(_.config.brokerId == 100).get&lt;br/&gt;
+    leaderServer.replicaManager.logManager.truncateFullyAndStartAt(topicPartition, 100L, false)&lt;br/&gt;
+&lt;br/&gt;
+    val topicJson: String = s&quot;&quot;&quot;{&quot;version&quot;:1,&quot;partitions&quot;:[&lt;/p&gt;
{&quot;topic&quot;:&quot;$topicName&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[101, 102]}
&lt;p&gt;]}&quot;&quot;&quot;&lt;br/&gt;
+    ReassignPartitionsCommand.executeAssignment(zkClient, Some(adminClient), topicJson, NoThrottle)&lt;br/&gt;
+&lt;br/&gt;
+    val newLeaderServer = servers.find(_.config.brokerId == 101).get&lt;br/&gt;
+&lt;br/&gt;
+    TestUtils.waitUntilTrue (&lt;br/&gt;
+      () =&amp;gt; newLeaderServer.replicaManager.getPartition(topicPartition).flatMap(_.leaderReplicaIfLocal).isDefined,&lt;br/&gt;
+      &quot;broker 101 should be the new leader&quot;, pause = 1L&lt;br/&gt;
+    )&lt;br/&gt;
+&lt;br/&gt;
+    assertEquals(100, newLeaderServer.replicaManager.getReplicaOrException(topicPartition).highWatermark.messageOffset)&lt;br/&gt;
+    servers.foreach(server =&amp;gt; waitUntilTrue(() =&amp;gt; server.replicaManager.getReplicaOrException(topicPartition).highWatermark.messageOffset == 100, &quot;&quot;))&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
   @Test&lt;br/&gt;
   def shouldMoveSinglePartition(): Unit = {&lt;br/&gt;
     //Given a single replica on server 100&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16401313" author="githubbot" created="Fri, 16 Mar 2018 00:26:14 +0000"  >&lt;p&gt;lindong28 opened a new pull request #4722: MINOR &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3978&quot; title=&quot;Cannot truncate to a negative offset (-1) exception at broker startup&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3978&quot;&gt;&lt;del&gt;KAFKA-3978&lt;/del&gt;&lt;/a&gt; followup&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4722&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4722&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   We should use logStartOffset as HW offset if the current HW offset is out of range.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16404097" author="githubbot" created="Sun, 18 Mar 2018 18:21:46 +0000"  >&lt;p&gt;hachikuji closed pull request #4722: MINOR &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3978&quot; title=&quot;Cannot truncate to a negative offset (-1) exception at broker startup&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3978&quot;&gt;&lt;del&gt;KAFKA-3978&lt;/del&gt;&lt;/a&gt; followup&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4722&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4722&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/core/src/main/scala/kafka/cluster/Replica.scala b/core/src/main/scala/kafka/cluster/Replica.scala&lt;br/&gt;
index 030e5b7eb58..4b65e439e2c 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/cluster/Replica.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/cluster/Replica.scala&lt;br/&gt;
@@ -175,8 +175,10 @@ class Replica(val brokerId: Int,&lt;br/&gt;
   def convertHWToLocalOffsetMetadata() {&lt;br/&gt;
     if (isLocal) {&lt;br/&gt;
       highWatermarkMetadata = log.get.convertToOffsetMetadata(highWatermarkMetadata.messageOffset).getOrElse {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val firstOffset = log.get.logSegments.head.baseOffset&lt;/li&gt;
	&lt;li&gt;new LogOffsetMetadata(firstOffset, firstOffset, 0)&lt;br/&gt;
+        log.get.convertToOffsetMetadata(logStartOffset).getOrElse 
{
+          val firstSegmentOffset = log.get.logSegments.head.baseOffset
+          new LogOffsetMetadata(firstSegmentOffset, firstSegmentOffset, 0)
+        }
&lt;p&gt;       }&lt;br/&gt;
     } else {&lt;br/&gt;
       throw new KafkaException(s&quot;Should not construct complete high watermark on partition $topicPartition&apos;s non-local replica $brokerId&quot;)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12772734">KAFKA-1923</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13142605">KAFKA-6610</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 35 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i319bz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>