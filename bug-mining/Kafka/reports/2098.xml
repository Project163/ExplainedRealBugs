<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:16:06 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-7576] Dynamic update of replica fetcher threads may fail to start/close fetchers</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-7576</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6051&quot; title=&quot;ReplicaFetcherThread should close the ReplicaFetcherBlockingSend earlier on shutdown&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6051&quot;&gt;&lt;del&gt;KAFKA-6051&lt;/del&gt;&lt;/a&gt; moved  ReplicaFetcherBlockingSend shutdown earlier in the shutdown sequence of ReplicaFetcherThread. As a result, shutdown of replica fetchers can now throw an exception because Selector may be closed on a different thread while data is being written on another thread. &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7464&quot; title=&quot;Fail to shutdown ReplicaManager during broker cleaned shutdown&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7464&quot;&gt;&lt;del&gt;KAFKA-7464&lt;/del&gt;&lt;/a&gt; changed this behaviour for 2.0.1 and 2.1.0. The exception during close() is now logged and not propagated to avoid exceptions during broker shutdown.&lt;/p&gt;

&lt;p&gt;When config update notification of `num.replica.fetchers` is processed, partitions are migrated as necessary to increase or decrease the number of fetcher threads. Existing fetchers are shutdown first before new ones are created.This migration is performed on the thread processing ZK change notification. The shutdown of Selector of existing fetchers is not safe since replica fetcher thread may be processing data at the time using the same Selector.&lt;/p&gt;

&lt;p&gt;Without the fix from &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7464&quot; title=&quot;Fail to shutdown ReplicaManager during broker cleaned shutdown&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7464&quot;&gt;&lt;del&gt;KAFKA-7464&lt;/del&gt;&lt;/a&gt;, another update of the config or broker restart is required to restart the replica fetchers after dynamic config update if shutdown encounters an exception.&lt;/p&gt;

&lt;p&gt;Exception stack trace:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
java.lang.IllegalArgumentException
        at java.nio.Buffer.position(Buffer.java:244)
        at sun.nio.ch.IOUtil.write(IOUtil.java:68)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
        at org.apache.kafka.common.network.SslTransportLayer.flush(SslTransportLayer.java:210)
        at org.apache.kafka.common.network.SslTransportLayer.close(SslTransportLayer.java:160)
        at org.apache.kafka.common.utils.Utils.closeAll(Utils.java:718)
        at org.apache.kafka.common.network.KafkaChannel.close(KafkaChannel.java:70)
        at org.apache.kafka.common.network.Selector.doClose(Selector.java:748)
        at org.apache.kafka.common.network.Selector.close(Selector.java:736)
        at org.apache.kafka.common.network.Selector.close(Selector.java:698)
        at org.apache.kafka.common.network.Selector.close(Selector.java:314)
        at org.apache.kafka.clients.NetworkClient.close(NetworkClient.java:533)
        at kafka.server.ReplicaFetcherBlockingSend.close(ReplicaFetcherBlockingSend.scala:107)
        at kafka.server.ReplicaFetcherThread.initiateShutdown(ReplicaFetcherThread.scala:90)
        at kafka.server.AbstractFetcherThread.shutdown(AbstractFetcherThread.scala:86)
        at kafka.server.AbstractFetcherManager$$anonfun$migratePartitions$1$1.apply(AbstractFetcherManager.scala:76)
        at kafka.server.AbstractFetcherManager$$anonfun$migratePartitions$1$1.apply(AbstractFetcherManager.scala:72)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:130)
        at scala.collection.mutable.HashTable$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreachEntry(HashTable.scala:236)
        at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
        at scala.collection.mutable.HashMap.foreach(HashMap.scala:130)
        at kafka.server.AbstractFetcherManager.migratePartitions$1(AbstractFetcherManager.scala:72)
        at kafka.server.AbstractFetcherManager.resizeThreadPool(AbstractFetcherManager.scala:88)
        at kafka.server.DynamicThreadPool.reconfigure(DynamicBrokerConfig.scala:574)
        at kafka.server.DynamicBrokerConfig$$anonfun$kafka$server$DynamicBrokerConfig$$updateCurrentConfig$1.apply(DynamicBrokerConfig.scala:410)
        at kafka.server.DynamicBrokerConfig$$anonfun$kafka$server$DynamicBrokerConfig$$updateCurrentConfig$1.apply(DynamicBrokerConfig.scala:410)
        at scala.collection.immutable.List.foreach(List.scala:392)
        at kafka.server.DynamicBrokerConfig.kafka$server$DynamicBrokerConfig$$updateCurrentConfig(DynamicBrokerConfig.scala:410)
&amp;lt;SKIP&amp;gt;kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread.doWork(ZkNodeChangeNotificationListener.scala:135)
        at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The fix from &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7464&quot; title=&quot;Fail to shutdown ReplicaManager during broker cleaned shutdown&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7464&quot;&gt;&lt;del&gt;KAFKA-7464&lt;/del&gt;&lt;/a&gt; in 2.0.1 and 2.1.0 avoids the issue with creation of replica fetchers during dynamic update. But even for those branches, we should clean up the Selector to avoid resource leak in the dynamic config update case (discarding the exception may be sufficient when the broker is shutdown).&lt;/p&gt;</description>
                <environment></environment>
        <key id="13195468">KAFKA-7576</key>
            <summary>Dynamic update of replica fetcher threads may fail to start/close fetchers</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rsivaram">Rajini Sivaram</assignee>
                                    <reporter username="rsivaram">Rajini Sivaram</reporter>
                        <labels>
                    </labels>
                <created>Wed, 31 Oct 2018 19:20:29 +0000</created>
                <updated>Thu, 22 Nov 2018 09:18:19 +0000</updated>
                            <resolved>Fri, 16 Nov 2018 11:16:11 +0000</resolved>
                                    <version>1.1.1</version>
                    <version>2.0.1</version>
                    <version>2.1.0</version>
                                    <fixVersion>1.1.2</fixVersion>
                    <fixVersion>2.0.2</fixVersion>
                    <fixVersion>2.1.1</fixVersion>
                                    <component>core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="16673801" author="githubbot" created="Fri, 2 Nov 2018 23:07:54 +0000"  >&lt;p&gt;rajinisivaram opened a new pull request #5875: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7576&quot; title=&quot;Dynamic update of replica fetcher threads may fail to start/close fetchers&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7576&quot;&gt;&lt;del&gt;KAFKA-7576&lt;/del&gt;&lt;/a&gt;: Fix shutdown of replica fetcher threads&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5875&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5875&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   ReplicaFetcherThread.shutdown attempts to close the fetcher&apos;s Selector while the thread is running. This in unsafe and can result in `Selector.close()` failing with an exception. The exception is caught and logged at debug level, but this can lead to socket leak if the shutdown is due to dynamic config update rather than broker shutdown. This PR changes the shutdown logic to close Selector after the replica fetcher thread is shutdown, with a wakeup() and flag to terminate blocking sends first.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16688886" author="githubbot" created="Fri, 16 Nov 2018 01:27:32 +0000"  >&lt;p&gt;hachikuji closed pull request #5875: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7576&quot; title=&quot;Dynamic update of replica fetcher threads may fail to start/close fetchers&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7576&quot;&gt;&lt;del&gt;KAFKA-7576&lt;/del&gt;&lt;/a&gt;: Fix shutdown of replica fetcher threads&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5875&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5875&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/clients/src/main/java/org/apache/kafka/clients/KafkaClient.java b/clients/src/main/java/org/apache/kafka/clients/KafkaClient.java&lt;br/&gt;
index 448932e358b..18a7eefe202 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/KafkaClient.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/KafkaClient.java&lt;br/&gt;
@@ -197,4 +197,20 @@ ClientRequest newClientRequest(String nodeId,&lt;br/&gt;
                                    int requestTimeoutMs,&lt;br/&gt;
                                    RequestCompletionHandler callback);&lt;/p&gt;

&lt;p&gt;+&lt;br/&gt;
+&lt;br/&gt;
+    /**&lt;br/&gt;
+     * Initiates shutdown of this client. This method may be invoked from another thread while this&lt;br/&gt;
+     * client is being polled. No further requests may be sent using the client. The current poll()&lt;br/&gt;
+     * will be terminated using wakeup(). The client should be explicitly shutdown using &lt;/p&gt;
{@link #close()}&lt;br/&gt;
+     * after poll returns. Note that {@link #close()}
&lt;p&gt; should not be invoked concurrently while polling.&lt;br/&gt;
+     */&lt;br/&gt;
+    void initiateClose();&lt;br/&gt;
+&lt;br/&gt;
+    /**&lt;br/&gt;
+     * Returns true if the client is still active. Returns false if &lt;/p&gt;
{@link #initiateClose()}
&lt;p&gt; or &lt;/p&gt;
{@link #close()}
&lt;p&gt;+     * was invoked for this client.&lt;br/&gt;
+     */&lt;br/&gt;
+    boolean active();&lt;br/&gt;
+&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/clients/NetworkClient.java b/clients/src/main/java/org/apache/kafka/clients/NetworkClient.java&lt;br/&gt;
index 902ef1c3fda..144987e8494 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/NetworkClient.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/NetworkClient.java&lt;br/&gt;
@@ -20,6 +20,7 @@&lt;br/&gt;
 import org.apache.kafka.common.Node;&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition;&lt;br/&gt;
 import org.apache.kafka.common.errors.AuthenticationException;&lt;br/&gt;
+import org.apache.kafka.common.errors.DisconnectException;&lt;br/&gt;
 import org.apache.kafka.common.errors.UnsupportedVersionException;&lt;br/&gt;
 import org.apache.kafka.common.metrics.Sensor;&lt;br/&gt;
 import org.apache.kafka.common.network.ChannelState;&lt;br/&gt;
@@ -54,6 +55,7 @@&lt;br/&gt;
 import java.util.List;&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
 import java.util.Random;&lt;br/&gt;
+import java.util.concurrent.atomic.AtomicReference;&lt;br/&gt;
 import java.util.stream.Collectors;&lt;/p&gt;

&lt;p&gt; /**&lt;br/&gt;
@@ -64,6 +66,12 @@&lt;br/&gt;
  */&lt;br/&gt;
 public class NetworkClient implements KafkaClient {&lt;/p&gt;

&lt;p&gt;+    private enum State &lt;/p&gt;
{
+        ACTIVE,
+        CLOSING,
+        CLOSED
+    }
&lt;p&gt;+&lt;br/&gt;
     private final Logger log;&lt;/p&gt;

&lt;p&gt;     /* the selector used to perform network i/o */&lt;br/&gt;
@@ -114,6 +122,8 @@&lt;/p&gt;

&lt;p&gt;     private final Sensor throttleTimeSensor;&lt;/p&gt;

&lt;p&gt;+    private final AtomicReference&amp;lt;State&amp;gt; state;&lt;br/&gt;
+&lt;br/&gt;
     public NetworkClient(Selectable selector,&lt;br/&gt;
                          Metadata metadata,&lt;br/&gt;
                          String clientId,&lt;br/&gt;
@@ -254,6 +264,7 @@ private NetworkClient(MetadataUpdater metadataUpdater,&lt;br/&gt;
         this.throttleTimeSensor = throttleTimeSensor;&lt;br/&gt;
         this.log = logContext.logger(NetworkClient.class);&lt;br/&gt;
         this.clientDnsLookup = clientDnsLookup;&lt;br/&gt;
+        this.state = new AtomicReference&amp;lt;&amp;gt;(State.ACTIVE);&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;     /**&lt;br/&gt;
@@ -429,6 +440,7 @@ private void sendInternalMetadataRequest(MetadataRequest.Builder builder,&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;     private void doSend(ClientRequest clientRequest, boolean isInternalRequest, long now) {&lt;br/&gt;
+        ensureActive();&lt;br/&gt;
         String nodeId = clientRequest.destination();&lt;br/&gt;
         if (!isInternalRequest) {&lt;br/&gt;
             // If this request came from outside the NetworkClient, validate&lt;br/&gt;
@@ -507,6 +519,8 @@ private void doSend(ClientRequest clientRequest, boolean isInternalRequest, long&lt;br/&gt;
      */&lt;br/&gt;
     @Override&lt;br/&gt;
     public List&amp;lt;ClientResponse&amp;gt; poll(long timeout, long now) {&lt;br/&gt;
+        ensureActive();&lt;br/&gt;
+&lt;br/&gt;
         if (!abortedSends.isEmpty()) {&lt;br/&gt;
             // If there are aborted sends because of unsupported version exceptions or disconnects,&lt;br/&gt;
             // handle them immediately without waiting for Selector#poll.&lt;br/&gt;
@@ -586,13 +600,35 @@ public void wakeup() &lt;/p&gt;
{
         this.selector.wakeup();
     }

&lt;p&gt;+    @Override&lt;br/&gt;
+    public void initiateClose() {&lt;br/&gt;
+        if (state.compareAndSet(State.ACTIVE, State.CLOSING)) &lt;/p&gt;
{
+            wakeup();
+        }
&lt;p&gt;+    }&lt;br/&gt;
+&lt;br/&gt;
+    @Override&lt;br/&gt;
+    public boolean active() &lt;/p&gt;
{
+        return state.get() == State.ACTIVE;
+    }
&lt;p&gt;+&lt;br/&gt;
+    private void ensureActive() &lt;/p&gt;
{
+        if (!active())
+            throw new DisconnectException(&quot;NetworkClient is no longer active, state is &quot; + state);
+    }
&lt;p&gt;+&lt;br/&gt;
     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Close the network client&lt;br/&gt;
      */&lt;br/&gt;
     @Override&lt;br/&gt;
     public void close() {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;this.selector.close();&lt;/li&gt;
	&lt;li&gt;this.metadataUpdater.close();&lt;br/&gt;
+        state.compareAndSet(State.ACTIVE, State.CLOSING);&lt;br/&gt;
+        if (state.compareAndSet(State.CLOSING, State.CLOSED)) 
{
+            this.selector.close();
+            this.metadataUpdater.close();
+        }
&lt;p&gt; else &lt;/p&gt;
{
+            log.warn(&quot;Attempting to close NetworkClient that has already been closed.&quot;);
+        }
&lt;p&gt;     }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/clients/NetworkClientUtils.java b/clients/src/main/java/org/apache/kafka/clients/NetworkClientUtils.java&lt;br/&gt;
index 94fe288090e..c952b82462d 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/NetworkClientUtils.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/NetworkClientUtils.java&lt;br/&gt;
@@ -18,6 +18,7 @@&lt;br/&gt;
 package org.apache.kafka.clients;&lt;/p&gt;

&lt;p&gt; import org.apache.kafka.common.Node;&lt;br/&gt;
+import org.apache.kafka.common.errors.DisconnectException;&lt;br/&gt;
 import org.apache.kafka.common.utils.Time;&lt;/p&gt;

&lt;p&gt; import java.io.IOException;&lt;br/&gt;
@@ -83,25 +84,35 @@ public static boolean awaitReady(KafkaClient client, Node node, Time time, long&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;disconnection happens (which can happen for a number of reasons including a request timeout).&lt;br/&gt;
      *&lt;/li&gt;
	&lt;li&gt;In case of a disconnection, an `IOException` is thrown.&lt;br/&gt;
+     * If shutdown is initiated on the client during this method, an IOException is thrown.&lt;br/&gt;
      *&lt;/li&gt;
	&lt;li&gt;This method is useful for implementing blocking behaviour on top of the non-blocking `NetworkClient`, use it with&lt;/li&gt;
	&lt;li&gt;care.&lt;br/&gt;
      */&lt;br/&gt;
     public static ClientResponse sendAndReceive(KafkaClient client, ClientRequest request, Time time) throws IOException {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;client.send(request, time.milliseconds());&lt;/li&gt;
	&lt;li&gt;while (true) {&lt;/li&gt;
	&lt;li&gt;List&amp;lt;ClientResponse&amp;gt; responses = client.poll(Long.MAX_VALUE, time.milliseconds());&lt;/li&gt;
	&lt;li&gt;for (ClientResponse response : responses) {&lt;/li&gt;
	&lt;li&gt;if (response.requestHeader().correlationId() == request.correlationId()) {&lt;/li&gt;
	&lt;li&gt;if (response.wasDisconnected()) {&lt;/li&gt;
	&lt;li&gt;throw new IOException(&quot;Connection to &quot; + response.destination() + &quot; was disconnected before the response was read&quot;);&lt;br/&gt;
+        try {&lt;br/&gt;
+            client.send(request, time.milliseconds());&lt;br/&gt;
+            while (client.active()) {&lt;br/&gt;
+                List&amp;lt;ClientResponse&amp;gt; responses = client.poll(Long.MAX_VALUE, time.milliseconds());&lt;br/&gt;
+                for (ClientResponse response : responses) {&lt;br/&gt;
+                    if (response.requestHeader().correlationId() == request.correlationId()) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+                        if (response.wasDisconnected()) {
+                            throw new IOException(&quot;Connection to &quot; + response.destination() + &quot; was disconnected before the response was read&quot;);
+                        }+                        if (response.versionMismatch() != null) {
+                            throw response.versionMismatch();
+                        }+                        return response;                     }&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
	&lt;li&gt;if (response.versionMismatch() != null) 
{
-                        throw response.versionMismatch();
-                    }&lt;/li&gt;
	&lt;li&gt;return response;&lt;br/&gt;
                 }&lt;br/&gt;
             }&lt;br/&gt;
+            throw new IOException(&quot;Client was shutdown before response was read&quot;);&lt;br/&gt;
+        } catch (DisconnectException e) 
{
+            if (client.active())
+                throw e;
+            else
+                throw new IOException(&quot;Client was shutdown before response was read&quot;);
+
         }
&lt;p&gt;     }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/clients/src/test/java/org/apache/kafka/clients/MockClient.java b/clients/src/test/java/org/apache/kafka/clients/MockClient.java&lt;br/&gt;
index 0cfb3be59af..0dd09d2b4d8 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/clients/src/test/java/org/apache/kafka/clients/MockClient.java&lt;br/&gt;
+++ b/clients/src/test/java/org/apache/kafka/clients/MockClient.java&lt;br/&gt;
@@ -93,6 +93,7 @@ public FutureResponse(Node node,&lt;br/&gt;
     private final Queue&amp;lt;MetadataUpdate&amp;gt; metadataUpdates = new ConcurrentLinkedDeque&amp;lt;&amp;gt;();&lt;br/&gt;
     private volatile NodeApiVersions nodeApiVersions = NodeApiVersions.create();&lt;br/&gt;
     private volatile int numBlockingWakeups = 0;&lt;br/&gt;
+    private volatile boolean active = true;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     public MockClient(Time time, Metadata metadata) &lt;/p&gt;
{
         this(time, new DefaultMockMetadataUpdater(metadata));
@@ -516,8 +517,19 @@ public ClientRequest newClientRequest(String nodeId,
                 expectResponse, requestTimeoutMs, callback);
     }

&lt;p&gt;+    @Override&lt;br/&gt;
+    public void initiateClose() &lt;/p&gt;
{
+        close();
+    }
&lt;p&gt;+&lt;br/&gt;
+    @Override&lt;br/&gt;
+    public boolean active() &lt;/p&gt;
{
+        return active;
+    }
&lt;p&gt;+&lt;br/&gt;
     @Override&lt;br/&gt;
     public void close() &lt;/p&gt;
{
+        active = false;
         metadataUpdater.close();
     }

&lt;p&gt;diff --git a/core/src/main/scala/kafka/controller/ControllerChannelManager.scala b/core/src/main/scala/kafka/controller/ControllerChannelManager.scala&lt;br/&gt;
index a11f5535bda..aec929862c4 100755&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/controller/ControllerChannelManager.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/controller/ControllerChannelManager.scala&lt;br/&gt;
@@ -292,6 +292,13 @@ class RequestSendThread(val controllerId: Int,&lt;br/&gt;
     }&lt;br/&gt;
   }&lt;/p&gt;

&lt;p&gt;+  override def initiateShutdown(): Boolean = {&lt;br/&gt;
+    if (super.initiateShutdown()) &lt;/p&gt;
{
+      networkClient.initiateClose()
+      true
+    }
&lt;p&gt; else&lt;br/&gt;
+      false&lt;br/&gt;
+  }&lt;br/&gt;
 }&lt;/p&gt;

&lt;p&gt; class ControllerBrokerRequestBatch(controller: KafkaController, stateChangeLogger: StateChangeLogger) extends  Logging {&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/server/ReplicaFetcherBlockingSend.scala b/core/src/main/scala/kafka/server/ReplicaFetcherBlockingSend.scala&lt;br/&gt;
index 01a9b9f7b14..924111c4a86 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/server/ReplicaFetcherBlockingSend.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/server/ReplicaFetcherBlockingSend.scala&lt;br/&gt;
@@ -35,6 +35,8 @@ trait BlockingSend &lt;/p&gt;
{
 
   def sendRequest(requestBuilder: AbstractRequest.Builder[_ &amp;lt;: AbstractRequest]): ClientResponse
 
+  def initiateClose()
+
   def close()
 }

&lt;p&gt;@@ -105,6 +107,10 @@ class ReplicaFetcherBlockingSend(sourceBroker: BrokerEndPoint,&lt;br/&gt;
     }&lt;br/&gt;
   }&lt;/p&gt;

&lt;p&gt;+  override def initiateClose(): Unit = &lt;/p&gt;
{
+    networkClient.initiateClose()
+  }
&lt;p&gt;+&lt;br/&gt;
   def close(): Unit = &lt;/p&gt;
{
     networkClient.close()
   }
&lt;p&gt;diff --git a/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala b/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala&lt;br/&gt;
index 71a4b9559d1..4452d89b494 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala&lt;br/&gt;
@@ -115,23 +115,32 @@ class ReplicaFetcherThread(name: String,&lt;br/&gt;
   override def initiateShutdown(): Boolean = {&lt;br/&gt;
     val justShutdown = super.initiateShutdown()&lt;br/&gt;
     if (justShutdown) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// leaderEndpoint.close() can throw an exception when the replica fetcher thread is still&lt;/li&gt;
	&lt;li&gt;// actively fetching because the selector can close the channel while sending the request&lt;/li&gt;
	&lt;li&gt;// after we initiate leaderEndpoint.close() and the leaderEndpoint.close() itself may also close&lt;/li&gt;
	&lt;li&gt;// the channel again. When this race condition happens, an exception will be thrown.&lt;/li&gt;
	&lt;li&gt;// Throwing the exception to the caller may fail the ReplicaManager shutdown. It is safe to catch&lt;/li&gt;
	&lt;li&gt;// the exception without here causing correctness issue because we are going to shutdown the thread&lt;/li&gt;
	&lt;li&gt;// and will not re-use the leaderEndpoint anyway.&lt;br/&gt;
+      // This is thread-safe, so we don&apos;t expect any exceptions, but catch and log any errors&lt;br/&gt;
+      // to avoid failing the caller, especially during shutdown. We will attempt to close&lt;br/&gt;
+      // leaderEndpoint after the thread terminates.&lt;br/&gt;
       try 
{
-        leaderEndpoint.close()
+        leaderEndpoint.initiateClose()
       }
&lt;p&gt; catch &lt;/p&gt;
{
         case t: Throwable =&amp;gt;
-          debug(s&quot;Fail to close leader endpoint $leaderEndpoint after initiating replica fetcher thread shutdown&quot;, t)
+          error(s&quot;Failed to initiate shutdown of leader endpoint $leaderEndpoint after initiating replica fetcher thread shutdown&quot;, t)
       }
&lt;p&gt;     }&lt;br/&gt;
     justShutdown&lt;br/&gt;
   }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+  override def awaitShutdown(): Unit = {&lt;br/&gt;
+    super.awaitShutdown()&lt;br/&gt;
+    // We don&apos;t expect any exceptions here, but catch and log any errors to avoid failing the caller,&lt;br/&gt;
+    // especially during shutdown. It is safe to catch the exception here without causing correctness&lt;br/&gt;
+    // issue because we are going to shutdown the thread and will not re-use the leaderEndpoint anyway.&lt;br/&gt;
+    try &lt;/p&gt;
{
+      leaderEndpoint.close()
+    }
&lt;p&gt; catch &lt;/p&gt;
{
+      case t: Throwable =&amp;gt;
+        error(s&quot;Failed to close leader endpoint $leaderEndpoint after shutting down replica fetcher thread&quot;, t)
+    }
&lt;p&gt;+  }&lt;br/&gt;
+&lt;br/&gt;
   // process fetched data&lt;br/&gt;
   override def processPartitionData(topicPartition: TopicPartition,&lt;br/&gt;
                                     fetchOffset: Long,&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/server/ReplicaFetcherThreadTest.scala b/core/src/test/scala/unit/kafka/server/ReplicaFetcherThreadTest.scala&lt;br/&gt;
index 93a7a1e6aaa..c65c2542b2b 100644&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/server/ReplicaFetcherThreadTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/server/ReplicaFetcherThreadTest.scala&lt;br/&gt;
@@ -24,7 +24,7 @@ import kafka.cluster.Partition&lt;br/&gt;
 import kafka.server.QuotaFactory.UnboundedQuota&lt;br/&gt;
 import kafka.server.epoch.LeaderEpochFileCache&lt;br/&gt;
 import kafka.server.epoch.util.ReplicaFetcherMockBlockingSend&lt;br/&gt;
-import kafka.utils.&lt;/p&gt;
{LogCaptureAppender, TestUtils}
&lt;p&gt;+import kafka.utils.TestUtils&lt;br/&gt;
 import org.apache.kafka.clients.ClientResponse&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition&lt;br/&gt;
 import org.apache.kafka.common.metrics.Metrics&lt;br/&gt;
@@ -33,7 +33,6 @@ import org.apache.kafka.common.protocol.Errors._&lt;br/&gt;
 import org.apache.kafka.common.requests.&lt;/p&gt;
{EpochEndOffset, OffsetsForLeaderEpochRequest}
&lt;p&gt; import org.apache.kafka.common.requests.EpochEndOffset._&lt;br/&gt;
 import org.apache.kafka.common.utils.SystemTime&lt;br/&gt;
-import org.apache.log4j.Level&lt;br/&gt;
 import org.easymock.EasyMock._&lt;br/&gt;
 import org.easymock.&lt;/p&gt;
{Capture, CaptureType, IAnswer}
&lt;p&gt; import org.junit.Assert._&lt;br/&gt;
@@ -799,7 +798,8 @@ class ReplicaFetcherThreadTest {&lt;br/&gt;
     val config = KafkaConfig.fromProps(props)&lt;br/&gt;
     val mockBlockingSend: BlockingSend = createMock(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;BlockingSend&amp;#93;&lt;/span&gt;)&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;expect(mockBlockingSend.close()).andThrow(new IllegalArgumentException()).once()&lt;br/&gt;
+    expect(mockBlockingSend.initiateClose()).andThrow(new IllegalArgumentException()).once()&lt;br/&gt;
+    expect(mockBlockingSend.close()).andThrow(new IllegalStateException()).once()&lt;br/&gt;
     replay(mockBlockingSend)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val thread = new ReplicaFetcherThread(&lt;br/&gt;
@@ -812,24 +812,15 @@ class ReplicaFetcherThreadTest {&lt;br/&gt;
       time = new SystemTime(),&lt;br/&gt;
       quota = null,&lt;br/&gt;
       leaderEndpointBlockingSend = Some(mockBlockingSend))&lt;br/&gt;
-&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val previousLevel = LogCaptureAppender.setClassLoggerLevel(thread.getClass, Level.DEBUG)&lt;/li&gt;
	&lt;li&gt;val logCaptureAppender = LogCaptureAppender.createAndRegister()&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;try 
{
-      thread.initiateShutdown()
-
-      val event = logCaptureAppender.getMessages.find(e =&amp;gt; e.getLevel == Level.DEBUG
-        &amp;amp;&amp;amp; e.getRenderedMessage.contains(s&quot;Fail to close leader endpoint $mockBlockingSend after initiating replica fetcher thread shutdown&quot;)
-        &amp;amp;&amp;amp; e.getThrowableInformation != null
-        &amp;amp;&amp;amp; e.getThrowableInformation.getThrowable.getClass.getName.equals(new IllegalArgumentException().getClass.getName))
-      assertTrue(event.isDefined)
-
-      verify(mockBlockingSend)
-    }
&lt;p&gt; finally &lt;/p&gt;
{
-      LogCaptureAppender.unregister(logCaptureAppender)
-      LogCaptureAppender.setClassLoggerLevel(thread.getClass, previousLevel)
-    }
&lt;p&gt;+    thread.start()&lt;br/&gt;
+&lt;br/&gt;
+    // Verify that:&lt;br/&gt;
+    //   1) IllegalArgumentException thrown by BlockingSend#initiateClose() during `initiateShutdown` is not propagated&lt;br/&gt;
+    //   2) BlockingSend.close() is invoked even if BlockingSend#initiateClose() fails&lt;br/&gt;
+    //   3) IllegalStateException thrown by BlockingSend.close() during `awaitShutdown` is not propagated&lt;br/&gt;
+    thread.initiateShutdown()&lt;br/&gt;
+    thread.awaitShutdown()&lt;br/&gt;
+    verify(mockBlockingSend)&lt;br/&gt;
   }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def stub(replica: Replica, partition: Partition, replicaManager: ReplicaManager) = {&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/server/ServerShutdownTest.scala b/core/src/test/scala/unit/kafka/server/ServerShutdownTest.scala&lt;br/&gt;
index ff097496e02..416e46c011e 100755&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/server/ServerShutdownTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/server/ServerShutdownTest.scala&lt;br/&gt;
@@ -19,15 +19,24 @@ package kafka.server&lt;br/&gt;
 import kafka.zk.ZooKeeperTestHarness&lt;br/&gt;
 import kafka.utils.&lt;/p&gt;
{CoreUtils, TestUtils}
&lt;p&gt; import kafka.utils.TestUtils._&lt;br/&gt;
-import java.io.File&lt;br/&gt;
+import java.io.&lt;/p&gt;
{DataInputStream, File}
&lt;p&gt;+import java.net.ServerSocket&lt;br/&gt;
+import java.util.concurrent.&lt;/p&gt;
{Executors, TimeUnit}

&lt;p&gt;+import kafka.cluster.Broker&lt;br/&gt;
+import kafka.controller.&lt;/p&gt;
{ControllerChannelManager, ControllerContext, StateChangeLogger}
&lt;p&gt; import kafka.log.LogManager&lt;br/&gt;
 import kafka.zookeeper.ZooKeeperClientTimeoutException&lt;br/&gt;
 import org.apache.kafka.clients.consumer.KafkaConsumer&lt;br/&gt;
 import org.apache.kafka.clients.producer.&lt;/p&gt;
{KafkaProducer, ProducerRecord}
&lt;p&gt; import org.apache.kafka.common.errors.KafkaStorageException&lt;br/&gt;
+import org.apache.kafka.common.metrics.Metrics&lt;br/&gt;
+import org.apache.kafka.common.network.ListenerName&lt;br/&gt;
+import org.apache.kafka.common.protocol.ApiKeys&lt;br/&gt;
+import org.apache.kafka.common.requests.LeaderAndIsrRequest&lt;br/&gt;
 import org.apache.kafka.common.security.auth.SecurityProtocol&lt;br/&gt;
 import org.apache.kafka.common.serialization.&lt;/p&gt;
{IntegerDeserializer, IntegerSerializer, StringDeserializer, StringSerializer}
&lt;p&gt;+import org.apache.kafka.common.utils.Time&lt;br/&gt;
 import org.junit.&lt;/p&gt;
{Before, Test}
&lt;p&gt; import org.junit.Assert._&lt;/p&gt;

&lt;p&gt;@@ -189,4 +198,58 @@ class ServerShutdownTest extends ZooKeeperTestHarness &lt;/p&gt;
{
     server.awaitShutdown()
     server.shutdown()
   }
&lt;p&gt;+&lt;br/&gt;
+  // Verify that if controller is in the midst of processing a request, shutdown completes&lt;br/&gt;
+  // without waiting for request timeout.&lt;br/&gt;
+  @Test&lt;br/&gt;
+  def testControllerShutdownDuringSend(): Unit = {&lt;br/&gt;
+    val securityProtocol = SecurityProtocol.PLAINTEXT&lt;br/&gt;
+    val listenerName = ListenerName.forSecurityProtocol(securityProtocol)&lt;br/&gt;
+&lt;br/&gt;
+    val controllerId = 2&lt;br/&gt;
+    val metrics = new Metrics&lt;br/&gt;
+    val executor = Executors.newSingleThreadExecutor&lt;br/&gt;
+    var serverSocket: ServerSocket = null&lt;br/&gt;
+    var controllerChannelManager: ControllerChannelManager = null&lt;br/&gt;
+&lt;br/&gt;
+    try {&lt;br/&gt;
+      // Set up a server to accept a connection and receive one byte from the first request. No response is sent.&lt;br/&gt;
+      serverSocket = new ServerSocket(0)&lt;br/&gt;
+      val receiveFuture = executor.submit(new Runnable {&lt;br/&gt;
+        override def run(): Unit = &lt;/p&gt;
{
+          val socket = serverSocket.accept()
+          new DataInputStream(socket.getInputStream).readByte()
+        }
&lt;p&gt;+      })&lt;br/&gt;
+&lt;br/&gt;
+      // Start a ControllerChannelManager&lt;br/&gt;
+      val brokers = Seq(new Broker(1, &quot;localhost&quot;, serverSocket.getLocalPort, listenerName, securityProtocol))&lt;br/&gt;
+      val controllerConfig = KafkaConfig.fromProps(TestUtils.createBrokerConfig(controllerId, zkConnect))&lt;br/&gt;
+      val controllerContext = new ControllerContext&lt;br/&gt;
+      controllerContext.liveBrokers = brokers.toSet&lt;br/&gt;
+      controllerChannelManager = new ControllerChannelManager(controllerContext, controllerConfig, Time.SYSTEM,&lt;br/&gt;
+        metrics, new StateChangeLogger(controllerId, inControllerContext = true, None))&lt;br/&gt;
+      controllerChannelManager.startup()&lt;br/&gt;
+&lt;br/&gt;
+      // Initiate a sendRequest and wait until connection is established and one byte is received by the peer&lt;br/&gt;
+      val requestBuilder = new LeaderAndIsrRequest.Builder(ApiKeys.LEADER_AND_ISR.latestVersion,&lt;br/&gt;
+        controllerId, 1, Map.empty.asJava, brokers.map(_.node(listenerName)).toSet.asJava)&lt;br/&gt;
+      controllerChannelManager.sendRequest(1, ApiKeys.LEADER_AND_ISR, requestBuilder)&lt;br/&gt;
+      receiveFuture.get(10, TimeUnit.SECONDS)&lt;br/&gt;
+&lt;br/&gt;
+      // Shutdown controller. Request timeout is 30s, verify that shutdown completed well before that&lt;br/&gt;
+      val shutdownFuture = executor.submit(new Runnable &lt;/p&gt;
{
+        override def run(): Unit = controllerChannelManager.shutdown()
+      }
&lt;p&gt;)&lt;br/&gt;
+      shutdownFuture.get(10, TimeUnit.SECONDS)&lt;br/&gt;
+&lt;br/&gt;
+    } finally &lt;/p&gt;
{
+      if (serverSocket != null)
+        serverSocket.close()
+      if (controllerChannelManager != null)
+        controllerChannelManager.shutdown()
+      executor.shutdownNow()
+      metrics.close()
+    }
&lt;p&gt;+  }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/server/epoch/util/ReplicaFetcherMockBlockingSend.scala b/core/src/test/scala/unit/kafka/server/epoch/util/ReplicaFetcherMockBlockingSend.scala&lt;br/&gt;
index 8c7e0dc390e..f87e9a5e6c8 100644&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/server/epoch/util/ReplicaFetcherMockBlockingSend.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/server/epoch/util/ReplicaFetcherMockBlockingSend.scala&lt;br/&gt;
@@ -94,5 +94,7 @@ class ReplicaFetcherMockBlockingSend(offsets: java.util.Map[TopicPartition, Epoc&lt;br/&gt;
       true)&lt;br/&gt;
   }&lt;/p&gt;

&lt;p&gt;+  override def initiateClose(): Unit = {}&lt;br/&gt;
+&lt;br/&gt;
   override def close(): Unit = {}&lt;br/&gt;
 }&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13196987">KAFKA-7607</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3zv07:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>hachikuji</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>