<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:08:24 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6530] Use actual first offset of messages when rolling log segment for magic v2</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6530</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;We&apos;ve implemented a heuristic to avoid overflowing when rolling a log segment to determine the base offset of the next segment without decompressing the message set to find the actual first offset. With the&#160;v2 message format, we can find the first offset without needing decompression, so we can set the correct base offset exactly.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13136020">KAFKA-6530</key>
            <summary>Use actual first offset of messages when rolling log segment for magic v2</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dhruvilshah">Dhruvil Shah</assignee>
                                    <reporter username="hachikuji">Jason Gustafson</reporter>
                        <labels>
                    </labels>
                <created>Sat, 3 Feb 2018 07:25:35 +0000</created>
                <updated>Wed, 25 Apr 2018 09:42:02 +0000</updated>
                            <resolved>Sat, 17 Mar 2018 17:30:17 +0000</resolved>
                                                    <fixVersion>2.0.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16390468" author="githubbot" created="Wed, 7 Mar 2018 23:55:38 +0000"  >&lt;p&gt;dhruvilshah3 opened a new pull request #4660: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6530&quot; title=&quot;Use actual first offset of messages when rolling log segment for magic v2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6530&quot;&gt;&lt;del&gt;KAFKA-6530&lt;/del&gt;&lt;/a&gt;: Use actual first offset of message set when rolling log segment&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4660&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4660&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   *More detailed description of your change,&lt;br/&gt;
   if necessary. The PR title and PR message become&lt;br/&gt;
   the squashed commit message, so use a separate&lt;br/&gt;
   comment to ping reviewers.*&lt;br/&gt;
   Use the exact first offset of message set when rolling log segment. This is possible to do for message format V2 and beyond without any performance penalty, because we have the first offset stored in the header. This augments the fix made in &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-4451&quot; title=&quot;Recovering empty replica yields negative offsets in index of compact partitions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-4451&quot;&gt;&lt;del&gt;KAFKA-4451&lt;/del&gt;&lt;/a&gt; to avoid using the heuristic for V2 and beyond messages.&lt;/p&gt;

&lt;p&gt;   *Summary of testing strategy (including rationale)&lt;br/&gt;
   for the feature or bug fix. Unit and/or integration&lt;br/&gt;
   tests are expected for any behaviour change and&lt;br/&gt;
   system tests should be considered for larger changes.*&lt;br/&gt;
   Added unit tests to simulate cases where segment needs to roll because of overflow in index offsets. Verified that the new segment created in these cases uses the first offset, instead of the heuristic in use previously.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16403558" author="githubbot" created="Sat, 17 Mar 2018 17:29:45 +0000"  >&lt;p&gt;hachikuji closed pull request #4660: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6530&quot; title=&quot;Use actual first offset of messages when rolling log segment for magic v2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6530&quot;&gt;&lt;del&gt;KAFKA-6530&lt;/del&gt;&lt;/a&gt;: Use actual first offset of message set when rolling log segment&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4660&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4660&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/clients/src/main/java/org/apache/kafka/common/record/MemoryRecords.java b/clients/src/main/java/org/apache/kafka/common/record/MemoryRecords.java&lt;br/&gt;
index 932d4b69c22..da6b68c0bc6 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/common/record/MemoryRecords.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/common/record/MemoryRecords.java&lt;br/&gt;
@@ -510,6 +510,10 @@ public static MemoryRecords withRecords(long initialOffset, CompressionType comp&lt;br/&gt;
                 records);&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;+    public static MemoryRecords withRecords(byte magic, long initialOffset, CompressionType compressionType, SimpleRecord... records) &lt;/p&gt;
{
+        return withRecords(magic, initialOffset, compressionType, TimestampType.CREATE_TIME, records);
+    }
&lt;p&gt;+&lt;br/&gt;
     public static MemoryRecords withRecords(long initialOffset, CompressionType compressionType, Integer partitionLeaderEpoch, SimpleRecord... records) {&lt;br/&gt;
         return withRecords(RecordBatch.CURRENT_MAGIC_VALUE, initialOffset, compressionType, TimestampType.CREATE_TIME, RecordBatch.NO_PRODUCER_ID,&lt;br/&gt;
                 RecordBatch.NO_PRODUCER_EPOCH, RecordBatch.NO_SEQUENCE, partitionLeaderEpoch, false, records);&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/log/Log.scala b/core/src/main/scala/kafka/log/Log.scala&lt;br/&gt;
index f0050f54aef..cc693375079 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/log/Log.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/log/Log.scala&lt;br/&gt;
@@ -47,11 +47,11 @@ import java.lang.&lt;/p&gt;
{Long =&amp;gt; JLong}
&lt;p&gt; import java.util.regex.Pattern&lt;/p&gt;

&lt;p&gt; object LogAppendInfo &lt;/p&gt;
{
-  val UnknownLogAppendInfo = LogAppendInfo(-1, -1, RecordBatch.NO_TIMESTAMP, -1L, RecordBatch.NO_TIMESTAMP, -1L,
+  val UnknownLogAppendInfo = LogAppendInfo(None, -1, RecordBatch.NO_TIMESTAMP, -1L, RecordBatch.NO_TIMESTAMP, -1L,
     RecordsProcessingStats.EMPTY, NoCompressionCodec, NoCompressionCodec, -1, -1, offsetsMonotonic = false)
 
   def unknownLogAppendInfoWithLogStartOffset(logStartOffset: Long): LogAppendInfo =
-    LogAppendInfo(-1, -1, RecordBatch.NO_TIMESTAMP, -1L, RecordBatch.NO_TIMESTAMP, logStartOffset,
+    LogAppendInfo(None, -1, RecordBatch.NO_TIMESTAMP, -1L, RecordBatch.NO_TIMESTAMP, logStartOffset,
       RecordsProcessingStats.EMPTY, NoCompressionCodec, NoCompressionCodec, -1, -1, offsetsMonotonic = false)
 }

&lt;p&gt;@@ -59,7 +59,7 @@ object LogAppendInfo {&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Struct to hold various quantities we compute about each message set before appending to the log&lt;br/&gt;
  *&lt;/li&gt;
	&lt;li&gt;@param firstOffset The first offset in the message set unless the message format is less than V2 and we are appending&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;*                    to the follower. In that case, this will be the last offset for performance reasons.&lt;br/&gt;
+ *                    to the follower.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param lastOffset The last offset in the message set&lt;/li&gt;
	&lt;li&gt;@param maxTimestamp The maximum timestamp of the message set.&lt;/li&gt;
	&lt;li&gt;@param offsetOfMaxTimestamp The offset of the message with the maximum timestamp.&lt;br/&gt;
@@ -72,7 +72,7 @@ object LogAppendInfo {&lt;/li&gt;
	&lt;li&gt;@param validBytes The number of valid bytes&lt;/li&gt;
	&lt;li&gt;@param offsetsMonotonic Are the offsets in this message set monotonically increasing&lt;br/&gt;
  */&lt;br/&gt;
-case class LogAppendInfo(var firstOffset: Long,&lt;br/&gt;
+case class LogAppendInfo(var firstOffset: Option&lt;span class=&quot;error&quot;&gt;&amp;#91;Long&amp;#93;&lt;/span&gt;,&lt;br/&gt;
                          var lastOffset: Long,&lt;br/&gt;
                          var maxTimestamp: Long,&lt;br/&gt;
                          var offsetOfMaxTimestamp: Long,&lt;br/&gt;
@@ -83,7 +83,24 @@ case class LogAppendInfo(var firstOffset: Long,&lt;br/&gt;
                          targetCodec: CompressionCodec,&lt;br/&gt;
                          shallowCount: Int,&lt;br/&gt;
                          validBytes: Int,&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;offsetsMonotonic: Boolean)&lt;br/&gt;
+                         offsetsMonotonic: Boolean) {&lt;br/&gt;
+  /**&lt;br/&gt;
+    * Get the first offset if it exists, else get the last offset.&lt;br/&gt;
+    * @return The offset of first message if it exists; else offset of the last message.&lt;br/&gt;
+    */&lt;br/&gt;
+  def firstOrLastOffset: Long = firstOffset.getOrElse(lastOffset)&lt;br/&gt;
+&lt;br/&gt;
+  /**&lt;br/&gt;
+    * Get the (maximum) number of messages described by LogAppendInfo&lt;br/&gt;
+    * @return Maximum possible number of messages described by LogAppendInfo&lt;br/&gt;
+    */&lt;br/&gt;
+  def numMessages: Long = 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+    firstOffset match {
+      case Some(firstOffsetVal) if (firstOffsetVal &amp;gt;= 0 &amp;amp;&amp;amp; lastOffset &amp;gt;= 0) =&amp;gt; (lastOffset - firstOffsetVal + 1)
+      case _ =&amp;gt; 0
+    }+  }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;+}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;A class used to hold useful metadata about a completed transaction. This is used to build&lt;br/&gt;
@@ -653,7 +670,7 @@ class Log(@volatile var dir: File,&lt;br/&gt;
         if (assignOffsets) {&lt;br/&gt;
           // assign offsets to the message set&lt;br/&gt;
           val offset = new LongRef(nextOffsetMetadata.messageOffset)&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;appendInfo.firstOffset = offset.value&lt;br/&gt;
+          appendInfo.firstOffset = Some(offset.value)&lt;br/&gt;
           val now = time.milliseconds&lt;br/&gt;
           val validateAndOffsetAssignResult = try 
{
             LogValidator.validateMessagesAndAssignOffsets(validRecords,
@@ -695,7 +712,7 @@ class Log(@volatile var dir: File,
           }
&lt;p&gt;         } else &lt;/p&gt;
{
           // we are taking the offsets we are given
-          if (!appendInfo.offsetsMonotonic || appendInfo.firstOffset &amp;lt; nextOffsetMetadata.messageOffset)
+          if (!appendInfo.offsetsMonotonic || appendInfo.firstOrLastOffset &amp;lt; nextOffsetMetadata.messageOffset)
             throw new IllegalArgumentException(&quot;Out of order offsets found in &quot; + records.records.asScala.map(_.offset))
         }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -715,7 +732,7 @@ class Log(@volatile var dir: File,&lt;br/&gt;
         // validate the idempotent/transactional state of the producers and collect some metadata&lt;br/&gt;
         val (updatedProducers, completedTxns, maybeDuplicate) = analyzeAndValidateProducerState(validRecords, isFromClient)&lt;br/&gt;
         maybeDuplicate.foreach &lt;/p&gt;
{ duplicate =&amp;gt;
-          appendInfo.firstOffset = duplicate.firstOffset
+          appendInfo.firstOffset = Some(duplicate.firstOffset)
           appendInfo.lastOffset = duplicate.lastOffset
           appendInfo.logAppendTime = duplicate.timestamp
           appendInfo.logStartOffset = logStartOffset
@@ -723,17 +740,14 @@ class Log(@volatile var dir: File,
         }

&lt;p&gt;         // maybe roll the log if this segment is full&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val segment = maybeRoll(messagesSize = validRecords.sizeInBytes,&lt;/li&gt;
	&lt;li&gt;maxTimestampInMessages = appendInfo.maxTimestamp,&lt;/li&gt;
	&lt;li&gt;maxOffsetInMessages = appendInfo.lastOffset)&lt;br/&gt;
+        val segment = maybeRoll(validRecords.sizeInBytes, appendInfo)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         val logOffsetMetadata = LogOffsetMetadata(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;messageOffset = appendInfo.firstOffset,&lt;br/&gt;
+          messageOffset = appendInfo.firstOrLastOffset,&lt;br/&gt;
           segmentBaseOffset = segment.baseOffset,&lt;br/&gt;
           relativePositionInSegment = segment.size)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;segment.append(firstOffset = appendInfo.firstOffset,&lt;/li&gt;
	&lt;li&gt;largestOffset = appendInfo.lastOffset,&lt;br/&gt;
+        segment.append(largestOffset = appendInfo.lastOffset,&lt;br/&gt;
           largestTimestamp = appendInfo.maxTimestamp,&lt;br/&gt;
           shallowOffsetOfMaxTimestamp = appendInfo.offsetOfMaxTimestamp,&lt;br/&gt;
           records = validRecords)&lt;br/&gt;
@@ -761,8 +775,8 @@ class Log(@volatile var dir: File,&lt;br/&gt;
         // update the first unstable offset (which is used to compute LSO)&lt;br/&gt;
         updateFirstUnstableOffset()&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;trace(&quot;Appended message set to log %s with first offset: %d, next offset: %d, and messages: %s&quot;&lt;/li&gt;
	&lt;li&gt;.format(this.name, appendInfo.firstOffset, nextOffsetMetadata.messageOffset, validRecords))&lt;br/&gt;
+        trace(s&quot;Appended message set to log ${this.name} with last offset: ${appendInfo.lastOffset}, &quot; +&lt;br/&gt;
+              s&quot;first offset: ${appendInfo.firstOffset}, next offset: ${nextOffsetMetadata.messageOffset}, and messages: $validRecords&quot;)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         if (unflushedMessages &amp;gt;= config.flushInterval)&lt;br/&gt;
           flush()&lt;br/&gt;
@@ -859,12 +873,13 @@ class Log(@volatile var dir: File,&lt;br/&gt;
   private def analyzeAndValidateRecords(records: MemoryRecords, isFromClient: Boolean): LogAppendInfo = {&lt;br/&gt;
     var shallowMessageCount = 0&lt;br/&gt;
     var validBytesCount = 0&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;var firstOffset = -1L&lt;br/&gt;
+    var firstOffset: Option&lt;span class=&quot;error&quot;&gt;&amp;#91;Long&amp;#93;&lt;/span&gt; = None&lt;br/&gt;
     var lastOffset = -1L&lt;br/&gt;
     var sourceCodec: CompressionCodec = NoCompressionCodec&lt;br/&gt;
     var monotonic = true&lt;br/&gt;
     var maxTimestamp = RecordBatch.NO_TIMESTAMP&lt;br/&gt;
     var offsetOfMaxTimestamp = -1L&lt;br/&gt;
+    var readFirstMessage = false&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     for (batch &amp;lt;- records.batches.asScala) {&lt;br/&gt;
       // we only validate V2 and higher to avoid potential compatibility issues with older clients&lt;br/&gt;
@@ -876,8 +891,12 @@ class Log(@volatile var dir: File,&lt;br/&gt;
       // For magic version 2, we can get the first offset directly from the batch header.&lt;br/&gt;
       // When appending to the leader, we will update LogAppendInfo.baseOffset with the correct value. In the follower&lt;br/&gt;
       // case, validation will be more lenient.&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (firstOffset &amp;lt; 0)&lt;/li&gt;
	&lt;li&gt;firstOffset = if (batch.magic &amp;gt;= RecordBatch.MAGIC_VALUE_V2) batch.baseOffset else batch.lastOffset&lt;br/&gt;
+      // Also indicate whether we have the accurate first offset or not&lt;br/&gt;
+      if (!readFirstMessage) 
{
+        if (batch.magic &amp;gt;= RecordBatch.MAGIC_VALUE_V2)
+          firstOffset = Some(batch.baseOffset)
+        readFirstMessage = true
+      }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;       // check that offsets are monotonically increasing&lt;br/&gt;
       if (lastOffset &amp;gt;= batch.lastOffset)&lt;br/&gt;
@@ -1268,8 +1287,8 @@ class Log(@volatile var dir: File,&lt;br/&gt;
   /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Roll the log over to a new empty log segment if necessary.&lt;br/&gt;
    *&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* @param messagesSize The messages set size in bytes&lt;/li&gt;
	&lt;li&gt;* @param maxTimestampInMessages The maximum timestamp in the messages.&lt;br/&gt;
+   * @param messagesSize The messages set size in bytes.&lt;br/&gt;
+   * @param appendInfo log append information&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;logSegment will be rolled if one of the following conditions met&lt;/li&gt;
	&lt;li&gt;&amp;lt;ol&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;li&amp;gt; The logSegment is full&lt;br/&gt;
@@ -1279,14 +1298,19 @@ class Log(@volatile var dir: File,&lt;/li&gt;
	&lt;li&gt;&amp;lt;/ol&amp;gt;&lt;/li&gt;
	&lt;li&gt;@return The currently active segment after (perhaps) rolling to a new segment&lt;br/&gt;
    */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private def maybeRoll(messagesSize: Int, maxTimestampInMessages: Long, maxOffsetInMessages: Long): LogSegment = {&lt;br/&gt;
+  private def maybeRoll(messagesSize: Int, appendInfo: LogAppendInfo): LogSegment = {&lt;br/&gt;
     val segment = activeSegment&lt;br/&gt;
     val now = time.milliseconds&lt;br/&gt;
+&lt;br/&gt;
+    val maxTimestampInMessages = appendInfo.maxTimestamp&lt;br/&gt;
+    val maxOffsetInMessages = appendInfo.lastOffset&lt;br/&gt;
+&lt;br/&gt;
     if (segment.shouldRoll(messagesSize, maxTimestampInMessages, maxOffsetInMessages, now)) {&lt;br/&gt;
       debug(s&quot;Rolling new log segment in $name (log_size = ${segment.size}/${config.segmentSize}}, &quot; +&lt;br/&gt;
           s&quot;offset_index_size = ${segment.offsetIndex.entries}/${segment.offsetIndex.maxEntries}, &quot; +&lt;br/&gt;
           s&quot;time_index_size = ${segment.timeIndex.entries}/${segment.timeIndex.maxEntries}, &quot; +&lt;br/&gt;
           s&quot;inactive_time_ms = ${segment.timeWaitedForRoll(now, maxTimestampInMessages)}/${config.segmentMs - segment.rollJitterMs}).&quot;)&lt;br/&gt;
+&lt;br/&gt;
       /*&lt;br/&gt;
         maxOffsetInMessages - Integer.MAX_VALUE is a heuristic value for the first offset in the set of messages.&lt;br/&gt;
         Since the offset in messages will not differ by more than Integer.MAX_VALUE, this is guaranteed &amp;lt;= the real&lt;br/&gt;
@@ -1296,8 +1320,13 @@ class Log(@volatile var dir: File,&lt;br/&gt;
         Integer.MAX_VALUE.toLong + 2 or more.  In this case, the prior behavior would roll a new log segment whose&lt;br/&gt;
         base offset was too low to contain the next message.  This edge case is possible when a replica is recovering a&lt;br/&gt;
         highly compacted topic from scratch.&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;roll(maxOffsetInMessages - Integer.MAX_VALUE)&lt;br/&gt;
+        Note that this is only required for pre-V2 message formats because these do not store the first message offset&lt;br/&gt;
+        in the header.&lt;br/&gt;
+      */&lt;br/&gt;
+      appendInfo.firstOffset match 
{
+        case Some(firstOffset) =&amp;gt; roll(firstOffset)
+        case None =&amp;gt; roll(maxOffsetInMessages - Integer.MAX_VALUE)
+      }
&lt;p&gt;     } else &lt;/p&gt;
{
       segment
     }
&lt;p&gt;diff --git a/core/src/main/scala/kafka/log/LogCleaner.scala b/core/src/main/scala/kafka/log/LogCleaner.scala&lt;br/&gt;
index 07e8440f26f..0ee994252a1 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/main/scala/kafka/log/LogCleaner.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/log/LogCleaner.scala&lt;br/&gt;
@@ -614,8 +614,7 @@ private&lt;span class=&quot;error&quot;&gt;&amp;#91;log&amp;#93;&lt;/span&gt; class Cleaner(val id: Int,&lt;br/&gt;
         val retained = MemoryRecords.readableRecords(outputBuffer)&lt;br/&gt;
         // it&apos;s OK not to hold the Log&apos;s lock in this case, because this segment is only accessed by other threads&lt;br/&gt;
         // after `Log.replaceSegments` (which acquires the lock) is called&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;dest.append(firstOffset = retained.batches.iterator.next().baseOffset,&lt;/li&gt;
	&lt;li&gt;largestOffset = result.maxOffset,&lt;br/&gt;
+        dest.append(largestOffset = result.maxOffset,&lt;br/&gt;
           largestTimestamp = result.maxTimestamp,&lt;br/&gt;
           shallowOffsetOfMaxTimestamp = result.shallowOffsetOfMaxTimestamp,&lt;br/&gt;
           records = retained)&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/log/LogSegment.scala b/core/src/main/scala/kafka/log/LogSegment.scala&lt;br/&gt;
index 5970f42f6d9..5130b28b597 100755
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/main/scala/kafka/log/LogSegment.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/log/LogSegment.scala&lt;br/&gt;
@@ -112,7 +112,6 @@ class LogSegment private&lt;span class=&quot;error&quot;&gt;&amp;#91;log&amp;#93;&lt;/span&gt; (val log: FileRecords,&lt;br/&gt;
    *&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;It is assumed this method is being called from within a lock.&lt;br/&gt;
    *&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* @param firstOffset The first offset in the message set.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param largestOffset The last offset in the message set&lt;/li&gt;
	&lt;li&gt;@param largestTimestamp The largest timestamp in the message set.&lt;/li&gt;
	&lt;li&gt;@param shallowOffsetOfMaxTimestamp The offset of the message that has the largest timestamp in the messages to append.&lt;br/&gt;
@@ -120,21 +119,20 @@ class LogSegment private&lt;span class=&quot;error&quot;&gt;&amp;#91;log&amp;#93;&lt;/span&gt; (val log: FileRecords,&lt;/li&gt;
	&lt;li&gt;@return the physical position in the file of the appended records&lt;br/&gt;
    */&lt;br/&gt;
   @nonthreadsafe&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def append(firstOffset: Long,&lt;/li&gt;
	&lt;li&gt;largestOffset: Long,&lt;br/&gt;
+  def append(largestOffset: Long,&lt;br/&gt;
              largestTimestamp: Long,&lt;br/&gt;
              shallowOffsetOfMaxTimestamp: Long,&lt;br/&gt;
              records: MemoryRecords): Unit = {&lt;br/&gt;
     if (records.sizeInBytes &amp;gt; 0) {&lt;/li&gt;
	&lt;li&gt;trace(&quot;Inserting %d bytes at offset %d at position %d with largest timestamp %d at shallow offset %d&quot;&lt;/li&gt;
	&lt;li&gt;.format(records.sizeInBytes, firstOffset, log.sizeInBytes(), largestTimestamp, shallowOffsetOfMaxTimestamp))&lt;br/&gt;
+      trace(s&quot;Inserting ${records.sizeInBytes} bytes at end offset $largestOffset at position ${log.sizeInBytes} &quot; +&lt;br/&gt;
+            s&quot;with largest timestamp $largestTimestamp at shallow offset $shallowOffsetOfMaxTimestamp&quot;)&lt;br/&gt;
       val physicalPosition = log.sizeInBytes()&lt;br/&gt;
       if (physicalPosition == 0)&lt;br/&gt;
         rollingBasedTimestamp = Some(largestTimestamp)&lt;br/&gt;
       // append the messages&lt;br/&gt;
       require(canConvertToRelativeOffset(largestOffset), &quot;largest offset in message set can not be safely converted to relative offset.&quot;)&lt;br/&gt;
       val appendedBytes = log.append(records)&lt;/li&gt;
	&lt;li&gt;trace(s&quot;Appended $appendedBytes to ${log.file()} at offset $firstOffset&quot;)&lt;br/&gt;
+      trace(s&quot;Appended $appendedBytes to ${log.file()} at end offset $largestOffset&quot;)&lt;br/&gt;
       // Update the in memory max timestamp and corresponding offset.&lt;br/&gt;
       if (largestTimestamp &amp;gt; maxTimestampSoFar) 
{
         maxTimestampSoFar = largestTimestamp
@@ -142,7 +140,7 @@ class LogSegment private[log] (val log: FileRecords,
       }
&lt;p&gt;       // append an entry to the index (if needed)&lt;br/&gt;
       if(bytesSinceLastIndexEntry &amp;gt; indexIntervalBytes) &lt;/p&gt;
{
-        offsetIndex.append(firstOffset, physicalPosition)
+        offsetIndex.append(largestOffset, physicalPosition)
         timeIndex.maybeAppend(maxTimestampSoFar, offsetOfMaxTimestamp)
         bytesSinceLastIndexEntry = 0
       }
&lt;p&gt;diff --git a/core/src/main/scala/kafka/server/ReplicaManager.scala b/core/src/main/scala/kafka/server/ReplicaManager.scala&lt;br/&gt;
index 470842e9d9e..d4abc11be1b 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/main/scala/kafka/server/ReplicaManager.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/server/ReplicaManager.scala&lt;br/&gt;
@@ -474,7 +474,7 @@ class ReplicaManager(val config: KafkaConfig,&lt;br/&gt;
         topicPartition -&amp;gt;&lt;br/&gt;
                 ProducePartitionStatus(&lt;br/&gt;
                   result.info.lastOffset + 1, // required offset&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;new PartitionResponse(result.error, result.info.firstOffset, result.info.logAppendTime, result.info.logStartOffset)) // response status&lt;br/&gt;
+                  new PartitionResponse(result.error, result.info.firstOffset.getOrElse(-1), result.info.logAppendTime, result.info.logStartOffset)) // response status&lt;br/&gt;
       }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;       processingStatsCallback(localProduceResults.mapValues(_.info.recordsProcessingStats))&lt;br/&gt;
@@ -502,7 +502,7 @@ class ReplicaManager(val config: KafkaConfig,&lt;br/&gt;
       // Just return an error and don&apos;t handle the request at all&lt;br/&gt;
       val responseStatus = entriesPerPartition.map &lt;/p&gt;
{ case (topicPartition, _) =&amp;gt;
         topicPartition -&amp;gt; new PartitionResponse(Errors.INVALID_REQUIRED_ACKS,
-          LogAppendInfo.UnknownLogAppendInfo.firstOffset, RecordBatch.NO_TIMESTAMP, LogAppendInfo.UnknownLogAppendInfo.logStartOffset)
+          LogAppendInfo.UnknownLogAppendInfo.firstOffset.getOrElse(-1), RecordBatch.NO_TIMESTAMP, LogAppendInfo.UnknownLogAppendInfo.logStartOffset)
       }
&lt;p&gt;       responseCallback(responseStatus)&lt;br/&gt;
     }&lt;br/&gt;
@@ -747,11 +747,7 @@ class ReplicaManager(val config: KafkaConfig,&lt;br/&gt;
               .format(topicPartition, localBrokerId))&lt;br/&gt;
           }&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val numAppendedMessages =&lt;/li&gt;
	&lt;li&gt;if (info.firstOffset == -1L || info.lastOffset == -1L)&lt;/li&gt;
	&lt;li&gt;0&lt;/li&gt;
	&lt;li&gt;else&lt;/li&gt;
	&lt;li&gt;info.lastOffset - info.firstOffset + 1&lt;br/&gt;
+          val numAppendedMessages = info.numMessages&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;           // update stats for successfully appended bytes and messages as bytesInRate and messageInRate&lt;br/&gt;
           brokerTopicStats.topicStats(topicPartition.topic).bytesInRate.mark(records.sizeInBytes)&lt;br/&gt;
diff --git a/core/src/test/scala/other/kafka/StressTestLog.scala b/core/src/test/scala/other/kafka/StressTestLog.scala&lt;br/&gt;
index 1710da7b9c3..54f8582c4c0 100755&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/other/kafka/StressTestLog.scala&lt;br/&gt;
+++ b/core/src/test/scala/other/kafka/StressTestLog.scala&lt;br/&gt;
@@ -68,47 +68,76 @@ object StressTestLog {&lt;br/&gt;
     })&lt;/p&gt;

&lt;p&gt;     while(running.get) &lt;/p&gt;
{
-      println(&quot;Reader offset = %d, writer offset = %d&quot;.format(reader.offset, writer.offset))
       Thread.sleep(1000)
+      println(&quot;Reader offset = %d, writer offset = %d&quot;.format(reader.currentOffset, writer.currentOffset))
+      writer.checkProgress()
+      reader.checkProgress()
     }
&lt;p&gt;   }&lt;/p&gt;

&lt;p&gt;   abstract class WorkerThread extends Thread {&lt;br/&gt;
+    val threadInfo = &quot;Thread: &quot; + Thread.currentThread.getName + &quot; Class: &quot; + getClass.getName&lt;br/&gt;
+&lt;br/&gt;
     override def run() {&lt;br/&gt;
       try &lt;/p&gt;
{
         while(running.get)
           work()
       }
&lt;p&gt; catch {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;case e: Exception =&amp;gt;&lt;br/&gt;
+        case e: Exception =&amp;gt; 
{
           e.printStackTrace()
-          running.set(false)
+        }
&lt;p&gt;+      } finally &lt;/p&gt;
{
+        running.set(false)
       }&lt;/li&gt;
	&lt;li&gt;println(getClass.getName + &quot; exiting...&quot;)&lt;br/&gt;
     }&lt;br/&gt;
+&lt;br/&gt;
     def work()&lt;br/&gt;
+    def isMakingProgress(): Boolean&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  trait LogProgress {&lt;br/&gt;
+    @volatile var currentOffset = 0&lt;br/&gt;
+    private var lastOffsetCheckpointed = currentOffset&lt;br/&gt;
+    private var lastProgressCheckTime = System.currentTimeMillis&lt;br/&gt;
+&lt;br/&gt;
+    def isMakingProgress(): Boolean = 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+      if (currentOffset &amp;gt; lastOffsetCheckpointed) {
+        lastOffsetCheckpointed = currentOffset
+        return true
+      }++      false+    }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;+&lt;br/&gt;
+    def checkProgress() &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+      // Check if we are making progress every 500ms+      val curTime = System.currentTimeMillis+      if ((curTime - lastProgressCheckTime) &amp;gt; 500) {
+        require(isMakingProgress(), &quot;Thread not making progress&quot;)
+        lastProgressCheckTime = curTime
+      }+    }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;   }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;class WriterThread(val log: Log) extends WorkerThread {&lt;/li&gt;
	&lt;li&gt;@volatile var offset = 0&lt;br/&gt;
+  class WriterThread(val log: Log) extends WorkerThread with LogProgress 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {     override def work() {
-      val logAppendInfo = log.appendAsFollower(TestUtils.singletonRecords(offset.toString.getBytes))
-      require(logAppendInfo.firstOffset == offset &amp;amp;&amp;amp; logAppendInfo.lastOffset == offset)
-      offset += 1
-      if(offset % 1000 == 0)
-        Thread.sleep(500)
+      val logAppendInfo = log.appendAsLeader(TestUtils.singletonRecords(currentOffset.toString.getBytes), 0)
+      require(logAppendInfo.firstOffset.forall(_ == currentOffset) &amp;amp;&amp;amp; logAppendInfo.lastOffset == currentOffset)
+      currentOffset += 1
+      if (currentOffset % 1000 == 0)
+        Thread.sleep(50)
     }   }&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;class ReaderThread(val log: Log) extends WorkerThread {&lt;/li&gt;
	&lt;li&gt;@volatile var offset = 0&lt;br/&gt;
+  class ReaderThread(val log: Log) extends WorkerThread with LogProgress {&lt;br/&gt;
     override def work() {&lt;br/&gt;
       try {&lt;/li&gt;
	&lt;li&gt;log.read(offset, 1024, Some(offset+1), isolationLevel = IsolationLevel.READ_UNCOMMITTED).records match {&lt;br/&gt;
+        log.read(currentOffset, 1024, Some(currentOffset + 1), isolationLevel = IsolationLevel.READ_UNCOMMITTED).records match 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {           case read}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;diff --git a/core/src/test/scala/unit/kafka/log/LogCleanerIntegrationTest.scala b/core/src/test/scala/unit/kafka/log/LogCleanerIntegrationTest.scala&lt;br/&gt;
index 152d6d37237..4f5ba5caef0 100755&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/test/scala/unit/kafka/log/LogCleanerIntegrationTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/log/LogCleanerIntegrationTest.scala&lt;br/&gt;
@@ -69,7 +69,7 @@ class LogCleanerIntegrationTest(compressionCodec: String) extends AbstractLogCle&lt;br/&gt;
     checkLogAfterAppendingDups(log, startSize, appends)&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val appendInfo = log.appendAsLeader(largeMessageSet, leaderEpoch = 0)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val largeMessageOffset = appendInfo.firstOffset&lt;br/&gt;
+    val largeMessageOffset = appendInfo.firstOffset.get&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val dups = writeDups(startKey = largeMessageKey + 1, numKeys = 100, numDups = 3, log = log, codec = codec)&lt;br/&gt;
     val appends2 = appends ++ Seq((largeMessageKey, largeMessageValue, largeMessageOffset)) ++ dups&lt;br/&gt;
@@ -176,7 +176,7 @@ class LogCleanerIntegrationTest(compressionCodec: String) extends AbstractLogCle&lt;br/&gt;
     val appends2: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;(Int, String, Long)&amp;#93;&lt;/span&gt; = &lt;/p&gt;
{
       val dupsV0 = writeDups(numKeys = 40, numDups = 3, log = log, codec = codec, magicValue = RecordBatch.MAGIC_VALUE_V0)
       val appendInfo = log.appendAsLeader(largeMessageSet, leaderEpoch = 0)
-      val largeMessageOffset = appendInfo.firstOffset
+      val largeMessageOffset = appendInfo.firstOffset.get
 
       // also add some messages with version 1 and version 2 to check that we handle mixed format versions correctly
       props.put(LogConfig.MessageFormatVersionProp, KAFKA_0_11_0_IV0.version)
@@ -314,7 +314,7 @@ class LogCleanerIntegrationTest(compressionCodec: String) extends AbstractLogCle
       val appendInfo = log.appendAsLeader(TestUtils.singletonRecords(value = value.toString.getBytes, codec = codec,
               key = key.toString.getBytes, magicValue = magicValue), leaderEpoch = 0)
       counter += 1
-      (key, value, appendInfo.firstOffset)
+      (key, value, appendInfo.firstOffset.get)
     }
&lt;p&gt;   }&lt;/p&gt;

&lt;p&gt;@@ -331,7 +331,7 @@ class LogCleanerIntegrationTest(compressionCodec: String) extends AbstractLogCle&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;     val appendInfo = log.appendAsLeader(MemoryRecords.withRecords(magicValue, codec, records: _*), leaderEpoch = 0)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val offsets = appendInfo.firstOffset to appendInfo.lastOffset&lt;br/&gt;
+    val offsets = appendInfo.firstOffset.get to appendInfo.lastOffset&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     kvs.zip(offsets).map &lt;/p&gt;
{ case (kv, offset) =&amp;gt; (kv._1, kv._2, offset) }
&lt;p&gt;   }&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/log/LogCleanerTest.scala b/core/src/test/scala/unit/kafka/log/LogCleanerTest.scala&lt;br/&gt;
index c12f617ddaa..906c26da4cf 100755&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/log/LogCleanerTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/log/LogCleanerTest.scala&lt;br/&gt;
@@ -147,17 +147,17 @@ class LogCleanerTest extends JUnitSuite {&lt;/p&gt;

&lt;p&gt;     // check duplicate append from producer 1&lt;br/&gt;
     var logAppendInfo = appendIdempotentAsLeader(log, pid1, producerEpoch)(Seq(1, 2, 3))&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertEquals(0L, logAppendInfo.firstOffset)&lt;br/&gt;
+    assertEquals(0L, logAppendInfo.firstOffset.get)&lt;br/&gt;
     assertEquals(2L, logAppendInfo.lastOffset)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // check duplicate append from producer 3&lt;br/&gt;
     logAppendInfo = appendIdempotentAsLeader(log, pid3, producerEpoch)(Seq(1, 4))&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertEquals(6L, logAppendInfo.firstOffset)&lt;br/&gt;
+    assertEquals(6L, logAppendInfo.firstOffset.get)&lt;br/&gt;
     assertEquals(7L, logAppendInfo.lastOffset)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // check duplicate append from producer 2&lt;br/&gt;
     logAppendInfo = appendIdempotentAsLeader(log, pid2, producerEpoch)(Seq(3, 1, 4))&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertEquals(3L, logAppendInfo.firstOffset)&lt;br/&gt;
+    assertEquals(3L, logAppendInfo.firstOffset.get)&lt;br/&gt;
     assertEquals(5L, logAppendInfo.lastOffset)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // do one more append and a round of cleaning to force another deletion from producer 1&apos;s batch&lt;br/&gt;
@@ -173,7 +173,7 @@ class LogCleanerTest extends JUnitSuite &lt;/p&gt;
{
 
     // duplicate append from producer1 should still be fine
     logAppendInfo = appendIdempotentAsLeader(log, pid1, producerEpoch)(Seq(1, 2, 3))
-    assertEquals(0L, logAppendInfo.firstOffset)
+    assertEquals(0L, logAppendInfo.firstOffset.get)
     assertEquals(2L, logAppendInfo.lastOffset)
   }

&lt;p&gt;@@ -1082,16 +1082,17 @@ class LogCleanerTest extends JUnitSuite &lt;/p&gt;
{
     val logConfig = LogConfig(logProps)
     val log = makeLog(config = logConfig)
     val cleaner = makeCleaner(Int.MaxValue)
-    val start = 0
-    val end = 2
-    val offsetSeq = Seq(0L, 7206178L)
-    writeToLog(log, (start until end) zip (start until end), offsetSeq)
-    cleaner.buildOffsetMap(log, start, end, map, new CleanerStats())
-    val endOffset = map.latestOffset
-    assertEquals(&quot;Last offset should be the end offset.&quot;, 7206178L, endOffset)
-    assertEquals(&quot;Should have the expected number of messages in the map.&quot;, end - start, map.size)
+    val keyStart = 0
+    val keyEnd = 2
+    val offsetStart = 0L
+    val offsetEnd = 7206178L
+    val offsetSeq = Seq(offsetStart, offsetEnd)
+    writeToLog(log, (keyStart until keyEnd) zip (keyStart until keyEnd), offsetSeq)
+    cleaner.buildOffsetMap(log, keyStart, offsetEnd + 1L, map, new CleanerStats())
+    assertEquals(&quot;Last offset should be the end offset.&quot;, offsetEnd, map.latestOffset)
+    assertEquals(&quot;Should have the expected number of messages in the map.&quot;, keyEnd - keyStart, map.size)
     assertEquals(&quot;Map should contain first value&quot;, 0L, map.get(key(0)))
-    assertEquals(&quot;Map should contain second value&quot;, 7206178L, map.get(key(1)))
+    assertEquals(&quot;Map should contain second value&quot;, offsetEnd, map.get(key(1)))
   }

&lt;p&gt;   /**&lt;br/&gt;
@@ -1265,7 +1266,7 @@ class LogCleanerTest extends JUnitSuite {&lt;br/&gt;
                 checkDone = checkDone)&lt;/p&gt;

&lt;p&gt;   private def writeToLog(log: Log, seq: Iterable&lt;span class=&quot;error&quot;&gt;&amp;#91;(Int, Int)&amp;#93;&lt;/span&gt;): Iterable&lt;span class=&quot;error&quot;&gt;&amp;#91;Long&amp;#93;&lt;/span&gt; = &lt;/p&gt;
{
-    for ((key, value) &amp;lt;- seq) yield log.appendAsLeader(record(key, value), leaderEpoch = 0).firstOffset
+    for ((key, value) &amp;lt;- seq) yield log.appendAsLeader(record(key, value), leaderEpoch = 0).firstOffset.get
   }

&lt;p&gt;   private def key(id: Int) = ByteBuffer.wrap(id.toString.getBytes)&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/log/LogManagerTest.scala b/core/src/test/scala/unit/kafka/log/LogManagerTest.scala&lt;br/&gt;
index 8a049147793..2fdda6b8827 100755&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/log/LogManagerTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/log/LogManagerTest.scala&lt;br/&gt;
@@ -142,7 +142,7 @@ class LogManagerTest {&lt;br/&gt;
     for (_ &amp;lt;- 0 until numMessages) &lt;/p&gt;
{
       val set = TestUtils.singletonRecords(&quot;test&quot;.getBytes())
       val info = log.appendAsLeader(set, leaderEpoch = 0)
-      offset = info.firstOffset
+      offset = info.firstOffset.get
     }

&lt;p&gt;     log.onHighWatermarkIncremented(log.logEndOffset)&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/log/LogSegmentTest.scala b/core/src/test/scala/unit/kafka/log/LogSegmentTest.scala&lt;br/&gt;
index c45ed0d2986..31bcf9c2a3b 100644&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/log/LogSegmentTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/log/LogSegmentTest.scala&lt;br/&gt;
@@ -85,7 +85,7 @@ class LogSegmentTest {&lt;br/&gt;
   def testReadBeforeFirstOffset() &lt;/p&gt;
{
     val seg = createSegment(40)
     val ms = records(50, &quot;hello&quot;, &quot;there&quot;, &quot;little&quot;, &quot;bee&quot;)
-    seg.append(50, 53, RecordBatch.NO_TIMESTAMP, -1L, ms)
+    seg.append(53, RecordBatch.NO_TIMESTAMP, -1L, ms)
     val read = seg.read(startOffset = 41, maxSize = 300, maxOffset = None).records
     checkEquals(ms.records.iterator, read.records.iterator)
   }
&lt;p&gt;@@ -99,7 +99,7 @@ class LogSegmentTest {&lt;br/&gt;
     val baseOffset = 50&lt;br/&gt;
     val seg = createSegment(baseOffset)&lt;br/&gt;
     val ms = records(baseOffset, &quot;hello&quot;, &quot;there&quot;, &quot;beautiful&quot;)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;seg.append(baseOffset, 52, RecordBatch.NO_TIMESTAMP, -1L, ms)&lt;br/&gt;
+    seg.append(52, RecordBatch.NO_TIMESTAMP, -1L, ms)&lt;br/&gt;
     def validate(offset: Long) =&lt;br/&gt;
       assertEquals(ms.records.asScala.filter(_.offset == offset).toList,&lt;br/&gt;
                    seg.read(startOffset = offset, maxSize = 1024, maxOffset = Some(offset+1)).records.records.asScala.toList)&lt;br/&gt;
@@ -115,7 +115,7 @@ class LogSegmentTest {&lt;br/&gt;
   def testReadAfterLast() 
{
     val seg = createSegment(40)
     val ms = records(50, &quot;hello&quot;, &quot;there&quot;)
-    seg.append(50, 51, RecordBatch.NO_TIMESTAMP, -1L, ms)
+    seg.append(51, RecordBatch.NO_TIMESTAMP, -1L, ms)
     val read = seg.read(startOffset = 52, maxSize = 200, maxOffset = None)
     assertNull(&quot;Read beyond the last offset in the segment should give null&quot;, read)
   }
&lt;p&gt;@@ -128,9 +128,9 @@ class LogSegmentTest {&lt;br/&gt;
   def testReadFromGap() &lt;/p&gt;
{
     val seg = createSegment(40)
     val ms = records(50, &quot;hello&quot;, &quot;there&quot;)
-    seg.append(50, 51, RecordBatch.NO_TIMESTAMP, -1L, ms)
+    seg.append(51, RecordBatch.NO_TIMESTAMP, -1L, ms)
     val ms2 = records(60, &quot;alpha&quot;, &quot;beta&quot;)
-    seg.append(60, 61, RecordBatch.NO_TIMESTAMP, -1L, ms2)
+    seg.append(61, RecordBatch.NO_TIMESTAMP, -1L, ms2)
     val read = seg.read(startOffset = 55, maxSize = 200, maxOffset = None)
     checkEquals(ms2.records.iterator, read.records.records.iterator)
   }
&lt;p&gt;@@ -145,9 +145,9 @@ class LogSegmentTest {&lt;br/&gt;
     var offset = 40&lt;br/&gt;
     for (_ &amp;lt;- 0 until 30) {&lt;br/&gt;
       val ms1 = records(offset, &quot;hello&quot;)&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;seg.append(offset, offset, RecordBatch.NO_TIMESTAMP, -1L, ms1)&lt;br/&gt;
+      seg.append(offset, RecordBatch.NO_TIMESTAMP, -1L, ms1)&lt;br/&gt;
       val ms2 = records(offset + 1, &quot;hello&quot;)&lt;/li&gt;
	&lt;li&gt;seg.append(offset + 1, offset + 1, RecordBatch.NO_TIMESTAMP, -1L, ms2)&lt;br/&gt;
+      seg.append(offset + 1, RecordBatch.NO_TIMESTAMP, -1L, ms2)&lt;br/&gt;
       // check that we can read back both messages&lt;br/&gt;
       val read = seg.read(offset, None, 10000)&lt;br/&gt;
       assertEquals(List(ms1.records.iterator.next(), ms2.records.iterator.next()), read.records.records.asScala.toList)&lt;br/&gt;
@@ -207,7 +207,7 @@ class LogSegmentTest {&lt;br/&gt;
     val seg = createSegment(40, 2 * records(0, &quot;hello&quot;).sizeInBytes - 1)&lt;br/&gt;
     var offset = 40&lt;br/&gt;
     for (_ &amp;lt;- 0 until numMessages) 
{
-      seg.append(offset, offset, offset, offset, records(offset, &quot;hello&quot;))
+      seg.append(offset, offset, offset, records(offset, &quot;hello&quot;))
       offset += 1
     }
&lt;p&gt;     assertEquals(offset, seg.readNextOffset)&lt;br/&gt;
@@ -229,7 +229,7 @@ class LogSegmentTest {&lt;br/&gt;
     // test the case where we fully truncate the log&lt;br/&gt;
     val time = new MockTime&lt;br/&gt;
     val seg = createSegment(40, time = time)&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;seg.append(40, 41, RecordBatch.NO_TIMESTAMP, -1L, records(40, &quot;hello&quot;, &quot;there&quot;))&lt;br/&gt;
+    seg.append(41, RecordBatch.NO_TIMESTAMP, -1L, records(40, &quot;hello&quot;, &quot;there&quot;))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // If the segment is empty after truncation, the create time should be reset&lt;br/&gt;
     time.sleep(500)&lt;br/&gt;
@@ -241,7 +241,7 @@ class LogSegmentTest &lt;/p&gt;
{
     assertFalse(seg.offsetIndex.isFull)
     assertNull(&quot;Segment should be empty.&quot;, seg.read(0, None, 1024))
 
-    seg.append(40, 41, RecordBatch.NO_TIMESTAMP, -1L, records(40, &quot;hello&quot;, &quot;there&quot;))
+    seg.append(41, RecordBatch.NO_TIMESTAMP, -1L, records(40, &quot;hello&quot;, &quot;there&quot;))
   }

&lt;p&gt;   /**&lt;br/&gt;
@@ -253,7 +253,7 @@ class LogSegmentTest {&lt;br/&gt;
     val seg = createSegment(40, messageSize * 2 - 1)&lt;br/&gt;
     // Produce some messages&lt;br/&gt;
     for (i &amp;lt;- 40 until 50)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;seg.append(i, i, i * 10, i, records(i, s&quot;msg$i&quot;))&lt;br/&gt;
+      seg.append(i, i * 10, i, records(i, s&quot;msg$i&quot;))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     assertEquals(490, seg.largestTimestamp)&lt;br/&gt;
     // Search for an indexed timestamp&lt;br/&gt;
@@ -277,7 +277,7 @@ class LogSegmentTest {&lt;br/&gt;
   def testNextOffsetCalculation() &lt;/p&gt;
{
     val seg = createSegment(40)
     assertEquals(40, seg.readNextOffset)
-    seg.append(50, 52, RecordBatch.NO_TIMESTAMP, -1L, records(50, &quot;hello&quot;, &quot;there&quot;, &quot;you&quot;))
+    seg.append(52, RecordBatch.NO_TIMESTAMP, -1L, records(50, &quot;hello&quot;, &quot;there&quot;, &quot;you&quot;))
     assertEquals(53, seg.readNextOffset)
   }

&lt;p&gt;@@ -304,7 +304,7 @@ class LogSegmentTest {&lt;br/&gt;
   def testRecoveryFixesCorruptIndex() {&lt;br/&gt;
     val seg = createSegment(0)&lt;br/&gt;
     for(i &amp;lt;- 0 until 100)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;seg.append(i, i, RecordBatch.NO_TIMESTAMP, -1L, records(i, i.toString))&lt;br/&gt;
+      seg.append(i, RecordBatch.NO_TIMESTAMP, -1L, records(i, i.toString))&lt;br/&gt;
     val indexFile = seg.offsetIndex.file&lt;br/&gt;
     TestUtils.writeNonsenseToFile(indexFile, 5, indexFile.length.toInt)&lt;br/&gt;
     seg.recover(new ProducerStateManager(topicPartition, logDir))&lt;br/&gt;
@@ -323,26 +323,26 @@ class LogSegmentTest {&lt;br/&gt;
     val pid2 = 10L&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // append transactional records from pid1&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;segment.append(firstOffset = 100L, largestOffset = 101L, largestTimestamp = RecordBatch.NO_TIMESTAMP,&lt;br/&gt;
+    segment.append(largestOffset = 101L, largestTimestamp = RecordBatch.NO_TIMESTAMP,&lt;br/&gt;
       shallowOffsetOfMaxTimestamp = 100L, MemoryRecords.withTransactionalRecords(100L, CompressionType.NONE,&lt;br/&gt;
         pid1, producerEpoch, sequence, partitionLeaderEpoch, new SimpleRecord(&quot;a&quot;.getBytes), new SimpleRecord(&quot;b&quot;.getBytes)))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // append transactional records from pid2&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;segment.append(firstOffset = 102L, largestOffset = 103L, largestTimestamp = RecordBatch.NO_TIMESTAMP,&lt;br/&gt;
+    segment.append(largestOffset = 103L, largestTimestamp = RecordBatch.NO_TIMESTAMP,&lt;br/&gt;
       shallowOffsetOfMaxTimestamp = 102L, MemoryRecords.withTransactionalRecords(102L, CompressionType.NONE,&lt;br/&gt;
         pid2, producerEpoch, sequence, partitionLeaderEpoch, new SimpleRecord(&quot;a&quot;.getBytes), new SimpleRecord(&quot;b&quot;.getBytes)))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // append non-transactional records&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;segment.append(firstOffset = 104L, largestOffset = 105L, largestTimestamp = RecordBatch.NO_TIMESTAMP,&lt;br/&gt;
+    segment.append(largestOffset = 105L, largestTimestamp = RecordBatch.NO_TIMESTAMP,&lt;br/&gt;
       shallowOffsetOfMaxTimestamp = 104L, MemoryRecords.withRecords(104L, CompressionType.NONE,&lt;br/&gt;
         partitionLeaderEpoch, new SimpleRecord(&quot;a&quot;.getBytes), new SimpleRecord(&quot;b&quot;.getBytes)))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // abort the transaction from pid2 (note LSO should be 100L since the txn from pid1 has not completed)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;segment.append(firstOffset = 106L, largestOffset = 106L, largestTimestamp = RecordBatch.NO_TIMESTAMP,&lt;br/&gt;
+    segment.append(largestOffset = 106L, largestTimestamp = RecordBatch.NO_TIMESTAMP,&lt;br/&gt;
       shallowOffsetOfMaxTimestamp = 106L, endTxnRecords(ControlRecordType.ABORT, pid2, producerEpoch, offset = 106L))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // commit the transaction from pid1&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;segment.append(firstOffset = 107L, largestOffset = 107L, largestTimestamp = RecordBatch.NO_TIMESTAMP,&lt;br/&gt;
+    segment.append(largestOffset = 107L, largestTimestamp = RecordBatch.NO_TIMESTAMP,&lt;br/&gt;
       shallowOffsetOfMaxTimestamp = 107L, endTxnRecords(ControlRecordType.COMMIT, pid1, producerEpoch, offset = 107L))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     var stateManager = new ProducerStateManager(topicPartition, logDir)&lt;br/&gt;
@@ -393,7 +393,7 @@ class LogSegmentTest {&lt;br/&gt;
   def testRecoveryFixesCorruptTimeIndex() {&lt;br/&gt;
     val seg = createSegment(0)&lt;br/&gt;
     for(i &amp;lt;- 0 until 100)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;seg.append(i, i, i * 10, i, records(i, i.toString))&lt;br/&gt;
+      seg.append(i, i * 10, i, records(i, i.toString))&lt;br/&gt;
     val timeIndexFile = seg.timeIndex.file&lt;br/&gt;
     TestUtils.writeNonsenseToFile(timeIndexFile, 5, timeIndexFile.length.toInt)&lt;br/&gt;
     seg.recover(new ProducerStateManager(topicPartition, logDir))&lt;br/&gt;
@@ -413,7 +413,7 @@ class LogSegmentTest {&lt;br/&gt;
     for (_ &amp;lt;- 0 until 10) {&lt;br/&gt;
       val seg = createSegment(0)&lt;br/&gt;
       for (i &amp;lt;- 0 until messagesAppended)&lt;/li&gt;
	&lt;li&gt;seg.append(i, i, RecordBatch.NO_TIMESTAMP, -1L, records(i, i.toString))&lt;br/&gt;
+        seg.append(i, RecordBatch.NO_TIMESTAMP, -1L, records(i, i.toString))&lt;br/&gt;
       val offsetToBeginCorruption = TestUtils.random.nextInt(messagesAppended)&lt;br/&gt;
       // start corrupting somewhere in the middle of the chosen record all the way to the end&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -445,9 +445,9 @@ class LogSegmentTest {&lt;br/&gt;
   def testCreateWithInitFileSizeAppendMessage() &lt;/p&gt;
{
     val seg = createSegment(40, false, 512*1024*1024, true)
     val ms = records(50, &quot;hello&quot;, &quot;there&quot;)
-    seg.append(50, 51, RecordBatch.NO_TIMESTAMP, -1L, ms)
+    seg.append(51, RecordBatch.NO_TIMESTAMP, -1L, ms)
     val ms2 = records(60, &quot;alpha&quot;, &quot;beta&quot;)
-    seg.append(60, 61, RecordBatch.NO_TIMESTAMP, -1L, ms2)
+    seg.append(61, RecordBatch.NO_TIMESTAMP, -1L, ms2)
     val read = seg.read(startOffset = 55, maxSize = 200, maxOffset = None)
     checkEquals(ms2.records.iterator, read.records.records.iterator)
   }
&lt;p&gt;@@ -466,9 +466,9 @@ class LogSegmentTest {&lt;br/&gt;
       initFileSize = 512 * 1024 * 1024, preallocate = true)&lt;/p&gt;

&lt;p&gt;     val ms = records(50, &quot;hello&quot;, &quot;there&quot;)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;seg.append(50, 51, RecordBatch.NO_TIMESTAMP, -1L, ms)&lt;br/&gt;
+    seg.append(51, RecordBatch.NO_TIMESTAMP, -1L, ms)&lt;br/&gt;
     val ms2 = records(60, &quot;alpha&quot;, &quot;beta&quot;)&lt;/li&gt;
	&lt;li&gt;seg.append(60, 61, RecordBatch.NO_TIMESTAMP, -1L, ms2)&lt;br/&gt;
+    seg.append(61, RecordBatch.NO_TIMESTAMP, -1L, ms2)&lt;br/&gt;
     val read = seg.read(startOffset = 55, maxSize = 200, maxOffset = None)&lt;br/&gt;
     checkEquals(ms2.records.iterator, read.records.records.iterator)&lt;br/&gt;
     val oldSize = seg.log.sizeInBytes()&lt;br/&gt;
@@ -504,9 +504,9 @@ class LogSegmentTest {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     //Given two messages with a gap between them (e.g. mid offset compacted away)&lt;br/&gt;
     val ms1 = records(offset, &quot;first message&quot;)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;seg.append(offset, offset, RecordBatch.NO_TIMESTAMP, -1L, ms1)&lt;br/&gt;
+    seg.append(offset, RecordBatch.NO_TIMESTAMP, -1L, ms1)&lt;br/&gt;
     val ms2 = records(offset + 3, &quot;message after gap&quot;)&lt;/li&gt;
	&lt;li&gt;seg.append(offset + 3, offset + 3, RecordBatch.NO_TIMESTAMP, -1L, ms2)&lt;br/&gt;
+    seg.append(offset + 3, RecordBatch.NO_TIMESTAMP, -1L, ms2)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // When we truncate to an offset without a corresponding log entry&lt;br/&gt;
     seg.truncateTo(offset + 1)&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/log/LogTest.scala b/core/src/test/scala/unit/kafka/log/LogTest.scala&lt;br/&gt;
index 6753939f3d8..ec748156e23 100755&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/log/LogTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/log/LogTest.scala&lt;br/&gt;
@@ -897,12 +897,12 @@ class LogTest {&lt;br/&gt;
       new SimpleRecord(mockTime.milliseconds, s&quot;key-$seq&quot;.getBytes, s&quot;value-$seq&quot;.getBytes)&lt;br/&gt;
     ), producerId = pid, producerEpoch = epoch, sequence = seq)&lt;br/&gt;
     val multiEntryAppendInfo = log.appendAsLeader(createRecords, leaderEpoch = 0)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertEquals(&quot;should have appended 3 entries&quot;, multiEntryAppendInfo.lastOffset - multiEntryAppendInfo.firstOffset + 1, 3)&lt;br/&gt;
+    assertEquals(&quot;should have appended 3 entries&quot;, multiEntryAppendInfo.lastOffset - multiEntryAppendInfo.firstOffset.get + 1, 3)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // Append a Duplicate of the tail, when the entry at the tail has multiple records.&lt;br/&gt;
     val dupMultiEntryAppendInfo = log.appendAsLeader(createRecords, leaderEpoch = 0)&lt;br/&gt;
     assertEquals(&quot;Somehow appended a duplicate entry with multiple log records to the tail&quot;,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;multiEntryAppendInfo.firstOffset, dupMultiEntryAppendInfo.firstOffset)&lt;br/&gt;
+      multiEntryAppendInfo.firstOffset.get, dupMultiEntryAppendInfo.firstOffset.get)&lt;br/&gt;
     assertEquals(&quot;Somehow appended a duplicate entry with multiple log records to the tail&quot;,&lt;br/&gt;
       multiEntryAppendInfo.lastOffset, dupMultiEntryAppendInfo.lastOffset)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -945,7 +945,7 @@ class LogTest &lt;/p&gt;
{
       producerId = pid, producerEpoch = epoch, sequence = seq)
     val origAppendInfo = log.appendAsLeader(createRecordsWithDuplicate, leaderEpoch = 0)
     val newAppendInfo = log.appendAsLeader(createRecordsWithDuplicate, leaderEpoch = 0)
-    assertEquals(&quot;Inserted a duplicate records into the log&quot;, origAppendInfo.firstOffset, newAppendInfo.firstOffset)
+    assertEquals(&quot;Inserted a duplicate records into the log&quot;, origAppendInfo.firstOffset.get, newAppendInfo.firstOffset.get)
     assertEquals(&quot;Inserted a duplicate records into the log&quot;, origAppendInfo.lastOffset, newAppendInfo.lastOffset)
   }

&lt;p&gt;@@ -1387,7 +1387,7 @@ class LogTest {&lt;br/&gt;
       assertEquals(&quot;Still no change in the logEndOffset&quot;, currOffset, log.logEndOffset)&lt;br/&gt;
       assertEquals(&quot;Should still be able to append and should get the logEndOffset assigned to the new append&quot;,&lt;br/&gt;
                    currOffset,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;log.appendAsLeader(TestUtils.singletonRecords(value = &quot;hello&quot;.getBytes, timestamp = mockTime.milliseconds), leaderEpoch = 0).firstOffset)&lt;br/&gt;
+                   log.appendAsLeader(TestUtils.singletonRecords(value = &quot;hello&quot;.getBytes, timestamp = mockTime.milliseconds), leaderEpoch = 0).firstOffset.get)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;       // cleanup the log&lt;br/&gt;
       log.delete()&lt;br/&gt;
@@ -1919,17 +1919,96 @@ class LogTest {&lt;br/&gt;
     //Writes into an empty log with baseOffset 0&lt;br/&gt;
     log.appendAsFollower(set1)&lt;br/&gt;
     assertEquals(0L, log.activeSegment.baseOffset)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;//This write will roll the segment, yielding a new segment with base offset = max(2, 1) = 2&lt;br/&gt;
+    //This write will roll the segment, yielding a new segment with base offset = max(1, Integer.MAX_VALUE+2) = Integer.MAX_VALUE+2&lt;br/&gt;
     log.appendAsFollower(set2)&lt;/li&gt;
	&lt;li&gt;assertEquals(2L, log.activeSegment.baseOffset)&lt;/li&gt;
	&lt;li&gt;assertTrue(Log.producerSnapshotFile(logDir, 2L).exists)&lt;/li&gt;
	&lt;li&gt;//This will also roll the segment, yielding a new segment with base offset = max(3, Integer.MAX_VALUE+3) = Integer.MAX_VALUE+3&lt;br/&gt;
+    assertEquals(Integer.MAX_VALUE.toLong + 2, log.activeSegment.baseOffset)&lt;br/&gt;
+    assertTrue(Log.producerSnapshotFile(logDir, Integer.MAX_VALUE.toLong + 2).exists)&lt;br/&gt;
+    //This will go into the existing log&lt;br/&gt;
+    log.appendAsFollower(set3)&lt;br/&gt;
+    assertEquals(Integer.MAX_VALUE.toLong + 2, log.activeSegment.baseOffset)&lt;br/&gt;
+    //This will go into the existing log&lt;br/&gt;
+    log.appendAsFollower(set4)&lt;br/&gt;
+    assertEquals(Integer.MAX_VALUE.toLong + 2, log.activeSegment.baseOffset)&lt;br/&gt;
+    log.close()&lt;br/&gt;
+    val indexFiles = logDir.listFiles.filter(file =&amp;gt; file.getName.contains(&quot;.index&quot;))&lt;br/&gt;
+    assertEquals(2, indexFiles.length)&lt;br/&gt;
+    for (file &amp;lt;- indexFiles) 
{
+      val offsetIndex = new OffsetIndex(file, file.getName.replace(&quot;.index&quot;,&quot;&quot;).toLong)
+      assertTrue(offsetIndex.lastOffset &amp;gt;= 0)
+      offsetIndex.close()
+    }&lt;br/&gt;
+    Utils.delete(logDir)&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  def testOverCompactedLogRecoveryMultiRecord(): Unit = {&lt;br/&gt;
+    // append some messages to create some segments&lt;br/&gt;
+    val logConfig = createLogConfig(segmentBytes = 1000, indexIntervalBytes = 1, maxMessageBytes = 64 * 1024)&lt;br/&gt;
+    val log = createLog(logDir, logConfig)&lt;br/&gt;
+    val set1 = MemoryRecords.withRecords(0, CompressionType.NONE, 0, new SimpleRecord(&quot;v1&quot;.getBytes(), &quot;k1&quot;.getBytes()))&lt;br/&gt;
+    val set2 = MemoryRecords.withRecords(Integer.MAX_VALUE.toLong + 2, CompressionType.GZIP, 0,&lt;br/&gt;
+      new SimpleRecord(&quot;v3&quot;.getBytes(), &quot;k3&quot;.getBytes()),&lt;br/&gt;
+      new SimpleRecord(&quot;v4&quot;.getBytes(), &quot;k4&quot;.getBytes()))&lt;br/&gt;
+    val set3 = MemoryRecords.withRecords(Integer.MAX_VALUE.toLong + 4, CompressionType.GZIP, 0,&lt;br/&gt;
+      new SimpleRecord(&quot;v5&quot;.getBytes(), &quot;k5&quot;.getBytes()),&lt;br/&gt;
+      new SimpleRecord(&quot;v6&quot;.getBytes(), &quot;k6&quot;.getBytes()))&lt;br/&gt;
+    val set4 = MemoryRecords.withRecords(Integer.MAX_VALUE.toLong + 6, CompressionType.GZIP, 0,&lt;br/&gt;
+      new SimpleRecord(&quot;v7&quot;.getBytes(), &quot;k7&quot;.getBytes()),&lt;br/&gt;
+      new SimpleRecord(&quot;v8&quot;.getBytes(), &quot;k8&quot;.getBytes()))&lt;br/&gt;
+    //Writes into an empty log with baseOffset 0&lt;br/&gt;
+    log.appendAsFollower(set1)&lt;br/&gt;
+    assertEquals(0L, log.activeSegment.baseOffset)&lt;br/&gt;
+    //This write will roll the segment, yielding a new segment with base offset = max(1, Integer.MAX_VALUE+2) = Integer.MAX_VALUE+2&lt;br/&gt;
+    log.appendAsFollower(set2)&lt;br/&gt;
+    assertEquals(Integer.MAX_VALUE.toLong + 2, log.activeSegment.baseOffset)&lt;br/&gt;
+    assertTrue(Log.producerSnapshotFile(logDir, Integer.MAX_VALUE.toLong + 2).exists)&lt;br/&gt;
+    //This will go into the existing log&lt;br/&gt;
+    log.appendAsFollower(set3)&lt;br/&gt;
+    assertEquals(Integer.MAX_VALUE.toLong + 2, log.activeSegment.baseOffset)&lt;br/&gt;
+    //This will go into the existing log&lt;br/&gt;
+    log.appendAsFollower(set4)&lt;br/&gt;
+    assertEquals(Integer.MAX_VALUE.toLong + 2, log.activeSegment.baseOffset)&lt;br/&gt;
+    log.close()&lt;br/&gt;
+    val indexFiles = logDir.listFiles.filter(file =&amp;gt; file.getName.contains(&quot;.index&quot;))&lt;br/&gt;
+    assertEquals(2, indexFiles.length)&lt;br/&gt;
+    for (file &amp;lt;- indexFiles) {+      val offsetIndex = new OffsetIndex(file, file.getName.replace(&quot;.index&quot;,&quot;&quot;).toLong)+      assertTrue(offsetIndex.lastOffset &amp;gt;= 0)+      offsetIndex.close()+    }
&lt;p&gt;+    Utils.delete(logDir)&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  def testOverCompactedLogRecoveryMultiRecordV1(): Unit = {&lt;br/&gt;
+    // append some messages to create some segments&lt;br/&gt;
+    val logConfig = createLogConfig(segmentBytes = 1000, indexIntervalBytes = 1, maxMessageBytes = 64 * 1024)&lt;br/&gt;
+    val log = createLog(logDir, logConfig)&lt;br/&gt;
+    val set1 = MemoryRecords.withRecords(RecordBatch.MAGIC_VALUE_V1, 0, CompressionType.NONE,&lt;br/&gt;
+      new SimpleRecord(&quot;v1&quot;.getBytes(), &quot;k1&quot;.getBytes()))&lt;br/&gt;
+    val set2 = MemoryRecords.withRecords(RecordBatch.MAGIC_VALUE_V1, Integer.MAX_VALUE.toLong + 2, CompressionType.GZIP,&lt;br/&gt;
+      new SimpleRecord(&quot;v3&quot;.getBytes(), &quot;k3&quot;.getBytes()),&lt;br/&gt;
+      new SimpleRecord(&quot;v4&quot;.getBytes(), &quot;k4&quot;.getBytes()))&lt;br/&gt;
+    val set3 = MemoryRecords.withRecords(RecordBatch.MAGIC_VALUE_V1, Integer.MAX_VALUE.toLong + 4, CompressionType.GZIP,&lt;br/&gt;
+      new SimpleRecord(&quot;v5&quot;.getBytes(), &quot;k5&quot;.getBytes()),&lt;br/&gt;
+      new SimpleRecord(&quot;v6&quot;.getBytes(), &quot;k6&quot;.getBytes()))&lt;br/&gt;
+    val set4 = MemoryRecords.withRecords(RecordBatch.MAGIC_VALUE_V1, Integer.MAX_VALUE.toLong + 6, CompressionType.GZIP,&lt;br/&gt;
+      new SimpleRecord(&quot;v7&quot;.getBytes(), &quot;k7&quot;.getBytes()),&lt;br/&gt;
+      new SimpleRecord(&quot;v8&quot;.getBytes(), &quot;k8&quot;.getBytes()))&lt;br/&gt;
+    //Writes into an empty log with baseOffset 0&lt;br/&gt;
+    log.appendAsFollower(set1)&lt;br/&gt;
+    assertEquals(0L, log.activeSegment.baseOffset)&lt;br/&gt;
+    //This write will roll the segment, yielding a new segment with base offset = max(1, 3) = 3&lt;br/&gt;
+    log.appendAsFollower(set2)&lt;br/&gt;
+    assertEquals(3, log.activeSegment.baseOffset)&lt;br/&gt;
+    assertTrue(Log.producerSnapshotFile(logDir, 3).exists)&lt;br/&gt;
+    //This will also roll the segment, yielding a new segment with base offset = max(5, Integer.MAX_VALUE+4) = Integer.MAX_VALUE+4&lt;br/&gt;
     log.appendAsFollower(set3)&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;assertEquals(Integer.MAX_VALUE.toLong + 3, log.activeSegment.baseOffset)&lt;/li&gt;
	&lt;li&gt;assertTrue(Log.producerSnapshotFile(logDir, Integer.MAX_VALUE.toLong + 3).exists)&lt;br/&gt;
+    assertEquals(Integer.MAX_VALUE.toLong + 4, log.activeSegment.baseOffset)&lt;br/&gt;
+    assertTrue(Log.producerSnapshotFile(logDir, Integer.MAX_VALUE.toLong + 4).exists)&lt;br/&gt;
     //This will go into the existing log&lt;br/&gt;
     log.appendAsFollower(set4)&lt;/li&gt;
	&lt;li&gt;assertEquals(Integer.MAX_VALUE.toLong + 3, log.activeSegment.baseOffset)&lt;br/&gt;
+    assertEquals(Integer.MAX_VALUE.toLong + 4, log.activeSegment.baseOffset)&lt;br/&gt;
     log.close()&lt;br/&gt;
     val indexFiles = logDir.listFiles.filter(file =&amp;gt; file.getName.contains(&quot;.index&quot;))&lt;br/&gt;
     assertEquals(3, indexFiles.length)&lt;br/&gt;
@@ -2534,7 +2613,7 @@ class LogTest {&lt;br/&gt;
       new SimpleRecord(&quot;baz&quot;.getBytes))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val firstAppendInfo = log.appendAsLeader(records, leaderEpoch = 0)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertEquals(Some(firstAppendInfo.firstOffset), log.firstUnstableOffset.map(_.messageOffset))&lt;br/&gt;
+    assertEquals(Some(firstAppendInfo.firstOffset.get), log.firstUnstableOffset.map(_.messageOffset))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // add more transactional records&lt;br/&gt;
     seq += 3&lt;br/&gt;
@@ -2542,14 +2621,14 @@ class LogTest {&lt;br/&gt;
       new SimpleRecord(&quot;blah&quot;.getBytes)), leaderEpoch = 0)&lt;/p&gt;

&lt;p&gt;     // LSO should not have changed&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertEquals(Some(firstAppendInfo.firstOffset), log.firstUnstableOffset.map(_.messageOffset))&lt;br/&gt;
+    assertEquals(Some(firstAppendInfo.firstOffset.get), log.firstUnstableOffset.map(_.messageOffset))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // now transaction is committed&lt;br/&gt;
     val commitAppendInfo = log.appendAsLeader(endTxnRecords(ControlRecordType.COMMIT, pid, epoch),&lt;br/&gt;
       isFromClient = false, leaderEpoch = 0)&lt;/p&gt;

&lt;p&gt;     // first unstable offset is not updated until the high watermark is advanced&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertEquals(Some(firstAppendInfo.firstOffset), log.firstUnstableOffset.map(_.messageOffset))&lt;br/&gt;
+    assertEquals(Some(firstAppendInfo.firstOffset.get), log.firstUnstableOffset.map(_.messageOffset))&lt;br/&gt;
     log.onHighWatermarkIncremented(commitAppendInfo.lastOffset + 1)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // now there should be no first unstable offset&lt;br/&gt;
@@ -2885,7 +2964,7 @@ class LogTest {&lt;br/&gt;
       new SimpleRecord(&quot;a&quot;.getBytes),&lt;br/&gt;
       new SimpleRecord(&quot;b&quot;.getBytes),&lt;br/&gt;
       new SimpleRecord(&quot;c&quot;.getBytes)), leaderEpoch = 0)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertEquals(Some(firstAppendInfo.firstOffset), log.firstUnstableOffset.map(_.messageOffset))&lt;br/&gt;
+    assertEquals(Some(firstAppendInfo.firstOffset.get), log.firstUnstableOffset.map(_.messageOffset))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // mix in some non-transactional data&lt;br/&gt;
     log.appendAsLeader(MemoryRecords.withRecords(CompressionType.NONE,&lt;br/&gt;
@@ -2900,7 +2979,7 @@ class LogTest {&lt;br/&gt;
       new SimpleRecord(&quot;f&quot;.getBytes)), leaderEpoch = 0)&lt;/p&gt;

&lt;p&gt;     // LSO should not have changed&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertEquals(Some(firstAppendInfo.firstOffset), log.firstUnstableOffset.map(_.messageOffset))&lt;br/&gt;
+    assertEquals(Some(firstAppendInfo.firstOffset.get), log.firstUnstableOffset.map(_.messageOffset))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // now first producer&apos;s transaction is aborted&lt;br/&gt;
     val abortAppendInfo = log.appendAsLeader(endTxnRecords(ControlRecordType.ABORT, pid1, epoch),&lt;br/&gt;
@@ -2908,7 +2987,7 @@ class LogTest {&lt;br/&gt;
     log.onHighWatermarkIncremented(abortAppendInfo.lastOffset + 1)&lt;/p&gt;

&lt;p&gt;     // LSO should now point to one less than the first offset of the second transaction&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertEquals(Some(secondAppendInfo.firstOffset), log.firstUnstableOffset.map(_.messageOffset))&lt;br/&gt;
+    assertEquals(Some(secondAppendInfo.firstOffset.get), log.firstUnstableOffset.map(_.messageOffset))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // commit the second transaction&lt;br/&gt;
     val commitAppendInfo = log.appendAsLeader(endTxnRecords(ControlRecordType.COMMIT, pid2, epoch),&lt;br/&gt;
@@ -2934,7 +3013,7 @@ class LogTest {&lt;br/&gt;
     val log = createLog(logDir, logConfig)&lt;/p&gt;

&lt;p&gt;     val firstAppendInfo = log.appendAsLeader(records, leaderEpoch = 0)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertEquals(Some(firstAppendInfo.firstOffset), log.firstUnstableOffset.map(_.messageOffset))&lt;br/&gt;
+    assertEquals(Some(firstAppendInfo.firstOffset.get), log.firstUnstableOffset.map(_.messageOffset))&lt;br/&gt;
     assertEquals(Some(0L), log.firstUnstableOffset.map(_.segmentBaseOffset))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // this write should spill to the second segment&lt;br/&gt;
@@ -2943,7 +3022,7 @@ class LogTest {&lt;br/&gt;
       new SimpleRecord(&quot;d&quot;.getBytes),&lt;br/&gt;
       new SimpleRecord(&quot;e&quot;.getBytes),&lt;br/&gt;
       new SimpleRecord(&quot;f&quot;.getBytes)), leaderEpoch = 0)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertEquals(Some(firstAppendInfo.firstOffset), log.firstUnstableOffset.map(_.messageOffset))&lt;br/&gt;
+    assertEquals(Some(firstAppendInfo.firstOffset.get), log.firstUnstableOffset.map(_.messageOffset))&lt;br/&gt;
     assertEquals(Some(0L), log.firstUnstableOffset.map(_.segmentBaseOffset))&lt;br/&gt;
     assertEquals(3L, log.logEndOffsetMetadata.segmentBaseOffset)&lt;/li&gt;
&lt;/ul&gt;






&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 35 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3pr87:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>