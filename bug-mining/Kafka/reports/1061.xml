<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:54:16 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-3587] LogCleaner fails due to incorrect offset map computation on a replica</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-3587</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Log Cleaner fails to compact a segment even when the number of messages in it is less than the offset map.&lt;/p&gt;


&lt;p&gt;In version 0.9.0.1, (LogCleaner.scala -&amp;gt; buildOffsetMap()), LogCleaner computes segment size by subtracting segment&apos;s base offset from the latest offset (&quot;segmentSize = segment.nextOffset() - segment.baseOffset&quot;).  This works fine until you create another replica. When you create a replica, it&apos;s segment could contain data which is already compacted on other brokers. Depending up on the type of data, offset difference could be too big, larger than the offset map (maxDesiredMapSize), and that causes LogCleaner to fail on that segment.&lt;/p&gt;


&lt;p&gt;Scenario:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Kafka 0.9.0.1&lt;/li&gt;
	&lt;li&gt;Cluster has two brokers.&lt;/li&gt;
	&lt;li&gt;Server.properties:&lt;br/&gt;
log.cleaner.enable=true&lt;br/&gt;
log.cleaner.dedupe.buffer.size=10485760 #10MB&lt;br/&gt;
log.roll.ms=300000&lt;br/&gt;
delete.topic.enable=true&lt;br/&gt;
log.cleanup.policy=compact&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Steps to reproduce:&lt;br/&gt;
1. Create a topic with replication-factor of 1.&lt;/p&gt;

&lt;p&gt;./kafka-topics.sh --zookeeper=localhost:2181 --create --topic test.log.compact.1M --partitions 1 --replication-factor 1 --config cleanup.policy=compact --config segment.ms=300000&lt;/p&gt;

&lt;p&gt;2. Use kafka-console-producer.sh to produce a single message with the following key:&lt;br/&gt;
LC1,&lt;/p&gt;
{&quot;test&quot;: &quot;xyz&quot;}

&lt;p&gt;3. Use  kafka-console-producer.sh to produce a large number of messages with the following key:&lt;br/&gt;
LC2,&lt;/p&gt;
{&quot;test&quot;: &quot;abc&quot;}

&lt;p&gt;4. Let log cleaner run. Make sure log is compacted.  Verify with:&lt;br/&gt;
 ./kafka-run-class.sh kafka.tools.DumpLogSegments  --files 00000000000000000000.log  --print-data-log&lt;/p&gt;

&lt;p&gt;Dumping 00000000000000000000.log&lt;br/&gt;
Starting offset: 0&lt;br/&gt;
offset: 0 position: 0 isvalid: true payloadsize: 11 magic: 0 compresscodec: NoCompressionCodec crc: 3067045277 keysize: 11 key: LC1 payload: &lt;/p&gt;
{&quot;test&quot;: &quot;xyz&quot;}
&lt;p&gt;offset: 7869818 position: 48 isvalid: true payloadsize: 11 magic: 0 compresscodec: NoCompressionCodec crc: 2668089711 keysize: 11 key: LC2 payload: &lt;/p&gt;
{&quot;test&quot;: &quot;abc&quot;}

&lt;p&gt;5.  Increase Replication Factor to 2.  Followed these steps: &lt;a href=&quot;http://kafka.apache.org/documentation.html#basic_ops_increase_replication_factor&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://kafka.apache.org/documentation.html#basic_ops_increase_replication_factor&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;6. Notice that log cleaner fails to compact the newly created replica with the following error.&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2016-04-18 14:49:45,599&amp;#93;&lt;/span&gt; ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-log-cleaner-thread-0&amp;#93;&lt;/span&gt;, Error due to  (kafka.log.LogCleaner)&lt;br/&gt;
java.lang.IllegalArgumentException: requirement failed: 7206179 messages in segment test.log.compact.1M-0/00000000000000000000.log but offset map can fit only 393215. You can increase log.cleaner.dedupe.buffer.size or decrease log.cleaner.threads&lt;br/&gt;
        at scala.Predef$.require(Predef.scala:219)&lt;br/&gt;
        at kafka.log.Cleaner$$anonfun$buildOffsetMap$4.apply(LogCleaner.scala:584)&lt;br/&gt;
        at kafka.log.Cleaner$$anonfun$buildOffsetMap$4.apply(LogCleaner.scala:580)&lt;br/&gt;
        at scala.collection.immutable.Stream$StreamWithFilter.foreach(Stream.scala:570)&lt;br/&gt;
        at kafka.log.Cleaner.buildOffsetMap(LogCleaner.scala:580)&lt;br/&gt;
        at kafka.log.Cleaner.clean(LogCleaner.scala:322)&lt;br/&gt;
        at kafka.log.LogCleaner$CleanerThread.cleanOrSleep(LogCleaner.scala:230)&lt;br/&gt;
        at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:208)&lt;br/&gt;
        at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2016-04-18 14:49:45,601&amp;#93;&lt;/span&gt; INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-log-cleaner-thread-0&amp;#93;&lt;/span&gt;, Stopped  (kafka.log.LogCleaner)&lt;/p&gt;

&lt;p&gt;7. Examine the entries in the replica segment:&lt;/p&gt;

&lt;p&gt;./kafka-run-class.sh kafka.tools.DumpLogSegments --files 00000000000000000000.log  --print-data-log&lt;br/&gt;
There are only 218418 messages in that segment.&lt;/p&gt;

&lt;p&gt;However, Log Cleaner seems to think that there are 7206179 messages in that segment (as per the above error)&lt;/p&gt;


&lt;p&gt;Error stems from this line in LogCleaner.scala:&lt;br/&gt;
&quot;&quot;&quot;val segmentSize = segment.nextOffset() - segment.baseOffset&quot;&quot;&quot;&lt;/p&gt;

&lt;p&gt;In Replica&apos;s log segment file ( 00000000000000000000.log), ending offset is 7206178. Beginning offset is 0.  That makes Log Cleaner think that there are 7206179 messages in that segment although there are only 218418 messages in it.&lt;/p&gt;

&lt;p&gt;IMO,  to address this kind of scenario, LogCleaner.scala should check for the number of messages in the segment, instead of subtracting beginning offset from the ending offset.&lt;/p&gt;</description>
                <environment>Linux</environment>
        <key id="12960070">KAFKA-3587</key>
            <summary>LogCleaner fails due to incorrect offset map computation on a replica</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ecomar">Edoardo Comar</assignee>
                                    <reporter username="kiranp">Kiran Pillarisetty</reporter>
                        <labels>
                    </labels>
                <created>Tue, 19 Apr 2016 17:56:23 +0000</created>
                <updated>Fri, 22 Dec 2017 20:18:18 +0000</updated>
                            <resolved>Mon, 9 May 2016 17:11:33 +0000</resolved>
                                    <version>0.9.0.1</version>
                                    <fixVersion>0.9.0.2</fixVersion>
                    <fixVersion>0.10.0.0</fixVersion>
                                        <due></due>
                            <votes>1</votes>
                                    <watches>19</watches>
                                                                                                                <comments>
                            <comment id="15253833" author="ecomar" created="Fri, 22 Apr 2016 12:31:16 +0000"  >&lt;p&gt;Hi I was having a look at this issue too.&lt;/p&gt;

&lt;p&gt;in LogCleaner.scala  Cleaner.buildOffsetMap &lt;br/&gt;
the calculation of segmentSize as described in this defect is actually an upper bound for the actual segmentSize;&lt;br/&gt;
moreover segmentSize itself is an upper bound to the number of entries to the offsetMap that a segment may contribute&lt;br/&gt;
(as many entries may share the same key, else why dedup ?).&lt;/p&gt;

&lt;p&gt;So the result is that the memorybuffer allocated may not be used near its loadfactor &lt;br/&gt;
i.e. the map actual size may be much, much smaller than maxDesiredMapSize&lt;/p&gt;

&lt;p&gt;Perhaps a different trade-off may be used. &lt;br/&gt;
The current one seems based on speed vs memory size.&lt;/p&gt;

&lt;p&gt;Rather than aborting on a test that may be overly pessimistic,&lt;br/&gt;
the alternative trade-off could be that the &lt;br/&gt;
the code checks * while building the map * if actually the mapSize goes over the desired size &lt;br/&gt;
and only in that case, abort the compaction with an exception.&lt;/p&gt;

&lt;p&gt;What do you think?&lt;br/&gt;
cheers Edoardo&lt;/p&gt;</comment>
                            <comment id="15261312" author="kiranp" created="Thu, 28 Apr 2016 00:48:01 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ecomar&quot; class=&quot;user-hover&quot; rel=&quot;ecomar&quot;&gt;ecomar&lt;/a&gt; That sounds like a good trade-off.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=omkreddy&quot; class=&quot;user-hover&quot; rel=&quot;omkreddy&quot;&gt;omkreddy&lt;/a&gt; What do you think about the trade-off proposed by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ecomar&quot; class=&quot;user-hover&quot; rel=&quot;ecomar&quot;&gt;ecomar&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="15261630" author="omkreddy" created="Thu, 28 Apr 2016 06:51:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ecomar&quot; class=&quot;user-hover&quot; rel=&quot;ecomar&quot;&gt;ecomar&lt;/a&gt; your alternative approach looks good. I haven&apos;t started work on this.  If you want to work on this jira,  pl feel free to assign yourself.&lt;/p&gt;</comment>
                            <comment id="15269586" author="wushujames" created="Tue, 3 May 2016 21:05:36 +0000"  >&lt;p&gt;The fix for &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3587&quot; title=&quot;LogCleaner fails due to incorrect offset map computation on a replica&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3587&quot;&gt;&lt;del&gt;KAFKA-3587&lt;/del&gt;&lt;/a&gt; may resolve both &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-2235&quot; title=&quot;LogCleaner offset map overflow&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-2235&quot;&gt;&lt;del&gt;KAFKA-2235&lt;/del&gt;&lt;/a&gt; and KAFAK-2303&lt;/p&gt;</comment>
                            <comment id="15273293" author="alekar" created="Thu, 5 May 2016 23:10:15 +0000"  >&lt;p&gt;I have attached a patch which explains one feasible approach to this issue. If it seems like a good direction to proceed, I work on getting it into trunk.&lt;/p&gt;</comment>
                            <comment id="15273305" author="liquanpei" created="Thu, 5 May 2016 23:20:54 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ecomar&quot; class=&quot;user-hover&quot; rel=&quot;ecomar&quot;&gt;ecomar&lt;/a&gt; &lt;br/&gt;
I have a WIP PR, mind to take a look? &lt;a href=&quot;https://github.com/apache/kafka/pull/1328&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1328&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15273313" author="gwenshap" created="Thu, 5 May 2016 23:26:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=alekar&quot; class=&quot;user-hover&quot; rel=&quot;alekar&quot;&gt;alekar&lt;/a&gt; Thanks for the patch! In general, Apache Kafka is taking contributions through github PRs (&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/Contributing+Code+Changes&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://cwiki.apache.org/confluence/display/KAFKA/Contributing+Code+Changes&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;This particular JIRA already has a PR by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=liquanpei&quot; class=&quot;user-hover&quot; rel=&quot;liquanpei&quot;&gt;liquanpei&lt;/a&gt;:  &lt;a href=&quot;https://github.com/apache/kafka/pull/1328&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1328&lt;/a&gt;&lt;br/&gt;
Perhaps you can help review his approach?&lt;/p&gt;</comment>
                            <comment id="15273325" author="alekar" created="Thu, 5 May 2016 23:48:09 +0000"  >&lt;p&gt;It was easier to explain a fix in code than in comments. Thanks for letting me know about the pull request.&lt;/p&gt;</comment>
                            <comment id="15273455" author="ecomar" created="Fri, 6 May 2016 01:29:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=alekar&quot; class=&quot;user-hover&quot; rel=&quot;alekar&quot;&gt;alekar&lt;/a&gt; I had a look at your patch. The approach you took is that of using one temp map per segment and one overall map, which I had considered too.&lt;br/&gt;
Do you think that allocating to the overall map just 1/2 the memory (w.r.t. the current approach ) is a good strategy?&lt;/p&gt;

&lt;p&gt;The approach I and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mimaison&quot; class=&quot;user-hover&quot; rel=&quot;mimaison&quot;&gt;mimaison&lt;/a&gt; are working on is to try and compact until the (only-one-per-thread) map is full, which is maximising the use of the memory allocated to the map.&lt;/p&gt;</comment>
                            <comment id="15273457" author="junrao" created="Fri, 6 May 2016 01:34:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=alekar&quot; class=&quot;user-hover&quot; rel=&quot;alekar&quot;&gt;alekar&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=liquanpei&quot; class=&quot;user-hover&quot; rel=&quot;liquanpei&quot;&gt;liquanpei&lt;/a&gt;, thanks for both your patches. Overall, I feel that &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=alekar&quot; class=&quot;user-hover&quot; rel=&quot;alekar&quot;&gt;alekar&lt;/a&gt;&apos;s approach is better. It tries to fit as many segments as possible when building the map at the expense of perhaps wasting the read of the last segment. However, if the last segment does fit, it eliminates one round of extra scanning of all cleaned log. So, it seems to pay off overall. A few comments on the patch.&lt;/p&gt;

&lt;p&gt;1. In LogCleaner.buildOffsetMap(), we should throw an exception if the first segment can&apos;t fit into the map. The exception should include information on what the user should do to fix the problem.&lt;/p&gt;

&lt;p&gt;2. In LogCleaner.buildOffsetMap(), we should stop taking new segments as soon as a segment&apos;s scratchMap can&apos;t be merged into the offsetMap.&lt;/p&gt;

&lt;p&gt;3. We probably want to keep the OffsetMap interface since it can make unit test easier.&lt;/p&gt;
</comment>
                            <comment id="15273466" author="alekar" created="Fri, 6 May 2016 01:41:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ecomar&quot; class=&quot;user-hover&quot; rel=&quot;ecomar&quot;&gt;ecomar&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I used 1/2 because the worst case for the cleaner is when it sees no duplicates. I am not sure how you compact till it fills up. Like my comment on &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ishiihara&quot; class=&quot;user-hover&quot; rel=&quot;ishiihara&quot;&gt;ishiihara&lt;/a&gt;&apos;s PR, the offset map needs to take all or none at segment boundaries for the cleaner&apos;s current architecture to work.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I&apos;ll clean it up, add some tests and open a PR if that is useful.&lt;/p&gt;</comment>
                            <comment id="15273481" author="alekar" created="Fri, 6 May 2016 01:54:39 +0000"  >&lt;p&gt;1. I believe this should happen when any scratchMap fails to build. Should we change that in the assertion in OffsetMap.put?&lt;/p&gt;

&lt;p&gt;3. Problem is OffsetMap.putAll(map: OffsetMap) cannot accept the interface as it&apos;s argument: how to merge different implementations of OffsetMap and maintain any efficiency?  I could specify subtype in interface, but this seemed cleaner.&lt;/p&gt;</comment>
                            <comment id="15273482" author="ecomar" created="Fri, 6 May 2016 01:57:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ishiihara&quot; class=&quot;user-hover&quot; rel=&quot;ishiihara&quot;&gt;ishiihara&lt;/a&gt; In your PR the very pessimistic check &lt;br/&gt;
val segmentSize = segment.nextOffset() - segment.baseOffset&lt;br/&gt;
is still used. That is the reason if this JIRA&lt;/p&gt;</comment>
                            <comment id="15273584" author="liquanpei" created="Fri, 6 May 2016 03:27:38 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ecomar&quot; class=&quot;user-hover&quot; rel=&quot;ecomar&quot;&gt;ecomar&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=alekar&quot; class=&quot;user-hover&quot; rel=&quot;alekar&quot;&gt;alekar&lt;/a&gt; Moving the pessimistic check to the second segment will solve the issue in the JIRA, but it may not be the best performant solution, we may end up clean up the second segment in the next clean up. It seems that &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=alekar&quot; class=&quot;user-hover&quot; rel=&quot;alekar&quot;&gt;alekar&lt;/a&gt;&apos;s approach is better, so please submit a PR when it is ready. Thanks!&lt;/p&gt;</comment>
                            <comment id="15273592" author="githubbot" created="Fri, 6 May 2016 03:33:36 +0000"  >&lt;p&gt;Github user Ishiihara closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1328&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1328&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15273606" author="junrao" created="Fri, 6 May 2016 03:48:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=alekar&quot; class=&quot;user-hover&quot; rel=&quot;alekar&quot;&gt;alekar&lt;/a&gt;, I think &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ecomar&quot; class=&quot;user-hover&quot; rel=&quot;ecomar&quot;&gt;ecomar&lt;/a&gt; is suggesting a potentially better approach. You still use one map and keep adding new entries to the map until the map is full. However, in the probe phase, you only scan up to the end offset of the last full log segment that can be put into the map. The map may include some keys from a partially loaded log segment, but it shouldn&apos;t affect the correctness.&lt;/p&gt;</comment>
                            <comment id="15273626" author="alekar" created="Fri, 6 May 2016 04:40:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt; That will create the same &amp;lt;key,offset&amp;gt; pairs in cleaned segments and active segments. I guess you are saying that will not affect correctness?&lt;/p&gt;</comment>
                            <comment id="15273777" author="githubbot" created="Fri, 6 May 2016 08:07:18 +0000"  >&lt;p&gt;GitHub user alekar opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1329&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1329&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3587&quot; title=&quot;LogCleaner fails due to incorrect offset map computation on a replica&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3587&quot;&gt;&lt;del&gt;KAFKA-3587&lt;/del&gt;&lt;/a&gt; Improve logic to build offsetMap in log.Cleaner.&lt;/p&gt;



&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/alekar/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/alekar/kafka&lt;/a&gt; trunk&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1329.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1329.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #1329&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 1ec4f93656d4a67f42e90e776833a798034ace15&lt;br/&gt;
Author: Manas Alekar &amp;lt;malekar@netflix.com&amp;gt;&lt;br/&gt;
Date:   2016-05-05T23:03:26Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3587&quot; title=&quot;LogCleaner fails due to incorrect offset map computation on a replica&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3587&quot;&gt;&lt;del&gt;KAFKA-3587&lt;/del&gt;&lt;/a&gt; Improve logic to build offsetMap in Cleaner.&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15273821" author="ecomar" created="Fri, 6 May 2016 09:06:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt; I was thinking of two possible optimistic approaches (if you allow me to call &apos;pessimistic&apos; the current one &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.&lt;/p&gt;

&lt;p&gt;1 - try scanning all dirty segments without the pessimistic check; use the (only) map until full; &lt;br/&gt;
this may allow to process all dirty segment (optimism) or may happen in the middle of a dirt segment. &lt;br/&gt;
In either case, do compaction using the map loaded that way.&lt;br/&gt;
When compaction takes place, if the map became full in the mid of a segment, compaction may replace some values in the compacted segments with values that actually come from the last partially examined segment - but this should not affect correctness of consumer for the topic as the topic actually has such values for a given key and they are newer than the values contained in the compacted segments.&lt;/p&gt;

&lt;p&gt;OR&lt;/p&gt;

&lt;p&gt;2 - try scanning all dirty segments without the pessimistic check, but, if the map gets full, save as state the last segment that was fully loaded without filling the map, and restart compaction for that log, this time stopping at the segment that we now know will fit.&lt;br/&gt;
So in the unlucky case that compaction has not enough memory for processing all segments - this incurs a perf penalty.&lt;br/&gt;
But such a case is rendered less likely to happen than now for a given amount of memory, because of the optimistic use of the map.&lt;br/&gt;
If a single segment has too many different keys for the map - then that segment is not compactable - as happens now.&lt;/p&gt;</comment>
                            <comment id="15274201" author="githubbot" created="Fri, 6 May 2016 15:25:15 +0000"  >&lt;p&gt;GitHub user mimaison opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1332&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1332&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3587&quot; title=&quot;LogCleaner fails due to incorrect offset map computation on a replica&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3587&quot;&gt;&lt;del&gt;KAFKA-3587&lt;/del&gt;&lt;/a&gt;: LogCleaner fails due to incorrect offset map computation &#8230;&lt;/p&gt;

&lt;p&gt;    Removed the over pessimistic require and instead attempt to fill the dedup buffer. Use the (only) map until full;&lt;br/&gt;
    this may allow to process all dirty segment (optimism) or may happen in the middle of a dirt segment.&lt;br/&gt;
    In either case, do compaction using the map loaded that way.&lt;/p&gt;

&lt;p&gt;    This patch was developed with @edoardocomar&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/mimaison/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/mimaison/kafka&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3587&quot; title=&quot;LogCleaner fails due to incorrect offset map computation on a replica&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3587&quot;&gt;&lt;del&gt;KAFKA-3587&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1332.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1332.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #1332&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit e4f4e5ed75a845f0c4cc2b6745dc213f71affe6d&lt;br/&gt;
Author: Mickael Maison &amp;lt;mickael.maison@gmail.com&amp;gt;&lt;br/&gt;
Date:   2016-05-06T15:08:03Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3587&quot; title=&quot;LogCleaner fails due to incorrect offset map computation on a replica&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3587&quot;&gt;&lt;del&gt;KAFKA-3587&lt;/del&gt;&lt;/a&gt;: LogCleaner fails due to incorrect offset map computation on a replica&lt;/p&gt;

&lt;p&gt;    Removed the over pessimistic require and instead attempt to fill the dedup buffer. Use the (only) map until full;&lt;br/&gt;
    this may allow to process all dirty segment (optimism) or may happen in the middle of a dirt segment.&lt;br/&gt;
    In either case, do compaction using the map loaded that way.&lt;/p&gt;

&lt;p&gt;    This patch was developed with @edoardocomar&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15274204" author="ecomar" created="Fri, 6 May 2016 15:27:29 +0000"  >&lt;p&gt;For clarity, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mimaison&quot; class=&quot;user-hover&quot; rel=&quot;mimaison&quot;&gt;mimaison&lt;/a&gt; PR &lt;a href=&quot;https://github.com/apache/kafka/pull/1332&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1332&lt;/a&gt; impleemnts the 1st of the two options I mentioned in my previous comment &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3587?focusedCommentId=15273821&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15273821&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/KAFKA-3587?focusedCommentId=15273821&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15273821&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15274372" author="junrao" created="Fri, 6 May 2016 17:13:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ecomar&quot; class=&quot;user-hover&quot; rel=&quot;ecomar&quot;&gt;ecomar&lt;/a&gt;, thanks for the explanation. I am not sure about your first option. The issue is that if a segment is only partially loaded into the map and you clean the full segment, the cleaned segment may still contain messages with duplicated keys. Our current contract is that all messages in the cleaned portion of the log have no duplicated keys. If this is violated, the problem is that if there are no new messages published on those keys, those duplicated keys will never be de-duped.&lt;/p&gt;

&lt;p&gt;Your second option doesn&apos;t have this problem and is what I thought you were suggesting. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=alekar&quot; class=&quot;user-hover&quot; rel=&quot;alekar&quot;&gt;alekar&lt;/a&gt;, as long as you stop cleaning at the last segment whose keys are fully loaded into the map, you still guarantee that all cleaned portion of the log has no duplicated keys.&lt;/p&gt;</comment>
                            <comment id="15274442" author="junrao" created="Fri, 6 May 2016 17:50:16 +0000"  >&lt;p&gt;Yes, let&apos;s first agree upon the best approach on the jira.&lt;/p&gt;

&lt;p&gt;It would be really nice if we can fix this issue in 0.10.0.0. Then, ideally we should patch this by today. Anyone wants to take this on?&lt;/p&gt;</comment>
                            <comment id="15274454" author="guozhang" created="Fri, 6 May 2016 17:53:32 +0000"  >&lt;p&gt;Oops, accidentally deleted my previous comment, re-posting here: &quot;there are multiple proposals and PRs for this ticket, let&apos;s centralize our discussion on this ticket first and then move ahead to work on the PR.&quot;&lt;/p&gt;</comment>
                            <comment id="15274500" author="alekar" created="Fri, 6 May 2016 18:19:19 +0000"  >&lt;p&gt;The issue with just building the map till it is full as proposed in pull request 1332 is that the offset boundary reported by buildOffsetMap is now in the middle of a segment which has not been fully de-deuplicated. I doubt &lt;b&gt;clean&lt;/b&gt;, the way it is written works in this case.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt;[log] def clean(cleanable: LogToClean): &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; = {
...
    val endOffset = buildOffsetMap(log, cleanable.firstDirtyOffset, upperBoundOffset, offsetMap) + 1
...
    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (group &amp;lt;- groupSegmentsBySize(log.logSegments(0, endOffset), log.config.segmentSize, log.config.maxIndexSize))
      cleanSegments(log, group, offsetMap, deleteHorizonMs)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This is easily fixed by only updating the offset returned by buildOffsetMap if the map merged to segment boundary, otherwise report the last complete segment boundary. However, this leads to an interesting situation.&lt;br/&gt;
Consider,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;lt;segment0&amp;gt; (Ka, Oa) ... (Kx, O1) ... &amp;lt;/segment0&amp;gt; ... &amp;lt;/segment4&amp;gt; ... (Kx, O2) ... (Kb, Ob) ... &amp;lt;/segment4&amp;gt;&lt;br/&gt;
--------------------------------------------------------------------------------------------------------^ offsetMap fills here&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;If we continue to greedily de duplicate segments in buildOffsetMap, and offsetMap fills between Kx and Kb, we now have (kx,O2) reported in the compacted segment for &lt;em&gt;segments-1-to-3&lt;/em&gt; as well as the offsetMap for the next iteration of buildOffsetMap called at &lt;em&gt;segment4&lt;/em&gt; baseOffset.&lt;/p&gt;

&lt;p&gt;I am under the impression that this is unacceptable. Jun Rao&apos;s comment seems to indicate that this might be acceptable. If it is, this has the advantage over my pull request that SkimpyOfffsetMap.putAll is likely to suffer a lot if collision probability in the map is high. Of course, this can be fixed by switching hash algorithms, but avoiding the problem altogether would be preferable.&lt;/p&gt;</comment>
                            <comment id="15274513" author="alekar" created="Fri, 6 May 2016 18:26:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt; Like your idea, I&apos;ll wait for us to decide on what the right approach is before I fix my pull request. It is passing Units but failing Integrations right now.&lt;/p&gt;</comment>
                            <comment id="15274526" author="junrao" created="Fri, 6 May 2016 18:32:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=alekar&quot; class=&quot;user-hover&quot; rel=&quot;alekar&quot;&gt;alekar&lt;/a&gt;, note that when copying retained messages to new log segments, we only take messages from the segments being scanned, not from the map. So, in your example, let&apos;s say the map contains (Kx, O2), after cleaning segments 1-3, the new segments that replace segments 1-3 won&apos;t have (Kx, O1), which is correct. It won&apos;t have (Kx, O2) either since that message in never scanned. So,  (Kx, O2) remains only in segment 4 and will be either retained or cleaned when the next round of cleaning happens.&lt;/p&gt;</comment>
                            <comment id="15274534" author="alekar" created="Fri, 6 May 2016 18:36:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt; During cleaning the offset stored in offsetMap is from segment4 if the greedy build terminated there. Isn&apos;t that wrong?&lt;/p&gt;</comment>
                            <comment id="15274622" author="ecomar" created="Fri, 6 May 2016 19:39:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt; thanks for your observation &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3587?focusedCommentId=15274372&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15274372&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/KAFKA-3587?focusedCommentId=15274372&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15274372&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The idea for option 1 is NOT to clean the segment for which we the map was partially loaded.&lt;br/&gt;
But to clean the segments up to the one which was fully map loaded.&lt;/p&gt;

&lt;p&gt;Even if the clean would use potentially values coming from a subsequent segment, these are &quot;newer&quot; than the ones they replace and so would satisfy the contract of deduplication.&lt;/p&gt;

&lt;p&gt;This is what we implemented in &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mimaison&quot; class=&quot;user-hover&quot; rel=&quot;mimaison&quot;&gt;mimaison&lt;/a&gt; PR&lt;/p&gt;</comment>
                            <comment id="15274677" author="junrao" created="Fri, 6 May 2016 20:31:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ecomar&quot; class=&quot;user-hover&quot; rel=&quot;ecomar&quot;&gt;ecomar&lt;/a&gt;, yes, what you described matches my expectation. Now, I am not sure that I understand the difference between your option 2 and option 1. In any case, I took a look at &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mimaison&quot; class=&quot;user-hover&quot; rel=&quot;mimaison&quot;&gt;mimaison&lt;/a&gt;&apos;s patch. It looks good. I left a comment there. Would you or &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mimaison&quot; class=&quot;user-hover&quot; rel=&quot;mimaison&quot;&gt;mimaison&lt;/a&gt; be up to fixing this today?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=alekar&quot; class=&quot;user-hover&quot; rel=&quot;alekar&quot;&gt;alekar&lt;/a&gt;, yes, as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ecomar&quot; class=&quot;user-hover&quot; rel=&quot;ecomar&quot;&gt;ecomar&lt;/a&gt; explained, it&apos;s fine for the offsetMap to include newer messages that are not being cleaned in this round since the retained messages will still be correct. The only impact is that since we have loaded a partial segment into the map, we could have scanned and cleaned the partial segment. However, that&apos;s a bit harder to do since the current cleaner logic always cleans full segments.&lt;/p&gt;</comment>
                            <comment id="15274683" author="githubbot" created="Fri, 6 May 2016 20:35:34 +0000"  >&lt;p&gt;Github user alekar closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1329&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1329&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15274977" author="ecomar" created="Sat, 7 May 2016 00:29:38 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt; the difference between option 1 and option 2 is that with the latter we would guarantee that deduplication of a segment would alway retain a value that came from one of the compacted segments, while with option 1 the value might come from a &apos;later&apos; segment. &lt;br/&gt;
However option 1 as you observed, satisfies the log deduplication contract (though not the individual segment deduplication) and so it may well suffice as it&apos;s simpler and more performant.&lt;/p&gt;</comment>
                            <comment id="15275650" author="guozhang" created="Sun, 8 May 2016 18:14:23 +0000"  >&lt;p&gt;If I understand correctly, let&apos;s day the producer sends (a:1), (b:2), (c:3), (a:4), following the option 1 a consumer could possibly get  (a:4), (b:2), (c:3), (a:4).&lt;/p&gt;

&lt;p&gt;With the current at-least-once semantics this does not break the contract I think. But I do not know how that may be related to ongoing exactly-once semantics, do we actually have any guarantees for log-compacted topics?&lt;/p&gt;</comment>
                            <comment id="15275741" author="junrao" created="Sun, 8 May 2016 21:13:50 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt;, I don&apos;t think (a:4) will ever be duplicated with option 1. In each round of cleaning, the cleaner scans through every message in the log once and makes a decision on whether to keep the message or not. The cleaner never duplicates a message or replaces an existing message with a new one. It can only remove an existing message.&lt;/p&gt;</comment>
                            <comment id="15276207" author="mimaison" created="Mon, 9 May 2016 10:36:20 +0000"  >&lt;p&gt;I&apos;ve updated the PR with all your feedback: &lt;a href=&quot;https://github.com/apache/kafka/pull/1332&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1332&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15276639" author="githubbot" created="Mon, 9 May 2016 17:11:11 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1332&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1332&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15276640" author="ijuma" created="Mon, 9 May 2016 17:11:33 +0000"  >&lt;p&gt;Issue resolved by pull request 1332&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/pull/1332&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1332&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15451637" author="zmstone" created="Wed, 31 Aug 2016 08:56:39 +0000"  >&lt;p&gt;any plan to port the fix back to 0.9 ?&lt;/p&gt;</comment>
                            <comment id="15458428" author="githubbot" created="Fri, 2 Sep 2016 12:46:39 +0000"  >&lt;p&gt;GitHub user id opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1818&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1818&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Backport &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3587&quot; title=&quot;LogCleaner fails due to incorrect offset map computation on a replica&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3587&quot;&gt;&lt;del&gt;KAFKA-3587&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;



&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/klarna/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/klarna/kafka&lt;/a&gt; backport-&lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3587&quot; title=&quot;LogCleaner fails due to incorrect offset map computation on a replica&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3587&quot;&gt;&lt;del&gt;KAFKA-3587&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1818.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1818.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #1818&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit f2e99a874b30bb3b26f15348a9ac5f55dd7d700e&lt;br/&gt;
Author: Ivan Dyachkov &amp;lt;ivan.dyachkov@klarna.com&amp;gt;&lt;br/&gt;
Date:   2016-09-02T09:43:15Z&lt;/p&gt;

&lt;p&gt;    Applying &lt;a href=&quot;https://github.com/apache/kafka/pull/1332&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1332&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3587&quot; title=&quot;LogCleaner fails due to incorrect offset map computation on a replica&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3587&quot;&gt;&lt;del&gt;KAFKA-3587&lt;/del&gt;&lt;/a&gt;: LogCleaner fails due to incorrect offset map computation&lt;/p&gt;

&lt;p&gt;commit c7453a0a4a782a5c2194fb6d9d18f76034d2490e&lt;br/&gt;
Author: Ivan Dyachkov &amp;lt;ivan.dyachkov@klarna.com&amp;gt;&lt;br/&gt;
Date:   2016-09-02T11:47:33Z&lt;/p&gt;

&lt;p&gt;    fix test&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="16301904" author="githubbot" created="Fri, 22 Dec 2017 20:18:18 +0000"  >&lt;p&gt;guozhangwang closed pull request #1818: Backport &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3587&quot; title=&quot;LogCleaner fails due to incorrect offset map computation on a replica&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3587&quot;&gt;&lt;del&gt;KAFKA-3587&lt;/del&gt;&lt;/a&gt;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/1818&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1818&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/core/src/main/scala/kafka/log/LogCleaner.scala b/core/src/main/scala/kafka/log/LogCleaner.scala&lt;br/&gt;
index d5c247cab95..1fd2e3f8931 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/log/LogCleaner.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/log/LogCleaner.scala&lt;br/&gt;
@@ -575,17 +575,19 @@ private&lt;span class=&quot;error&quot;&gt;&amp;#91;log&amp;#93;&lt;/span&gt; class Cleaner(val id: Int,&lt;br/&gt;
     // but we may be able to fit more (if there is lots of duplication in the dirty section of the log)&lt;br/&gt;
     var offset = dirty.head.baseOffset&lt;br/&gt;
     require(offset == start, &quot;Last clean offset is %d but segment base offset is %d for log %s.&quot;.format(start, offset, log.name))&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val maxDesiredMapSize = (map.slots * this.dupBufferLoadFactor).toInt&lt;br/&gt;
     var full = false&lt;br/&gt;
     for (segment &amp;lt;- dirty if !full) {&lt;br/&gt;
       checkDone(log.topicAndPartition)&lt;/li&gt;
	&lt;li&gt;val segmentSize = segment.nextOffset() - segment.baseOffset&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;require(segmentSize &amp;lt;= maxDesiredMapSize, &quot;%d messages in segment %s/%s but offset map can fit only %d. You can increase log.cleaner.dedupe.buffer.size or decrease log.cleaner.threads&quot;.format(segmentSize,  log.name, segment.log.file.getName, maxDesiredMapSize))&lt;/li&gt;
	&lt;li&gt;if (map.size + segmentSize &amp;lt;= maxDesiredMapSize)&lt;/li&gt;
	&lt;li&gt;offset = buildOffsetMapForSegment(log.topicAndPartition, segment, map)&lt;/li&gt;
	&lt;li&gt;else&lt;br/&gt;
+      val newOffset = buildOffsetMapForSegment(log.topicAndPartition, segment, map)&lt;br/&gt;
+      if (newOffset &amp;gt; -1L)&lt;br/&gt;
+        offset = newOffset&lt;br/&gt;
+      else 
{
+        // If not even one segment can fit in the map, compaction cannot happen
+        require(offset &amp;gt; start, &quot;Unable to build the offset map for segment %s/%s. You can increase log.cleaner.dedupe.buffer.size or decrease log.cleaner.threads&quot;.format(log.name, segment.log.file.getName))
+        debug(&quot;Offset map is full, %d segments fully mapped, segment with base offset %d is partially mapped&quot;.format(dirty.indexOf(segment), segment.baseOffset))
         full = true
+      }
&lt;p&gt;     }&lt;br/&gt;
     info(&quot;Offset map for log %s complete.&quot;.format(log.name))&lt;br/&gt;
     offset&lt;br/&gt;
@@ -597,11 +599,12 @@ private&lt;span class=&quot;error&quot;&gt;&amp;#91;log&amp;#93;&lt;/span&gt; class Cleaner(val id: Int,&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param segment The segment to index&lt;/li&gt;
	&lt;li&gt;@param map The map in which to store the key=&amp;gt;offset mapping&lt;br/&gt;
    *&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* @return The final offset covered by the map&lt;br/&gt;
+   * @return The final offset covered by the map or -1 if the map is full&lt;br/&gt;
    */&lt;br/&gt;
   private def buildOffsetMapForSegment(topicAndPartition: TopicAndPartition, segment: LogSegment, map: OffsetMap): Long = {&lt;br/&gt;
     var position = 0&lt;br/&gt;
     var offset = segment.baseOffset&lt;br/&gt;
+    val maxDesiredMapSize = (map.slots * this.dupBufferLoadFactor).toInt&lt;br/&gt;
     while (position &amp;lt; segment.log.sizeInBytes) {&lt;br/&gt;
       checkDone(topicAndPartition)&lt;br/&gt;
       readBuffer.clear()&lt;br/&gt;
@@ -610,8 +613,14 @@ private&lt;span class=&quot;error&quot;&gt;&amp;#91;log&amp;#93;&lt;/span&gt; class Cleaner(val id: Int,&lt;br/&gt;
       val startPosition = position&lt;br/&gt;
       for (entry &amp;lt;- messages) {&lt;br/&gt;
         val message = entry.message&lt;/li&gt;
	&lt;li&gt;if (message.hasKey)&lt;/li&gt;
	&lt;li&gt;map.put(message.key, entry.offset)&lt;br/&gt;
+        if (message.hasKey) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+          if (map.size &amp;lt; maxDesiredMapSize)+            map.put(message.key, entry.offset)+          else {
+            // The map is full, stop looping and return
+            return -1L
+          }+        }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;         offset = entry.offset&lt;br/&gt;
         stats.indexMessagesRead(1)&lt;br/&gt;
       }&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/log/CleanerTest.scala b/core/src/test/scala/unit/kafka/log/CleanerTest.scala&lt;br/&gt;
index 8ab9f91e82d..6d8a7bad227 100755&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/test/scala/unit/kafka/log/CleanerTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/log/CleanerTest.scala&lt;br/&gt;
@@ -422,8 +422,33 @@ class CleanerTest extends JUnitSuite 
{
     recoverAndCheck(config, cleanedKeys)
     
   }&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;&lt;/li&gt;
	&lt;li&gt;&lt;p&gt;+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  def testBuildOffsetMapFakeLarge() &lt;/p&gt;
{
+    val map = new FakeOffsetMap(1000)
+    val logProps = new Properties()
+    logProps.put(LogConfig.SegmentBytesProp, 72: java.lang.Integer)
+    logProps.put(LogConfig.SegmentIndexBytesProp, 72: java.lang.Integer)
+    logProps.put(LogConfig.CleanupPolicyProp, LogConfig.Compact)
+    val logConfig = LogConfig(logProps)
+    val log = makeLog(config = logConfig)
+    val cleaner = makeCleaner(Int.MaxValue)
+    val start = 0
+    val end = 2
+    val offsetSeq = Seq(0L, 7206178L)
+    writeToLog(log, (start until end) zip (start until end), offsetSeq)
+    val endOffset = cleaner.buildOffsetMap(log, start, end, map)
+    assertEquals(&quot;Last offset should be the end offset.&quot;, 7206178L, endOffset)
+    assertEquals(&quot;Should have the expected number of messages in the map.&quot;, end - start, map.size)
+    assertEquals(&quot;Map should contain first value&quot;, 0L, map.get(key(0)))
+    assertEquals(&quot;Map should contain second value&quot;, 7206178L, map.get(key(1)))
+  }
&lt;p&gt;+&lt;br/&gt;
+  private def writeToLog(log: Log, keysAndValues: Iterable&lt;span class=&quot;error&quot;&gt;&amp;#91;(Int, Int)&amp;#93;&lt;/span&gt;, offsetSeq: Iterable&lt;span class=&quot;error&quot;&gt;&amp;#91;Long&amp;#93;&lt;/span&gt;): Iterable&lt;span class=&quot;error&quot;&gt;&amp;#91;Long&amp;#93;&lt;/span&gt; = &lt;/p&gt;
{
+    for(((key, value), offset) &amp;lt;- keysAndValues.zip(offsetSeq))
+      yield log.append(messageWithOffset(key, value, offset), assignOffsets = false).firstOffset
+  }
&lt;p&gt;+&lt;br/&gt;
   def makeLog(dir: File = dir, config: LogConfig = logConfig) =&lt;br/&gt;
     new Log(dir = dir, config = config, recoveryPoint = 0L, scheduler = time.scheduler, time = time)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -449,6 +474,10 @@ class CleanerTest extends JUnitSuite {&lt;br/&gt;
   def message(key: Int, value: Int) = &lt;br/&gt;
     new ByteBufferMessageSet(new Message(key=key.toString.getBytes, bytes=value.toString.getBytes))&lt;/p&gt;

&lt;p&gt;+  def messageWithOffset(key: Int, value: Int, offset: Long) = &lt;br/&gt;
+    new ByteBufferMessageSet(NoCompressionCodec, new AtomicLong(offset),&lt;br/&gt;
+      new Message(key=key.toString.getBytes, bytes=value.toString.getBytes))&lt;br/&gt;
+&lt;br/&gt;
   def unkeyedMessage(value: Int) =&lt;br/&gt;
     new ByteBufferMessageSet(new Message(bytes=value.toString.getBytes))&lt;/p&gt;

&lt;p&gt;@@ -478,4 +507,4 @@ class FakeOffsetMap(val slots: Int) extends OffsetMap &lt;/p&gt;
{
   
   def size: Int = map.size
   
-}
&lt;p&gt;\ No newline at end of file&lt;br/&gt;
+}&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12834338">KAFKA-2235</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12841039">KAFKA-2303</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12802561" name="0001-POC-improving-deduping-segments.patch" size="9332" author="alekar" created="Thu, 5 May 2016 23:09:10 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 47 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2wc0f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>junrao</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>