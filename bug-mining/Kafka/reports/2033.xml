<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:14:10 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6859] Follower should not send OffsetForLeaderEpoch for undefined leader epochs</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6859</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;This is more of an optimization, rather than correctness.&lt;/p&gt;

&lt;p&gt;Currently, if the follower on inter broker protocol version 0.11 and higher,&#160;but on older message format, it does not track leader epochs. However, will still send OffsetForLeaderEpoch request to the leader with undefined epoch which is guaranteed to return undefined offset, so that the follower truncated to high watermark. Another example is a bootstrapping follower that does not have any leader epochs recorded,&#160;&lt;/p&gt;

&lt;p&gt;It is cleaner and more efficient to not send OffsetForLeaderEpoch requests to the follower with undefined leader epochs, since we already know the answer.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13157017">KAFKA-6859</key>
            <summary>Follower should not send OffsetForLeaderEpoch for undefined leader epochs</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="enether">Stanislav Kozlovski</assignee>
                                    <reporter username="apovzner">Anna Povzner</reporter>
                        <labels>
                    </labels>
                <created>Fri, 4 May 2018 01:03:27 +0000</created>
                <updated>Fri, 31 Aug 2018 00:05:32 +0000</updated>
                            <resolved>Fri, 31 Aug 2018 00:05:32 +0000</resolved>
                                    <version>0.11.0.0</version>
                                    <fixVersion>2.1.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="16529868" author="githubbot" created="Mon, 2 Jul 2018 13:19:20 +0000"  >&lt;p&gt;stanislavkozlovski opened a new pull request #5320: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6859&quot; title=&quot;Follower should not send OffsetForLeaderEpoch for undefined leader epochs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6859&quot;&gt;&lt;del&gt;KAFKA-6859&lt;/del&gt;&lt;/a&gt;: Do not send LeaderEpochRequest for undefined leader epochs&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5320&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5320&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   If a broker or topic has a message format &amp;lt; 0.11, he does not track leader epochs. LeaderEpochRequests for such will always return undefined, making the follower truncate to the highest watermark. Since there is no use to use the network for such cases, don&apos;t send a request.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Notes&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
	&lt;li&gt;I am not sure whether we should even check `brokerConfig.interBrokerProtocolVersion &amp;gt;= KAFKA_0_11_0_IV2`, since log message format is the only thing we care about and as far as I understand it is always defined&lt;/li&gt;
	&lt;li&gt;I am not fond of the subclassing in the tests for mocking the method (and also making it protected) but this was the cleanest solution I could come up with. Other ideas are welcome&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16598061" author="githubbot" created="Fri, 31 Aug 2018 00:04:31 +0000"  >&lt;p&gt;hachikuji closed pull request #5320: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6859&quot; title=&quot;Follower should not send OffsetForLeaderEpoch for undefined leader epochs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6859&quot;&gt;&lt;del&gt;KAFKA-6859&lt;/del&gt;&lt;/a&gt;: Do not send LeaderEpochRequest for undefined leader epochs&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5320&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5320&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/core/src/main/scala/kafka/log/LogSegment.scala b/core/src/main/scala/kafka/log/LogSegment.scala&lt;br/&gt;
index 0b7167087d1..0c00e5588f2 100755&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/log/LogSegment.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/log/LogSegment.scala&lt;br/&gt;
@@ -358,7 +358,7 @@ class LogSegment private&lt;span class=&quot;error&quot;&gt;&amp;#91;log&amp;#93;&lt;/span&gt; (val log: FileRecords,&lt;/p&gt;

&lt;p&gt;         if (batch.magic &amp;gt;= RecordBatch.MAGIC_VALUE_V2) {&lt;br/&gt;
           leaderEpochCache.foreach &lt;/p&gt;
{ cache =&amp;gt;
-            if (batch.partitionLeaderEpoch &amp;gt; cache.latestEpoch()) // this is to avoid unnecessary warning in cache.assign()
+            if (batch.partitionLeaderEpoch &amp;gt; cache.latestEpoch) // this is to avoid unnecessary warning in cache.assign()
               cache.assign(batch.partitionLeaderEpoch, batch.baseOffset)
           }
&lt;p&gt;           updateProducerState(producerStateManager, batch)&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/server/ReplicaAlterLogDirsThread.scala b/core/src/main/scala/kafka/server/ReplicaAlterLogDirsThread.scala&lt;br/&gt;
index 08c4a17f2d7..05dc3566c03 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/server/ReplicaAlterLogDirsThread.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/server/ReplicaAlterLogDirsThread.scala&lt;br/&gt;
@@ -147,7 +147,7 @@ class ReplicaAlterLogDirsThread(name: String,&lt;/p&gt;

&lt;p&gt;     val (partitionsWithEpoch, partitionsWithoutEpoch) = partitionEpochOpts.partition &lt;/p&gt;
{ case (_, epochCacheOpt) =&amp;gt; epochCacheOpt.nonEmpty }&lt;br/&gt;
 &lt;br/&gt;
-    val result = partitionsWithEpoch.map { case (tp, epochCacheOpt) =&amp;gt; tp -&amp;gt; epochCacheOpt.get.latestEpoch() }&lt;br/&gt;
+    val result = partitionsWithEpoch.map { case (tp, epochCacheOpt) =&amp;gt; tp -&amp;gt; epochCacheOpt.get.latestEpoch }&lt;br/&gt;
     ResultWithPartitions(result, partitionsWithoutEpoch.keys.toSet)&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
diff --git a/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala b/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala&lt;br/&gt;
index 56335a62b60..3b1a54f3bb1 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/server/ReplicaFetcherThread.scala&lt;br/&gt;
@@ -95,7 +95,8 @@ class ReplicaFetcherThread(name: String,&lt;br/&gt;
   private val minBytes = brokerConfig.replicaFetchMinBytes&lt;br/&gt;
   private val maxBytes = brokerConfig.replicaFetchResponseMaxBytes&lt;br/&gt;
   private val fetchSize = brokerConfig.replicaFetchMaxBytes&lt;br/&gt;
-  private val shouldSendLeaderEpochRequest: Boolean = brokerConfig.interBrokerProtocolVersion &amp;gt;= KAFKA_0_11_0_IV2&lt;br/&gt;
+  private val brokerSupportsLeaderEpochRequest: Boolean = brokerConfig.interBrokerProtocolVersion &amp;gt;= KAFKA_0_11_0_IV2&lt;br/&gt;
+&lt;br/&gt;
   private val fetchSessionHandler = new FetchSessionHandler(logContext, sourceBroker.id)&lt;br/&gt;
 &lt;br/&gt;
   private def epochCacheOpt(tp: TopicPartition): Option&lt;span class=&quot;error&quot;&gt;&amp;#91;LeaderEpochCache&amp;#93;&lt;/span&gt; =  replicaMgr.getReplica(tp).map(_.epochs.get)&lt;br/&gt;
@@ -346,19 +347,29 @@ class ReplicaFetcherThread(name: String,&lt;br/&gt;
     val (partitionsWithEpoch, partitionsWithoutEpoch) = partitionEpochOpts.partition { case (_, epochCacheOpt) =&amp;gt; epochCacheOpt.nonEmpty }

&lt;p&gt;     debug(s&quot;Build leaderEpoch request $partitionsWithEpoch&quot;)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val result = partitionsWithEpoch.map 
{ case (tp, epochCacheOpt) =&amp;gt; tp -&amp;gt; epochCacheOpt.get.latestEpoch() }
&lt;p&gt;+    val result = partitionsWithEpoch.map &lt;/p&gt;
{ case (tp, epochCacheOpt) =&amp;gt; tp -&amp;gt; epochCacheOpt.get.latestEpoch }
&lt;p&gt;     ResultWithPartitions(result, partitionsWithoutEpoch.keys.toSet)&lt;br/&gt;
   }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   override def fetchEpochsFromLeader(partitions: Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, Int&amp;#93;&lt;/span&gt;): Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, EpochEndOffset&amp;#93;&lt;/span&gt; = {&lt;br/&gt;
     var result: Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, EpochEndOffset&amp;#93;&lt;/span&gt; = null&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (shouldSendLeaderEpochRequest) {&lt;/li&gt;
	&lt;li&gt;val partitionsAsJava = partitions.map 
{ case (tp, epoch) =&amp;gt; tp -&amp;gt; epoch.asInstanceOf[Integer] }.toMap.asJava&lt;br/&gt;
+    if (brokerSupportsLeaderEpochRequest) {&lt;br/&gt;
+      // skip request for partitions without epoch, as their topic log message format doesn&apos;t support epochs&lt;br/&gt;
+      val (partitionsWithEpoch, partitionsWithoutEpoch) = partitions.partition { case (_, epoch) =&amp;gt; epoch != UNDEFINED_EPOCH }&lt;br/&gt;
+      val resultWithoutEpoch = partitionsWithoutEpoch.map { case (tp, _) =&amp;gt; (tp, new EpochEndOffset(Errors.NONE, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)) }&lt;br/&gt;
+&lt;br/&gt;
+      if (partitionsWithEpoch.isEmpty) {
+        debug(&quot;Skipping leaderEpoch request since all partitions do not have an epoch&quot;)
+        return resultWithoutEpoch
+      }&lt;br/&gt;
+&lt;br/&gt;
+      val partitionsAsJava = partitionsWithEpoch.map { case (tp, epoch) =&amp;gt; tp -&amp;gt; epoch.asInstanceOf[Integer] }
&lt;p&gt;.toMap.asJava&lt;br/&gt;
       val epochRequest = new OffsetsForLeaderEpochRequest.Builder(offsetForLeaderEpochRequestVersion, partitionsAsJava)&lt;br/&gt;
       try {&lt;br/&gt;
         val response = leaderEndpoint.sendRequest(epochRequest)&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;result = response.responseBody.asInstanceOf&lt;span class=&quot;error&quot;&gt;&amp;#91;OffsetsForLeaderEpochResponse&amp;#93;&lt;/span&gt;.responses.asScala&lt;/li&gt;
	&lt;li&gt;debug(s&quot;Receive leaderEpoch response $result&quot;)&lt;br/&gt;
+&lt;br/&gt;
+        result = response.responseBody.asInstanceOf&lt;span class=&quot;error&quot;&gt;&amp;#91;OffsetsForLeaderEpochResponse&amp;#93;&lt;/span&gt;.responses.asScala ++ resultWithoutEpoch&lt;br/&gt;
+        debug(s&quot;Receive leaderEpoch response $result; Skipped request for partitions ${partitionsWithoutEpoch.keys}&quot;)&lt;br/&gt;
       } catch {&lt;br/&gt;
         case t: Throwable =&amp;gt;&lt;br/&gt;
           warn(s&quot;Error when sending leader epoch request for $partitions&quot;, t)&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/server/epoch/LeaderEpochFileCache.scala b/core/src/main/scala/kafka/server/epoch/LeaderEpochFileCache.scala&lt;br/&gt;
index 23a53056f32..88f5d6bd8e3 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/main/scala/kafka/server/epoch/LeaderEpochFileCache.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/server/epoch/LeaderEpochFileCache.scala&lt;br/&gt;
@@ -28,7 +28,7 @@ import scala.collection.mutable.ListBuffer&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; trait LeaderEpochCache {&lt;br/&gt;
   def assign(leaderEpoch: Int, offset: Long)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def latestEpoch(): Int&lt;br/&gt;
+  def latestEpoch: Int&lt;br/&gt;
   def endOffsetFor(epoch: Int): (Int, Long)&lt;br/&gt;
   def clearAndFlushLatest(offset: Long)&lt;br/&gt;
   def clearAndFlushEarliest(offset: Long)&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/server/ReplicaFetcherThreadTest.scala b/core/src/test/scala/unit/kafka/server/ReplicaFetcherThreadTest.scala&lt;br/&gt;
index fbf77404b02..9c759cebc3f 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/test/scala/unit/kafka/server/ReplicaFetcherThreadTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/server/ReplicaFetcherThreadTest.scala&lt;br/&gt;
@@ -23,7 +23,9 @@ import kafka.server.QuotaFactory.UnboundedQuota&lt;br/&gt;
 import kafka.server.epoch.LeaderEpochCache&lt;br/&gt;
 import kafka.server.epoch.util.ReplicaFetcherMockBlockingSend&lt;br/&gt;
 import kafka.utils.TestUtils&lt;br/&gt;
+import org.apache.kafka.clients.ClientResponse&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition&lt;br/&gt;
+import org.apache.kafka.common.internals.PartitionStates&lt;br/&gt;
 import org.apache.kafka.common.metrics.Metrics&lt;br/&gt;
 import org.apache.kafka.common.protocol.
{ApiKeys, Errors}
&lt;p&gt; import org.apache.kafka.common.protocol.Errors._&lt;br/&gt;
@@ -31,7 +33,7 @@ import org.apache.kafka.common.requests.EpochEndOffset&lt;br/&gt;
 import org.apache.kafka.common.requests.EpochEndOffset._&lt;br/&gt;
 import org.apache.kafka.common.utils.SystemTime&lt;br/&gt;
 import org.easymock.EasyMock._&lt;br/&gt;
-import org.easymock.&lt;/p&gt;
{Capture, CaptureType}
&lt;p&gt;+import org.easymock.&lt;/p&gt;
{Capture, CaptureType, IAnswer}
&lt;p&gt; import org.junit.Assert._&lt;br/&gt;
 import org.junit.Test&lt;/p&gt;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -44,6 +46,7 @@ class ReplicaFetcherThreadTest {&lt;br/&gt;
   private val t1p1 = new TopicPartition(&quot;topic1&quot;, 1)&lt;br/&gt;
   private val t2p1 = new TopicPartition(&quot;topic2&quot;, 1)&lt;/p&gt;

&lt;p&gt;+  private var toFail = false&lt;br/&gt;
   private val brokerEndPoint = new BrokerEndPoint(0, &quot;localhost&quot;, 1000)&lt;/p&gt;

&lt;p&gt;   @Test&lt;br/&gt;
@@ -71,6 +74,14 @@ class ReplicaFetcherThreadTest {&lt;br/&gt;
     props.put(KafkaConfig.InterBrokerProtocolVersionProp, &quot;0.10.2&quot;)&lt;br/&gt;
     props.put(KafkaConfig.LogMessageFormatVersionProp, &quot;0.10.2&quot;)&lt;br/&gt;
     val config = KafkaConfig.fromProps(props)&lt;br/&gt;
+    val leaderEndpoint = createMock(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;BlockingSend&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+    expect(leaderEndpoint.sendRequest(anyObject())).andAnswer(new IAnswer&lt;span class=&quot;error&quot;&gt;&amp;#91;ClientResponse&amp;#93;&lt;/span&gt; {&lt;br/&gt;
+      override def answer(): ClientResponse = &lt;/p&gt;
{
+        toFail = true // assert no leader request is sent
+        createMock(classOf[ClientResponse])
+      }&lt;br/&gt;
+    })&lt;br/&gt;
+    replay(leaderEndpoint)&lt;br/&gt;
     val thread = new ReplicaFetcherThread(&lt;br/&gt;
       name = &quot;bob&quot;,&lt;br/&gt;
       fetcherId = 0,&lt;br/&gt;
@@ -89,9 +100,148 @@ class ReplicaFetcherThreadTest {
       t1p1 -&amp;gt; new EpochEndOffset(Errors.NONE, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)
     )
 
+    assertFalse(&quot;Leader request should not have been sent&quot;, toFail)
+    assertEquals(&quot;results from leader epoch request should have undefined offset&quot;, expected, result)
+  }&lt;br/&gt;
+&lt;br/&gt;
+  /**&lt;br/&gt;
+    * If a partition doesn&apos;t have an epoch in the cache, this means it either&lt;br/&gt;
+    *   does not support epochs (log message format below 0.11) or it is a bootstrapping follower.&lt;br/&gt;
+    *&lt;br/&gt;
+    * In both cases, the partition has an undefined epoch&lt;br/&gt;
+    *   and there is no use to send the request, as we know the broker will answer with that epoch&lt;br/&gt;
+    */&lt;br/&gt;
+  @Test&lt;br/&gt;
+  def shouldNotSendEpochRequestIfLastEpochUndefinedForAllPartitions(): Unit = {&lt;br/&gt;
+    val props = TestUtils.createBrokerConfig(1, &quot;localhost:1234&quot;)&lt;br/&gt;
+    props.put(KafkaConfig.InterBrokerProtocolVersionProp, &quot;1.0.0&quot;)&lt;br/&gt;
+    val config = KafkaConfig.fromProps(props)&lt;br/&gt;
+    val leaderEndpoint = createMock(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;BlockingSend&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+&lt;br/&gt;
+    expect(leaderEndpoint.sendRequest(anyObject())).andAnswer(new IAnswer&lt;span class=&quot;error&quot;&gt;&amp;#91;ClientResponse&amp;#93;&lt;/span&gt; {&lt;br/&gt;
+      override def answer(): ClientResponse = {+        toFail = true // assert no leader request is sent+        createMock(classOf[ClientResponse])+      }
&lt;p&gt;+    })&lt;br/&gt;
+    replay(leaderEndpoint)&lt;br/&gt;
+    val thread = new ReplicaFetcherThread(&lt;br/&gt;
+      name = &quot;bob&quot;,&lt;br/&gt;
+      fetcherId = 0,&lt;br/&gt;
+      sourceBroker = brokerEndPoint,&lt;br/&gt;
+      brokerConfig = config,&lt;br/&gt;
+      replicaMgr = null,&lt;br/&gt;
+      metrics =  new Metrics(),&lt;br/&gt;
+      time = new SystemTime(),&lt;br/&gt;
+      quota = null,&lt;br/&gt;
+      leaderEndpointBlockingSend = Some(leaderEndpoint))&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
+    val result = thread.fetchEpochsFromLeader(Map(t1p0 -&amp;gt; UNDEFINED_EPOCH, t1p1 -&amp;gt; UNDEFINED_EPOCH))&lt;br/&gt;
+&lt;br/&gt;
+    val expected = Map(&lt;br/&gt;
+      t1p0 -&amp;gt; new EpochEndOffset(Errors.NONE, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET),&lt;br/&gt;
+      t1p1 -&amp;gt; new EpochEndOffset(Errors.NONE, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)&lt;br/&gt;
+    )&lt;br/&gt;
+&lt;br/&gt;
+    assertFalse(&quot;Leader request should not have been sent&quot;, toFail)&lt;br/&gt;
     assertEquals(&quot;results from leader epoch request should have undefined offset&quot;, expected, result)&lt;br/&gt;
   }&lt;/p&gt;

&lt;p&gt;+  @Test&lt;br/&gt;
+  def shouldFetchLeaderEpochRequestIfLastEpochDefinedForSomePartitions(): Unit = &lt;/p&gt;
{
+    val config = KafkaConfig.fromProps(TestUtils.createBrokerConfig(1, &quot;localhost:1234&quot;))
+
+    //Setup all dependencies
+    val quota = createNiceMock(classOf[ReplicationQuotaManager])
+    val leaderEpochs = createNiceMock(classOf[LeaderEpochCache])
+    val logManager = createMock(classOf[LogManager])
+    val replicaAlterLogDirsManager = createMock(classOf[ReplicaAlterLogDirsManager])
+    val replica = createNiceMock(classOf[Replica])
+    val partition = createMock(classOf[Partition])
+    val replicaManager = createMock(classOf[ReplicaManager])
+
+    val leaderEpoch = 5
+
+    //Stubs
+    expect(replica.epochs).andReturn(Some(leaderEpochs)).anyTimes()
+    expect(replica.logEndOffset).andReturn(new LogOffsetMetadata(0)).anyTimes()
+    expect(replica.highWatermark).andReturn(new LogOffsetMetadata(0)).anyTimes()
+    expect(leaderEpochs.latestEpoch).andReturn(leaderEpoch).once()
+    expect(leaderEpochs.latestEpoch).andReturn(leaderEpoch).once()
+    expect(leaderEpochs.latestEpoch).andReturn(UNDEFINED_EPOCH).once()  // t2p1 doesnt support epochs
+    expect(leaderEpochs.endOffsetFor(leaderEpoch)).andReturn((leaderEpoch, 0)).anyTimes()
+    expect(replicaManager.logManager).andReturn(logManager).anyTimes()
+    expect(replicaManager.replicaAlterLogDirsManager).andReturn(replicaAlterLogDirsManager).anyTimes()
+    stub(replica, partition, replicaManager)
+
+    //Expectations
+    expect(partition.truncateTo(anyLong(), anyBoolean())).once
+
+    replay(leaderEpochs, replicaManager, logManager, quota, replica)
+
+    //Define the offsets for the OffsetsForLeaderEpochResponse
+    val offsets = Map(t1p0 -&amp;gt; new EpochEndOffset(leaderEpoch, 1),
+      t1p1 -&amp;gt; new EpochEndOffset(leaderEpoch, 1),
+      t2p1 -&amp;gt; new EpochEndOffset(-1, 1)).asJava
+
+    //Create the fetcher thread
+    val mockNetwork = new ReplicaFetcherMockBlockingSend(offsets, brokerEndPoint, new SystemTime())
+
+    val thread = new ReplicaFetcherThread(&quot;bob&quot;, 0, brokerEndPoint, config, replicaManager, new Metrics(), new SystemTime(), quota, Some(mockNetwork))
+
+    // topic 1 supports epoch, t2 doesn&apos;t
+    thread.addPartitions(Map(t1p0 -&amp;gt; 0, t1p1 -&amp;gt; 0, t2p1 -&amp;gt; 0))
+
+    assertPartitionStates(thread.partitionStates, shouldBeReadyForFetch = false, shouldBeTruncatingLog = true, shouldBeDelayed = false)
+    //Loop 1
+    thread.doWork()
+    assertEquals(1, mockNetwork.epochFetchCount)
+    assertEquals(1, mockNetwork.fetchCount)
+
+    assertPartitionStates(thread.partitionStates, shouldBeReadyForFetch = true, shouldBeTruncatingLog = false, shouldBeDelayed = false)
+
+    //Loop 2 we should not fetch epochs
+    thread.doWork()
+    assertEquals(1, mockNetwork.epochFetchCount)
+    assertEquals(2, mockNetwork.fetchCount)
+
+    assertPartitionStates(thread.partitionStates, shouldBeReadyForFetch = true, shouldBeTruncatingLog = false, shouldBeDelayed = false)
+
+    //Loop 3 we should not fetch epochs
+    thread.doWork()
+    assertEquals(1, mockNetwork.epochFetchCount)
+    assertEquals(3, mockNetwork.fetchCount)
+
+    assertPartitionStates(thread.partitionStates, shouldBeReadyForFetch = true, shouldBeTruncatingLog = false, shouldBeDelayed = false)
+
+    //Assert that truncate to is called exactly once (despite two loops)
+    verify(logManager)
+  }
&lt;p&gt;+&lt;br/&gt;
+  /**&lt;br/&gt;
+    * Assert that all partitions&apos; states are as expected&lt;br/&gt;
+    *&lt;br/&gt;
+    */&lt;br/&gt;
+  def assertPartitionStates(states: PartitionStates&lt;span class=&quot;error&quot;&gt;&amp;#91;PartitionFetchState&amp;#93;&lt;/span&gt;, shouldBeReadyForFetch: Boolean,&lt;br/&gt;
+                            shouldBeTruncatingLog: Boolean, shouldBeDelayed: Boolean): Unit = {&lt;br/&gt;
+    for (tp &amp;lt;- List(t1p0, t1p1, t2p1)) {&lt;br/&gt;
+      assertEquals(&lt;br/&gt;
+        s&quot;Partition $tp should${if (!shouldBeReadyForFetch) &quot; NOT&quot; else &quot;&quot;} be ready for fetching&quot;,&lt;br/&gt;
+        shouldBeReadyForFetch, states.stateValue(tp).isReadyForFetch)&lt;br/&gt;
+&lt;br/&gt;
+      assertEquals(&lt;br/&gt;
+        s&quot;Partition $tp should${if (!shouldBeTruncatingLog) &quot; NOT&quot; else &quot;&quot;} be truncating its log&quot;,&lt;br/&gt;
+        shouldBeTruncatingLog,&lt;br/&gt;
+        states.stateValue(tp).isTruncatingLog)&lt;br/&gt;
+&lt;br/&gt;
+      assertEquals(&lt;br/&gt;
+        s&quot;Partition $tp should${if (!shouldBeDelayed) &quot; NOT&quot; else &quot;&quot;} be delayed&quot;,&lt;br/&gt;
+        shouldBeDelayed,&lt;br/&gt;
+        states.stateValue(tp).isDelayed)&lt;br/&gt;
+    }&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
   @Test&lt;br/&gt;
   def shouldHandleExceptionFromBlockingSend(): Unit = {&lt;br/&gt;
     val props = TestUtils.createBrokerConfig(1, &quot;localhost:1234&quot;)&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/server/ReplicaManagerTest.scala b/core/src/test/scala/unit/kafka/server/ReplicaManagerTest.scala&lt;br/&gt;
index 171bcf3528c..41564a54b05 100644&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/server/ReplicaManagerTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/server/ReplicaManagerTest.scala&lt;br/&gt;
@@ -625,7 +625,7 @@ class ReplicaManagerTest {&lt;br/&gt;
     val mockBrokerTopicStats = new BrokerTopicStats&lt;br/&gt;
     val mockLogDirFailureChannel = new LogDirFailureChannel(config.logDirs.size)&lt;br/&gt;
     val mockLeaderEpochCache = EasyMock.createMock(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;LeaderEpochCache&amp;#93;&lt;/span&gt;)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;EasyMock.expect(mockLeaderEpochCache.latestEpoch()).andReturn(leaderEpochFromLeader)&lt;br/&gt;
+    EasyMock.expect(mockLeaderEpochCache.latestEpoch).andReturn(leaderEpochFromLeader)&lt;br/&gt;
     EasyMock.expect(mockLeaderEpochCache.endOffsetFor(leaderEpochFromLeader))&lt;br/&gt;
       .andReturn((leaderEpochFromLeader, localLogOffset))&lt;br/&gt;
     EasyMock.replay(mockLeaderEpochCache)&lt;/li&gt;
&lt;/ul&gt;





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 11 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3tbun:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>