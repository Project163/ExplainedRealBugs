<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:06:37 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6504] Connect: Some per-task-metrics not working</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6504</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Some Kafka-Connect-metrics seems to be wrong with respect to per-task - at least it seems like MBean &quot;kafka.connect:type=source-task-metrics,connector=&amp;lt;connector-name&amp;gt;,task=x&quot; attribute &quot;source-record-active-count&quot; reports the same number for all x tasks running in the same Kafka-Connect instance/JVM. E.g. if I have a source-connector &quot;my-connector&quot; with 2 tasks that both run in the same Kafka-Connect instance, but I know that only one of them actually produces anything (and therefore can have &quot;active source-records&quot;) both &quot;kafka.connect:type=source-task-metrics,connector=my-connector,task=0&quot; and &quot;kafka.connect:type=source-task-metrics,connector=my-connector,task=1&quot; goes up (following each other). It should only go up for the one task that actually produces something.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13134770">KAFKA-6504</key>
            <summary>Connect: Some per-task-metrics not working</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rayokota">Robert Yokota</assignee>
                                    <reporter username="steff1193">Per Steffensen</reporter>
                        <labels>
                    </labels>
                <created>Tue, 30 Jan 2018 14:26:14 +0000</created>
                <updated>Mon, 12 Feb 2018 17:20:39 +0000</updated>
                            <resolved>Thu, 8 Feb 2018 16:35:56 +0000</resolved>
                                    <version>1.0.0</version>
                                    <fixVersion>1.0.1</fixVersion>
                    <fixVersion>1.1.0</fixVersion>
                                    <component>connect</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16349545" author="githubbot" created="Fri, 2 Feb 2018 00:02:40 +0000"  >&lt;p&gt;rayokota opened a new pull request #4514: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6504&quot; title=&quot;Connect: Some per-task-metrics not working&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6504&quot;&gt;&lt;del&gt;KAFKA-6504&lt;/del&gt;&lt;/a&gt;: Fix source task metric caused by copy-paste error&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4514&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4514&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   This is a simple change to correct &quot;sink-active-record-count&quot; with &quot;source-active-record-count&quot; for the &lt;/p&gt;


&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16354172" author="githubbot" created="Tue, 6 Feb 2018 17:18:41 +0000"  >&lt;p&gt;hachikuji closed pull request #4514: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6504&quot; title=&quot;Connect: Some per-task-metrics not working&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6504&quot;&gt;&lt;del&gt;KAFKA-6504&lt;/del&gt;&lt;/a&gt;: Fix creation of a sensor to be specific to a metric group so it is not shared&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4514&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4514&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java&lt;br/&gt;
index 69614948147..4ee8ad6a808 100644&lt;br/&gt;
&amp;#8212; a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java&lt;br/&gt;
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java&lt;br/&gt;
@@ -677,34 +677,34 @@ public SinkTaskMetricsGroup(ConnectorTaskId id, ConnectMetrics connectMetrics) &lt;/p&gt;
{
             // prevent collisions by removing any previously created metrics in this group.
             metricGroup.close();
 
-            sinkRecordRead = metricGroup.metrics().sensor(&quot;sink-record-read&quot;);
+            sinkRecordRead = metricGroup.sensor(&quot;sink-record-read&quot;);
             sinkRecordRead.add(metricGroup.metricName(registry.sinkRecordReadRate), new Rate());
             sinkRecordRead.add(metricGroup.metricName(registry.sinkRecordReadTotal), new Total());
 
-            sinkRecordSend = metricGroup.metrics().sensor(&quot;sink-record-send&quot;);
+            sinkRecordSend = metricGroup.sensor(&quot;sink-record-send&quot;);
             sinkRecordSend.add(metricGroup.metricName(registry.sinkRecordSendRate), new Rate());
             sinkRecordSend.add(metricGroup.metricName(registry.sinkRecordSendTotal), new Total());
 
-            sinkRecordActiveCount = metricGroup.metrics().sensor(&quot;sink-record-active-count&quot;);
+            sinkRecordActiveCount = metricGroup.sensor(&quot;sink-record-active-count&quot;);
             sinkRecordActiveCount.add(metricGroup.metricName(registry.sinkRecordActiveCount), new Value());
             sinkRecordActiveCount.add(metricGroup.metricName(registry.sinkRecordActiveCountMax), new Max());
             sinkRecordActiveCount.add(metricGroup.metricName(registry.sinkRecordActiveCountAvg), new Avg());
 
-            partitionCount = metricGroup.metrics().sensor(&quot;partition-count&quot;);
+            partitionCount = metricGroup.sensor(&quot;partition-count&quot;);
             partitionCount.add(metricGroup.metricName(registry.sinkRecordPartitionCount), new Value());
 
-            offsetSeqNum = metricGroup.metrics().sensor(&quot;offset-seq-number&quot;);
+            offsetSeqNum = metricGroup.sensor(&quot;offset-seq-number&quot;);
             offsetSeqNum.add(metricGroup.metricName(registry.sinkRecordOffsetCommitSeqNum), new Value());
 
-            offsetCompletion = metricGroup.metrics().sensor(&quot;offset-commit-completion&quot;);
+            offsetCompletion = metricGroup.sensor(&quot;offset-commit-completion&quot;);
             offsetCompletion.add(metricGroup.metricName(registry.sinkRecordOffsetCommitCompletionRate), new Rate());
             offsetCompletion.add(metricGroup.metricName(registry.sinkRecordOffsetCommitCompletionTotal), new Total());
 
-            offsetCompletionSkip = metricGroup.metrics().sensor(&quot;offset-commit-completion-skip&quot;);
+            offsetCompletionSkip = metricGroup.sensor(&quot;offset-commit-completion-skip&quot;);
             offsetCompletionSkip.add(metricGroup.metricName(registry.sinkRecordOffsetCommitSkipRate), new Rate());
             offsetCompletionSkip.add(metricGroup.metricName(registry.sinkRecordOffsetCommitSkipTotal), new Total());
 
-            putBatchTime = metricGroup.metrics().sensor(&quot;put-batch-time&quot;);
+            putBatchTime = metricGroup.sensor(&quot;put-batch-time&quot;);
             putBatchTime.add(metricGroup.metricName(registry.sinkRecordPutBatchTimeMax), new Max());
             putBatchTime.add(metricGroup.metricName(registry.sinkRecordPutBatchTimeAvg), new Avg());
         }
&lt;p&gt;diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSourceTask.java b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSourceTask.java&lt;br/&gt;
index a172cdb45f0..473e2359578 100644&lt;br/&gt;
&amp;#8212; a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSourceTask.java&lt;br/&gt;
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSourceTask.java&lt;br/&gt;
@@ -509,7 +509,7 @@ public SourceTaskMetricsGroup(ConnectorTaskId id, ConnectMetrics connectMetrics)&lt;br/&gt;
             pollTime.add(metricGroup.metricName(registry.sourceRecordPollBatchTimeMax), new Max());&lt;br/&gt;
             pollTime.add(metricGroup.metricName(registry.sourceRecordPollBatchTimeAvg), new Avg());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;sourceRecordActiveCount = metricGroup.metrics().sensor(&quot;sink-record-active-count&quot;);&lt;br/&gt;
+            sourceRecordActiveCount = metricGroup.sensor(&quot;source-record-active-count&quot;);&lt;br/&gt;
             sourceRecordActiveCount.add(metricGroup.metricName(registry.sourceRecordActiveCount), new Value());&lt;br/&gt;
             sourceRecordActiveCount.add(metricGroup.metricName(registry.sourceRecordActiveCountMax), new Max());&lt;br/&gt;
             sourceRecordActiveCount.add(metricGroup.metricName(registry.sourceRecordActiveCountAvg), new Avg());&lt;br/&gt;
diff --git a/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerSinkTaskTest.java b/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerSinkTaskTest.java&lt;br/&gt;
index b714dcce05c..c69473212f5 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerSinkTaskTest.java&lt;br/&gt;
+++ b/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerSinkTaskTest.java&lt;br/&gt;
@@ -22,6 +22,7 @@&lt;br/&gt;
 import org.apache.kafka.clients.consumer.KafkaConsumer;&lt;br/&gt;
 import org.apache.kafka.clients.consumer.OffsetAndMetadata;&lt;br/&gt;
 import org.apache.kafka.clients.consumer.OffsetCommitCallback;&lt;br/&gt;
+import org.apache.kafka.common.MetricName;&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition;&lt;br/&gt;
 import org.apache.kafka.common.errors.WakeupException;&lt;br/&gt;
 import org.apache.kafka.common.record.RecordBatch;&lt;br/&gt;
@@ -32,6 +33,7 @@&lt;br/&gt;
 import org.apache.kafka.connect.runtime.ConnectMetrics.MetricGroup;&lt;br/&gt;
 import org.apache.kafka.connect.runtime.isolation.PluginClassLoader;&lt;br/&gt;
 import org.apache.kafka.connect.runtime.standalone.StandaloneConfig;&lt;br/&gt;
+import org.apache.kafka.connect.runtime.WorkerSinkTask.SinkTaskMetricsGroup;&lt;br/&gt;
 import org.apache.kafka.connect.sink.SinkConnector;&lt;br/&gt;
 import org.apache.kafka.connect.sink.SinkRecord;&lt;br/&gt;
 import org.apache.kafka.connect.sink.SinkTask;&lt;br/&gt;
@@ -74,6 +76,7 @@&lt;br/&gt;
 import static org.junit.Assert.assertEquals;&lt;br/&gt;
 import static org.junit.Assert.assertFalse;&lt;br/&gt;
 import static org.junit.Assert.assertNotEquals;&lt;br/&gt;
+import static org.junit.Assert.assertNull;&lt;br/&gt;
 import static org.junit.Assert.assertTrue;&lt;br/&gt;
 import static org.junit.Assert.fail;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -107,6 +110,7 @@&lt;br/&gt;
     private static final TaskConfig TASK_CONFIG = new TaskConfig(TASK_PROPS);&lt;/p&gt;

&lt;p&gt;     private ConnectorTaskId taskId = new ConnectorTaskId(&quot;job&quot;, 0);&lt;br/&gt;
+    private ConnectorTaskId taskId1 = new ConnectorTaskId(&quot;job&quot;, 1);&lt;br/&gt;
     private TargetState initialState = TargetState.STARTED;&lt;br/&gt;
     private MockTime time;&lt;br/&gt;
     private WorkerSinkTask workerTask;&lt;br/&gt;
@@ -1180,6 +1184,67 @@ public void testTopicsRegex() throws Exception &lt;/p&gt;
{
         PowerMock.verifyAll();
     }

&lt;p&gt;+    @Test&lt;br/&gt;
+    public void testMetricsGroup() {&lt;br/&gt;
+        SinkTaskMetricsGroup group = new SinkTaskMetricsGroup(taskId, metrics);&lt;br/&gt;
+        SinkTaskMetricsGroup group1 = new SinkTaskMetricsGroup(taskId1, metrics);&lt;br/&gt;
+        for (int i = 0; i != 10; ++i) &lt;/p&gt;
{
+            group.recordRead(1);
+            group.recordSend(2);
+            group.recordPut(3);
+            group.recordPartitionCount(4);
+            group.recordOffsetSequenceNumber(5);
+        }
&lt;p&gt;+        Map&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt; committedOffsets = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
+        committedOffsets.put(TOPIC_PARTITION, new OffsetAndMetadata(FIRST_OFFSET + 1));&lt;br/&gt;
+        group.recordCommittedOffsets(committedOffsets);&lt;br/&gt;
+        Map&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt; consumedOffsets = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
+        consumedOffsets.put(TOPIC_PARTITION, new OffsetAndMetadata(FIRST_OFFSET + 10));&lt;br/&gt;
+        group.recordConsumedOffsets(consumedOffsets);&lt;br/&gt;
+&lt;br/&gt;
+        for (int i = 0; i != 20; ++i) &lt;/p&gt;
{
+            group1.recordRead(1);
+            group1.recordSend(2);
+            group1.recordPut(30);
+            group1.recordPartitionCount(40);
+            group1.recordOffsetSequenceNumber(50);
+        }
&lt;p&gt;+        committedOffsets = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
+        committedOffsets.put(TOPIC_PARTITION2, new OffsetAndMetadata(FIRST_OFFSET + 2));&lt;br/&gt;
+        committedOffsets.put(TOPIC_PARTITION3, new OffsetAndMetadata(FIRST_OFFSET + 3));&lt;br/&gt;
+        group1.recordCommittedOffsets(committedOffsets);&lt;br/&gt;
+        consumedOffsets = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
+        consumedOffsets.put(TOPIC_PARTITION2, new OffsetAndMetadata(FIRST_OFFSET + 20));&lt;br/&gt;
+        consumedOffsets.put(TOPIC_PARTITION3, new OffsetAndMetadata(FIRST_OFFSET + 30));&lt;br/&gt;
+        group1.recordConsumedOffsets(consumedOffsets);&lt;br/&gt;
+&lt;br/&gt;
+        assertEquals(0.333, metrics.currentMetricValueAsDouble(group.metricGroup(), &quot;sink-record-read-rate&quot;), 0.001d);&lt;br/&gt;
+        assertEquals(0.667, metrics.currentMetricValueAsDouble(group.metricGroup(), &quot;sink-record-send-rate&quot;), 0.001d);&lt;br/&gt;
+        assertEquals(9, metrics.currentMetricValueAsDouble(group.metricGroup(), &quot;sink-record-active-count&quot;), 0.001d);&lt;br/&gt;
+        assertEquals(4, metrics.currentMetricValueAsDouble(group.metricGroup(), &quot;partition-count&quot;), 0.001d);&lt;br/&gt;
+        assertEquals(5, metrics.currentMetricValueAsDouble(group.metricGroup(), &quot;offset-commit-seq-no&quot;), 0.001d);&lt;br/&gt;
+        assertEquals(3, metrics.currentMetricValueAsDouble(group.metricGroup(), &quot;put-batch-max-time-ms&quot;), 0.001d);&lt;br/&gt;
+&lt;br/&gt;
+        // Close the group&lt;br/&gt;
+        group.close();&lt;br/&gt;
+&lt;br/&gt;
+        for (MetricName metricName : group.metricGroup().metrics().metrics().keySet()) &lt;/p&gt;
{
+            // Metrics for this group should no longer exist
+            assertFalse(group.metricGroup().groupId().includes(metricName));
+        }&lt;br/&gt;
+        // Sensors for this group should no longer exist&lt;br/&gt;
+        assertNull(group.metricGroup().metrics().getSensor(&quot;source-record-poll&quot;));&lt;br/&gt;
+        assertNull(group.metricGroup().metrics().getSensor(&quot;source-record-write&quot;));&lt;br/&gt;
+        assertNull(group.metricGroup().metrics().getSensor(&quot;poll-batch-time&quot;));&lt;br/&gt;
+&lt;br/&gt;
+        assertEquals(0.667, metrics.currentMetricValueAsDouble(group1.metricGroup(), &quot;sink-record-read-rate&quot;), 0.001d);&lt;br/&gt;
+        assertEquals(1.333, metrics.currentMetricValueAsDouble(group1.metricGroup(), &quot;sink-record-send-rate&quot;), 0.001d);&lt;br/&gt;
+        assertEquals(45, metrics.currentMetricValueAsDouble(group1.metricGroup(), &quot;sink-record-active-count&quot;), 0.001d);&lt;br/&gt;
+        assertEquals(40, metrics.currentMetricValueAsDouble(group1.metricGroup(), &quot;partition-count&quot;), 0.001d);&lt;br/&gt;
+        assertEquals(50, metrics.currentMetricValueAsDouble(group1.metricGroup(), &quot;offset-commit-seq-no&quot;), 0.001d);&lt;br/&gt;
+        assertEquals(30, metrics.currentMetricValueAsDouble(group1.metricGroup(), &quot;put-batch-max-time-ms&quot;), 0.001d);&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
     private void expectInitializeTask() throws Exception {&lt;br/&gt;
         PowerMock.expectPrivate(workerTask, &quot;createConsumer&quot;).andReturn(consumer);&lt;br/&gt;
         consumer.subscribe(EasyMock.eq(asList(TOPIC)), EasyMock.capture(rebalanceListener));&lt;br/&gt;
diff --git a/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerSourceTaskTest.java b/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerSourceTaskTest.java&lt;br/&gt;
index 4f0d24357e7..dfdf415e0ed 100644&lt;br/&gt;
&amp;#8212; a/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerSourceTaskTest.java&lt;br/&gt;
+++ b/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerSourceTaskTest.java&lt;br/&gt;
@@ -19,6 +19,7 @@&lt;br/&gt;
 import org.apache.kafka.clients.producer.KafkaProducer;&lt;br/&gt;
 import org.apache.kafka.clients.producer.ProducerRecord;&lt;br/&gt;
 import org.apache.kafka.clients.producer.RecordMetadata;&lt;br/&gt;
+import org.apache.kafka.common.MetricName;&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition;&lt;br/&gt;
 import org.apache.kafka.common.record.InvalidRecordException;&lt;br/&gt;
 import org.apache.kafka.common.utils.Time;&lt;br/&gt;
@@ -65,6 +66,7 @@&lt;br/&gt;
 import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
 &lt;br/&gt;
 import static org.junit.Assert.assertEquals;&lt;br/&gt;
+import static org.junit.Assert.assertFalse;&lt;br/&gt;
 import static org.junit.Assert.assertNull;&lt;br/&gt;
 import static org.junit.Assert.assertTrue;&lt;br/&gt;
 &lt;br/&gt;
@@ -87,6 +89,7 @@&lt;br/&gt;
 &lt;br/&gt;
     private ExecutorService executor = Executors.newSingleThreadExecutor();&lt;br/&gt;
     private ConnectorTaskId taskId = new ConnectorTaskId(&quot;job&quot;, 0);&lt;br/&gt;
+    private ConnectorTaskId taskId1 = new ConnectorTaskId(&quot;job&quot;, 1);&lt;br/&gt;
     private WorkerConfig config;&lt;br/&gt;
     private Plugins plugins;&lt;br/&gt;
     private MockConnectMetrics metrics;&lt;br/&gt;
@@ -611,16 +614,47 @@ public Object answer() throws Throwable {&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testMetricsGroup() {&lt;br/&gt;
         SourceTaskMetricsGroup group = new SourceTaskMetricsGroup(taskId, metrics);&lt;br/&gt;
+        SourceTaskMetricsGroup group1 = new SourceTaskMetricsGroup(taskId1, metrics);&lt;br/&gt;
         for (int i = 0; i != 10; ++i) {
             group.recordPoll(100, 1000 + i * 100);
             group.recordWrite(10);
         }&lt;br/&gt;
+        for (int i = 0; i != 20; ++i) {
+            group1.recordPoll(100, 1000 + i * 100);
+            group1.recordWrite(10);
+        }&lt;br/&gt;
         assertEquals(1900.0, metrics.currentMetricValueAsDouble(group.metricGroup(), &quot;poll-batch-max-time-ms&quot;), 0.001d);&lt;br/&gt;
         assertEquals(1450.0, metrics.currentMetricValueAsDouble(group.metricGroup(), &quot;poll-batch-avg-time-ms&quot;), 0.001d);&lt;br/&gt;
         assertEquals(33.333, metrics.currentMetricValueAsDouble(group.metricGroup(), &quot;source-record-poll-rate&quot;), 0.001d);&lt;br/&gt;
         assertEquals(1000, metrics.currentMetricValueAsDouble(group.metricGroup(), &quot;source-record-poll-total&quot;), 0.001d);&lt;br/&gt;
         assertEquals(3.3333, metrics.currentMetricValueAsDouble(group.metricGroup(), &quot;source-record-write-rate&quot;), 0.001d);&lt;br/&gt;
         assertEquals(100, metrics.currentMetricValueAsDouble(group.metricGroup(), &quot;source-record-write-total&quot;), 0.001d);&lt;br/&gt;
+        assertEquals(900.0, metrics.currentMetricValueAsDouble(group.metricGroup(), &quot;source-record-active-count&quot;), 0.001d);&lt;br/&gt;
+&lt;br/&gt;
+        // Close the group&lt;br/&gt;
+        group.close();&lt;br/&gt;
+&lt;br/&gt;
+        for (MetricName metricName : group.metricGroup().metrics().metrics().keySet()) {+            // Metrics for this group should no longer exist+            assertFalse(group.metricGroup().groupId().includes(metricName));+        }
&lt;p&gt;+        // Sensors for this group should no longer exist&lt;br/&gt;
+        assertNull(group.metricGroup().metrics().getSensor(&quot;sink-record-read&quot;));&lt;br/&gt;
+        assertNull(group.metricGroup().metrics().getSensor(&quot;sink-record-send&quot;));&lt;br/&gt;
+        assertNull(group.metricGroup().metrics().getSensor(&quot;sink-record-active-count&quot;));&lt;br/&gt;
+        assertNull(group.metricGroup().metrics().getSensor(&quot;partition-count&quot;));&lt;br/&gt;
+        assertNull(group.metricGroup().metrics().getSensor(&quot;offset-seq-number&quot;));&lt;br/&gt;
+        assertNull(group.metricGroup().metrics().getSensor(&quot;offset-commit-completion&quot;));&lt;br/&gt;
+        assertNull(group.metricGroup().metrics().getSensor(&quot;offset-commit-completion-skip&quot;));&lt;br/&gt;
+        assertNull(group.metricGroup().metrics().getSensor(&quot;put-batch-time&quot;));&lt;br/&gt;
+&lt;br/&gt;
+        assertEquals(2900.0, metrics.currentMetricValueAsDouble(group1.metricGroup(), &quot;poll-batch-max-time-ms&quot;), 0.001d);&lt;br/&gt;
+        assertEquals(1950.0, metrics.currentMetricValueAsDouble(group1.metricGroup(), &quot;poll-batch-avg-time-ms&quot;), 0.001d);&lt;br/&gt;
+        assertEquals(66.667, metrics.currentMetricValueAsDouble(group1.metricGroup(), &quot;source-record-poll-rate&quot;), 0.001d);&lt;br/&gt;
+        assertEquals(2000, metrics.currentMetricValueAsDouble(group1.metricGroup(), &quot;source-record-poll-total&quot;), 0.001d);&lt;br/&gt;
+        assertEquals(6.667, metrics.currentMetricValueAsDouble(group1.metricGroup(), &quot;source-record-write-rate&quot;), 0.001d);&lt;br/&gt;
+        assertEquals(200, metrics.currentMetricValueAsDouble(group1.metricGroup(), &quot;source-record-write-total&quot;), 0.001d);&lt;br/&gt;
+        assertEquals(1800.0, metrics.currentMetricValueAsDouble(group1.metricGroup(), &quot;source-record-active-count&quot;), 0.001d);&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;     private CountDownLatch expectPolls(int minimum, final AtomicInteger count) throws InterruptedException {&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16355089" author="steff1193" created="Wed, 7 Feb 2018 07:47:43 +0000"  >&lt;p&gt;Havnt looked that much into the patch from PR 4514, but do you expect that it fixes the problem? Besides tests, the only thing it does is to change a metric name from sink-record-active-count to source-record-active-count. But where was source-record-active-count then controlled before? Please note that my observation is not that source-record-active-count did not exist or was always 0. The observed problem was/is that it seemed to be the same value for all tasks, and that it was increasing for all tasks, even if there were only activity in one task.&lt;/p&gt;</comment>
                            <comment id="16355562" author="rhauch" created="Wed, 7 Feb 2018 14:59:43 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rayokota&quot; class=&quot;user-hover&quot; rel=&quot;rayokota&quot;&gt;rayokota&lt;/a&gt;, ping. Please see &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=steff1193&quot; class=&quot;user-hover&quot; rel=&quot;steff1193&quot;&gt;steff1193&lt;/a&gt;&apos;s comments. &lt;/p&gt;

&lt;p&gt;Also, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt; this issue was not closed when the PR was merged, and there&apos;s no fix version.&lt;/p&gt;</comment>
                            <comment id="16355785" author="rayokota" created="Wed, 7 Feb 2018 17:35:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=steff1193&quot; class=&quot;user-hover&quot; rel=&quot;steff1193&quot;&gt;steff1193&lt;/a&gt;, it&apos;s not just the metric name change. &#160;The PR also changes calls to metricGroup.metrics().sensor() with metricGroup.sensor(). &#160;This ensures that&#160;sensors names will be prepended with the metric group ID to ensure they are not shared across metric groups.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13127578">KAFKA-6407</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 40 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3pjj3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>