<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:40:12 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-17062] RemoteLogManager - RemoteStorageException causes data loss</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-17062</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;When Tiered Storage is configured, retention.bytes defines the limit for the amount of data stored in the filesystem and in remote storage. However a failure while offloading to remote storage can cause segments to be dropped before the retention limit is met.&lt;/p&gt;

&lt;p&gt;What happens&lt;/p&gt;

&lt;p&gt;Assuming a topic configured with &lt;tt&gt;retention.bytes=4294967296&lt;/tt&gt; (4GB) and a &lt;tt&gt;local.retention.bytes=1073741824&lt;/tt&gt; (1GB, equal to segment.bytes) we would expect Kafka to keep up to 3 segments (3GB) in the remote store and 1 segment locally (the local segment) and possibly more if the remote storage is offline. i.e. segments in the following RemoteLogSegmentStates in the RemoteLogMetadataManager (RLMM) :&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Segment 3 (&lt;tt&gt;COPY_SEGMENT_FINISHED&lt;/tt&gt;)&lt;/li&gt;
	&lt;li&gt;Segment 2 (&lt;tt&gt;COPY_SEGMENT_FINISHED&lt;/tt&gt;)&lt;/li&gt;
	&lt;li&gt;Segment 1 (&lt;tt&gt;COPY_SEGMENT_FINISHED&lt;/tt&gt;)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Let&apos;s assume the RLMM starts failing when segment 4 rolls. At the first iteration of an RLMTask we will have -&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://github.com/apache/kafka/blob/d0dfefbe6394276eb329b6ca998842a984add506/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L773&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;&lt;tt&gt;copyLogSegmentsToRemote&lt;/tt&gt;&lt;/a&gt; : is called first
	&lt;ul&gt;
		&lt;li&gt;RLMM becomes aware of Segment 4 and adds it to the metadata:
		&lt;ul&gt;
			&lt;li&gt;Segment 4 (&lt;tt&gt;COPY_SEGMENT_STARTED&lt;/tt&gt;),&lt;/li&gt;
			&lt;li&gt;Segment 3 (&lt;tt&gt;COPY_SEGMENT_FINISHED&lt;/tt&gt;),&lt;/li&gt;
			&lt;li&gt;Segment 2 (&lt;tt&gt;COPY_SEGMENT_FINISHED&lt;/tt&gt;),&lt;/li&gt;
			&lt;li&gt;Segment 1 (&lt;tt&gt;COPY_SEGMENT_FINISHED&lt;/tt&gt;)&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
		&lt;li&gt;An exception is raised during the copy operation (&lt;a href=&quot;https://github.com/apache/kafka/blob/d0dfefbe6394276eb329b6ca998842a984add506/storage/api/src/main/java/org/apache/kafka/server/log/remote/storage/RemoteStorageManager.java#L93&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;&lt;tt&gt;copyLogSegmentData&lt;/tt&gt;&lt;/a&gt; in RemoteStorageManager) which is caught with the error message &#8220;&lt;tt&gt;Error occurred while copying log segments of partition&lt;/tt&gt;&#8221; and no further copy will be attempted for the duration of this RLMTask.&lt;/li&gt;
		&lt;li&gt;At that point the Segment will never move to &lt;tt&gt;COPY_SEGMENT_FINISHED&lt;/tt&gt; but will transition to &lt;tt&gt;DELETE_SEGMENT_STARTED&lt;/tt&gt; eventually before being cleaned up when the associated segment is deleted.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://github.com/apache/kafka/blob/d0dfefbe6394276eb329b6ca998842a984add506/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L1122&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;&lt;tt&gt;cleanupExpiredRemoteLogSegments&lt;/tt&gt;&lt;/a&gt; is then called
	&lt;ul&gt;
		&lt;li&gt;Retention size is computed in &lt;a href=&quot;https://github.com/apache/kafka/blob/d0dfefbe6394276eb329b6ca998842a984add506/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L1296&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;&lt;tt&gt;buildRetentionSizeData&lt;/tt&gt;&lt;/a&gt; as the sum of all the segments size regardless of their state so computed size of the topic is 1 (local) + 4 (remote)&lt;/li&gt;
		&lt;li&gt;Segment 1 as being the oldest will be dropped.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;At the second iteration after &lt;a href=&quot;https://github.com/apache/kafka/blob/d0dfefbe6394276eb329b6ca998842a984add506/storage/src/main/java/org/apache/kafka/server/log/remote/storage/RemoteLogManagerConfig.java#L395&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;&lt;tt&gt;remote.log.manager.task.interval.ms&lt;/tt&gt;&lt;/a&gt; (default: 30s), the same will happen. The RLMM will now have 2 x Segment 4 in a &lt;tt&gt;COPY_SEGMENT_STARTED&lt;/tt&gt; state each with a different &lt;tt&gt;RemoteLogSegmentId&lt;/tt&gt; and Segment 2 will be dropped. The same will happen to Segment 3 after another iteration.&lt;/p&gt;

&lt;p&gt;At that point, we now have the RLMM composed of 4 copies of Segment 4 in &lt;tt&gt;COPY_SEGMENT_STARTED&lt;/tt&gt; state. Segment 4 is marked for deletion increasing the LSO at the same time and causing the UnifiedLog to delete the local and remote data for Segment 4 including its metadata.&lt;/p&gt;

&lt;p&gt;Under those circumstances Kafka can quickly delete segments that were not meant for deletion causing a data loss.&lt;/p&gt;

&lt;p&gt;Steps to reproduce the problem:&lt;/p&gt;

&lt;p&gt;1. Enable tiered storage&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-bash&quot;&gt;
mkdir -p /tmp/tieredStorage/kafka-tiered-storage/
cat &amp;lt;&amp;lt;EOF &amp;gt;&amp;gt; config/kraft/server.properties
remote.log.storage.system.enable=True
remote.log.storage.manager.class.name=org.apache.kafka.server.log.remote.storage.LocalTieredStorage
remote.log.manager.task.interval.ms=5000
remote.log.metadata.manager.listener.name=PLAINTEXT
rlmm.config.remote.log.metadata.topic.replication.factor=1
rsm.config.dir=/tmp/tieredStorage
EOF
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;2. Start a Kafka server with the following classpath. This is needed so we can use test class LocalTieredStorage as an implementation of RemoteStorageManager.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-bash&quot;&gt;
export CLASSPATH=&lt;span class=&quot;code-quote-red&quot;&gt;&quot;$(pwd)/storage/build/libs/{*}:$(pwd)/clients/build/libs/{*}&quot;&lt;/span&gt;
export KAFKA_CLUSTER_ID=&lt;span class=&quot;code-quote-red&quot;&gt;&quot;$(bin/kafka-storage.sh random-uuid)&quot;&lt;/span&gt;
bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c config/kraft/server.properties
bin/kafka-server-start.sh config/kraft/server.properties
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;3. In a separate shell, create the topic and produce enough records to fill the remote log&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-bash&quot;&gt;
bin/kafka-topics.sh --create --topic bug-ts --bootstrap-server localhost:9092 \
   --config retention.bytes=1000000000 --config segment.bytes=100000000 \
   --config remote.storage.enable=true --config &lt;span class=&quot;code-object&quot;&gt;local&lt;/span&gt;.retention.bytes=1
bin/kafka-producer-perf-test.sh --topic bug-ts --num-records=1000000 \
   --throughput -1 --record-size 1000 \
   --producer-props acks=1 batch.size=100000  bootstrap.servers=localhost:9092
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;4. In a separate shell, watch the remote log directory content&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-bash&quot;&gt;
watch -n 1 &#8211; s -R /tmp/tieredStorage/kafka-tiered-storage/
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;5. Once all logs are sent to the remote storage (when the server logs stops, should take around 2min), stop the Kafka server &lt;br/&gt;
6. Edit the file LocalTieredStorage#L309 in &lt;tt&gt;copyLogSegmentData()&lt;/tt&gt; in order to throw a &lt;tt&gt;RemoteStorageException&lt;/tt&gt; and disable the ability to store new remote segments.&lt;br/&gt;
7. Rebuild Kafka&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-bash&quot;&gt;
 ./gradlew testJar
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;8. Restart the Kafka server&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-bash&quot;&gt;
bin/kafka-server-start.sh config/kraft/server.properties
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;9. Send enough data for one segment rollup&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-bash&quot;&gt;
bin/kafka-producer-perf-test.sh \
  --topic bug-ts --num-records=10000 --throughput -1 --record-size 10000 \
  --producer-props acks=1 batch.size=100000 bootstrap.servers=localhost:9092
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;All data in the remote directory will start getting deleted when we would expect just no more writes to happen to the remote storage.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13584471">KAFKA-17062</key>
            <summary>RemoteLogManager - RemoteStorageException causes data loss</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="showuon">Luke Chen</assignee>
                                    <reporter username="guillaumemallet">Guillaume Mallet</reporter>
                        <labels>
                            <label>tiered-storage</label>
                    </labels>
                <created>Tue, 2 Jul 2024 11:43:07 +0000</created>
                <updated>Thu, 29 Aug 2024 06:10:50 +0000</updated>
                            <resolved>Thu, 29 Aug 2024 06:10:50 +0000</resolved>
                                    <version>3.7.1</version>
                    <version>3.8.0</version>
                    <version>3.9.0</version>
                                    <fixVersion>3.9.0</fixVersion>
                                    <component>Tiered-Storage</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>11</watches>
                                                                                                                <comments>
                            <comment id="17862439" author="divijvaidya" created="Tue, 2 Jul 2024 13:05:24 +0000"  >&lt;p&gt;I haven&apos;t looked at it in great detail but the bug sounds legitimate. For a fix, we need to filter the segment based on their state at &lt;a href=&quot;https://github.com/apache/kafka/blob/d0dfefbe6394276eb329b6ca998842a984add506/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L1184&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/d0dfefbe6394276eb329b6ca998842a984add506/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L1184&lt;/a&gt; and only delete segments which are in copy_finished and/or delete_started state. Note that inclusion of copy_started segments was intentional as per &lt;a href=&quot;https://github.com/apache/kafka/pull/13561#discussion_r1181527119&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/13561#discussion_r1181527119&lt;/a&gt; but we probably missed that the calculated retention size will include all previous copy_started copies of the same segment.&lt;/p&gt;

&lt;p&gt;cc: &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=showuon&quot; class=&quot;user-hover&quot; rel=&quot;showuon&quot;&gt;showuon&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Kamal+C&quot; class=&quot;user-hover&quot; rel=&quot;Kamal C&quot;&gt;Kamal C&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=satishd&quot; class=&quot;user-hover&quot; rel=&quot;satishd&quot;&gt;satishd&lt;/a&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17862464" author="JIRAUSER306008" created="Tue, 2 Jul 2024 14:19:52 +0000"  >&lt;p&gt;Hey &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=divijvaidya&quot; class=&quot;user-hover&quot; rel=&quot;divijvaidya&quot;&gt;divijvaidya&lt;/a&gt; thanks for checking this !&lt;/p&gt;

&lt;p&gt;I was thinking of how to fix this and thought of not accounting for segments in a different state than copy_finished and/or delete_started as you said but this means we could potentially breach the &lt;tt&gt;retention.bytes&lt;/tt&gt; we initially planned for.&#160;&lt;/p&gt;

&lt;p&gt;For example, if the RemoteLogSegmentId changes the name of the file on the remote system we could potentially have them remaining for an extended period of time (while the Segment itself hasn&apos;t been cleaned up) causing the overall size of the topic to go above what we would expect.&lt;/p&gt;

&lt;p&gt;I wonder if moving failed segment to delete_started when we handle the exception could help clean things up a bit earlier and help reducing the drift in storage.&lt;/p&gt;

&lt;p&gt;Another concern it could help with is keeping the size of the metadata bounded if the failure happens only on the write path (in case of complete failure we still have an unbounded growth with one new segment every &lt;a href=&quot;https://github.com/apache/kafka/blob/d0dfefbe6394276eb329b6ca998842a984add506/storage/src/main/java/org/apache/kafka/server/log/remote/storage/RemoteLogManagerConfig.java#L395&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;&lt;tt&gt;remote.log.manager.task.interval.ms&lt;/tt&gt;&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;What do you think ?&#160;&lt;/p&gt;</comment>
                            <comment id="17862679" author="showuon" created="Wed, 3 Jul 2024 07:27:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guillaumemallet&quot; class=&quot;user-hover&quot; rel=&quot;guillaumemallet&quot;&gt;guillaumemallet&lt;/a&gt; , thanks for reporting this issue. This is indeed a bug!&lt;/p&gt;

&lt;p&gt;Questions:&lt;/p&gt;

&lt;p&gt;&amp;gt; For example, if the RemoteLogSegmentId changes the name of the file on the remote system we could potentially have them remaining for an extended period of time (while the Segment itself hasn&apos;t been cleaned up) causing the overall size of the topic to go above what we would expect.&lt;/p&gt;

&lt;p&gt;&amp;gt; I wonder if moving failed segment to delete_started when we handle the exception could help clean things up a bit earlier and help reducing the drift in storage.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Could you help me understand why moving the failed segment to delete_started state will help reducing this issue? Because it must be cleaned next time when we enter `&lt;a href=&quot;https://github.com/apache/kafka/blob/d0dfefbe6394276eb329b6ca998842a984add506/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L1122&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;&lt;tt&gt;cleanupExpiredRemoteLogSegments&lt;/tt&gt;&lt;/a&gt;`? But the upload failed segments should not get deleted, right?&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&amp;gt; Another concern it could help with is keeping the size of the metadata bounded if the failure happens only on the write path (in case of complete failure we still have an unbounded growth with one new segment every &lt;a href=&quot;https://github.com/apache/kafka/blob/d0dfefbe6394276eb329b6ca998842a984add506/storage/src/main/java/org/apache/kafka/server/log/remote/storage/RemoteLogManagerConfig.java#L395&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;&lt;tt&gt;remote.log.manager.task.interval.ms&lt;/tt&gt;&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;This is indeed a problem. Could you help open a separate Jira for this issue? And welcome to contribute to it. I think we don&apos;t have to do it complicatedly. Just a simple counter should be enough given this is a rare case and won&apos;t cause too much problem. WDYT?&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17862802" author="JIRAUSER306008" created="Wed, 3 Jul 2024 14:06:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=showuon&quot; class=&quot;user-hover&quot; rel=&quot;showuon&quot;&gt;showuon&lt;/a&gt; thanks for the feedback !&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&amp;gt;&#160;Could you help me understand why moving the failed segment to delete_started state will help reducing this issue? Because it must be cleaned next time when we enter `&lt;a href=&quot;https://github.com/apache/kafka/blob/d0dfefbe6394276eb329b6ca998842a984add506/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L1122&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;&lt;tt&gt;cleanupExpiredRemoteLogSegments&lt;/tt&gt;&lt;/a&gt;`?&lt;/p&gt;

&lt;p&gt;That&apos;s what I had in mind but that would address only issues where writes are failing and not deletions (e.g. no more available space)&lt;/p&gt;

&lt;p&gt;&amp;gt;&#160;But the upload failed segments should not get deleted, right?&lt;/p&gt;

&lt;p&gt;This portion seems a bit unclear to me. Because each iteration of the RLMTask creates a unique &lt;a href=&quot;https://github.com/apache/kafka/blob/d0dfefbe6394276eb329b6ca998842a984add506/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L850&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;RemoteLogSegmentId&lt;/a&gt; I assumed that multiple retries should result in multiple deletion as &lt;a href=&quot;https://github.com/apache/kafka/blob/20e101c2e4cb2b34c2c575287cfaec76aa8c5db0/storage/api/src/main/java/org/apache/kafka/server/log/remote/storage/RemoteStorageManager.java#L152&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;deleteLogSegmentData&lt;/a&gt; will be called once per unique RemoteLogSegmentId and that failed copies are safe to be deleted as soon as possible.&#160;&lt;/p&gt;

&lt;p&gt;If your understanding of the contract is that failed uploads shouldn&apos;t be deleted and multiple iteration of the RLMTask should reuse previous files then I probably misunderstood the role of the RemoteLogSegmentId because it sounds like we could reuse it in case of failure as we&apos;re asking for the &lt;a href=&quot;https://github.com/apache/kafka/blob/35baa0ac4fcb7f21bb0df037d0756429db5d3bb2/storage/api/src/main/java/org/apache/kafka/server/log/remote/storage/RemoteStorageManager.java#L85&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;idempotency&lt;/a&gt; of a copy.&#160;&lt;/p&gt;

&lt;p&gt;I was under the impression that each upload should be unique due to this RemoteLogSegmentId which is why I was steered in that direction.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&amp;gt; This is indeed a problem. Could you help open a separate Jira for this issue? And welcome to contribute to it. I think we don&apos;t have to do it complicatedly. Just a simple counter should be enough given this is a rare case and won&apos;t cause too much problem. WDYT?&lt;/p&gt;

&lt;p&gt;Good suggestion, I&apos;ll file one asap, that would probably be better for treating those tasks independently. I&apos;m not sure I understand what you mean by a simple counter but maybe this discussion should happen in that new Jira. I&apos;ll ping you when I have it filed to make sure I understand what you mean.&lt;/p&gt;</comment>
                            <comment id="17862925" author="showuon" created="Thu, 4 Jul 2024 05:55:06 +0000"  >&lt;p&gt;Good quesiton that should we create new &#160;&lt;a href=&quot;https://github.com/apache/kafka/blob/d0dfefbe6394276eb329b6ca998842a984add506/core/src/main/java/kafka/log/remote/RemoteLogManager.java#L850&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;RemoteLogSegmentId&lt;/a&gt; when failed segment retried?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=satishd&quot; class=&quot;user-hover&quot; rel=&quot;satishd&quot;&gt;satishd&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ckamal&quot; class=&quot;user-hover&quot; rel=&quot;ckamal&quot;&gt;ckamal&lt;/a&gt; , we&apos;d like to hear your thought about it?&lt;/p&gt;</comment>
                            <comment id="17863117" author="satish.duggana" created="Fri, 5 Jul 2024 04:37:44 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guillaumemallet&quot; class=&quot;user-hover&quot; rel=&quot;guillaumemallet&quot;&gt;guillaumemallet&lt;/a&gt; Thanks for filing the issue.&lt;/p&gt;

&lt;p&gt;&amp;gt;I was thinking of how to fix this and thought of not accounting for segments in a different state than copy_finished and/or delete_started as you said but this means we could potentially breach the retention.bytes we initially planned for. &lt;/p&gt;

&lt;p&gt;Right, that is why this approach was not considered earlier.&lt;/p&gt;


&lt;p&gt;&amp;gt;Good quesiton that should we create new  RemoteLogSegmentId when failed segment retried?&lt;/p&gt;

&lt;p&gt;Any retried operation for copying a segment will have a unique id and it will create a new file/object in the remote store. This will make sure we will not reference partially copied data in later reads and these semantics may vary across different remote storages like object stores. The safe way is to generate a new uuid and try copying the failed segment again.&lt;/p&gt;

&lt;p&gt;One possible tradeoff that can be explored is do not delete the data sooner but we may end up occupying more than the targeted storage in a few scenarios which will eventually be cleaned up. &lt;/p&gt;</comment>
                            <comment id="17863384" author="JIRAUSER306008" created="Fri, 5 Jul 2024 16:31:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=satish.duggana&quot; class=&quot;user-hover&quot; rel=&quot;satish.duggana&quot;&gt;satish.duggana&lt;/a&gt; Thanks for the context.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&amp;gt;&#160;Any retried operation for copying a segment will have a unique id and it will create a new file/object in the remote store. This will make sure we will not reference partially copied data in later reads and these semantics may vary across different remote storages like object stores. The safe way is to generate a new uuid and try copying the failed segment again.&lt;/p&gt;

&lt;p&gt;If my understanding is correct, we could drop the expected idempotent of the &lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/storage/api/src/main/java/org/apache/kafka/server/log/remote/storage/RemoteStorageManager.java#L82-L86&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;copy operation&lt;/a&gt; as we&apos;re never using it (the &lt;tt&gt;RemoteLogSegmentMetadata&lt;/tt&gt; will always have a different ID.&lt;/p&gt;

&lt;p&gt;&amp;gt; &#160;One possible tradeoff that can be explored is do not delete the data sooner but we may end up occupying more than the targeted storage in a few scenarios which will eventually be cleaned up.&lt;/p&gt;

&lt;p&gt;You said above that &quot;Any retried operation for copying a segment will have a unique id and it will create a new file/object in the remote store.&quot;, I fail to see the drawbacks of attempting to delete those segments earlier if they are expected to be independent from the ones for which the copy succeeded. Could you help me understand why we wouldn&apos;t want to do that ?&#160;&lt;/p&gt;

&lt;p&gt;It would make the tradeoff easier to accept as the few scenarios where we would end up using more than targeted would also get resolved faster.&lt;/p&gt;</comment>
                            <comment id="17864577" author="showuon" created="Wed, 10 Jul 2024 09:54:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guillaumemallet&quot; class=&quot;user-hover&quot; rel=&quot;guillaumemallet&quot;&gt;guillaumemallet&lt;/a&gt; , &lt;/p&gt;

&lt;p&gt;&amp;gt; I fail to see the drawbacks of attempting to delete those segments earlier if they are expected to be independent from the ones for which the copy succeeded. Could you help me understand why we wouldn&apos;t want to do that ?&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Sorry, I still don&apos;t understand why we should delete the failed copy segments? Let&apos;s say, we have a segment &quot;A&quot; needed to be copied to the remote storage. It then creates a &#160;RemoteLogSegmentId &quot;ID1&quot;, but failed. So the remote metadata log contains &quot;COPY_SEGMENT_STARTED&quot; of RemoteLogSegmentId &quot;ID1&quot;. So at this state, why do we want to delete this &quot;failed uploaded&quot; segment? Did I miss anything?&lt;/p&gt;</comment>
                            <comment id="17864649" author="JIRAUSER306008" created="Wed, 10 Jul 2024 12:56:14 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=showuon&quot; class=&quot;user-hover&quot; rel=&quot;showuon&quot;&gt;showuon&lt;/a&gt;&#160;&lt;/p&gt;

&lt;p&gt;I probably haven&apos;t been clear enough. The idea behind deleting them if they are failed copies is more a &quot;nice to have&quot;. Kafka would work fine with those &quot;COPY_SEGMENT_STARTED&quot;, granted we do not account them in retention, but they would pollute the cache and will still be billed for in the remote store.&lt;br/&gt;
What I am proposing is that if those segments will not be used at any point, we should discard them when possible in order to release capacity rather than keeping them till the segment they represent becomes a candidate for being cleaned.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;The fact that they will not be used is due to the RemoteLogSegmentId which would become &quot;ID2&quot; for the same segment A at the second upload making the files independent from the first upload.&lt;/p&gt;

&lt;p&gt;Does that answer your question ?&#160;&lt;/p&gt;</comment>
                            <comment id="17868684" author="showuon" created="Thu, 25 Jul 2024 12:57:57 +0000"  >&lt;p&gt;Marking this issue as v3.9.0 blocker because it will cause data loss.&lt;/p&gt;</comment>
                            <comment id="17872462" author="cmccabe" created="Fri, 9 Aug 2024 21:33:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=showuon&quot; class=&quot;user-hover&quot; rel=&quot;showuon&quot;&gt;showuon&lt;/a&gt;: If this isn&apos;t a regression in 3.9, then it isn&apos;t a 3.9 blocker. However, I agree that it would be very good to get it into the upcoming 3.9 release (and also backport it to the older releases that were also affected.)&lt;/p&gt;

&lt;p&gt;I will leave &quot;Fix release&quot; at 3.9 for now, under the assumption that we can get this done in the next few weeks.&lt;/p&gt;

&lt;p&gt;Note that code freeze for 3.9 hasn&apos;t happened yet, so you can merge the fix into 3.9 without explicit approval. (Code freeze will happen at the end of this month)&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310250" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10431"><![CDATA[Important]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 13 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1q40w:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>