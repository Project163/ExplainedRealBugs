<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:36:22 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-593] Empty log index file created when it shouldn&apos;t be empty</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-593</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;We have met empty index file during system test when it shouldn&apos;t be empty. In this case, there&apos;re around 100 messages in each segment, each of size around 100 bytes, given the &quot;logIndexIntervalBytes&quot; 4096, there should be at least 2 log index entries, but we see empty index file. The kafka and zookeeper logs are attached&lt;/p&gt;



&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;yye@yye-ld kafka_server_3_logs&amp;#93;&lt;/span&gt;$ cd test_1-2/&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;yye@yye-ld test_1-2&amp;#93;&lt;/span&gt;$ ls -l&lt;br/&gt;
total 84&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;- 1 yye eng        8 Oct 29 15:22 00000000000000000000.index&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;- 1 yye eng    10248 Oct 29 15:22 00000000000000000000.log&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;- 1 yye eng        8 Oct 29 15:22 00000000000000000100.index&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;- 1 yye eng    10296 Oct 29 15:22 00000000000000000100.log&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;- 1 yye eng        0 Oct 29 15:23 00000000000000000200.index&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;- 1 yye eng    10293 Oct 29 15:23 00000000000000000200.log&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;- 1 yye eng        0 Oct 29 15:23 00000000000000000300.index&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;- 1 yye eng    10274 Oct 29 15:23 00000000000000000300.log&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;- 1 yye eng        0 Oct 29 15:23 00000000000000000399.index&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;- 1 yye eng    10276 Oct 29 15:23 00000000000000000399.log&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;- 1 yye eng        0 Oct 29 15:23 00000000000000000498.index&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;- 1 yye eng    10256 Oct 29 15:23 00000000000000000498.log&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;- 1 yye eng 10485760 Oct 29 15:23 00000000000000000596.index&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;- 1 yye eng     3564 Oct 29 15:23 00000000000000000596.log&lt;/p&gt;</description>
                <environment></environment>
        <key id="12613975">KAFKA-593</key>
            <summary>Empty log index file created when it shouldn&apos;t be empty</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="yeyangever">Yang Ye</reporter>
                        <labels>
                    </labels>
                <created>Tue, 30 Oct 2012 00:07:59 +0000</created>
                <updated>Tue, 6 Nov 2012 03:44:23 +0000</updated>
                            <resolved>Tue, 6 Nov 2012 03:44:23 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="13486631" author="jkreps" created="Tue, 30 Oct 2012 03:59:05 +0000"  >&lt;p&gt;I am not sure that this is a bug. The index entries are not placed at exact intervals. Rather, we add a single index entry per append if the bytesSinceLastIndexEntry &amp;gt; indexIntervalBytes. What this means is that you could get a log of 10,296 bytes by appending a single message set of that size or by appending one message set &amp;lt;= 4095 and then another that made up the difference.&lt;/p&gt;

&lt;p&gt;What was batch size being used in this test?&lt;/p&gt;</comment>
                            <comment id="13486990" author="junrao" created="Tue, 30 Oct 2012 16:28:29 +0000"  >&lt;p&gt;Producer used sync mode. So, there is 1 message per batch and each segment has about 100 messages. I expect at least 2 index entries being added per segment.&lt;/p&gt;</comment>
                            <comment id="13487841" author="junrao" created="Wed, 31 Oct 2012 15:12:14 +0000"  >&lt;p&gt;Here is the issue. We rolled a new segment in the follower. The follower in one fetch gets 10k bytes of data and appends to its log. This won&apos;t add any index entry since it&apos;s the very first append to this segment. After the append, the log rolled since the max segment size is reached. This leaves an empty index.&lt;/p&gt;

&lt;p&gt;Technically, the logic is still correct. It does mean that index entries may not be generated as frequently as one expects, depending on the fetch size used in the follower fetcher thread and how far behind a follower is. This may impact consumer performance a bit.&lt;/p&gt;</comment>
                            <comment id="13487878" author="jkreps" created="Wed, 31 Oct 2012 15:46:42 +0000"  >&lt;p&gt;Makes sense, clever. I thought a bit about this during the implementation and decided not to try to make the index entries exact just to reduce complexity. It would be possible to be more exact by having LogSegment calculate inter-messageset positions and append multiple entries to the index if necessary. This would not necessarily be a bad change, but there is definitely some complexity, especially in the face of truncation, so this would need pretty thorough testing.&lt;/p&gt;</comment>
                            <comment id="13487879" author="jkreps" created="Wed, 31 Oct 2012 15:47:14 +0000"  >&lt;p&gt;Err, that should read &quot;intra-messageset positions&quot;.&lt;/p&gt;</comment>
                            <comment id="13489217" author="yeyangever" created="Fri, 2 Nov 2012 02:48:02 +0000"  >
&lt;p&gt;Basically the problem was during restarting the server and truncation from existing log and index files. &lt;/p&gt;

&lt;p&gt;When after the restart or truncation the existing index file is empty (so it&apos;s always full), one of the conditions of maybeRoll() will be true, so a new log segment will be rolled ---- we will end up with two log segments starting from the same offset, one of them is empty.&lt;/p&gt;

&lt;p&gt;To fix it, we change the function trimToSize() in OffsetIndex to trimOrReallocate(), it does either trimming or reallocating the offset index file (and memory mapping). At truncation or restart, it will do reallocation, so that enough space for offset index is allocated.&lt;/p&gt;

&lt;p&gt;We also check existing log segments at roll() function, and throws exception if some segment exists with the same offset as the target offset. (This should not happen)&lt;/p&gt;
</comment>
                            <comment id="13489260" author="junrao" created="Fri, 2 Nov 2012 04:51:49 +0000"  >&lt;p&gt;Thanks for the patch. A couple of comments:&lt;/p&gt;

&lt;p&gt;1. Log.rollToOffset(): We just need to verify that the starting offset of the last segment doesn&apos;t equal to the new offset.&lt;/p&gt;

&lt;p&gt;2. OffsetIndex: When loading the log segment on broker startup, it is possible to have a segment with empty data and empty index. So, we will hit the same issue of rolling a segment with a duplicated name. We probably should extend the index size to max index size in the constructor of OffsetIndex.&lt;/p&gt;</comment>
                            <comment id="13489500" author="jkreps" created="Fri, 2 Nov 2012 15:50:35 +0000"  >&lt;p&gt;trimOrReallocate(isReallocate: Boolean)  is a bit of a hacky interface. This supports resizing to two sizes: entries or maxSize, but it would be better to just implement the more general&lt;br/&gt;
  resize(numEntries: Int)&lt;br/&gt;
numEntries is the mmap.limit/8. It might be nice to leave the helper method trimToSize as a less error prone alias&lt;br/&gt;
  def trimToSize() = resize(entries)&lt;br/&gt;
If we do this we should be able to use resize to implement OffsetIndex.truncateTo (the difference between truncateTo and resize is that truncateTo is in terms of offset whereas resize is in terms of entries).&lt;/p&gt;

&lt;p&gt;We should also add a test case to cover these corner cases.&lt;/p&gt;
</comment>
                            <comment id="13489845" author="yeyangever" created="Fri, 2 Nov 2012 23:41:20 +0000"  >
&lt;p&gt;Jay, Jun,&lt;/p&gt;

&lt;p&gt;Thanks for the comments.&lt;/p&gt;

&lt;p&gt;Jun also pointed out that there may still be cases where at startup, the last log segment has empty index and empty log file ---- and the trimOrReallocate() is not called because it was a clean shutdown before. &lt;/p&gt;

&lt;p&gt;What about an alternative idea, which is, whenever we load a log segment, we always make sure its offset index has enough disk space and memory. In this case, when we truncate back to old segment, its index will not be full, when we start the last log segment with empty log file and index file, its index will also not be full. &lt;/p&gt;

&lt;p&gt;To do this, we just need to change the constructor of OffsetIndex, by always set the index file size and mmap limit to maxIndexSize.&lt;/p&gt;</comment>
                            <comment id="13489889" author="yeyangever" created="Sat, 3 Nov 2012 01:02:28 +0000"  >&lt;p&gt;&lt;br/&gt;
&lt;br/&gt;
Thanks for the discussions, and here&apos;s the third patch which is also verified to be working.&lt;/p&gt;</comment>
                            <comment id="13490770" author="junrao" created="Mon, 5 Nov 2012 17:54:20 +0000"  >&lt;p&gt;Thanks for patch v3. Looks good. Some minor comments.&lt;/p&gt;

&lt;p&gt;30. Log.rollToOffset():  segmentsView.last.index.file.getName.split(&quot;&lt;br class=&quot;atl-forced-newline&quot; /&gt;.&quot;)(0).toLong can just be segmentsView.last.start.&lt;/p&gt;

&lt;p&gt;31. Log.loadSegments(): Just to be consistent. Should we use index.maxIndexSize instead of maxIndexSize in the following statement?&lt;br/&gt;
      logSegments.get(logSegments.size() - 1).index.resetSizeTo(maxIndexSize)&lt;/p&gt;</comment>
                            <comment id="13490858" author="yeyangever" created="Mon, 5 Nov 2012 19:40:00 +0000"  >
&lt;p&gt;For 30,&lt;br/&gt;
It&apos;s fixed&lt;/p&gt;

&lt;p&gt;For 31,&lt;br/&gt;
It seems simpler to keep as it is&lt;/p&gt;


&lt;p&gt;Jay, can you help have a look at this patch?&lt;/p&gt;</comment>
                            <comment id="13490869" author="jkreps" created="Mon, 5 Nov 2012 19:53:41 +0000"  >&lt;p&gt;Looks good, two minor things:&lt;br/&gt;
1. Can we name resetSize to resize?&lt;br/&gt;
2. Can we change the argument to be in terms of number of entries rather than number of bytes? It is incorrect to set to a number of bytes that is not a multiple of the entry size and the entry size is kind of an implementation detail of that class so this would be nicer.&lt;br/&gt;
3. Can we add a test for this case?&lt;/p&gt;</comment>
                            <comment id="13490971" author="jkreps" created="Mon, 5 Nov 2012 21:54:43 +0000"  >&lt;p&gt;Discussed with Victor. (1) and (3) should be doable, but (2) is not very convenient because the usage actually resizes to indexMaxSize which is in terms of bytes. So our solution was to have the API take bytes and just round to a multiple of 8.&lt;/p&gt;</comment>
                            <comment id="13491066" author="yeyangever" created="Tue, 6 Nov 2012 00:08:34 +0000"  >
&lt;p&gt;Thanks for the comments, changes in v5:&lt;/p&gt;

&lt;p&gt;1. rename resetSize() to resize()&lt;br/&gt;
2. add using roundToMultiple() in resize()&lt;br/&gt;
3. add comments to resize()&lt;br/&gt;
4. add one unit test &quot;testIndexResizingAtTruncation&quot; in LogTest for this case&lt;/p&gt;</comment>
                            <comment id="13491082" author="jkreps" created="Tue, 6 Nov 2012 00:20:51 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13491187" author="nehanarkhede" created="Tue, 6 Nov 2012 03:44:23 +0000"  >&lt;p&gt;+1 on v5. Committed this patch&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12613384">KAFKA-583</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12551284" name="kafka_583_zk_kafka_data.tar.gz" size="537981" author="yeyangever" created="Tue, 30 Oct 2012 00:08:18 +0000"/>
                            <attachment id="12551812" name="kafka_593_v1.diff" size="2429" author="yeyangever" created="Fri, 2 Nov 2012 02:48:02 +0000"/>
                            <attachment id="12551947" name="kafka_593_v2.diff" size="2878" author="yeyangever" created="Fri, 2 Nov 2012 23:41:20 +0000"/>
                            <attachment id="12551957" name="kafka_593_v3.diff" size="3802" author="yeyangever" created="Sat, 3 Nov 2012 01:02:28 +0000"/>
                            <attachment id="12552150" name="kafka_593_v4.diff" size="3766" author="yeyangever" created="Mon, 5 Nov 2012 19:47:48 +0000"/>
                            <attachment id="12552187" name="kafka_593_v5.diff" size="6025" author="yeyangever" created="Tue, 6 Nov 2012 00:08:34 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>252903</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            13 years, 3 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0da87:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>75586</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>