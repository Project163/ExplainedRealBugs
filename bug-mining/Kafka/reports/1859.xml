<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:08:26 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6676] System tests do not handle ZK chroot properly with SCRAM</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6676</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;This is related to the issue observed in&#160;&lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6672&quot; title=&quot;ConfigCommand failing to alter configs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6672&quot;&gt;&lt;del&gt;KAFKA-6672&lt;/del&gt;&lt;/a&gt;. There, we are now automatically creating parent nodes if they do not exist. However, if using a chroot within ZK and that chroot does not yet exist, you get an error message about &quot;Path length must be &amp;gt; 0&quot; as it tries to create all the parent paths.&lt;/p&gt;

&lt;p&gt;It would probably be better to be able to detect this issue and account for it, but currently system test code will fail if you use SCRAM and a chroot because while Kafka will create the chroot when it starts up, there are some commands related to security that may need to be executed before that and assume the chroot will already be there.&lt;/p&gt;

&lt;p&gt;We&apos;re currently missing this because while the chroot option is there, nothing in Kafka&apos;s tests are currently exercising it. So given what is apparently a common assumption in tools that the chroot already exists (since I think the core kafka server is the only thing that handles creating it if needed), I think the fix here would be two-fold:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Make KafkaService ensure the chroot exists before running any commands that might need it.&lt;/li&gt;
	&lt;li&gt;On at least one test that exercises security support, use a zk_chroot so that functionality is at least reasonably well exercised.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;It would be good to have this in both trunk and 1.1 branches.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13145986">KAFKA-6676</key>
            <summary>System tests do not handle ZK chroot properly with SCRAM</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ewencp">Ewen Cheslack-Postava</assignee>
                                    <reporter username="ewencp">Ewen Cheslack-Postava</reporter>
                        <labels>
                    </labels>
                <created>Sat, 17 Mar 2018 21:23:14 +0000</created>
                <updated>Fri, 23 Mar 2018 17:02:27 +0000</updated>
                            <resolved>Fri, 23 Mar 2018 17:02:27 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="16403741" author="githubbot" created="Sat, 17 Mar 2018 21:33:29 +0000"  >&lt;p&gt;ewencp opened a new pull request #4729: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6676&quot; title=&quot;System tests do not handle ZK chroot properly with SCRAM&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6676&quot;&gt;&lt;del&gt;KAFKA-6676&lt;/del&gt;&lt;/a&gt;: Ensure Kafka chroot exists in system tests and use chroot on one test with security parameterizations&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4729&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4729&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Ensures Kafka chroot exists in ZK when starting KafkaService so commands that use ZK and are executed before the first Kafka broker starts do not fail due to the missing chroot.&lt;/p&gt;

&lt;p&gt;   Also uses chroot with one test that also has security parameterizations so Kafka&apos;s test suite exercises these combinations. Previously no tests were exercising chroots.&lt;/p&gt;

&lt;p&gt;   To validate, I kicked off a &lt;span class=&quot;error&quot;&gt;&amp;#91;test run&amp;#93;&lt;/span&gt;(&lt;a href=&quot;https://jenkins.confluent.io/job/system-test-kafka-branch-builder/1483/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://jenkins.confluent.io/job/system-test-kafka-branch-builder/1483/&lt;/a&gt;) of the sanity_checks (which include the chroot-ed test as well as some non-chroot-ed tests).&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16404613" author="githubbot" created="Mon, 19 Mar 2018 10:37:05 +0000"  >&lt;p&gt;rajinisivaram closed pull request #4729: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6676&quot; title=&quot;System tests do not handle ZK chroot properly with SCRAM&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6676&quot;&gt;&lt;del&gt;KAFKA-6676&lt;/del&gt;&lt;/a&gt;: Ensure Kafka chroot exists in system tests and use chroot on one test with security parameterizations&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4729&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4729&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/tests/kafkatest/sanity_checks/test_console_consumer.py b/tests/kafkatest/sanity_checks/test_console_consumer.py&lt;br/&gt;
index 066d6d42c14..537755d5820 100644&lt;br/&gt;
&amp;#8212; a/tests/kafkatest/sanity_checks/test_console_consumer.py&lt;br/&gt;
+++ b/tests/kafkatest/sanity_checks/test_console_consumer.py&lt;br/&gt;
@@ -36,7 +36,7 @@ def _&lt;em&gt;init&lt;/em&gt;_(self, test_context):&lt;/p&gt;

&lt;p&gt;         self.topic = &quot;topic&quot;&lt;br/&gt;
         self.zk = ZookeeperService(test_context, num_nodes=1)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;self.kafka = KafkaService(self.test_context, num_nodes=1, zk=self.zk,&lt;br/&gt;
+        self.kafka = KafkaService(self.test_context, num_nodes=1, zk=self.zk, zk_chroot=&quot;/kafka&quot;,&lt;br/&gt;
                                   topics={self.topic: {&quot;partitions&quot;: 1, &quot;replication-factor&quot;: 1}})&lt;br/&gt;
         self.consumer = ConsoleConsumer(self.test_context, num_nodes=1, kafka=self.kafka, topic=self.topic, new_consumer=False)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;diff --git a/tests/kafkatest/services/kafka/kafka.py b/tests/kafkatest/services/kafka/kafka.py&lt;br/&gt;
index e563ab82dab..c4d4b247557 100644&lt;br/&gt;
&amp;#8212; a/tests/kafkatest/services/kafka/kafka.py&lt;br/&gt;
+++ b/tests/kafkatest/services/kafka/kafka.py&lt;br/&gt;
@@ -163,6 +163,8 @@ def start(self, add_principals=&quot;&quot;):&lt;br/&gt;
         self.open_port(self.interbroker_security_protocol)&lt;/p&gt;

&lt;p&gt;         self.start_minikdc(add_principals)&lt;br/&gt;
+        self._ensure_zk_chroot()&lt;br/&gt;
+&lt;br/&gt;
         Service.start(self)&lt;/p&gt;

&lt;p&gt;         self.logger.info(&quot;Waiting for brokers to register at ZK&quot;)&lt;br/&gt;
@@ -183,6 +185,16 @@ def start(self, add_principals=&quot;&quot;):&lt;br/&gt;
                 topic_cfg&lt;span class=&quot;error&quot;&gt;&amp;#91;&amp;quot;topic&amp;quot;&amp;#93;&lt;/span&gt; = topic&lt;br/&gt;
                 self.create_topic(topic_cfg)&lt;/p&gt;

&lt;p&gt;+    def _ensure_zk_chroot(self):&lt;br/&gt;
+        self.logger.info(&quot;Ensuring zk_chroot %s exists&quot;, self.zk_chroot)&lt;br/&gt;
+        if self.zk_chroot:&lt;br/&gt;
+            if not self.zk_chroot.startswith(&apos;/&apos;):&lt;br/&gt;
+                raise Exception(&quot;Zookeeper chroot must start with &apos;/&apos; but found &quot; + self.zk_chroot)&lt;br/&gt;
+&lt;br/&gt;
+            parts = self.zk_chroot.split(&apos;/&apos;)&lt;span class=&quot;error&quot;&gt;&amp;#91;1:&amp;#93;&lt;/span&gt;&lt;br/&gt;
+            for i in range(len(parts)):&lt;br/&gt;
+                self.zk.create(&apos;/&apos; + &apos;/&apos;.join(parts&lt;span class=&quot;error&quot;&gt;&amp;#91;:i+1&amp;#93;&lt;/span&gt;))&lt;br/&gt;
+&lt;br/&gt;
     def set_protocol_and_port(self, node):&lt;br/&gt;
         listeners = []&lt;br/&gt;
         advertised_listeners = []&lt;br/&gt;
diff --git a/tests/kafkatest/services/zookeeper.py b/tests/kafkatest/services/zookeeper.py&lt;br/&gt;
index b181a12210a..5bda867ed7c 100644&lt;br/&gt;
&amp;#8212; a/tests/kafkatest/services/zookeeper.py&lt;br/&gt;
+++ b/tests/kafkatest/services/zookeeper.py&lt;br/&gt;
@@ -103,7 +103,7 @@ def stop_node(self, node):&lt;br/&gt;
         idx = self.idx(node)&lt;br/&gt;
         self.logger.info(&quot;Stopping %s node %d on %s&quot; % (type(self)._&lt;em&gt;name&lt;/em&gt;_, idx, node.account.hostname))&lt;br/&gt;
         node.account.kill_java_processes(self.java_class_name(), allow_fail=False)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;node.account.kill_java_processes(self.java_query_class_name(), allow_fail=False)&lt;br/&gt;
+        node.account.kill_java_processes(self.java_cli_class_name(), allow_fail=False)&lt;br/&gt;
         wait_until(lambda: not self.alive(node), timeout_sec=5, err_msg=&quot;Timed out waiting for zookeeper to stop.&quot;)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     def clean_node(self, node):&lt;br/&gt;
@@ -113,7 +113,7 @@ def clean_node(self, node):&lt;br/&gt;
                              (self._&lt;em&gt;class&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;em&gt;name&lt;/em&gt;_, node.account))&lt;br/&gt;
         node.account.kill_java_processes(self.java_class_name(),&lt;br/&gt;
                                          clean_shutdown=False, allow_fail=True)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;node.account.kill_java_processes(self.java_query_class_name(),&lt;br/&gt;
+        node.account.kill_java_processes(self.java_cli_class_name(),&lt;br/&gt;
                                          clean_shutdown=False, allow_fail=False)&lt;br/&gt;
         node.account.ssh(&quot;rm -rf &amp;#8211; %s&quot; % ZookeeperService.ROOT, allow_fail=False)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -134,18 +134,21 @@ def zookeeper_migration(self, node, zk_acl):&lt;br/&gt;
                        (self.path.script(&quot;zookeeper-security-migration.sh&quot;, node), zk_acl, self.connect_setting())&lt;br/&gt;
         node.account.ssh(la_migra_cmd)&lt;/p&gt;

&lt;p&gt;+    def _check_chroot(self, chroot):&lt;br/&gt;
+        if chroot and not chroot.startswith(&quot;/&quot;):&lt;br/&gt;
+            raise Exception(&quot;ZK chroot must start with &apos;/&apos;, invalid chroot: %s&quot; % chroot)&lt;br/&gt;
+&lt;br/&gt;
     def query(self, path, chroot=None):&lt;br/&gt;
         &quot;&quot;&quot;&lt;br/&gt;
         Queries zookeeper for data associated with &apos;path&apos; and returns all fields in the schema&lt;br/&gt;
         &quot;&quot;&quot;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if chroot and not chroot.startswith(&quot;/&quot;):&lt;/li&gt;
	&lt;li&gt;raise Exception(&quot;ZK chroot must start with &apos;/&apos;, invalid chroot: %s&quot; % chroot)&lt;br/&gt;
+        self._check_chroot(chroot)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         chroot_path = (&apos;&apos; if chroot is None else chroot) + path&lt;/p&gt;

&lt;p&gt;         kafka_run_class = self.path.script(&quot;kafka-run-class.sh&quot;, DEV_BRANCH)&lt;br/&gt;
         cmd = &quot;%s %s -server %s get %s&quot; % \&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;(kafka_run_class, self.java_query_class_name(), self.connect_setting(), chroot_path)&lt;br/&gt;
+              (kafka_run_class, self.java_cli_class_name(), self.connect_setting(), chroot_path)&lt;br/&gt;
         self.logger.debug(cmd)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         node = self.nodes&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;&lt;br/&gt;
@@ -158,10 +161,25 @@ def query(self, path, chroot=None):&lt;br/&gt;
                     result = match.groups()&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;&lt;br/&gt;
         return result&lt;/p&gt;

&lt;p&gt;+    def create(self, path, chroot=None):&lt;br/&gt;
+        &quot;&quot;&quot;&lt;br/&gt;
+        Create an znode at the given path&lt;br/&gt;
+        &quot;&quot;&quot;&lt;br/&gt;
+        self._check_chroot(chroot)&lt;br/&gt;
+&lt;br/&gt;
+        chroot_path = (&apos;&apos; if chroot is None else chroot) + path&lt;br/&gt;
+&lt;br/&gt;
+        kafka_run_class = self.path.script(&quot;kafka-run-class.sh&quot;, DEV_BRANCH)&lt;br/&gt;
+        cmd = &quot;%s %s -server %s create %s &apos;&apos;&quot; % \&lt;br/&gt;
+              (kafka_run_class, self.java_cli_class_name(), self.connect_setting(), chroot_path)&lt;br/&gt;
+        self.logger.debug(cmd)&lt;br/&gt;
+        output = self.nodes&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;.account.ssh_output(cmd)&lt;br/&gt;
+        self.logger.debug(output)&lt;br/&gt;
+&lt;br/&gt;
     def java_class_name(self):&lt;br/&gt;
         &quot;&quot;&quot; The class name of the Zookeeper quorum peers. &quot;&quot;&quot;&lt;br/&gt;
         return &quot;org.apache.zookeeper.server.quorum.QuorumPeerMain&quot;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def java_query_class_name(self):&lt;br/&gt;
+    def java_cli_class_name(self):&lt;br/&gt;
         &quot;&quot;&quot; The class name of the Zookeeper tool within Kafka. &quot;&quot;&quot;&lt;br/&gt;
         return &quot;kafka.tools.ZooKeeperMainWrapper&quot;&lt;/li&gt;
&lt;/ul&gt;





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 35 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3rg7j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>