<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:07:09 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6577] Connect standalone SASL file source and sink test fails without explanation</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6577</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;The &lt;tt&gt;tests/kafkatest/tests/connect/connect_test.py::ConnectStandaloneFileTest.test_file_source_and_sink&lt;/tt&gt; test is failing with the SASL configuration without a sufficient explanation. During the test, the Connect worker fails to start, but the Connect log contains no useful information.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13140009">KAFKA-6577</key>
            <summary>Connect standalone SASL file source and sink test fails without explanation</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rhauch">Randall Hauch</assignee>
                                    <reporter username="rhauch">Randall Hauch</reporter>
                        <labels>
                    </labels>
                <created>Wed, 21 Feb 2018 20:43:23 +0000</created>
                <updated>Wed, 25 Apr 2018 09:43:02 +0000</updated>
                            <resolved>Thu, 22 Feb 2018 09:43:33 +0000</resolved>
                                    <version>1.1.0</version>
                                    <fixVersion>1.1.0</fixVersion>
                    <fixVersion>2.0.0</fixVersion>
                                    <component>connect</component>
                    <component>system tests</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="16371989" author="rhauch" created="Wed, 21 Feb 2018 20:48:27 +0000"  >&lt;p&gt;See &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6578&quot; title=&quot;Connect distributed and standalone worker &amp;#39;main()&amp;#39; methods should catch and log all exceptions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6578&quot;&gt;&lt;del&gt;KAFKA-6578&lt;/del&gt;&lt;/a&gt; for a change to catch and log all runtime exceptions.&lt;/p&gt;</comment>
                            <comment id="16371992" author="rhauch" created="Wed, 21 Feb 2018 20:48:48 +0000"  >&lt;p&gt;There are actual several things compounding to cause the failure and make it difficult to understand the problem.&lt;/p&gt;

&lt;p&gt;First, the &lt;tt&gt;tests/kafkatest/tests/connect/templates/connect_standalone.properties&lt;/tt&gt; is only adding in the broker&apos;s security configuration with the &quot;producer.&quot; and &quot;consumer.&quot; prefixes, but is not adding them with no prefix. The worker uses the AdminClient to connect to the broker to get the Kafka cluster ID and to manage the three internal topics, and the AdminClient is configured via top-level properties. Because the SASL test requires the clients all connect using SASL, the lack of broker security configs means the AdminClient was attempting and failing to connect to the broker. This is corrected by adding the broker&apos;s security configuration to the Connect worker configuration file at the top-level. (This was already being done in the &lt;tt&gt;connect_distributed.properties&lt;/tt&gt; file.)&lt;/p&gt;

&lt;p&gt;Second, the default &lt;tt&gt;request.timeout.ms&lt;/tt&gt; for the AdminClient (and the other clients) is 120 seconds, so the AdminClient was retrying for 120 seconds before it would give up and thrown an error. However, the test was only waiting for 60 seconds before determining that the service failed to start. This can be corrected by setting &lt;tt&gt;request.timeout.ms=10000&lt;/tt&gt; in the Connect worker configurations (both distributed and standalone).&lt;/p&gt;

&lt;p&gt;Third, the Connect workers were recently changed to lookup the Kafka cluster ID before it started the herder. This is unlike the older uses of the AdminClient to find and manage the internal topics, where failure to connect was not necessarily logged correctly but nevertheless still skipped over, relying upon broker auto-topic creation to create the internal topics. (This may be why the test did not fail prior to the recent change to always require a successful AdminClient connection.) Although the worker never got this far in its startup process, the fact that we missed such an error since the prior releases means that failure to connect with the AdminClient was not being properly reported.&lt;/p&gt;</comment>
                            <comment id="16372223" author="githubbot" created="Wed, 21 Feb 2018 23:42:21 +0000"  >&lt;p&gt;rhauch opened a new pull request #4610: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6577&quot; title=&quot;Connect standalone SASL file source and sink test fails without explanation&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6577&quot;&gt;&lt;del&gt;KAFKA-6577&lt;/del&gt;&lt;/a&gt;: Fix Connect system tests and add debug messages&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4610&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4610&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   *&lt;b&gt;NOTE: This should be backported to the `1.1` branch, and is currently a blocker for 1.1.&lt;/b&gt;*&lt;/p&gt;

&lt;p&gt;   The `connect_test.py::ConnectStandaloneFileTest.test_file_source_and_sink` system test is failing with the SASL configuration without a sufficient explanation. During the test, the Connect worker fails to start, but the Connect log contains no useful information. There are actual several things compounding to cause the failure and make it difficult to understand the problem.&lt;/p&gt;

&lt;p&gt;   First, the `tests/kafkatest/tests/connect/templates/connect_standalone.properties` is only adding in the broker&apos;s security configuration with the `producer.` and `consumer.` prefixes, but is not adding them with no prefix. The worker uses the AdminClient to connect to the broker to get the Kafka cluster ID and to manage the three internal topics, and the AdminClient is configured via top-level properties. Because the SASL test requires the clients all connect using SASL, the lack of broker security configs means the AdminClient was attempting and failing to connect to the broker. This is corrected by adding the broker&apos;s security configuration to the Connect worker configuration file at the top-level. (This was already being done in the `connect_distributed.properties` file.)&lt;/p&gt;

&lt;p&gt;   Second, the default `request.timeout.ms` for the AdminClient (and the other clients) is 120 seconds, so the AdminClient was retrying for 120 seconds before it would give up and thrown an error. However, the test was only waiting for 60 seconds before determining that the service failed to start. This can be corrected by setting `request.timeout.ms=10000` in the Connect distributed and standalone worker configurations.&lt;/p&gt;

&lt;p&gt;   Third, the Connect workers were recently changed to lookup the Kafka cluster ID before it started the herder. This is unlike the older uses of the AdminClient to find and manage the internal topics, where failure to connect was not necessarily logged correctly but nevertheless still skipped over, relying upon broker auto-topic creation to create the internal topics. (This may be why the test did not fail prior to the recent change to always require a successful AdminClient connection.) Although the worker never got this far in its startup process, the fact that we missed such an error since the prior releases means that failure to connect with the AdminClient was not being properly reported.&lt;/p&gt;

&lt;p&gt;   The `ConnectStandaloneFileTest.test_file_source_and_sink` system tests were run locally prior to this fix, and they failed as with the nightlies. Once these fixes were made, the locally run system tests passed.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16372605" author="damianguy" created="Thu, 22 Feb 2018 09:43:33 +0000"  >&lt;p&gt;Issue resolved by pull request 4610&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/pull/4610&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4610&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16372606" author="githubbot" created="Thu, 22 Feb 2018 09:44:02 +0000"  >&lt;p&gt;dguy closed pull request #4610: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6577&quot; title=&quot;Connect standalone SASL file source and sink test fails without explanation&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6577&quot;&gt;&lt;del&gt;KAFKA-6577&lt;/del&gt;&lt;/a&gt;: Fix Connect system tests and add debug messages&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4610&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4610&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java b/connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java&lt;br/&gt;
index 4afa47dda1a..3b7ec87f644 100644&lt;br/&gt;
&amp;#8212; a/connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java&lt;br/&gt;
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java&lt;br/&gt;
@@ -74,6 +74,7 @@ public static void main(String[] args) throws Exception {&lt;br/&gt;
         DistributedConfig config = new DistributedConfig(workerProps);&lt;/p&gt;

&lt;p&gt;         String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);&lt;br/&gt;
+        log.debug(&quot;Kafka cluster ID: {}&quot;, kafkaClusterId);&lt;/p&gt;

&lt;p&gt;         RestServer rest = new RestServer(config);&lt;br/&gt;
         URI advertisedUrl = rest.advertisedUrl();&lt;br/&gt;
diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java b/connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java&lt;br/&gt;
index 17699053541..413cb46cf28 100644&lt;br/&gt;
&amp;#8212; a/connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java&lt;br/&gt;
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java&lt;br/&gt;
@@ -78,6 +78,7 @@ public static void main(String[] args) throws Exception {&lt;br/&gt;
         StandaloneConfig config = new StandaloneConfig(workerProps);&lt;/p&gt;

&lt;p&gt;         String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);&lt;br/&gt;
+        log.debug(&quot;Kafka cluster ID: {}&quot;, kafkaClusterId);&lt;/p&gt;

&lt;p&gt;         RestServer rest = new RestServer(config);&lt;br/&gt;
         URI advertisedUrl = rest.advertisedUrl();&lt;br/&gt;
diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/storage/KafkaConfigBackingStore.java b/connect/runtime/src/main/java/org/apache/kafka/connect/storage/KafkaConfigBackingStore.java&lt;br/&gt;
index b34e48390e1..e51b365cec6 100644&lt;br/&gt;
&amp;#8212; a/connect/runtime/src/main/java/org/apache/kafka/connect/storage/KafkaConfigBackingStore.java&lt;br/&gt;
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/storage/KafkaConfigBackingStore.java&lt;br/&gt;
@@ -432,6 +432,7 @@ public void putTargetState(String connector, TargetState state) {&lt;br/&gt;
         Runnable createTopics = new Runnable() {&lt;br/&gt;
             @Override&lt;br/&gt;
             public void run() {&lt;br/&gt;
+                log.debug(&quot;Creating admin client to manage Connect internal config topic&quot;);&lt;br/&gt;
                 try (TopicAdmin admin = new TopicAdmin(adminProps)) &lt;/p&gt;
{
                     admin.createTopics(topicDescription);
                 }&lt;br/&gt;
diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/storage/KafkaOffsetBackingStore.java b/connect/runtime/src/main/java/org/apache/kafka/connect/storage/KafkaOffsetBackingStore.java&lt;br/&gt;
index f29f3c23d03..fb8ad97b48d 100644&lt;br/&gt;
&amp;#8212; a/connect/runtime/src/main/java/org/apache/kafka/connect/storage/KafkaOffsetBackingStore.java&lt;br/&gt;
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/storage/KafkaOffsetBackingStore.java&lt;br/&gt;
@@ -94,6 +94,7 @@ public void configure(final WorkerConfig config) {&lt;br/&gt;
         Runnable createTopics = new Runnable() {&lt;br/&gt;
             @Override&lt;br/&gt;
             public void run() {&lt;br/&gt;
+                log.debug(&quot;Creating admin client to manage Connect internal offset topic&quot;);&lt;br/&gt;
                 try (TopicAdmin admin = new TopicAdmin(adminProps)) {                     admin.createTopics(topicDescription);                 }
&lt;p&gt;diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/storage/KafkaStatusBackingStore.java b/connect/runtime/src/main/java/org/apache/kafka/connect/storage/KafkaStatusBackingStore.java&lt;br/&gt;
index 8ca21ebb350..6710808f9a9 100644&lt;br/&gt;
&amp;#8212; a/connect/runtime/src/main/java/org/apache/kafka/connect/storage/KafkaStatusBackingStore.java&lt;br/&gt;
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/storage/KafkaStatusBackingStore.java&lt;br/&gt;
@@ -157,6 +157,7 @@ public void onCompletion(Throwable error, ConsumerRecord&amp;lt;String, byte[]&amp;gt; record)&lt;br/&gt;
         Runnable createTopics = new Runnable() {&lt;br/&gt;
             @Override&lt;br/&gt;
             public void run() {&lt;br/&gt;
+                log.debug(&quot;Creating admin client to manage Connect internal status topic&quot;);&lt;br/&gt;
                 try (TopicAdmin admin = new TopicAdmin(adminProps)) &lt;/p&gt;
{
                     admin.createTopics(topicDescription);
                 }
&lt;p&gt;diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/util/ConnectUtils.java b/connect/runtime/src/main/java/org/apache/kafka/connect/util/ConnectUtils.java&lt;br/&gt;
index 19452047fcb..9f30236fdee 100644&lt;br/&gt;
&amp;#8212; a/connect/runtime/src/main/java/org/apache/kafka/connect/util/ConnectUtils.java&lt;br/&gt;
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/util/ConnectUtils.java&lt;br/&gt;
@@ -40,6 +40,7 @@ else if (timestamp == RecordBatch.NO_TIMESTAMP)&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;     public static String lookupKafkaClusterId(WorkerConfig config) {&lt;br/&gt;
+        log.info(&quot;Creating Kafka admin client&quot;);&lt;br/&gt;
         try (AdminClient adminClient = AdminClient.create(config.originals())) &lt;/p&gt;
{
             return lookupKafkaClusterId(adminClient);
         }
&lt;p&gt;@@ -53,13 +54,15 @@ static String lookupKafkaClusterId(AdminClient adminClient) &lt;/p&gt;
{
                 log.info(&quot;Kafka cluster version is too old to return cluster ID&quot;);
                 return null;
             }
&lt;p&gt;+            log.debug(&quot;Fetching Kafka cluster ID&quot;);&lt;br/&gt;
             String kafkaClusterId = clusterIdFuture.get();&lt;br/&gt;
             log.info(&quot;Kafka cluster ID: {}&quot;, kafkaClusterId);&lt;br/&gt;
             return kafkaClusterId;&lt;br/&gt;
         } catch (InterruptedException e) &lt;/p&gt;
{
             throw new ConnectException(&quot;Unexpectedly interrupted when looking up Kafka cluster info&quot;, e);
         }
&lt;p&gt; catch (ExecutionException e) &lt;/p&gt;
{
-            throw new ConnectException(&quot;Failed to connect to and describe Kafka cluster&quot;, e);
+            throw new ConnectException(&quot;Failed to connect to and describe Kafka cluster. &quot;
+                                       + &quot;Check worker&apos;s broker connection and security properties.&quot;, e);
         }
&lt;p&gt;     }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/tests/kafkatest/tests/connect/connect_test.py b/tests/kafkatest/tests/connect/connect_test.py&lt;br/&gt;
index 9436119f886..37538763337 100644&lt;br/&gt;
&amp;#8212; a/tests/kafkatest/tests/connect/connect_test.py&lt;br/&gt;
+++ b/tests/kafkatest/tests/connect/connect_test.py&lt;br/&gt;
@@ -91,7 +91,7 @@ def test_file_source_and_sink(self, converter=&quot;org.apache.kafka.connect.json.Jso&lt;br/&gt;
         self.source = ConnectStandaloneService(self.test_context, self.kafka, &lt;span class=&quot;error&quot;&gt;&amp;#91;self.INPUT_FILE, self.OFFSETS_FILE&amp;#93;&lt;/span&gt;)&lt;br/&gt;
         self.sink = ConnectStandaloneService(self.test_context, self.kafka, &lt;span class=&quot;error&quot;&gt;&amp;#91;self.OUTPUT_FILE, self.OFFSETS_FILE&amp;#93;&lt;/span&gt;)&lt;br/&gt;
         self.consumer_validator = ConsoleConsumer(self.test_context, 1, self.kafka, self.TOPIC,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;consumer_timeout_ms=1000)&lt;br/&gt;
+                                                  consumer_timeout_ms=10000)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         self.zk.start()&lt;br/&gt;
         self.kafka.start()&lt;br/&gt;
diff --git a/tests/kafkatest/tests/connect/templates/connect-distributed.properties b/tests/kafkatest/tests/connect/templates/connect-distributed.properties&lt;br/&gt;
index 6660e6c0e34..a1d3de29d51 100644&lt;br/&gt;
&amp;#8212; a/tests/kafkatest/tests/connect/templates/connect-distributed.properties&lt;br/&gt;
+++ b/tests/kafkatest/tests/connect/templates/connect-distributed.properties&lt;br/&gt;
@@ -52,3 +52,6 @@ rest.advertised.host.name = {{ node.account.hostname }}&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Reduce session timeouts so tests that kill workers don&apos;t need to wait as long to recover&lt;br/&gt;
 session.timeout.ms=10000&lt;br/&gt;
 consumer.session.timeout.ms=10000&lt;br/&gt;
+&lt;br/&gt;
+# Reduce the admin client request timeouts so that we don&apos;t wait the default 120 sec before failing to connect the admin client&lt;br/&gt;
+request.timeout.ms=30000&lt;br/&gt;
diff --git a/tests/kafkatest/tests/connect/templates/connect-standalone.properties b/tests/kafkatest/tests/connect/templates/connect-standalone.properties&lt;br/&gt;
index 09c648720c7..5f079f7a396 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/tests/kafkatest/tests/connect/templates/connect-standalone.properties&lt;br/&gt;
+++ b/tests/kafkatest/tests/connect/templates/connect-standalone.properties&lt;br/&gt;
@@ -14,6 +14,7 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt; bootstrap.servers={{ kafka.bootstrap_servers(kafka.security_config.security_protocol) }}&lt;br/&gt;
+{{ kafka.security_config.client_config().props() }}&lt;br/&gt;
 {{ kafka.security_config.client_config().props(&quot;producer.&quot;) }}&lt;br/&gt;
 {{ kafka.security_config.client_config().props(&quot;consumer.&quot;) }}&lt;/p&gt;

&lt;p&gt;@@ -32,3 +33,6 @@ internal.key.converter.schemas.enable=false&lt;br/&gt;
 internal.value.converter.schemas.enable=false&lt;/p&gt;

&lt;p&gt; offset.storage.file.filename={{ OFFSETS_FILE }}&lt;br/&gt;
+&lt;br/&gt;
+# Reduce the admin client request timeouts so that we don&apos;t wait the default 120 sec before failing to connect the admin client&lt;br/&gt;
+request.timeout.ms=30000&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13140011">KAFKA-6578</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 38 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3qftb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>