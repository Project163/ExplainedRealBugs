<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:15:32 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-7366] topic level segment.bytes and segment.ms not taking effect immediately</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-7366</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;It used to be that topic level configs such as segment.bytes takes effect immediately. Because of&#160;&lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6324&quot; title=&quot;Change LogSegment.delete to deleteIfExists and harden log recovery&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6324&quot;&gt;&lt;del&gt;KAFKA-6324&lt;/del&gt;&lt;/a&gt; in 1.1, those configs now only take effect after the active segment has rolled. The relevant part of &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6324&quot; title=&quot;Change LogSegment.delete to deleteIfExists and harden log recovery&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6324&quot;&gt;&lt;del&gt;KAFKA-6324&lt;/del&gt;&lt;/a&gt; is that in Log.maybeRoll, the checking of the segment rolling is moved to LogSegment.shouldRoll().&lt;/p&gt;</description>
                <environment></environment>
        <key id="13182387">KAFKA-7366</key>
            <summary>topic level segment.bytes and segment.ms not taking effect immediately</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="omkreddy">Manikumar</assignee>
                                    <reporter username="junrao">Jun Rao</reporter>
                        <labels>
                    </labels>
                <created>Fri, 31 Aug 2018 16:38:51 +0000</created>
                <updated>Tue, 9 Oct 2018 17:46:17 +0000</updated>
                            <resolved>Tue, 9 Oct 2018 17:46:17 +0000</resolved>
                                    <version>1.1.0</version>
                    <version>2.0.0</version>
                                    <fixVersion>2.1.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="16598993" author="ijuma" created="Fri, 31 Aug 2018 16:43:07 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rsivaram&quot; class=&quot;user-hover&quot; rel=&quot;rsivaram&quot;&gt;rsivaram&lt;/a&gt; noticed this while working on dynamic configs as well. We discussed it then and I&apos;m not sure what was the conclusion. I guess you&apos;re saying we should change it back &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="16599003" author="junrao" created="Fri, 31 Aug 2018 16:48:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt;, it might be debatable. However, if all other topic level configs take effect immediately, it seems that we should make that consistent for all configs.&lt;/p&gt;</comment>
                            <comment id="16635806" author="githubbot" created="Tue, 2 Oct 2018 16:50:16 +0000"  >&lt;p&gt;omkreddy opened a new pull request #5728: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7366&quot; title=&quot;topic level segment.bytes and segment.ms not taking effect immediately&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7366&quot;&gt;&lt;del&gt;KAFKA-7366&lt;/del&gt;&lt;/a&gt;: Make topic configs segment.bytes and segment.ms to take effect immediately&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5728&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5728&lt;/a&gt;&lt;/p&gt;




&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16643791" author="githubbot" created="Tue, 9 Oct 2018 17:37:57 +0000"  >&lt;p&gt;junrao closed pull request #5728: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7366&quot; title=&quot;topic level segment.bytes and segment.ms not taking effect immediately&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7366&quot;&gt;&lt;del&gt;KAFKA-7366&lt;/del&gt;&lt;/a&gt;: Make topic configs segment.bytes and segment.ms to take effect immediately&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5728&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5728&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/core/src/main/scala/kafka/log/Log.scala b/core/src/main/scala/kafka/log/Log.scala&lt;br/&gt;
index 094473a8e26..bc328d77efc 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/log/Log.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/log/Log.scala&lt;br/&gt;
@@ -145,6 +145,26 @@ case class CompletedTxn(producerId: Long, firstOffset: Long, lastOffset: Long, i&lt;br/&gt;
   }&lt;br/&gt;
 }&lt;/p&gt;

&lt;p&gt;+/**&lt;br/&gt;
+ * A class used to hold params required to decide to rotate a log segment or not.&lt;br/&gt;
+ */&lt;br/&gt;
+case class RollParams(maxSegmentMs: Long,&lt;br/&gt;
+                      maxSegmentBytes: Int,&lt;br/&gt;
+                      maxTimestampInMessages: Long,&lt;br/&gt;
+                      maxOffsetInMessages: Long,&lt;br/&gt;
+                      messagesSize: Int,&lt;br/&gt;
+                      now: Long)&lt;br/&gt;
+&lt;br/&gt;
+object RollParams {&lt;br/&gt;
+  def apply(config: LogConfig, appendInfo: LogAppendInfo, messagesSize: Int, now: Long): RollParams = &lt;/p&gt;
{
+   new RollParams(config.segmentMs,
+     config.segmentSize,
+     appendInfo.maxTimestamp,
+     appendInfo.lastOffset,
+     messagesSize, now)
+  }
&lt;p&gt;+}&lt;br/&gt;
+&lt;br/&gt;
 /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;An append-only log for storing messages.&lt;br/&gt;
  *&lt;br/&gt;
@@ -1493,7 +1513,7 @@ class Log(@volatile var dir: File,&lt;br/&gt;
     val maxTimestampInMessages = appendInfo.maxTimestamp&lt;br/&gt;
     val maxOffsetInMessages = appendInfo.lastOffset&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (segment.shouldRoll(messagesSize, maxTimestampInMessages, maxOffsetInMessages, now)) {&lt;br/&gt;
+    if (segment.shouldRoll(RollParams(config, appendInfo, messagesSize, now))) {&lt;br/&gt;
       debug(s&quot;Rolling new log segment (log_size = ${segment.size}/${config.segmentSize}}, &quot; +&lt;br/&gt;
         s&quot;offset_index_size = ${segment.offsetIndex.entries}/${segment.offsetIndex.maxEntries}, &quot; +&lt;br/&gt;
         s&quot;time_index_size = ${segment.timeIndex.entries}/${segment.timeIndex.maxEntries}, &quot; +&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/log/LogSegment.scala b/core/src/main/scala/kafka/log/LogSegment.scala&lt;br/&gt;
index 80763a8d797..d910a29100c 100755
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/main/scala/kafka/log/LogSegment.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/log/LogSegment.scala&lt;br/&gt;
@@ -45,8 +45,10 @@ import scala.math._&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param log The file records containing log entries&lt;/li&gt;
	&lt;li&gt;@param offsetIndex The offset index&lt;/li&gt;
	&lt;li&gt;@param timeIndex The timestamp index&lt;br/&gt;
+ * @param txnIndex The transaction index&lt;/li&gt;
	&lt;li&gt;@param baseOffset A lower bound on the offsets in this segment&lt;/li&gt;
	&lt;li&gt;@param indexIntervalBytes The approximate number of bytes between entries in the index&lt;br/&gt;
+ * @param rollJitterMs The maximum random jitter subtracted from the scheduled segment roll time&lt;/li&gt;
	&lt;li&gt;@param time The time instance&lt;br/&gt;
  */&lt;br/&gt;
 @nonthreadsafe&lt;br/&gt;
@@ -57,15 +59,13 @@ class LogSegment private&lt;span class=&quot;error&quot;&gt;&amp;#91;log&amp;#93;&lt;/span&gt; (val log: FileRecords,&lt;br/&gt;
                                val baseOffset: Long,&lt;br/&gt;
                                val indexIntervalBytes: Int,&lt;br/&gt;
                                val rollJitterMs: Long,&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val maxSegmentMs: Long,&lt;/li&gt;
	&lt;li&gt;val maxSegmentBytes: Int,&lt;br/&gt;
                                val time: Time) extends Logging {&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def shouldRoll(messagesSize: Int, maxTimestampInMessages: Long, maxOffsetInMessages: Long, now: Long): Boolean = {&lt;/li&gt;
	&lt;li&gt;val reachedRollMs = timeWaitedForRoll(now, maxTimestampInMessages) &amp;gt; maxSegmentMs - rollJitterMs&lt;/li&gt;
	&lt;li&gt;size &amp;gt; maxSegmentBytes - messagesSize ||&lt;br/&gt;
+  def shouldRoll(rollParams: RollParams): Boolean = 
{
+    val reachedRollMs = timeWaitedForRoll(rollParams.now, rollParams.maxTimestampInMessages) &amp;gt; rollParams.maxSegmentMs - rollJitterMs
+    size &amp;gt; rollParams.maxSegmentBytes - rollParams.messagesSize ||
       (size &amp;gt; 0 &amp;amp;&amp;amp; reachedRollMs) ||
-      offsetIndex.isFull || timeIndex.isFull || !canConvertToRelativeOffset(maxOffsetInMessages)
+      offsetIndex.isFull || timeIndex.isFull || !canConvertToRelativeOffset(rollParams.maxOffsetInMessages)
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def resizeIndexes(size: Int): Unit = {&lt;br/&gt;
@@ -637,8 +637,6 @@ object LogSegment &lt;/p&gt;
{
       baseOffset,
       indexIntervalBytes = config.indexInterval,
       rollJitterMs = config.randomSegmentJitter,
-      maxSegmentMs = config.segmentMs,
-      maxSegmentBytes = config.segmentSize,
       time)
   }

&lt;p&gt;diff --git a/core/src/test/scala/unit/kafka/log/LogSegmentTest.scala b/core/src/test/scala/unit/kafka/log/LogSegmentTest.scala&lt;br/&gt;
index 40b687443a0..353e5537588 100644&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/log/LogSegmentTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/log/LogSegmentTest.scala&lt;br/&gt;
@@ -38,9 +38,8 @@ class LogSegmentTest {&lt;br/&gt;
   /* create a segment with the given base offset */&lt;br/&gt;
   def createSegment(offset: Long,&lt;br/&gt;
                     indexIntervalBytes: Int = 10,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;maxSegmentMs: Int = Int.MaxValue,&lt;br/&gt;
                     time: Time = Time.SYSTEM): LogSegment = 
{
-    val seg = LogUtils.createSegment(offset, logDir, indexIntervalBytes, maxSegmentMs, time)
+    val seg = LogUtils.createSegment(offset, logDir, indexIntervalBytes, time)
     segments += seg
     seg
   }
&lt;p&gt;@@ -163,10 +162,10 @@ class LogSegmentTest {&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val maxSegmentMs = 300000&lt;br/&gt;
     val time = new MockTime&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val seg = createSegment(0, maxSegmentMs = maxSegmentMs, time = time)&lt;br/&gt;
+    val seg = createSegment(0, time = time)&lt;br/&gt;
     seg.close()&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val reopened = createSegment(0, maxSegmentMs = maxSegmentMs, time = time)&lt;br/&gt;
+    val reopened = createSegment(0, time = time)&lt;br/&gt;
     assertEquals(0, seg.timeIndex.sizeInBytes)&lt;br/&gt;
     assertEquals(0, seg.offsetIndex.sizeInBytes)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -176,24 +175,21 @@ class LogSegmentTest &lt;/p&gt;
{
     assertFalse(reopened.timeIndex.isFull)
     assertFalse(reopened.offsetIndex.isFull)
 
-    assertFalse(reopened.shouldRoll(messagesSize = 1024,
-      maxTimestampInMessages = RecordBatch.NO_TIMESTAMP,
-      maxOffsetInMessages = 100L,
-      now = time.milliseconds()))
+    var rollParams = RollParams(maxSegmentMs, maxSegmentBytes = Int.MaxValue, RecordBatch.NO_TIMESTAMP,
+      maxOffsetInMessages = 100L, messagesSize = 1024, time.milliseconds())
+    assertFalse(reopened.shouldRoll(rollParams))
 
     // The segment should not be rolled even if maxSegmentMs has been exceeded
     time.sleep(maxSegmentMs + 1)
     assertEquals(maxSegmentMs + 1, reopened.timeWaitedForRoll(time.milliseconds(), RecordBatch.NO_TIMESTAMP))
-    assertFalse(reopened.shouldRoll(messagesSize = 1024,
-      maxTimestampInMessages = RecordBatch.NO_TIMESTAMP,
-      maxOffsetInMessages = 100L,
-      now = time.milliseconds()))
+    rollParams = RollParams(maxSegmentMs, maxSegmentBytes = Int.MaxValue, RecordBatch.NO_TIMESTAMP,
+      maxOffsetInMessages = 100L, messagesSize = 1024, time.milliseconds())
+    assertFalse(reopened.shouldRoll(rollParams))
 
     // But we should still roll the segment if we cannot fit the next offset
-    assertTrue(reopened.shouldRoll(messagesSize = 1024,
-      maxTimestampInMessages = RecordBatch.NO_TIMESTAMP,
-      maxOffsetInMessages = Int.MaxValue.toLong + 200,
-      now = time.milliseconds()))
+    rollParams = RollParams(maxSegmentMs, maxSegmentBytes = Int.MaxValue, RecordBatch.NO_TIMESTAMP,
+      maxOffsetInMessages = Int.MaxValue.toLong + 200L, messagesSize = 1024, time.milliseconds())
+    assertTrue(reopened.shouldRoll(rollParams))
   }

&lt;p&gt;   @Test&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/log/LogTest.scala b/core/src/test/scala/unit/kafka/log/LogTest.scala&lt;br/&gt;
index 151c4ed0ad8..77289989546 100755&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/log/LogTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/log/LogTest.scala&lt;br/&gt;
@@ -277,7 +277,7 @@ class LogTest {&lt;/p&gt;

&lt;p&gt;         override def addSegment(segment: LogSegment): LogSegment = {&lt;br/&gt;
           val wrapper = new LogSegment(segment.log, segment.offsetIndex, segment.timeIndex, segment.txnIndex, segment.baseOffset,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;segment.indexIntervalBytes, segment.rollJitterMs, segment.maxSegmentMs, segment.maxSegmentBytes, mockTime) {&lt;br/&gt;
+            segment.indexIntervalBytes, segment.rollJitterMs, mockTime) {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             override def read(startOffset: Long, maxOffset: Option&lt;span class=&quot;error&quot;&gt;&amp;#91;Long&amp;#93;&lt;/span&gt;, maxSize: Int, maxPosition: Long,&lt;br/&gt;
                               minOneMessage: Boolean): FetchDataInfo = {&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/log/LogUtils.scala b/core/src/test/scala/unit/kafka/log/LogUtils.scala&lt;br/&gt;
index eb218952d0a..8652aa509d0 100644&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/log/LogUtils.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/log/LogUtils.scala&lt;br/&gt;
@@ -29,13 +29,12 @@ object LogUtils {&lt;br/&gt;
   def createSegment(offset: Long,&lt;br/&gt;
                     logDir: File,&lt;br/&gt;
                     indexIntervalBytes: Int = 10,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;maxSegmentMs: Int = Int.MaxValue,&lt;br/&gt;
                     time: Time = Time.SYSTEM): LogSegment = 
{
     val ms = FileRecords.open(Log.logFile(logDir, offset))
     val idx = new OffsetIndex(Log.offsetIndexFile(logDir, offset), offset, maxIndexSize = 1000)
     val timeIdx = new TimeIndex(Log.timeIndexFile(logDir, offset), offset, maxIndexSize = 1500)
     val txnIndex = new TransactionIndex(offset, Log.transactionIndexFile(logDir, offset))
 
-    new LogSegment(ms, idx, timeIdx, txnIndex, offset, indexIntervalBytes, 0, maxSegmentMs, Int.MaxValue, time)
+    new LogSegment(ms, idx, timeIdx, txnIndex, offset, indexIntervalBytes, 0, time)
   }
&lt;p&gt; }&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/server/DynamicConfigChangeTest.scala b/core/src/test/scala/unit/kafka/server/DynamicConfigChangeTest.scala&lt;br/&gt;
index 510c4a3e273..cabe0a984e2 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/test/scala/unit/kafka/server/DynamicConfigChangeTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/server/DynamicConfigChangeTest.scala&lt;br/&gt;
@@ -59,6 +59,33 @@ class DynamicConfigChangeTest extends KafkaServerTestHarness {&lt;br/&gt;
     }&lt;br/&gt;
   }&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+  @Test&lt;br/&gt;
+  def testDynamicTopicConfigChange() {&lt;br/&gt;
+    val tp = new TopicPartition(&quot;test&quot;, 0)&lt;br/&gt;
+    val oldSegmentSize = 1000&lt;br/&gt;
+    val logProps = new Properties()&lt;br/&gt;
+    logProps.put(SegmentBytesProp, oldSegmentSize.toString)&lt;br/&gt;
+    createTopic(tp.topic, 1, 1, logProps)&lt;br/&gt;
+    TestUtils.retry(10000) &lt;/p&gt;
{
+      val logOpt = this.servers.head.logManager.getLog(tp)
+      assertTrue(logOpt.isDefined)
+      assertEquals(oldSegmentSize, logOpt.get.config.segmentSize)
+    }
&lt;p&gt;+&lt;br/&gt;
+    val log = servers.head.logManager.getLog(tp).get&lt;br/&gt;
+&lt;br/&gt;
+    val newSegmentSize = 2000&lt;br/&gt;
+    logProps.put(SegmentBytesProp, newSegmentSize.toString)&lt;br/&gt;
+    adminZkClient.changeTopicConfig(tp.topic, logProps)&lt;br/&gt;
+    TestUtils.retry(10000) &lt;/p&gt;
{
+      assertEquals(newSegmentSize, log.config.segmentSize)
+    }
&lt;p&gt;+&lt;br/&gt;
+    (1 to 50).foreach(i =&amp;gt; TestUtils.produceMessage(servers, tp.topic, i.toString))&lt;br/&gt;
+    // Verify that the new config is used for all segments&lt;br/&gt;
+    assertTrue(&quot;Log segment size change not applied&quot;, log.logSegments.forall(_.size &amp;gt; 1000))&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
   private def testQuotaConfigChange(user: String, clientId: String, rootEntityType: String, configEntityName: String) {&lt;br/&gt;
     assertTrue(&quot;Should contain a ConfigHandler for &quot; + rootEntityType ,&lt;br/&gt;
                this.servers.head.dynamicConfigHandlers.contains(rootEntityType))&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16643798" author="junrao" created="Tue, 9 Oct 2018 17:46:17 +0000"  >&lt;p&gt;Merged to 2.1 and trunk.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="13181853">KAFKA-7355</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 5 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3xmuv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>