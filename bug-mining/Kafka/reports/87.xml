<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:35:34 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-391] Producer request and response classes should use maps</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-391</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Producer response contains two arrays of error codes and offsets - the ordering in these arrays correspond to the flattened ordering of the request arrays.&lt;/p&gt;

&lt;p&gt;It would be better to switch to maps in the request and response as this would make the code clearer and more efficient (right now, linear scans are used in handling producer acks).&lt;/p&gt;

&lt;p&gt;We can probably do the same in the fetch request/response.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12596693">KAFKA-391</key>
            <summary>Producer request and response classes should use maps</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jjkoshy">Joel Jacob Koshy</assignee>
                                    <reporter username="jjkoshy">Joel Jacob Koshy</reporter>
                        <labels>
                            <label>optimization</label>
                    </labels>
                <created>Mon, 2 Jul 2012 18:32:38 +0000</created>
                <updated>Fri, 7 Nov 2014 06:57:57 +0000</updated>
                            <resolved>Mon, 17 Sep 2012 20:21:31 +0000</resolved>
                                                    <fixVersion>0.8.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="13448121" author="jjkoshy" created="Tue, 4 Sep 2012 22:26:56 +0000"  >&lt;p&gt;Attached a draft patch. I was out of action for the last two weeks and 0.8&lt;br/&gt;
has moved along quite a bit, so this will need a significant rebase. (This&lt;br/&gt;
patch should cleanly apply on r1374069.) Before I spend time rebasing I was&lt;br/&gt;
hoping to get some high-level feedback on this change. I think it makes the&lt;br/&gt;
code clearer and likely more efficient (although an extensive perf test is&lt;br/&gt;
pending).&lt;/p&gt;

&lt;p&gt;It is pretty straightforward and should be quick to review at least for this&lt;br/&gt;
round. The main changes are as follows:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Switched to maps for the data/status in the producer request/response&lt;br/&gt;
  classes.&lt;/li&gt;
	&lt;li&gt;I&apos;m using SortedMap as that helps with the serializing to the wire format.&lt;br/&gt;
  The maps of course are only in memory. The wire format is mostly the same&lt;br/&gt;
  although I modified the response format to include topic names (similar to&lt;br/&gt;
  the request format). This is not strictly required but I think it is&lt;br/&gt;
  clearer this way.&lt;/li&gt;
	&lt;li&gt;Made some of the related code simpler/clearer (e.g., produceToLocalLog,&lt;br/&gt;
  DelayedProduce.respond, etc.)&lt;/li&gt;
	&lt;li&gt;Minor fixes in the tests due to the above changes.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13448180" author="jjkoshy" created="Tue, 4 Sep 2012 23:20:57 +0000"  >&lt;p&gt;One more comment I forgot to add above: we can/should probably get rid of the global&lt;br/&gt;
error code in ProducerResponse as it is unused and does not seem to make sense&lt;br/&gt;
anyway in the absence of a &quot;generic error&quot; code.&lt;/p&gt;</comment>
                            <comment id="13448915" author="junrao" created="Wed, 5 Sep 2012 17:40:12 +0000"  >&lt;p&gt;Thanks for the patch. Some comments:&lt;/p&gt;

&lt;p&gt;1. We probably shouldn&apos;t use scala sortedMap in kafka.javaapi.ProducerRequest. On that thought, why can&apos;t ProducerRequest take a regular map in the constructor? If we want some ordering on the serialized data, we can sort the map before serialization. SortedMap seems to reveal an implementation detail that clients don&apos;t (and shouldn&apos;t) really care. Ditto for ProducerResponse.&lt;/p&gt;

&lt;p&gt;2. To be consistent, should we change FetchResponse (and maybe FetchRequest) to use map, instead of array too?&lt;/p&gt;

&lt;p&gt;3. ProducerRequest.writeTo() can use foreach like the following:&lt;br/&gt;
   groupedData.foreach&lt;/p&gt;
{ case(topic, TopciAndPartitionData) =&amp;gt; ... }</comment>
                            <comment id="13449113" author="jjkoshy" created="Wed, 5 Sep 2012 20:45:17 +0000"  >&lt;p&gt;(1) Yes that&apos;s a good point. I should have thought through it more carefully. We only need the sorted property once (serialization).&lt;br/&gt;
(2) I had considered this, but decided to punt to see how the producer-side came out. I&apos;ll take a stab at the fetch side as well as part of this jira.&lt;br/&gt;
(3) Nice.&lt;/p&gt;

&lt;p&gt;So I&apos;ll rebase now and incorporate the above.&lt;/p&gt;</comment>
                            <comment id="13449121" author="jjkoshy" created="Wed, 5 Sep 2012 20:51:46 +0000"  >&lt;p&gt;(Accidentally deleted the description.)&lt;/p&gt;</comment>
                            <comment id="13449271" author="junrao" created="Wed, 5 Sep 2012 23:46:32 +0000"  >&lt;p&gt;Also, I agree that we can remove the global errorcode from both the fetch and the produce responses.&lt;/p&gt;</comment>
                            <comment id="13453627" author="jjkoshy" created="Wed, 12 Sep 2012 01:33:12 +0000"  >&lt;p&gt;2.1 - Rebased after the first review, but I will need to rebase again. Unit&lt;br/&gt;
  tests and system tests pass. This patch applies cleanly to svn revision&lt;br/&gt;
  1381858 - it would be great if this can be reviewed against that revision.   I can provide an incremental patch if that helps after I rebase.&lt;/p&gt;

&lt;p&gt;2.2 - Removed all the equals methods in classes that were using Arrays earlier.&lt;/p&gt;

&lt;p&gt;2.3 - Switched fetch request/response to maps. It makes the code a little&lt;br/&gt;
  cleaner, but I think the improvement was greater with the refactoring on&lt;br/&gt;
  the producer side. Anyway, this makes the APIs more consistent.  One small&lt;br/&gt;
  observation: previously, fetch requests would throw a&lt;br/&gt;
  FetchRequestFormatException if the TopicData array for a fetch request&lt;br/&gt;
  contained the same topic multiple times. Right now we don&apos;t do any checks&lt;br/&gt;
  since we use a map. We can add it to the FetchRequestBuilder, but not sure&lt;br/&gt;
  if it is required/worth it. Also, I think it previously would allow&lt;br/&gt;
  fetches from different offsets in the same partition in the same fetch&lt;br/&gt;
  request. That is no longer allowed, although I don&apos;t know why anyone would&lt;br/&gt;
  need that.&lt;/p&gt;

&lt;p&gt;2.4 - Removed the global error code.&lt;/p&gt;

&lt;p&gt;Another minor detail: I wonder if it would help to have a case class for&lt;br/&gt;
TopicAndPartition. We use (topic, partition) and the associated tuple&lt;br/&gt;
addressing all over the place. That would make the Map declarations slightly&lt;br/&gt;
clearer, although now we&apos;re accustomed to understanding that (String, Int)&lt;br/&gt;
must mean (topic, partitionId).&lt;/p&gt;</comment>
                            <comment id="13454106" author="jjkoshy" created="Wed, 12 Sep 2012 16:38:31 +0000"  >&lt;p&gt;BTW, I forgot to remove OffsetDetail from FetchRequest - we don&apos;t need that anymore.&lt;/p&gt;</comment>
                            <comment id="13454140" author="junrao" created="Wed, 12 Sep 2012 17:17:32 +0000"  >&lt;p&gt;Thanks for patch v2. Some comments.&lt;/p&gt;

&lt;p&gt;20. It&apos;s a good idea to create a case class of TopicPartition. This helps 2 things: (1) Tuple doesn&apos;t exist in java and javaapi.ProducerRequest currently uses tuple. (2) This avoids things like x._1._1, which is harder to understand. Similarly, should we create a case class of ProducerResponsStatus that wraps (errrocode, offset)?&lt;/p&gt;

&lt;p&gt;21. javaapi.ProduceRequest should use java map, instead of scala map. javaapi.SyncProducer should return a java version of ProducerResponse. Thinking about it. Should we even provide a javaapi for SyncProducer since everyone should really be using the high level Producer api? In other words, SyncProducer probably is not our public api for clients. For consumers, we likely still need to provide a java version of SimpleConsumer since there may be applications that want to control the fetch offset. &lt;/p&gt;

&lt;p&gt;23. It doesn&apos;t look like that we have a java version of FetchRequest. We should add that  and use it in the java version of SimpleConsumer.&lt;/p&gt;

&lt;p&gt;24. FetchResponse: We probably should add a helper method errorCode(topic, partition)?&lt;/p&gt;

&lt;p&gt;25. AbstractFetchThread: can use the pattern response.data.foreach&lt;/p&gt;
{ case(key, partitionData) =&amp;gt; }

&lt;p&gt;26. KafkaApis.handleFetchRequest(): can use the pattern in #25 too.&lt;/p&gt;
</comment>
                            <comment id="13455022" author="jjkoshy" created="Thu, 13 Sep 2012 17:25:02 +0000"  >&lt;p&gt;Marking as blocker since I ended up changing the wire format.&lt;/p&gt;</comment>
                            <comment id="13455481" author="jjkoshy" created="Fri, 14 Sep 2012 00:14:13 +0000"  >&lt;p&gt;Overview of changes in v3:&lt;/p&gt;

&lt;p&gt;(3.1) - (20) - This actually caused bulk of the changes in v3. I did this &lt;br/&gt;
for just the topic-partition pairs in producer/consumer request handling;&lt;br/&gt;
same for producer response status. There are a lot more places where we&lt;br/&gt;
could move from tuples to case classes. I think (as mentioned on the mailing&lt;br/&gt;
list) it would be good to do this as part of cleanup but we should defer&lt;br/&gt;
that for later since such changes cut across a lot of files. Going forward I&lt;br/&gt;
think this brings out a convention that we might want to follow. The &quot;scala&lt;br/&gt;
book&quot; has a reasonable guideline. I&apos;ll send out an email to kafka-dev for&lt;br/&gt;
discussion and add it to our coding convention depending on how that pans&lt;br/&gt;
out.&lt;/p&gt;

&lt;p&gt;(3.2) (21)-(23) - Thanks for catching the javaapi issue. Couple of changes&lt;br/&gt;
here: &lt;br/&gt;
a - Added javaapi for FetchRequest. (I needed to provide both java/non-java&lt;br/&gt;
  fetchrequest to the simpleconsumer since FetchBuilder returns a scala&lt;br/&gt;
  FetchRequest.) &lt;br/&gt;
b - Java map for all the Fetch/Produce request/response in the javaapi.&lt;br/&gt;
c - Removed SyncProducer: agreed that is unnecessary since Producer supports&lt;br/&gt;
  both sync and async; made the hadoop producer code use the high level&lt;br/&gt;
  producer. I think that&apos;s safe - i.e., I don&apos;t see a good reason why anyone&lt;br/&gt;
  would &quot;depend&quot; on the data going to a single broker.&lt;br/&gt;
d - Got rid of the unreferenced ProducerConsumerTestHarness in javaapi.&lt;br/&gt;
e - Fixed the equals method in javaapi ProducerRequest; added one to&lt;br/&gt;
FetchResponse - actually we can abstract this out into a trait, but that is&lt;br/&gt;
a minor improvement that I punted on.&lt;br/&gt;
f - Made the ProducerRequest use Java map in javaapi.&lt;br/&gt;
g - (I did not add Java versions of ProducerResponse since the SyncProducer&lt;br/&gt;
  has been removed.)&lt;/p&gt;

&lt;p&gt;(3.3) (24) - added the helper method, although I don&apos;t think I&apos;m using it&lt;br/&gt;
anywhere.&lt;/p&gt;

&lt;p&gt;(3.4) - Got rid of OffsetDetail.&lt;/p&gt;

&lt;p&gt;For (25)(26) - I tried to use the pattern wherever I could, but may have &lt;br/&gt;
missed a few.&lt;/p&gt;

&lt;p&gt;I did not rebase this (i.e., it still applies on r1381858). I&apos;ll rebase &lt;br/&gt;
after we are done with reviews.&lt;/p&gt;</comment>
                            <comment id="13455566" author="junrao" created="Fri, 14 Sep 2012 04:27:45 +0000"  >&lt;p&gt;V3 looks good overall. Some additional comments:&lt;/p&gt;

&lt;p&gt;30. remove javaapi.ProducerRequest&lt;br/&gt;
31. We probably should call TopicPartition TopicAndPartition.&lt;br/&gt;
32. javaapi.SimpleConsumer: It&apos;s bit confusing to the scala version of send here. Let&apos;s at least explain in the comment how to use it.&lt;/p&gt;</comment>
                            <comment id="13455927" author="jjkoshy" created="Fri, 14 Sep 2012 16:49:48 +0000"  >&lt;p&gt;30 - Why should it be removed?&lt;/p&gt;</comment>
                            <comment id="13455928" author="jjkoshy" created="Fri, 14 Sep 2012 16:50:51 +0000"  >&lt;p&gt;Ok nm - I see it&apos;s because we removed SyncProducer and only need ProducerData. Ok - so I&apos;ll rebase now and upload the final patch in a bit.&lt;/p&gt;</comment>
                            <comment id="13456242" author="jjkoshy" created="Sat, 15 Sep 2012 00:12:26 +0000"  >&lt;p&gt;Here is the rebased patch. I also had to include a small edit to ReplicaFetcherThread to address the issue in &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-517&quot; title=&quot;Ensure that we escape the metric names if they include user strings&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-517&quot;&gt;KAFKA-517&lt;/a&gt; which affects our system tests.&lt;/p&gt;</comment>
                            <comment id="13456710" author="junrao" created="Sun, 16 Sep 2012 23:35:30 +0000"  >&lt;p&gt;Thanks for patch v4. +1 Could you fix the following minor issues before checking in?&lt;/p&gt;

&lt;p&gt;41. scala version of FetchResponse: We throw an exception in errorCode if the map key doesn&apos;t exist. To be consistent, we should do the same for messageSet and highWatermark.&lt;/p&gt;

&lt;p&gt;42. PartitionStatus: Since this is a case class, there is no need to define requiredOffset as val.&lt;/p&gt;

&lt;p&gt;43. DefaultEventHandler.serialize(): This is not introduced in this patch, but could you change  error(&quot;Error serializing message &quot; + t) to error(&quot;Error serializing message &quot;, t)&lt;/p&gt;



</comment>
                            <comment id="13457281" author="jjkoshy" created="Mon, 17 Sep 2012 20:21:31 +0000"  >&lt;p&gt;Thanks for the review. Checked-in to 0.8 after addressing the minor issues.&lt;/p&gt;</comment>
                            <comment id="14181170" author="waldenchen" created="Thu, 23 Oct 2014 09:35:51 +0000"  >&lt;p&gt;Why this fix add this line code?&lt;br/&gt;
Sometimes got 2 responses for one request,   Why fall into this situation, will there be duplicate data in Kafka?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=kafka.git;a=commitdiff;h=b688c3ba045df340bc32caa40ba1909eddbcbec5&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=kafka.git;a=commitdiff;h=b688c3ba045df340bc32caa40ba1909eddbcbec5&lt;/a&gt; &lt;br/&gt;
+        if (response.status.size != producerRequest.data.size)+          throw new KafkaException(&quot;Incomplete response (%s) for producer request (%s)&quot;+                                           .format(response, producerRequest))&lt;/p&gt;
</comment>
                            <comment id="14182057" author="junrao" created="Thu, 23 Oct 2014 21:58:49 +0000"  >&lt;p&gt;The client should always receive one response per request. Are you see otherwise?&lt;/p&gt;</comment>
                            <comment id="14182097" author="waldenchen" created="Thu, 23 Oct 2014 22:44:21 +0000"  >&lt;p&gt;Yes,  after add more information to the error message ,  sometimes see two response for one request.&lt;/p&gt;</comment>
                            <comment id="14182197" author="junrao" created="Thu, 23 Oct 2014 23:49:01 +0000"  >&lt;p&gt;Which version of Kafka are you using? Is that easily reproducible?&lt;/p&gt;</comment>
                            <comment id="14182240" author="jjkoshy" created="Fri, 24 Oct 2014 00:23:35 +0000"  >&lt;p&gt;You mean two responses to the caller of send? I don&apos;t see why those two lines would cause two responses. Can you explain further and provide steps to reproduce if there really is an issue? Do you see errors/warns in the logs?&lt;/p&gt;</comment>
                            <comment id="14182260" author="waldenchen" created="Fri, 24 Oct 2014 00:45:17 +0000"  >&lt;p&gt;Not that two line cause two responses.&lt;br/&gt;
We just hit that two line while run.&lt;br/&gt;
And after change that line to output the value of response.status.size and  producerRequest.data.size ,   we found that sometimes  response.status.size=2 and producerRequest.data.size =1.&lt;/p&gt;

&lt;p&gt;Want to ask initially why add this line?   when will response.status.size != producerRequest.data.size happen?&lt;/p&gt;</comment>
                            <comment id="14182276" author="jjkoshy" created="Fri, 24 Oct 2014 01:08:40 +0000"  >&lt;p&gt;Yeah I see your point. That&apos;s interesting - I actually don&apos;t remember why that was added but it appears there must have been a legitimate reason (since you ran into it&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  ).&lt;/p&gt;

&lt;p&gt;Since you are able to reproduce it can you actually print the full original request and response itself? It should be in the exception that is thrown.&lt;/p&gt;

&lt;p&gt;Also, what is your broker Kafka version? Also, what is the version of the producer? Is it the same?&lt;/p&gt;</comment>
                            <comment id="14195762" author="waldenchen" created="Tue, 4 Nov 2014 06:11:13 +0000"  >&lt;p&gt;This situation happen under below scenario:&lt;br/&gt;
one broker is leader for several partitions, for example 3,   when send one messageset which has message for all of the 3 partitions of this broker ,      the response.status.size is 3 and  the producerRequest.data.size is 1.    then it hit this exception.   Any idea for fix?  Do we need compare response.status.size  with messagesPerTopic.Count instead of producerRequest.data.size ?&lt;/p&gt;


&lt;p&gt;  private def send(brokerId: Int, messagesPerTopic: collection.mutable.Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicAndPartition, ByteBufferMessageSet&amp;#93;&lt;/span&gt;) = {&lt;br/&gt;
    if(brokerId &amp;lt; 0) &lt;/p&gt;
{
      warn(&quot;Failed to send data since partitions %s don&apos;t have a leader&quot;.format(messagesPerTopic.map(_._1).mkString(&quot;,&quot;)))
      messagesPerTopic.keys.toSeq
    }
&lt;p&gt; else if(messagesPerTopic.size &amp;gt; 0) {&lt;br/&gt;
      val currentCorrelationId = correlationId.getAndIncrement&lt;br/&gt;
      val producerRequest = new ProducerRequest(currentCorrelationId, config.clientId, config.requestRequiredAcks,&lt;br/&gt;
        config.requestTimeoutMs, messagesPerTopic)&lt;br/&gt;
      var failedTopicPartitions = Seq.empty&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicAndPartition&amp;#93;&lt;/span&gt;&lt;br/&gt;
      try {&lt;br/&gt;
        val syncProducer = producerPool.getProducer(brokerId)&lt;br/&gt;
        debug(&quot;Producer sending messages with correlation id %d for topics %s to broker %d on %s:%d&quot;&lt;br/&gt;
          .format(currentCorrelationId, messagesPerTopic.keySet.mkString(&quot;,&quot;), brokerId, syncProducer.config.host, syncProducer.config.port))&lt;br/&gt;
        val response = syncProducer.send(producerRequest)&lt;br/&gt;
        debug(&quot;Producer sent messages with correlation id %d for topics %s to broker %d on %s:%d&quot;&lt;br/&gt;
          .format(currentCorrelationId, messagesPerTopic.keySet.mkString(&quot;,&quot;), brokerId, syncProducer.config.host, syncProducer.config.port))&lt;br/&gt;
        if(response != null) {&lt;br/&gt;
          if (response.status.size != producerRequest.data.size)&lt;br/&gt;
            throw new KafkaException(&quot;Incomplete response (%s) for producer request (%s)&quot;.format(response, producerRequest))&lt;/p&gt;
</comment>
                            <comment id="14198699" author="jjkoshy" created="Wed, 5 Nov 2014 17:29:50 +0000"  >&lt;p&gt;If there are three partitions, then there will be three message-sets. i.e., producerRequest.data.size will be three, not one. Can you give example &lt;em&gt;application&lt;/em&gt; code that reproduces the issue that you are seeing?&lt;/p&gt;</comment>
                            <comment id="14201702" author="waldenchen" created="Fri, 7 Nov 2014 06:57:57 +0000"  >&lt;p&gt;Many thanks for you help.&lt;br/&gt;
After debugging and testing, seemly I can&apos;t hit that exception.&lt;br/&gt;
Actually we&apos;re using one c# version client which is inherit from &lt;a href=&quot;https://github.com/precog/kafka/tree/master/clients/csharp/src/Kafka/Kafka.Client&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/precog/kafka/tree/master/clients/csharp/src/Kafka/Kafka.Client&lt;/a&gt; , and after debug and compare it&apos;s code with java version, finally prove that it&apos;s the bug of the C# code.&lt;br/&gt;
In java version, when create ProducerRequest, it set produceRequest.data as messagesPerTopic,  and do group by topic just before send binary.&lt;br/&gt;
But in our c# version,  it group it first and set the produceRequest.data as dictionary of &amp;lt;Topic,Data&amp;gt;, so we hit this exception wrongly, we fixed it.&lt;/p&gt;

&lt;p&gt;Many thanks for your time.&lt;br/&gt;
But anyway, can&apos;t find our related open source version from internet, our version has DefaultCallbackHandler.cs, but the version on &lt;a href=&quot;https://github.com/precog/kafka/tree/master/clients/csharp/src/Kafka/Kafka.Client&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/precog/kafka/tree/master/clients/csharp/src/Kafka/Kafka.Client&lt;/a&gt; has no, so can&apos;t provide the link here.&lt;/p&gt;

&lt;p&gt;The java link:&lt;br/&gt;
&lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=kafka.git;a=blob;f=core/src/main/scala/kafka/api/ProducerRequest.scala;h=570b2da1d865086f9830aa919a49063abbbe574d;hb=HEAD&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=kafka.git;a=blob;f=core/src/main/scala/kafka/api/ProducerRequest.scala;h=570b2da1d865086f9830aa919a49063abbbe574d;hb=HEAD&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=kafka.git;a=blob;f=core/src/main/scala/kafka/producer/async/DefaultEventHandler.scala;h=821901e4f434dfd9eec6eceabfc2e1e65507a57c;hb=HEAD#l260&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=kafka.git;a=blob;f=core/src/main/scala/kafka/producer/async/DefaultEventHandler.scala;h=821901e4f434dfd9eec6eceabfc2e1e65507a57c;hb=HEAD#l260&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12543757" name="KAFKA-391-draft-r1374069.patch" size="37856" author="jjkoshy" created="Tue, 4 Sep 2012 22:26:56 +0000"/>
                            <attachment id="12544753" name="KAFKA-391-v2.patch" size="81343" author="jjkoshy" created="Wed, 12 Sep 2012 01:33:12 +0000"/>
                            <attachment id="12545086" name="KAFKA-391-v3.patch" size="117767" author="jjkoshy" created="Fri, 14 Sep 2012 00:14:13 +0000"/>
                            <attachment id="12545251" name="KAFKA-391-v4.patch" size="128470" author="jjkoshy" created="Sat, 15 Sep 2012 00:12:26 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>299107</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 2 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i15zn3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>243074</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>