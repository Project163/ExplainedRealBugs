<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:58:54 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-2000] Delete consumer offsets from kafka once the topic is deleted</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-2000</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description></description>
                <environment></environment>
        <key id="12779167">KAFKA-2000</key>
            <summary>Delete consumer offsets from kafka once the topic is deleted</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="omkreddy">Manikumar</assignee>
                                    <reporter username="sriharsha">Harsha</reporter>
                        <labels>
                            <label>newbie++</label>
                    </labels>
                <created>Tue, 3 Mar 2015 20:06:56 +0000</created>
                <updated>Sun, 25 Feb 2018 06:56:29 +0000</updated>
                            <resolved>Wed, 25 Jan 2017 16:18:16 +0000</resolved>
                                                    <fixVersion>0.10.2.0</fixVersion>
                    <fixVersion>0.11.0.0</fixVersion>
                                        <due></due>
                            <votes>2</votes>
                                    <watches>13</watches>
                                                                                                                <comments>
                            <comment id="14387479" author="sriharsha" created="Mon, 30 Mar 2015 21:47:20 +0000"  >&lt;p&gt;Created reviewboard &lt;a href=&quot;https://reviews.apache.org/r/32650/diff/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.apache.org/r/32650/diff/&lt;/a&gt;&lt;br/&gt;
 against branch origin/trunk&lt;/p&gt;</comment>
                            <comment id="14525913" author="sriharsha" created="Sun, 3 May 2015 17:39:19 +0000"  >&lt;p&gt;Updated reviewboard &lt;a href=&quot;https://reviews.apache.org/r/32650/diff/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.apache.org/r/32650/diff/&lt;/a&gt;&lt;br/&gt;
 against branch origin/trunk&lt;/p&gt;</comment>
                            <comment id="15062334" author="ijuma" created="Thu, 17 Dec 2015 16:58:07 +0000"  >&lt;p&gt;Is this still applicable?&lt;/p&gt;</comment>
                            <comment id="15062369" author="ijuma" created="Thu, 17 Dec 2015 17:18:55 +0000"  >&lt;p&gt;Looks like it is, `GroupMetadataManager` has the following code:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;val expiredOffsets = offsetsCache.filter { &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; (groupTopicPartition, offsetAndMetadata) =&amp;gt;
  offsetAndMetadata.expireTimestamp &amp;lt; startMs
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=harsha_ch&quot; class=&quot;user-hover&quot; rel=&quot;harsha_ch&quot;&gt;harsha_ch&lt;/a&gt;, do you want to submit a PR with this change?&lt;/p&gt;</comment>
                            <comment id="15062547" author="sriharsha" created="Thu, 17 Dec 2015 18:54:39 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt; Yes.&lt;/p&gt;</comment>
                            <comment id="15064564" author="parth.brahmbhatt" created="Fri, 18 Dec 2015 19:27:02 +0000"  >&lt;p&gt;Talked to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=harsha_ch&quot; class=&quot;user-hover&quot; rel=&quot;harsha_ch&quot;&gt;harsha_ch&lt;/a&gt; , I will submit an updated patch for this one today.&lt;/p&gt;</comment>
                            <comment id="15067028" author="githubbot" created="Mon, 21 Dec 2015 20:18:32 +0000"  >&lt;p&gt;GitHub user Parth-Brahmbhatt opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/704&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/704&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-2000&quot; title=&quot;Delete consumer offsets from kafka once the topic is deleted&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-2000&quot;&gt;&lt;del&gt;KAFKA-2000&lt;/del&gt;&lt;/a&gt;: Delete topic should also delete consumer offsets.&lt;/p&gt;



&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/Parth-Brahmbhatt/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/Parth-Brahmbhatt/kafka&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-2000&quot; title=&quot;Delete consumer offsets from kafka once the topic is deleted&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-2000&quot;&gt;&lt;del&gt;KAFKA-2000&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/704.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/704.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #704&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit ceae0b7031d297a7db6664b435bb3cdc55228646&lt;br/&gt;
Author: Parth Brahmbhatt &amp;lt;brahmbhatt.parth@gmail.com&amp;gt;&lt;br/&gt;
Date:   2015-12-18T20:35:32Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-2000&quot; title=&quot;Delete consumer offsets from kafka once the topic is deleted&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-2000&quot;&gt;&lt;del&gt;KAFKA-2000&lt;/del&gt;&lt;/a&gt;: Delete topic should also delete consumer offsets.&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15067936" author="sslavic" created="Tue, 22 Dec 2015 10:47:03 +0000"  >&lt;p&gt;I&apos;m still on 0.8.2.x and it&apos;s hurting my system smoke tests, reusing same topics over and over again in the test, (consumer) state preserved - deleting topic, creating it, publishing message, not being able to read just published message. Now have to introduce dummy read after topic is recreated, just to have existing offset fall outside of the valid range, and get reset.&lt;/p&gt;

&lt;p&gt;Curious, are there any plans to backport this fix to 0.9.0.x or even 0.8.2.x?&lt;/p&gt;</comment>
                            <comment id="15487758" author="githubbot" created="Tue, 13 Sep 2016 17:00:30 +0000"  >&lt;p&gt;GitHub user omkreddy opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1850&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1850&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-2000&quot; title=&quot;Delete consumer offsets from kafka once the topic is deleted&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-2000&quot;&gt;&lt;del&gt;KAFKA-2000&lt;/del&gt;&lt;/a&gt;: Delete topic should also delete consumer offsets.&lt;/p&gt;



&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/omkreddy/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/omkreddy/kafka&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-2700&quot; title=&quot;delete topic should remove the corresponding ACL and configs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-2700&quot;&gt;&lt;del&gt;KAFKA-2700&lt;/del&gt;&lt;/a&gt;-DELETE&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1850.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1850.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #1850&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 3bcb8232b6f184e232797519b1a829e74d0f37b1&lt;br/&gt;
Author: Manikumar Reddy O &amp;lt;manikumar.reddy@gmail.com&amp;gt;&lt;br/&gt;
Date:   2016-09-13T16:07:41Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-2000&quot; title=&quot;Delete consumer offsets from kafka once the topic is deleted&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-2000&quot;&gt;&lt;del&gt;KAFKA-2000&lt;/del&gt;&lt;/a&gt;: Delete topic should also delete consumer offsets.&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15832295" author="hachikuji" created="Fri, 20 Jan 2017 19:28:45 +0000"  >&lt;p&gt;It would be nice to get this fixed. The patch from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=parth.brahmbhatt&quot; class=&quot;user-hover&quot; rel=&quot;parth.brahmbhatt&quot;&gt;parth.brahmbhatt&lt;/a&gt; has review comments from Feb. 2016 which have not been addressed. Perhaps &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=omkreddy&quot; class=&quot;user-hover&quot; rel=&quot;omkreddy&quot;&gt;omkreddy&lt;/a&gt; can rebase the patch posted above and we can try to get it merged?&lt;/p&gt;</comment>
                            <comment id="15832378" author="jeffwidman" created="Fri, 20 Jan 2017 20:45:28 +0000"  >&lt;p&gt;If neither of them is interested, I&apos;m happy to cleanup the existing patch to get it merged into 0.10.2. The test suite at my work would benefit from this. Just let me know.&lt;/p&gt;</comment>
                            <comment id="15832410" author="sriharsha" created="Fri, 20 Jan 2017 21:16:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jeffwidman&quot; class=&quot;user-hover&quot; rel=&quot;jeffwidman&quot;&gt;jeffwidman&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=omkreddy&quot; class=&quot;user-hover&quot; rel=&quot;omkreddy&quot;&gt;omkreddy&lt;/a&gt; working on it.&lt;/p&gt;</comment>
                            <comment id="15838022" author="sriharsha" created="Wed, 25 Jan 2017 16:18:16 +0000"  >&lt;p&gt;Issue resolved by pull request 1850&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/pull/1850&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1850&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15838024" author="githubbot" created="Wed, 25 Jan 2017 16:18:52 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1850&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1850&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16375965" author="githubbot" created="Sun, 25 Feb 2018 06:56:29 +0000"  >&lt;p&gt;hachikuji closed pull request #704: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-2000&quot; title=&quot;Delete consumer offsets from kafka once the topic is deleted&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-2000&quot;&gt;&lt;del&gt;KAFKA-2000&lt;/del&gt;&lt;/a&gt;: Delete topic should also delete consumer offsets.&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/704&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/704&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/core/src/main/scala/kafka/coordinator/GroupMetadataManager.scala b/core/src/main/scala/kafka/coordinator/GroupMetadataManager.scala&lt;br/&gt;
index 48818c3edff..56dc1139cf1 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/coordinator/GroupMetadataManager.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/coordinator/GroupMetadataManager.scala&lt;br/&gt;
@@ -62,14 +62,14 @@ class GroupMetadataManager(val brokerId: Int,&lt;br/&gt;
   /* group metadata cache */&lt;br/&gt;
   private val groupsCache = new Pool&lt;span class=&quot;error&quot;&gt;&amp;#91;String, GroupMetadata&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/* partitions of consumer groups that are being loaded, its lock should be always called BEFORE offsetExpireLock and the group lock if needed */&lt;br/&gt;
+  /* partitions of consumer groups that are being loaded, its lock should be always called BEFORE removeOffsetLock and the group lock if needed */&lt;br/&gt;
   private val loadingPartitions: mutable.Set&lt;span class=&quot;error&quot;&gt;&amp;#91;Int&amp;#93;&lt;/span&gt; = mutable.Set()&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   /* partitions of consumer groups that are assigned, using the same loading partition lock */&lt;br/&gt;
   private val ownedPartitions: mutable.Set&lt;span class=&quot;error&quot;&gt;&amp;#91;Int&amp;#93;&lt;/span&gt; = mutable.Set()&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/* lock for expiring stale offsets, it should be always called BEFORE the group lock if needed */&lt;/li&gt;
	&lt;li&gt;private val offsetExpireLock = new ReentrantReadWriteLock()&lt;br/&gt;
+  /* lock for removing stale/deleted topic&apos;s offsets, it should be always called BEFORE the group lock if needed */&lt;br/&gt;
+  private val removeOffsetLock = new ReentrantReadWriteLock()&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   /* shutting down flag */&lt;br/&gt;
   private val shuttingDown = new AtomicBoolean(false)&lt;br/&gt;
@@ -163,6 +163,19 @@ class GroupMetadataManager(val brokerId: Int,&lt;br/&gt;
     }&lt;br/&gt;
   }&lt;/p&gt;

&lt;p&gt;+  /**&lt;br/&gt;
+   * Removes all the groups and corresponding offsets for this topicPartition.&lt;br/&gt;
+   * @param topicPartition&lt;br/&gt;
+   */&lt;br/&gt;
+  def removeOffsetsByTopicPartition(topicPartition: TopicPartition): Unit = {&lt;br/&gt;
+    val startMs = SystemTime.milliseconds&lt;br/&gt;
+    val numberOfDeletedExpiredOffsets = inWriteLock(removeOffsetLock) &lt;/p&gt;
{
+      val offsetsToBeDeleted = offsetsCache.filter(_._1.topicPartition == TopicAndPartition(topicPartition.topic, topicPartition.partition))
+      deleteOffsets(offsetsToBeDeleted)
+    }
&lt;p&gt;+    info(s&quot;Removed ${numberOfDeletedExpiredOffsets} offsets in ${SystemTime.milliseconds - startMs} milliseconds for topicPartition ${topicPartition}&quot;)&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
   def prepareStoreGroup(group: GroupMetadata,&lt;br/&gt;
                         groupAssignment: Map[String, Array&lt;span class=&quot;error&quot;&gt;&amp;#91;Byte&amp;#93;&lt;/span&gt;],&lt;br/&gt;
                         responseCallback: Short =&amp;gt; Unit): DelayedStore = {&lt;br/&gt;
@@ -365,7 +378,7 @@ class GroupMetadataManager(val brokerId: Int,&lt;br/&gt;
             var currOffset = log.logSegments.head.baseOffset&lt;br/&gt;
             val buffer = ByteBuffer.allocate(config.loadBufferSize)&lt;br/&gt;
             // loop breaks if leader changes at any time during the load, since getHighWatermark is -1&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;inWriteLock(offsetExpireLock) {&lt;br/&gt;
+            inWriteLock(removeOffsetLock) {&lt;br/&gt;
               val loadedGroups = mutable.Map&lt;span class=&quot;error&quot;&gt;&amp;#91;String, GroupMetadata&amp;#93;&lt;/span&gt;()&lt;br/&gt;
               val removedGroups = mutable.Set&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;()&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -534,53 +547,62 @@ class GroupMetadataManager(val brokerId: Int,&lt;br/&gt;
     debug(&quot;Collecting expired offsets.&quot;)&lt;br/&gt;
     val startMs = SystemTime.milliseconds&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val numExpiredOffsetsRemoved = inWriteLock(offsetExpireLock) {&lt;br/&gt;
+    val numExpiredOffsetsRemoved = inWriteLock(removeOffsetLock) {&lt;br/&gt;
       val expiredOffsets = offsetsCache.filter 
{ case (groupTopicPartition, offsetAndMetadata) =&amp;gt;
         offsetAndMetadata.expireTimestamp &amp;lt; startMs
       }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;debug(&quot;Found %d expired offsets.&quot;.format(expiredOffsets.size))&lt;br/&gt;
+      deleteOffsets(expiredOffsets)&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    info(s&quot;Removed ${numExpiredOffsetsRemoved} expired offsets in ${SystemTime.milliseconds - startMs} milliseconds.&quot;)&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  /**&lt;br/&gt;
+   * Deletes the provided offsets.&lt;br/&gt;
+   * @param offsetsToBeDeleted collection of offsets that needs to be deleted.&lt;br/&gt;
+   * @return number of deleted offsets.&lt;br/&gt;
+   */&lt;br/&gt;
+  def deleteOffsets(offsetsToBeDeleted: scala.Iterable&lt;span class=&quot;error&quot;&gt;&amp;#91;(GroupTopicPartition, OffsetAndMetadata)&amp;#93;&lt;/span&gt;): Int = {&lt;br/&gt;
+    debug(&quot;Found %d offsets that needs to be removed.&quot;.format(offsetsToBeDeleted.size))&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// delete the expired offsets from the table and generate tombstone messages to remove them from the log&lt;/li&gt;
	&lt;li&gt;val tombstonesForPartition = expiredOffsets.map { case (groupTopicAndPartition, offsetAndMetadata) =&amp;gt;&lt;/li&gt;
	&lt;li&gt;val offsetsPartition = partitionFor(groupTopicAndPartition.group)&lt;/li&gt;
	&lt;li&gt;trace(&quot;Removing expired offset and metadata for %s: %s&quot;.format(groupTopicAndPartition, offsetAndMetadata))&lt;br/&gt;
+    // delete the offsets from the table and generate tombstone messages to remove them from the log&lt;br/&gt;
+    val tombstonesForPartition = offsetsToBeDeleted.map 
{ case (groupTopicAndPartition, offsetAndMetadata) =&amp;gt;
+      val offsetsPartition = partitionFor(groupTopicAndPartition.group)
+      trace(&quot;Removing offset and metadata for %s: %s&quot;.format(groupTopicAndPartition, offsetAndMetadata))
 
-        offsetsCache.remove(groupTopicAndPartition)
+      offsetsCache.remove(groupTopicAndPartition)
 
-        val commitKey = GroupMetadataManager.offsetCommitKey(groupTopicAndPartition.group,
-          groupTopicAndPartition.topicPartition.topic, groupTopicAndPartition.topicPartition.partition)
+      val commitKey = GroupMetadataManager.offsetCommitKey(groupTopicAndPartition.group,
+        groupTopicAndPartition.topicPartition.topic, groupTopicAndPartition.topicPartition.partition)
 
-        (offsetsPartition, new Message(bytes = null, key = commitKey))
-      }
&lt;p&gt;.groupBy &lt;/p&gt;
{ case (partition, tombstone) =&amp;gt; partition }&lt;br/&gt;
+      (offsetsPartition, new Message(bytes = null, key = commitKey))&lt;br/&gt;
+    }.groupBy { case (partition, tombstone) =&amp;gt; partition }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// Append the tombstone messages to the offset partitions. It is okay if the replicas don&apos;t receive these (say,&lt;/li&gt;
	&lt;li&gt;// if we crash or leaders move) since the new leaders will get rid of expired offsets during their own purge cycles.&lt;/li&gt;
	&lt;li&gt;tombstonesForPartition.flatMap { case (offsetsPartition, tombstones) =&amp;gt;&lt;/li&gt;
	&lt;li&gt;val partitionOpt = replicaManager.getPartition(GroupCoordinator.GroupMetadataTopicName, offsetsPartition)&lt;/li&gt;
	&lt;li&gt;partitionOpt.map { partition =&amp;gt;&lt;/li&gt;
	&lt;li&gt;val appendPartition = TopicAndPartition(GroupCoordinator.GroupMetadataTopicName, offsetsPartition)&lt;/li&gt;
	&lt;li&gt;val messages = tombstones.map(_._2).toSeq&lt;br/&gt;
+    // Append the tombstone messages to the offset partitions. It is okay if the replicas don&apos;t receive these (say,&lt;br/&gt;
+    // if we crash or leaders move) since the new leaders will get rid of expired offsets during their own purge cycles.&lt;br/&gt;
+    tombstonesForPartition.flatMap { case (offsetsPartition, tombstones) =&amp;gt;&lt;br/&gt;
+      val partitionOpt = replicaManager.getPartition(GroupCoordinator.GroupMetadataTopicName, offsetsPartition)&lt;br/&gt;
+      partitionOpt.map { partition =&amp;gt;&lt;br/&gt;
+        val appendPartition = TopicAndPartition(GroupCoordinator.GroupMetadataTopicName, offsetsPartition)&lt;br/&gt;
+        val messages = tombstones.map(_._2).toSeq&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;trace(&quot;Marked %d offsets in %s for deletion.&quot;.format(messages.size, appendPartition))&lt;br/&gt;
+        trace(&quot;Marked %d offsets in %s for deletion.&quot;.format(messages.size, appendPartition))&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;try 
{
-            // do not need to require acks since even if the tombstone is lost,
-            // it will be appended again in the next purge cycle
-            partition.appendMessagesToLeader(new ByteBufferMessageSet(config.offsetsTopicCompressionCodec, messages: _*))
-            tombstones.size
-          }&lt;/li&gt;
	&lt;li&gt;catch 
{
-            case t: Throwable =&amp;gt;
-              error(&quot;Failed to mark %d expired offsets for deletion in %s.&quot;.format(messages.size, appendPartition), t)
-              // ignore and continue
-              0
-          }
&lt;p&gt;+        try &lt;/p&gt;
{
+          // do not need to require acks since even if the tombsone is lost,
+          // it will be appended again in the next purge cycle
+          partition.appendMessagesToLeader(new ByteBufferMessageSet(config.offsetsTopicCompressionCodec, messages: _*))
+          tombstones.size
         }&lt;/li&gt;
	&lt;li&gt;}.sum&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;info(&quot;Removed %d expired offsets in %d milliseconds.&quot;.format(numExpiredOffsetsRemoved, SystemTime.milliseconds - startMs))&lt;br/&gt;
+        catch 
{
+          case t: Throwable =&amp;gt;
+            error(&quot;Failed to mark %d offsets for deletion in %s.&quot;.format(messages.size, appendPartition), t)
+            // ignore and continue
+            0
+        }
&lt;p&gt;+      }&lt;br/&gt;
+    }.sum&lt;br/&gt;
   }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   private def getHighWatermark(partitionId: Int): Long = {&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/server/KafkaApis.scala b/core/src/main/scala/kafka/server/KafkaApis.scala&lt;br/&gt;
index f2e95332e8f..09cb06196ab 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/server/KafkaApis.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/server/KafkaApis.scala&lt;br/&gt;
@@ -164,6 +164,7 @@ class KafkaApis(val requestChannel: RequestChannel,&lt;br/&gt;
     val response =&lt;br/&gt;
       if (authorize(request.session, ClusterAction, Resource.ClusterResource)) &lt;/p&gt;
{
         val (result, error) = replicaManager.stopReplicas(stopReplicaRequest)
+        stopReplicaRequest.partitions.asScala.foreach(topicPartition =&amp;gt; coordinator.groupManager.removeOffsetsByTopicPartition(topicPartition))
         new StopReplicaResponse(error, result.asInstanceOf[Map[TopicPartition, JShort]].asJava)
       }
&lt;p&gt; else {&lt;br/&gt;
         val result = stopReplicaRequest.partitions.asScala.map((_, new JShort(Errors.CLUSTER_AUTHORIZATION_FAILED.code))).toMap&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/server/OffsetCommitTest.scala b/core/src/test/scala/unit/kafka/server/OffsetCommitTest.scala&lt;br/&gt;
index 1d5148b0e15..cffe852b6a8 100755&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/server/OffsetCommitTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/server/OffsetCommitTest.scala&lt;br/&gt;
@@ -17,9 +17,10 @@&lt;/p&gt;

&lt;p&gt; package kafka.server&lt;/p&gt;

&lt;p&gt;+import kafka.admin.AdminUtils&lt;br/&gt;
 import kafka.api.&lt;/p&gt;
{GroupCoordinatorRequest, OffsetCommitRequest, OffsetFetchRequest}
&lt;p&gt; import kafka.consumer.SimpleConsumer&lt;br/&gt;
-import kafka.common.&lt;/p&gt;
{OffsetMetadata, OffsetMetadataAndError, OffsetAndMetadata, TopicAndPartition}
&lt;p&gt;+import kafka.common._&lt;br/&gt;
 import kafka.utils._&lt;br/&gt;
 import kafka.utils.TestUtils._&lt;br/&gt;
 import kafka.zk.ZooKeeperTestHarness&lt;br/&gt;
@@ -49,7 +50,7 @@ class OffsetCommitTest extends ZooKeeperTestHarness {&lt;br/&gt;
   @Before&lt;br/&gt;
   override def setUp() {&lt;br/&gt;
     super.setUp()&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val config: Properties = createBrokerConfig(1, zkConnect)&lt;br/&gt;
+    val config: Properties = createBrokerConfig(1, zkConnect, enableDeleteTopic = true)&lt;br/&gt;
     config.setProperty(KafkaConfig.OffsetsTopicReplicationFactorProp, &quot;1&quot;)&lt;br/&gt;
     config.setProperty(KafkaConfig.OffsetsRetentionCheckIntervalMsProp, retentionCheckInterval.toString)&lt;br/&gt;
     val logDirPath = config.getProperty(&quot;log.dir&quot;)&lt;br/&gt;
@@ -307,4 +308,33 @@ class OffsetCommitTest extends ZooKeeperTestHarness 
{
     assertEquals(Errors.UNKNOWN_TOPIC_OR_PARTITION.code, commitResponse.commitStatus.get(TopicAndPartition(topic1, 0)).get)
     assertEquals(Errors.NONE.code, commitResponse.commitStatus.get(TopicAndPartition(topic2, 0)).get)
   }
&lt;p&gt;+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  def testOffsetsDeleteAfterTopicDeletion() &lt;/p&gt;
{
+    // set up topic partition
+    val topic = &quot;topic&quot;
+    val topicPartition = TopicAndPartition(topic, 0)
+    createTopic(zkUtils, topic, servers = Seq(server), numPartitions = 1)
+
+    val fetchRequest = OffsetFetchRequest(group, Seq(TopicAndPartition(topic, 0)))
+
+    // v0 version commit request with commit timestamp set to -1
+    // should not expire
+    val commitRequest0 = OffsetCommitRequest(
+      groupId = group,
+      requestInfo = immutable.Map(topicPartition -&amp;gt; OffsetAndMetadata(1L, &quot;metadata&quot;, -1L)),
+      versionId = 0
+    )
+    assertEquals(Errors.NONE.code(), simpleConsumer.commitOffsets(commitRequest0).commitStatus.get(topicPartition).get)
+
+    // start topic deletion
+    AdminUtils.deleteTopic(zkUtils, topic)
+    TestUtils.verifyTopicDeletion(zkUtils, topic, 1, Seq(server))
+    Thread.sleep(retentionCheckInterval * 2)
+
+    // check if offsets deleted
+    val offsetMetadataAndErrorMap = simpleConsumer.fetchOffsets(fetchRequest)
+    val offsetMetadataAndError = offsetMetadataAndErrorMap.requestInfo(topicPartition)
+    assertEquals(OffsetMetadataAndError.NoOffset, offsetMetadataAndError)
+  }
&lt;p&gt; }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13023854">KAFKA-4456</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12708244" name="KAFKA-2000.patch" size="1125" author="sriharsha" created="Mon, 30 Mar 2015 21:47:19 +0000"/>
                            <attachment id="12730040" name="KAFKA-2000_2015-05-03_10:39:11.patch" size="4235" author="sriharsha" created="Sun, 3 May 2015 17:39:18 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 38 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i26b53:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>hachikuji</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>