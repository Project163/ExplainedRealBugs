<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:16:30 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-7655] Metadata spamming requests from Kafka Streams under some circumstances, potential DOS</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-7655</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;There is a bug in the InternalTopicManager that&#160;makes the client believe that a topic exists&#160;even though it doesn&apos;t, it occurs mostly in those few seconds between when a topic is marked for deletion and when it is actually deleted. In that timespan, the Broker gives inconsistent information, first&#160;it hides the topic but then it refuses to create a new one therefore&#160;the client believes the topic was existing already and it starts polling for metadata.&lt;/p&gt;

&lt;p&gt;The consequence is that the client&#160;goes into a loop where it polls&#160;for topic metadata and if this is done by many threads it can take down a small cluster or degrade greatly its performances.&lt;/p&gt;

&lt;p&gt;The real life scenario is probably a reset gone wrong. Reproducing the issue is fairly simple, these are the steps:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Stop a Kafka streams application&lt;/li&gt;
	&lt;li&gt;Delete one of its changelog and the local store&lt;/li&gt;
	&lt;li&gt;Restart the application immediately after the topic delete&lt;/li&gt;
	&lt;li&gt;You will see the Kafka streams application hanging after the bootstrap saying something like:&#160;INFO&#160; Metadata - Cluster ID: xxxx&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;I am attaching a patch that fixes the issue client side but my personal opinion is that this should be tackled on the broker&#160;as well, metadata requests seem expensive and it would be easy to craft a DDOS that can potentially take down an entire cluster in seconds just by flooding the brokers with metadata requests.&lt;/p&gt;

&lt;p&gt;The patch kicks in only when a topic that wasn&apos;t existing in the first call to&#160;getNumPartitions&#160;triggers a&#160;TopicExistsException.&#160;When this happens it forces the re-validation of the topic and if it still looks like doesn&apos;t exists plan a retry with some delay, to give the broker the necessary time to sort it&#160;out.&lt;/p&gt;

&lt;p&gt;I think this patch makes sense&#160;beside the above mentioned use case where a topic it&apos;s not existing, because, even if the topic was actually created, the client should not blindly trust it and should still re-validate it by checking the number of partitions. IE: a topic can be created automatically by the&#160;first request and then it would have the default partitions rather than the expected ones.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13199362">KAFKA-7655</key>
            <summary>Metadata spamming requests from Kafka Streams under some circumstances, potential DOS</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="p.vazzana">Pasquale Vazzana</assignee>
                                    <reporter username="p.vazzana">Pasquale Vazzana</reporter>
                        <labels>
                            <label>performance</label>
                            <label>pull-request-available</label>
                            <label>security</label>
                    </labels>
                <created>Mon, 19 Nov 2018 15:26:48 +0000</created>
                <updated>Fri, 14 Dec 2018 09:12:56 +0000</updated>
                            <resolved>Thu, 13 Dec 2018 16:34:01 +0000</resolved>
                                    <version>2.0.1</version>
                                    <fixVersion>2.0.2</fixVersion>
                    <fixVersion>2.1.1</fixVersion>
                    <fixVersion>2.2.0</fixVersion>
                                    <component>streams</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16691875" author="githubbot" created="Mon, 19 Nov 2018 15:32:53 +0000"  >&lt;p&gt;Pasvaz opened a new pull request #5929: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7655&quot; title=&quot;Metadata spamming requests from Kafka Streams under some circumstances, potential DOS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7655&quot;&gt;&lt;del&gt;KAFKA-7655&lt;/del&gt;&lt;/a&gt; Metadata spamming requests from Kafka Streams under some circumstances, potential DOS&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5929&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5929&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Re-validate and make sure the topic either exists or it&apos;s gone by using a delay.&lt;/p&gt;

&lt;p&gt;   There is a bug in the InternalTopicManager that makes the client believe that a topic exists even though it doesn&apos;t, it occurs mostly in those few seconds between when a topic is marked for deletion and when it is actually deleted. In that timespan, the Broker gives inconsistent information, first it hides the topic but then it refuses to create a new one therefore the client believes the topic was existing already and it starts polling for metadata.&lt;/p&gt;

&lt;p&gt;   The consequence is that the client goes into a loop where it polls for topic metadata and if this is done by many threads it can take down a small cluster or degrade greatly its performances.&lt;/p&gt;

&lt;p&gt;   The real life scenario is probably a reset gone wrong. Reproducing the issue is fairly simple, these are the steps:&lt;/p&gt;

&lt;p&gt;   Stop a Kafka streams application&lt;br/&gt;
   Delete one of its changelog and the local store&lt;br/&gt;
   Restart the application immediately after the topic delete&lt;br/&gt;
   You will see the Kafka streams application hanging after the bootstrap saying something like: INFO  Metadata - Cluster ID: xxxx&lt;/p&gt;


&lt;p&gt;   I am attaching a patch that fixes the issue client side but my personal opinion is that this should be tackled on the broker as well, metadata requests seem expensive and it would be easy to craft a DDOS that can potentially take down an entire cluster in seconds just by flooding the brokers with metadata requests.&lt;/p&gt;

&lt;p&gt;   The patch kicks in only when a topic that wasn&apos;t existing in the first call to getNumPartitions triggers a TopicExistsException. When this happens it forces the re-validation of the topic and if it still looks like doesn&apos;t exists plan a retry with some delay, to give the broker the necessary time to sort it out.&lt;/p&gt;

&lt;p&gt;   I think this patch makes sense beside the above mentioned use case where a topic it&apos;s not existing, because, even if the topic was actually created, the client should not blindly trust it and should still re-validate it by checking the number of partitions. IE: a topic can be created automatically by the first request and then it would have the default partitions rather than the expected ones.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16720316" author="githubbot" created="Thu, 13 Dec 2018 15:40:43 +0000"  >&lt;p&gt;mjsax closed pull request #5929: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7655&quot; title=&quot;Metadata spamming requests from Kafka Streams under some circumstances, potential DOS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7655&quot;&gt;&lt;del&gt;KAFKA-7655&lt;/del&gt;&lt;/a&gt; Metadata spamming requests from Kafka Streams under some circumstances, potential DOS&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5929&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5929&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java b/streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java&lt;br/&gt;
index b25894c2e04..c30ca43eb99 100644&lt;br/&gt;
&amp;#8212; a/streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java&lt;br/&gt;
@@ -980,6 +980,7 @@ private void checkIfUnexpectedUserSpecifiedConsumerConfig(final Map&amp;lt;String, Obje&lt;br/&gt;
         // add admin retries configs for creating topics&lt;br/&gt;
         final AdminClientConfig adminClientDefaultConfig = new AdminClientConfig(getClientPropsWithPrefix(ADMIN_CLIENT_PREFIX, AdminClientConfig.configNames()));&lt;br/&gt;
         consumerProps.put(adminClientPrefix(AdminClientConfig.RETRIES_CONFIG), adminClientDefaultConfig.getInt(AdminClientConfig.RETRIES_CONFIG));&lt;br/&gt;
+        consumerProps.put(adminClientPrefix(AdminClientConfig.RETRY_BACKOFF_MS_CONFIG), adminClientDefaultConfig.getLong(AdminClientConfig.RETRY_BACKOFF_MS_CONFIG));&lt;/p&gt;

&lt;p&gt;         // verify that producer batch config is no larger than segment size, then add topic configs required for creating topics&lt;br/&gt;
         final Map&amp;lt;String, Object&amp;gt; topicProps = originalsWithPrefix(TOPIC_PREFIX, false);&lt;br/&gt;
diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopicManager.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopicManager.java&lt;br/&gt;
index 6159ee25d6f..7e35126d263 100644&lt;br/&gt;
&amp;#8212; a/streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopicManager.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopicManager.java&lt;br/&gt;
@@ -57,6 +57,7 @@ private InternalAdminClientConfig(final Map&amp;lt;?, ?&amp;gt; props) {&lt;br/&gt;
     private final AdminClient adminClient;&lt;/p&gt;

&lt;p&gt;     private final int retries;&lt;br/&gt;
+    private final long retryBackOffMs;&lt;/p&gt;

&lt;p&gt;     public InternalTopicManager(final AdminClient adminClient,&lt;br/&gt;
                                 final StreamsConfig streamsConfig) {&lt;br/&gt;
@@ -67,7 +68,9 @@ public InternalTopicManager(final AdminClient adminClient,&lt;/p&gt;

&lt;p&gt;         replicationFactor = streamsConfig.getInt(StreamsConfig.REPLICATION_FACTOR_CONFIG).shortValue();&lt;br/&gt;
         windowChangeLogAdditionalRetention = streamsConfig.getLong(StreamsConfig.WINDOW_STORE_CHANGE_LOG_ADDITIONAL_RETENTION_MS_CONFIG);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;retries = new InternalAdminClientConfig(streamsConfig.getAdminConfigs(&quot;dummy&quot;)).getInt(AdminClientConfig.RETRIES_CONFIG);&lt;br/&gt;
+        final InternalAdminClientConfig dummyAdmin = new InternalAdminClientConfig(streamsConfig.getAdminConfigs(&quot;dummy&quot;));&lt;br/&gt;
+        retries = dummyAdmin.getInt(AdminClientConfig.RETRIES_CONFIG);&lt;br/&gt;
+        retryBackOffMs = dummyAdmin.getLong(AdminClientConfig.RETRY_BACKOFF_MS_CONFIG);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         log.debug(&quot;Configs:&quot; + Utils.NL,&lt;br/&gt;
             &quot;\t{} = {}&quot; + Utils.NL,&lt;br/&gt;
@@ -115,17 +118,22 @@ public void makeReady(final Map&amp;lt;String, InternalTopicConfig&amp;gt; topics) {&lt;/p&gt;

&lt;p&gt;             // TODO: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6928&quot; title=&quot;StreamsPartitionAssignor is double retrying within InternalTopicManager&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6928&quot;&gt;&lt;del&gt;KAFKA-6928&lt;/del&gt;&lt;/a&gt;. should not need retries in the outer caller as it will be retried internally in admin client&lt;br/&gt;
             int remainingRetries = retries;&lt;br/&gt;
+            boolean retryBackOff = false;&lt;br/&gt;
             boolean retry;&lt;br/&gt;
             do {&lt;br/&gt;
                 retry = false;&lt;/p&gt;

&lt;p&gt;                 final CreateTopicsResult createTopicsResult = adminClient.createTopics(newTopics);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final Set&amp;lt;String&amp;gt; createTopicNames = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
+                final Set&amp;lt;String&amp;gt; createdTopicNames = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
                 for (final Map.Entry&amp;lt;String, KafkaFuture&amp;lt;Void&amp;gt;&amp;gt; createTopicResult : createTopicsResult.values().entrySet()) {&lt;br/&gt;
                     try {&lt;br/&gt;
+                        if (retryBackOff) 
{
+                            retryBackOff = false;
+                            Thread.sleep(retryBackOffMs);
+                        }
&lt;p&gt;                         createTopicResult.getValue().get();&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;createTopicNames.add(createTopicResult.getKey());&lt;br/&gt;
+                        createdTopicNames.add(createTopicResult.getKey());&lt;br/&gt;
                     } catch (final ExecutionException couldNotCreateTopic) {&lt;br/&gt;
                         final Throwable cause = couldNotCreateTopic.getCause();&lt;br/&gt;
                         final String topicName = createTopicResult.getKey();&lt;br/&gt;
@@ -135,10 +143,23 @@ public void makeReady(final Map&amp;lt;String, InternalTopicConfig&amp;gt; topics) {&lt;br/&gt;
                             log.debug(&quot;Could not get number of partitions for topic {} due to timeout. &quot; +&lt;br/&gt;
                                 &quot;Will try again (remaining retries {}).&quot;, topicName, remainingRetries - 1);&lt;br/&gt;
                         } else if (cause instanceof TopicExistsException) {&lt;/li&gt;
	&lt;li&gt;createTopicNames.add(createTopicResult.getKey());&lt;/li&gt;
	&lt;li&gt;log.info(&quot;Topic {} exist already: {}&quot;,&lt;/li&gt;
	&lt;li&gt;topicName,&lt;/li&gt;
	&lt;li&gt;couldNotCreateTopic.toString());&lt;br/&gt;
+                            // This topic didn&apos;t exist earlier, it might be marked for deletion or it might differ&lt;br/&gt;
+                            // from the desired setup. It needs re-validation.&lt;br/&gt;
+                            final Map&amp;lt;String, Integer&amp;gt; existingTopicPartition = getNumPartitions(Collections.singleton(topicName));&lt;br/&gt;
+&lt;br/&gt;
+                            if (existingTopicPartition.containsKey(topicName)&lt;br/&gt;
+                                    &amp;amp;&amp;amp; validateTopicPartitions(Collections.singleton(topics.get(topicName)), existingTopicPartition).isEmpty()) {&lt;br/&gt;
+                                createdTopicNames.add(createTopicResult.getKey());&lt;br/&gt;
+                                log.info(&quot;Topic {} exists already and has the right number of partitions: {}&quot;,&lt;br/&gt;
+                                        topicName,&lt;br/&gt;
+                                        couldNotCreateTopic.toString());&lt;br/&gt;
+                            } else {&lt;br/&gt;
+                                retry = true;&lt;br/&gt;
+                                retryBackOff = true;&lt;br/&gt;
+                                log.info(&quot;Could not create topic {}. Topic is probably marked for deletion (number of partitions is unknown).\n&quot; +&lt;br/&gt;
+                                        &quot;Will retry to create this topic in {} ms (to let broker finish async delete operation first).\n&quot; +&lt;br/&gt;
+                                        &quot;Error message was: {}&quot;, topicName, retryBackOffMs, couldNotCreateTopic.toString());&lt;br/&gt;
+                            }&lt;br/&gt;
                         } else {&lt;br/&gt;
                             throw new StreamsException(String.format(&quot;Could not create topic %s.&quot;, topicName),&lt;br/&gt;
                                 couldNotCreateTopic);&lt;br/&gt;
@@ -151,7 +172,7 @@ public void makeReady(final Map&amp;lt;String, InternalTopicConfig&amp;gt; topics) {&lt;br/&gt;
                 }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;                 if (retry) &lt;/p&gt;
{
-                    newTopics.removeIf(newTopic -&amp;gt; createTopicNames.contains(newTopic.name()));
+                    newTopics.removeIf(newTopic -&amp;gt; createdTopicNames.contains(newTopic.name()));
 
                     continue;
                 }
&lt;p&gt;diff --git a/streams/src/test/java/org/apache/kafka/streams/StreamsConfigTest.java b/streams/src/test/java/org/apache/kafka/streams/StreamsConfigTest.java&lt;br/&gt;
index a86c38946df..c510f7d83ad 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/StreamsConfigTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/StreamsConfigTest.java&lt;br/&gt;
@@ -129,9 +129,11 @@ public void consumerConfigMustContainStreamPartitionAssignorConfig() {&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;     @Test&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void consumerConfigMustUseAdminClientConfigForRetries() {&lt;br/&gt;
+    public void consumerConfigShouldContainAdminClientConfigsForRetriesAndRetryBackOffMsWithAdminPrefix() {&lt;br/&gt;
         props.put(StreamsConfig.adminClientPrefix(StreamsConfig.RETRIES_CONFIG), 20);&lt;br/&gt;
+        props.put(StreamsConfig.adminClientPrefix(StreamsConfig.RETRY_BACKOFF_MS_CONFIG), 200L);&lt;br/&gt;
         props.put(StreamsConfig.RETRIES_CONFIG, 10);&lt;br/&gt;
+        props.put(StreamsConfig.RETRY_BACKOFF_MS_CONFIG, 100L);&lt;br/&gt;
         final StreamsConfig streamsConfig = new StreamsConfig(props);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         final String groupId = &quot;example-application&quot;;&lt;br/&gt;
@@ -139,6 +141,7 @@ public void consumerConfigMustUseAdminClientConfigForRetries() &lt;/p&gt;
{
         final Map&amp;lt;String, Object&amp;gt; returnedProps = streamsConfig.getMainConsumerConfigs(groupId, clientId);
 
         assertEquals(20, returnedProps.get(StreamsConfig.adminClientPrefix(StreamsConfig.RETRIES_CONFIG)));
+        assertEquals(200L, returnedProps.get(StreamsConfig.adminClientPrefix(StreamsConfig.RETRY_BACKOFF_MS_CONFIG)));
     }

&lt;p&gt;     @Test&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16720370" author="mjsax" created="Thu, 13 Dec 2018 16:34:40 +0000"  >&lt;p&gt;Added you to the list on contributors and assigned the ticket to you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=p.vazzana&quot; class=&quot;user-hover&quot; rel=&quot;p.vazzana&quot;&gt;p.vazzana&lt;/a&gt;. You can now also self-assign tickets.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13160832">KAFKA-6928</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310250" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10430"><![CDATA[Patch]]></customfieldvalue>
    <customfieldvalue key="10431"><![CDATA[Important]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 48 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|s00nq0:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>