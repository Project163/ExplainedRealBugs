<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:06:30 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6492] LogSemgent.truncateTo() should always resize the index file</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6492</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;The bug is the following:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Initially on a follower broker there are two segments 0 and segment 10000. Segment 0 is empty (maybe due to log compaction)&lt;/li&gt;
	&lt;li&gt;log is truncated to 0.&lt;/li&gt;
	&lt;li&gt;LogSemgent.Truncate() will not find a message to truncate in segment 0, so it will skip resizing the index/timeindex files.&#160;&lt;/li&gt;
	&lt;li&gt;When a new message is fetched, Log.maybeRoll() will try to roll a new segment because the index file of segment 0 is already full (max size is 0)&lt;/li&gt;
	&lt;li&gt;After creating the new segment 0, the replica fetcher thread finds that there is already a segment 0 exists. So it just throws exception and dies.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;The fix would be let the broker&#160;make sure the index files of active segments are always resized properly.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13134336">KAFKA-6492</key>
            <summary>LogSemgent.truncateTo() should always resize the index file</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hachikuji">Jason Gustafson</assignee>
                                    <reporter username="becket_qin">Jiangjie Qin</reporter>
                        <labels>
                    </labels>
                <created>Mon, 29 Jan 2018 00:35:05 +0000</created>
                <updated>Fri, 2 Feb 2018 01:07:28 +0000</updated>
                            <resolved>Fri, 2 Feb 2018 01:07:28 +0000</resolved>
                                    <version>0.10.0.2</version>
                    <version>0.10.1.1</version>
                    <version>0.10.2.1</version>
                    <version>0.11.0.2</version>
                    <version>1.0.0</version>
                                    <fixVersion>1.1.0</fixVersion>
                                    <component>core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="16347394" author="hachikuji" created="Wed, 31 Jan 2018 18:58:50 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=becket_qin&quot; class=&quot;user-hover&quot; rel=&quot;becket_qin&quot;&gt;becket_qin&lt;/a&gt; Does this only affect 1.0.0? As far as I can tell, it&#160;can happen on older versions as well. I have seen recently an instance of the failure during log rolling on 0.10.1. It was a compacted topic, but I cannot confirm whether it is the specific truncation scenario you describe above (I don&apos;t have all the historic logs).&lt;/p&gt;</comment>
                            <comment id="16347612" author="githubbot" created="Wed, 31 Jan 2018 21:06:58 +0000"  >&lt;p&gt;hachikuji opened a new pull request #4498: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6492&quot; title=&quot;LogSemgent.truncateTo() should always resize the index file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6492&quot;&gt;&lt;del&gt;KAFKA-6492&lt;/del&gt;&lt;/a&gt;: Fix log truncation to empty segment&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4498&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4498&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   This patch ensures that truncation to an empty segment forces resizing of the index file in order to prevent premature rolling.&lt;/p&gt;

&lt;p&gt;   I have added unit tests which verify that appends are permitted following truncation to an empty segment. Without the fix, this test case reproduces the failure in which the rolled segment matches the current active segment.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16347670" author="becket_qin" created="Wed, 31 Jan 2018 21:49:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt;&#160;You are right. This issue will affect earlier versions as well. I&apos;ll submit a PR.&lt;/p&gt;</comment>
                            <comment id="16347816" author="hachikuji" created="Thu, 1 Feb 2018 00:25:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=becket_qin&quot; class=&quot;user-hover&quot; rel=&quot;becket_qin&quot;&gt;becket_qin&lt;/a&gt; Beat you to it. Let me know if the PR I&#160;submitted makes sense.&lt;/p&gt;</comment>
                            <comment id="16349179" author="githubbot" created="Thu, 1 Feb 2018 19:59:32 +0000"  >&lt;p&gt;becketqin closed pull request #4498: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6492&quot; title=&quot;LogSemgent.truncateTo() should always resize the index file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6492&quot;&gt;&lt;del&gt;KAFKA-6492&lt;/del&gt;&lt;/a&gt;: Fix log truncation to empty segment&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4498&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4498&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/core/src/main/scala/kafka/log/LogSegment.scala b/core/src/main/scala/kafka/log/LogSegment.scala&lt;br/&gt;
index 45c820bff8d..5970f42f6d9 100755&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/log/LogSegment.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/log/LogSegment.scala&lt;br/&gt;
@@ -28,7 +28,7 @@ import kafka.utils._&lt;br/&gt;
 import org.apache.kafka.common.errors.CorruptRecordException&lt;br/&gt;
 import org.apache.kafka.common.record.FileRecords.LogOffsetPosition&lt;br/&gt;
 import org.apache.kafka.common.record._&lt;br/&gt;
-import org.apache.kafka.common.utils.&lt;/p&gt;
{Time}
&lt;p&gt;+import org.apache.kafka.common.utils.Time&lt;/p&gt;

&lt;p&gt; import scala.collection.JavaConverters._&lt;br/&gt;
 import scala.math._&lt;br/&gt;
@@ -345,20 +345,23 @@ class LogSegment private&lt;span class=&quot;error&quot;&gt;&amp;#91;log&amp;#93;&lt;/span&gt; (val log: FileRecords,&lt;br/&gt;
    */&lt;br/&gt;
   @nonthreadsafe&lt;br/&gt;
   def truncateTo(offset: Long): Int = {&lt;br/&gt;
+    // Do offset translation before truncating the index to avoid needless scanning&lt;br/&gt;
+    // in case we truncate the full index&lt;br/&gt;
     val mapping = translateOffset(offset)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (mapping == null)&lt;/li&gt;
	&lt;li&gt;return 0&lt;br/&gt;
     offsetIndex.truncateTo(offset)&lt;br/&gt;
     timeIndex.truncateTo(offset)&lt;br/&gt;
     txnIndex.truncateTo(offset)&lt;/li&gt;
	&lt;li&gt;// after truncation, reset and allocate more space for the (new currently  active) index&lt;br/&gt;
+&lt;br/&gt;
+    // After truncation, reset and allocate more space for the (new currently active) index&lt;br/&gt;
     offsetIndex.resize(offsetIndex.maxIndexSize)&lt;br/&gt;
     timeIndex.resize(timeIndex.maxIndexSize)&lt;/li&gt;
	&lt;li&gt;val bytesTruncated = log.truncateTo(mapping.position)&lt;/li&gt;
	&lt;li&gt;if(log.sizeInBytes == 0) {&lt;br/&gt;
+&lt;br/&gt;
+    val bytesTruncated = if (mapping == null) 0 else log.truncateTo(mapping.position)&lt;br/&gt;
+    if (log.sizeInBytes == 0) 
{
       created = time.milliseconds
       rollingBasedTimestamp = None
     }
&lt;p&gt;+&lt;br/&gt;
     bytesSinceLastIndexEntry = 0&lt;br/&gt;
     if (maxTimestampSoFar &amp;gt;= 0)&lt;br/&gt;
       loadLargestTimestamp()&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/log/LogSegmentTest.scala b/core/src/test/scala/unit/kafka/log/LogSegmentTest.scala&lt;br/&gt;
index 469b3cca40e..c45ed0d2986 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/test/scala/unit/kafka/log/LogSegmentTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/log/LogSegmentTest.scala&lt;br/&gt;
@@ -22,7 +22,7 @@ import kafka.utils.TestUtils&lt;br/&gt;
 import kafka.utils.TestUtils.checkEquals&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition&lt;br/&gt;
 import org.apache.kafka.common.record._&lt;br/&gt;
-import org.apache.kafka.common.utils.
{Time, Utils}
&lt;p&gt;+import org.apache.kafka.common.utils.&lt;/p&gt;
{MockTime, Time, Utils}
&lt;p&gt; import org.junit.Assert._&lt;br/&gt;
 import org.junit.&lt;/p&gt;
{After, Before, Test}&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -36,13 +36,16 @@ class LogSegmentTest {&lt;br/&gt;
   var logDir: File = _&lt;/p&gt;

&lt;p&gt;   /* create a segment with the given base offset */&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def createSegment(offset: Long, indexIntervalBytes: Int = 10): LogSegment = {&lt;br/&gt;
+  def createSegment(offset: Long,&lt;br/&gt;
+                    indexIntervalBytes: Int = 10,&lt;br/&gt;
+                    maxSegmentMs: Int = Int.MaxValue,&lt;br/&gt;
+                    time: Time = Time.SYSTEM): LogSegment = 
{
     val ms = FileRecords.open(Log.logFile(logDir, offset))
     val idx = new OffsetIndex(Log.offsetIndexFile(logDir, offset), offset, maxIndexSize = 1000)
     val timeIdx = new TimeIndex(Log.timeIndexFile(logDir, offset), offset, maxIndexSize = 1500)
     val txnIndex = new TransactionIndex(offset, Log.transactionIndexFile(logDir, offset))
-    val seg = new LogSegment(ms, idx, timeIdx, txnIndex, offset, indexIntervalBytes, 0, maxSegmentMs = Int.MaxValue,
-      maxSegmentBytes = Int.MaxValue, Time.SYSTEM)
+    val seg = new LogSegment(ms, idx, timeIdx, txnIndex, offset, indexIntervalBytes, 0, maxSegmentMs = maxSegmentMs,
+      maxSegmentBytes = Int.MaxValue, time)
     segments += seg
     seg
   }
&lt;p&gt;@@ -157,6 +160,47 @@ class LogSegmentTest {&lt;br/&gt;
     }&lt;br/&gt;
   }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+  @Test&lt;br/&gt;
+  def testTruncateEmptySegment() &lt;/p&gt;
{
+    // This tests the scenario in which the follower truncates to an empty segment. In this
+    // case we must ensure that the index is resized so that the log segment is not mistakenly
+    // rolled due to a full index
+
+    val maxSegmentMs = 300000
+    val time = new MockTime
+    val seg = createSegment(0, maxSegmentMs = maxSegmentMs, time = time)
+    seg.close()
+
+    val reopened = createSegment(0, maxSegmentMs = maxSegmentMs, time = time)
+    assertEquals(0, seg.timeIndex.sizeInBytes)
+    assertEquals(0, seg.offsetIndex.sizeInBytes)
+
+    time.sleep(500)
+    reopened.truncateTo(57)
+    assertEquals(0, reopened.timeWaitedForRoll(time.milliseconds(), RecordBatch.NO_TIMESTAMP))
+    assertFalse(reopened.timeIndex.isFull)
+    assertFalse(reopened.offsetIndex.isFull)
+
+    assertFalse(reopened.shouldRoll(messagesSize = 1024,
+      maxTimestampInMessages = RecordBatch.NO_TIMESTAMP,
+      maxOffsetInMessages = 100L,
+      now = time.milliseconds()))
+
+    // The segment should not be rolled even if maxSegmentMs has been exceeded
+    time.sleep(maxSegmentMs + 1)
+    assertEquals(maxSegmentMs + 1, reopened.timeWaitedForRoll(time.milliseconds(), RecordBatch.NO_TIMESTAMP))
+    assertFalse(reopened.shouldRoll(messagesSize = 1024,
+      maxTimestampInMessages = RecordBatch.NO_TIMESTAMP,
+      maxOffsetInMessages = 100L,
+      now = time.milliseconds()))
+
+    // But we should still roll the segment if we cannot fit the next offset
+    assertTrue(reopened.shouldRoll(messagesSize = 1024,
+      maxTimestampInMessages = RecordBatch.NO_TIMESTAMP,
+      maxOffsetInMessages = Int.MaxValue.toLong + 200,
+      now = time.milliseconds()))
+  }
&lt;p&gt;+&lt;br/&gt;
   @Test&lt;br/&gt;
   def testReloadLargestTimestampAndNextOffsetAfterTruncation() {&lt;br/&gt;
     val numMessages = 30&lt;br/&gt;
@@ -183,10 +227,20 @@ class LogSegmentTest {&lt;br/&gt;
   @Test&lt;br/&gt;
   def testTruncateFull() &lt;/p&gt;
{
     // test the case where we fully truncate the log
-    val seg = createSegment(40)
+    val time = new MockTime
+    val seg = createSegment(40, time = time)
     seg.append(40, 41, RecordBatch.NO_TIMESTAMP, -1L, records(40, &quot;hello&quot;, &quot;there&quot;))
+
+    // If the segment is empty after truncation, the create time should be reset
+    time.sleep(500)
+    assertEquals(500, seg.timeWaitedForRoll(time.milliseconds(), RecordBatch.NO_TIMESTAMP))
+
     seg.truncateTo(0)
+    assertEquals(0, seg.timeWaitedForRoll(time.milliseconds(), RecordBatch.NO_TIMESTAMP))
+    assertFalse(seg.timeIndex.isFull)
+    assertFalse(seg.offsetIndex.isFull)
     assertNull(&quot;Segment should be empty.&quot;, seg.read(0, None, 1024))
+
     seg.append(40, 41, RecordBatch.NO_TIMESTAMP, -1L, records(40, &quot;hello&quot;, &quot;there&quot;))
   }

&lt;p&gt;diff --git a/core/src/test/scala/unit/kafka/log/LogTest.scala b/core/src/test/scala/unit/kafka/log/LogTest.scala&lt;br/&gt;
index 2f78ec3cae1..6753939f3d8 100755&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/log/LogTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/log/LogTest.scala&lt;br/&gt;
@@ -152,6 +152,28 @@ class LogTest &lt;/p&gt;
{
     log.appendAsLeader(nextRecords, leaderEpoch = 0)
   }

&lt;p&gt;+  @Test&lt;br/&gt;
+  def testTruncateToEmptySegment(): Unit = &lt;/p&gt;
{
+    val log = createLog(logDir, LogConfig())
+
+    // Force a segment roll by using a large offset. The first segment will be empty
+    val records = TestUtils.records(List(new SimpleRecord(mockTime.milliseconds, &quot;key&quot;.getBytes, &quot;value&quot;.getBytes)),
+      baseOffset = Int.MaxValue.toLong + 200)
+    appendAsFollower(log, records)
+    assertEquals(0, log.logSegments.head.size)
+    assertEquals(2, log.logSegments.size)
+
+    // Truncate to an offset before the base offset of the latest segment
+    log.truncateTo(0L)
+    assertEquals(1, log.logSegments.size)
+
+    // Now verify that we can still append to the active segment
+    appendAsFollower(log, TestUtils.records(List(new SimpleRecord(mockTime.milliseconds, &quot;key&quot;.getBytes, &quot;value&quot;.getBytes)),
+      baseOffset = 100L))
+    assertEquals(1, log.logSegments.size)
+    assertEquals(101L, log.logEndOffset)
+  }
&lt;p&gt;+&lt;br/&gt;
   @Test&lt;br/&gt;
   def testInitializationOfProducerSnapshotsUpgradePath(): Unit = {&lt;br/&gt;
     // simulate the upgrade path by creating a new log with several segments, deleting the&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 41 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3pguv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>