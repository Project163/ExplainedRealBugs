<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:55:18 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-3915] LogCleaner IO buffers do not account for potential size difference due to message format change</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-3915</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;We are upgrading from Kafka 0.8.1 to 0.10.0.0 and discovered an issue after getting the following exception from the log cleaner:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[2016-06-28 10:02:18,759] ERROR [kafka-log-cleaner-thread-0], Error due to  (kafka.log.LogCleaner)
java.nio.BufferOverflowException
	at java.nio.HeapByteBuffer.put(HeapByteBuffer.java:206)
	at kafka.message.ByteBufferMessageSet$.writeMessage(ByteBufferMessageSet.scala:169)
	at kafka.log.Cleaner$$anonfun$cleanInto$1.apply(LogCleaner.scala:435)
	at kafka.log.Cleaner$$anonfun$cleanInto$1.apply(LogCleaner.scala:429)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:893)
	at kafka.utils.IteratorTemplate.foreach(IteratorTemplate.scala:30)
	at kafka.log.Cleaner.cleanInto(LogCleaner.scala:429)
	at kafka.log.Cleaner$$anonfun$cleanSegments$1.apply(LogCleaner.scala:380)
	at kafka.log.Cleaner$$anonfun$cleanSegments$1.apply(LogCleaner.scala:376)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:376)
	at kafka.log.Cleaner$$anonfun$clean$4.apply(LogCleaner.scala:343)
	at kafka.log.Cleaner$$anonfun$clean$4.apply(LogCleaner.scala:342)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at kafka.log.Cleaner.clean(LogCleaner.scala:342)
	at kafka.log.LogCleaner$CleanerThread.cleanOrSleep(LogCleaner.scala:237)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:215)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;At first this seems impossible because the input and output buffers are identically sized. But in the case where the source messages are of an older format, additional space may be required to write them out in the new one. Since the message header is 8 bytes larger in 0.10.0, this failure can happen. &lt;/p&gt;

&lt;p&gt;We&apos;re planning to work around this by adding the following config:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;log.message.format.version=0.8.1&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; but this definitely needs a fix.&lt;/p&gt;

&lt;p&gt;We could simply preserve the existing message format (since in this case we can&apos;t retroactively add a timestamp anyway). Otherwise, the log cleaner would have to be smarter about ensuring there is sufficient &quot;slack space&quot; in the output buffer to account for the size difference * the number of messages in the input buffer. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12984402">KAFKA-3915</key>
            <summary>LogCleaner IO buffers do not account for potential size difference due to message format change</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ijuma">Ismael Juma</assignee>
                                    <reporter username="twbecker">Tommy Becker</reporter>
                        <labels>
                    </labels>
                <created>Tue, 28 Jun 2016 14:58:57 +0000</created>
                <updated>Wed, 20 Jul 2016 19:59:34 +0000</updated>
                            <resolved>Wed, 20 Jul 2016 19:59:33 +0000</resolved>
                                    <version>0.10.0.0</version>
                                    <fixVersion>0.10.0.1</fixVersion>
                    <fixVersion>0.10.1.0</fixVersion>
                                    <component>log</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>8</watches>
                                                                                                                <comments>
                            <comment id="15353396" author="junrao" created="Tue, 28 Jun 2016 17:14:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=twbecker&quot; class=&quot;user-hover&quot; rel=&quot;twbecker&quot;&gt;twbecker&lt;/a&gt;, thanks for reporting this. &lt;/p&gt;

&lt;p&gt;Keeping the old message format during cleaning will be an easy fix. However, converting the message format to the latest version allows us to potentially deprecate the old message format in the future, even though we don&apos;t get more information on timestamp during conversion. Another point is that in the future, when copying the messages out to the new segment, we may want to use the compression type specified at the topic level instead of the original compression type. If we do that, the new message size could also be different. So, it&apos;s probably worth thinking through how to make the cleaner handle the case of write overflow.&lt;/p&gt;

&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=becket_qin&quot; class=&quot;user-hover&quot; rel=&quot;becket_qin&quot;&gt;becket_qin&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="15353422" author="ijuma" created="Tue, 28 Jun 2016 17:33:01 +0000"  >&lt;p&gt;&quot;Another point is that in the future, when copying the messages out to the new segment, we may want to use the compression type specified at the topic level instead of the original compression type&quot;&lt;/p&gt;

&lt;p&gt;That&apos;s &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3252&quot; title=&quot;compression type for a topic should be used during log compaction &quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3252&quot;&gt;KAFKA-3252&lt;/a&gt; where there is a PR (there are some questions there about how to handle some of the issues in the PR).&lt;/p&gt;</comment>
                            <comment id="15354183" author="junrao" created="Wed, 29 Jun 2016 01:38:40 +0000"  >&lt;p&gt;The writeBuffer is set to maxMessageSize. We can&apos;t really exceed that. So, it seems that we will have to preserve the existing message format.&lt;/p&gt;</comment>
                            <comment id="15355135" author="twbecker" created="Wed, 29 Jun 2016 12:29:49 +0000"  >&lt;p&gt;Should a change to the default maxMessageSize be considered? Otherwise applications which are close to the current limit will likely fail at some point due to the additional timestamp overhead.&lt;/p&gt;</comment>
                            <comment id="15355150" author="twbecker" created="Wed, 29 Jun 2016 12:39:52 +0000"  >&lt;p&gt;Actually, I don&apos;t think this is true. The buffer is set to maxMessageSize but it potentially buffers multiple messages before it is written out. This error occurs when there is not 8 * N bytes of slack in the writeBuffer, where N is number of messages in the read buffer. Only in the case of N = 1 would we be forced to keep the old format.&lt;/p&gt;</comment>
                            <comment id="15357996" author="junrao" created="Thu, 30 Jun 2016 22:53:20 +0000"  >&lt;p&gt;Yes, we could choose to only keep the old message format if converting a single message exceeds the maxMessageSize. However, if we can&apos;t guarantee to get rid of all old message format, it&apos;s probably simpler to just always keep the old messages for now. We can figure out how to do the conversion consistently in the future.&lt;/p&gt;

&lt;p&gt;About the default maxMessageSize. The default max message size is supposed to include the message overhead. In Log.append(), we check the following. So, I think we are covered even with the additional timestamp overhead.&lt;br/&gt;
              if (MessageSet.entrySize(messageAndOffset.message) &amp;gt; config.maxMessageSize) {&lt;/p&gt;
</comment>
                            <comment id="15383610" author="wushujames" created="Tue, 19 Jul 2016 05:52:31 +0000"  >&lt;p&gt;We just saw this in one of our brokers as well. We are running Kafka 0.10.0.0.&lt;/p&gt;</comment>
                            <comment id="15384017" author="twbecker" created="Tue, 19 Jul 2016 12:03:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt; Yes I understand the max message size includes overhead, that is my point. It is possible to have a message that is very close to the current max size that will no longer fit with the additional overhead. If the max size was increased by 8 bytes, we could guarantee that all current messages are migratable. Am I missing something?&lt;/p&gt;</comment>
                            <comment id="15384060" author="ijuma" created="Tue, 19 Jul 2016 12:20:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=twbecker&quot; class=&quot;user-hover&quot; rel=&quot;twbecker&quot;&gt;twbecker&lt;/a&gt;, the issue is that consumers might not be able to consume such messages if their `max.partition.fetch.bytes` is not updated to take this into account. As such, the suggested change is not safe. There is a discussion about changing the consumer semantics so that it can handle messages larger than `max.partition.fetch.bytes`, but we need a fix now so Jun&apos;s suggested change is the way forward in my opinion. I have done the change locally and should have a PR ready soon.&lt;/p&gt;</comment>
                            <comment id="15385866" author="githubbot" created="Wed, 20 Jul 2016 13:38:59 +0000"  >&lt;p&gt;GitHub user ijuma opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1643&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1643&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3915&quot; title=&quot;LogCleaner IO buffers do not account for potential size difference due to message format change&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3915&quot;&gt;&lt;del&gt;KAFKA-3915&lt;/del&gt;&lt;/a&gt;; Don&apos;t convert messages from v0 to v1 during log compaction&lt;/p&gt;

&lt;p&gt;    The conversion is unsafe as the converted message size may be greater&lt;br/&gt;
    than the message size limit. Updated `LogCleanerIntegrationTest` to test the max message size case for both V0 and the current version.&lt;/p&gt;

&lt;p&gt;    Also include a few minor clean-ups:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Remove unused expression&lt;/li&gt;
	&lt;li&gt;Avoid unintentional usage of `scala.collection.immutable.Stream` (`toSeq` on an `Iterator`)&lt;/li&gt;
	&lt;li&gt;Add explicit result type in `FileMessageSet.iterator`&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/ijuma/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/ijuma/kafka&lt;/a&gt; kafka-3915-log-cleaner-io-buffers-message-conversion&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1643.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1643.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #1643&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 083029d12a12ca0e750dddf08a4ce8f4ec5db8bb&lt;br/&gt;
Author: Ismael Juma &amp;lt;ismael@juma.me.uk&amp;gt;&lt;br/&gt;
Date:   2016-07-20T13:34:04Z&lt;/p&gt;

&lt;p&gt;    Don&apos;t convert messages from version 0 to version 1 during log compaction&lt;/p&gt;

&lt;p&gt;    The conversion is unsafe as the converted message size may be greater&lt;br/&gt;
    than the message size limit.&lt;/p&gt;

&lt;p&gt;commit 1262c2f87f6dd65c8624dde7f3406de7ab00cb99&lt;br/&gt;
Author: Ismael Juma &amp;lt;ismael@juma.me.uk&amp;gt;&lt;br/&gt;
Date:   2016-07-20T13:35:47Z&lt;/p&gt;

&lt;p&gt;    Remove unused expression, avoid usage of scala.Stream and use explicit return type for public method&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15386504" author="githubbot" created="Wed, 20 Jul 2016 19:50:06 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1643&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1643&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15386518" author="guozhang" created="Wed, 20 Jul 2016 19:59:34 +0000"  >&lt;p&gt;Issue resolved by pull request 1643&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/pull/1643&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1643&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 17 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i309gn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>