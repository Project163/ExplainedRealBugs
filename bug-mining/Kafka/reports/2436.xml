<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:21:14 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-9231] Streams Threads may die from recoverable errors with EOS enabled</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-9231</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;While testing Streams in EOS mode under frequent and heavy network partitions, I&apos;ve encountered the following error, leading to thread death:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[2019-11-26 04:54:02,650] ERROR [stream-soak-test-4290196e-d805-4acd-9f78-b459cc7e99ee-StreamThread-2] stream-thread [stream-soak-test-4290196e-d805-4acd-9f78-b459cc7e99ee-StreamThread-2] Encountered the following unexpected Kafka exception during processing, this usually indicate Streams internal errors: (org.apache.kafka.streams.processor.internals.StreamThread)
org.apache.kafka.streams.errors.StreamsException: stream-thread [stream-soak-test-4290196e-d805-4acd-9f78-b459cc7e99ee-StreamThread-2] Failed to rebalance.
	at org.apache.kafka.streams.processor.internals.StreamThread.pollRequests(StreamThread.java:852)
	at org.apache.kafka.streams.processor.internals.StreamThread.runOnce(StreamThread.java:739)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:698)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:671)
Caused by: org.apache.kafka.streams.errors.StreamsException: stream-thread [stream-soak-test-4290196e-d805-4acd-9f78-b459cc7e99ee-StreamThread-2] failed to suspend stream tasks
	at org.apache.kafka.streams.processor.internals.TaskManager.suspendActiveTasksAndState(TaskManager.java:253)
	at org.apache.kafka.streams.processor.internals.StreamsRebalanceListener.onPartitionsRevoked(StreamsRebalanceListener.java:116)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.invokePartitionsRevoked(ConsumerCoordinator.java:291)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onLeavePrepare(ConsumerCoordinator.java:707)
	at org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe(KafkaConsumer.java:1073)
	at org.apache.kafka.streams.processor.internals.StreamThread.enforceRebalance(StreamThread.java:716)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:710)
	... 1 more
Caused by: org.apache.kafka.streams.errors.ProcessorStateException: task [1_1] Failed to flush state store KSTREAM-AGGREGATE-STATE-STORE-0000000007
	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flush(ProcessorStateManager.java:279)
	at org.apache.kafka.streams.processor.internals.AbstractTask.flushState(AbstractTask.java:175)
	at org.apache.kafka.streams.processor.internals.StreamTask.flushState(StreamTask.java:581)
	at org.apache.kafka.streams.processor.internals.StreamTask.commit(StreamTask.java:535)
	at org.apache.kafka.streams.processor.internals.StreamTask.suspend(StreamTask.java:660)
	at org.apache.kafka.streams.processor.internals.StreamTask.suspend(StreamTask.java:628)
	at org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.suspendRunningTasks(AssignedStreamsTasks.java:145)
	at org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.suspendOrCloseTasks(AssignedStreamsTasks.java:128)
	at org.apache.kafka.streams.processor.internals.TaskManager.suspendActiveTasksAndState(TaskManager.java:246)
	... 7 more
Caused by: org.apache.kafka.common.errors.ProducerFencedException: Producer attempted an operation with an old epoch. Either there is a newer producer with the same transactionalId, or the producer&apos;s transaction has been expired by the broker.
[2019-11-26 04:54:02,650] INFO [stream-soak-test-4290196e-d805-4acd-9f78-b459cc7e99ee-StreamThread-2] stream-thread [stream-soak-test-4290196e-d805-4acd-9f78-b459cc7e99ee-StreamThread-2] State transition from PARTITIONS_REVOKED to PENDING_SHUTDOWN (org.apache.kafka.streams.processor.internals.StreamThread)
[2019-11-26 04:54:02,650] INFO [stream-soak-test-4290196e-d805-4acd-9f78-b459cc7e99ee-StreamThread-2] stream-thread [stream-soak-test-4290196e-d805-4acd-9f78-b459cc7e99ee-StreamThread-2] Shutting down (org.apache.kafka.streams.processor.internals.StreamThread)
[2019-11-26 04:54:02,650] INFO [stream-soak-test-4290196e-d805-4acd-9f78-b459cc7e99ee-StreamThread-2] [Consumer clientId=stream-soak-test-4290196e-d805-4acd-9f78-b459cc7e99ee-StreamThread-2-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[2019-11-26 04:54:02,653] INFO [stream-soak-test-4290196e-d805-4acd-9f78-b459cc7e99ee-StreamThread-2] stream-thread [stream-soak-test-4290196e-d805-4acd-9f78-b459cc7e99ee-StreamThread-2] State transition from PENDING_SHUTDOWN to DEAD (org.apache.kafka.streams.processor.internals.StreamThread)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Elsewhere in the code, we catch ProducerFencedExceptions and trigger a rebalance instead of killing the thread. It seems like one possible avenue has slipped through the cracks.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13270749">KAFKA-9231</key>
            <summary>Streams Threads may die from recoverable errors with EOS enabled</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="vvcephei">John Roesler</assignee>
                                    <reporter username="vvcephei">John Roesler</reporter>
                        <labels>
                    </labels>
                <created>Tue, 26 Nov 2019 16:02:38 +0000</created>
                <updated>Tue, 17 Dec 2019 21:21:03 +0000</updated>
                            <resolved>Wed, 4 Dec 2019 00:55:57 +0000</resolved>
                                    <version>2.4.0</version>
                                    <fixVersion>2.4.0</fixVersion>
                                    <component>streams</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16982634" author="githubbot" created="Tue, 26 Nov 2019 16:05:43 +0000"  >&lt;p&gt;vvcephei commented on pull request #7748: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-9231&quot; title=&quot;Streams Threads may die from recoverable errors with EOS enabled&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-9231&quot;&gt;&lt;del&gt;KAFKA-9231&lt;/del&gt;&lt;/a&gt;: Streams: Rebalance when fenced in suspend&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/7748&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/7748&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   We missed a branch in which we might catch a ProducerFencedException. It should always be converted to a TaskMigratedException.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on to GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16985429" author="vvcephei" created="Sat, 30 Nov 2019 20:24:42 +0000"  >&lt;p&gt;In addition to the error I listed above (ProducerFencedException), I have also observed the following recoverable exceptions leading to threads dying:&lt;/p&gt;

&lt;p&gt;UnknownProducerIdException:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.kafka.streams.errors.StreamsException: task [1_0] Abort sending since an error caught with a previous record (timestamp 1574960233670) to topic stream-soak-test-KSTREAM-AGGREGATE-STATE-STORE-0000000019-changelog due to org.apache.kafka.common.errors.UnknownProducerIdException: This exception is raised by the broker if it could not locate the producer metadata associated with the producerId in question. This could happen if, for instance, the producer&apos;s records were deleted because their retention time had elapsed. Once the last records of the producerId are removed, the producer&apos;s metadata is removed from the broker, and future appends by the producer will return this exception.
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:143)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.access$500(RecordCollectorImpl.java:51)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl$1.onCompletion(RecordCollectorImpl.java:202)
	at org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1348)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:230)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:196)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:730)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:716)
	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:674)
	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:596)
	at org.apache.kafka.clients.producer.internals.Sender.access$100(Sender.java:74)
	at org.apache.kafka.clients.producer.internals.Sender$1.onComplete(Sender.java:798)
	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:109)
	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:562)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:554)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:335)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:244)
	at java.lang.Thread.run(Thread.java:748)
 Caused by: org.apache.kafka.common.errors.UnknownProducerIdException: This exception is raised by the broker if it could not locate the producer metadata associated with the producerId in question. This could happen if, for instance, the producer&apos;s records were deleted because their retention time had elapsed. Once the last records of the producerId are removed, the producer&apos;s metadata is removed from the broker, and future appends by the producer will return this exception.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and an internal assertion:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;java.lang.IllegalStateException: RocksDB metrics recorder for store &quot;KSTREAM-AGGREGATE-STATE-STORE-0000000049&quot; of task 3_1 has already been added. This is a bug in Kafka Streams.
	at org.apache.kafka.streams.state.internals.metrics.RocksDBMetricsRecordingTrigger.addMetricsRecorder(RocksDBMetricsRecordingTrigger.java:30)
	at org.apache.kafka.streams.state.internals.metrics.RocksDBMetricsRecorder.addStatistics(RocksDBMetricsRecorder.java:93)
	at org.apache.kafka.streams.state.internals.RocksDBStore.maybeSetUpMetricsRecorder(RocksDBStore.java:205)
	at org.apache.kafka.streams.state.internals.RocksDBStore.openDB(RocksDBStore.java:191)
	at org.apache.kafka.streams.state.internals.RocksDBStore.init(RocksDBStore.java:227)
	at org.apache.kafka.streams.state.internals.WrappedStateStore.init(WrappedStateStore.java:48)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.init(ChangeLoggingKeyValueBytesStore.java:44)
	at org.apache.kafka.streams.state.internals.WrappedStateStore.init(WrappedStateStore.java:48)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.init(CachingKeyValueStore.java:58)
	at org.apache.kafka.streams.state.internals.WrappedStateStore.init(WrappedStateStore.java:48)
	at org.apache.kafka.streams.state.internals.MeteredKeyValueStore.lambda$init$0(MeteredKeyValueStore.java:203)
	at org.apache.kafka.streams.state.internals.MeteredKeyValueStore.measureLatency(MeteredKeyValueStore.java:356)
	at org.apache.kafka.streams.state.internals.MeteredKeyValueStore.init(MeteredKeyValueStore.java:201)
	at org.apache.kafka.streams.processor.internals.AbstractTask.registerStateStores(AbstractTask.java:211)
	at org.apache.kafka.streams.processor.internals.StreamTask.initializeStateStores(StreamTask.java:323)
	at org.apache.kafka.streams.processor.internals.AssignedTasks.initializeNewTasks(AssignedTasks.java:76)
	at org.apache.kafka.streams.processor.internals.TaskManager.updateNewAndRestoringTasks(TaskManager.java:385)
	at org.apache.kafka.streams.processor.internals.StreamThread.runOnce(StreamThread.java:769)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:698)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:671)
[2019-11-29 08:27:08,883] INFO [stream-soak-test-a0363f9f-ff9c-4dbd-b38a-8e898d77a22e-StreamThread-2] stream-thread [stream-soak-test-a0363f9f-ff9c-4dbd-b38a-8e898d77a22e-StreamThread-2] State transition from PARTITIONS_ASSIGNED to PENDING_SHUTDOWN (org.apache.kafka.streams.processor.internals.StreamThread)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is a specific internal assertion. What happened there is that the RocksDBStore initializer registers itself with the metric collector before fully creating the store. The store creation failed, but it was still registered, leading to a situation where the store could no longer be created at all.&lt;/p&gt;

&lt;p&gt;My testing setup is to run a Streams application processing data at a modest rate (~ 20K records/sec) in a three-instance configuration, each of which have three StreamsThreads. I&apos;m introducing network partitions separating each instance one at a time from the brokers, at an incidence of about one network partition per hour, each lasting up to 5 minutes.&lt;/p&gt;

&lt;p&gt;I&apos;ve observed all of these exceptions to kill Streams threads within a few occurrences of network partitioning. Note that Streams is configured with appropriate timeouts/retries to tolerate network interruptions lasting longer than 5 mintues, so any thread deaths are unexpected. All the thread deaths I&apos;ve observed are the results of bugs in the Streams exception handling code.&lt;/p&gt;

&lt;p&gt;There are two main categories of exception:&lt;br/&gt;
1. ProducerFencedException and UnknownProducerIdException . While they reflect different root causes, both of these are expected with EOS enabled, if the producer is silent for too long and ceases to be considered a valid member by the broker. Streams is supposed to handle this situation by rejoining the group (which includes discarding and re-creating its Producers). These were uncovered by repeated rebalances ultimately caused by the injected network partitions.&lt;br/&gt;
2. IllegalStateException. A specific internal assertion revealed buggy store initialization logic. This was also uncovered by repeated rebalances ultimately caused by the injected network partitions.&lt;/p&gt;

&lt;p&gt;I have addressed all of these bugs in my PR &lt;a href=&quot;https://github.com/apache/kafka/pull/7748&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/7748&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I&apos;m proposing to consider this a Blocker for the 2.4.0 release. It is both severe (the exceptions above have reliably caused my Streams cluster to die completely within about 12-24 hours), and it is a regression. &lt;/p&gt;

&lt;p&gt;To determine the latter claim, I ran the exact same workload with the exact same scenario using Kafka Streams 2.3. It should be noted that I still observed threads to die on that branch, but &lt;b&gt;only&lt;/b&gt; due to the UnknownProducerId exception. So, there is some overlap with what I&apos;m seeing on 2.4, but aside from that one cause, the fact that Streams is losing threads at a high rate from both ProducerFencedExceptions and its own internal assertion (IllegalStateException) leads me to think that Streams would be less stable in production using EOS on 2.4 than it was on 2.3.&lt;/p&gt;

&lt;p&gt;For completeness, note that I&apos;ve run the same test on 2.4 and 2.3 &lt;em&gt;without&lt;/em&gt; EOS, and Streams is quite stable. Also note, that the exceptions killing my applications seem to be directly caused by frequent rebalances and network interruptions. For users running EOS Streams in reliable and stable conditions, I do not expect them to suffer thread deaths.&lt;/p&gt;

&lt;p&gt;I know that everyone is waiting for the much-delayed 2.4.0 release, so I&apos;m not taking a hard stance on it, but from where I&apos;m sitting, the situation seems to warrant a new RC once the fix is prepared. Also note, a new RC was just announced this morning, so assuming I can merge my PR on Monday, we&apos;re only setting the release back a couple of extra days.&lt;/p&gt;

&lt;p&gt;Note that we have not previously tested Streams under these conditions, which is why we&apos;re discovering these bugs so late in the game.&lt;/p&gt;</comment>
                            <comment id="16987393" author="githubbot" created="Wed, 4 Dec 2019 00:50:30 +0000"  >&lt;p&gt;vvcephei commented on pull request #7748: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-9231&quot; title=&quot;Streams Threads may die from recoverable errors with EOS enabled&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-9231&quot;&gt;&lt;del&gt;KAFKA-9231&lt;/del&gt;&lt;/a&gt;: Streams Threads may die from recoverable errors with EOS enabled&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/7748&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/7748&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on to GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16987395" author="vvcephei" created="Wed, 4 Dec 2019 00:55:57 +0000"  >&lt;p&gt;Fixed in 2.4 by &lt;a href=&quot;https://github.com/apache/kafka/commit/d7fe494b2a983256092bcc50eac8eab8eb8a6163&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/commit/d7fe494b2a983256092bcc50eac8eab8eb8a6163&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And in trunk by &lt;a href=&quot;https://github.com/apache/kafka/commit/18c13d38ed7090801f125088e3eaec7e3c85c09d&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/commit/18c13d38ed7090801f125088e3eaec7e3c85c09d&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16987992" author="vvcephei" created="Wed, 4 Dec 2019 16:53:11 +0000"  >&lt;p&gt;Opened &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-9268&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/KAFKA-9268&lt;/a&gt; as a follow-on for earlier branches.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10020">
                    <name>Cloners</name>
                                                                <inwardlinks description="is cloned by">
                                        <issuelink>
            <issuekey id="13272285">KAFKA-9268</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13275095">KAFKA-9310</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 49 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0912w:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>