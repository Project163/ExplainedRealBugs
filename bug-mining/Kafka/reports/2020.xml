<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:13:59 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-7301] KTable to KTable join invocation does not resolve in Scala DSL</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-7301</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;I found a peculiar problem while doing KTable to KTable join using Scala DSL. The following code:&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
val t1: KTable[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, Int] = ...
val t2: KTable[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, Int] = ...
val result = t1.join(t2)((x: Int, y: Int) =&amp;gt; x + y)&#160;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;does not compile with &quot;ambiguous reference to overloaded function&quot;.&#160;&lt;/p&gt;

&lt;p&gt;A quick look at the code shows the join functions are defined as follows:&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
def join[VO, VR](other: KTable[K, VO])(
 joiner: (V, VO) =&amp;gt; VR,
 materialized: Materialized[K, VR, ByteArrayKeyValueStore]
)
def join[VO, VR](other: KTable[K, VO])(joiner: (V, VO) =&amp;gt; VR)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;the reason it does not compile is the fact that the first parameter list is identical. For some peculiar reason the KTable class actually compiles...&lt;/p&gt;

&lt;p&gt;The same problem exists for KTable to KTable leftJoin. Other joins (stream-stream, stream-table) do not seem to be affected as there are no overloaded versions of the functions.&lt;/p&gt;

&lt;p&gt;This can be reproduced in smaller scale by some simple scala code:&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
object F {
 &lt;span class=&quot;code-comment&quot;&gt;//def x(a: Int): Int = 5
&lt;/span&gt; &lt;span class=&quot;code-comment&quot;&gt;//def x(a: Int): Int = 6 //obviously does not compile
&lt;/span&gt;
 def f(x: Int)(y: Int): Int = x

 def f(x: Int)(y: Int, z: Int): Int = x
}
val r = F.f(5)(4) &lt;span class=&quot;code-comment&quot;&gt;//Cannot resolve
&lt;/span&gt;val r2 = F.f(5)(4, 6) &lt;span class=&quot;code-comment&quot;&gt;//cannot resolve
&lt;/span&gt;val partial = F.f(5) _ &lt;span class=&quot;code-comment&quot;&gt;//cannot resolve
&lt;/span&gt;
/* you get following error:
Error: ambiguous reference to overloaded definition,
both method f in object F of type (x: Int)(y: Int, z: Int)Int
and method f in object F of type (x: Int)(y: Int)Int
match argument types (Int)
*/&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;The solution: get rid of the multiple parameter lists. I fail to see what practical purpose they serve anyways. I am happy to supply appropriate PR if there is agreement.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13179274">KAFKA-7301</key>
            <summary>KTable to KTable join invocation does not resolve in Scala DSL</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="joan@goyeau.com">Joan Goyeau</assignee>
                                    <reporter username="michald">Michal</reporter>
                        <labels>
                            <label>scala</label>
                    </labels>
                <created>Thu, 16 Aug 2018 07:21:43 +0000</created>
                <updated>Wed, 31 Oct 2018 08:59:14 +0000</updated>
                            <resolved>Tue, 21 Aug 2018 22:42:20 +0000</resolved>
                                    <version>2.0.0</version>
                                    <fixVersion>2.0.1</fixVersion>
                    <fixVersion>2.1.0</fixVersion>
                                    <component>streams</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16582742" author="guozhang" created="Thu, 16 Aug 2018 16:01:17 +0000"  >&lt;p&gt;I think it is being fixed in this PR: &lt;a href=&quot;https://github.com/apache/kafka/pull/5502#issuecomment-413372228&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5502#issuecomment-413372228&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16582747" author="michald" created="Thu, 16 Aug 2018 16:04:45 +0000"  >&lt;p&gt;Awsome&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="16588106" author="githubbot" created="Tue, 21 Aug 2018 22:41:39 +0000"  >&lt;p&gt;guozhangwang closed pull request #5502: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7301&quot; title=&quot;KTable to KTable join invocation does not resolve in Scala DSL&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7301&quot;&gt;&lt;del&gt;KAFKA-7301&lt;/del&gt;&lt;/a&gt;: Fix streams Scala join ambiguous overload&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5502&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5502&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/build.gradle b/build.gradle&lt;br/&gt;
index c1387d4ef60..c963253a8bc 100644&lt;br/&gt;
&amp;#8212; a/build.gradle&lt;br/&gt;
+++ b/build.gradle&lt;br/&gt;
@@ -1021,6 +1021,7 @@ project(&apos;:streams:streams-scala&apos;) {&lt;br/&gt;
     testCompile project(&apos;:core&apos;).sourceSets.test.output&lt;br/&gt;
     testCompile project(&apos;:streams&apos;).sourceSets.test.output&lt;br/&gt;
     testCompile project(&apos;:clients&apos;).sourceSets.test.output&lt;br/&gt;
+    testCompile project(&apos;:streams:test-utils&apos;)&lt;/p&gt;

&lt;p&gt;     testCompile libs.junit&lt;br/&gt;
     testCompile libs.scalatest&lt;br/&gt;
diff --git a/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KTable.scala b/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KTable.scala&lt;br/&gt;
index b66977193e1..a78d321c941 100644&lt;br/&gt;
&amp;#8212; a/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KTable.scala&lt;br/&gt;
+++ b/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KTable.scala&lt;br/&gt;
@@ -20,6 +20,7 @@&lt;br/&gt;
 package org.apache.kafka.streams.scala&lt;br/&gt;
 package kstream&lt;/p&gt;

&lt;p&gt;+import org.apache.kafka.common.serialization.Serde&lt;br/&gt;
 import org.apache.kafka.common.utils.Bytes&lt;br/&gt;
 import org.apache.kafka.streams.kstream.&lt;/p&gt;
{KTable =&amp;gt; KTableJ, _}
&lt;p&gt; import org.apache.kafka.streams.scala.ImplicitConversions._&lt;br/&gt;
@@ -245,9 +246,8 @@ class KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(val inner: KTableJ&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;) {&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;one for each matched record-pair with the same key&lt;/li&gt;
	&lt;li&gt;@see `org.apache.kafka.streams.kstream.KTable#join`&lt;br/&gt;
    */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def join&lt;span class=&quot;error&quot;&gt;&amp;#91;VO, VR&amp;#93;&lt;/span&gt;(other: KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;K, VO&amp;#93;&lt;/span&gt;)(&lt;/li&gt;
	&lt;li&gt;joiner: (V, VO) =&amp;gt; VR,&lt;/li&gt;
	&lt;li&gt;materialized: Materialized&lt;span class=&quot;error&quot;&gt;&amp;#91;K, VR, ByteArrayKeyValueStore&amp;#93;&lt;/span&gt;&lt;br/&gt;
+  def join&lt;span class=&quot;error&quot;&gt;&amp;#91;VO, VR&amp;#93;&lt;/span&gt;(other: KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;K, VO&amp;#93;&lt;/span&gt;, materialized: Materialized&lt;span class=&quot;error&quot;&gt;&amp;#91;K, VR, ByteArrayKeyValueStore&amp;#93;&lt;/span&gt;)(&lt;br/&gt;
+    joiner: (V, VO) =&amp;gt; VR&lt;br/&gt;
   ): KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;K, VR&amp;#93;&lt;/span&gt; =&lt;br/&gt;
     inner.join&lt;span class=&quot;error&quot;&gt;&amp;#91;VO, VR&amp;#93;&lt;/span&gt;(other.inner, joiner.asValueJoiner, materialized)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -274,9 +274,8 @@ class KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(val inner: KTableJ&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;) {&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;one for each matched record-pair with the same key&lt;/li&gt;
	&lt;li&gt;@see `org.apache.kafka.streams.kstream.KTable#leftJoin`&lt;br/&gt;
    */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def leftJoin&lt;span class=&quot;error&quot;&gt;&amp;#91;VO, VR&amp;#93;&lt;/span&gt;(other: KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;K, VO&amp;#93;&lt;/span&gt;)(&lt;/li&gt;
	&lt;li&gt;joiner: (V, VO) =&amp;gt; VR,&lt;/li&gt;
	&lt;li&gt;materialized: Materialized&lt;span class=&quot;error&quot;&gt;&amp;#91;K, VR, ByteArrayKeyValueStore&amp;#93;&lt;/span&gt;&lt;br/&gt;
+  def leftJoin&lt;span class=&quot;error&quot;&gt;&amp;#91;VO, VR&amp;#93;&lt;/span&gt;(other: KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;K, VO&amp;#93;&lt;/span&gt;, materialized: Materialized&lt;span class=&quot;error&quot;&gt;&amp;#91;K, VR, ByteArrayKeyValueStore&amp;#93;&lt;/span&gt;)(&lt;br/&gt;
+    joiner: (V, VO) =&amp;gt; VR&lt;br/&gt;
   ): KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;K, VR&amp;#93;&lt;/span&gt; =&lt;br/&gt;
     inner.leftJoin&lt;span class=&quot;error&quot;&gt;&amp;#91;VO, VR&amp;#93;&lt;/span&gt;(other.inner, joiner.asValueJoiner, materialized)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -303,9 +302,8 @@ class KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(val inner: KTableJ&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;) {&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;one for each matched record-pair with the same key&lt;/li&gt;
	&lt;li&gt;@see `org.apache.kafka.streams.kstream.KTable#leftJoin`&lt;br/&gt;
    */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def outerJoin&lt;span class=&quot;error&quot;&gt;&amp;#91;VO, VR&amp;#93;&lt;/span&gt;(other: KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;K, VO&amp;#93;&lt;/span&gt;)(&lt;/li&gt;
	&lt;li&gt;joiner: (V, VO) =&amp;gt; VR,&lt;/li&gt;
	&lt;li&gt;materialized: Materialized&lt;span class=&quot;error&quot;&gt;&amp;#91;K, VR, ByteArrayKeyValueStore&amp;#93;&lt;/span&gt;&lt;br/&gt;
+  def outerJoin&lt;span class=&quot;error&quot;&gt;&amp;#91;VO, VR&amp;#93;&lt;/span&gt;(other: KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;K, VO&amp;#93;&lt;/span&gt;, materialized: Materialized&lt;span class=&quot;error&quot;&gt;&amp;#91;K, VR, ByteArrayKeyValueStore&amp;#93;&lt;/span&gt;)(&lt;br/&gt;
+    joiner: (V, VO) =&amp;gt; VR&lt;br/&gt;
   ): KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;K, VR&amp;#93;&lt;/span&gt; =&lt;br/&gt;
     inner.outerJoin&lt;span class=&quot;error&quot;&gt;&amp;#91;VO, VR&amp;#93;&lt;/span&gt;(other.inner, joiner.asValueJoiner, materialized)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;diff --git a/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/KStreamTest.scala b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/KStreamTest.scala&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..6a302b207a9&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/KStreamTest.scala&lt;br/&gt;
@@ -0,0 +1,70 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Copyright (C) 2018 Joan Goyeau.&lt;br/&gt;
+ *&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one or more&lt;br/&gt;
+ * contributor license agreements. See the NOTICE file distributed with&lt;br/&gt;
+ * this work for additional information regarding copyright ownership.&lt;br/&gt;
+ * The ASF licenses this file to You under the Apache License, Version 2.0&lt;br/&gt;
+ * (the &quot;License&quot;); you may not use this file except in compliance with&lt;br/&gt;
+ * the License. You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+package org.apache.kafka.streams.scala&lt;br/&gt;
+&lt;br/&gt;
+import org.apache.kafka.streams.kstream.JoinWindows&lt;br/&gt;
+import org.apache.kafka.streams.scala.Serdes._&lt;br/&gt;
+import org.apache.kafka.streams.scala.ImplicitConversions._&lt;br/&gt;
+import org.apache.kafka.streams.scala.utils.TestDriver&lt;br/&gt;
+import org.junit.runner.RunWith&lt;br/&gt;
+import org.scalatest.junit.JUnitRunner&lt;br/&gt;
+import org.scalatest.&lt;/p&gt;
{FlatSpec, Matchers}&lt;br/&gt;
+&lt;br/&gt;
+@RunWith(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;JUnitRunner&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+class KStreamTest extends FlatSpec with Matchers with TestDriver {&lt;br/&gt;
+&lt;br/&gt;
+  &quot;selectKey a KStream&quot; should &quot;select a new key&quot; in {
+    val builder = new StreamsBuilder()
+    val sourceTopic = &quot;source&quot;
+    val sinkTopic = &quot;sink&quot;
+
+    builder.stream[String, String](sourceTopic).selectKey((_, value) =&amp;gt; value).to(sinkTopic)
+
+    val testDriver = createTestDriver(builder)
+
+    testDriver.pipeRecord(sourceTopic, (&quot;1&quot;, &quot;value1&quot;))
+    testDriver.readRecord[String, String](sinkTopic).key shouldBe &quot;value1&quot;
+
+    testDriver.pipeRecord(sourceTopic, (&quot;1&quot;, &quot;value2&quot;))
+    testDriver.readRecord[String, String](sinkTopic).key shouldBe &quot;value2&quot;
+
+    testDriver.close()
+  }&lt;br/&gt;
+&lt;br/&gt;
+  &quot;join 2 KStreams&quot; should &quot;join correctly records&quot; in {
+    val builder = new StreamsBuilder()
+    val sourceTopic1 = &quot;source1&quot;
+    val sourceTopic2 = &quot;source2&quot;
+    val sinkTopic = &quot;sink&quot;
+
+    val stream1 = builder.stream[String, String](sourceTopic1)
+    val stream2 = builder.stream[String, String](sourceTopic2)
+    stream1.join(stream2)((a, b) =&amp;gt; s&quot;$a-$b&quot;, JoinWindows.of(1000)).to(sinkTopic)
+
+    val testDriver = createTestDriver(builder)
+
+    testDriver.pipeRecord(sourceTopic1, (&quot;1&quot;, &quot;topic1value1&quot;))
+    testDriver.pipeRecord(sourceTopic2, (&quot;1&quot;, &quot;topic2value1&quot;))
+    testDriver.readRecord[String, String](sinkTopic).value shouldBe &quot;topic1value1-topic2value1&quot;
+
+    testDriver.readRecord[String, String](sinkTopic) shouldBe null
+
+    testDriver.close()
+  }&lt;br/&gt;
+}&lt;br/&gt;
diff --git a/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/KTableTest.scala b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/KTableTest.scala&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..8c88ff5066f&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/KTableTest.scala&lt;br/&gt;
@@ -0,0 +1,79 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Copyright (C) 2018 Joan Goyeau.&lt;br/&gt;
+ *&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one or more&lt;br/&gt;
+ * contributor license agreements. See the NOTICE file distributed with&lt;br/&gt;
+ * this work for additional information regarding copyright ownership.&lt;br/&gt;
+ * The ASF licenses this file to You under the Apache License, Version 2.0&lt;br/&gt;
+ * (the &quot;License&quot;); you may not use this file except in compliance with&lt;br/&gt;
+ * the License. You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+package org.apache.kafka.streams.scala&lt;br/&gt;
+&lt;br/&gt;
+import org.apache.kafka.streams.kstream.Materialized&lt;br/&gt;
+import org.apache.kafka.streams.scala.ImplicitConversions._&lt;br/&gt;
+import org.apache.kafka.streams.scala.Serdes._&lt;br/&gt;
+import org.apache.kafka.streams.scala.utils.TestDriver&lt;br/&gt;
+import org.junit.runner.RunWith&lt;br/&gt;
+import org.scalatest.junit.JUnitRunner&lt;br/&gt;
+import org.scalatest.{FlatSpec, Matchers}
&lt;p&gt;+&lt;br/&gt;
+@RunWith(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;JUnitRunner&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+class KTableTest extends FlatSpec with Matchers with TestDriver {&lt;br/&gt;
+&lt;br/&gt;
+  &quot;join 2 KTables&quot; should &quot;join correctly records&quot; in &lt;/p&gt;
{
+    val builder = new StreamsBuilder()
+    val sourceTopic1 = &quot;source1&quot;
+    val sourceTopic2 = &quot;source2&quot;
+    val sinkTopic = &quot;sink&quot;
+
+    val table1 = builder.stream[String, String](sourceTopic1).groupBy((key, _) =&amp;gt; key).count()
+    val table2 = builder.stream[String, String](sourceTopic2).groupBy((key, _) =&amp;gt; key).count()
+    table1.join(table2)((a, b) =&amp;gt; a + b).toStream.to(sinkTopic)
+
+    val testDriver = createTestDriver(builder)
+
+    testDriver.pipeRecord(sourceTopic1, (&quot;1&quot;, &quot;topic1value1&quot;))
+    testDriver.pipeRecord(sourceTopic2, (&quot;1&quot;, &quot;topic2value1&quot;))
+    testDriver.readRecord[String, Long](sinkTopic).value shouldBe 2
+
+    testDriver.readRecord[String, Long](sinkTopic) shouldBe null
+
+    testDriver.close()
+  }
&lt;p&gt;+&lt;br/&gt;
+  &quot;join 2 KTables with a Materialized&quot; should &quot;join correctly records and state store&quot; in &lt;/p&gt;
{
+    val builder = new StreamsBuilder()
+    val sourceTopic1 = &quot;source1&quot;
+    val sourceTopic2 = &quot;source2&quot;
+    val sinkTopic = &quot;sink&quot;
+    val stateStore = &quot;store&quot;
+    val materialized = Materialized
+      .as[String, Long, ByteArrayKeyValueStore](stateStore)
+      .withKeySerde(Serdes.String)
+      .withValueSerde(Serdes.Long)
+
+    val table1 = builder.stream[String, String](sourceTopic1).groupBy((key, _) =&amp;gt; key).count()
+    val table2 = builder.stream[String, String](sourceTopic2).groupBy((key, _) =&amp;gt; key).count()
+    table1.join(table2, materialized)((a, b) =&amp;gt; a + b).toStream.to(sinkTopic)
+
+    val testDriver = createTestDriver(builder)
+
+    testDriver.pipeRecord(sourceTopic1, (&quot;1&quot;, &quot;topic1value1&quot;))
+    testDriver.pipeRecord(sourceTopic2, (&quot;1&quot;, &quot;topic2value1&quot;))
+    testDriver.readRecord[String, Long](sinkTopic).value shouldBe 2
+    testDriver.getKeyValueStore[String, Long](stateStore).get(&quot;1&quot;) shouldBe 2
+
+    testDriver.readRecord[String, Long](sinkTopic) shouldBe null
+
+    testDriver.close()
+  }
&lt;p&gt;+}&lt;br/&gt;
diff --git a/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/StreamToTableJoinScalaIntegrationTestImplicitSerdes.scala b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/StreamToTableJoinScalaIntegrationTestImplicitSerdes.scala&lt;br/&gt;
index 3d1bab5d086..fd5f361a5b6 100644&lt;br/&gt;
&amp;#8212; a/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/StreamToTableJoinScalaIntegrationTestImplicitSerdes.scala&lt;br/&gt;
+++ b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/StreamToTableJoinScalaIntegrationTestImplicitSerdes.scala&lt;br/&gt;
@@ -18,20 +18,11 @@ package org.apache.kafka.streams.scala&lt;/p&gt;

&lt;p&gt; import java.util.Properties&lt;/p&gt;

&lt;p&gt;-import org.apache.kafka.clients.consumer.ConsumerConfig&lt;br/&gt;
-import org.apache.kafka.clients.producer.ProducerConfig&lt;br/&gt;
-import org.apache.kafka.common.serialization._&lt;br/&gt;
-import org.apache.kafka.common.utils.MockTime&lt;br/&gt;
 import org.apache.kafka.streams._&lt;br/&gt;
-import org.apache.kafka.streams.integration.utils.&lt;/p&gt;
{EmbeddedKafkaCluster, IntegrationTestUtils}
&lt;p&gt;-import org.apache.kafka.streams.processor.internals.StreamThread&lt;br/&gt;
 import org.apache.kafka.streams.scala.ImplicitConversions._&lt;br/&gt;
 import org.apache.kafka.streams.scala.kstream._&lt;br/&gt;
-import org.apache.kafka.test.TestUtils&lt;br/&gt;
-import org.junit.Assert._&lt;br/&gt;
+import org.apache.kafka.streams.scala.utils.StreamToTableJoinScalaIntegrationTestBase&lt;br/&gt;
 import org.junit._&lt;br/&gt;
-import org.junit.rules.TemporaryFolder&lt;br/&gt;
-import org.scalatest.junit.JUnitSuite&lt;/p&gt;

&lt;p&gt; /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Test suite that does an example to demonstrate stream-table joins in Kafka Streams&lt;br/&gt;
@@ -141,10 +132,7 @@ class StreamToTableJoinScalaIntegrationTestImplicitSerdes extends StreamToTableJ&lt;br/&gt;
     val streams: KafkaStreamsJ = new KafkaStreamsJ(builder.build(), streamsConfiguration)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     streams.start()&lt;br/&gt;
-&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val actualClicksPerRegion: java.util.List[KeyValue&lt;span class=&quot;error&quot;&gt;&amp;#91;String, Long&amp;#93;&lt;/span&gt;] =&lt;/li&gt;
	&lt;li&gt;produceNConsume(userClicksTopicJ, userRegionsTopicJ, outputTopicJ)&lt;br/&gt;
-&lt;br/&gt;
+    produceNConsume(userClicksTopicJ, userRegionsTopicJ, outputTopicJ)&lt;br/&gt;
     streams.close()&lt;br/&gt;
   }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/StreamToTableJoinScalaIntegrationTestBase.scala b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/utils/StreamToTableJoinScalaIntegrationTestBase.scala&lt;br/&gt;
similarity index 99%&lt;br/&gt;
rename from streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/StreamToTableJoinScalaIntegrationTestBase.scala&lt;br/&gt;
rename to streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/utils/StreamToTableJoinScalaIntegrationTestBase.scala&lt;br/&gt;
index cf87eb5e27d..9a3ee7f2794 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/StreamToTableJoinScalaIntegrationTestBase.scala&lt;br/&gt;
+++ b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/utils/StreamToTableJoinScalaIntegrationTestBase.scala&lt;br/&gt;
@@ -14,7 +14,7 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
  */&lt;br/&gt;
-package org.apache.kafka.streams.scala&lt;br/&gt;
+package org.apache.kafka.streams.scala.utils&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import java.util.Properties&lt;/p&gt;

&lt;p&gt;diff --git a/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/StreamToTableJoinTestData.scala b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/utils/StreamToTableJoinTestData.scala&lt;br/&gt;
similarity index 97%&lt;br/&gt;
rename from streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/StreamToTableJoinTestData.scala&lt;br/&gt;
rename to streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/utils/StreamToTableJoinTestData.scala&lt;br/&gt;
index e9040eee5d4..890d8c2ee14 100644&lt;br/&gt;
&amp;#8212; a/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/StreamToTableJoinTestData.scala&lt;br/&gt;
+++ b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/utils/StreamToTableJoinTestData.scala&lt;br/&gt;
@@ -14,7 +14,7 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
  */&lt;br/&gt;
-package org.apache.kafka.streams.scala&lt;br/&gt;
+package org.apache.kafka.streams.scala.utils&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import org.apache.kafka.streams.KeyValue&lt;/p&gt;

&lt;p&gt;diff --git a/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/utils/TestDriver.scala b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/utils/TestDriver.scala&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..1497dd74793&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/utils/TestDriver.scala&lt;br/&gt;
@@ -0,0 +1,52 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Copyright (C) 2018 Joan Goyeau.&lt;br/&gt;
+ *&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one or more&lt;br/&gt;
+ * contributor license agreements. See the NOTICE file distributed with&lt;br/&gt;
+ * this work for additional information regarding copyright ownership.&lt;br/&gt;
+ * The ASF licenses this file to You under the Apache License, Version 2.0&lt;br/&gt;
+ * (the &quot;License&quot;); you may not use this file except in compliance with&lt;br/&gt;
+ * the License. You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+package org.apache.kafka.streams.scala.utils&lt;br/&gt;
+&lt;br/&gt;
+import java.util.&lt;/p&gt;
{Properties, UUID}
&lt;p&gt;+&lt;br/&gt;
+import org.apache.kafka.clients.producer.ProducerRecord&lt;br/&gt;
+import org.apache.kafka.common.serialization.Serde&lt;br/&gt;
+import org.apache.kafka.streams.scala.StreamsBuilder&lt;br/&gt;
+import org.apache.kafka.streams.test.ConsumerRecordFactory&lt;br/&gt;
+import org.apache.kafka.streams.&lt;/p&gt;
{StreamsConfig, TopologyTestDriver}
&lt;p&gt;+import org.scalatest.Suite&lt;br/&gt;
+&lt;br/&gt;
+trait TestDriver { this: Suite =&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+  def createTestDriver(builder: StreamsBuilder, initialWallClockTimeMs: Long = System.currentTimeMillis()) = {&lt;br/&gt;
+    val config = new Properties()&lt;br/&gt;
+    config.put(StreamsConfig.APPLICATION_ID_CONFIG, &quot;test&quot;)&lt;br/&gt;
+    config.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;dummy:1234&quot;)&lt;br/&gt;
+    config.put(StreamsConfig.STATE_DIR_CONFIG, s&quot;out/state-store-${UUID.randomUUID()}&quot;)&lt;br/&gt;
+    new TopologyTestDriver(builder.build(), config, initialWallClockTimeMs)&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  implicit class TopologyTestDriverOps(inner: TopologyTestDriver) {&lt;br/&gt;
+    def pipeRecord&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(topic: String, record: (K, V), timestampMs: Long = System.currentTimeMillis())(&lt;br/&gt;
+      implicit serdeKey: Serde&lt;span class=&quot;error&quot;&gt;&amp;#91;K&amp;#93;&lt;/span&gt;,&lt;br/&gt;
+      serdeValue: Serde&lt;span class=&quot;error&quot;&gt;&amp;#91;V&amp;#93;&lt;/span&gt;&lt;br/&gt;
+    ): Unit = &lt;/p&gt;
{
+      val recordFactory = new ConsumerRecordFactory[K, V](serdeKey.serializer, serdeValue.serializer)
+      inner.pipeInput(recordFactory.create(topic, record._1, record._2, timestampMs))
+    }
&lt;p&gt;+&lt;br/&gt;
+    def readRecord&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(topic: String)(implicit serdeKey: Serde&lt;span class=&quot;error&quot;&gt;&amp;#91;K&amp;#93;&lt;/span&gt;, serdeValue: Serde&lt;span class=&quot;error&quot;&gt;&amp;#91;V&amp;#93;&lt;/span&gt;): ProducerRecord&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt; =&lt;br/&gt;
+      inner.readOutput(topic, serdeKey.deserializer, serdeValue.deserializer)&lt;br/&gt;
+  }&lt;br/&gt;
+}&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 12 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3x3pb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>