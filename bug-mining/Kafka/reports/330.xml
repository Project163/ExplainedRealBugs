<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:38:56 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-937] ConsumerFetcherThread can deadlock</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-937</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;We have the following access pattern that can introduce a deadlock.&lt;/p&gt;

&lt;p&gt;AbstractFetcherThread.processPartitionsWithError() -&amp;gt;&lt;br/&gt;
ConsumerFetcherThread.processPartitionsWithError() -&amp;gt; &lt;br/&gt;
ConsumerFetcherManager.addPartitionsWithError() wait for lock -&amp;gt;&lt;br/&gt;
LeaderFinderThread holding lock while calling AbstractFetcherManager.shutdownIdleFetcherThreads() -&amp;gt;&lt;br/&gt;
AbstractFetcherManager calling fetcher.shutdown, which needs to wait until AbstractFetcherThread.processPartitionsWithError() completes.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12651933">KAFKA-937</key>
            <summary>ConsumerFetcherThread can deadlock</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="junrao">Jun Rao</assignee>
                                    <reporter username="junrao">Jun Rao</reporter>
                        <labels>
                    </labels>
                <created>Sun, 9 Jun 2013 15:25:37 +0000</created>
                <updated>Wed, 4 Sep 2013 03:52:14 +0000</updated>
                            <resolved>Thu, 13 Jun 2013 03:51:15 +0000</resolved>
                                    <version>0.8.0</version>
                                    <fixVersion>0.8.0</fixVersion>
                                    <component>core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="13679091" author="junrao" created="Sun, 9 Jun 2013 15:45:36 +0000"  >&lt;p&gt;Attach a patch. The fix is to make sure that the fetcher thread never gets blocked, no matter what other threads like the LeaderFindThread does. Specifically, LeaderFinderThread no longer holds lock when calling addFetcher() or shudownIdleFetcherThreads(). This way ConsumerFetcherManager.addPartitionsWithError() never gets blocked, which in turn means that the ConsumerFetcherThread never gets blocked and can complete the shutdown if required.&lt;/p&gt;

&lt;p&gt;Double-checked other paths and don&apos;t see any other potential deadlocks.&lt;/p&gt;

&lt;p&gt;Also fixed another potential socket leak through SimpleConsumer. When we shutdown a fetcher, we first interrupt the fetcher thread and close the SimpleConsumer. However, after that, it is possible for the fetcher thread to make another fetch request on SimpleConsumer. This will establish the socket connection again. Add a fix in SimpleConsumer so that after it is closed, no new socket connections will be established and the fetch call will get a ClosedChannelException instead.&lt;/p&gt;</comment>
                            <comment id="13681787" author="jjkoshy" created="Thu, 13 Jun 2013 00:12:34 +0000"  >&lt;p&gt;+1 on the patch.&lt;/p&gt;

&lt;p&gt;Additionally, can you make this small (unrelated change) -  make the console consumer&apos;s autoCommitIntervalOpt default to ConsumerConfig.AutoCommitInterval ?&lt;/p&gt;

&lt;p&gt;I think it is worth documenting the typical path of getting into the above deadlock:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Assume at least two fetchers F1, F2&lt;/li&gt;
	&lt;li&gt;One or more partitions on F1 go into error and leader finder thread L is notified&lt;/li&gt;
	&lt;li&gt;L unblocks and proceeds to handle partitions without leader. It holds the ConsumerFetcherManager&apos;s lock at this point.&lt;/li&gt;
	&lt;li&gt;All partitions on F2 go into error.&lt;/li&gt;
	&lt;li&gt;F2&apos;s handlePartitionsWithError removes partitions from its fetcher&apos;s partitionMap. (At this point, F2 is by definition an idle fetcher thread.)&lt;/li&gt;
	&lt;li&gt;L tries to shutdown idle fetcher threads - i.e., tries to shutdown F2.&lt;/li&gt;
	&lt;li&gt;However, F2 at this point is trying to addPartitionsWithError which needs to acquire the ConsumerFetcherManager&apos;s lock (which is currently held by L).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;It is relatively rare in the sense that it can happen only if all partitions on the fetcher are in error. This could happen for example if all the leaders for those partitions move or become unavailable. Another instance where this may be seen in practice is mirroring: we ran into it when running the mirror maker with a very large number of producers and ran out of file handles. Running out of file handles could easily lead to exceptions on most/all fetches and result in an error state for all partitions.&lt;/p&gt;</comment>
                            <comment id="13681894" author="junrao" created="Thu, 13 Jun 2013 03:51:15 +0000"  >&lt;p&gt;Thanks for the review. Committed to 0.8.&lt;/p&gt;</comment>
                            <comment id="13691691" author="junrao" created="Mon, 24 Jun 2013 03:44:25 +0000"  >&lt;p&gt;Just realize a rare corner case issue. addFetcher() may call ConsumerFetcherThread.handleOffsetOutOfRange() and can get an exception from SimpleConsumer.earliestOrLatestOffset(). In this case, we shouldn&apos;t kill the leaderFinderThread unless it is shut down. Attach a patch.&lt;/p&gt;</comment>
                            <comment id="13691998" author="aozeritsky" created="Mon, 24 Jun 2013 14:12:19 +0000"  >&lt;p&gt;That patch breaks kafka.tools.ConsumerOffsetChecker:&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;2013-06-24 18:11:17,638&amp;#93;&lt;/span&gt; INFO Reconnect due to socket error:  (kafka.consumer.SimpleConsumer)&lt;br/&gt;
java.nio.channels.ClosedChannelException&lt;br/&gt;
        at kafka.network.BlockingChannel.send(BlockingChannel.scala:89)&lt;br/&gt;
        at kafka.consumer.SimpleConsumer.liftedTree1$1(SimpleConsumer.scala:72)&lt;br/&gt;
        at kafka.consumer.SimpleConsumer.kafka$consumer$SimpleConsumer$$sendRequest(SimpleConsumer.scala:71)&lt;br/&gt;
        at kafka.consumer.SimpleConsumer.getOffsetsBefore(SimpleConsumer.scala:125)&lt;br/&gt;
        at kafka.tools.ConsumerOffsetChecker$.kafka$tools$ConsumerOffsetChecker$$processPartition(ConsumerOffsetChecker.scala:72)&lt;br/&gt;
        at kafka.tools.ConsumerOffsetChecker$$anonfun$kafka$tools$ConsumerOffsetChecker$$processTopic$1.apply$mcVI$sp(ConsumerOffsetChecker.scala:90)&lt;br/&gt;
        at kafka.tools.ConsumerOffsetChecker$$anonfun$kafka$tools$ConsumerOffsetChecker$$processTopic$1.apply(ConsumerOffsetChecker.scala:90)&lt;br/&gt;
        at kafka.tools.ConsumerOffsetChecker$$anonfun$kafka$tools$ConsumerOffsetChecker$$processTopic$1.apply(ConsumerOffsetChecker.scala:90)&lt;br/&gt;
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)&lt;br/&gt;
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)&lt;br/&gt;
        at kafka.tools.ConsumerOffsetChecker$.kafka$tools$ConsumerOffsetChecker$$processTopic(ConsumerOffsetChecker.scala:89)&lt;br/&gt;
        at kafka.tools.ConsumerOffsetChecker$$anonfun$main$3.apply(ConsumerOffsetChecker.scala:154)&lt;br/&gt;
        at kafka.tools.ConsumerOffsetChecker$$anonfun$main$3.apply(ConsumerOffsetChecker.scala:154)&lt;br/&gt;
        at scala.collection.immutable.List.foreach(List.scala:318)&lt;br/&gt;
        at kafka.tools.ConsumerOffsetChecker$.main(ConsumerOffsetChecker.scala:153)&lt;br/&gt;
        at kafka.tools.ConsumerOffsetChecker.main(ConsumerOffsetChecker.scala)&lt;/p&gt;</comment>
                            <comment id="13692085" author="junrao" created="Mon, 24 Jun 2013 15:45:08 +0000"  >&lt;p&gt;Alexey,&lt;/p&gt;

&lt;p&gt;This issue seems to be unrelated to this patch. The exception is thrown in SimpleConsumer and this patch doesn&apos;t touch SimpleConsumer. Could you describe how you get to this issue and how reproducible it is?&lt;/p&gt;</comment>
                            <comment id="13692411" author="aozeritsky" created="Mon, 24 Jun 2013 21:35:19 +0000"  >&lt;p&gt;kafka.tools.ConsumerOffsetChecker uses SimpleConsumer for OffsetRequest&lt;/p&gt;

&lt;p&gt;To reproduce just make git pull and run&lt;br/&gt;
bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --group group --zkconnect zk-servers --topic topic&lt;/p&gt;

&lt;p&gt;The problem is in the following diff:&lt;/p&gt;

&lt;p&gt;diff --git a/core/src/main/scala/kafka/consumer/SimpleConsumer.scala b/core/src/main/scala/kafka/consumer/SimpleConsumer.scala&lt;br/&gt;
index bdeee91..1c28328 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/consumer/SimpleConsumer.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/consumer/SimpleConsumer.scala&lt;br/&gt;
@@ -37,6 +37,7 @@ class SimpleConsumer(val host: String,&lt;br/&gt;
   private val blockingChannel = new BlockingChannel(host, port, bufferSize, BlockingChannel.UseDefaultBufferSize, soTimeout)&lt;br/&gt;
   val brokerInfo = &quot;host_%s-port_%s&quot;.format(host, port)&lt;br/&gt;
   private val fetchRequestAndResponseStats = FetchRequestAndResponseStatsRegistry.getFetchRequestAndResponseStats(clientId)&lt;br/&gt;
+  private var isClosed = false&lt;/p&gt;

&lt;p&gt;   private def connect(): BlockingChannel = {&lt;br/&gt;
     close&lt;br/&gt;
@@ -58,7 +59,8 @@ class SimpleConsumer(val host: String,&lt;/p&gt;

&lt;p&gt;   def close() {&lt;br/&gt;
     lock synchronized &lt;/p&gt;
{
-        disconnect()
+      disconnect()
+      isClosed = true
     }
&lt;p&gt;   }&lt;/p&gt;

&lt;p&gt;@@ -123,7 +125,7 @@ class SimpleConsumer(val host: String,&lt;br/&gt;
   def getOffsetsBefore(request: OffsetRequest) = OffsetResponse.readFrom(sendRequest(request).buffer)&lt;/p&gt;

&lt;p&gt;   private def getOrMakeConnection() {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if(!blockingChannel.isConnected) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+    if(!isClosed &amp;amp;&amp;amp; !blockingChannel.isConnected) {
       connect()
     }   }&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;SimpleConsumer stops working after close (ConsumerOffsetChecker.scala, line 77)&lt;/p&gt;</comment>
                            <comment id="13692418" author="aozeritsky" created="Mon, 24 Jun 2013 21:41:50 +0000"  >&lt;p&gt;This patch touches SimpleConsumer.&lt;/p&gt;

&lt;p&gt;proof:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=kafka.git;a=blobdiff;f=core/src/main/scala/kafka/consumer/SimpleConsumer.scala;h=1c283280873eef597018f2f0a5ddfec942356c18;hp=bdeee9174a32a02209d769c18a0337ade0356e99;hb=5bd33c1517bb2e7734166dc3e787ac90a4ef8f86;hpb=640026467cf705fbcf6fd6bcada058b18a95bff5&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=kafka.git;a=blobdiff;f=core/src/main/scala/kafka/consumer/SimpleConsumer.scala;h=1c283280873eef597018f2f0a5ddfec942356c18;hp=bdeee9174a32a02209d769c18a0337ade0356e99;hb=5bd33c1517bb2e7734166dc3e787ac90a4ef8f86;hpb=640026467cf705fbcf6fd6bcada058b18a95bff5&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13692732" author="junrao" created="Tue, 25 Jun 2013 04:26:23 +0000"  >&lt;p&gt;Thanks for reporting this. It is actually a real issue. However, the problem is not because of the change in SimpleConsumer, but in how ConsumerOffsetChecker uses SimpleConsumer. It should only close a SimpleConsumer after it&apos;s no longer needed. Could you try the attached patch?&lt;/p&gt;</comment>
                            <comment id="13692816" author="aozeritsky" created="Tue, 25 Jun 2013 07:43:13 +0000"  >&lt;p&gt;This patch works, thanks.&lt;/p&gt;</comment>
                            <comment id="13693664" author="junrao" created="Wed, 26 Jun 2013 05:49:04 +0000"  >&lt;p&gt;Alexey,&lt;/p&gt;

&lt;p&gt;Thanks for the review. Committed the ConsumerOffsetChecker patch to 0.8.&lt;/p&gt;</comment>
                            <comment id="13756807" author="jjkoshy" created="Tue, 3 Sep 2013 17:28:27 +0000"  >&lt;p&gt;The delta patch slipped through the cracks. We hit that issue recently - a network glitch led to the leader-finder-thread hitting an exception while adding fetchers and the thread quit:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;leader-finder-thread], Error due to 
java.net.ConnectException: Connection timed out
        at sun.nio.ch.Net.connect(Native Method)
        at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:507)
        at kafka.network.BlockingChannel.connect(BlockingChannel.scala:57)
        at kafka.consumer.SimpleConsumer.connect(SimpleConsumer.scala:44)
        at kafka.consumer.SimpleConsumer.getOrMakeConnection(SimpleConsumer.scala:129)
        at kafka.consumer.SimpleConsumer.kafka$consumer$SimpleConsumer$$sendRequest(SimpleConsumer.scala:69)
        at kafka.consumer.SimpleConsumer.getOffsetsBefore(SimpleConsumer.scala:125)
        at kafka.consumer.SimpleConsumer.earliestOrLatestOffset(SimpleConsumer.scala:144)
        at kafka.consumer.ConsumerFetcherThread.handleOffsetOutOfRange(ConsumerFetcherThread.scala:60)
        at kafka.server.AbstractFetcherThread.addPartition(AbstractFetcherThread.scala:180)
        at kafka.server.AbstractFetcherManager.addFetcher(AbstractFetcherManager.scala:80)
        at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread$$anonfun$doWork$7.apply(ConsumerFetcherManager.scala:95)
        at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread$$anonfun$doWork$7.apply(ConsumerFetcherManager.scala:92)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:80)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:80)
        at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:631)
        at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:161)
        at scala.collection.mutable.HashTable$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreachEntry(HashTable.scala:194)
        at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)
        at scala.collection.mutable.HashMap.foreach(HashMap.scala:80)
        at kafka.consumer.ConsumerFetcherManager$LeaderFinderThread.doWork(ConsumerFetcherManager.scala:92)
        at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:51)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;



&lt;p&gt;+1 on kafka-937_delta with one minor comment: change the log to indicate that will attempt to look up the leader again and add fetchers - right now it just says &quot;failed to add&quot;.&lt;/p&gt;</comment>
                            <comment id="13757440" author="junrao" created="Wed, 4 Sep 2013 03:52:14 +0000"  >&lt;p&gt;Thanks for the review. Committed the delta patch to 0.8, after fixing the logging.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12586957" name="kafka-937.patch" size="7701" author="junrao" created="Sun, 9 Jun 2013 15:45:36 +0000"/>
                            <attachment id="12589544" name="kafka-937_ConsumerOffsetChecker.patch" size="1532" author="junrao" created="Tue, 25 Jun 2013 04:26:23 +0000"/>
                            <attachment id="12589364" name="kafka-937_delta.patch" size="1314" author="junrao" created="Mon, 24 Jun 2013 03:44:25 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>332257</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            12 years, 11 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1lbgv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>332586</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>