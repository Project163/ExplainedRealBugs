<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:37:50 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-16277] CooperativeStickyAssignor does not spread topics evenly among consumer group</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-16277</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Consider the following scenario:&lt;/p&gt;

&lt;p&gt;`topic-1`: 12 partitions&lt;/p&gt;

&lt;p&gt;`topic-2`: 12 partitions&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Of note, `topic-1` gets approximately 10 times more messages through it than `topic-2`.&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Both of these topics are consumed by a single application, single consumer group, which scales under load. Each member of the consumer group subscribes to both topics. The `partition.assignment.strategy`&#160;being used is `org.apache.kafka.clients.consumer.CooperativeStickyAssignor`. The application may start with one consumer. It consumes all partitions from both topics.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;The problem begins when the application scales up to two consumers. What is seen is that all partitions from `topic-1` go to one consumer, and all partitions from `topic-2` go to the other consumer. In the case with one topic receiving more messages than the other, this results in a very imbalanced group where one consumer is receiving 10x the traffic of the other due to partition assignment.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;This is the issue being seen in our cluster at the moment. See this graph of the number of messages being processed by each consumer as the group scales from one to four consumers:&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13066871/13066871_image-2024-02-19-13-00-28-306.png&quot; height=&quot;612&quot; width=&quot;537&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Things to note from this graphic:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;With two consumers, the partitions for a topic all go to a single consumer each&lt;/li&gt;
	&lt;li&gt;With three consumers, the partitions for a topic are split between two consumers each&lt;/li&gt;
	&lt;li&gt;With four consumers, the partitions for a topic are split between three consumers each&lt;/li&gt;
	&lt;li&gt;The total number of messages being processed by each consumer in the group is very imbalanced throughout the entire period&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;With regard to the number of &lt;em&gt;partitions&lt;/em&gt; being assigned to each consumer, the group is balanced. However, the assignment appears to be biased so that partitions from the same topic go to the same consumer. In our scenario, this leads to very undesirable partition assignment.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;I question if the behaviour of the assignor should be revised, so that each topic has its partitions maximally spread across all available members of the consumer group. In the above scenario, this would result in much more even distribution of load. The behaviour would then be:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;With two consumers, 6 partitions from each topic go to each consumer&lt;/li&gt;
	&lt;li&gt;With three consumers, 4 partitions from each topic go to each consumer&lt;/li&gt;
	&lt;li&gt;With four consumers, 3 partitions from each topic go to each consumer&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Of note, we only saw this behaviour after migrating to the `CooperativeStickyAssignor`. It was not an issue with the default partition assignment strategy.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;It is possible this may be intended behaviour. In which case, what is the preferred workaround for our scenario? Our current workaround if we decide to go ahead with the update to `CooperativeStickyAssignor` may be to limit our consumers so they only subscribe to one topic, and have two consumer threads per instance of the application.&#160;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13568992">KAFKA-16277</key>
            <summary>CooperativeStickyAssignor does not spread topics evenly among consumer group</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="credpath-seek">Cameron Redpath</assignee>
                                    <reporter username="credpath-seek">Cameron Redpath</reporter>
                        <labels>
                    </labels>
                <created>Mon, 19 Feb 2024 02:41:34 +0000</created>
                <updated>Fri, 14 Mar 2025 01:17:32 +0000</updated>
                            <resolved>Mon, 26 Feb 2024 21:34:04 +0000</resolved>
                                                    <fixVersion>3.7.1</fixVersion>
                    <fixVersion>3.8.0</fixVersion>
                                    <component>clients</component>
                    <component>consumer</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="17818594" author="ableegoldman" created="Mon, 19 Feb 2024 23:36:04 +0000"  >&lt;p&gt;Hey &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=credpath-seek&quot; class=&quot;user-hover&quot; rel=&quot;credpath-seek&quot;&gt;credpath-seek&lt;/a&gt; &#8211; first up, while it&apos;s been a while since I&apos;ve looked at the sticky assignor code, I&apos;m not too surprised that this might be the case. The obvious emphasis (per the name) was put on &quot;stickiness&quot; and partition-number balance, with good data parallelism ie topic-level balance being best-effort at most.&#160;&lt;/p&gt;

&lt;p&gt;That said, I suspect the assignor could be making a better effort. Presumably what is happening is that during the phase where it attempts to re-assign previously-owned partitions back to their former owner, we make a pass over a sorted list of previously-owned partitions that is grouped by topic. The assignor will then assign partitions from this list one-by-one to its previous owner until it hits the expected total number of partitions. So in the scenario you describe, it&apos;s basically looping over (t1p0, t1p1, t1p2, t1p3...t1pN, t2p0, t2p1, t2p2...t2pN) and assigning the first N partitions to the first consumer, which would be everything from topic 1, then just dumping the remaining partitions &#8211; all of which belong to topic 2 &#8211; onto the new consumer.&#160;&lt;/p&gt;

&lt;p&gt;The fix should be fairly simple &#8211; we just need to group this sorted list by partition, rather than by topic (ie t1p0, t2p0, t1p1, t2p1...t1pN, t2pN). Would you be interested in submitting a patch for this?&#160;&lt;/p&gt;

&lt;p&gt;As for what you can do right now: technically even if a fix for this was merged, you&apos;d have to wait for the next release. However, the assignment is technically completely customizable, so in theory you could just copy/paste all the code from the patched assignor into a custom ConsumerPartitionAssignor implementation and then plug that in instead of the &quot;cooperative-sticky&quot; assignment strategy.&lt;/p&gt;

&lt;p&gt;Otherwise, the workaround you suggest is a reasonable backup &#8211; with the obvious downside being that the two threads will have an unbalanced load between them, at least the overall node-level workload will be more even&lt;/p&gt;</comment>
                            <comment id="17819013" author="JIRAUSER304311" created="Tue, 20 Feb 2024 23:39:28 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ableegoldman&quot; class=&quot;user-hover&quot; rel=&quot;ableegoldman&quot;&gt;ableegoldman&lt;/a&gt; for the response - yes we will try to submit a patch soon.&lt;/p&gt;</comment>
                            <comment id="17819877" author="JIRAUSER304311" created="Fri, 23 Feb 2024 02:26:37 +0000"  >&lt;p&gt;We have a PR ready for review with a small change as you suggested, plus updated expected assignment in existing tests&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/kafka/pull/15416&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/15416&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It&apos;s failing CI, but I don&apos;t think it&apos;s related to our changes&lt;/p&gt;</comment>
                            <comment id="17820880" author="ableegoldman" created="Mon, 26 Feb 2024 21:35:25 +0000"  >&lt;p&gt;FYI I added you as a contributor so you should be able to self-assign tickets from now on. Thanks again for contributing a fix!&lt;/p&gt;</comment>
                            <comment id="17821435" author="JIRAUSER304311" created="Tue, 27 Feb 2024 22:12:04 +0000"  >&lt;p&gt;Thanks for the guidance! &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="17934604" author="JIRAUSER308988" created="Wed, 12 Mar 2025 17:10:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=credpath-seek&quot; class=&quot;user-hover&quot; rel=&quot;credpath-seek&quot;&gt;credpath-seek&lt;/a&gt; /&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ableegoldman&quot; class=&quot;user-hover&quot; rel=&quot;ableegoldman&quot;&gt;ableegoldman&lt;/a&gt; I came across a scenario where we see the spread of partitions with topic across consumer threads is uneven. Unlike the above scenario where the partition count was 12 for both the topics, in our case, the topic with high TPS (for ex. 85% traffic) had more partitions compared to the topics with low TPS (for ex. 15% traffic).&#160; The consumer threads had subscribed to both the topics. Subsequently, some of the consumer threads were assigned with the more partitions of low TPS topics. As a result, the pods with the consumer threads that had more partitions of high TPS topics had to slog more resulting in higher lag. However, if we choose round robin, the distribution is even between threads and across pods. But we are limited by the stop the world condition. Any feedback to overcome the above observation while using the cooperative sticky is much appreciated.&lt;/p&gt;</comment>
                            <comment id="17934667" author="JIRAUSER304311" created="Wed, 12 Mar 2025 22:36:15 +0000"  >&lt;p&gt;FYI we ended up rolling back from the CooperativeStickyAssignor for similar issues again, even with both topics having 12 partitions. The consumer group would scale up until the partitions were uneven between consumers, eg to 7/8/9, then when it scaled back down to eg 6/4/3, the assignment was uneven between topics again resulting in lag. We reverted to RangeAssignor.&lt;/p&gt;</comment>
                            <comment id="17935039" author="JIRAUSER308988" created="Thu, 13 Mar 2025 01:47:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=credpath-seek&quot; class=&quot;user-hover&quot; rel=&quot;credpath-seek&quot;&gt;credpath-seek&lt;/a&gt; thanks for info. When you say that consumer group would scale up to 7/8/9, was the even distribution guaranteed then? Because I see that though initial distribution is attempted to be round robin inside the AbstractStickyAssignor, when it eventually retains the partitions with minimum quota, the distribution is not guaranteed.&lt;/p&gt;

&lt;p&gt;Is it that even distribution cannot be achieved alongside stickiness? Do you is it a bug that should be corrected using the cooperative sticky assignor?&lt;/p&gt;</comment>
                            <comment id="17935045" author="JIRAUSER304311" created="Thu, 13 Mar 2025 03:10:16 +0000"  >&lt;p&gt;Given both topics had 12 partitions, even distribution should be possible with 1/2/3/4/6/12 consumers, so yes when it goes to 7/8/9/10/11 consumers, even distribution is impossible. That wasn&apos;t really an issue when there was 7/8/9/10/11 consumers as the difference is smaller, but when you scale back to fewer consumers, the difference is more noticeable as it ends up very imbalanced relatively between topics&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Per Sophie&apos;s comment &quot;emphasis ... was put on &quot;stickiness&quot; and partition-number balance, with good data parallelism ie topic-level balance being best-effort at most&quot; so I think it&apos;s not a priority of this assignor, so maybe not a bug, but could be improved with some effort. Our use case is not too affected by the &quot;stop the world&quot; condition as you put it, so decided to simply go back to what was working for us.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17935048" author="JIRAUSER308988" created="Thu, 13 Mar 2025 03:16:49 +0000"  >&lt;p&gt;thanks for the quick feedback Cameron.&lt;/p&gt;</comment>
                            <comment id="17935391" author="ableegoldman" created="Fri, 14 Mar 2025 01:17:32 +0000"  >&lt;p&gt;I agree it could be better. I see you filed &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-18974&quot; title=&quot;Uneven distribution of topic partitions across consumers while using Cooperative Sticky Assignor&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-18974&quot;&gt;KAFKA-18974&lt;/a&gt; for this issue so we can continue the discussion there&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="13066871" name="image-2024-02-19-13-00-28-306.png" size="295697" author="credpath-seek" created="Mon, 19 Feb 2024 02:00:29 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            34 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1nh2g:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>