<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:35:08 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-306] broker failure system test broken on replication branch</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-306</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;The system test in system_test/broker_failure is broken on the replication branch. This test is a pretty useful failure injection test that exercises the consumer rebalancing feature, various replication features like leader election. It will be good to have this test fixed as well as run on every checkin to the replication branch&lt;/p&gt;</description>
                <environment></environment>
        <key id="12546609">KAFKA-306</key>
            <summary>broker failure system test broken on replication branch</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jfung">John Fung</assignee>
                                    <reporter username="nehanarkhede">Neha Narkhede</reporter>
                        <labels>
                            <label>replication</label>
                    </labels>
                <created>Thu, 15 Mar 2012 16:33:36 +0000</created>
                <updated>Tue, 10 Jul 2012 18:06:45 +0000</updated>
                            <resolved>Tue, 10 Jul 2012 18:06:45 +0000</resolved>
                                    <version>0.8.0</version>
                                    <fixVersion>0.8.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="13231404" author="nehanarkhede" created="Fri, 16 Mar 2012 17:23:14 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-45&quot; title=&quot;Broker startup, leader election, becoming a leader/follower for intra-cluster replication&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-45&quot;&gt;&lt;del&gt;KAFKA-45&lt;/del&gt;&lt;/a&gt; marks the start of server side replication related code changes. I think this test is a pretty good sanity check, if not a complete system testing suite. I would prefer having this fixed before accepting more patches on 0.8 branch. &lt;/p&gt;</comment>
                            <comment id="13285784" author="jfung" created="Wed, 30 May 2012 16:15:09 +0000"  >&lt;p&gt;Broker Failure Test is broken in Kafka 0.8 branch. This patch is fixing the issues and contains the following changes:&lt;br/&gt;
1. All server_*.properties are updated such that the first brokerid is starting from &apos;0&apos;&lt;br/&gt;
2. All mirror_producer*.properties are updated to use zk.connect (and not broker.list)&lt;br/&gt;
3. After the source brokers cluster is started, call kafka.admin.CreateTopicCommand to create topic.&lt;/p&gt;

&lt;p&gt;Currently this patch is working with branch 0.8 (rev. 1342841 patched with &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-46&quot; title=&quot;Commit thread, ReplicaFetcherThread for intra-cluster replication&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-46&quot;&gt;&lt;del&gt;KAFKA-46&lt;/del&gt;&lt;/a&gt;) with the following workarounds:&lt;/p&gt;

&lt;p&gt;1. Before starting the target brokers cluster, start and stop one target broker to eliminate the following error:&lt;br/&gt;
       org.I0Itec.zkclient.exception.ZkNoNodeException: &lt;br/&gt;
       org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /brokers/ids&lt;/p&gt;

&lt;p&gt;2. The argument &quot;--consumer-timeout-ms&quot; doesn&apos;t seem to work properly. The consumer processes will be terminated manually&lt;/p&gt;

&lt;p&gt;3. Consumer Lag info is not available from Zookeeper. Therefore, extra sleep time is added to the test to wait for the complete consumption of messages&lt;/p&gt;

&lt;p&gt;The above issues are being investigated.&lt;/p&gt;</comment>
                            <comment id="13293752" author="junrao" created="Tue, 12 Jun 2012 16:37:58 +0000"  >&lt;p&gt;Sorry, just got to review this. Trunk has moved, could you rebase? &lt;/p&gt;

&lt;p&gt;For 1, do you know the cause of this? Is this a bug? If so, please create a jira.&lt;/p&gt;

&lt;p&gt;For 2,3, we just merged some changes from trunk to 0.8. Could you retry and see if this works now?&lt;/p&gt;</comment>
                            <comment id="13397607" author="jfung" created="Wed, 20 Jun 2012 16:18:21 +0000"  >&lt;p&gt;Uploaded kafka-306-v2.patch for branch 0.8 with the following changes:&lt;/p&gt;

&lt;p&gt;1. Removed the worked around code and comments for NoNodeException (which is not reproducible with the latest 0.8 code).&lt;br/&gt;
2. The script can take a command line argument to bounce any combination of source broker, target broker and mirror maker in a round-robin fashion.&lt;br/&gt;
3. Use &quot;info&quot;, &quot;kill_child_processes&quot; methods from a common script &quot;system_test/common/util.sh&quot;.&lt;br/&gt;
4. Updated README.&lt;/p&gt;</comment>
                            <comment id="13397691" author="junrao" created="Wed, 20 Jun 2012 17:55:45 +0000"  >&lt;p&gt;Thanks for patch v2. Some comments:&lt;/p&gt;

&lt;p&gt;21. run_test.sh&lt;br/&gt;
21.1 Does the following check in start_test() need to be repeated for source, mirror and target, or can we just use 1 check for all 3 cases?&lt;br/&gt;
            if [[ $num_iterations -ge $iter &amp;amp;&amp;amp; $svr_idx -gt 0 ]]; then&lt;br/&gt;
                echo&lt;br/&gt;
                info &quot;==========================================&quot;&lt;br/&gt;
                info &quot;Iteration $iter of ${num_iterations}&quot;&lt;br/&gt;
                info &quot;==========================================&quot;&lt;br/&gt;
21.2 Do we need to sleep for 30s at the end start_test()? Isn&apos;t calling wait_for_zero_consumer_lags enough? Also, the comment says sleep for 10s.&lt;br/&gt;
21.3 In the header, we should add that mirror make can be terminated too.&lt;br/&gt;
21.4 If the test fails, could we generate a list of missing messages in a file? Ideally, messages can just be strings with sequential numbers in them.&lt;/p&gt;

&lt;p&gt;22. The following test seems to fail sometimes.&lt;br/&gt;
bin/run-test.sh 2 23&lt;/p&gt;

&lt;p&gt;23. README: We should add that one needs to do ./sbt package at the root level first.&lt;/p&gt;

</comment>
                            <comment id="13397847" author="jfung" created="Wed, 20 Jun 2012 20:41:01 +0000"  >&lt;p&gt;Uploaded kafka-306-v3.patch with the following changes:&lt;/p&gt;

&lt;p&gt;1. Set the server_source*.properties - log file size to approx 10MB:&lt;br/&gt;
log.file.size=10000000&lt;/p&gt;

&lt;p&gt;2. Set the server_target*.properties - log file size to approx 10MB:&lt;br/&gt;
log.file.size=10000000&lt;/p&gt;</comment>
                            <comment id="13398643" author="jfung" created="Thu, 21 Jun 2012 17:53:22 +0000"  >&lt;p&gt;Hi Jun,&lt;/p&gt;

&lt;p&gt;Thanks for reviewing kafka-306-v2.patch.&lt;/p&gt;

&lt;p&gt;kafka-306-v4.patch is uploaded with the following changes suggested by you:&lt;/p&gt;

&lt;p&gt;21.1 The following check is required for each of the source, target and mirror maker. It is because the following 2 lines are needed for:&lt;br/&gt;
    Line 1: find out if the $bounce_source_id is a char in the string $svr_to_bounce&lt;br/&gt;
    Line 2: check to see if $num_iterations is already reached and if $svr_idx &amp;gt; 0 (meaning this server needs to be bounced)&lt;/p&gt;

&lt;p&gt;    Line 1:        svr_idx=`expr index $svr_to_bounce $bounce_source_id`&lt;br/&gt;
    Line 2:        if [[ $num_iterations -ge $iter &amp;amp;&amp;amp; $svr_idx -gt 0 ]]; then&lt;/p&gt;

&lt;p&gt;21.2 ConsumerOffsetChecker needs to be enhanced for 0.8 and it depends on &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-313&quot; title=&quot;Add JSON/CSV output and looping options to ConsumerGroupCommand&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-313&quot;&gt;KAFKA-313&lt;/a&gt;. &quot;sleep&quot; is temporarily used for kafka to catch up with the offset lags.&lt;/p&gt;

&lt;p&gt;21.3 The header is now updated to &quot;#### Starting Kafka Broker / Mirror Maker Failure Test ####&quot;&lt;/p&gt;

&lt;p&gt;21.4 There is a file &quot;checksum.log&quot; generated at the end of the test which will give the checksums found in producer, source consumer, target consumer logs&lt;/p&gt;

&lt;p&gt;22. You may see inconsistent failure in this test due to the issue specified in &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-370&quot; title=&quot;Exception &amp;quot;java.util.NoSuchElementException: None.get&amp;quot; appears inconsistently in Mirror Maker log.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-370&quot;&gt;&lt;del&gt;KAFKA-370&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;23. README is updated with the steps for ./sbt package&lt;/p&gt;

&lt;p&gt;Thanks,&lt;br/&gt;
John&lt;/p&gt;</comment>
                            <comment id="13399439" author="junrao" created="Fri, 22 Jun 2012 16:58:54 +0000"  >&lt;p&gt;Thanks for patch v4. A few more comments:&lt;/p&gt;

&lt;p&gt;21.2 KAFA-313 adds 2 more options, which option does this jira depends on?&lt;/p&gt;

&lt;p&gt;21.3 I meant that we should add mirror maker in the following line in the header:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;5. One of the Kafka SOURCE or TARGET brokers in the cluster will&lt;/li&gt;
	&lt;li&gt;be randomly terminated and waiting for the consumer to catch up.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;21.4 Instead of using checksum, can we use the message string itself? This makes it a bit easier to figure out the missing messages, if any.&lt;/p&gt;

&lt;p&gt;22. Just attached a patch to kafka-370. Could you give it a try?&lt;/p&gt;</comment>
                            <comment id="13402568" author="jfung" created="Wed, 27 Jun 2012 21:28:39 +0000"  >&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;In replying to Jun&apos;s question about &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-313&quot; title=&quot;Add JSON/CSV output and looping options to ConsumerGroupCommand&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-313&quot;&gt;KAFKA-313&lt;/a&gt;: in this script, the function &quot;wait_for_zero_consumer_lag&quot; is calling ConsumerOffsetChecker to get the Consumer lag value. However, the topic-partition info is changed in 0.8 and it&apos;s not returned correctly in ConsumerOffsetChecker. Please refer to this comment: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-313?focusedCommentId=13397990&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13397990&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/KAFKA-313?focusedCommentId=13397990&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13397990&lt;/a&gt;&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;Uploaded kafka-306-v5.patch. Changes made in kafka-306-v5.patch:&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;1. In &quot;initialize&quot; function, added code to find the location of the zk &amp;amp; kafka log4j log files.&lt;/p&gt;

&lt;p&gt;2. In &quot;cleanup&quot; function, added code to remove the zk &amp;amp; kafka log4j log files&lt;/p&gt;

&lt;p&gt;3. The header of the script is now removed and the description are in README&lt;/p&gt;

&lt;p&gt;4. Use getopt to process command line arguments&lt;/p&gt;

&lt;p&gt;5. Consolidated the following functions:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;start_console_consumer_for_source_producer&lt;/li&gt;
	&lt;li&gt;start_console_consumer_for_mirror_producer&lt;/li&gt;
	&lt;li&gt;wait_for_zero_source_console_consumer_lags&lt;/li&gt;
	&lt;li&gt;wait_for_zero_mirror_console_consumer_lags&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;6. The file to notify producer to stop:&lt;br/&gt;
The producer is sent to the background to run in a while-loop. If a file is used to notify the producer process in the background, the producer will exit properly inside the while loop.&lt;/p&gt;

&lt;p&gt;7. The following check is required for each of the source, target and mirror maker. It is because the following 2 lines are needed for:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Line 1: find out if the $bounce_source_id is a char in the string $svr_to_bounce&lt;/li&gt;
	&lt;li&gt;Line 2: check to see if $num_iterations is already reached and if $svr_idx &amp;gt; 0 (meaning this server needs to be bounced)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Line 1: svr_idx=`expr index $svr_to_bounce $bounce_source_id`&lt;/li&gt;
	&lt;li&gt;Line 2: if [[ $num_iterations -ge $iter &amp;amp;&amp;amp; $svr_idx -gt 0 ]]; then&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13406067" author="jfung" created="Tue, 3 Jul 2012 21:31:57 +0000"  >&lt;p&gt;Uploaded kafka-306-v6.patch and made further changes in ProducerPerformance and ConsoleConsumer to support producing sequential message IDs such that it would be easier to troubleshoot data loss.&lt;/p&gt;

&lt;p&gt;ProducerPerformance.scala&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Added command line option &quot;--seq-id-starting-from&quot;. This option enable &quot;seqIdMode&quot; with the following changes:&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Every message will be tagged with a sequential message ID such that all IDs are unique&lt;/li&gt;
	&lt;li&gt;Every message will be sent by its own producer thread sequentially&lt;/li&gt;
	&lt;li&gt;Each producer thread will use a unique range of numbers to give sequential message IDs&lt;/li&gt;
	&lt;li&gt;All message IDs are leftpadded with 0s for easier troubleshooting&lt;/li&gt;
	&lt;li&gt;Extra characters are added to the message to make up the required message size&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;ConsoleConsumer.scala&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Added DecodedMessageFormatter class to display message contents&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;run-test.sh&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Modified to use the enhanced ProducerPerformance and ConsoleConsumer&lt;/li&gt;
	&lt;li&gt;Validate &quot;MessageID&quot; instead of &quot;checksum&quot; for data matching between source and target consumers&lt;/li&gt;
&lt;/ul&gt;

</comment>
                            <comment id="13406230" author="jjkoshy" created="Wed, 4 Jul 2012 01:45:37 +0000"  >&lt;p&gt;John, thanks for the patch. The test script itself looks good - as we&lt;br/&gt;
discussed on the other jira we can do further cleanup separately. Here are&lt;br/&gt;
some comments on the new changes:&lt;/p&gt;

&lt;p&gt;ProducerPerformance:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;seqIdStartFromopt -&amp;gt; startId or initialId would be more&lt;br/&gt;
  convenient/intuitive.&lt;/li&gt;
	&lt;li&gt;May be better not to describe the message format in detail in the help&lt;br/&gt;
  message. I think the template: &quot;Message:000..1:xxx...&quot; is good enough.&lt;/li&gt;
	&lt;li&gt;On line 136, 137 I think you mean if (options.has) and not&lt;br/&gt;
  if(!options.has) - something odd there. Can you double-check?&lt;/li&gt;
	&lt;li&gt;Try to avoid using vars if possible. vals are generally clearer and safer&lt;/li&gt;
	&lt;li&gt;for example,&lt;br/&gt;
  val isFixSize = options.has(seqIdStartFromOpt) || !options.has(varyMessageSizeOpt)&lt;br/&gt;
  val numThreads = if (options.has(seqIdStartFromOpt)) 1 else options.valueOf(numThreadsOpt).intValue()&lt;br/&gt;
  etc.&lt;/li&gt;
	&lt;li&gt;For user-specified options that you override can you log a warning?&lt;/li&gt;
	&lt;li&gt;Instead of the complicated padding logic I think you can get it for free&lt;br/&gt;
  with Java format strings - i.e., specify the width/justification of each&lt;br/&gt;
  column in the format string. That would be much easier I think.&lt;/li&gt;
	&lt;li&gt;numThreads override to 1 -&amp;gt; did it work to prefix the id with thread-id&lt;br/&gt;
  and allow &amp;gt; 1 thread?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Server property files:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;send/receive.buffer.size don&apos;t seem to be valid config options - may be&lt;br/&gt;
  deprecated by the socket buffer size settings, but not sure.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Util functions:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Small suggestion: would be better to echo the result than return. So you&lt;br/&gt;
  can have: idx=$(get_random_range ...) which is clearer than&lt;br/&gt;
  get_random_range; idx=$? . Also, non-zero bash returns typically indicate&lt;br/&gt;
  an error.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13407574" author="jfung" created="Thu, 5 Jul 2012 23:00:37 +0000"  >&lt;p&gt;Hi Joel,&lt;/p&gt;

&lt;p&gt;Thanks for reviewing. I just uploaded kafka-306-v7.patch with the changes you suggested:&lt;/p&gt;

&lt;p&gt;ProducerPerformance&lt;br/&gt;
===================&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;seqIdStartFromopt -&amp;gt; startId or initialId would be more convenient/intuitive.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Changed&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;May be better not to describe the message format in detail in the help message. I think the template: &quot;Message:000..1:xxx...&quot; is good enough.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Changed&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;On line 136, 137 I think you mean if (options.has) and not if(!options.has) - something odd there. Can you double-check?&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;In &quot;seqIdMode&quot;, if &quot;numThreadsOpt&quot; is not specified, numThreads default to 1. Otherwise, it will take the user specified value&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Try to avoid using vars if possible. vals are generally clearer and safer, for example,&lt;br/&gt;
  val isFixSize = options.has(seqIdStartFromOpt) || !options.has(varyMessageSizeOpt)&lt;br/&gt;
  val numThreads = if (options.has(seqIdStartFromOpt)) 1 else options.valueOf(numThreadsOpt).intValue()&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;This is because the values may be overridden later by user specified values. Therefore, some of the val is changed to var&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;For user-specified options that you override can you log a warning?&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Changed&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Instead of the complicated padding logic I think you can get it for free with Java format strings - i.e., specify the width/justification of each column in the format string. That would be much easier I think.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Changed&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;numThreads override to 1 -&amp;gt; did it work to prefix the id with thread-id and allow &amp;gt; 1 thread?&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;numThreads will be overridden if &quot;--threads&quot; is specified in command line arg&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Server property files&lt;br/&gt;
=====================&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;send/receive.buffer.size don&apos;t seem to be valid config options - may be deprecated by the socket buffer size settings, but not sure.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Changed&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Util functions&lt;br/&gt;
==============&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Small suggestion: would be better to echo the result than return.&lt;br/&gt;
So you can have: idx=$(get_random_range ...) which is clearer than get_random_range; idx=$? .&lt;br/&gt;
Also, non-zero bash returns typically indicate an error.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Changed&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13408262" author="jfung" created="Fri, 6 Jul 2012 19:56:40 +0000"  >&lt;p&gt;Uploaded kafka-306-v8.patch.&lt;/p&gt;

&lt;p&gt;The changes made in the previous patch (kafka-306-v7.patch) will break single_host_multi_brokers/bin/run-test.sh due to the fact that ProducerPerformance will no longer print the message checksum.&lt;/p&gt;

&lt;p&gt;The changes made in this patch supports single_host_multi_brokers/bin/run-test.sh to make use of the sequential message ID for test results validation.&lt;/p&gt;</comment>
                            <comment id="13408271" author="jjkoshy" created="Fri, 6 Jul 2012 20:08:31 +0000"  >&lt;p&gt;Thanks for making the changes - looks better.&lt;/p&gt;

&lt;p&gt;&amp;gt; - This is because the values may be overridden later by user specified&lt;br/&gt;
&amp;gt; values. Therefore, some of the val is changed to var &lt;/p&gt;

&lt;p&gt;I meant even with overrides I don&apos;t think you need these vars and they can &lt;br/&gt;
be handled better with vals. However, it&apos;s a minor issue and looking at&lt;br/&gt;
ProducerPerformance it seems it needs an overhaul - the main loop is pretty hard to &lt;br/&gt;
read. We should probably do that in a separate jira as it isn&apos;t directly&lt;br/&gt;
related to this one.&lt;/p&gt;

&lt;p&gt;BTW, it seems bytesSent is not updated in seqIdMode.&lt;/p&gt;</comment>
                            <comment id="13409985" author="junrao" created="Tue, 10 Jul 2012 00:43:42 +0000"  >&lt;p&gt;Patch v8 looks good overall. Some minor comments on ProducerPerformance:&lt;/p&gt;

&lt;p&gt;81. Could we default numThreadsOpt to 1? Then we can get rid of the following override.&lt;/p&gt;

&lt;p&gt;      if (!options.has(numThreadsOpt)) &lt;/p&gt;
{ 
        numThreads = 1 
        warn(&quot;seqIdMode - numThreads is overridden to: &quot; + numThreads)
      }

&lt;p&gt;82. Could we replace the following code&lt;br/&gt;
            if (config.seqIdMode) &lt;/p&gt;
{
              producer.send(new ProducerData[Message,Message](config.topic, null, message))
            }
&lt;p&gt;            else if(!config.isFixSize) {&lt;br/&gt;
     with&lt;br/&gt;
            if(!config.isFixSize || !config.seqIdMode) {&lt;/p&gt;</comment>
                            <comment id="13410530" author="jfung" created="Tue, 10 Jul 2012 16:54:14 +0000"  >&lt;p&gt;Thanks Jun for reviewing. Your suggestion are made in kafka-306-v9.patch.&lt;/p&gt;

&lt;p&gt;The changes are:&lt;br/&gt;
91. numThreadsOpt is defaulted to 1 and the &apos;if&apos; block is removed&lt;/p&gt;

&lt;p&gt;92. The following block is actually not necessary and it&apos;s now removed:&lt;br/&gt;
          if (config.seqIdMode) &lt;/p&gt;
{ 
              producer.send(new ProducerData[Message,Message](config.topic, null, message)) 
            }
&lt;p&gt; &lt;/p&gt;</comment>
                            <comment id="13410642" author="junrao" created="Tue, 10 Jul 2012 18:06:45 +0000"  >&lt;p&gt;John, thanks for patch v9. Removed the commented out code in ProducerPerformance and committed to 0.8.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="12514682">KAFKA-45</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12530225" name="kafka-306-v1.patch" size="13210" author="jfung" created="Wed, 30 May 2012 16:15:09 +0000"/>
                            <attachment id="12532716" name="kafka-306-v2.patch" size="49107" author="jfung" created="Wed, 20 Jun 2012 16:18:21 +0000"/>
                            <attachment id="12532759" name="kafka-306-v3.patch" size="52725" author="jfung" created="Wed, 20 Jun 2012 20:41:01 +0000"/>
                            <attachment id="12532912" name="kafka-306-v4.patch" size="54646" author="jfung" created="Thu, 21 Jun 2012 17:53:22 +0000"/>
                            <attachment id="12533709" name="kafka-306-v5.patch" size="55826" author="jfung" created="Wed, 27 Jun 2012 21:28:39 +0000"/>
                            <attachment id="12534985" name="kafka-306-v6.patch" size="65279" author="jfung" created="Tue, 3 Jul 2012 21:31:56 +0000"/>
                            <attachment id="12535280" name="kafka-306-v7.patch" size="67098" author="jfung" created="Thu, 5 Jul 2012 23:00:37 +0000"/>
                            <attachment id="12535410" name="kafka-306-v8.patch" size="73628" author="jfung" created="Fri, 6 Jul 2012 19:56:40 +0000"/>
                            <attachment id="12535871" name="kafka-306-v9.patch" size="73776" author="jfung" created="Tue, 10 Jul 2012 16:54:14 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>231767</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            13 years, 19 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i029n3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>11163</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>