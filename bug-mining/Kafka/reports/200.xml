<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:37:15 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-749] Bug in socket server shutdown logic makes the broker hang on shutdown until it has to be killed</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-749</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;The current shutdown logic of the server shuts down the io threads first, followed by acceptor and finally processor threads. The shutdown API of io threads enqueues a special AllDone command into the common request queue. It shuts down the io thread when it dequeues this special all done command. What can happen is that while this shutdown command processing is happening on the io threads, the network/processor threads can still accept new connections and requests and will add those new requests to the request queue. That means, more requests can be enqueued after the AllDone command. What happens is that after the io threads have shutdown, there is no thread available to dequeue from the request queue. So the processor threads can hang while adding new requests to a full request queue, thereby blocking the server from shutting down.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12630779">KAFKA-749</key>
            <summary>Bug in socket server shutdown logic makes the broker hang on shutdown until it has to be killed</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="nehanarkhede">Neha Narkhede</assignee>
                                    <reporter username="nehanarkhede">Neha Narkhede</reporter>
                        <labels>
                            <label>bugs</label>
                            <label>p1</label>
                    </labels>
                <created>Mon, 4 Feb 2013 23:14:03 +0000</created>
                <updated>Wed, 6 Feb 2013 04:11:27 +0000</updated>
                            <resolved>Wed, 6 Feb 2013 04:11:24 +0000</resolved>
                                    <version>0.8.0</version>
                                                    <component>network</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                    <workratio workratioPercent="0"/>
                                    <progress percentage="0">
                                    <originalProgress>
                                                    <row percentage="100" backgroundColor="#89afd7"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="0" backgroundColor="#51a825"/>
                                                    <row percentage="100" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="0">
                                    <originalProgress>
                                                    <row percentage="100" backgroundColor="#89afd7"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="0" backgroundColor="#51a825"/>
                                                    <row percentage="100" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                    <timeoriginalestimate seconds="86400">24h</timeoriginalestimate>
                            <timeestimate seconds="86400">24h</timeestimate>
                                        <comments>
                            <comment id="13570822" author="nehanarkhede" created="Tue, 5 Feb 2013 01:09:06 +0000"  >&lt;p&gt;Bug fix includes the following changes -&lt;/p&gt;

&lt;p&gt;1. KafkaRequestHandler&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Removed AllDone, instead the shutdown() command will set isRunning to false and wait for the request handler thread to finish processing existing request and then stop&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;2. RequestChannel&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Modified receiveRequest to wait on a condition variable if the queue is empty. The purpose is to introduce a clean way to wake it up when it is time to shutdown.&lt;/li&gt;
	&lt;li&gt;Added a close() API that will set isShuttingDown to true and signal the condition so all io threads waiting to receiveRequest() will return null&lt;/li&gt;
	&lt;li&gt;Did not clear the queue since the io threads shutdown after the socket server. If we clear the queue, all io threads will try to get the next request and will get null until it shuts down. This time period should hopefully be very short, but it is still inefficient. This is ok for the io thread shutdown logic since it will just process one request before it shuts down as well. So its ok to not clear the queue.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;3. SocketServer&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Invoke close on request channel after the acceptor and processor threads are shutdown&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;4. KafkaServer&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Shutdown the socket server before the request handler. This ensures we don&apos;t accept and enqueue more requests that will timeout anyway.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13571067" author="sriramsub" created="Tue, 5 Feb 2013 05:43:05 +0000"  >&lt;p&gt;Took a look at this. &lt;/p&gt;

&lt;p&gt;1. This adds another layer of locking to the Request queue which in itself is a Blocking queue implementation. This does not seem very efficient. Either we implement our blocking queue or use the api.&lt;br/&gt;
2. Having said that, it seems a lot easier to just purge the queue. Is this not an option? &lt;br/&gt;
3. If 2 is not possible, a more elegant way is to use the poison pill approach. We shutdown the socket server, and enqueue a shutdown request to the queue. Each request handler thread dequeues the request, checks it is is shutdown request, if so re-queues it and exits.&lt;/p&gt;</comment>
                            <comment id="13571071" author="jkreps" created="Tue, 5 Feb 2013 05:56:02 +0000"  >&lt;p&gt;The ugly part here is the extra layer of synchronization and signally around the already synchronized blocking queue. This code is a bit hard to validate (for example shouldn&apos;t it be signal instead of signalAll--since only one thing was added?) so it tends to quickly get broken by later people who don&apos;t understand it.&lt;/p&gt;

&lt;p&gt;I think I don&apos;t quite understand why we can&apos;t just call clear on the queue and enqueue the AllDone object to achieve this. The uglinesses of the previous implementation where that AllDone actually came out of the RequestChannel and that it was a ProducerRequest. This is easily fixed. There is no reason it should be a Producer request, and the check for eq AllDone can be done in receiveRequest.&lt;/p&gt;</comment>
                            <comment id="13571074" author="nehanarkhede" created="Tue, 5 Feb 2013 06:02:16 +0000"  >&lt;p&gt;The only problem with the AllDone approach is that we need to ensure that the request queue size is atleast as big as the number of io threads we have. If it is less than that, we have the same problem where shutdown will hang.&lt;/p&gt;</comment>
                            <comment id="13571353" author="jkreps" created="Tue, 5 Feb 2013 14:46:13 +0000"  >&lt;p&gt;So what if we just do&lt;/p&gt;

&lt;p&gt;while(true) {&lt;br/&gt;
  queue.clear()&lt;br/&gt;
  queue.offer(AllDone)&lt;br/&gt;
  return&lt;br/&gt;
}&lt;/p&gt;</comment>
                            <comment id="13571355" author="jkreps" created="Tue, 5 Feb 2013 14:46:55 +0000"  >&lt;p&gt;Err, should be&lt;/p&gt;

&lt;p&gt;while(true) {&lt;br/&gt;
  queue.clear()&lt;br/&gt;
  if(queue.offer(AllDone))&lt;br/&gt;
    return&lt;br/&gt;
}&lt;/p&gt;</comment>
                            <comment id="13571425" author="nehanarkhede" created="Tue, 5 Feb 2013 16:21:35 +0000"  >&lt;p&gt;Is this the logic for the shutdown() API in KafkaRequestHandler ? If yes, then I don&apos;t think we can keep clearing the queue in a loop. What can happen is that AllDone requests for the rest of the request handlers might still be in the queue. If we clear those, then request handlers won&apos;t shutdown and some of the request handlers will just busy wait trying to clear and offer AllDone in a loop.&lt;/p&gt;

&lt;p&gt;I&apos;m thinking an easier solution might be to just require the request queue size as large as the number of io threads. This makes sense so that io threads are never underutilized and there is space for one request per io thread in the request queue. Thoughts ?&lt;/p&gt;</comment>
                            <comment id="13571505" author="jkreps" created="Tue, 5 Feb 2013 17:48:36 +0000"  >&lt;p&gt;That makes sense, good solution.&lt;/p&gt;</comment>
                            <comment id="13571511" author="sriramsub" created="Tue, 5 Feb 2013 17:56:18 +0000"  >&lt;p&gt;If that works fine. But it looks like there really is a solution that does not need any constraints. &lt;/p&gt;

&lt;p&gt;1. SocketServer on shutdown closes the acceptor and processor threads. It can then add a alldone request to the queue.&lt;br/&gt;
2. Each requesthandler thread just dequeues from the request queue. If it is alldone, it just re-enqueues it and exits.&lt;br/&gt;
3. requesthandler shutdown just waits for all threads to exit (this is same as today).&lt;/p&gt;

&lt;p&gt;Will this not work? &lt;/p&gt;</comment>
                            <comment id="13571517" author="nehanarkhede" created="Tue, 5 Feb 2013 18:02:59 +0000"  >&lt;p&gt;Thanks for the review ! I think I was over thinking the issue of request queue size having to be larger than io threads. Even if  it is smaller, some io thread&apos;s shutdown will wait for some space to free up. Space will free up since some other io thread will dequeue the AllDone command. &lt;/p&gt;

&lt;p&gt;This patch is very simple. It changed the shutdown logic of the Kafka server to go through following steps -&lt;br/&gt;
1. Shutdown acceptor, so no new connections are accepted&lt;br/&gt;
2. Shutdown processor threads, they will enqueue the currently selected keys&apos; requests in the request queue. This is fine since io threads are alive and will dequeue requests. So this step will not block&lt;br/&gt;
3. Request channel shutdown will clear the queue. At this time, no thread is enqueuing more data. IO threads trying to dequeue data will hang on the receiveRequest&lt;br/&gt;
4. Shutdown io threads, this will enqueue AllDone command in the queue. And all io threads will shutdown one after the other. Even if the request queue is smaller than # of io threads, it will eventually shutdown&lt;/p&gt;
</comment>
                            <comment id="13571520" author="nehanarkhede" created="Tue, 5 Feb 2013 18:07:48 +0000"  >&lt;p&gt;Sriram, That is what I had described in my simpler solution and is what patch v2 does.&lt;/p&gt;</comment>
                            <comment id="13571527" author="sriramsub" created="Tue, 5 Feb 2013 18:12:26 +0000"  >&lt;p&gt;Awesome. looks good to me. Nit - are we planning to fix getShutdownReceive to not use produceRequest as part of this patch or is that a separate jira?&lt;/p&gt;</comment>
                            <comment id="13571535" author="nehanarkhede" created="Tue, 5 Feb 2013 18:19:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-745&quot; title=&quot;Remove getShutdownReceive() and other kafka specific code from the RequestChannel&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-745&quot;&gt;&lt;del&gt;KAFKA-745&lt;/del&gt;&lt;/a&gt; is filed for that. I prefer to not touch it here, it is a much bigger change&lt;/p&gt;</comment>
                            <comment id="13571578" author="jkreps" created="Tue, 5 Feb 2013 18:52:16 +0000"  >&lt;p&gt;Why is that a big change?&lt;/p&gt;</comment>
                            <comment id="13571585" author="jkreps" created="Tue, 5 Feb 2013 18:55:09 +0000"  >&lt;p&gt;Also, not sure if I get it. If the I/O threads are able to make progress and the response queue is unlimited in size then shouldn&apos;t requestQueue.put always succeed eventually? Even if the queue is currently full some requests will get processed and free up some space...?&lt;/p&gt;</comment>
                            <comment id="13571625" author="nehanarkhede" created="Tue, 5 Feb 2013 19:19:45 +0000"  >&lt;p&gt;That is correct. Also, removing the getShutdownReceive() is part of the refactoring in &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-745&quot; title=&quot;Remove getShutdownReceive() and other kafka specific code from the RequestChannel&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-745&quot;&gt;&lt;del&gt;KAFKA-745&lt;/del&gt;&lt;/a&gt;. This patch includes the bug fix itself, I would prefer not to extend the scope of this bug fix. &lt;/p&gt;</comment>
                            <comment id="13572131" author="nehanarkhede" created="Wed, 6 Feb 2013 04:11:24 +0000"  >&lt;p&gt;Thanks for the reviews, checked in patch v2&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12567920" name="kafka-749-v1.patch" size="7089" author="nehanarkhede" created="Tue, 5 Feb 2013 01:09:06 +0000"/>
                            <attachment id="12568043" name="kafka-749-v2.patch" size="2807" author="nehanarkhede" created="Tue, 5 Feb 2013 18:02:59 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>311275</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            12 years, 41 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1hpvz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>311621</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>