<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:56:08 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-4099] Change the time based log rolling to only based on the message timestamp.</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-4099</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;This is an issue introduced in &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3163&quot; title=&quot;KIP-33 - Add a time based log index to Kafka&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3163&quot;&gt;&lt;del&gt;KAFKA-3163&lt;/del&gt;&lt;/a&gt;. When partition relocation occurs, the newly created replica may have messages with old timestamp and cause the log segment rolling for each message. The fix is to change the log rolling behavior to only based on the message timestamp when the messages are in message format 0.10.0 or above. If the first message in the segment does not have a timetamp, we will fall back to use the wall clock time for log rolling.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13001110">KAFKA-4099</key>
            <summary>Change the time based log rolling to only based on the message timestamp.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="becket_qin">Jiangjie Qin</assignee>
                                    <reporter username="becket_qin">Jiangjie Qin</reporter>
                        <labels>
                    </labels>
                <created>Mon, 29 Aug 2016 20:44:25 +0000</created>
                <updated>Tue, 25 Oct 2016 01:40:08 +0000</updated>
                            <resolved>Fri, 2 Sep 2016 19:49:55 +0000</resolved>
                                                    <fixVersion>0.10.1.0</fixVersion>
                                    <component>core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="15447253" author="becket_qin" created="Mon, 29 Aug 2016 22:27:51 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt; I am thinking about this solution. It seems still not ideal. For some low volume topics, if we roll the log based on the segment create time, during partition relocation, we may keep the sensitive data for much longer than we wanted to - because all the data may be end up in the same segment and the old data cannot be deleted because they are still with the new data.&lt;/p&gt;

&lt;p&gt;It seems the root cause of the unnecessary log rolling is that we are comparing the timestamp in the message and the wall clock time. This caused the log rolling to become wall clock time sensitive. I am thinking may be we should always use the timestamp in the message. i.e. we roll out the log segment if the timestamp in the current message is greater than the timestamp of the first message in the segment by more than log.roll.ms. This approach is wall clock independent and should solve the problem. With message.timestamp.difference.max.ms configuration, we can achieve 1) the log segment will be rolled out in a bounded time, 2) no excessively large timestamp will be accepted and cause frequent log rolling.&lt;/p&gt;

&lt;p&gt;What do you think?&lt;/p&gt;</comment>
                            <comment id="15450166" author="becket_qin" created="Tue, 30 Aug 2016 21:11:16 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt; Any thoughts? Thanks.&lt;/p&gt;</comment>
                            <comment id="15450309" author="junrao" created="Tue, 30 Aug 2016 22:18:33 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=becket_qin&quot; class=&quot;user-hover&quot; rel=&quot;becket_qin&quot;&gt;becket_qin&lt;/a&gt;, thanks for the proposal. Your suggestion sounds reasonable to me. It should cover the common usage of log based rolling. One case that this doesn&apos;t quite cover is that if the timestamp of the first message is large and a message with a much smaller timestamp shows up later. In this case, the rolling of the segment may not be quick enough. However, that should be rare. So, could you email the KIP mailing thread about this change and provide a patch?&lt;/p&gt;</comment>
                            <comment id="15454198" author="githubbot" created="Thu, 1 Sep 2016 03:44:53 +0000"  >&lt;p&gt;GitHub user becketqin opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1809&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1809&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-4099&quot; title=&quot;Change the time based log rolling to only based on the message timestamp.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-4099&quot;&gt;&lt;del&gt;KAFKA-4099&lt;/del&gt;&lt;/a&gt;: Fix the potential frequent log rolling&lt;/p&gt;



&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/becketqin/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/becketqin/kafka&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-4099&quot; title=&quot;Change the time based log rolling to only based on the message timestamp.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-4099&quot;&gt;&lt;del&gt;KAFKA-4099&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1809.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1809.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #1809&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 06b9548feaa68c5f224d56df5e1d35bb0287fc8c&lt;br/&gt;
Author: Jiangjie Qin &amp;lt;becket.qin@gmail.com&amp;gt;&lt;br/&gt;
Date:   2016-09-01T03:24:52Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-4099&quot; title=&quot;Change the time based log rolling to only based on the message timestamp.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-4099&quot;&gt;&lt;del&gt;KAFKA-4099&lt;/del&gt;&lt;/a&gt;: Fix the potential frequent log rolling.&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15459424" author="junrao" created="Fri, 2 Sep 2016 19:49:56 +0000"  >&lt;p&gt;Issue resolved by pull request 1809&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/pull/1809&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1809&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15459428" author="githubbot" created="Fri, 2 Sep 2016 19:50:20 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1809&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1809&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15594095" author="junrao" created="Fri, 21 Oct 2016 05:15:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=becket_qin&quot; class=&quot;user-hover&quot; rel=&quot;becket_qin&quot;&gt;becket_qin&lt;/a&gt;, Ewen brought up another example that may still lead to undesirable behavior with log rolling. Suppose that you have 2 producers, one producing data with the current timestamp and another producing data with timestamp 7 days old (e.g., if some data is delayed or some old data is replayed), this will still cause the log segments to roll frequently. This may not be common, but can definitely happen. So, it seems we will still need to improve on how log rolls.&lt;/p&gt;</comment>
                            <comment id="15594273" author="becket_qin" created="Fri, 21 Oct 2016 06:48:14 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt; Is the purpose of log.rolling.ms to avoid the case where low volume topics never get rolled? This is usually because we want to enforce the log retention. In the described use case, would it be  reasonable to turn off log.rolling.ms completely until the bootstrap finishes? It seems user actually do not care about the log rolling or even log retention in that case.&lt;/p&gt;</comment>
                            <comment id="15596037" author="junrao" created="Fri, 21 Oct 2016 19:06:15 +0000"  >&lt;p&gt;I had two use cases of time-based rolling in mind. The first one is for users who don&apos;t want to retain a message (say sensitive data) in the log for too long. In this case, we want to be able to roll the log periodically based on time such that it will freeze the largest timestamp in the rolled segment and cause it to be deleted when the time limit has been reached. The second one is for log cleaner to happen quicker since the cleaner never cleans the active segment. In both cases, we really just want to be able to roll the log at some predicable time interval. There are different implementations can achieve this. &lt;/p&gt;

&lt;p&gt;The issue with the current implementation is that if data with oscillating timestamp are published at the same time, it causes the log to roll to quickly, which will surprise people. We can ask people to turn off log rolling in most cases. However, the default log rolling is 7 days and people could hit this issue before realizing it. In some of the rare cases, people may indeed want to configure time-based log rolling and may still send data with oscillating timestamp. It would be good if the underlying system can support his without any performance impact.&lt;/p&gt;

&lt;p&gt;As for a better implementation, the original approach of just rolling based on create time addresses both use cases in the common cases, without the risk of rolling too frequently. The only thing is that create time will be reset when segments get moved. However, that happens rarely though. So, if there are no other better solutions that we could think of, this could be a safer implementation.&lt;/p&gt;</comment>
                            <comment id="15596965" author="becket_qin" created="Sat, 22 Oct 2016 02:21:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt; Thanks for the explanation. I agree that it is reasonable to roll the log segment based on create time. However, I have a few concern over using the original proposal:&lt;br/&gt;
1. It seems the rareness of replica movement is related to scale. e.g. today we have over 1800 brokers at LI and 1-2 brokers die every day. So partition reassignment almost happen every day. So I think there is a difference between &quot;rare at small scale&quot; and &quot;rare regardless of scale&quot;. &lt;br/&gt;
2. The incorrect create time does not only happen when partition movement occurs. It seems most linux does not have a create time for the files. So the create time of a segment would be lost when the brokers are rebooted.&lt;/p&gt;

&lt;p&gt;Actually after thinking about the case of oscillating timestamp again, I am not sure if that would actually cause frequent log rolling or not. Let&apos;s say we have two producers one producing messages with current timestamp. The other one is producing with timestamps of 7 days old. Assume the current active segment is segment 0 and the current time is T. Because the log rolling is based on the timestamp of the first message in a log segment, it is possible that the first timestamp in segment 0 is 7 days ago (T - 7 days) so once we append a current timestamp T, segment 1 is rolled out and its first timestamp will be T, so segment 1 won&apos;t roll immediately like the previous one, i.e. segment 2 will only be rolled out when it sees a timestamp greater than (T + log.roll.ms), and so on.&lt;/p&gt;

&lt;p&gt;In the above example, it is possible that segment 2 is rolled out because of the segment size. In that case, segment 2 may have the first timestamp of (T - 7days) and segment 3 may get rolled out immediately but segment 3 will again wait until either the segment is full or it sees a bigger timestamp that triggers the log rolling. So in the worst case, we may roll out two new segments in a row. not sure how bad it would be in terms of performance.&lt;/p&gt;

&lt;p&gt;Admittedly, if we have some certain timestamp pattern, frequent log rolling may still happen. I am curious did you see any real timestamp pattern that has caused the frequent log rolling?&lt;/p&gt;</comment>
                            <comment id="15602189" author="ijuma" created="Mon, 24 Oct 2016 14:42:57 +0000"  >&lt;p&gt;I filed &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-4336&quot; title=&quot;Frequent log rolling when there&amp;#39;s a mix of delayed and current data&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-4336&quot;&gt;KAFKA-4336&lt;/a&gt; to make sure we don&apos;t lose track of this. It would be good to continue the discussion there.&lt;/p&gt;</comment>
                            <comment id="15603377" author="junrao" created="Mon, 24 Oct 2016 22:10:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=becket_qin&quot; class=&quot;user-hover&quot; rel=&quot;becket_qin&quot;&gt;becket_qin&lt;/a&gt;, thanks the explanation. What you described makes sense. So the issue is probably not that bad since the log won&apos;t be rolled as frequently as I thought. In the worse case, if we hit this issue, we may create twice as many segments as we ideally want to have in the interim. However, since this is relatively rare, we can probably just leave the current implementation as it is.&lt;/p&gt;

&lt;p&gt;A related issue is on log retention. Suppose that an app reprocesses data from more than 7 days ago. What will happen is that those data will be written to a log segment only to be deleted when the log retention thread kicks in, at which point, a new segment will be rolled. So, in this case, a log will be rolled as frequently as log.retention.check.interval.ms, which defaults to 5 mins. I am wondering if we should improve this by configuring log.message.timestamp.difference.max.ms to match log.retention.ms. This will avoid older data to be unnecessarily written to the log. It will help time-based log rolling as well.&lt;/p&gt;</comment>
                            <comment id="15603857" author="becket_qin" created="Tue, 25 Oct 2016 01:40:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt; Good point about making log.message.timestamp.difference.max.ms the same as log.retention.ms. That makes sense. This change may have some impact on the users who is currently pumping data into Kafka and consume it immediately before the log retention thread kicks in. But it should be rare and seems fragile anyway.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 4 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i32z13:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>