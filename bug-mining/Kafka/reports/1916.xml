<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:10:30 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-5697] StreamThread.shutdown() need to interrupt the stream threads to break the loop</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-5697</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;In &lt;tt&gt;StreamThread.shutdown()&lt;/tt&gt; we currently do nothing but set the state, hoping the stream thread may eventually check it and shutdown itself. However, under certain scenarios the thread may get blocked within a single loop and hence will never check on this state enum. For example, it&apos;s &lt;tt&gt;consumer.poll&lt;/tt&gt; call trigger &lt;tt&gt;ensureCoordinatorReady()&lt;/tt&gt; which will block until the coordinator can be found. If the coordinator broker is never up and running then the Stream instance will be blocked forever.&lt;/p&gt;

&lt;p&gt;A simple way to produce this issue is to start the work count demo without starting the ZK / Kafka broker, and then it will get stuck in a single loop and even `ctrl-C` will not stop it since its set state will never be read by the thread:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[2017-08-03 15:17:39,981] WARN Connection to node -1 could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2017-08-03 15:17:40,046] WARN Connection to node -1 could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2017-08-03 15:17:40,101] WARN Connection to node -1 could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2017-08-03 15:17:40,206] WARN Connection to node -1 could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2017-08-03 15:17:40,261] WARN Connection to node -1 could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2017-08-03 15:17:40,366] WARN Connection to node -1 could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2017-08-03 15:17:40,472] WARN Connection to node -1 could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
^C[2017-08-03 15:17:40,580] WARN Connection to node -1 could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13092321">KAFKA-5697</key>
            <summary>StreamThread.shutdown() need to interrupt the stream threads to break the loop</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="vvcephei">John Roesler</assignee>
                                    <reporter username="guozhang">Guozhang Wang</reporter>
                        <labels>
                            <label>newbie</label>
                    </labels>
                <created>Thu, 3 Aug 2017 22:31:01 +0000</created>
                <updated>Fri, 15 May 2020 02:43:29 +0000</updated>
                            <resolved>Fri, 8 Jun 2018 17:55:39 +0000</resolved>
                                                    <fixVersion>2.0.0</fixVersion>
                                    <component>streams</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="16285540" author="guozhang" created="Mon, 11 Dec 2017 05:52:50 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=johnma&quot; class=&quot;user-hover&quot; rel=&quot;johnma&quot;&gt;johnma&lt;/a&gt; are you still working on this ticket?&lt;/p&gt;</comment>
                            <comment id="16333410" author="johnma" created="Sun, 21 Jan 2018 06:27:08 +0000"  >&lt;p&gt;@Guozhang Wang, sorry for the delay in responding. Just saw the comment on this bug. I am not working on this bug , so I unassigned myself. Thank you.&lt;/p&gt;</comment>
                            <comment id="16397347" author="yuzhihong@gmail.com" created="Tue, 13 Mar 2018 17:39:23 +0000"  >&lt;p&gt;Looks like StreamThread.close() doesn&apos;t exist (after refactoring).&lt;/p&gt;</comment>
                            <comment id="16434478" author="vvcephei" created="Wed, 11 Apr 2018 19:53:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt; From your problem description, it seems like the solution isn&apos;t to make shutdown more aggressive, but to make consumer.poll not block forever.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;WDYT?&lt;/p&gt;</comment>
                            <comment id="16434745" author="githubbot" created="Thu, 12 Apr 2018 00:07:15 +0000"  >&lt;p&gt;vvcephei opened a new pull request #4855: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5697&quot; title=&quot;StreamThread.shutdown() need to interrupt the stream threads to break the loop&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5697&quot;&gt;&lt;del&gt;KAFKA-5697&lt;/del&gt;&lt;/a&gt;: prevent poll() from blocking forever&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4855&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4855&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   As the name says, currently `KafkaConsumer#poll` may block forever&lt;br/&gt;
   despite having a timeout parameter, since that timeout only applies to&lt;br/&gt;
   the `ConsumerNetworkClient#poll` and not the `ConsumerCoordinator#poll`.&lt;/p&gt;

&lt;p&gt;   This change applies the timeout to the entire `poll` operation, allowing us to&lt;br/&gt;
   ensure threads won&apos;t hang forever in the event, e.g., that we can&apos;t talk to the &lt;br/&gt;
   coordinator. I&apos;ve tried tomake the change in a &apos;private&apos; fashion so as not to &lt;br/&gt;
   change any public APIs, but let me know if you think it still needs a KIP.&lt;/p&gt;

&lt;p&gt;   Several tests depended on being able to send a timeout of 0, but still&lt;br/&gt;
   have the coordinator poll take non-zero time to do its work. I updated&lt;br/&gt;
   them to send a long enough timeout for the coordinator to to the&lt;br/&gt;
   required work.&lt;/p&gt;

&lt;p&gt;   I believe our testing suite should be sufficient to validate this change.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16452916" author="githubbot" created="Wed, 25 Apr 2018 19:21:27 +0000"  >&lt;p&gt;vvcephei opened a new pull request #4930: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5697&quot; title=&quot;StreamThread.shutdown() need to interrupt the stream threads to break the loop&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5697&quot;&gt;&lt;del&gt;KAFKA-5697&lt;/del&gt;&lt;/a&gt;: issue Consumer#wakeup during Streams shutdown&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4930&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4930&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Wakeup consumers during shutdown to break them out of any internally blocking calls.&lt;/p&gt;

&lt;p&gt;   Semantically, it should be fine to treat a WakeupException as &quot;no work to do&quot;, which will then continue the threads&apos; polling loops, leading them to discover that they are supposed to shut down, which they will do gracefully.&lt;/p&gt;

&lt;p&gt;   The existing tests should be sufficient to verify no regressions.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16464069" author="guozhang" created="Fri, 4 May 2018 16:06:28 +0000"  >&lt;p&gt;Issue resolved by pull request 4930&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/pull/4930&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4930&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16464072" author="githubbot" created="Fri, 4 May 2018 16:08:06 +0000"  >&lt;p&gt;guozhangwang closed pull request #4930: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5697&quot; title=&quot;StreamThread.shutdown() need to interrupt the stream threads to break the loop&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5697&quot;&gt;&lt;del&gt;KAFKA-5697&lt;/del&gt;&lt;/a&gt;: issue Consumer#wakeup during Streams shutdown&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4930&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4930&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java b/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java&lt;br/&gt;
index 66a8934d283..2c409d1015d 100644&lt;br/&gt;
&amp;#8212; a/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java&lt;br/&gt;
@@ -67,6 +67,7 @@&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
 import java.util.HashMap;&lt;br/&gt;
 import java.util.HashSet;&lt;br/&gt;
+import java.util.LinkedHashMap;&lt;br/&gt;
 import java.util.List;&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
 import java.util.Properties;&lt;br/&gt;
@@ -382,7 +383,13 @@ public void setGlobalStateRestoreListener(final StateRestoreListener globalState&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@return Map of all metrics.&lt;br/&gt;
      */&lt;br/&gt;
     public Map&amp;lt;MetricName, ? extends Metric&amp;gt; metrics() {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return Collections.unmodifiableMap(metrics.metrics());&lt;br/&gt;
+        final Map&amp;lt;MetricName, Metric&amp;gt; result = new LinkedHashMap&amp;lt;&amp;gt;();&lt;br/&gt;
+        for (final StreamThread thread : threads) 
{
+            result.putAll(thread.consumerMetrics());
+        }
&lt;p&gt;+        if (globalStreamThread != null) result.putAll(globalStreamThread.consumerMetrics());&lt;br/&gt;
+        result.putAll(metrics.metrics());&lt;br/&gt;
+        return Collections.unmodifiableMap(result);&lt;br/&gt;
     }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;br/&gt;
diff --git a/streams/src/main/java/org/apache/kafka/streams/errors/ShutdownException.java b/streams/src/main/java/org/apache/kafka/streams/errors/ShutdownException.java&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..d404642793c&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/errors/ShutdownException.java&lt;br/&gt;
@@ -0,0 +1,31 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one or more&lt;br/&gt;
+ * contributor license agreements. See the NOTICE file distributed with&lt;br/&gt;
+ * this work for additional information regarding copyright ownership.&lt;br/&gt;
+ * The ASF licenses this file to You under the Apache License, Version 2.0&lt;br/&gt;
+ * (the &quot;License&quot;); you may not use this file except in compliance with&lt;br/&gt;
+ * the License. You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+package org.apache.kafka.streams.errors;&lt;br/&gt;
+&lt;br/&gt;
+public class ShutdownException extends StreamsException {&lt;br/&gt;
+    public ShutdownException(final String message) &lt;/p&gt;
{
+        super(message);
+    }
&lt;p&gt;+&lt;br/&gt;
+    public ShutdownException(final String message, final Throwable throwable) &lt;/p&gt;
{
+        super(message, throwable);
+    }
&lt;p&gt;+&lt;br/&gt;
+    public ShutdownException(final Throwable throwable) &lt;/p&gt;
{
+        super(throwable);
+    }
&lt;p&gt;+}&lt;br/&gt;
diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/ConsumerUtils.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/ConsumerUtils.java&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..8b912579b9a&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/ConsumerUtils.java&lt;br/&gt;
@@ -0,0 +1,38 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one or more&lt;br/&gt;
+ * contributor license agreements. See the NOTICE file distributed with&lt;br/&gt;
+ * this work for additional information regarding copyright ownership.&lt;br/&gt;
+ * The ASF licenses this file to You under the Apache License, Version 2.0&lt;br/&gt;
+ * (the &quot;License&quot;); you may not use this file except in compliance with&lt;br/&gt;
+ * the License. You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+package org.apache.kafka.streams.processor.internals;&lt;br/&gt;
+&lt;br/&gt;
+import org.apache.kafka.clients.consumer.Consumer;&lt;br/&gt;
+import org.apache.kafka.clients.consumer.ConsumerRecord;&lt;br/&gt;
+import org.apache.kafka.clients.consumer.ConsumerRecords;&lt;br/&gt;
+import org.apache.kafka.common.TopicPartition;&lt;br/&gt;
+import org.apache.kafka.common.errors.WakeupException;&lt;br/&gt;
+&lt;br/&gt;
+import java.util.Collections;&lt;br/&gt;
+import java.util.List;&lt;br/&gt;
+&lt;br/&gt;
+public final class ConsumerUtils {&lt;br/&gt;
+    private ConsumerUtils() {}&lt;br/&gt;
+&lt;br/&gt;
+    public static &amp;lt;K, V&amp;gt; ConsumerRecords&amp;lt;K, V&amp;gt; poll(final Consumer&amp;lt;K, V&amp;gt; consumer, final long maxDurationMs) {&lt;br/&gt;
+        try &lt;/p&gt;
{
+            return consumer.poll(maxDurationMs);
+        }
&lt;p&gt; catch (final WakeupException e) &lt;/p&gt;
{
+            return new ConsumerRecords&amp;lt;&amp;gt;(Collections.&amp;lt;TopicPartition, List&amp;lt;ConsumerRecord&amp;lt;K, V&amp;gt;&amp;gt;&amp;gt;emptyMap());
+        }
&lt;p&gt;+    }&lt;br/&gt;
+}&lt;br/&gt;
diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java&lt;br/&gt;
index e8ec5e9fe5f..017f2da198f 100644&lt;br/&gt;
&amp;#8212; a/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java&lt;br/&gt;
@@ -23,12 +23,14 @@&lt;br/&gt;
 import org.apache.kafka.common.PartitionInfo;&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition;&lt;br/&gt;
 import org.apache.kafka.common.errors.TimeoutException;&lt;br/&gt;
+import org.apache.kafka.common.errors.WakeupException;&lt;br/&gt;
 import org.apache.kafka.common.utils.LogContext;&lt;br/&gt;
 import org.apache.kafka.common.utils.Utils;&lt;br/&gt;
 import org.apache.kafka.streams.KeyValue;&lt;br/&gt;
 import org.apache.kafka.streams.StreamsConfig;&lt;br/&gt;
 import org.apache.kafka.streams.errors.LockException;&lt;br/&gt;
 import org.apache.kafka.streams.errors.ProcessorStateException;&lt;br/&gt;
+import org.apache.kafka.streams.errors.ShutdownException;&lt;br/&gt;
 import org.apache.kafka.streams.errors.StreamsException;&lt;br/&gt;
 import org.apache.kafka.streams.processor.BatchingStateRestoreCallback;&lt;br/&gt;
 import org.apache.kafka.streams.processor.StateRestoreCallback;&lt;br/&gt;
@@ -46,6 +48,8 @@&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
 import java.util.Set;&lt;/p&gt;

&lt;p&gt;+import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;&lt;br/&gt;
+&lt;br/&gt;
 /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;This class is responsible for the initialization, restoration, closing, flushing etc&lt;/li&gt;
	&lt;li&gt;of Global State Stores. There is only ever 1 instance of this class per Application Instance.&lt;br/&gt;
@@ -60,13 +64,15 @@&lt;br/&gt;
     private InternalProcessorContext processorContext;&lt;br/&gt;
     private final int retries;&lt;br/&gt;
     private final long retryBackoffMs;&lt;br/&gt;
+    private final IsRunning isRunning;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     public GlobalStateManagerImpl(final LogContext logContext,&lt;br/&gt;
                                   final ProcessorTopology topology,&lt;br/&gt;
                                   final Consumer&amp;lt;byte[], byte[]&amp;gt; globalConsumer,&lt;br/&gt;
                                   final StateDirectory stateDirectory,&lt;br/&gt;
                                   final StateRestoreListener stateRestoreListener,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final StreamsConfig config) {&lt;br/&gt;
+                                  final StreamsConfig config,&lt;br/&gt;
+                                  final IsRunning isRunning) 
{
         super(stateDirectory.globalStateDir());
 
         this.log = logContext.logger(GlobalStateManagerImpl.class);
@@ -76,6 +82,11 @@ public GlobalStateManagerImpl(final LogContext logContext,
         this.stateRestoreListener = stateRestoreListener;
         this.retries = config.getInt(StreamsConfig.RETRIES_CONFIG);
         this.retryBackoffMs = config.getLong(StreamsConfig.RETRY_BACKOFF_MS_CONFIG);
+        this.isRunning = isRunning;
+    }
&lt;p&gt;+&lt;br/&gt;
+    public interface IsRunning &lt;/p&gt;
{
+        boolean check();
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @Override&lt;br/&gt;
@@ -200,6 +211,13 @@ public void register(final StateStore store,&lt;br/&gt;
             try &lt;/p&gt;
{
                 partitionInfos = globalConsumer.partitionsFor(sourceTopic);
                 break;
+            }
&lt;p&gt; catch (final WakeupException wakeupException) {&lt;br/&gt;
+                if (isRunning.check()) &lt;/p&gt;
{
+                    // note we may decide later that this condition is ok and just let the retry loop continue
+                    throw new IllegalStateException(&quot;Got unexpected WakeupException during initialization.&quot;, wakeupException);
+                }
&lt;p&gt; else &lt;/p&gt;
{
+                    throw new ShutdownException(&quot;Shutting down from fetching partitions&quot;);
+                }
&lt;p&gt;             } catch (final TimeoutException retryableException) {&lt;br/&gt;
                 if (++attempts &amp;gt; retries) {&lt;br/&gt;
                     log.error(&quot;Failed to get partitions for topic {} after {} retry attempts due to timeout. &quot; +&lt;br/&gt;
@@ -250,19 +268,20 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,&lt;/p&gt;

&lt;p&gt;             long offset = globalConsumer.position(topicPartition);&lt;br/&gt;
             final Long highWatermark = highWatermarks.get(topicPartition);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;BatchingStateRestoreCallback&lt;/li&gt;
	&lt;li&gt;stateRestoreAdapter =&lt;/li&gt;
	&lt;li&gt;(BatchingStateRestoreCallback) ((stateRestoreCallback instanceof&lt;/li&gt;
	&lt;li&gt;BatchingStateRestoreCallback)&lt;/li&gt;
	&lt;li&gt;? stateRestoreCallback&lt;/li&gt;
	&lt;li&gt;: new WrappedBatchingStateRestoreCallback(stateRestoreCallback));&lt;br/&gt;
+            final BatchingStateRestoreCallback stateRestoreAdapter =&lt;br/&gt;
+                (BatchingStateRestoreCallback) ((stateRestoreCallback instanceof BatchingStateRestoreCallback)&lt;br/&gt;
+                    ? stateRestoreCallback&lt;br/&gt;
+                    : new WrappedBatchingStateRestoreCallback(stateRestoreCallback));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             stateRestoreListener.onRestoreStart(topicPartition, storeName, offset, highWatermark);&lt;br/&gt;
             long restoreCount = 0L;&lt;/p&gt;

&lt;p&gt;             while (offset &amp;lt; highWatermark) {&lt;br/&gt;
+                if (!isRunning.check()) &lt;/p&gt;
{
+                    throw new ShutdownException(&quot;Streams is not running (any more)&quot;);
+                }
&lt;p&gt;                 try {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = globalConsumer.poll(100);&lt;br/&gt;
+                    final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(globalConsumer, 100);&lt;br/&gt;
                     final List&amp;lt;KeyValue&amp;lt;byte[], byte[]&amp;gt;&amp;gt; restoreRecords = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
                     for (ConsumerRecord&amp;lt;byte[], byte[]&amp;gt; record : records) {&lt;br/&gt;
                         if (record.key() != null) {&lt;br/&gt;
diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java&lt;br/&gt;
index 1c348975f2a..4b6bfb1fd65 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java&lt;br/&gt;
@@ -20,6 +20,8 @@&lt;br/&gt;
 import org.apache.kafka.clients.consumer.ConsumerRecord;&lt;br/&gt;
 import org.apache.kafka.clients.consumer.ConsumerRecords;&lt;br/&gt;
 import org.apache.kafka.clients.consumer.InvalidOffsetException;&lt;br/&gt;
+import org.apache.kafka.common.Metric;&lt;br/&gt;
+import org.apache.kafka.common.MetricName;&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition;&lt;br/&gt;
 import org.apache.kafka.common.metrics.Metrics;&lt;br/&gt;
 import org.apache.kafka.common.utils.LogContext;&lt;br/&gt;
@@ -27,6 +29,7 @@&lt;br/&gt;
 import org.apache.kafka.common.utils.Utils;&lt;br/&gt;
 import org.apache.kafka.streams.StreamsConfig;&lt;br/&gt;
 import org.apache.kafka.streams.errors.LockException;&lt;br/&gt;
+import org.apache.kafka.streams.errors.ShutdownException;&lt;br/&gt;
 import org.apache.kafka.streams.errors.StreamsException;&lt;br/&gt;
 import org.apache.kafka.streams.processor.StateRestoreListener;&lt;br/&gt;
 import org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl;&lt;br/&gt;
@@ -35,10 +38,12 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import java.io.IOException;&lt;br/&gt;
 import java.util.Arrays;&lt;br/&gt;
+import java.util.Collections;&lt;br/&gt;
 import java.util.HashSet;&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
 import java.util.Set;&lt;/p&gt;

&lt;p&gt;+import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;&lt;br/&gt;
 import static org.apache.kafka.streams.processor.internals.GlobalStreamThread.State.DEAD;&lt;br/&gt;
 import static org.apache.kafka.streams.processor.internals.GlobalStreamThread.State.PENDING_SHUTDOWN;&lt;/p&gt;

&lt;p&gt;@@ -103,6 +108,10 @@ public boolean isRunning() &lt;/p&gt;
{
             return equals(RUNNING);
         }

&lt;p&gt;+        public boolean isStarting() &lt;/p&gt;
{
+            return equals(CREATED);
+        }
&lt;p&gt;+&lt;br/&gt;
         @Override&lt;br/&gt;
         public boolean isValidTransition(final ThreadStateTransitionValidator newState) {&lt;br/&gt;
             final State tmpState = (State) newState;&lt;br/&gt;
@@ -170,6 +179,12 @@ public boolean stillRunning() {&lt;br/&gt;
         }&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;+    private boolean stillStarting() {&lt;br/&gt;
+        synchronized (stateLock) &lt;/p&gt;
{
+            return state.isStarting();
+        }
&lt;p&gt;+    }&lt;br/&gt;
+&lt;br/&gt;
     public GlobalStreamThread(final ProcessorTopology topology,&lt;br/&gt;
                               final StreamsConfig config,&lt;br/&gt;
                               final Consumer&amp;lt;byte[], byte[]&amp;gt; globalConsumer,&lt;br/&gt;
@@ -232,7 +247,7 @@ void initialize() {&lt;/p&gt;

&lt;p&gt;         void pollAndUpdate() {&lt;br/&gt;
             try {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; received = globalConsumer.poll(pollMs);&lt;br/&gt;
+                final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; received = poll(globalConsumer, pollMs);&lt;br/&gt;
                 for (final ConsumerRecord&amp;lt;byte[], byte[]&amp;gt; record : received) 
{
                     stateMaintainer.update(record);
                 }
&lt;p&gt;@@ -263,7 +278,19 @@ public void close() throws IOException {&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @Override&lt;br/&gt;
     public void run() {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final StateConsumer stateConsumer = initialize();&lt;br/&gt;
+        final StateConsumer stateConsumer;&lt;br/&gt;
+        try 
{
+            stateConsumer = initialize();
+        }
&lt;p&gt; catch (final ShutdownException e) &lt;/p&gt;
{
+            log.info(&quot;Shutting down from initialization&quot;);
+            // Almost certainly, we arrived here because the state is already PENDING_SHUTDOWN, but it&apos;s harmless to
+            // just make sure
+            setState(State.PENDING_SHUTDOWN);
+            setState(State.DEAD);
+            streamsMetrics.removeAllThreadLevelSensors();
+            log.info(&quot;Shutdown complete&quot;);
+            return;
+        }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         if (stateConsumer == null) {&lt;br/&gt;
             // during initialization, the caller thread would wait for the state consumer&lt;br/&gt;
@@ -275,6 +302,7 @@ public void run() &lt;/p&gt;
{
             setState(State.DEAD);
 
             log.warn(&quot;Error happened during initialization of the global state store; this thread has shutdown&quot;);
+            streamsMetrics.removeAllThreadLevelSensors();
 
             return;
         }
&lt;p&gt;@@ -314,7 +342,14 @@ private StateConsumer initialize() {&lt;br/&gt;
                 globalConsumer,&lt;br/&gt;
                 stateDirectory,&lt;br/&gt;
                 stateRestoreListener,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;config);&lt;br/&gt;
+                config,&lt;br/&gt;
+                new GlobalStateManagerImpl.IsRunning() 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+                    @Override+                    public boolean check() {
+                        return stillStarting() || stillRunning();
+                    }+                }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;+            );&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             final GlobalProcessorContextImpl globalProcessorContext = new GlobalProcessorContextImpl(&lt;br/&gt;
                 config,&lt;br/&gt;
@@ -367,5 +402,10 @@ public void shutdown() &lt;/p&gt;
{
         // one could call shutdown() multiple times, so ignore subsequent calls
         // if already shutting down or dead
         setState(PENDING_SHUTDOWN);
+        globalConsumer.wakeup();
+    }
&lt;p&gt;+&lt;br/&gt;
+    public Map&amp;lt;MetricName, Metric&amp;gt; consumerMetrics() &lt;/p&gt;
{
+        return Collections.unmodifiableMap(globalConsumer.metrics());
     }
&lt;p&gt; }&lt;br/&gt;
diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreChangelogReader.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreChangelogReader.java&lt;br/&gt;
index 5fcba76570e..9b67fc4263c 100644&lt;br/&gt;
&amp;#8212; a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreChangelogReader.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreChangelogReader.java&lt;br/&gt;
@@ -40,6 +40,8 @@&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
 import java.util.Set;&lt;/p&gt;

&lt;p&gt;+import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;&lt;br/&gt;
+&lt;br/&gt;
 public class StoreChangelogReader implements ChangelogReader {&lt;/p&gt;

&lt;p&gt;     private final Logger log;&lt;br/&gt;
@@ -81,7 +83,7 @@ public void register(final StateRestorer restorer) {&lt;/p&gt;

&lt;p&gt;         final Set&amp;lt;TopicPartition&amp;gt; restoringPartitions = new HashSet&amp;lt;&amp;gt;(needsRestoring.keySet());&lt;br/&gt;
         try {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; allRecords = restoreConsumer.poll(10);&lt;br/&gt;
+            final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; allRecords = poll(restoreConsumer, 10);&lt;br/&gt;
             for (final TopicPartition partition : restoringPartitions) 
{
                 restorePartition(allRecords, partition, active.restoringTaskFor(partition));
             }
&lt;p&gt;diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java&lt;br/&gt;
index cc5a07f0a91..32993f6b0be 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java&lt;br/&gt;
@@ -26,6 +26,8 @@&lt;br/&gt;
 import org.apache.kafka.clients.producer.Producer;&lt;br/&gt;
 import org.apache.kafka.clients.producer.ProducerConfig;&lt;br/&gt;
 import org.apache.kafka.common.KafkaException;&lt;br/&gt;
+import org.apache.kafka.common.Metric;&lt;br/&gt;
+import org.apache.kafka.common.MetricName;&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition;&lt;br/&gt;
 import org.apache.kafka.common.metrics.Metrics;&lt;br/&gt;
 import org.apache.kafka.common.metrics.Sensor;&lt;br/&gt;
@@ -54,6 +56,7 @@&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
 import java.util.HashMap;&lt;br/&gt;
 import java.util.HashSet;&lt;br/&gt;
+import java.util.LinkedHashMap;&lt;br/&gt;
 import java.util.List;&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
 import java.util.Set;&lt;br/&gt;
@@ -62,6 +65,7 @@&lt;br/&gt;
 import java.util.concurrent.atomic.AtomicInteger;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import static java.util.Collections.singleton;&lt;br/&gt;
+import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;&lt;/p&gt;

&lt;p&gt; public class StreamThread extends Thread {&lt;/p&gt;

&lt;p&gt;@@ -824,7 +828,7 @@ long runOnce(final long recordsProcessedBeforeCommit) {&lt;br/&gt;
         ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = null;&lt;/p&gt;

&lt;p&gt;         try &lt;/p&gt;
{
-            records = consumer.poll(pollTimeMs);
+            records = poll(consumer, pollTimeMs);
         }
&lt;p&gt; catch (final InvalidOffsetException e) &lt;/p&gt;
{
             resetInvalidOffsets(e);
         }
&lt;p&gt;@@ -1051,7 +1055,7 @@ private void maybeUpdateStandbyTasks(final long now) {&lt;br/&gt;
             }&lt;/p&gt;

&lt;p&gt;             try {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = restoreConsumer.poll(0);&lt;br/&gt;
+                final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(restoreConsumer, 0);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;                 if (!records.isEmpty()) {&lt;br/&gt;
                     for (final TopicPartition partition : records.partitions()) {&lt;br/&gt;
@@ -1116,6 +1120,8 @@ private long computeLatency() {&lt;br/&gt;
     public void shutdown() {&lt;br/&gt;
         log.info(&quot;Informed to shut down&quot;);&lt;br/&gt;
         final State oldState = setState(State.PENDING_SHUTDOWN);&lt;br/&gt;
+        consumer.wakeup();&lt;br/&gt;
+        restoreConsumer.wakeup();&lt;br/&gt;
         if (oldState == State.CREATED) {&lt;br/&gt;
             // The thread may not have been started. Take responsibility for shutting down&lt;br/&gt;
             completeShutdown(true);&lt;br/&gt;
@@ -1210,4 +1216,13 @@ TaskManager taskManager() {&lt;br/&gt;
     Map&amp;lt;TopicPartition, List&amp;lt;ConsumerRecord&amp;lt;byte[], byte[]&amp;gt;&amp;gt;&amp;gt; standbyRecords() &lt;/p&gt;
{
         return standbyRecords;
     }
&lt;p&gt;+&lt;br/&gt;
+    public Map&amp;lt;MetricName, Metric&amp;gt; consumerMetrics() &lt;/p&gt;
{
+        final Map&amp;lt;MetricName, ? extends Metric&amp;gt; consumerMetrics = consumer.metrics();
+        final Map&amp;lt;MetricName, ? extends Metric&amp;gt; restoreConsumerMetrics = restoreConsumer.metrics();
+        final LinkedHashMap&amp;lt;MetricName, Metric&amp;gt; result = new LinkedHashMap&amp;lt;&amp;gt;();
+        result.putAll(consumerMetrics);
+        result.putAll(restoreConsumerMetrics);
+        return result;
+    }
&lt;p&gt; }&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java b/streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java&lt;br/&gt;
index 1dc8602c280..1c33f647ad4 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java&lt;br/&gt;
@@ -18,8 +18,6 @@&lt;/p&gt;

&lt;p&gt; import org.apache.kafka.clients.producer.MockProducer;&lt;br/&gt;
 import org.apache.kafka.common.Cluster;&lt;br/&gt;
-import org.apache.kafka.common.Metric;&lt;br/&gt;
-import org.apache.kafka.common.MetricName;&lt;br/&gt;
 import org.apache.kafka.common.Node;&lt;br/&gt;
 import org.apache.kafka.common.PartitionInfo;&lt;br/&gt;
 import org.apache.kafka.common.config.ConfigException;&lt;br/&gt;
@@ -43,6 +41,7 @@&lt;br/&gt;
 import org.junit.Assert;&lt;br/&gt;
 import org.junit.Before;&lt;br/&gt;
 import org.junit.ClassRule;&lt;br/&gt;
+import org.junit.Ignore;&lt;br/&gt;
 import org.junit.Test;&lt;br/&gt;
 import org.junit.experimental.categories.Category;&lt;/p&gt;

&lt;p&gt;@@ -232,7 +231,43 @@ public boolean conditionMet() &lt;/p&gt;
{
 
         streams.close();
         assertEquals(streams.state(), KafkaStreams.State.NOT_RUNNING);
+    }
&lt;p&gt;+&lt;br/&gt;
+    @Ignore // this test cannot pass as long as GST blocks KS.start()&lt;br/&gt;
+    @Test&lt;br/&gt;
+    public void testGlobalThreadCloseWithoutConnectingToBroker() &lt;/p&gt;
{
+        final Properties props = new Properties();
+        props.setProperty(StreamsConfig.APPLICATION_ID_CONFIG, &quot;appId&quot;);
+        props.setProperty(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:1&quot;);
+        props.setProperty(StreamsConfig.METRIC_REPORTER_CLASSES_CONFIG, MockMetricsReporter.class.getName());
+        props.setProperty(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());
+        props.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, NUM_THREADS);
 
+        final StreamsBuilder builder = new StreamsBuilder();
+        // make sure we have the global state thread running too
+        builder.globalTable(&quot;anyTopic&quot;);
+        final KafkaStreams streams = new KafkaStreams(builder.build(), props);
+        streams.start();
+        streams.close();
+        // There&apos;s nothing to assert... We&apos;re testing that this operation actually completes.
+    }
&lt;p&gt;+&lt;br/&gt;
+    @Test&lt;br/&gt;
+    public void testLocalThreadCloseWithoutConnectingToBroker() &lt;/p&gt;
{
+        final Properties props = new Properties();
+        props.setProperty(StreamsConfig.APPLICATION_ID_CONFIG, &quot;appId&quot;);
+        props.setProperty(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:1&quot;);
+        props.setProperty(StreamsConfig.METRIC_REPORTER_CLASSES_CONFIG, MockMetricsReporter.class.getName());
+        props.setProperty(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());
+        props.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, NUM_THREADS);
+
+        final StreamsBuilder builder = new StreamsBuilder();
+        // make sure we have the global state thread running too
+        builder.table(&quot;anyTopic&quot;);
+        final KafkaStreams streams = new KafkaStreams(builder.build(), props);
+        streams.start();
+        streams.close();
+        // There&apos;s nothing to assert... We&apos;re testing that this operation actually completes.
     }


&lt;p&gt;@@ -327,16 +362,6 @@ public void shouldThrowExceptionSettingStateListenerNotInCreateState() {&lt;br/&gt;
         }&lt;br/&gt;
     }&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test&lt;/li&gt;
	&lt;li&gt;public void testNumberDefaultMetrics() 
{
-        props.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, &quot;1&quot;);
-        final StreamsBuilder builder = new StreamsBuilder();
-        final KafkaStreams streams = new KafkaStreams(builder.build(), props);
-        final Map&amp;lt;MetricName, ? extends Metric&amp;gt; metrics = streams.metrics();
-        // all 22 default StreamThread metrics + 1 metric that keeps track of number of metrics
-        assertEquals(23, metrics.size());
-    }
&lt;p&gt;-&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testIllegalMetricsConfig() {&lt;br/&gt;
         props.setProperty(StreamsConfig.METRICS_RECORDING_LEVEL_CONFIG, &quot;illegalConfig&quot;);&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/InternalTopicIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/InternalTopicIntegrationTest.java&lt;br/&gt;
index 2d9c8c4bdc9..e8ee50764a7 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/integration/InternalTopicIntegrationTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/integration/InternalTopicIntegrationTest.java&lt;br/&gt;
@@ -55,6 +55,7 @@&lt;br/&gt;
 import java.util.Properties;&lt;br/&gt;
 import java.util.concurrent.TimeUnit;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.waitForCompletion;&lt;br/&gt;
 import static org.junit.Assert.assertEquals;&lt;br/&gt;
 import static org.junit.Assert.assertTrue;&lt;/p&gt;

&lt;p&gt;@@ -118,8 +119,9 @@ private Properties getTopicProperties(final String changelog) {&lt;br/&gt;
             final Map&amp;lt;String, Properties&amp;gt; topicConfigs = scala.collection.JavaConversions.mapAsJavaMap(adminZkClient.getAllTopicConfigs());&lt;/p&gt;

&lt;p&gt;             for (Map.Entry&amp;lt;String, Properties&amp;gt; topicConfig : topicConfigs.entrySet()) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (topicConfig.getKey().equals(changelog))&lt;br/&gt;
+                if (topicConfig.getKey().equals(changelog)) 
{
                     return topicConfig.getValue();
+                }
&lt;p&gt;             }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             return new Properties();&lt;br/&gt;
@@ -157,6 +159,7 @@ public void shouldCompactTopicsForKeyValueStoreChangelogs() throws Exception &lt;/p&gt;
{
         //
         // Step 3: Verify the state changelog topics are compact
         //
+        waitForCompletion(streams, 2, 5000);
         streams.close();
 
         final Properties changelogProps = getTopicProperties(ProcessorStateManager.storeChangelogTopic(appID, &quot;Counts&quot;));
@@ -201,6 +204,7 @@ public void shouldCompactAndDeleteTopicsForWindowStoreChangelogs() throws Except
         //
         // Step 3: Verify the state changelog topics are compact
         //
+        waitForCompletion(streams, 2, 5000);
         streams.close();
         final Properties properties = getTopicProperties(ProcessorStateManager.storeChangelogTopic(appID, &quot;CountWindows&quot;));
         final List&amp;lt;String&amp;gt; policies = Arrays.asList(properties.getProperty(LogConfig.CleanupPolicyProp()).split(&quot;,&quot;));
diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java b/streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java
index e8cd59e0925..ec97f125ece 100644
--- a/streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java
+++ b/streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java
@@ -28,10 +28,12 @@
 import org.apache.kafka.clients.producer.Producer;
 import org.apache.kafka.clients.producer.ProducerRecord;
 import org.apache.kafka.clients.producer.RecordMetadata;
+import org.apache.kafka.common.Metric;
 import org.apache.kafka.common.TopicPartition;
 import org.apache.kafka.common.requests.UpdateMetadataRequest;
 import org.apache.kafka.common.utils.Time;
 import org.apache.kafka.common.utils.Utils;
+import org.apache.kafka.streams.KafkaStreams;
 import org.apache.kafka.streams.KeyValue;
 import org.apache.kafka.streams.StreamsConfig;
 import org.apache.kafka.test.TestCondition;
@@ -49,6 +51,8 @@
 import java.util.concurrent.ExecutionException;
 import java.util.concurrent.Future;
 
+import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;
+
 /**
  * Utility functions to make integration testing more convenient.
  */
@@ -158,6 +162,40 @@ public static void purgeLocalStreamsState(final Properties streamsConfiguration)
         produceKeyValuesSynchronously(topic, keyedRecords, producerConfig, time, enableTransactions);
     }

&lt;p&gt;+    /**&lt;br/&gt;
+     * Wait for streams to &quot;finish&quot;, based on the consumer lag metric.&lt;br/&gt;
+     *&lt;br/&gt;
+     * Caveats:&lt;br/&gt;
+     * - Inputs must be finite, fully loaded, and flushed before this method is called&lt;br/&gt;
+     * - expectedPartitions is the total number of partitions to watch the lag on, including both input and internal.&lt;br/&gt;
+     *   It&apos;s somewhat ok to get this wrong, as the main failure case would be an immediate return due to the clients&lt;br/&gt;
+     *   not being initialized, which you can avoid with any non-zero value. But it&apos;s probably better to get it right &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
+     */&lt;br/&gt;
+    public static void waitForCompletion(final KafkaStreams streams,&lt;br/&gt;
+                                         final int expectedPartitions,&lt;br/&gt;
+                                         final int timeoutMilliseconds) {&lt;br/&gt;
+        final long start = System.currentTimeMillis();&lt;br/&gt;
+        while (true) {&lt;br/&gt;
+            int lagMetrics = 0;&lt;br/&gt;
+            double totalLag = 0.0;&lt;br/&gt;
+            for (final Metric metric : streams.metrics().values()) {&lt;br/&gt;
+                if (metric.metricName().name().equals(&quot;records-lag&quot;)) &lt;/p&gt;
{
+                    lagMetrics++;
+                    totalLag += ((Number) metric.metricValue()).doubleValue();
+                }
&lt;p&gt;+            }&lt;br/&gt;
+            if (lagMetrics &amp;gt;= expectedPartitions &amp;amp;&amp;amp; totalLag == 0.0) &lt;/p&gt;
{
+                return;
+            }
&lt;p&gt;+            if (System.currentTimeMillis() - start &amp;gt;= timeoutMilliseconds) &lt;/p&gt;
{
+                throw new RuntimeException(String.format(
+                    &quot;Timed out waiting for completion. lagMetrics=[%s/%s] totalLag=[%s]&quot;,
+                    lagMetrics, expectedPartitions, totalLag
+                ));
+            }
&lt;p&gt;+        }&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
     public static &amp;lt;K, V&amp;gt; List&amp;lt;KeyValue&amp;lt;K, V&amp;gt;&amp;gt; waitUntilMinKeyValueRecordsReceived(final Properties consumerConfig,&lt;br/&gt;
                                                                                   final String topic,&lt;br/&gt;
                                                                                   final int expectedNumRecords) throws InterruptedException {&lt;br/&gt;
@@ -352,7 +390,7 @@ public boolean conditionMet() {&lt;br/&gt;
         while (totalPollTimeMs &amp;lt; waitTime &amp;amp;&amp;amp;&lt;br/&gt;
             continueConsuming(consumedValues.size(), maxMessages)) {&lt;br/&gt;
             totalPollTimeMs += pollIntervalMs;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;K, V&amp;gt; records = consumer.poll(pollIntervalMs);&lt;br/&gt;
+            final ConsumerRecords&amp;lt;K, V&amp;gt; records = poll(consumer, pollIntervalMs);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             for (final ConsumerRecord&amp;lt;K, V&amp;gt; record : records) {&lt;br/&gt;
                 consumedValues.add(new KeyValue&amp;lt;&amp;gt;(record.key(), record.value()));&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/perf/SimpleBenchmark.java b/streams/src/test/java/org/apache/kafka/streams/perf/SimpleBenchmark.java&lt;br/&gt;
index d956f278c50..9cd68572962 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/perf/SimpleBenchmark.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/perf/SimpleBenchmark.java&lt;br/&gt;
@@ -62,6 +62,8 @@&lt;br/&gt;
 import java.util.concurrent.CountDownLatch;&lt;br/&gt;
 import java.util.concurrent.TimeUnit;&lt;/p&gt;

&lt;p&gt;+import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;&lt;br/&gt;
+&lt;br/&gt;
 /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Class that provides support for a series of benchmarks. It is usually driven by&lt;/li&gt;
	&lt;li&gt;tests/kafkatest/benchmarks/streams/streams_simple_benchmark_test.py.&lt;br/&gt;
@@ -334,7 +336,7 @@ private void consumeAndProduce(final String topic) {&lt;br/&gt;
             consumer.seekToBeginning(partitions);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             while (true) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;Integer, byte[]&amp;gt; records = consumer.poll(POLL_MS);&lt;br/&gt;
+                final ConsumerRecords&amp;lt;Integer, byte[]&amp;gt; records = poll(consumer, POLL_MS);&lt;br/&gt;
                 if (records.isEmpty()) {&lt;br/&gt;
                     if (processedRecords == numRecords) {&lt;br/&gt;
                         break;&lt;br/&gt;
@@ -372,7 +374,7 @@ private void consume(final String topic) {&lt;br/&gt;
             consumer.seekToBeginning(partitions);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             while (true) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;Integer, byte[]&amp;gt; records = consumer.poll(POLL_MS);&lt;br/&gt;
+                final ConsumerRecords&amp;lt;Integer, byte[]&amp;gt; records = poll(consumer, POLL_MS);&lt;br/&gt;
                 if (records.isEmpty()) {&lt;br/&gt;
                     if (processedRecords == numRecords) {&lt;br/&gt;
                         break;&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImplTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImplTest.java&lt;br/&gt;
index d19e63e0543..7935271cdf9 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImplTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImplTest.java&lt;br/&gt;
@@ -79,6 +79,14 @@&lt;br/&gt;
     private final TopicPartition t2 = new TopicPartition(&quot;t2&quot;, 1);&lt;br/&gt;
     private final TopicPartition t3 = new TopicPartition(&quot;t3&quot;, 1);&lt;br/&gt;
     private final TopicPartition t4 = new TopicPartition(&quot;t4&quot;, 1);&lt;br/&gt;
+&lt;br/&gt;
+    private final GlobalStateManagerImpl.IsRunning alwaysRunning = new GlobalStateManagerImpl.IsRunning() 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+        @Override+        public boolean check() {
+            return true;
+        }+    }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;;&lt;br/&gt;
+&lt;br/&gt;
     private GlobalStateManagerImpl stateManager;&lt;br/&gt;
     private StateDirectory stateDirectory;&lt;br/&gt;
     private StreamsConfig streamsConfig;&lt;br/&gt;
@@ -119,7 +127,8 @@ public void before() throws IOException {&lt;br/&gt;
             consumer,&lt;br/&gt;
             stateDirectory,&lt;br/&gt;
             stateRestoreListener,&lt;/p&gt;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;streamsConfig);&lt;br/&gt;
+            streamsConfig,&lt;br/&gt;
+            alwaysRunning);&lt;br/&gt;
         processorContext = new InternalMockProcessorContext(stateDirectory.globalStateDir(), streamsConfig);&lt;br/&gt;
         stateManager.setGlobalProcessorContext(processorContext);&lt;br/&gt;
         checkpointFile = new File(stateManager.baseDir(), ProcessorStateManager.CHECKPOINT_FILE_NAME);&lt;br/&gt;
@@ -496,12 +505,20 @@ public void shouldCheckpointRestoredOffsetsToFile() throws IOException {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @Test&lt;br/&gt;
     public void shouldThrowLockExceptionIfIOExceptionCaughtWhenTryingToLockStateDir() {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;stateManager = new GlobalStateManagerImpl(new LogContext(&quot;mock&quot;), topology, consumer, new StateDirectory(streamsConfig, time) {&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public boolean lockGlobalState() throws IOException 
{
-                throw new IOException(&quot;KABOOM!&quot;);
-            }&lt;/li&gt;
	&lt;li&gt;}, stateRestoreListener, streamsConfig);&lt;br/&gt;
+        stateManager = new GlobalStateManagerImpl(&lt;br/&gt;
+            new LogContext(&quot;mock&quot;),&lt;br/&gt;
+            topology,&lt;br/&gt;
+            consumer,&lt;br/&gt;
+            new StateDirectory(streamsConfig, time) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+                @Override+                public boolean lockGlobalState() throws IOException {
+                    throw new IOException(&quot;KABOOM!&quot;);
+                }+            }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;,&lt;br/&gt;
+            stateRestoreListener,&lt;br/&gt;
+            streamsConfig,&lt;br/&gt;
+            alwaysRunning&lt;br/&gt;
+        );&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         try {&lt;br/&gt;
             stateManager.initialize();&lt;br/&gt;
@@ -538,7 +555,8 @@ public void shouldRetryWhenEndOffsetsThrowsTimeoutException() &lt;/p&gt;
{
                 consumer,
                 stateDirectory,
                 stateRestoreListener,
-                streamsConfig);
+                streamsConfig,
+                alwaysRunning);
         } catch (final StreamsException expected) {
             assertEquals(numberOfCalls.get(), retries);
         }&lt;br/&gt;
@@ -571,7 +589,8 @@ public void shouldRetryWhenPartitionsForThrowsTimeoutException() {                 consumer,                 stateDirectory,                 stateRestoreListener,-                streamsConfig);+                streamsConfig,+                alwaysRunning);         }
&lt;p&gt; catch (final StreamsException expected) &lt;/p&gt;
{
             assertEquals(numberOfCalls.get(), retries);
         }
&lt;p&gt;diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java&lt;br/&gt;
index 605ab337983..54ea1ce7329 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java&lt;br/&gt;
@@ -63,6 +63,7 @@&lt;br/&gt;
 import java.util.concurrent.atomic.AtomicBoolean;&lt;/p&gt;

&lt;p&gt; import static java.util.Collections.singleton;&lt;br/&gt;
+import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;&lt;br/&gt;
 import static org.hamcrest.CoreMatchers.equalTo;&lt;br/&gt;
 import static org.hamcrest.MatcherAssert.assertThat;&lt;br/&gt;
 import static org.junit.Assert.assertEquals;&lt;br/&gt;
@@ -189,7 +190,7 @@ public void testUpdate() throws IOException {&lt;br/&gt;
         }&lt;/p&gt;

&lt;p&gt;         restoreStateConsumer.seekToBeginning(partition);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;task.update(partition2, restoreStateConsumer.poll(100).records(partition2));&lt;br/&gt;
+        task.update(partition2, poll(restoreStateConsumer, 100).records(partition2));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         StandbyContextImpl context = (StandbyContextImpl) task.context();&lt;br/&gt;
         MockStateStore store1 = (MockStateStore) context.getStateMgr().getStore(storeName1);&lt;br/&gt;
@@ -246,7 +247,7 @@ public void testUpdateKTable() throws IOException {&lt;br/&gt;
         }&lt;/p&gt;

&lt;p&gt;         // The commit offset is at 0L. Records should not be processed&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;List&amp;lt;ConsumerRecord&amp;lt;byte[], byte[]&amp;gt;&amp;gt; remaining = task.update(globalTopicPartition, restoreStateConsumer.poll(100).records(globalTopicPartition));&lt;br/&gt;
+        List&amp;lt;ConsumerRecord&amp;lt;byte[], byte[]&amp;gt;&amp;gt; remaining = task.update(globalTopicPartition, poll(restoreStateConsumer, 100).records(globalTopicPartition));&lt;br/&gt;
         assertEquals(5, remaining.size());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         committedOffsets.put(new TopicPartition(globalTopicPartition.topic(), globalTopicPartition.partition()), new OffsetAndMetadata(10L));&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/tests/BrokerCompatibilityTest.java b/streams/src/test/java/org/apache/kafka/streams/tests/BrokerCompatibilityTest.java&lt;br/&gt;
index e897088beca..c420d9878a4 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/tests/BrokerCompatibilityTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/tests/BrokerCompatibilityTest.java&lt;br/&gt;
@@ -42,6 +42,8 @@&lt;br/&gt;
 import java.util.Properties;&lt;br/&gt;
 import java.util.concurrent.TimeUnit;&lt;/p&gt;

&lt;p&gt;+import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;&lt;br/&gt;
+&lt;br/&gt;
 public class BrokerCompatibilityTest {&lt;/p&gt;

&lt;p&gt;     private static final String SOURCE_TOPIC = &quot;brokerCompatibilitySourceTopic&quot;;&lt;br/&gt;
@@ -153,7 +155,7 @@ private static void loopUntilRecordReceived(final String kafka, final boolean eo&lt;br/&gt;
             consumer.subscribe(Collections.singletonList(SINK_TOPIC));&lt;/p&gt;

&lt;p&gt;             while (true) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(100);&lt;br/&gt;
+                final ConsumerRecords&amp;lt;String, String&amp;gt; records = poll(consumer, 100);&lt;br/&gt;
                 for (final ConsumerRecord&amp;lt;String, String&amp;gt; record : records) {&lt;br/&gt;
                     if (record.key().equals(&quot;key&quot;) &amp;amp;&amp;amp; record.value().equals(&quot;1&quot;)) {&lt;br/&gt;
                         return;&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/tests/EosTestDriver.java b/streams/src/test/java/org/apache/kafka/streams/tests/EosTestDriver.java&lt;br/&gt;
index 752cdd696ed..513d592fa38 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/tests/EosTestDriver.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/tests/EosTestDriver.java&lt;br/&gt;
@@ -52,6 +52,8 @@&lt;br/&gt;
 import java.util.Random;&lt;br/&gt;
 import java.util.Set;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;&lt;br/&gt;
+&lt;br/&gt;
 public class EosTestDriver extends SmokeTestUtil {&lt;/p&gt;

&lt;p&gt;     private static final int MAX_NUMBER_OF_KEYS = 100;&lt;br/&gt;
@@ -254,7 +256,7 @@ private static void ensureStreamsApplicationDown(final String kafka) &lt;/p&gt;
{
                 topics.add(&quot;repartition&quot;);
             }
&lt;p&gt;             consumer.subscribe(topics);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;consumer.poll(0);&lt;br/&gt;
+            poll(consumer, 0);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             final Set&amp;lt;TopicPartition&amp;gt; partitions = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
             for (final String topic : topics) {&lt;br/&gt;
@@ -284,7 +286,7 @@ private static void ensureStreamsApplicationDown(final String kafka) {&lt;br/&gt;
         long maxWaitTime = System.currentTimeMillis() + MAX_IDLE_TIME_MS;&lt;br/&gt;
         boolean allRecordsReceived = false;&lt;br/&gt;
         while (!allRecordsReceived &amp;amp;&amp;amp; System.currentTimeMillis() &amp;lt; maxWaitTime) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; receivedRecords = consumer.poll(100);&lt;br/&gt;
+            final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; receivedRecords = poll(consumer, 100);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             for (final ConsumerRecord&amp;lt;byte[], byte[]&amp;gt; record : receivedRecords) {&lt;br/&gt;
                 maxWaitTime = System.currentTimeMillis() + MAX_IDLE_TIME_MS;&lt;br/&gt;
@@ -591,7 +593,7 @@ public void onCompletion(final RecordMetadata metadata, final Exception exceptio&lt;/p&gt;

&lt;p&gt;         long maxWaitTime = System.currentTimeMillis() + MAX_IDLE_TIME_MS;&lt;br/&gt;
         while (!partitions.isEmpty() &amp;amp;&amp;amp; System.currentTimeMillis() &amp;lt; maxWaitTime) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(100);&lt;br/&gt;
+            final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 100);&lt;br/&gt;
             if (records.isEmpty()) {&lt;br/&gt;
                 System.out.println(&quot;No data received.&quot;);&lt;br/&gt;
                 for (final TopicPartition tp : partitions) {&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestDriver.java b/streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestDriver.java&lt;br/&gt;
index 50330a08e61..74eac3f156c 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestDriver.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestDriver.java&lt;br/&gt;
@@ -47,6 +47,8 @@&lt;br/&gt;
 import java.util.Set;&lt;br/&gt;
 import java.util.concurrent.TimeUnit;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;&lt;br/&gt;
+&lt;br/&gt;
 public class SmokeTestDriver extends SmokeTestUtil {&lt;/p&gt;

&lt;p&gt;     public static final int MAX_RECORD_EMPTY_RETRIES = 60;&lt;br/&gt;
@@ -289,7 +291,7 @@ public static void verify(String kafka, Map&amp;lt;String, Set&amp;lt;Integer&amp;gt;&amp;gt; allData, int m&lt;br/&gt;
         int retry = 0;&lt;br/&gt;
         final long start = System.currentTimeMillis();&lt;br/&gt;
         while (System.currentTimeMillis() - start &amp;lt; TimeUnit.MINUTES.toMillis(6)) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);&lt;br/&gt;
+            ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);&lt;br/&gt;
             if (records.isEmpty() &amp;amp;&amp;amp; recordsProcessed &amp;gt;= recordsGenerated) {&lt;br/&gt;
                 if (verifyMin(min, allData, false)&lt;br/&gt;
                     &amp;amp;&amp;amp; verifyMax(max, allData, false)&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/tools/StreamsResetterTest.java b/streams/src/test/java/org/apache/kafka/streams/tools/StreamsResetterTest.java&lt;br/&gt;
index ad19f32fd1d..49f699ec658 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/tools/StreamsResetterTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/tools/StreamsResetterTest.java&lt;br/&gt;
@@ -40,6 +40,7 @@&lt;br/&gt;
 import java.util.Set;&lt;br/&gt;
 import java.util.concurrent.ExecutionException;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;&lt;br/&gt;
 import static org.junit.Assert.assertEquals;&lt;br/&gt;
 import static org.junit.Assert.fail;&lt;/p&gt;

&lt;p&gt;@@ -74,7 +75,7 @@ public void testResetToSpecificOffsetWhenBetweenBeginningAndEndOffset() &lt;/p&gt;
{
 
         streamsResetter.resetOffsetsTo(consumer, inputTopicPartitions, 2L);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);
         assertEquals(3, records.count());
     }

&lt;p&gt;@@ -90,7 +91,7 @@ public void testResetToSpecificOffsetWhenBeforeBeginningOffset() &lt;/p&gt;
{
 
         streamsResetter.resetOffsetsTo(consumer, inputTopicPartitions, 2L);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);
         assertEquals(2, records.count());
     }

&lt;p&gt;@@ -106,7 +107,7 @@ public void testResetToSpecificOffsetWhenAfterEndOffset() &lt;/p&gt;
{
 
         streamsResetter.resetOffsetsTo(consumer, inputTopicPartitions, 4L);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);
         assertEquals(2, records.count());
     }

&lt;p&gt;@@ -122,7 +123,7 @@ public void testShiftOffsetByWhenBetweenBeginningAndEndOffset() &lt;/p&gt;
{
 
         streamsResetter.shiftOffsetsBy(consumer, inputTopicPartitions, 3L);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);
         assertEquals(2, records.count());
     }

&lt;p&gt;@@ -138,7 +139,7 @@ public void testShiftOffsetByWhenBeforeBeginningOffset() &lt;/p&gt;
{
 
         streamsResetter.shiftOffsetsBy(consumer, inputTopicPartitions, -3L);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);
         assertEquals(5, records.count());
     }

&lt;p&gt;@@ -154,7 +155,7 @@ public void testShiftOffsetByWhenAfterEndOffset() &lt;/p&gt;
{
 
         streamsResetter.shiftOffsetsBy(consumer, inputTopicPartitions, 5L);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);
         assertEquals(2, records.count());
     }

&lt;p&gt;@@ -172,7 +173,7 @@ public void testResetUsingPlanWhenBetweenBeginningAndEndOffset() &lt;/p&gt;
{
         topicPartitionsAndOffset.put(topicPartition, 3L);
         streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);
         assertEquals(2, records.count());
     }

&lt;p&gt;@@ -190,7 +191,7 @@ public void testResetUsingPlanWhenBeforeBeginningOffset() &lt;/p&gt;
{
         topicPartitionsAndOffset.put(topicPartition, 1L);
         streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);
         assertEquals(2, records.count());
     }

&lt;p&gt;@@ -208,7 +209,7 @@ public void testResetUsingPlanWhenAfterEndOffset() &lt;/p&gt;
{
         topicPartitionsAndOffset.put(topicPartition, 5L);
         streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);
         assertEquals(2, records.count());
     }

&lt;p&gt;@@ -226,7 +227,7 @@ public void shouldSeekToEndOffset() &lt;/p&gt;
{
         intermediateTopicPartitions.add(topicPartition);
         streamsResetter.maybeSeekToEnd(&quot;g1&quot;, consumer, intermediateTopicPartitions);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);
         assertEquals(2, records.count());
     }

&lt;p&gt;diff --git a/streams/test-utils/src/main/java/org/apache/kafka/streams/TopologyTestDriver.java b/streams/test-utils/src/main/java/org/apache/kafka/streams/TopologyTestDriver.java&lt;br/&gt;
index 7343d59e013..f6bbc4b5c27 100644&lt;br/&gt;
&amp;#8212; a/streams/test-utils/src/main/java/org/apache/kafka/streams/TopologyTestDriver.java&lt;br/&gt;
+++ b/streams/test-utils/src/main/java/org/apache/kafka/streams/TopologyTestDriver.java&lt;br/&gt;
@@ -309,7 +309,13 @@ public void onRestoreEnd(final TopicPartition topicPartition, final String store&lt;br/&gt;
                 consumer,&lt;br/&gt;
                 stateDirectory,&lt;br/&gt;
                 stateRestoreListener,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;streamsConfig);&lt;br/&gt;
+                streamsConfig,&lt;br/&gt;
+                new GlobalStateManagerImpl.IsRunning() 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+                    @Override+                    public boolean check() {
+                        return true;
+                    }+                }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;);&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             final GlobalProcessorContextImpl globalProcessorContext&lt;br/&gt;
                 = new GlobalProcessorContextImpl(streamsConfig, globalStateManager, streamsMetrics, cache);&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16480778" author="githubbot" created="Fri, 18 May 2018 15:05:12 +0000"  >&lt;p&gt;guozhangwang closed pull request #5035: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5697&quot; title=&quot;StreamThread.shutdown() need to interrupt the stream threads to break the loop&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5697&quot;&gt;&lt;del&gt;KAFKA-5697&lt;/del&gt;&lt;/a&gt;: Revert streams wakeup&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5035&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5035&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/streams/src/main/java/org/apache/kafka/streams/errors/ShutdownException.java b/streams/src/main/java/org/apache/kafka/streams/errors/ShutdownException.java&lt;br/&gt;
deleted file mode 100644&lt;br/&gt;
index d404642793c..00000000000&lt;br/&gt;
&amp;#8212; a/streams/src/main/java/org/apache/kafka/streams/errors/ShutdownException.java&lt;br/&gt;
+++ /dev/null&lt;br/&gt;
@@ -1,31 +0,0 @@&lt;br/&gt;
-/*&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Licensed to the Apache Software Foundation (ASF) under one or more&lt;/li&gt;
	&lt;li&gt;* contributor license agreements. See the NOTICE file distributed with&lt;/li&gt;
	&lt;li&gt;* this work for additional information regarding copyright ownership.&lt;/li&gt;
	&lt;li&gt;* The ASF licenses this file to You under the Apache License, Version 2.0&lt;/li&gt;
	&lt;li&gt;* (the &quot;License&quot;); you may not use this file except in compliance with&lt;/li&gt;
	&lt;li&gt;* the License. You may obtain a copy of the License at&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;*    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* Unless required by applicable law or agreed to in writing, software&lt;/li&gt;
	&lt;li&gt;* distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;/li&gt;
	&lt;li&gt;* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;/li&gt;
	&lt;li&gt;* See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;* limitations under the License.&lt;/li&gt;
	&lt;li&gt;*/&lt;br/&gt;
-package org.apache.kafka.streams.errors;&lt;br/&gt;
-&lt;br/&gt;
-public class ShutdownException extends StreamsException {&lt;/li&gt;
	&lt;li&gt;public ShutdownException(final String message) 
{
-        super(message);
-    }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;public ShutdownException(final String message, final Throwable throwable) 
{
-        super(message, throwable);
-    }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;public ShutdownException(final Throwable throwable) 
{
-        super(throwable);
-    }
&lt;p&gt;-}&lt;br/&gt;
diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/ConsumerUtils.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/ConsumerUtils.java&lt;br/&gt;
deleted file mode 100644&lt;br/&gt;
index 8b912579b9a..00000000000&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/main/java/org/apache/kafka/streams/processor/internals/ConsumerUtils.java&lt;br/&gt;
+++ /dev/null&lt;br/&gt;
@@ -1,38 +0,0 @@&lt;br/&gt;
-/*&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;* Licensed to the Apache Software Foundation (ASF) under one or more&lt;/li&gt;
	&lt;li&gt;* contributor license agreements. See the NOTICE file distributed with&lt;/li&gt;
	&lt;li&gt;* this work for additional information regarding copyright ownership.&lt;/li&gt;
	&lt;li&gt;* The ASF licenses this file to You under the Apache License, Version 2.0&lt;/li&gt;
	&lt;li&gt;* (the &quot;License&quot;); you may not use this file except in compliance with&lt;/li&gt;
	&lt;li&gt;* the License. You may obtain a copy of the License at&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;*    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* Unless required by applicable law or agreed to in writing, software&lt;/li&gt;
	&lt;li&gt;* distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;/li&gt;
	&lt;li&gt;* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;/li&gt;
	&lt;li&gt;* See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;* limitations under the License.&lt;/li&gt;
	&lt;li&gt;*/&lt;br/&gt;
-package org.apache.kafka.streams.processor.internals;&lt;br/&gt;
-&lt;br/&gt;
-import org.apache.kafka.clients.consumer.Consumer;&lt;br/&gt;
-import org.apache.kafka.clients.consumer.ConsumerRecord;&lt;br/&gt;
-import org.apache.kafka.clients.consumer.ConsumerRecords;&lt;br/&gt;
-import org.apache.kafka.common.TopicPartition;&lt;br/&gt;
-import org.apache.kafka.common.errors.WakeupException;&lt;br/&gt;
-&lt;br/&gt;
-import java.util.Collections;&lt;br/&gt;
-import java.util.List;&lt;br/&gt;
-&lt;br/&gt;
-public final class ConsumerUtils {&lt;/li&gt;
	&lt;li&gt;private ConsumerUtils() {}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;public static &amp;lt;K, V&amp;gt; ConsumerRecords&amp;lt;K, V&amp;gt; poll(final Consumer&amp;lt;K, V&amp;gt; consumer, final long maxDurationMs) {&lt;/li&gt;
	&lt;li&gt;try 
{
-            return consumer.poll(maxDurationMs);
-        }
&lt;p&gt; catch (final WakeupException e) &lt;/p&gt;
{
-            return new ConsumerRecords&amp;lt;&amp;gt;(Collections.&amp;lt;TopicPartition, List&amp;lt;ConsumerRecord&amp;lt;K, V&amp;gt;&amp;gt;&amp;gt;emptyMap());
-        }&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-}&lt;br/&gt;
diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java&lt;br/&gt;
index 017f2da198f..e8ec5e9fe5f 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java&lt;br/&gt;
@@ -23,14 +23,12 @@&lt;br/&gt;
 import org.apache.kafka.common.PartitionInfo;&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition;&lt;br/&gt;
 import org.apache.kafka.common.errors.TimeoutException;&lt;br/&gt;
-import org.apache.kafka.common.errors.WakeupException;&lt;br/&gt;
 import org.apache.kafka.common.utils.LogContext;&lt;br/&gt;
 import org.apache.kafka.common.utils.Utils;&lt;br/&gt;
 import org.apache.kafka.streams.KeyValue;&lt;br/&gt;
 import org.apache.kafka.streams.StreamsConfig;&lt;br/&gt;
 import org.apache.kafka.streams.errors.LockException;&lt;br/&gt;
 import org.apache.kafka.streams.errors.ProcessorStateException;&lt;br/&gt;
-import org.apache.kafka.streams.errors.ShutdownException;&lt;br/&gt;
 import org.apache.kafka.streams.errors.StreamsException;&lt;br/&gt;
 import org.apache.kafka.streams.processor.BatchingStateRestoreCallback;&lt;br/&gt;
 import org.apache.kafka.streams.processor.StateRestoreCallback;&lt;br/&gt;
@@ -48,8 +46,6 @@&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
 import java.util.Set;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;-import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;&lt;br/&gt;
-&lt;br/&gt;
 /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;This class is responsible for the initialization, restoration, closing, flushing etc&lt;/li&gt;
	&lt;li&gt;of Global State Stores. There is only ever 1 instance of this class per Application Instance.&lt;br/&gt;
@@ -64,15 +60,13 @@&lt;br/&gt;
     private InternalProcessorContext processorContext;&lt;br/&gt;
     private final int retries;&lt;br/&gt;
     private final long retryBackoffMs;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final IsRunning isRunning;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     public GlobalStateManagerImpl(final LogContext logContext,&lt;br/&gt;
                                   final ProcessorTopology topology,&lt;br/&gt;
                                   final Consumer&amp;lt;byte[], byte[]&amp;gt; globalConsumer,&lt;br/&gt;
                                   final StateDirectory stateDirectory,&lt;br/&gt;
                                   final StateRestoreListener stateRestoreListener,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final StreamsConfig config,&lt;/li&gt;
	&lt;li&gt;final IsRunning isRunning) {&lt;br/&gt;
+                                  final StreamsConfig config) 
{
         super(stateDirectory.globalStateDir());
 
         this.log = logContext.logger(GlobalStateManagerImpl.class);
@@ -82,11 +76,6 @@ public GlobalStateManagerImpl(final LogContext logContext,
         this.stateRestoreListener = stateRestoreListener;
         this.retries = config.getInt(StreamsConfig.RETRIES_CONFIG);
         this.retryBackoffMs = config.getLong(StreamsConfig.RETRY_BACKOFF_MS_CONFIG);
-        this.isRunning = isRunning;
-    }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;public interface IsRunning 
{
-        boolean check();
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @Override&lt;br/&gt;
@@ -211,13 +200,6 @@ public void register(final StateStore store,&lt;br/&gt;
             try &lt;/p&gt;
{
                 partitionInfos = globalConsumer.partitionsFor(sourceTopic);
                 break;
-            }
&lt;p&gt; catch (final WakeupException wakeupException) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (isRunning.check()) 
{
-                    // note we may decide later that this condition is ok and just let the retry loop continue
-                    throw new IllegalStateException(&quot;Got unexpected WakeupException during initialization.&quot;, wakeupException);
-                }
&lt;p&gt; else &lt;/p&gt;
{
-                    throw new ShutdownException(&quot;Shutting down from fetching partitions&quot;);
-                }
&lt;p&gt;             } catch (final TimeoutException retryableException) {&lt;br/&gt;
                 if (++attempts &amp;gt; retries) {&lt;br/&gt;
                     log.error(&quot;Failed to get partitions for topic {} after {} retry attempts due to timeout. &quot; +&lt;br/&gt;
@@ -268,20 +250,19 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             long offset = globalConsumer.position(topicPartition);&lt;br/&gt;
             final Long highWatermark = highWatermarks.get(topicPartition);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final BatchingStateRestoreCallback stateRestoreAdapter =&lt;/li&gt;
	&lt;li&gt;(BatchingStateRestoreCallback) ((stateRestoreCallback instanceof BatchingStateRestoreCallback)&lt;/li&gt;
	&lt;li&gt;? stateRestoreCallback&lt;/li&gt;
	&lt;li&gt;: new WrappedBatchingStateRestoreCallback(stateRestoreCallback));&lt;br/&gt;
+            BatchingStateRestoreCallback&lt;br/&gt;
+                stateRestoreAdapter =&lt;br/&gt;
+                (BatchingStateRestoreCallback) ((stateRestoreCallback instanceof&lt;br/&gt;
+                                                     BatchingStateRestoreCallback)&lt;br/&gt;
+                                                ? stateRestoreCallback&lt;br/&gt;
+                                                : new WrappedBatchingStateRestoreCallback(stateRestoreCallback));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             stateRestoreListener.onRestoreStart(topicPartition, storeName, offset, highWatermark);&lt;br/&gt;
             long restoreCount = 0L;&lt;/p&gt;

&lt;p&gt;             while (offset &amp;lt; highWatermark) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (!isRunning.check()) 
{
-                    throw new ShutdownException(&quot;Streams is not running (any more)&quot;);
-                }
&lt;p&gt;                 try {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(globalConsumer, 100);&lt;br/&gt;
+                    final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = globalConsumer.poll(100);&lt;br/&gt;
                     final List&amp;lt;KeyValue&amp;lt;byte[], byte[]&amp;gt;&amp;gt; restoreRecords = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
                     for (ConsumerRecord&amp;lt;byte[], byte[]&amp;gt; record : records) {&lt;br/&gt;
                         if (record.key() != null) {&lt;br/&gt;
diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java&lt;br/&gt;
index 4b6bfb1fd65..112011f47b8 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java&lt;br/&gt;
@@ -29,7 +29,6 @@&lt;br/&gt;
 import org.apache.kafka.common.utils.Utils;&lt;br/&gt;
 import org.apache.kafka.streams.StreamsConfig;&lt;br/&gt;
 import org.apache.kafka.streams.errors.LockException;&lt;br/&gt;
-import org.apache.kafka.streams.errors.ShutdownException;&lt;br/&gt;
 import org.apache.kafka.streams.errors.StreamsException;&lt;br/&gt;
 import org.apache.kafka.streams.processor.StateRestoreListener;&lt;br/&gt;
 import org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl;&lt;br/&gt;
@@ -43,7 +42,6 @@&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
 import java.util.Set;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;-import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;&lt;br/&gt;
 import static org.apache.kafka.streams.processor.internals.GlobalStreamThread.State.DEAD;&lt;br/&gt;
 import static org.apache.kafka.streams.processor.internals.GlobalStreamThread.State.PENDING_SHUTDOWN;&lt;/p&gt;

&lt;p&gt;@@ -108,10 +106,6 @@ public boolean isRunning() &lt;/p&gt;
{
             return equals(RUNNING);
         }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public boolean isStarting() 
{
-            return equals(CREATED);
-        }
&lt;p&gt;-&lt;br/&gt;
         @Override&lt;br/&gt;
         public boolean isValidTransition(final ThreadStateTransitionValidator newState) {&lt;br/&gt;
             final State tmpState = (State) newState;&lt;br/&gt;
@@ -179,12 +173,6 @@ public boolean stillRunning() {&lt;br/&gt;
         }&lt;br/&gt;
     }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private boolean stillStarting() {&lt;/li&gt;
	&lt;li&gt;synchronized (stateLock) 
{
-            return state.isStarting();
-        }&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;br/&gt;
     public GlobalStreamThread(final ProcessorTopology topology,&lt;br/&gt;
                               final StreamsConfig config,&lt;br/&gt;
                               final Consumer&amp;lt;byte[], byte[]&amp;gt; globalConsumer,&lt;br/&gt;
@@ -247,7 +235,7 @@ void initialize() {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         void pollAndUpdate() {&lt;br/&gt;
             try {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; received = poll(globalConsumer, pollMs);&lt;br/&gt;
+                final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; received = globalConsumer.poll(pollMs);&lt;br/&gt;
                 for (final ConsumerRecord&amp;lt;byte[], byte[]&amp;gt; record : received) 
{
                     stateMaintainer.update(record);
                 }
&lt;p&gt;@@ -278,19 +266,7 @@ public void close() throws IOException {&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @Override&lt;br/&gt;
     public void run() {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final StateConsumer stateConsumer;&lt;/li&gt;
	&lt;li&gt;try 
{
-            stateConsumer = initialize();
-        }
&lt;p&gt; catch (final ShutdownException e) &lt;/p&gt;
{
-            log.info(&quot;Shutting down from initialization&quot;);
-            // Almost certainly, we arrived here because the state is already PENDING_SHUTDOWN, but it&apos;s harmless to
-            // just make sure
-            setState(State.PENDING_SHUTDOWN);
-            setState(State.DEAD);
-            streamsMetrics.removeAllThreadLevelSensors();
-            log.info(&quot;Shutdown complete&quot;);
-            return;
-        }
&lt;p&gt;+        final StateConsumer stateConsumer = initialize();&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         if (stateConsumer == null) {&lt;br/&gt;
             // during initialization, the caller thread would wait for the state consumer&lt;br/&gt;
@@ -342,14 +318,7 @@ private StateConsumer initialize() {&lt;br/&gt;
                 globalConsumer,&lt;br/&gt;
                 stateDirectory,&lt;br/&gt;
                 stateRestoreListener,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;config,&lt;/li&gt;
	&lt;li&gt;new GlobalStateManagerImpl.IsRunning() {&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public boolean check() 
{
-                        return stillStarting() || stillRunning();
-                    }&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;);&lt;br/&gt;
+                config);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             final GlobalProcessorContextImpl globalProcessorContext = new GlobalProcessorContextImpl(&lt;br/&gt;
                 config,&lt;br/&gt;
@@ -402,7 +371,6 @@ public void shutdown() &lt;/p&gt;
{
         // one could call shutdown() multiple times, so ignore subsequent calls
         // if already shutting down or dead
         setState(PENDING_SHUTDOWN);
-        globalConsumer.wakeup();
     }

&lt;p&gt;     public Map&amp;lt;MetricName, Metric&amp;gt; consumerMetrics() {&lt;br/&gt;
diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreChangelogReader.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreChangelogReader.java&lt;br/&gt;
index 9b67fc4263c..5fcba76570e 100644&lt;br/&gt;
&amp;#8212; a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreChangelogReader.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreChangelogReader.java&lt;br/&gt;
@@ -40,8 +40,6 @@&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
 import java.util.Set;&lt;/p&gt;

&lt;p&gt;-import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;&lt;br/&gt;
-&lt;br/&gt;
 public class StoreChangelogReader implements ChangelogReader {&lt;/p&gt;

&lt;p&gt;     private final Logger log;&lt;br/&gt;
@@ -83,7 +81,7 @@ public void register(final StateRestorer restorer) {&lt;/p&gt;

&lt;p&gt;         final Set&amp;lt;TopicPartition&amp;gt; restoringPartitions = new HashSet&amp;lt;&amp;gt;(needsRestoring.keySet());&lt;br/&gt;
         try {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; allRecords = poll(restoreConsumer, 10);&lt;br/&gt;
+            final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; allRecords = restoreConsumer.poll(10);&lt;br/&gt;
             for (final TopicPartition partition : restoringPartitions) 
{
                 restorePartition(allRecords, partition, active.restoringTaskFor(partition));
             }
&lt;p&gt;diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java&lt;br/&gt;
index ddefd9ce0a5..3080d2e1583 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java&lt;br/&gt;
@@ -65,7 +65,6 @@&lt;br/&gt;
 import java.util.concurrent.atomic.AtomicInteger;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import static java.util.Collections.singleton;&lt;br/&gt;
-import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;&lt;/p&gt;

&lt;p&gt; public class StreamThread extends Thread {&lt;/p&gt;

&lt;p&gt;@@ -832,7 +831,7 @@ long runOnce(final long recordsProcessedBeforeCommit) {&lt;br/&gt;
         ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = null;&lt;/p&gt;

&lt;p&gt;         try &lt;/p&gt;
{
-            records = poll(consumer, pollTimeMs);
+            records = consumer.poll(pollTimeMs);
         }
&lt;p&gt; catch (final InvalidOffsetException e) &lt;/p&gt;
{
             resetInvalidOffsets(e);
         }
&lt;p&gt;@@ -1059,7 +1058,7 @@ private void maybeUpdateStandbyTasks(final long now) {&lt;br/&gt;
             }&lt;/p&gt;

&lt;p&gt;             try {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(restoreConsumer, 0);&lt;br/&gt;
+                final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = restoreConsumer.poll(0);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;                 if (!records.isEmpty()) {&lt;br/&gt;
                     for (final TopicPartition partition : records.partitions()) {&lt;br/&gt;
@@ -1124,8 +1123,6 @@ private long computeLatency() {&lt;br/&gt;
     public void shutdown() {&lt;br/&gt;
         log.info(&quot;Informed to shut down&quot;);&lt;br/&gt;
         final State oldState = setState(State.PENDING_SHUTDOWN);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;consumer.wakeup();&lt;/li&gt;
	&lt;li&gt;restoreConsumer.wakeup();&lt;br/&gt;
         if (oldState == State.CREATED) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {             // The thread may not have been started. Take responsibility for shutting down             completeShutdown(true);@@ -1229,10 +1226,10 @@ TaskManager taskManager() {
                 result.putAll(producerMetrics);
             }         }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt; else {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;// When EOS is turned on, each task will has its own producer client&lt;br/&gt;
+            // When EOS is turned on, each task will have its own producer client&lt;br/&gt;
             // and the producer object passed in here will be null. We would then iterate through&lt;br/&gt;
             // all the active tasks and add their metrics to the output metrics map.&lt;/li&gt;
	&lt;li&gt;for (StreamTask task: taskManager.activeTasks().values()) {&lt;br/&gt;
+            for (final StreamTask task: taskManager.activeTasks().values()) 
{
                 final Map&amp;lt;MetricName, ? extends Metric&amp;gt; taskProducerMetrics = task.getProducer().metrics();
                 result.putAll(taskProducerMetrics);
             }
&lt;p&gt;diff --git a/streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java b/streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java&lt;br/&gt;
index cdfc470c51b..904ebe2a611 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java&lt;br/&gt;
@@ -253,6 +253,7 @@ public void testGlobalThreadCloseWithoutConnectingToBroker() 
{
         // There&apos;s nothing to assert... We&apos;re testing that this operation actually completes.
     }&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+    @Ignore // this test cannot pass until we implement KIP-266&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testLocalThreadCloseWithoutConnectingToBroker() {&lt;br/&gt;
         final Properties props = new Properties();&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java b/streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java&lt;br/&gt;
index ec97f125ece..d306ee4607e 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java&lt;br/&gt;
@@ -51,8 +51,6 @@&lt;br/&gt;
 import java.util.concurrent.ExecutionException;&lt;br/&gt;
 import java.util.concurrent.Future;&lt;/p&gt;

&lt;p&gt;-import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;&lt;br/&gt;
-&lt;br/&gt;
 /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Utility functions to make integration testing more convenient.&lt;br/&gt;
  */&lt;br/&gt;
@@ -390,7 +388,7 @@ public boolean conditionMet() {&lt;br/&gt;
         while (totalPollTimeMs &amp;lt; waitTime &amp;amp;&amp;amp;&lt;br/&gt;
             continueConsuming(consumedValues.size(), maxMessages)) {&lt;br/&gt;
             totalPollTimeMs += pollIntervalMs;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;K, V&amp;gt; records = poll(consumer, pollIntervalMs);&lt;br/&gt;
+            final ConsumerRecords&amp;lt;K, V&amp;gt; records = consumer.poll(pollIntervalMs);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             for (final ConsumerRecord&amp;lt;K, V&amp;gt; record : records) {&lt;br/&gt;
                 consumedValues.add(new KeyValue&amp;lt;&amp;gt;(record.key(), record.value()));&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/perf/SimpleBenchmark.java b/streams/src/test/java/org/apache/kafka/streams/perf/SimpleBenchmark.java&lt;br/&gt;
index a660e6770bc..8187467aaa6 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/perf/SimpleBenchmark.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/perf/SimpleBenchmark.java&lt;br/&gt;
@@ -62,8 +62,6 @@&lt;br/&gt;
 import java.util.concurrent.CountDownLatch;&lt;br/&gt;
 import java.util.concurrent.TimeUnit;&lt;/p&gt;

&lt;p&gt;-import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;&lt;br/&gt;
-&lt;br/&gt;
 /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Class that provides support for a series of benchmarks. It is usually driven by&lt;/li&gt;
	&lt;li&gt;tests/kafkatest/benchmarks/streams/streams_simple_benchmark_test.py.&lt;br/&gt;
@@ -336,7 +334,7 @@ private void consumeAndProduce(final String topic) {&lt;br/&gt;
             consumer.seekToBeginning(partitions);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             while (true) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;Integer, byte[]&amp;gt; records = poll(consumer, POLL_MS);&lt;br/&gt;
+                final ConsumerRecords&amp;lt;Integer, byte[]&amp;gt; records = consumer.poll(POLL_MS);&lt;br/&gt;
                 if (records.isEmpty()) {&lt;br/&gt;
                     if (processedRecords == numRecords) {&lt;br/&gt;
                         break;&lt;br/&gt;
@@ -374,7 +372,7 @@ private void consume(final String topic) {&lt;br/&gt;
             consumer.seekToBeginning(partitions);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             while (true) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;Integer, byte[]&amp;gt; records = poll(consumer, POLL_MS);&lt;br/&gt;
+                final ConsumerRecords&amp;lt;Integer, byte[]&amp;gt; records = consumer.poll(POLL_MS);&lt;br/&gt;
                 if (records.isEmpty()) {&lt;br/&gt;
                     if (processedRecords == numRecords) {&lt;br/&gt;
                         break;&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImplTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImplTest.java&lt;br/&gt;
index 7935271cdf9..2ca9c211c1c 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImplTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImplTest.java&lt;br/&gt;
@@ -79,14 +79,6 @@&lt;br/&gt;
     private final TopicPartition t2 = new TopicPartition(&quot;t2&quot;, 1);&lt;br/&gt;
     private final TopicPartition t3 = new TopicPartition(&quot;t3&quot;, 1);&lt;br/&gt;
     private final TopicPartition t4 = new TopicPartition(&quot;t4&quot;, 1);&lt;br/&gt;
-&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;private final GlobalStateManagerImpl.IsRunning alwaysRunning = new GlobalStateManagerImpl.IsRunning() {&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public boolean check() 
{
-            return true;
-        }&lt;/li&gt;
	&lt;li&gt;};&lt;br/&gt;
-&lt;br/&gt;
     private GlobalStateManagerImpl stateManager;&lt;br/&gt;
     private StateDirectory stateDirectory;&lt;br/&gt;
     private StreamsConfig streamsConfig;&lt;br/&gt;
@@ -127,8 +119,7 @@ public void before() throws IOException {&lt;br/&gt;
             consumer,&lt;br/&gt;
             stateDirectory,&lt;br/&gt;
             stateRestoreListener,&lt;/li&gt;
	&lt;li&gt;streamsConfig,&lt;/li&gt;
	&lt;li&gt;alwaysRunning);&lt;br/&gt;
+            streamsConfig);&lt;br/&gt;
         processorContext = new InternalMockProcessorContext(stateDirectory.globalStateDir(), streamsConfig);&lt;br/&gt;
         stateManager.setGlobalProcessorContext(processorContext);&lt;br/&gt;
         checkpointFile = new File(stateManager.baseDir(), ProcessorStateManager.CHECKPOINT_FILE_NAME);&lt;br/&gt;
@@ -516,8 +507,7 @@ public boolean lockGlobalState() throws IOException {&lt;br/&gt;
                 }&lt;br/&gt;
             },&lt;br/&gt;
             stateRestoreListener,&lt;/li&gt;
	&lt;li&gt;streamsConfig,&lt;/li&gt;
	&lt;li&gt;alwaysRunning&lt;br/&gt;
+            streamsConfig&lt;br/&gt;
         );&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         try {&lt;br/&gt;
@@ -555,8 +545,7 @@ public void shouldRetryWhenEndOffsetsThrowsTimeoutException() &lt;/p&gt;
{
                 consumer,
                 stateDirectory,
                 stateRestoreListener,
-                streamsConfig,
-                alwaysRunning);
+                streamsConfig);
         } catch (final StreamsException expected) {
             assertEquals(numberOfCalls.get(), retries);
         }&lt;br/&gt;
@@ -589,8 +578,7 @@ public void shouldRetryWhenPartitionsForThrowsTimeoutException() {                 consumer,                 stateDirectory,                 stateRestoreListener,-                streamsConfig,-                alwaysRunning);+                streamsConfig);         }
&lt;p&gt; catch (final StreamsException expected) &lt;/p&gt;
{
             assertEquals(numberOfCalls.get(), retries);
         }
&lt;p&gt;diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java&lt;br/&gt;
index 486b35e7ea9..93d6a0d931b 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java&lt;br/&gt;
@@ -62,7 +62,6 @@&lt;br/&gt;
 import java.util.concurrent.atomic.AtomicBoolean;&lt;/p&gt;

&lt;p&gt; import static java.util.Collections.singleton;&lt;br/&gt;
-import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;&lt;br/&gt;
 import static org.hamcrest.CoreMatchers.equalTo;&lt;br/&gt;
 import static org.hamcrest.MatcherAssert.assertThat;&lt;br/&gt;
 import static org.junit.Assert.assertEquals;&lt;br/&gt;
@@ -189,7 +188,7 @@ public void testUpdate() throws IOException {&lt;br/&gt;
         }&lt;/p&gt;

&lt;p&gt;         restoreStateConsumer.seekToBeginning(partition);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;task.update(partition2, poll(restoreStateConsumer, 100).records(partition2));&lt;br/&gt;
+        task.update(partition2, restoreStateConsumer.poll(100).records(partition2));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         StandbyContextImpl context = (StandbyContextImpl) task.context();&lt;br/&gt;
         MockStateStore store1 = (MockStateStore) context.getStateMgr().getStore(storeName1);&lt;br/&gt;
@@ -246,7 +245,7 @@ public void testUpdateKTable() throws IOException {&lt;br/&gt;
         }&lt;/p&gt;

&lt;p&gt;         // The commit offset is at 0L. Records should not be processed&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;List&amp;lt;ConsumerRecord&amp;lt;byte[], byte[]&amp;gt;&amp;gt; remaining = task.update(globalTopicPartition, poll(restoreStateConsumer, 100).records(globalTopicPartition));&lt;br/&gt;
+        List&amp;lt;ConsumerRecord&amp;lt;byte[], byte[]&amp;gt;&amp;gt; remaining = task.update(globalTopicPartition, restoreStateConsumer.poll(100).records(globalTopicPartition));&lt;br/&gt;
         assertEquals(5, remaining.size());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         committedOffsets.put(new TopicPartition(globalTopicPartition.topic(), globalTopicPartition.partition()), new OffsetAndMetadata(10L));&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/tests/BrokerCompatibilityTest.java b/streams/src/test/java/org/apache/kafka/streams/tests/BrokerCompatibilityTest.java&lt;br/&gt;
index c420d9878a4..e897088beca 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/tests/BrokerCompatibilityTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/tests/BrokerCompatibilityTest.java&lt;br/&gt;
@@ -42,8 +42,6 @@&lt;br/&gt;
 import java.util.Properties;&lt;br/&gt;
 import java.util.concurrent.TimeUnit;&lt;/p&gt;

&lt;p&gt;-import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;&lt;br/&gt;
-&lt;br/&gt;
 public class BrokerCompatibilityTest {&lt;/p&gt;

&lt;p&gt;     private static final String SOURCE_TOPIC = &quot;brokerCompatibilitySourceTopic&quot;;&lt;br/&gt;
@@ -155,7 +153,7 @@ private static void loopUntilRecordReceived(final String kafka, final boolean eo&lt;br/&gt;
             consumer.subscribe(Collections.singletonList(SINK_TOPIC));&lt;/p&gt;

&lt;p&gt;             while (true) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;String, String&amp;gt; records = poll(consumer, 100);&lt;br/&gt;
+                final ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(100);&lt;br/&gt;
                 for (final ConsumerRecord&amp;lt;String, String&amp;gt; record : records) {&lt;br/&gt;
                     if (record.key().equals(&quot;key&quot;) &amp;amp;&amp;amp; record.value().equals(&quot;1&quot;)) {&lt;br/&gt;
                         return;&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/tests/EosTestDriver.java b/streams/src/test/java/org/apache/kafka/streams/tests/EosTestDriver.java&lt;br/&gt;
index 513d592fa38..752cdd696ed 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/tests/EosTestDriver.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/tests/EosTestDriver.java&lt;br/&gt;
@@ -52,8 +52,6 @@&lt;br/&gt;
 import java.util.Random;&lt;br/&gt;
 import java.util.Set;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;-import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;&lt;br/&gt;
-&lt;br/&gt;
 public class EosTestDriver extends SmokeTestUtil {&lt;/p&gt;

&lt;p&gt;     private static final int MAX_NUMBER_OF_KEYS = 100;&lt;br/&gt;
@@ -256,7 +254,7 @@ private static void ensureStreamsApplicationDown(final String kafka) &lt;/p&gt;
{
                 topics.add(&quot;repartition&quot;);
             }
&lt;p&gt;             consumer.subscribe(topics);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;poll(consumer, 0);&lt;br/&gt;
+            consumer.poll(0);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             final Set&amp;lt;TopicPartition&amp;gt; partitions = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
             for (final String topic : topics) {&lt;br/&gt;
@@ -286,7 +284,7 @@ private static void ensureStreamsApplicationDown(final String kafka) {&lt;br/&gt;
         long maxWaitTime = System.currentTimeMillis() + MAX_IDLE_TIME_MS;&lt;br/&gt;
         boolean allRecordsReceived = false;&lt;br/&gt;
         while (!allRecordsReceived &amp;amp;&amp;amp; System.currentTimeMillis() &amp;lt; maxWaitTime) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; receivedRecords = poll(consumer, 100);&lt;br/&gt;
+            final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; receivedRecords = consumer.poll(100);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             for (final ConsumerRecord&amp;lt;byte[], byte[]&amp;gt; record : receivedRecords) {&lt;br/&gt;
                 maxWaitTime = System.currentTimeMillis() + MAX_IDLE_TIME_MS;&lt;br/&gt;
@@ -593,7 +591,7 @@ public void onCompletion(final RecordMetadata metadata, final Exception exceptio&lt;/p&gt;

&lt;p&gt;         long maxWaitTime = System.currentTimeMillis() + MAX_IDLE_TIME_MS;&lt;br/&gt;
         while (!partitions.isEmpty() &amp;amp;&amp;amp; System.currentTimeMillis() &amp;lt; maxWaitTime) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 100);&lt;br/&gt;
+            final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(100);&lt;br/&gt;
             if (records.isEmpty()) {&lt;br/&gt;
                 System.out.println(&quot;No data received.&quot;);&lt;br/&gt;
                 for (final TopicPartition tp : partitions) {&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestDriver.java b/streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestDriver.java&lt;br/&gt;
index 74eac3f156c..50330a08e61 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestDriver.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestDriver.java&lt;br/&gt;
@@ -47,8 +47,6 @@&lt;br/&gt;
 import java.util.Set;&lt;br/&gt;
 import java.util.concurrent.TimeUnit;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;-import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;&lt;br/&gt;
-&lt;br/&gt;
 public class SmokeTestDriver extends SmokeTestUtil {&lt;/p&gt;

&lt;p&gt;     public static final int MAX_RECORD_EMPTY_RETRIES = 60;&lt;br/&gt;
@@ -291,7 +289,7 @@ public static void verify(String kafka, Map&amp;lt;String, Set&amp;lt;Integer&amp;gt;&amp;gt; allData, int m&lt;br/&gt;
         int retry = 0;&lt;br/&gt;
         final long start = System.currentTimeMillis();&lt;br/&gt;
         while (System.currentTimeMillis() - start &amp;lt; TimeUnit.MINUTES.toMillis(6)) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);&lt;br/&gt;
+            ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);&lt;br/&gt;
             if (records.isEmpty() &amp;amp;&amp;amp; recordsProcessed &amp;gt;= recordsGenerated) {&lt;br/&gt;
                 if (verifyMin(min, allData, false)&lt;br/&gt;
                     &amp;amp;&amp;amp; verifyMax(max, allData, false)&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/tools/StreamsResetterTest.java b/streams/src/test/java/org/apache/kafka/streams/tools/StreamsResetterTest.java&lt;br/&gt;
index 49f699ec658..ad19f32fd1d 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/tools/StreamsResetterTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/tools/StreamsResetterTest.java&lt;br/&gt;
@@ -40,7 +40,6 @@&lt;br/&gt;
 import java.util.Set;&lt;br/&gt;
 import java.util.concurrent.ExecutionException;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;-import static org.apache.kafka.streams.processor.internals.ConsumerUtils.poll;&lt;br/&gt;
 import static org.junit.Assert.assertEquals;&lt;br/&gt;
 import static org.junit.Assert.fail;&lt;/p&gt;

&lt;p&gt;@@ -75,7 +74,7 @@ public void testResetToSpecificOffsetWhenBetweenBeginningAndEndOffset() &lt;/p&gt;
{
 
         streamsResetter.resetOffsetsTo(consumer, inputTopicPartitions, 2L);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
         assertEquals(3, records.count());
     }

&lt;p&gt;@@ -91,7 +90,7 @@ public void testResetToSpecificOffsetWhenBeforeBeginningOffset() &lt;/p&gt;
{
 
         streamsResetter.resetOffsetsTo(consumer, inputTopicPartitions, 2L);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
         assertEquals(2, records.count());
     }

&lt;p&gt;@@ -107,7 +106,7 @@ public void testResetToSpecificOffsetWhenAfterEndOffset() &lt;/p&gt;
{
 
         streamsResetter.resetOffsetsTo(consumer, inputTopicPartitions, 4L);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
         assertEquals(2, records.count());
     }

&lt;p&gt;@@ -123,7 +122,7 @@ public void testShiftOffsetByWhenBetweenBeginningAndEndOffset() &lt;/p&gt;
{
 
         streamsResetter.shiftOffsetsBy(consumer, inputTopicPartitions, 3L);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
         assertEquals(2, records.count());
     }

&lt;p&gt;@@ -139,7 +138,7 @@ public void testShiftOffsetByWhenBeforeBeginningOffset() &lt;/p&gt;
{
 
         streamsResetter.shiftOffsetsBy(consumer, inputTopicPartitions, -3L);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
         assertEquals(5, records.count());
     }

&lt;p&gt;@@ -155,7 +154,7 @@ public void testShiftOffsetByWhenAfterEndOffset() &lt;/p&gt;
{
 
         streamsResetter.shiftOffsetsBy(consumer, inputTopicPartitions, 5L);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
         assertEquals(2, records.count());
     }

&lt;p&gt;@@ -173,7 +172,7 @@ public void testResetUsingPlanWhenBetweenBeginningAndEndOffset() &lt;/p&gt;
{
         topicPartitionsAndOffset.put(topicPartition, 3L);
         streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
         assertEquals(2, records.count());
     }

&lt;p&gt;@@ -191,7 +190,7 @@ public void testResetUsingPlanWhenBeforeBeginningOffset() &lt;/p&gt;
{
         topicPartitionsAndOffset.put(topicPartition, 1L);
         streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
         assertEquals(2, records.count());
     }

&lt;p&gt;@@ -209,7 +208,7 @@ public void testResetUsingPlanWhenAfterEndOffset() &lt;/p&gt;
{
         topicPartitionsAndOffset.put(topicPartition, 5L);
         streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
         assertEquals(2, records.count());
     }

&lt;p&gt;@@ -227,7 +226,7 @@ public void shouldSeekToEndOffset() &lt;/p&gt;
{
         intermediateTopicPartitions.add(topicPartition);
         streamsResetter.maybeSeekToEnd(&quot;g1&quot;, consumer, intermediateTopicPartitions);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = poll(consumer, 500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
         assertEquals(2, records.count());
     }

&lt;p&gt;diff --git a/streams/test-utils/src/main/java/org/apache/kafka/streams/TopologyTestDriver.java b/streams/test-utils/src/main/java/org/apache/kafka/streams/TopologyTestDriver.java&lt;br/&gt;
index 7b8bdd5664d..c237ca77e1d 100644&lt;br/&gt;
&amp;#8212; a/streams/test-utils/src/main/java/org/apache/kafka/streams/TopologyTestDriver.java&lt;br/&gt;
+++ b/streams/test-utils/src/main/java/org/apache/kafka/streams/TopologyTestDriver.java&lt;br/&gt;
@@ -309,13 +309,7 @@ public void onRestoreEnd(final TopicPartition topicPartition, final String store&lt;br/&gt;
                 consumer,&lt;br/&gt;
                 stateDirectory,&lt;br/&gt;
                 stateRestoreListener,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;streamsConfig,&lt;/li&gt;
	&lt;li&gt;new GlobalStateManagerImpl.IsRunning() {&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public boolean check() 
{
-                        return true;
-                    }&lt;/li&gt;
	&lt;li&gt;});&lt;br/&gt;
+                streamsConfig);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             final GlobalProcessorContextImpl globalProcessorContext&lt;br/&gt;
                 = new GlobalProcessorContextImpl(streamsConfig, globalStateManager, streamsMetrics, cache);&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16480849" author="mjsax" created="Fri, 18 May 2018 16:08:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vvcephei&quot; class=&quot;user-hover&quot; rel=&quot;vvcephei&quot;&gt;vvcephei&lt;/a&gt;: should we reopen this issue?&lt;/p&gt;</comment>
                            <comment id="16491782" author="githubbot" created="Sat, 26 May 2018 18:50:54 +0000"  >&lt;p&gt;hachikuji closed pull request #4855: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5697&quot; title=&quot;StreamThread.shutdown() need to interrupt the stream threads to break the loop&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5697&quot;&gt;&lt;del&gt;KAFKA-5697&lt;/del&gt;&lt;/a&gt;: prevent poll() from blocking forever&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4855&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4855&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/Consumer.java b/clients/src/main/java/org/apache/kafka/clients/consumer/Consumer.java&lt;br/&gt;
index 0e27e1f0383..acb53e11088 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/consumer/Consumer.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/Consumer.java&lt;br/&gt;
@@ -22,6 +22,7 @@&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition;&lt;/p&gt;

&lt;p&gt; import java.io.Closeable;&lt;br/&gt;
+import java.time.Duration;&lt;br/&gt;
 import java.util.Collection;&lt;br/&gt;
 import java.util.List;&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
@@ -38,156 +39,162 @@&lt;br/&gt;
     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#assignment()&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public Set&amp;lt;TopicPartition&amp;gt; assignment();&lt;br/&gt;
+    Set&amp;lt;TopicPartition&amp;gt; assignment();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#subscription()&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public Set&amp;lt;String&amp;gt; subscription();&lt;br/&gt;
+    Set&amp;lt;String&amp;gt; subscription();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#subscribe(Collection)&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void subscribe(Collection&amp;lt;String&amp;gt; topics);&lt;br/&gt;
+    void subscribe(Collection&amp;lt;String&amp;gt; topics);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#subscribe(Collection, ConsumerRebalanceListener)&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void subscribe(Collection&amp;lt;String&amp;gt; topics, ConsumerRebalanceListener callback);&lt;br/&gt;
+    void subscribe(Collection&amp;lt;String&amp;gt; topics, ConsumerRebalanceListener callback);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#assign(Collection)&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void assign(Collection&amp;lt;TopicPartition&amp;gt; partitions);&lt;br/&gt;
+    void assign(Collection&amp;lt;TopicPartition&amp;gt; partitions);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#subscribe(Pattern, ConsumerRebalanceListener)&lt;br/&gt;
     */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void subscribe(Pattern pattern, ConsumerRebalanceListener callback);&lt;br/&gt;
+    void subscribe(Pattern pattern, ConsumerRebalanceListener callback);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#subscribe(Pattern)&lt;br/&gt;
     */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void subscribe(Pattern pattern);&lt;br/&gt;
+    void subscribe(Pattern pattern);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#unsubscribe()&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void unsubscribe();&lt;br/&gt;
+    void unsubscribe();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#poll(long)&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public ConsumerRecords&amp;lt;K, V&amp;gt; poll(long timeout);&lt;br/&gt;
+    @Deprecated&lt;br/&gt;
+    ConsumerRecords&amp;lt;K, V&amp;gt; poll(long timeout);&lt;br/&gt;
+&lt;br/&gt;
+    /**&lt;br/&gt;
+     * @see KafkaConsumer#poll(Duration)&lt;br/&gt;
+     */&lt;br/&gt;
+    ConsumerRecords&amp;lt;K, V&amp;gt; poll(Duration timeout);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#commitSync()&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void commitSync();&lt;br/&gt;
+    void commitSync();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#commitSync(Map)&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void commitSync(Map&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt; offsets);&lt;br/&gt;
+    void commitSync(Map&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt; offsets);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#commitAsync()&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void commitAsync();&lt;br/&gt;
+    void commitAsync();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#commitAsync(OffsetCommitCallback)&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void commitAsync(OffsetCommitCallback callback);&lt;br/&gt;
+    void commitAsync(OffsetCommitCallback callback);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#commitAsync(Map, OffsetCommitCallback)&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void commitAsync(Map&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt; offsets, OffsetCommitCallback callback);&lt;br/&gt;
+    void commitAsync(Map&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt; offsets, OffsetCommitCallback callback);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#seek(TopicPartition, long)&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void seek(TopicPartition partition, long offset);&lt;br/&gt;
+    void seek(TopicPartition partition, long offset);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#seekToBeginning(Collection)&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void seekToBeginning(Collection&amp;lt;TopicPartition&amp;gt; partitions);&lt;br/&gt;
+    void seekToBeginning(Collection&amp;lt;TopicPartition&amp;gt; partitions);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#seekToEnd(Collection)&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void seekToEnd(Collection&amp;lt;TopicPartition&amp;gt; partitions);&lt;br/&gt;
+    void seekToEnd(Collection&amp;lt;TopicPartition&amp;gt; partitions);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#position(TopicPartition)&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public long position(TopicPartition partition);&lt;br/&gt;
+    long position(TopicPartition partition);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#committed(TopicPartition)&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public OffsetAndMetadata committed(TopicPartition partition);&lt;br/&gt;
+    OffsetAndMetadata committed(TopicPartition partition);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#metrics()&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public Map&amp;lt;MetricName, ? extends Metric&amp;gt; metrics();&lt;br/&gt;
+    Map&amp;lt;MetricName, ? extends Metric&amp;gt; metrics();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#partitionsFor(String)&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public List&amp;lt;PartitionInfo&amp;gt; partitionsFor(String topic);&lt;br/&gt;
+    List&amp;lt;PartitionInfo&amp;gt; partitionsFor(String topic);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#listTopics()&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public Map&amp;lt;String, List&amp;lt;PartitionInfo&amp;gt;&amp;gt; listTopics();&lt;br/&gt;
+    Map&amp;lt;String, List&amp;lt;PartitionInfo&amp;gt;&amp;gt; listTopics();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#paused()&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public Set&amp;lt;TopicPartition&amp;gt; paused();&lt;br/&gt;
+    Set&amp;lt;TopicPartition&amp;gt; paused();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#pause(Collection)&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void pause(Collection&amp;lt;TopicPartition&amp;gt; partitions);&lt;br/&gt;
+    void pause(Collection&amp;lt;TopicPartition&amp;gt; partitions);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#resume(Collection)&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void resume(Collection&amp;lt;TopicPartition&amp;gt; partitions);&lt;br/&gt;
+    void resume(Collection&amp;lt;TopicPartition&amp;gt; partitions);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#offsetsForTimes(java.util.Map)&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public Map&amp;lt;TopicPartition, OffsetAndTimestamp&amp;gt; offsetsForTimes(Map&amp;lt;TopicPartition, Long&amp;gt; timestampsToSearch);&lt;br/&gt;
+    Map&amp;lt;TopicPartition, OffsetAndTimestamp&amp;gt; offsetsForTimes(Map&amp;lt;TopicPartition, Long&amp;gt; timestampsToSearch);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#beginningOffsets(java.util.Collection)&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public Map&amp;lt;TopicPartition, Long&amp;gt; beginningOffsets(Collection&amp;lt;TopicPartition&amp;gt; partitions);&lt;br/&gt;
+    Map&amp;lt;TopicPartition, Long&amp;gt; beginningOffsets(Collection&amp;lt;TopicPartition&amp;gt; partitions);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#endOffsets(java.util.Collection)&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public Map&amp;lt;TopicPartition, Long&amp;gt; endOffsets(Collection&amp;lt;TopicPartition&amp;gt; partitions);&lt;br/&gt;
+    Map&amp;lt;TopicPartition, Long&amp;gt; endOffsets(Collection&amp;lt;TopicPartition&amp;gt; partitions);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#close()&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void close();&lt;br/&gt;
+    void close();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#close(long, TimeUnit)&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void close(long timeout, TimeUnit unit);&lt;br/&gt;
+    void close(long timeout, TimeUnit unit);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see KafkaConsumer#wakeup()&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void wakeup();&lt;br/&gt;
+    void wakeup();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; }&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerInterceptor.java b/clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerInterceptor.java&lt;br/&gt;
index 2f4e310f702..763fe512217 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerInterceptor.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerInterceptor.java&lt;br/&gt;
@@ -35,14 +35,16 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;the user configures the interceptor with the wrong key and value type parameters, the consumer will not throw an exception,&lt;/li&gt;
	&lt;li&gt;just log the errors.&lt;/li&gt;
	&lt;li&gt;&amp;lt;p&amp;gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* ConsumerInterceptor callbacks are called from the same thread that invokes 
{@link org.apache.kafka.clients.consumer.KafkaConsumer#poll(long)}.&lt;br/&gt;
+ * ConsumerInterceptor callbacks are called from the same thread that invokes&lt;br/&gt;
+ * {@link org.apache.kafka.clients.consumer.KafkaConsumer#poll(java.time.Duration)}.&lt;br/&gt;
  * &amp;lt;p&amp;gt;&lt;br/&gt;
  * Implement {@link org.apache.kafka.common.ClusterResourceListener} to receive cluster metadata once it&apos;s available. Please see the class documentation for ClusterResourceListener for more information.&lt;br/&gt;
  */&lt;br/&gt;
 public interface ConsumerInterceptor&amp;lt;K, V&amp;gt; extends Configurable {&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
-     * This is called just before the records are returned by {@link org.apache.kafka.clients.consumer.KafkaConsumer#poll(long)}
&lt;p&gt;+     * This is called just before the records are returned by&lt;br/&gt;
+     * &lt;/p&gt;
{@link org.apache.kafka.clients.consumer.KafkaConsumer#poll(java.time.Duration)}&lt;br/&gt;
      * &amp;lt;p&amp;gt;&lt;br/&gt;
      * This method is allowed to modify consumer records, in which case the new records will be&lt;br/&gt;
      * returned. There is no limitation on number of records that could be returned from this&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerRebalanceListener.java b/clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerRebalanceListener.java&lt;br/&gt;
index ad2f61d1166..74e8b060c73 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerRebalanceListener.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerRebalanceListener.java&lt;br/&gt;
@@ -44,7 +44,8 @@&lt;br/&gt;
  * partition is reassigned it may want to automatically trigger a flush of this cache, before the new owner takes over&lt;br/&gt;
  * consumption.&lt;br/&gt;
  * &amp;lt;p&amp;gt;&lt;br/&gt;
- * This callback will only execute in the user thread as part of the {@link Consumer#poll(long) poll(long)} call whenever partition assignment changes.&lt;br/&gt;
+ * This callback will only execute in the user thread as part of the {@link Consumer#poll(java.time.Duration) poll(long)} call&lt;br/&gt;
+ * whenever partition assignment changes.&lt;br/&gt;
  * &amp;lt;p&amp;gt;&lt;br/&gt;
  * It is guaranteed that all consumer processes will invoke {@link #onPartitionsRevoked(Collection) onPartitionsRevoked} prior to&lt;br/&gt;
  * any process invoking {@link #onPartitionsAssigned(Collection) onPartitionsAssigned}. So if offsets or other state is saved in the&lt;br/&gt;
@@ -91,7 +92,7 @@&lt;br/&gt;
      * It is common for the revocation callback to use the consumer instance in order to commit offsets. It is possible&lt;br/&gt;
      * for a {@link org.apache.kafka.common.errors.WakeupException} or {@link org.apache.kafka.common.errors.InterruptException}&lt;br/&gt;
      * to be raised from one these nested invocations. In this case, the exception will be propagated to the current&lt;br/&gt;
-     * invocation of {@link KafkaConsumer#poll(long)} in which this callback is being executed. This means it is not&lt;br/&gt;
+     * invocation of {@link KafkaConsumer#poll(java.time.Duration)} in which this callback is being executed. This means it is not&lt;br/&gt;
      * necessary to catch these exceptions and re-attempt to wakeup or interrupt the consumer thread.&lt;br/&gt;
      *&lt;br/&gt;
      * @param partitions The list of partitions that were assigned to the consumer on the last rebalance&lt;br/&gt;
@@ -103,7 +104,7 @@&lt;br/&gt;
     /**&lt;br/&gt;
      * A callback method the user can implement to provide handling of customized offsets on completion of a successful&lt;br/&gt;
      * partition re-assignment. This method will be called after the partition re-assignment completes and before the&lt;br/&gt;
-     * consumer starts fetching data, and only as the result of a {@link Consumer#poll(long) poll(long)} call.&lt;br/&gt;
+     * consumer starts fetching data, and only as the result of a {@link Consumer#poll(java.time.Duration) poll(long)} call.&lt;br/&gt;
      * &amp;lt;p&amp;gt;&lt;br/&gt;
      * It is guaranteed that all the processes in a consumer group will execute their&lt;br/&gt;
      * {@link #onPartitionsRevoked(Collection)} callback before any instance executes its&lt;br/&gt;
@@ -112,7 +113,7 @@&lt;br/&gt;
      * It is common for the assignment callback to use the consumer instance in order to query offsets. It is possible&lt;br/&gt;
      * for a {@link org.apache.kafka.common.errors.WakeupException} or {@link org.apache.kafka.common.errors.InterruptException}&lt;br/&gt;
      * to be raised from one these nested invocations. In this case, the exception will be propagated to the current&lt;br/&gt;
-     * invocation of {@link KafkaConsumer#poll(long)} in which this callback is being executed. This means it is not&lt;br/&gt;
+     * invocation of {@link KafkaConsumer#poll(java.time.Duration)} in which this callback is being executed. This means it is not&lt;br/&gt;
      * necessary to catch these exceptions and re-attempt to wakeup or interrupt the consumer thread.&lt;br/&gt;
      *&lt;br/&gt;
      * @param partitions The list of partitions that are now assigned to the consumer (may include partitions previously&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerRecords.java b/clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerRecords.java&lt;br/&gt;
index f2dc9bbc2ba..4d0f62c3a1d 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerRecords.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerRecords.java&lt;br/&gt;
@@ -29,7 +29,7 @@&lt;br/&gt;
 /**&lt;br/&gt;
  * A container that holds the list {@link ConsumerRecord} per partition for a&lt;br/&gt;
  * particular topic. There is one {@link ConsumerRecord} list for every topic&lt;br/&gt;
- * partition returned by a {@link Consumer#poll(long)} operation.&lt;br/&gt;
+ * partition returned by a {@link Consumer#poll(java.time.Duration)} operation.&lt;br/&gt;
  */&lt;br/&gt;
 public class ConsumerRecords&amp;lt;K, V&amp;gt; implements Iterable&amp;lt;ConsumerRecord&amp;lt;K, V&amp;gt;&amp;gt; {&lt;br/&gt;
 &lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/KafkaConsumer.java b/clients/src/main/java/org/apache/kafka/clients/consumer/KafkaConsumer.java&lt;br/&gt;
index 0b18927c300..e5bc5c1d33c 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/consumer/KafkaConsumer.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/KafkaConsumer.java&lt;br/&gt;
@@ -24,7 +24,6 @@&lt;br/&gt;
 import org.apache.kafka.clients.consumer.internals.ConsumerInterceptors;&lt;br/&gt;
 import org.apache.kafka.clients.consumer.internals.ConsumerMetrics;&lt;br/&gt;
 import org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient;&lt;br/&gt;
-import org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.PollCondition;&lt;br/&gt;
 import org.apache.kafka.clients.consumer.internals.Fetcher;&lt;br/&gt;
 import org.apache.kafka.clients.consumer.internals.NoOpConsumerRebalanceListener;&lt;br/&gt;
 import org.apache.kafka.clients.consumer.internals.PartitionAssignor;&lt;br/&gt;
@@ -55,6 +54,7 @@&lt;br/&gt;
 import org.slf4j.Logger;&lt;br/&gt;
 &lt;br/&gt;
 import java.net.InetSocketAddress;&lt;br/&gt;
+import java.time.Duration;&lt;br/&gt;
 import java.util.Collection;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
 import java.util.ConcurrentModificationException;&lt;br/&gt;
@@ -98,7 +98,7 @@&lt;br/&gt;
  * &amp;lt;p&amp;gt;&lt;br/&gt;
  * The {@link #position(TopicPartition) position} of the consumer gives the offset of the next record that will be given&lt;br/&gt;
  * out. It will be one larger than the highest offset the consumer has seen in that partition. It automatically advances&lt;br/&gt;
- * every time the consumer receives messages in a call to {@link #poll(long)}.&lt;br/&gt;
+ * every time the consumer receives messages in a call to {@link #poll(Duration)}.&lt;br/&gt;
  * &amp;lt;p&amp;gt;&lt;br/&gt;
  * The {@link #commitSync() committed position} is the last offset that has been stored securely. Should the&lt;br/&gt;
  * process fail and restart, this is the offset that the consumer will recover to. The consumer can either automatically commit&lt;br/&gt;
@@ -149,7 +149,7 @@&lt;br/&gt;
  *&lt;br/&gt;
  * &amp;lt;h3&amp;gt;&amp;lt;a name=&quot;failuredetection&quot;&amp;gt;Detecting Consumer Failures&amp;lt;/a&amp;gt;&amp;lt;/h3&amp;gt;&lt;br/&gt;
  *&lt;br/&gt;
- * After subscribing to a set of topics, the consumer will automatically join the group when {@link #poll(long)} is&lt;br/&gt;
+ * After subscribing to a set of topics, the consumer will automatically join the group when {@link #poll(Duration)} is&lt;br/&gt;
  * invoked. The poll API is designed to ensure consumer liveness. As long as you continue to call poll, the consumer&lt;br/&gt;
  * will stay in the group and continue to receive messages from the partitions it was assigned. Underneath the covers,&lt;br/&gt;
  * the consumer sends periodic heartbeats to the server. If the consumer crashes or is unable to send heartbeats for&lt;br/&gt;
@@ -168,10 +168,10 @@&lt;br/&gt;
  * The consumer provides two configuration settings to control the behavior of the poll loop:&lt;br/&gt;
  * &amp;lt;ol&amp;gt;&lt;br/&gt;
  *     &amp;lt;li&amp;gt;&amp;lt;code&amp;gt;max.poll.interval.ms&amp;lt;/code&amp;gt;: By increasing the interval between expected polls, you can give&lt;br/&gt;
- *     the consumer more time to handle a batch of records returned from {@link #poll(long)}. The drawback&lt;br/&gt;
+ *     the consumer more time to handle a batch of records returned from {@link #poll(Duration)}. The drawback&lt;br/&gt;
  *     is that increasing this value may delay a group rebalance since the consumer will only join the rebalance&lt;br/&gt;
  *     inside the call to poll. You can use this setting to bound the time to finish a rebalance, but&lt;br/&gt;
- *     you risk slower progress if the consumer cannot actually call {@link #poll(long) poll} often enough.&amp;lt;/li&amp;gt;&lt;br/&gt;
+ *     you risk slower progress if the consumer cannot actually call {@link #poll(Duration) poll} often enough.&amp;lt;/li&amp;gt;&lt;br/&gt;
  *     &amp;lt;li&amp;gt;&amp;lt;code&amp;gt;max.poll.records&amp;lt;/code&amp;gt;: Use this setting to limit the total records returned from a single&lt;br/&gt;
  *     call to poll. This can make it easier to predict the maximum that must be handled within each poll&lt;br/&gt;
  *     interval. By tuning this value, you may be able to reduce the poll interval, which will reduce the&lt;br/&gt;
@@ -180,12 +180,12 @@&lt;br/&gt;
  * &amp;lt;p&amp;gt;&lt;br/&gt;
  * For use cases where message processing time varies unpredictably, neither of these options may be sufficient.&lt;br/&gt;
  * The recommended way to handle these cases is to move message processing to another thread, which allows&lt;br/&gt;
- * the consumer to continue calling {@link #poll(long) poll} while the processor is still working. Some care must be taken&lt;br/&gt;
- * to ensure that committed offsets do not get ahead of the actual position. Typically, you must disable automatic&lt;br/&gt;
- * commits and manually commit processed offsets for records only after the thread has finished handling them&lt;br/&gt;
- * (depending on the delivery semantics you need). Note also that you will need to {@link #pause(Collection) pause}&lt;br/&gt;
- * the partition so that no new records are received from poll until after thread has finished handling those&lt;br/&gt;
- * previously returned.&lt;br/&gt;
+ * the consumer to continue calling {@link #poll(Duration) poll} while the processor is still working.&lt;br/&gt;
+ * Some care must be taken to ensure that committed offsets do not get ahead of the actual position.&lt;br/&gt;
+ * Typically, you must disable automatic commits and manually commit processed offsets for records only after the&lt;br/&gt;
+ * thread has finished handling them (depending on the delivery semantics you need).&lt;br/&gt;
+ * Note also that you will need to {@link #pause(Collection) pause} the partition so that no new records are received&lt;br/&gt;
+ * from poll until after thread has finished handling those previously returned.&lt;br/&gt;
  *&lt;br/&gt;
  * &amp;lt;h3&amp;gt;Usage Examples&amp;lt;/h3&amp;gt;&lt;br/&gt;
  * The consumer APIs offer flexibility to cover a variety of consumption use cases. Here are some examples to&lt;br/&gt;
@@ -258,7 +258,8 @@&lt;br/&gt;
  *&lt;br/&gt;
  * In this example we will consume a batch of records and batch them up in memory. When we have enough records&lt;br/&gt;
  * batched, we will insert them into a database. If we allowed offsets to auto commit as in the previous example, records&lt;br/&gt;
- * would be considered consumed after they were returned to the user in {@link #poll(long) poll}. It would then be possible&lt;br/&gt;
+ * would be considered consumed after they were returned to the user in {@link #poll(Duration) poll}. It would then be&lt;br/&gt;
+ * possible&lt;br/&gt;
  * for our process to fail after batching the records, but before they had been inserted into the database.&lt;br/&gt;
  * &amp;lt;p&amp;gt;&lt;br/&gt;
  * To avoid this, we will manually commit the offsets only after the corresponding records have been inserted into the&lt;br/&gt;
@@ -270,7 +271,7 @@&lt;br/&gt;
  * time but in failure cases could be duplicated.&lt;br/&gt;
  * &amp;lt;p&amp;gt;&lt;br/&gt;
  * &amp;lt;b&amp;gt;Note: Using automatic offset commits can also give you &quot;at-least-once&quot; delivery, but the requirement is that&lt;br/&gt;
- * you must consume all data returned from each call to {@link #poll(long)} before any subsequent calls, or before&lt;br/&gt;
+ * you must consume all data returned from each call to {@link #poll(Duration)} before any subsequent calls, or before&lt;br/&gt;
  * {@link #close() closing} the consumer. If you fail to do either of these, it is possible for the committed offset&lt;br/&gt;
  * to get ahead of the consumed position, which results in missing records. The advantage of using manual offset&lt;br/&gt;
  * control is that you have direct control over when a record is considered &quot;consumed.&quot;&amp;lt;/b&amp;gt;&lt;br/&gt;
@@ -325,7 +326,7 @@&lt;br/&gt;
  *     consumer.assign(Arrays.asList(partition0, partition1));&lt;br/&gt;
  * &amp;lt;/pre&amp;gt;&lt;br/&gt;
  *&lt;br/&gt;
- * Once assigned, you can call {@link #poll(long) poll} in a loop, just as in the preceding examples to consume&lt;br/&gt;
+ * Once assigned, you can call {@link #poll(Duration) poll} in a loop, just as in the preceding examples to consume&lt;br/&gt;
  * records. The group that the consumer specifies is still used for committing offsets, but now the set of partitions&lt;br/&gt;
  * will only change with another call to {@link #assign(Collection) assign}. Manual partition assignment does&lt;br/&gt;
  * not use group coordination, so consumer failures will not cause assigned partitions to be rebalanced. Each consumer&lt;br/&gt;
@@ -417,7 +418,7 @@&lt;br/&gt;
  * &amp;lt;p&amp;gt;&lt;br/&gt;
  * Kafka supports dynamic controlling of consumption flows by using {@link #pause(Collection)} and {@link #resume(Collection)}&lt;br/&gt;
  * to pause the consumption on the specified assigned partitions and resume the consumption&lt;br/&gt;
- * on the specified paused partitions respectively in the future {@link #poll(long)} calls.&lt;br/&gt;
+ * on the specified paused partitions respectively in the future {@link #poll(Duration)} calls.&lt;br/&gt;
  *&lt;br/&gt;
  * &amp;lt;h3&amp;gt;Reading Transactional Messages&amp;lt;/h3&amp;gt;&lt;br/&gt;
  *&lt;br/&gt;
@@ -468,7 +469,7 @@&lt;br/&gt;
  *         try {&lt;br/&gt;
  *             consumer.subscribe(Arrays.asList(&quot;topic&quot;));&lt;br/&gt;
  *             while (!closed.get()) {
- *                 ConsumerRecords records = consumer.poll(10000);
+ *                 ConsumerRecords records = consumer.poll(Duration.ofMillis(10000));
  *                 // Handle new records
  *             }&lt;br/&gt;
  *         } catch (WakeupException e) {&lt;br/&gt;
@@ -574,6 +575,9 @@&lt;br/&gt;
     // refcount is used to allow reentrant access by the thread who has acquired currentThread&lt;br/&gt;
     private final AtomicInteger refcount = new AtomicInteger(0);&lt;br/&gt;
 &lt;br/&gt;
+    // to keep from repeatedly scanning subscriptions in poll(), cache the result during metadata updates&lt;br/&gt;
+    private boolean cachedSubscriptionHashAllFetchPositions;&lt;br/&gt;
+&lt;br/&gt;
     /**&lt;br/&gt;
      * A consumer is instantiated by providing a set of key-value pairs as configuration. Valid configuration strings&lt;br/&gt;
      * are documented &amp;lt;a href=&quot;http://kafka.apache.org/documentation.html#consumerconfigs&quot; &amp;gt;here&amp;lt;/a&amp;gt;. Values can be&lt;br/&gt;
@@ -878,7 +882,7 @@ private KafkaConsumer(ConsumerConfig config,&lt;br/&gt;
      * &amp;lt;p&amp;gt;&lt;br/&gt;
      * When any of these events are triggered, the provided listener will be invoked first to indicate that&lt;br/&gt;
      * the consumer&apos;s assignment has been revoked, and then again when the new assignment has been received.&lt;br/&gt;
-     * Note that rebalances will only occur during an active call to {@link #poll(long)}, so callbacks will&lt;br/&gt;
+     * Note that rebalances will only occur during an active call to {@link #poll(Duration)}, so callbacks will&lt;br/&gt;
      * also only be invoked during that time.&lt;br/&gt;
      *&lt;br/&gt;
      * The provided listener will immediately override any listener set in a previous call to subscribe.&lt;br/&gt;
@@ -954,7 +958,7 @@ public void subscribe(Collection&amp;lt;String&amp;gt; topics) {&lt;br/&gt;
      * See {@link #subscribe(Collection, ConsumerRebalanceListener)} for details on the&lt;br/&gt;
      * use of the {@link ConsumerRebalanceListener}. Generally rebalances are triggered when there&lt;br/&gt;
      * is a change to the topics matching the provided pattern and when consumer group membership changes.&lt;br/&gt;
-     * Group rebalances only take place during an active call to {@link #poll(long)}.&lt;br/&gt;
+     * Group rebalances only take place during an active call to {@link #poll(Duration)}.&lt;br/&gt;
      *&lt;br/&gt;
      * @param pattern Pattern to subscribe to&lt;br/&gt;
      * @param listener Non-null listener instance to get notifications on partition assignment/revocation for the&lt;br/&gt;
@@ -1096,22 +1100,82 @@ public void assign(Collection&amp;lt;TopicPartition&amp;gt; partitions) {&lt;br/&gt;
      * @throws java.lang.IllegalArgumentException if the timeout value is negative&lt;br/&gt;
      * @throws java.lang.IllegalStateException if the consumer is not subscribed to any topics or manually assigned any&lt;br/&gt;
      *             partitions to consume from&lt;br/&gt;
+     *&lt;br/&gt;
+     *&lt;br/&gt;
+     * @deprecated Since 2.0. Use {@link #poll(Duration)} to poll for records.&lt;br/&gt;
+     */&lt;br/&gt;
+    @Deprecated&lt;br/&gt;
+    @Override&lt;br/&gt;
+    public ConsumerRecords&amp;lt;K, V&amp;gt; poll(final long timeout) {
+        return poll(timeout, false);
+    }&lt;br/&gt;
+&lt;br/&gt;
+    /**&lt;br/&gt;
+     * Fetch data for the topics or partitions specified using one of the subscribe/assign APIs. It is an error to not have&lt;br/&gt;
+     * subscribed to any topics or partitions before polling for data.&lt;br/&gt;
+     * &amp;lt;p&amp;gt;&lt;br/&gt;
+     * On each poll, consumer will try to use the last consumed offset as the starting offset and fetch sequentially. The last&lt;br/&gt;
+     * consumed offset can be manually set through {@link #seek(TopicPartition, long)} or automatically set as the last committed&lt;br/&gt;
+     * offset for the subscribed list of partitions&lt;br/&gt;
+     *&lt;br/&gt;
+     *&lt;br/&gt;
+     * @param timeout The maximum time to block (must not be greater than {@link Long#MAX_VALUE} milliseconds)&lt;br/&gt;
+     *&lt;br/&gt;
+     * @return map of topic to records since the last fetch for the subscribed list of topics and partitions&lt;br/&gt;
+     *&lt;br/&gt;
+     * @throws org.apache.kafka.clients.consumer.InvalidOffsetException if the offset for a partition or set of&lt;br/&gt;
+     *             partitions is undefined or out of range and no offset reset policy has been configured&lt;br/&gt;
+     * @throws org.apache.kafka.common.errors.WakeupException if {@link #wakeup()} is called before or while this&lt;br/&gt;
+     *             function is called&lt;br/&gt;
+     * @throws org.apache.kafka.common.errors.InterruptException if the calling thread is interrupted before or while&lt;br/&gt;
+     *             this function is called&lt;br/&gt;
+     * @throws org.apache.kafka.common.errors.AuthenticationException if authentication fails. See the exception for more details&lt;br/&gt;
+     * @throws org.apache.kafka.common.errors.AuthorizationException if caller lacks Read access to any of the subscribed&lt;br/&gt;
+     *             topics or to the configured groupId. See the exception for more details&lt;br/&gt;
+     * @throws org.apache.kafka.common.KafkaException for any other unrecoverable errors (e.g. invalid groupId or&lt;br/&gt;
+     *             session timeout, errors deserializing key/value pairs, or any new error cases in future versions)&lt;br/&gt;
+     * @throws java.lang.IllegalArgumentException if the timeout value is negative&lt;br/&gt;
+     * @throws java.lang.IllegalStateException if the consumer is not subscribed to any topics or manually assigned any&lt;br/&gt;
+     *             partitions to consume from&lt;br/&gt;
+     * @throws java.lang.ArithmeticException if the timeout is greater than {@link Long#MAX_VALUE} milliseconds.&lt;br/&gt;
      */&lt;br/&gt;
     @Override&lt;br/&gt;
-    public ConsumerRecords&amp;lt;K, V&amp;gt; poll(long timeout) {&lt;br/&gt;
+    public ConsumerRecords&amp;lt;K, V&amp;gt; poll(final Duration timeout) {
+        return poll(timeout.toMillis(), true);
+    }&lt;br/&gt;
+&lt;br/&gt;
+    private ConsumerRecords&amp;lt;K, V&amp;gt; poll(final long timeoutMs, final boolean includeMetadataInTimeout) {&lt;br/&gt;
         acquireAndEnsureOpen();&lt;br/&gt;
         try {&lt;br/&gt;
-            if (timeout &amp;lt; 0)&lt;br/&gt;
-                throw new IllegalArgumentException(&quot;Timeout must not be negative&quot;);&lt;br/&gt;
+            if (timeoutMs &amp;lt; 0) throw new IllegalArgumentException(&quot;Timeout must not be negative&quot;);&lt;br/&gt;
 &lt;br/&gt;
-            if (this.subscriptions.hasNoSubscriptionOrUserAssignment())&lt;br/&gt;
+            if (this.subscriptions.hasNoSubscriptionOrUserAssignment()) {
                 throw new IllegalStateException(&quot;Consumer is not subscribed to any topics or assigned any partitions&quot;);
+            }&lt;br/&gt;
 &lt;br/&gt;
             // poll for new data until the timeout expires&lt;br/&gt;
-            long start = time.milliseconds();&lt;br/&gt;
-            long remaining = timeout;&lt;br/&gt;
+            long elapsedTime = 0L;&lt;br/&gt;
             do {&lt;br/&gt;
-                Map&amp;lt;TopicPartition, List&amp;lt;ConsumerRecord&amp;lt;K, V&amp;gt;&amp;gt;&amp;gt; records = pollOnce(remaining);&lt;br/&gt;
+&lt;br/&gt;
+                client.maybeTriggerWakeup();&lt;br/&gt;
+&lt;br/&gt;
+                final long metadataEnd;&lt;br/&gt;
+                if (includeMetadataInTimeout) {&lt;br/&gt;
+                    final long metadataStart = time.milliseconds();&lt;br/&gt;
+                    if (!updateAssignmentMetadataIfNeeded(remainingTimeAtLeastZero(timeoutMs, elapsedTime))) {
+                        return ConsumerRecords.empty();
+                    }&lt;br/&gt;
+                    metadataEnd = time.milliseconds();&lt;br/&gt;
+                    elapsedTime += metadataEnd - metadataStart;&lt;br/&gt;
+                } else {&lt;br/&gt;
+                    while (!updateAssignmentMetadataIfNeeded(Long.MAX_VALUE)) {
+                        log.warn(&quot;Still waiting for metadata&quot;);
+                    }&lt;br/&gt;
+                    metadataEnd = time.milliseconds();&lt;br/&gt;
+                }&lt;br/&gt;
+&lt;br/&gt;
+                final Map&amp;lt;TopicPartition, List&amp;lt;ConsumerRecord&amp;lt;K, V&amp;gt;&amp;gt;&amp;gt; records = pollForFetches(remainingTimeAtLeastZero(timeoutMs, elapsedTime));&lt;br/&gt;
+&lt;br/&gt;
                 if (!records.isEmpty()) {&lt;br/&gt;
                     // before returning the fetched records, we can send off the next round of fetches&lt;br/&gt;
                     // and avoid block waiting for their responses to enable pipelining while the user&lt;br/&gt;
@@ -1119,15 +1183,16 @@ public void assign(Collection&amp;lt;TopicPartition&amp;gt; partitions) {&lt;br/&gt;
                     //&lt;br/&gt;
                     // NOTE: since the consumed position has already been updated, we must not allow&lt;br/&gt;
                     // wakeups or any other errors to be triggered prior to returning the fetched records.&lt;br/&gt;
-                    if (fetcher.sendFetches() &amp;gt; 0 || client.hasPendingRequests())&lt;br/&gt;
+                    if (fetcher.sendFetches() &amp;gt; 0 || client.hasPendingRequests()) {
                         client.pollNoWakeup();
+                    }&lt;br/&gt;
 &lt;br/&gt;
                     return this.interceptors.onConsume(new ConsumerRecords&amp;lt;&amp;gt;(records));&lt;br/&gt;
                 }&lt;br/&gt;
+                final long fetchEnd = time.milliseconds();&lt;br/&gt;
+                elapsedTime += fetchEnd - metadataEnd;&lt;br/&gt;
 &lt;br/&gt;
-                long elapsed = time.milliseconds() - start;&lt;br/&gt;
-                remaining = timeout - elapsed;&lt;br/&gt;
-            } while (remaining &amp;gt; 0);&lt;br/&gt;
+            } while (elapsedTime &amp;lt; timeoutMs);&lt;br/&gt;
 &lt;br/&gt;
             return ConsumerRecords.empty();&lt;br/&gt;
         } finally {&lt;br/&gt;
@@ -1136,56 +1201,61 @@ public void assign(Collection&amp;lt;TopicPartition&amp;gt; partitions) {&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
-     * Do one round of polling. In addition to checking for new data, this does any needed offset commits&lt;br/&gt;
-     * (if auto-commit is enabled), and offset resets (if an offset reset policy is defined).&lt;br/&gt;
-     * @param timeout The maximum time to block in the underlying call to {@link ConsumerNetworkClient#poll(long)}.&lt;br/&gt;
-     * @return The fetched records (may be empty)&lt;br/&gt;
+     * Visible for testing&lt;br/&gt;
      */&lt;br/&gt;
-    private Map&amp;lt;TopicPartition, List&amp;lt;ConsumerRecord&amp;lt;K, V&amp;gt;&amp;gt;&amp;gt; pollOnce(long timeout) {&lt;br/&gt;
-        client.maybeTriggerWakeup();&lt;br/&gt;
+    boolean updateAssignmentMetadataIfNeeded(final long timeoutMs) {&lt;br/&gt;
+        final long startMs = time.milliseconds();&lt;br/&gt;
+        if (!coordinator.poll(timeoutMs)) {
+            return false;
+        }&lt;br/&gt;
 &lt;br/&gt;
-        long startMs = time.milliseconds();&lt;br/&gt;
-        coordinator.poll(startMs, timeout);&lt;br/&gt;
+        return updateFetchPositions(remainingTimeAtLeastZero(timeoutMs, time.milliseconds() - startMs));&lt;br/&gt;
+    }&lt;br/&gt;
 &lt;br/&gt;
-        // Lookup positions of assigned partitions&lt;br/&gt;
-        boolean hasAllFetchPositions = updateFetchPositions();&lt;br/&gt;
+    private Map&amp;lt;TopicPartition, List&amp;lt;ConsumerRecord&amp;lt;K, V&amp;gt;&amp;gt;&amp;gt; pollForFetches(final long timeoutMs) {&lt;br/&gt;
+        final long startMs = time.milliseconds();&lt;br/&gt;
+        long pollTimeout = Math.min(coordinator.timeToNextPoll(startMs), timeoutMs);&lt;br/&gt;
 &lt;br/&gt;
         // if data is available already, return it immediately&lt;br/&gt;
-        Map&amp;lt;TopicPartition, List&amp;lt;ConsumerRecord&amp;lt;K, V&amp;gt;&amp;gt;&amp;gt; records = fetcher.fetchedRecords();&lt;br/&gt;
-        if (!records.isEmpty())&lt;br/&gt;
+        final Map&amp;lt;TopicPartition, List&amp;lt;ConsumerRecord&amp;lt;K, V&amp;gt;&amp;gt;&amp;gt; records = fetcher.fetchedRecords();&lt;br/&gt;
+        if (!records.isEmpty()) {
             return records;
+        }&lt;br/&gt;
 &lt;br/&gt;
         // send any new fetches (won&apos;t resend pending fetches)&lt;br/&gt;
         fetcher.sendFetches();&lt;br/&gt;
 &lt;br/&gt;
-        long nowMs = time.milliseconds();&lt;br/&gt;
-        long remainingTimeMs = Math.max(0, timeout - (nowMs - startMs));&lt;br/&gt;
-        long pollTimeout = Math.min(coordinator.timeToNextPoll(nowMs), remainingTimeMs);&lt;br/&gt;
-&lt;br/&gt;
         // We do not want to be stuck blocking in poll if we are missing some positions&lt;br/&gt;
         // since the offset lookup may be backing off after a failure&lt;br/&gt;
-        if (!hasAllFetchPositions &amp;amp;&amp;amp; pollTimeout &amp;gt; retryBackoffMs)&lt;br/&gt;
+&lt;br/&gt;
+        // NOTE: the use of cachedSubscriptionHashAllFetchPositions means we MUST call&lt;br/&gt;
+        // updateAssignmentMetadataIfNeeded before this method.&lt;br/&gt;
+        if (!cachedSubscriptionHashAllFetchPositions &amp;amp;&amp;amp; pollTimeout &amp;gt; retryBackoffMs) {
             pollTimeout = retryBackoffMs;
+        }&lt;br/&gt;
 &lt;br/&gt;
-        client.poll(pollTimeout, nowMs, new PollCondition() {&lt;br/&gt;
-            @Override&lt;br/&gt;
-            public boolean shouldBlock() {
-                // since a fetch might be completed by the background thread, we need this poll condition
-                // to ensure that we do not block unnecessarily in poll()
-                return !fetcher.hasCompletedFetches();
-            }&lt;br/&gt;
+        client.poll(pollTimeout, startMs, () -&amp;gt; {
+            // since a fetch might be completed by the background thread, we need this poll condition
+            // to ensure that we do not block unnecessarily in poll()
+            return !fetcher.hasCompletedFetches();
         });&lt;br/&gt;
 &lt;br/&gt;
         // after the long poll, we should check whether the group needs to rebalance&lt;br/&gt;
         // prior to returning data so that the group can stabilize faster&lt;br/&gt;
-        if (coordinator.needRejoin())&lt;br/&gt;
+        if (coordinator.rejoinNeededOrPending()) {
             return Collections.emptyMap();
+        }&lt;br/&gt;
 &lt;br/&gt;
         return fetcher.fetchedRecords();&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
+    private long remainingTimeAtLeastZero(final long timeoutMs, final long elapsedTime) {
+        return Math.max(0, timeoutMs - elapsedTime);
+    }&lt;br/&gt;
+&lt;br/&gt;
     /**&lt;br/&gt;
-     * Commit offsets returned on the last {@link #poll(long) poll()} for all the subscribed list of topics and partitions.&lt;br/&gt;
+     * Commit offsets returned on the last {@link #poll(Duration) poll()} for all the subscribed list of topics and&lt;br/&gt;
+     * partitions.&lt;br/&gt;
      * &amp;lt;p&amp;gt;&lt;br/&gt;
      * This commits offsets only to Kafka. The offsets committed using this API will be used on the first fetch after&lt;br/&gt;
      * every rebalance and also on startup. As such, if you need to store offsets in anything other than Kafka, this API&lt;br/&gt;
@@ -1260,7 +1330,7 @@ public void commitSync(final Map&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt; offsets) {&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
-     * Commit offsets returned on the last {@link #poll(long) poll()} for all the subscribed list of topics and partition.&lt;br/&gt;
+     * Commit offsets returned on the last {@link #poll(Duration) poll()} for all the subscribed list of topics and partition.&lt;br/&gt;
      * Same as {@link #commitAsync(OffsetCommitCallback) commitAsync(null)}&lt;br/&gt;
      */&lt;br/&gt;
     @Override&lt;br/&gt;
@@ -1269,7 +1339,7 @@ public void commitAsync() {&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
-     * Commit offsets returned on the last {@link #poll(long) poll()} for the subscribed list of topics and partitions.&lt;br/&gt;
+     * Commit offsets returned on the last {@link #poll(Duration) poll()} for the subscribed list of topics and partitions.&lt;br/&gt;
      * &amp;lt;p&amp;gt;&lt;br/&gt;
      * This commits offsets only to Kafka. The offsets committed using this API will be used on the first fetch after&lt;br/&gt;
      * every rebalance and also on startup. As such, if you need to store offsets in anything other than Kafka, this API&lt;br/&gt;
@@ -1327,7 +1397,7 @@ public void commitAsync(final Map&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt; offsets, Of&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
-     * Overrides the fetch offsets that the consumer will use on the next {@link #poll(long) poll(timeout)}. If this API&lt;br/&gt;
+     * Overrides the fetch offsets that the consumer will use on the next {@link #poll(Duration) poll(timeout)}. If this API&lt;br/&gt;
      * is invoked for the same partition more than once, the latest offset will be used on the next poll(). Note that&lt;br/&gt;
      * you may lose data if this API is arbitrarily used in the middle of consumption, to reset the fetch offsets&lt;br/&gt;
      *&lt;br/&gt;
@@ -1350,7 +1420,7 @@ public void seek(TopicPartition partition, long offset) {&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
      * Seek to the first offset for each of the given partitions. This function evaluates lazily, seeking to the&lt;br/&gt;
-     * first offset in all partitions only when {@link #poll(long)} or {@link #position(TopicPartition)} are called.&lt;br/&gt;
+     * first offset in all partitions only when {@link #poll(Duration)} or {@link #position(TopicPartition)} are called.&lt;br/&gt;
      * If no partitions are provided, seek to the first offset for all of the currently assigned partitions.&lt;br/&gt;
      *&lt;br/&gt;
      * @throws IllegalArgumentException if {@code partitions} is {@code null} or the provided TopicPartition is not assigned to this consumer&lt;br/&gt;
@@ -1373,7 +1443,7 @@ public void seekToBeginning(Collection&amp;lt;TopicPartition&amp;gt; partitions) {&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
      * Seek to the last offset for each of the given partitions. This function evaluates lazily, seeking to the&lt;br/&gt;
-     * final offset in all partitions only when {@link #poll(long)} or {@link #position(TopicPartition)} are called.&lt;br/&gt;
+     * final offset in all partitions only when {@link #poll(Duration)} or {@link #position(TopicPartition)} are called.&lt;br/&gt;
      * If no partitions are provided, seek to the final offset for all of the currently assigned partitions.&lt;br/&gt;
      * &amp;lt;p&amp;gt;&lt;br/&gt;
      * If {@code isolation.level=read_committed}, the end offset will be the Last Stable Offset, i.e., the offset&lt;br/&gt;
@@ -1426,7 +1496,9 @@ public long position(TopicPartition partition) {&lt;br/&gt;
             Long offset = this.subscriptions.position(partition);&lt;br/&gt;
             while (offset == null) {&lt;br/&gt;
                 // batch update fetch positions for any partitions without a valid position&lt;br/&gt;
-                updateFetchPositions();&lt;br/&gt;
+                while (!updateFetchPositions(Long.MAX_VALUE)) {
+                    log.warn(&quot;Still updating fetch positions&quot;);
+                }&lt;br/&gt;
                 client.poll(retryBackoffMs);&lt;br/&gt;
                 offset = this.subscriptions.position(partition);&lt;br/&gt;
             }&lt;br/&gt;
@@ -1457,7 +1529,13 @@ public long position(TopicPartition partition) {&lt;br/&gt;
     public OffsetAndMetadata committed(TopicPartition partition) {&lt;br/&gt;
         acquireAndEnsureOpen();&lt;br/&gt;
         try {&lt;br/&gt;
-            Map&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt; offsets = coordinator.fetchCommittedOffsets(Collections.singleton(partition));&lt;br/&gt;
+            Map&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt; offsets = null;&lt;br/&gt;
+            while (offsets == null) {
+                offsets = coordinator.fetchCommittedOffsets(
+                    Collections.singleton(partition),
+                    Long.MAX_VALUE
+                );
+            }&lt;br/&gt;
             return offsets.get(partition);&lt;br/&gt;
         } finally {&lt;br/&gt;
             release();&lt;br/&gt;
@@ -1477,6 +1555,7 @@ public OffsetAndMetadata committed(TopicPartition partition) {&lt;br/&gt;
      * does not already have any metadata about the given topic.&lt;br/&gt;
      *&lt;br/&gt;
      * @param topic The topic to get partition metadata for&lt;br/&gt;
+     *&lt;br/&gt;
      * @return The list of partitions&lt;br/&gt;
      * @throws org.apache.kafka.common.errors.WakeupException if {@link #wakeup()} is called before or while this&lt;br/&gt;
      *             function is called&lt;br/&gt;
@@ -1510,6 +1589,7 @@ public OffsetAndMetadata committed(TopicPartition partition) {&lt;br/&gt;
      * remote call to the server.&lt;br/&gt;
 &lt;br/&gt;
      * @return The map of topics and its partitions&lt;br/&gt;
+     *&lt;br/&gt;
      * @throws org.apache.kafka.common.errors.WakeupException if {@link #wakeup()} is called before or while this&lt;br/&gt;
      *             function is called&lt;br/&gt;
      * @throws org.apache.kafka.common.errors.InterruptException if the calling thread is interrupted before or while&lt;br/&gt;
@@ -1529,7 +1609,7 @@ public OffsetAndMetadata committed(TopicPartition partition) {&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
-     * Suspend fetching from the requested partitions. Future calls to {@link #poll(long)} will not return&lt;br/&gt;
+     * Suspend fetching from the requested partitions. Future calls to {@link #poll(Duration)} will not return&lt;br/&gt;
      * any records from these partitions until they have been resumed using {@link #resume(Collection)}.&lt;br/&gt;
      * Note that this method does not affect partition subscription. In particular, it does not cause a group&lt;br/&gt;
      * rebalance when automatic assignment is used.&lt;br/&gt;
@@ -1551,7 +1631,7 @@ public void pause(Collection&amp;lt;TopicPartition&amp;gt; partitions) {&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
      * Resume specified partitions which have been paused with {@link #pause(Collection)}. New calls to&lt;br/&gt;
-     * {@link #poll(long)} will return records from these partitions if there are any to be fetched.&lt;br/&gt;
+     * {@link #poll(Duration)} will return records from these partitions if there are any to be fetched.&lt;br/&gt;
      * If the partitions were not previously paused, this method is a no-op.&lt;br/&gt;
      * @param partitions The partitions which should be resumed&lt;br/&gt;
      * @throws IllegalStateException if one of the provided partitions is not assigned to this consumer&lt;br/&gt;
@@ -1593,6 +1673,7 @@ public void resume(Collection&amp;lt;TopicPartition&amp;gt; partitions) {&lt;br/&gt;
      * will be returned for that partition.&lt;br/&gt;
      *&lt;br/&gt;
      * @param timestampsToSearch the mapping from partition to the timestamp to look up.&lt;br/&gt;
+     *&lt;br/&gt;
      * @return a mapping from partition to the timestamp and offset of the first message with timestamp greater&lt;br/&gt;
      *         than or equal to the target timestamp. {@code null} will be returned for the partition if there is no&lt;br/&gt;
      *         such message.&lt;br/&gt;
@@ -1772,18 +1853,18 @@ private void close(long timeoutMs, boolean swallowException) {&lt;br/&gt;
      * @throws org.apache.kafka.common.errors.AuthenticationException if authentication fails. See the exception for more details&lt;br/&gt;
      * @throws NoOffsetForPartitionException If no offset is stored for a given partition and no offset reset policy is&lt;br/&gt;
      *             defined&lt;br/&gt;
-     * @return true if all assigned positions have a position, false otherwise&lt;br/&gt;
+     * @return true iff the operation completed without timing out&lt;br/&gt;
      */&lt;br/&gt;
-    private boolean updateFetchPositions() {&lt;br/&gt;
-        if (subscriptions.hasAllFetchPositions())&lt;br/&gt;
-            return true;&lt;br/&gt;
+    private boolean updateFetchPositions(final long timeoutMs) {&lt;br/&gt;
+        cachedSubscriptionHashAllFetchPositions = subscriptions.hasAllFetchPositions();&lt;br/&gt;
+        if (cachedSubscriptionHashAllFetchPositions) return true;&lt;br/&gt;
 &lt;br/&gt;
         // If there are any partitions which do not have a valid position and are not&lt;br/&gt;
         // awaiting reset, then we need to fetch committed offsets. We will only do a&lt;br/&gt;
         // coordinator lookup if there are partitions which have missing positions, so&lt;br/&gt;
         // a consumer with manually assigned partitions can avoid a coordinator dependence&lt;br/&gt;
         // by always ensuring that assigned partitions have an initial position.&lt;br/&gt;
-        coordinator.refreshCommittedOffsetsIfNeeded();&lt;br/&gt;
+        if (!coordinator.refreshCommittedOffsetsIfNeeded(timeoutMs)) return false;&lt;br/&gt;
 &lt;br/&gt;
         // If there are partitions still needing a position and a reset policy is defined,&lt;br/&gt;
         // request reset using the default policy. If no reset strategy is defined and there&lt;br/&gt;
@@ -1794,7 +1875,7 @@ private boolean updateFetchPositions() {
         // partitions which are awaiting reset.
         fetcher.resetOffsetsIfNeeded();
 
-        return false;
+        return true;
     }&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
@@ -1835,4 +1916,5 @@ private void throwIfNoAssignorsConfigured() {
             throw new IllegalStateException(&quot;Must configure at least one partition assigner class name to &quot; +
                 ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG + &quot; configuration property&quot;);
     }&lt;br/&gt;
+&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/MockConsumer.java b/clients/src/main/java/org/apache/kafka/clients/consumer/MockConsumer.java&lt;br/&gt;
index ceb7024b97b..479a9ffaaf0 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/consumer/MockConsumer.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/MockConsumer.java&lt;br/&gt;
@@ -25,6 +25,7 @@&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition;&lt;br/&gt;
 import org.apache.kafka.common.errors.WakeupException;&lt;br/&gt;
 &lt;br/&gt;
+import java.time.Duration;&lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
 import java.util.Collection;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
@@ -43,7 +44,7 @@&lt;br/&gt;
 /**&lt;br/&gt;
  * A mock of the {@link Consumer} interface you can use for testing code that uses Kafka. This class is &amp;lt;i&amp;gt; not&lt;br/&gt;
  * threadsafe &amp;lt;/i&amp;gt;. However, you can use the {@link #schedulePollTask(Runnable)} method to write multithreaded tests&lt;br/&gt;
- * where a driver thread waits for {@link #poll(long)} to be called by a background thread and then can safely perform&lt;br/&gt;
+ * where a driver thread waits for {@link #poll(Duration)} to be called by a background thread and then can safely perform&lt;br/&gt;
  * operations during a callback.&lt;br/&gt;
  */&lt;br/&gt;
 public class MockConsumer&amp;lt;K, V&amp;gt; implements Consumer&amp;lt;K, V&amp;gt; {&lt;br/&gt;
@@ -146,8 +147,14 @@ public synchronized void unsubscribe() {
         subscriptions.unsubscribe();
     }&lt;br/&gt;
 &lt;br/&gt;
+    @Deprecated&lt;br/&gt;
     @Override&lt;br/&gt;
     public synchronized ConsumerRecords&amp;lt;K, V&amp;gt; poll(long timeout) {
+        return poll(Duration.ZERO);
+    }&lt;br/&gt;
+&lt;br/&gt;
+    @Override&lt;br/&gt;
+    public synchronized ConsumerRecords&amp;lt;K, V&amp;gt; poll(final Duration timeout) {&lt;br/&gt;
         ensureNotClosed();&lt;br/&gt;
 &lt;br/&gt;
         // Synchronize around the entire execution so new tasks to be triggered on subsequent poll calls can be added in&lt;br/&gt;
@@ -401,7 +408,7 @@ public synchronized void wakeup() {&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
-     * Schedule a task to be executed during a poll(). One enqueued task will be executed per {@link #poll(long)}&lt;br/&gt;
+     * Schedule a task to be executed during a poll(). One enqueued task will be executed per {@link #poll(Duration)}&lt;br/&gt;
      * invocation. You can use this repeatedly to mock out multiple responses to poll invocations.&lt;br/&gt;
      * @param task the task to be executed&lt;br/&gt;
      */&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/OffsetCommitCallback.java b/clients/src/main/java/org/apache/kafka/clients/consumer/OffsetCommitCallback.java&lt;br/&gt;
index b217a632574..383c1c82bce 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/consumer/OffsetCommitCallback.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/OffsetCommitCallback.java&lt;br/&gt;
@@ -23,7 +23,7 @@&lt;br/&gt;
 &lt;br/&gt;
 /**&lt;br/&gt;
  * A callback interface that the user can implement to trigger custom actions when a commit request completes. The callback&lt;br/&gt;
- * may be executed in any thread calling {@link Consumer#poll(long) poll()}.&lt;br/&gt;
+ * may be executed in any thread calling {@link Consumer#poll(java.time.Duration) poll()}.&lt;br/&gt;
  */&lt;br/&gt;
 public interface OffsetCommitCallback {&lt;br/&gt;
 &lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/AbstractCoordinator.java b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/AbstractCoordinator.java&lt;br/&gt;
index dd4bb7038f3..adbaae776ab 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/AbstractCoordinator.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/AbstractCoordinator.java&lt;br/&gt;
@@ -58,6 +58,7 @@&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
 import java.util.List;&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
+import java.util.Objects;&lt;br/&gt;
 import java.util.concurrent.TimeUnit;&lt;br/&gt;
 import java.util.concurrent.atomic.AtomicReference;&lt;br/&gt;
 &lt;br/&gt;
@@ -198,46 +199,44 @@ protected abstract void onJoinComplete(int generation,&lt;br/&gt;
                                            ByteBuffer memberAssignment);&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
-     * Block until the coordinator for this group is known and is ready to receive requests.&lt;br/&gt;
-     */&lt;br/&gt;
-    public synchronized void ensureCoordinatorReady() {
-        // Using zero as current time since timeout is effectively infinite
-        ensureCoordinatorReady(0, Long.MAX_VALUE);
-    }&lt;br/&gt;
-&lt;br/&gt;
-    /**&lt;br/&gt;
+     * Visible for testing.&lt;br/&gt;
+     *&lt;br/&gt;
      * Ensure that the coordinator is ready to receive requests.&lt;br/&gt;
-     * @param startTimeMs Current time in milliseconds&lt;br/&gt;
+     *&lt;br/&gt;
      * @param timeoutMs Maximum time to wait to discover the coordinator&lt;br/&gt;
      * @return true If coordinator discovery and initial connection succeeded, false otherwise&lt;br/&gt;
      */&lt;br/&gt;
-    protected synchronized boolean ensureCoordinatorReady(long startTimeMs, long timeoutMs) {&lt;br/&gt;
-        long remainingMs = timeoutMs;&lt;br/&gt;
+    protected synchronized boolean ensureCoordinatorReady(final long timeoutMs) {&lt;br/&gt;
+        final long startTimeMs = time.milliseconds();&lt;br/&gt;
+        long elapsedTime = 0L;&lt;br/&gt;
 &lt;br/&gt;
         while (coordinatorUnknown()) {&lt;br/&gt;
-            RequestFuture&amp;lt;Void&amp;gt; future = lookupCoordinator();&lt;br/&gt;
-            client.poll(future, remainingMs);&lt;br/&gt;
+            final RequestFuture&amp;lt;Void&amp;gt; future = lookupCoordinator();&lt;br/&gt;
+            client.poll(future, remainingTimeAtLeastZero(timeoutMs, elapsedTime));&lt;br/&gt;
+            if (!future.isDone()) {
+                // ran out of time
+                break;
+            }&lt;br/&gt;
 &lt;br/&gt;
             if (future.failed()) {&lt;br/&gt;
                 if (future.isRetriable()) {
-                    remainingMs = timeoutMs - (time.milliseconds() - startTimeMs);
-                    if (remainingMs &amp;lt;= 0)
-                        break;
+                    elapsedTime = time.milliseconds() - startTimeMs;
+
+                    if (elapsedTime &amp;gt;= timeoutMs) break;
 
                     log.debug(&quot;Coordinator discovery failed, refreshing metadata&quot;);
-                    client.awaitMetadataUpdate(remainingMs);
+                    client.awaitMetadataUpdate(remainingTimeAtLeastZero(timeoutMs, elapsedTime));
+                    elapsedTime = time.milliseconds() - startTimeMs;
                 } else&lt;br/&gt;
                     throw future.exception();&lt;br/&gt;
             } else if (coordinator != null &amp;amp;&amp;amp; client.isUnavailable(coordinator)) {
                 // we found the coordinator, but the connection has failed, so mark
                 // it dead and backoff before retrying discovery
                 markCoordinatorUnknown();
-                time.sleep(retryBackoffMs);
+                final long sleepTime = Math.min(retryBackoffMs, remainingTimeAtLeastZero(timeoutMs, elapsedTime));
+                time.sleep(sleepTime);
+                elapsedTime += sleepTime;
             }&lt;br/&gt;
-&lt;br/&gt;
-            remainingMs = timeoutMs - (time.milliseconds() - startTimeMs);&lt;br/&gt;
-            if (remainingMs &amp;lt;= 0)&lt;br/&gt;
-                break;&lt;br/&gt;
         }&lt;br/&gt;
 &lt;br/&gt;
         return !coordinatorUnknown();&lt;br/&gt;
@@ -261,15 +260,14 @@ private synchronized void clearFindCoordinatorFuture() {&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
-     * Check whether the group should be rejoined (e.g. if metadata changes)&lt;br/&gt;
+     * Check whether the group should be rejoined (e.g. if metadata changes) or whether a&lt;br/&gt;
+     * rejoin request is already in flight and needs to be completed.&lt;br/&gt;
+     *&lt;br/&gt;
      * @return true if it should, false otherwise&lt;br/&gt;
      */&lt;br/&gt;
-    protected synchronized boolean needRejoin() {
-        return rejoinNeeded;
-    }&lt;br/&gt;
-&lt;br/&gt;
-    private synchronized boolean rejoinIncomplete() {&lt;br/&gt;
-        return joinFuture != null;&lt;br/&gt;
+    protected synchronized boolean rejoinNeededOrPending() {
+        // if there&apos;s a pending joinFuture, we should try to complete handling it.
+        return rejoinNeeded || joinFuture != null;
     }&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
@@ -309,11 +307,28 @@ protected synchronized long timeToNextHeartbeat(long now) {&lt;br/&gt;
      * Ensure that the group is active (i.e. joined and synced)&lt;br/&gt;
      */&lt;br/&gt;
     public void ensureActiveGroup() {&lt;br/&gt;
+        while (!ensureActiveGroup(Long.MAX_VALUE)) {
+            log.warn(&quot;still waiting to ensure active group&quot;);
+        }&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    /**&lt;br/&gt;
+     * Ensure the group is active (i.e., joined and synced)&lt;br/&gt;
+     *&lt;br/&gt;
+     * @param timeoutMs A time budget for ensuring the group is active&lt;br/&gt;
+     * @return true iff the group is active&lt;br/&gt;
+     */&lt;br/&gt;
+    boolean ensureActiveGroup(final long timeoutMs) {&lt;br/&gt;
+        final long startTime = time.milliseconds();&lt;br/&gt;
         // always ensure that the coordinator is ready because we may have been disconnected&lt;br/&gt;
         // when sending heartbeats and does not necessarily require us to rejoin the group.&lt;br/&gt;
-        ensureCoordinatorReady();&lt;br/&gt;
+        if (!ensureCoordinatorReady(timeoutMs)) {
+            return false;
+        }&lt;br/&gt;
+&lt;br/&gt;
         startHeartbeatThreadIfNeeded();&lt;br/&gt;
-        joinGroupIfNeeded();&lt;br/&gt;
+&lt;br/&gt;
+        return joinGroupIfNeeded(remainingTimeAtLeastZero(timeoutMs, time.milliseconds() - startTime));&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     private synchronized void startHeartbeatThreadIfNeeded() {&lt;br/&gt;
@@ -345,10 +360,23 @@ private void closeHeartbeatThread() {&lt;br/&gt;
         }&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
-    // visible for testing. Joins the group without starting the heartbeat thread.&lt;br/&gt;
-    void joinGroupIfNeeded() {&lt;br/&gt;
-        while (needRejoin() || rejoinIncomplete()) {&lt;br/&gt;
-            ensureCoordinatorReady();&lt;br/&gt;
+    /**&lt;br/&gt;
+     * Joins the group without starting the heartbeat thread.&lt;br/&gt;
+     *&lt;br/&gt;
+     * Visible for testing.&lt;br/&gt;
+     *&lt;br/&gt;
+     * @param timeoutMs Time to complete this action&lt;br/&gt;
+     * @return true iff the operation succeeded&lt;br/&gt;
+     */&lt;br/&gt;
+    boolean joinGroupIfNeeded(final long timeoutMs) {&lt;br/&gt;
+        final long startTime = time.milliseconds();&lt;br/&gt;
+        long elapsedTime = 0L;&lt;br/&gt;
+&lt;br/&gt;
+        while (rejoinNeededOrPending()) {&lt;br/&gt;
+            if (!ensureCoordinatorReady(remainingTimeAtLeastZero(timeoutMs, elapsedTime))) {
+                return false;
+            }&lt;br/&gt;
+            elapsedTime = time.milliseconds() - startTime;&lt;br/&gt;
 &lt;br/&gt;
             // call onJoinPrepare if needed. We set a flag to make sure that we do not call it a second&lt;br/&gt;
             // time if the client is woken up before a pending rebalance completes. This must be called&lt;br/&gt;
@@ -360,8 +388,12 @@ void joinGroupIfNeeded() {
                 needsJoinPrepare = false;
             }&lt;br/&gt;
 &lt;br/&gt;
-            RequestFuture&amp;lt;ByteBuffer&amp;gt; future = initiateJoinGroup();&lt;br/&gt;
-            client.poll(future);&lt;br/&gt;
+            final RequestFuture&amp;lt;ByteBuffer&amp;gt; future = initiateJoinGroup();&lt;br/&gt;
+            client.poll(future, remainingTimeAtLeastZero(timeoutMs, elapsedTime));&lt;br/&gt;
+            if (!future.isDone()) {
+                // we ran out of time
+                return false;
+            }&lt;br/&gt;
 &lt;br/&gt;
             if (future.succeeded()) {&lt;br/&gt;
                 onJoinComplete(generation.generationId, generation.memberId, generation.protocol, future.value());&lt;br/&gt;
@@ -372,7 +404,7 @@ void joinGroupIfNeeded() {
                 needsJoinPrepare = true;
             } else {
                 resetJoinGroupFuture();
-                RuntimeException exception = future.exception();
+                final RuntimeException exception = future.exception();
                 if (exception instanceof UnknownMemberIdException ||
                         exception instanceof RebalanceInProgressException ||
                         exception instanceof IllegalGenerationException)
@@ -381,7 +413,16 @@ else if (!future.isRetriable())
                     throw exception;
                 time.sleep(retryBackoffMs);
             }&lt;br/&gt;
+&lt;br/&gt;
+            if (rejoinNeededOrPending()) {
+                elapsedTime = time.milliseconds() - startTime;
+            }&lt;br/&gt;
         }&lt;br/&gt;
+        return true;&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    private long remainingTimeAtLeastZero(final long timeout, final long elapsedTime) {
+        return Math.max(0, timeout - elapsedTime);
     }&lt;br/&gt;
 &lt;br/&gt;
     private synchronized void resetJoinGroupFuture() {&lt;br/&gt;
@@ -1035,6 +1076,21 @@ public Generation(int generationId, String memberId, String protocol) {
             this.memberId = memberId;
             this.protocol = protocol;
         }&lt;br/&gt;
+&lt;br/&gt;
+        @Override&lt;br/&gt;
+        public boolean equals(final Object o) {
+            if (this == o) return true;
+            if (o == null || getClass() != o.getClass()) return false;
+            final Generation that = (Generation) o;
+            return generationId == that.generationId &amp;amp;&amp;amp;
+                Objects.equals(memberId, that.memberId) &amp;amp;&amp;amp;
+                Objects.equals(protocol, that.protocol);
+        }&lt;br/&gt;
+&lt;br/&gt;
+        @Override&lt;br/&gt;
+        public int hashCode() {
+            return Objects.hash(generationId, memberId, protocol);
+        }&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     private static class UnjoinedGroupException extends RetriableException {&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java&lt;br/&gt;
index eec070ec663..e8c5bc6e598 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java&lt;br/&gt;
@@ -31,6 +31,7 @@&lt;br/&gt;
 import org.apache.kafka.common.errors.GroupAuthorizationException;&lt;br/&gt;
 import org.apache.kafka.common.errors.InterruptException;&lt;br/&gt;
 import org.apache.kafka.common.errors.RetriableException;&lt;br/&gt;
+import org.apache.kafka.common.errors.TimeoutException;&lt;br/&gt;
 import org.apache.kafka.common.errors.TopicAuthorizationException;&lt;br/&gt;
 import org.apache.kafka.common.errors.WakeupException;&lt;br/&gt;
 import org.apache.kafka.common.metrics.Measurable;&lt;br/&gt;
@@ -86,6 +87,32 @@&lt;br/&gt;
     private MetadataSnapshot assignmentSnapshot;&lt;br/&gt;
     private long nextAutoCommitDeadline;&lt;br/&gt;
 &lt;br/&gt;
+    // hold onto request&amp;amp;future for commited offset requests to enable async calls.&lt;br/&gt;
+    private PendingCommittedOffsetRequest pendingCommittedOffsetRequest = null;&lt;br/&gt;
+&lt;br/&gt;
+    private static class PendingCommittedOffsetRequest {&lt;br/&gt;
+        private final Set&amp;lt;TopicPartition&amp;gt; request;&lt;br/&gt;
+        private final Generation generation;&lt;br/&gt;
+        private final RequestFuture&amp;lt;Map&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt;&amp;gt; response;&lt;br/&gt;
+&lt;br/&gt;
+        private PendingCommittedOffsetRequest(final Set&amp;lt;TopicPartition&amp;gt; request,&lt;br/&gt;
+                                              final Generation generationAtRequestTime,&lt;br/&gt;
+                                              final RequestFuture&amp;lt;Map&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt;&amp;gt; response&lt;br/&gt;
+        ) {
+            if (request == null) throw new NullPointerException();
+            if (response == null) throw new NullPointerException();
+
+            this.request = request;
+            this.generation = generationAtRequestTime;
+            this.response = response;
+        }&lt;br/&gt;
+&lt;br/&gt;
+        private boolean sameRequest(final Set&amp;lt;TopicPartition&amp;gt; currentRequest, final Generation currentGeneration) {
+            return (generation == null ? currentGeneration == null : generation.equals(currentGeneration))
+                &amp;amp;&amp;amp; request.equals(currentRequest);
+        }&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
     /**&lt;br/&gt;
      * Initialize the coordination manager.&lt;br/&gt;
      */&lt;br/&gt;
@@ -243,7 +270,7 @@ protected void onJoinComplete(int generation,&lt;br/&gt;
         // update the metadata and enforce a refresh to make sure the fetcher can start&lt;br/&gt;
         // fetching data in the next iteration&lt;br/&gt;
         this.metadata.setTopics(subscriptions.groupSubscription());&lt;br/&gt;
-        client.ensureFreshMetadata();&lt;br/&gt;
+        if (!client.ensureFreshMetadata(Long.MAX_VALUE)) throw new TimeoutException();&lt;br/&gt;
 &lt;br/&gt;
         // give the assignor a chance to update internal state based on the received assignment&lt;br/&gt;
         assignor.onAssignment(assignment);&lt;br/&gt;
@@ -268,30 +295,43 @@ protected void onJoinComplete(int generation,&lt;br/&gt;
      * Poll for coordinator events. This ensures that the coordinator is known and that the consumer&lt;br/&gt;
      * has joined the group (if it is using group management). This also handles periodic offset commits&lt;br/&gt;
      * if they are enabled.&lt;br/&gt;
+     * &amp;lt;p&amp;gt;&lt;br/&gt;
+     * Returns early if the timeout expires&lt;br/&gt;
      *&lt;br/&gt;
-     * @param now current time in milliseconds&lt;br/&gt;
+     * @param timeoutMs The amount of time, in ms, allotted for this operation.&lt;br/&gt;
+     * @return true iff the operation succeeded&lt;br/&gt;
      */&lt;br/&gt;
-    public void poll(long now, long remainingMs) {&lt;br/&gt;
+    public boolean poll(final long timeoutMs) {&lt;br/&gt;
+        final long startTime = time.milliseconds();&lt;br/&gt;
+        long elapsed = 0L;&lt;br/&gt;
+&lt;br/&gt;
         invokeCompletedOffsetCommitCallbacks();&lt;br/&gt;
 &lt;br/&gt;
         if (subscriptions.partitionsAutoAssigned()) {&lt;br/&gt;
             if (coordinatorUnknown()) {&lt;br/&gt;
-                ensureCoordinatorReady();&lt;br/&gt;
-                now = time.milliseconds();&lt;br/&gt;
+                if (!ensureCoordinatorReady(remainingTimeAtLeastZero(timeoutMs, elapsed))) {
+                    return false;
+                }&lt;br/&gt;
+                elapsed = time.milliseconds() - startTime;&lt;br/&gt;
             }&lt;br/&gt;
 &lt;br/&gt;
-            if (needRejoin()) {&lt;br/&gt;
+            if (rejoinNeededOrPending()) {&lt;br/&gt;
                 // due to a race condition between the initial metadata fetch and the initial rebalance,&lt;br/&gt;
                 // we need to ensure that the metadata is fresh before joining initially. This ensures&lt;br/&gt;
                 // that we have matched the pattern against the cluster&apos;s topics at least once before joining.&lt;br/&gt;
-                if (subscriptions.hasPatternSubscription())&lt;br/&gt;
-                    client.ensureFreshMetadata();&lt;br/&gt;
+                if (subscriptions.hasPatternSubscription()) {&lt;br/&gt;
+                    if (!client.ensureFreshMetadata(remainingTimeAtLeastZero(timeoutMs, elapsed))) {
+                        return false;
+                    }&lt;br/&gt;
+                    elapsed = time.milliseconds() - startTime;&lt;br/&gt;
+                }&lt;br/&gt;
 &lt;br/&gt;
-                ensureActiveGroup();&lt;br/&gt;
-                now = time.milliseconds();&lt;br/&gt;
+                if (!ensureActiveGroup(remainingTimeAtLeastZero(timeoutMs, elapsed))) {+                    return false;+                }&lt;br/&gt;
             }&lt;br/&gt;
 &lt;br/&gt;
-            pollHeartbeat(now);&lt;br/&gt;
+            pollHeartbeat(startTime);&lt;br/&gt;
         } else {&lt;br/&gt;
             // For manually assigned partitions, if there are no ready nodes, await metadata.&lt;br/&gt;
             // If connections to all nodes fail, wakeups triggered while attempting to send fetch&lt;br/&gt;
@@ -301,18 +341,23 @@ public void poll(long now, long remainingMs) {&lt;br/&gt;
             // When group management is used, metadata wait is already performed for this scenario as&lt;br/&gt;
             // coordinator is unknown, hence this check is not required.&lt;br/&gt;
             if (metadata.updateRequested() &amp;amp;&amp;amp; !client.hasReadyNodes()) {&lt;br/&gt;
-                boolean metadataUpdated = client.awaitMetadataUpdate(remainingMs);&lt;br/&gt;
-                if (!metadataUpdated &amp;amp;&amp;amp; !client.hasReadyNodes())&lt;br/&gt;
-                    return;&lt;br/&gt;
-                now = time.milliseconds();&lt;br/&gt;
+                final boolean metadataUpdated = client.awaitMetadataUpdate(remainingTimeAtLeastZero(timeoutMs, elapsed));&lt;br/&gt;
+                if (!metadataUpdated &amp;amp;&amp;amp; !client.hasReadyNodes()) {
+                    return false;
+                }&lt;br/&gt;
             }&lt;br/&gt;
         }&lt;br/&gt;
 &lt;br/&gt;
-        maybeAutoCommitOffsetsAsync(now);&lt;br/&gt;
+        maybeAutoCommitOffsetsAsync(startTime);&lt;br/&gt;
+        return true;&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    private long remainingTimeAtLeastZero(final long timeoutMs, final long elapsed) {
+        return Math.max(0, timeoutMs - elapsed);
     }&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
-     * Return the time to the next needed invocation of {@link #poll(long, long)}.&lt;br/&gt;
+     * Return the time to the next needed invocation of {@link #poll(long)}.&lt;br/&gt;
      * @param now current time in milliseconds&lt;br/&gt;
      * @return the maximum time in milliseconds the caller should wait before the next invocation of poll()&lt;br/&gt;
      */&lt;br/&gt;
@@ -349,7 +394,7 @@ public long timeToNextPoll(long now) {&lt;br/&gt;
 &lt;br/&gt;
         // update metadata (if needed) and keep track of the metadata used for assignment so that&lt;br/&gt;
         // we can check after rebalance completion whether anything has changed&lt;br/&gt;
-        client.ensureFreshMetadata();&lt;br/&gt;
+        if (!client.ensureFreshMetadata(Long.MAX_VALUE)) throw new TimeoutException();&lt;br/&gt;
 &lt;br/&gt;
         isLeader = true;&lt;br/&gt;
 &lt;br/&gt;
@@ -385,7 +430,7 @@ public long timeToNextPoll(long now) {
             allSubscribedTopics.addAll(assignedTopics);
             this.subscriptions.groupSubscribe(allSubscribedTopics);
             metadata.setTopics(this.subscriptions.groupSubscription());
-            client.ensureFreshMetadata();
+            if (!client.ensureFreshMetadata(Long.MAX_VALUE)) throw new TimeoutException();
         }&lt;br/&gt;
 &lt;br/&gt;
         assignmentSnapshot = metadataSnapshot;&lt;br/&gt;
@@ -423,7 +468,7 @@ protected void onJoinPrepare(int generation, String memberId) {&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     @Override&lt;br/&gt;
-    public boolean needRejoin() {&lt;br/&gt;
+    public boolean rejoinNeededOrPending() {&lt;br/&gt;
         if (!subscriptions.partitionsAutoAssigned())&lt;br/&gt;
             return false;&lt;br/&gt;
 &lt;br/&gt;
@@ -435,60 +480,94 @@ public boolean needRejoin() {
         if (joinedSubscription != null &amp;amp;&amp;amp; !joinedSubscription.equals(subscriptions.subscription()))
             return true;
 
-        return super.needRejoin();
+        return super.rejoinNeededOrPending();
     }&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
      * Refresh the committed offsets for provided partitions.&lt;br/&gt;
+     *&lt;br/&gt;
+     * @param timeoutMs A time limit for this operation&lt;br/&gt;
+     * @return true iff the operation completed within the timeout&lt;br/&gt;
      */&lt;br/&gt;
-    public void refreshCommittedOffsetsIfNeeded() {&lt;br/&gt;
-        Set&amp;lt;TopicPartition&amp;gt; missingFetchPositions = subscriptions.missingFetchPositions();&lt;br/&gt;
-        Map&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt; offsets = fetchCommittedOffsets(missingFetchPositions);&lt;br/&gt;
-        for (Map.Entry&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt; entry : offsets.entrySet()) {&lt;br/&gt;
-            TopicPartition tp = entry.getKey();&lt;br/&gt;
-            long offset = entry.getValue().offset();&lt;br/&gt;
+    public boolean refreshCommittedOffsetsIfNeeded(final long timeoutMs) {&lt;br/&gt;
+        final Set&amp;lt;TopicPartition&amp;gt; missingFetchPositions = subscriptions.missingFetchPositions();&lt;br/&gt;
+&lt;br/&gt;
+        final Map&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt; offsets = fetchCommittedOffsets(missingFetchPositions, timeoutMs);&lt;br/&gt;
+        if (offsets == null) return false;&lt;br/&gt;
+&lt;br/&gt;
+        for (final Map.Entry&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt; entry : offsets.entrySet()) {&lt;br/&gt;
+            final TopicPartition tp = entry.getKey();&lt;br/&gt;
+            final long offset = entry.getValue().offset();&lt;br/&gt;
             log.debug(&quot;Setting offset for partition {} to the committed offset {}&quot;, tp, offset);&lt;br/&gt;
             this.subscriptions.seek(tp, offset);&lt;br/&gt;
         }&lt;br/&gt;
+        return true;&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
      * Fetch the current committed offsets from the coordinator for a set of partitions.&lt;br/&gt;
+     *&lt;br/&gt;
      * @param partitions The partitions to fetch offsets for&lt;br/&gt;
-     * @return A map from partition to the committed offset&lt;br/&gt;
+     * @return A map from partition to the committed offset or null if the operation timed out&lt;br/&gt;
      */&lt;br/&gt;
-    public Map&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt; fetchCommittedOffsets(Set&amp;lt;TopicPartition&amp;gt; partitions) {&lt;br/&gt;
-        if (partitions.isEmpty())&lt;br/&gt;
-            return Collections.emptyMap();&lt;br/&gt;
+    public Map&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt; fetchCommittedOffsets(final Set&amp;lt;TopicPartition&amp;gt; partitions,&lt;br/&gt;
+                                                                        final long timeoutMs) {&lt;br/&gt;
+        if (partitions.isEmpty()) return Collections.emptyMap();&lt;br/&gt;
+&lt;br/&gt;
+        final Generation generation = generation();&lt;br/&gt;
+        if (pendingCommittedOffsetRequest != null &amp;amp;&amp;amp; !pendingCommittedOffsetRequest.sameRequest(partitions, generation)) {
+            // if we were waiting for a different request, then just clear it.
+            pendingCommittedOffsetRequest = null;
+        }&lt;br/&gt;
+&lt;br/&gt;
+        final long startMs = time.milliseconds();&lt;br/&gt;
+        long elapsedTime = 0L;&lt;br/&gt;
 &lt;br/&gt;
         while (true) {&lt;br/&gt;
-            ensureCoordinatorReady();&lt;br/&gt;
+            if (!ensureCoordinatorReady(remainingTimeAtLeastZero(timeoutMs, elapsedTime))) return null;&lt;br/&gt;
+            elapsedTime = time.milliseconds() - startMs;&lt;br/&gt;
 &lt;br/&gt;
             // contact coordinator to fetch committed offsets&lt;br/&gt;
-            RequestFuture&amp;lt;Map&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt;&amp;gt; future = sendOffsetFetchRequest(partitions);&lt;br/&gt;
-            client.poll(future);&lt;br/&gt;
+            final RequestFuture&amp;lt;Map&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt;&amp;gt; future;&lt;br/&gt;
+            if (pendingCommittedOffsetRequest != null) {
+                future = pendingCommittedOffsetRequest.response;
+            } else {
+                future = sendOffsetFetchRequest(partitions);
+                pendingCommittedOffsetRequest = new PendingCommittedOffsetRequest(partitions, generation, future);
 
-            if (future.succeeded())
-                return future.value();
+            }&lt;br/&gt;
+            client.poll(future, remainingTimeAtLeastZero(timeoutMs, elapsedTime));&lt;br/&gt;
 &lt;br/&gt;
-            if (!future.isRetriable())&lt;br/&gt;
-                throw future.exception();&lt;br/&gt;
+            if (future.isDone()) {&lt;br/&gt;
+                pendingCommittedOffsetRequest = null;&lt;br/&gt;
 &lt;br/&gt;
-            time.sleep(retryBackoffMs);&lt;br/&gt;
+                if (future.succeeded()) {
+                    return future.value();
+                } else if (!future.isRetriable()) {
+                    throw future.exception();
+                } else {
+                    elapsedTime = time.milliseconds() - startMs;
+                    final long sleepTime = Math.min(retryBackoffMs, remainingTimeAtLeastZero(startMs, elapsedTime));
+                    time.sleep(sleepTime);
+                    elapsedTime += sleepTime;
+                }&lt;br/&gt;
+            } else {
+                return null;
+            }&lt;br/&gt;
         }&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
-    public void close(long timeoutMs) {&lt;br/&gt;
+    public void close(final long timeoutMs) {&lt;br/&gt;
         // we do not need to re-enable wakeups since we are closing already&lt;br/&gt;
         client.disableWakeups();&lt;br/&gt;
 &lt;br/&gt;
         long now = time.milliseconds();&lt;br/&gt;
-        long endTimeMs = now + timeoutMs;&lt;br/&gt;
+        final long endTimeMs = now + timeoutMs;&lt;br/&gt;
         try {&lt;br/&gt;
             maybeAutoCommitOffsetsSync(timeoutMs);&lt;br/&gt;
             now = time.milliseconds();&lt;br/&gt;
             if (pendingAsyncCommits.get() &amp;gt; 0 &amp;amp;&amp;amp; endTimeMs &amp;gt; now) {
-                ensureCoordinatorReady(now, endTimeMs - now);
+                ensureCoordinatorReady(endTimeMs - now);
                 now = time.milliseconds();
             }&lt;br/&gt;
         } finally {&lt;br/&gt;
@@ -587,7 +666,7 @@ public boolean commitOffsetsSync(Map&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt; offsets,&lt;br/&gt;
         long remainingMs = timeoutMs;&lt;br/&gt;
         do {&lt;br/&gt;
             if (coordinatorUnknown()) {&lt;br/&gt;
-                if (!ensureCoordinatorReady(now, remainingMs))&lt;br/&gt;
+                if (!ensureCoordinatorReady(remainingMs))&lt;br/&gt;
                     return false;&lt;br/&gt;
 &lt;br/&gt;
                 remainingMs = timeoutMs - (time.milliseconds() - startMs);&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerNetworkClient.java b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerNetworkClient.java&lt;br/&gt;
index e1598fa646d..7a9f717e28b 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerNetworkClient.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerNetworkClient.java&lt;br/&gt;
@@ -164,9 +164,13 @@ public boolean awaitMetadataUpdate(long timeout) {&lt;br/&gt;
      * Ensure our metadata is fresh (if an update is expected, this will block&lt;br/&gt;
      * until it has completed).&lt;br/&gt;
      */&lt;br/&gt;
-    public void ensureFreshMetadata() {&lt;br/&gt;
-        if (this.metadata.updateRequested() || this.metadata.timeToNextUpdate(time.milliseconds()) == 0)&lt;br/&gt;
-            awaitMetadataUpdate();&lt;br/&gt;
+    boolean ensureFreshMetadata(final long timeout) {&lt;br/&gt;
+        if (this.metadata.updateRequested() || this.metadata.timeToNextUpdate(time.milliseconds()) == 0) {
+            return awaitMetadataUpdate(timeout);
+        } else {
+            // the metadata is already fresh
+            return true;
+        }&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/common/ClusterResourceListener.java b/clients/src/main/java/org/apache/kafka/common/ClusterResourceListener.java&lt;br/&gt;
index f8f99ece183..97245a393b0 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/common/ClusterResourceListener.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/common/ClusterResourceListener.java&lt;br/&gt;
@@ -36,7 +36,8 @@&lt;br/&gt;
  * {@link org.apache.kafka.common.serialization.Deserializer} : The {@link ClusterResourceListener#onUpdate(ClusterResource)} method will be invoked before {@link org.apache.kafka.common.serialization.Deserializer#deserialize(String, byte[])}&lt;br/&gt;
  * &amp;lt;p&amp;gt;&lt;br/&gt;
  * {@link org.apache.kafka.common.metrics.MetricsReporter} : The {@link ClusterResourceListener#onUpdate(ClusterResource)} method will be invoked after first {@link org.apache.kafka.clients.producer.KafkaProducer#send(ProducerRecord)} invocation for Producer metrics reporter&lt;br/&gt;
- * and after first {@link org.apache.kafka.clients.consumer.KafkaConsumer#poll(long)} invocation for Consumer metrics reporters. The reporter may receive metric events from the network layer before this method is invoked.&lt;br/&gt;
+ * and after first {@link org.apache.kafka.clients.consumer.KafkaConsumer#poll(java.time.Duration)}
&lt;p&gt; invocation for Consumer metrics&lt;br/&gt;
+ * reporters. The reporter may receive metric events from the network layer before this method is invoked.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;&amp;lt;h4&amp;gt;Broker&amp;lt;/h4&amp;gt;&lt;/li&gt;
	&lt;li&gt;There is a single invocation 
{@link ClusterResourceListener#onUpdate(ClusterResource)}
&lt;p&gt; on broker start-up and the cluster metadata will never change.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;p&amp;gt;&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/common/errors/WakeupException.java b/clients/src/main/java/org/apache/kafka/common/errors/WakeupException.java&lt;br/&gt;
index 4726ec13cca..f8ae8403a5d 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/clients/src/main/java/org/apache/kafka/common/errors/WakeupException.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/common/errors/WakeupException.java&lt;br/&gt;
@@ -21,7 +21,7 @@&lt;br/&gt;
 /**&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;Exception used to indicate preemption of a blocking operation by an external thread.&lt;/li&gt;
	&lt;li&gt;For example, 
{@link org.apache.kafka.clients.consumer.KafkaConsumer#wakeup}&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* can be used to break out of an active 
{@link org.apache.kafka.clients.consumer.KafkaConsumer#poll(long)}
&lt;p&gt;,&lt;br/&gt;
+ * can be used to break out of an active &lt;/p&gt;
{@link org.apache.kafka.clients.consumer.KafkaConsumer#poll(java.time.Duration)}
&lt;p&gt;,&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;which would raise an instance of this exception.&lt;br/&gt;
  */&lt;br/&gt;
 public class WakeupException extends KafkaException {&lt;br/&gt;
diff --git a/clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java b/clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java&lt;br/&gt;
index 8c147a58f77..ce722cf12e3 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java&lt;br/&gt;
+++ b/clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java&lt;br/&gt;
@@ -78,6 +78,7 @@&lt;br/&gt;
 import org.junit.rules.ExpectedException;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import java.nio.ByteBuffer;&lt;br/&gt;
+import java.time.Duration;&lt;br/&gt;
 import java.util.Arrays;&lt;br/&gt;
 import java.util.Collection;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
@@ -87,6 +88,7 @@&lt;br/&gt;
 import java.util.List;&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
 import java.util.Properties;&lt;br/&gt;
+import java.util.Queue;&lt;br/&gt;
 import java.util.Set;&lt;br/&gt;
 import java.util.concurrent.ExecutorService;&lt;br/&gt;
 import java.util.concurrent.Executors;&lt;br/&gt;
@@ -353,7 +355,12 @@ public void verifyHeartbeatSent() throws Exception {&lt;br/&gt;
         // initial fetch&lt;br/&gt;
         client.prepareResponseFrom(fetchResponse(tp0, 0, 0), node);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;consumer.poll(0);&lt;br/&gt;
+        // We need two update calls:&lt;br/&gt;
+        // 1. the first call &quot;sends&quot; the metadata update requests&lt;br/&gt;
+        // 2. the second one gets the response we already queued up&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+&lt;br/&gt;
         assertEquals(singleton(tp0), consumer.assignment());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         AtomicBoolean heartbeatReceived = prepareHeartbeatResponse(client, coordinator);&lt;br/&gt;
@@ -362,7 +369,8 @@ public void verifyHeartbeatSent() throws Exception {&lt;br/&gt;
         time.sleep(heartbeatIntervalMs);&lt;br/&gt;
         Thread.sleep(heartbeatIntervalMs);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;consumer.poll(0);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertTrue(heartbeatReceived.get());&lt;br/&gt;
         consumer.close(0, TimeUnit.MILLISECONDS);&lt;br/&gt;
@@ -385,7 +393,9 @@ public void verifyHeartbeatSentWhenFetchedDataReady() throws Exception {&lt;br/&gt;
         consumer.subscribe(singleton(topic), getConsumerRebalanceListener(consumer));&lt;br/&gt;
         Node coordinator = prepareRebalance(client, node, assignor, singletonList(tp0), null);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;consumer.poll(0);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        consumer.poll(Duration.ZERO);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // respond to the outstanding fetch so that we have data available on the next poll&lt;br/&gt;
         client.respondFrom(fetchResponse(tp0, 0, 5), node);&lt;br/&gt;
@@ -397,12 +407,63 @@ public void verifyHeartbeatSentWhenFetchedDataReady() throws Exception &lt;/p&gt;
{
         time.sleep(heartbeatIntervalMs);
         Thread.sleep(heartbeatIntervalMs);
 
-        consumer.poll(0);
+        consumer.poll(Duration.ZERO);
 
         assertTrue(heartbeatReceived.get());
         consumer.close(0, TimeUnit.MILLISECONDS);
     }

&lt;p&gt;+    @Test&lt;br/&gt;
+    public void verifyPollTimesOutDuringMetadataUpdate() throws Exception &lt;/p&gt;
{
+        final Time time = new MockTime();
+        final Cluster cluster = TestUtils.singletonCluster(topic, 1);
+        final Node node = cluster.nodes().get(0);
+
+        final Metadata metadata = createMetadata();
+        metadata.update(cluster, Collections.&amp;lt;String&amp;gt;emptySet(), time.milliseconds());
+
+        final MockClient client = new MockClient(time, metadata);
+        client.setNode(node);
+        final PartitionAssignor assignor = new RoundRobinAssignor();
+
+        final KafkaConsumer&amp;lt;String, String&amp;gt; consumer = newConsumer(time, client, metadata, assignor, true);
+        consumer.subscribe(singleton(topic), getConsumerRebalanceListener(consumer));
+        prepareRebalance(client, node, assignor, singletonList(tp0), null);
+
+        consumer.poll(Duration.ZERO);
+
+        // The underlying client should NOT get a fetch request
+        final Queue&amp;lt;ClientRequest&amp;gt; requests = client.requests();
+        Assert.assertEquals(0, requests.size());
+    }
&lt;p&gt;+&lt;br/&gt;
+    @Test&lt;br/&gt;
+    public void verifyDeprecatedPollDoesNotTimeOutDuringMetadataUpdate() throws Exception &lt;/p&gt;
{
+        final Time time = new MockTime();
+        final Cluster cluster = TestUtils.singletonCluster(topic, 1);
+        final Node node = cluster.nodes().get(0);
+
+        final Metadata metadata = createMetadata();
+        metadata.update(cluster, Collections.&amp;lt;String&amp;gt;emptySet(), time.milliseconds());
+
+        final MockClient client = new MockClient(time, metadata);
+        client.setNode(node);
+        final PartitionAssignor assignor = new RoundRobinAssignor();
+
+        final KafkaConsumer&amp;lt;String, String&amp;gt; consumer = newConsumer(time, client, metadata, assignor, true);
+        consumer.subscribe(singleton(topic), getConsumerRebalanceListener(consumer));
+        prepareRebalance(client, node, assignor, singletonList(tp0), null);
+
+        //noinspection deprecation
+        consumer.poll(0L);
+
+        // The underlying client SHOULD get a fetch request
+        final Queue&amp;lt;ClientRequest&amp;gt; requests = client.requests();
+        Assert.assertEquals(1, requests.size());
+        final Class&amp;lt;? extends AbstractRequest.Builder&amp;gt; aClass = requests.peek().requestBuilder().getClass();
+        Assert.assertEquals(FetchRequest.Builder.class, aClass);
+    }
&lt;p&gt;+&lt;br/&gt;
     @Test&lt;br/&gt;
     public void verifyNoCoordinatorLookupForManualAssignmentWithSeek() {&lt;br/&gt;
         Time time = new MockTime();&lt;br/&gt;
@@ -425,7 +486,7 @@ public void verifyNoCoordinatorLookupForManualAssignmentWithSeek() {&lt;br/&gt;
         client.prepareResponse(listOffsetsResponse(Collections.singletonMap(tp0, 50L)));&lt;br/&gt;
         client.prepareResponse(fetchResponse(tp0, 50L, 5));&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(5);&lt;br/&gt;
+        ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(Duration.ofMillis(1));&lt;br/&gt;
         assertEquals(5, records.count());&lt;br/&gt;
         assertEquals(55L, consumer.position(tp0));&lt;br/&gt;
         consumer.close(0, TimeUnit.MILLISECONDS);&lt;br/&gt;
@@ -474,7 +535,7 @@ public boolean matches(AbstractRequest body) {&lt;br/&gt;
                     }&lt;br/&gt;
                 }, fetchResponse(tp0, 50L, 5));&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(5);&lt;br/&gt;
+        ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(Duration.ofMillis(1));&lt;br/&gt;
         assertEquals(5, records.count());&lt;br/&gt;
         assertEquals(singleton(tp0), records.partitions());&lt;br/&gt;
     }&lt;br/&gt;
@@ -501,7 +562,7 @@ public void testMissingOffsetNoResetPolicy() 
{
 
         // lookup committed offset and find nothing
         client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);
-        consumer.poll(0);
+        consumer.poll(Duration.ZERO);
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @Test&lt;br/&gt;
@@ -525,7 +586,7 @@ public void testResetToCommittedOffset() &lt;/p&gt;
{
         Node coordinator = new Node(Integer.MAX_VALUE - node.id(), node.host(), node.port());
 
         client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, 539L), Errors.NONE), coordinator);
-        consumer.poll(0);
+        consumer.poll(Duration.ZERO);
 
         assertEquals(539L, consumer.position(tp0));
     }
&lt;p&gt;@@ -553,7 +614,7 @@ public void testResetUsingAutoResetPolicy() &lt;/p&gt;
{
         client.prepareResponseFrom(offsetResponse(Collections.singletonMap(tp0, -1L), Errors.NONE), coordinator);
         client.prepareResponse(listOffsetsResponse(Collections.singletonMap(tp0, 50L)));
 
-        consumer.poll(0);
+        consumer.poll(Duration.ZERO);
 
         assertEquals(50L, consumer.position(tp0));
     }
&lt;p&gt;@@ -617,7 +678,9 @@ public void testAutoCommitSentBeforePositionUpdate() {&lt;br/&gt;
         consumer.subscribe(singleton(topic), getConsumerRebalanceListener(consumer));&lt;br/&gt;
         Node coordinator = prepareRebalance(client, node, assignor, singletonList(tp0), null);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;consumer.poll(0);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        consumer.poll(Duration.ZERO);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // respond to the outstanding fetch so that we have data available on the next poll&lt;br/&gt;
         client.respondFrom(fetchResponse(tp0, 0, 5), node);&lt;br/&gt;
@@ -630,7 +693,7 @@ public void testAutoCommitSentBeforePositionUpdate() {&lt;br/&gt;
         // no data has been returned to the user yet, so the committed offset should be 0&lt;br/&gt;
         AtomicBoolean commitReceived = prepareOffsetCommitResponse(client, coordinator, tp0, 0);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;consumer.poll(0);&lt;br/&gt;
+        consumer.poll(Duration.ZERO);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertTrue(commitReceived.get());&lt;br/&gt;
         consumer.close(0, TimeUnit.MILLISECONDS);&lt;br/&gt;
@@ -660,7 +723,9 @@ public void testRegexSubscription() {&lt;/p&gt;

&lt;p&gt;         client.prepareMetadataUpdate(cluster, Collections.&amp;lt;String&amp;gt;emptySet());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;consumer.poll(0);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+&lt;br/&gt;
         assertEquals(singleton(topic), consumer.subscription());&lt;br/&gt;
         assertEquals(singleton(tp0), consumer.assignment());&lt;br/&gt;
         consumer.close(0, TimeUnit.MILLISECONDS);&lt;br/&gt;
@@ -694,13 +759,16 @@ public void testChangingRegexSubscription() {&lt;br/&gt;
         Node coordinator = prepareRebalance(client, node, singleton(topic), assignor, singletonList(tp0), null);&lt;br/&gt;
         consumer.subscribe(Pattern.compile(topic), getConsumerRebalanceListener(consumer));&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;consumer.poll(0);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        consumer.poll(Duration.ZERO);&lt;br/&gt;
+&lt;br/&gt;
         assertEquals(singleton(topic), consumer.subscription());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         consumer.subscribe(Pattern.compile(otherTopic), getConsumerRebalanceListener(consumer));&lt;/p&gt;

&lt;p&gt;         prepareRebalance(client, node, singleton(otherTopic), assignor, singletonList(otherTopicPartition), coordinator);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;consumer.poll(0);&lt;br/&gt;
+        consumer.poll(Duration.ZERO);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertEquals(singleton(otherTopic), consumer.subscription());&lt;br/&gt;
         consumer.close(0, TimeUnit.MILLISECONDS);&lt;br/&gt;
@@ -723,7 +791,9 @@ public void testWakeupWithFetchDataAvailable() throws Exception {&lt;br/&gt;
         consumer.subscribe(singleton(topic), getConsumerRebalanceListener(consumer));&lt;br/&gt;
         prepareRebalance(client, node, assignor, singletonList(tp0), null);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;consumer.poll(0);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        consumer.poll(Duration.ZERO);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // respond to the outstanding fetch so that we have data available on the next poll&lt;br/&gt;
         client.respondFrom(fetchResponse(tp0, 0, 5), node);&lt;br/&gt;
@@ -732,7 +802,7 @@ public void testWakeupWithFetchDataAvailable() throws Exception {&lt;br/&gt;
         consumer.wakeup();&lt;/p&gt;

&lt;p&gt;         try &lt;/p&gt;
{
-            consumer.poll(0);
+            consumer.poll(Duration.ZERO);
             fail();
         }
&lt;p&gt; catch (WakeupException e) {&lt;br/&gt;
         }&lt;br/&gt;
@@ -741,7 +811,7 @@ public void testWakeupWithFetchDataAvailable() throws Exception {&lt;br/&gt;
         assertEquals(0, consumer.position(tp0));&lt;/p&gt;

&lt;p&gt;         // the next poll should return the completed fetch&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(0);&lt;br/&gt;
+        ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(Duration.ZERO);&lt;br/&gt;
         assertEquals(5, records.count());&lt;br/&gt;
         // Increment time asynchronously to clear timeouts in closing the consumer&lt;br/&gt;
         final ScheduledExecutorService exec = Executors.newSingleThreadScheduledExecutor();&lt;br/&gt;
@@ -773,13 +843,15 @@ public void testPollThrowsInterruptExceptionIfInterrupted() throws Exception {&lt;br/&gt;
         consumer.subscribe(singleton(topic), getConsumerRebalanceListener(consumer));&lt;br/&gt;
         prepareRebalance(client, node, assignor, singletonList(tp0), null);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;consumer.poll(0);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        consumer.poll(Duration.ZERO);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // interrupt the thread and call poll&lt;br/&gt;
         try &lt;/p&gt;
{
             Thread.currentThread().interrupt();
             expectedException.expect(InterruptException.class);
-            consumer.poll(0);
+            consumer.poll(Duration.ZERO);
         }
&lt;p&gt; finally {&lt;br/&gt;
             // clear interrupted state again since this thread may be reused by JUnit&lt;br/&gt;
             Thread.interrupted();&lt;br/&gt;
@@ -810,7 +882,10 @@ public void fetchResponseWithUnexpectedPartitionIsIgnored() &lt;/p&gt;
{
         fetches1.put(t2p0, new FetchInfo(0, 10)); // not assigned and not fetched
         client.prepareResponseFrom(fetchResponse(fetches1), node);
 
-        ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(0);
+        consumer.updateAssignmentMetadataIfNeeded(0L);
+        consumer.updateAssignmentMetadataIfNeeded(0L);
+
+        ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(Duration.ZERO);
         assertEquals(0, records.count());
         consumer.close(0, TimeUnit.MILLISECONDS);
     }
&lt;p&gt;@@ -852,7 +927,9 @@ public void testSubscriptionChangesWithAutoCommitEnabled() {&lt;br/&gt;
         // mock rebalance responses&lt;br/&gt;
         Node coordinator = prepareRebalance(client, node, assignor, Arrays.asList(tp0, t2p0), null);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;consumer.poll(0);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        consumer.poll(Duration.ZERO);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // verify that subscription is still the same, and now assignment has caught up&lt;br/&gt;
         assertTrue(consumer.subscription().size() == 2);&lt;br/&gt;
@@ -867,7 +944,7 @@ public void testSubscriptionChangesWithAutoCommitEnabled() {&lt;br/&gt;
         client.respondFrom(fetchResponse(fetches1), node);&lt;br/&gt;
         client.poll(0, time.milliseconds());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(0);&lt;br/&gt;
+        ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(Duration.ofMillis(1));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // clear out the prefetch so it doesn&apos;t interfere with the rest of the test&lt;br/&gt;
         fetches1.put(tp0, new FetchInfo(1, 0));&lt;br/&gt;
@@ -904,7 +981,7 @@ public void testSubscriptionChangesWithAutoCommitEnabled() {&lt;br/&gt;
         fetches2.put(t3p0, new FetchInfo(0, 100));&lt;br/&gt;
         client.prepareResponse(fetchResponse(fetches2));&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;records = consumer.poll(0);&lt;br/&gt;
+        records = consumer.poll(Duration.ofMillis(1));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // verify that the fetch occurred as expected&lt;br/&gt;
         assertEquals(101, records.count());&lt;br/&gt;
@@ -965,13 +1042,15 @@ public void testSubscriptionChangesWithAutoCommitDisabled() {&lt;br/&gt;
         // mock rebalance responses&lt;br/&gt;
         prepareRebalance(client, node, assignor, singletonList(tp0), null);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;consumer.poll(0);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        consumer.poll(Duration.ZERO);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // verify that subscription is still the same, and now assignment has caught up&lt;br/&gt;
         assertTrue(consumer.subscription().equals(singleton(topic)));&lt;br/&gt;
         assertTrue(consumer.assignment().equals(singleton(tp0)));&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;consumer.poll(0);&lt;br/&gt;
+        consumer.poll(Duration.ZERO);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // subscription change&lt;br/&gt;
         consumer.subscribe(singleton(topic2), getConsumerRebalanceListener(consumer));&lt;br/&gt;
@@ -1037,7 +1116,7 @@ public void testManualAssignmentChangeWithAutoCommitEnabled() {&lt;br/&gt;
         client.prepareResponse(listOffsetsResponse(Collections.singletonMap(tp0, 10L)));&lt;br/&gt;
         client.prepareResponse(fetchResponse(tp0, 10L, 1));&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(5);&lt;br/&gt;
+        ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(Duration.ofMillis(1));&lt;br/&gt;
         assertEquals(1, records.count());&lt;br/&gt;
         assertEquals(11L, consumer.position(tp0));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -1096,7 +1175,7 @@ public void testManualAssignmentChangeWithAutoCommitDisabled() {&lt;br/&gt;
         client.prepareResponse(listOffsetsResponse(Collections.singletonMap(tp0, 10L)));&lt;br/&gt;
         client.prepareResponse(fetchResponse(tp0, 10L, 1));&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(5);&lt;br/&gt;
+        ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(Duration.ofMillis(1));&lt;br/&gt;
         assertEquals(1, records.count());&lt;br/&gt;
         assertEquals(11L, consumer.position(tp0));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -1171,7 +1250,7 @@ public void testOffsetOfPausedPartitions() {&lt;br/&gt;
     @Test(expected = IllegalStateException.class)&lt;br/&gt;
     public void testPollWithNoSubscription() {&lt;br/&gt;
         try (KafkaConsumer&amp;lt;byte[], byte[]&amp;gt; consumer = newConsumer()) &lt;/p&gt;
{
-            consumer.poll(0);
+            consumer.poll(Duration.ZERO);
         }
&lt;p&gt;     }&lt;/p&gt;

&lt;p&gt;@@ -1179,7 +1258,7 @@ public void testPollWithNoSubscription() {&lt;br/&gt;
     public void testPollWithEmptySubscription() {&lt;br/&gt;
         try (KafkaConsumer&amp;lt;byte[], byte[]&amp;gt; consumer = newConsumer()) &lt;/p&gt;
{
             consumer.subscribe(Collections.&amp;lt;String&amp;gt;emptyList());
-            consumer.poll(0);
+            consumer.poll(Duration.ZERO);
         }
&lt;p&gt;     }&lt;/p&gt;

&lt;p&gt;@@ -1187,7 +1266,7 @@ public void testPollWithEmptySubscription() {&lt;br/&gt;
     public void testPollWithEmptyUserAssignment() {&lt;br/&gt;
         try (KafkaConsumer&amp;lt;byte[], byte[]&amp;gt; consumer = newConsumer()) &lt;/p&gt;
{
             consumer.assign(Collections.&amp;lt;TopicPartition&amp;gt;emptySet());
-            consumer.poll(0);
+            consumer.poll(Duration.ZERO);
         }
&lt;p&gt;     }&lt;/p&gt;

&lt;p&gt;@@ -1220,7 +1299,7 @@ public void testCloseNoWait() throws Exception {&lt;/p&gt;

&lt;p&gt;     @Test&lt;br/&gt;
     public void testCloseInterrupt() throws Exception &lt;/p&gt;
{
-        consumerCloseTest(Long.MAX_VALUE, Collections.&amp;lt;AbstractResponse&amp;gt;emptyList(), 0, true);
+        consumerCloseTest(Long.MAX_VALUE, Collections.emptyList(), 0, true);
     }

&lt;p&gt;     @Test&lt;br/&gt;
@@ -1270,7 +1349,9 @@ public void shouldAttemptToRejoinGroupAfterSyncGroupFailed() throws Exception {&lt;br/&gt;
         client.prepareResponseFrom(fetchResponse(tp0, 0, 1), node);&lt;br/&gt;
         client.prepareResponseFrom(fetchResponse(tp0, 1, 0), node);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;consumer.poll(0);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        consumer.poll(Duration.ZERO);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // heartbeat fails due to rebalance in progress&lt;br/&gt;
         client.prepareResponseFrom(new MockClient.RequestMatcher() {&lt;br/&gt;
@@ -1306,7 +1387,9 @@ public boolean matches(final AbstractRequest body) {&lt;br/&gt;
         }, fetchResponse(tp0, 1, 1), node);&lt;br/&gt;
         time.sleep(heartbeatIntervalMs);&lt;br/&gt;
         Thread.sleep(heartbeatIntervalMs);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(0);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        final ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(Duration.ZERO);&lt;br/&gt;
         assertFalse(records.isEmpty());&lt;br/&gt;
         consumer.close(0, TimeUnit.MILLISECONDS);&lt;br/&gt;
     }&lt;br/&gt;
@@ -1333,10 +1416,13 @@ private void consumerCloseTest(final long closeTimeoutMs,&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         client.prepareMetadataUpdate(cluster, Collections.&amp;lt;String&amp;gt;emptySet());&lt;/p&gt;

&lt;p&gt;+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+        consumer.updateAssignmentMetadataIfNeeded(0L);&lt;br/&gt;
+&lt;br/&gt;
         // Poll with responses&lt;br/&gt;
         client.prepareResponseFrom(fetchResponse(tp0, 0, 1), node);&lt;br/&gt;
         client.prepareResponseFrom(fetchResponse(tp0, 1, 0), node);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;consumer.poll(0);&lt;br/&gt;
+        consumer.poll(Duration.ZERO);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // Initiate close() after a commit request on another thread.&lt;br/&gt;
         // Kafka consumer is single-threaded, but the implementation allows calls on a&lt;br/&gt;
@@ -1457,7 +1543,7 @@ private void callConsumerApisAndExpectAnAuthenticationError(KafkaConsumer&amp;lt;?, ?&amp;gt;&lt;br/&gt;
         }&lt;/p&gt;

&lt;p&gt;         try &lt;/p&gt;
{
-            consumer.poll(10);
+            consumer.poll(Duration.ZERO);
             fail(&quot;Expected an authentication error!&quot;);
         }
&lt;p&gt; catch (AuthenticationException e) {&lt;br/&gt;
             // OK&lt;br/&gt;
diff --git a/clients/src/test/java/org/apache/kafka/clients/consumer/MockConsumerTest.java b/clients/src/test/java/org/apache/kafka/clients/consumer/MockConsumerTest.java&lt;br/&gt;
index 67f8e8d6837..1d01eb6d0b2 100644&lt;br/&gt;
&amp;#8212; a/clients/src/test/java/org/apache/kafka/clients/consumer/MockConsumerTest.java&lt;br/&gt;
+++ b/clients/src/test/java/org/apache/kafka/clients/consumer/MockConsumerTest.java&lt;br/&gt;
@@ -20,6 +20,7 @@&lt;br/&gt;
 import org.apache.kafka.common.record.TimestampType;&lt;br/&gt;
 import org.junit.Test;&lt;/p&gt;

&lt;p&gt;+import java.time.Duration;&lt;br/&gt;
 import java.util.Arrays;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
 import java.util.HashMap;&lt;br/&gt;
@@ -34,6 +35,32 @@&lt;/p&gt;

&lt;p&gt;     @Test&lt;br/&gt;
     public void testSimpleMock() &lt;/p&gt;
{
+        consumer.subscribe(Collections.singleton(&quot;test&quot;));
+        assertEquals(0, consumer.poll(Duration.ZERO).count());
+        consumer.rebalance(Arrays.asList(new TopicPartition(&quot;test&quot;, 0), new TopicPartition(&quot;test&quot;, 1)));
+        // Mock consumers need to seek manually since they cannot automatically reset offsets
+        HashMap&amp;lt;TopicPartition, Long&amp;gt; beginningOffsets = new HashMap&amp;lt;&amp;gt;();
+        beginningOffsets.put(new TopicPartition(&quot;test&quot;, 0), 0L);
+        beginningOffsets.put(new TopicPartition(&quot;test&quot;, 1), 0L);
+        consumer.updateBeginningOffsets(beginningOffsets);
+        consumer.seek(new TopicPartition(&quot;test&quot;, 0), 0);
+        ConsumerRecord&amp;lt;String, String&amp;gt; rec1 = new ConsumerRecord&amp;lt;&amp;gt;(&quot;test&quot;, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, &quot;key1&quot;, &quot;value1&quot;);
+        ConsumerRecord&amp;lt;String, String&amp;gt; rec2 = new ConsumerRecord&amp;lt;&amp;gt;(&quot;test&quot;, 0, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, &quot;key2&quot;, &quot;value2&quot;);
+        consumer.addRecord(rec1);
+        consumer.addRecord(rec2);
+        ConsumerRecords&amp;lt;String, String&amp;gt; recs = consumer.poll(Duration.ofMillis(1));
+        Iterator&amp;lt;ConsumerRecord&amp;lt;String, String&amp;gt;&amp;gt; iter = recs.iterator();
+        assertEquals(rec1, iter.next());
+        assertEquals(rec2, iter.next());
+        assertFalse(iter.hasNext());
+        assertEquals(2L, consumer.position(new TopicPartition(&quot;test&quot;, 0)));
+        consumer.commitSync();
+        assertEquals(2L, consumer.committed(new TopicPartition(&quot;test&quot;, 0)).offset());
+    }
&lt;p&gt;+&lt;br/&gt;
+    @SuppressWarnings(&quot;deprecation&quot;)&lt;br/&gt;
+    @Test&lt;br/&gt;
+    public void testSimpleMockDeprecated() {&lt;br/&gt;
         consumer.subscribe(Collections.singleton(&quot;test&quot;));&lt;br/&gt;
         assertEquals(0, consumer.poll(1000).count());&lt;br/&gt;
         consumer.rebalance(Arrays.asList(new TopicPartition(&quot;test&quot;, 0), new TopicPartition(&quot;test&quot;, 1)));&lt;br/&gt;
diff --git a/clients/src/test/java/org/apache/kafka/clients/consumer/internals/AbstractCoordinatorTest.java b/clients/src/test/java/org/apache/kafka/clients/consumer/internals/AbstractCoordinatorTest.java&lt;br/&gt;
index 1c88803e26c..135763d3f41 100644&lt;br/&gt;
&amp;#8212; a/clients/src/test/java/org/apache/kafka/clients/consumer/internals/AbstractCoordinatorTest.java&lt;br/&gt;
+++ b/clients/src/test/java/org/apache/kafka/clients/consumer/internals/AbstractCoordinatorTest.java&lt;br/&gt;
@@ -102,7 +102,7 @@ public void testCoordinatorDiscoveryBackoff() {&lt;br/&gt;
         mockClient.blackout(coordinatorNode, 10L);&lt;/p&gt;

&lt;p&gt;         long initialTime = mockTime.milliseconds();&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;br/&gt;
         long endTime = mockTime.milliseconds();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertTrue(endTime - initialTime &amp;gt;= RETRY_BACKOFF_MS);&lt;br/&gt;
@@ -183,7 +183,7 @@ public void testLookupCoordinator() throws Exception &lt;/p&gt;
{
         assertTrue(&quot;New request sent while one is in progress&quot;, future == coordinator.lookupCoordinator());
 
         mockClient.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));
-        coordinator.ensureCoordinatorReady();
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);
         assertTrue(&quot;New request not sent after previous completed&quot;, future != coordinator.lookupCoordinator());
     }

&lt;p&gt;@@ -527,7 +527,7 @@ public void testEnsureCoordinatorReadyWithinBlackoutPeriodAfterAuthenticationFai&lt;br/&gt;
         mockClient.authenticationFailed(node, 300);&lt;/p&gt;

&lt;p&gt;         try &lt;/p&gt;
{
-            coordinator.ensureCoordinatorReady();
+            coordinator.ensureCoordinatorReady(Long.MAX_VALUE);
             fail(&quot;Expected an authentication error.&quot;);
         } catch (AuthenticationException e) {&lt;br/&gt;
             // OK&lt;br/&gt;
@@ -537,7 +537,7 @@ public void testEnsureCoordinatorReadyWithinBlackoutPeriodAfterAuthenticationFai&lt;br/&gt;
         assertTrue(mockClient.connectionFailed(node));&lt;br/&gt;
 &lt;br/&gt;
         try {-            coordinator.ensureCoordinatorReady();+            coordinator.ensureCoordinatorReady(Long.MAX_VALUE);             fail(&quot;Expected an authentication error.&quot;);         }
&lt;p&gt; catch (AuthenticationException e) {&lt;br/&gt;
             // OK&lt;br/&gt;
diff --git a/clients/src/test/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinatorTest.java b/clients/src/test/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinatorTest.java&lt;br/&gt;
index 030419075c6..18288735805 100644&lt;br/&gt;
&amp;#8212; a/clients/src/test/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinatorTest.java&lt;br/&gt;
+++ b/clients/src/test/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinatorTest.java&lt;br/&gt;
@@ -144,7 +144,7 @@ public void teardown() {&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testNormalHeartbeat() {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // normal heartbeat&lt;br/&gt;
         time.sleep(sessionTimeoutMs);&lt;br/&gt;
@@ -162,7 +162,7 @@ public void testNormalHeartbeat() {&lt;br/&gt;
     @Test(expected = GroupAuthorizationException.class)&lt;br/&gt;
     public void testGroupDescribeUnauthorized() &lt;/p&gt;
{
         client.prepareResponse(groupCoordinatorResponse(node, Errors.GROUP_AUTHORIZATION_FAILED));
-        coordinator.ensureCoordinatorReady();
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);
     }

&lt;p&gt;     @Test(expected = GroupAuthorizationException.class)&lt;br/&gt;
@@ -170,17 +170,17 @@ public void testGroupReadUnauthorized() &lt;/p&gt;
{
         subscriptions.subscribe(singleton(topic1), rebalanceListener);
 
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));
-        coordinator.ensureCoordinatorReady();
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);
 
         client.prepareResponse(joinGroupLeaderResponse(0, &quot;memberId&quot;, Collections.&amp;lt;String, List&amp;lt;String&amp;gt;&amp;gt;emptyMap(),
                 Errors.GROUP_AUTHORIZATION_FAILED));
-        coordinator.poll(time.milliseconds(), Long.MAX_VALUE);
+        coordinator.poll(Long.MAX_VALUE);
     }

&lt;p&gt;     @Test&lt;br/&gt;
     public void testCoordinatorNotAvailable() {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // COORDINATOR_NOT_AVAILABLE will mark coordinator as unknown&lt;br/&gt;
         time.sleep(sessionTimeoutMs);&lt;br/&gt;
@@ -201,7 +201,7 @@ public void testCoordinatorNotAvailable() {&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testManyInFlightAsyncCommitsWithCoordinatorDisconnect() throws Exception {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         int numRequests = 1000;&lt;br/&gt;
         TopicPartition tp = new TopicPartition(&quot;foo&quot;, 0);&lt;br/&gt;
@@ -233,7 +233,7 @@ public void testCoordinatorUnknownInUnsentCallbacksAfterCoordinatorDead() throws&lt;br/&gt;
         // the coordinator as unknown which prevents additional retries to the same coordinator.&lt;/p&gt;

&lt;p&gt;         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         final AtomicBoolean asyncCallbackInvoked = new AtomicBoolean(false);&lt;br/&gt;
         Map&amp;lt;TopicPartition, OffsetCommitRequest.PartitionData&amp;gt; offsets = singletonMap(&lt;br/&gt;
@@ -259,7 +259,7 @@ public void onFailure(RuntimeException e, RequestFuture&amp;lt;Object&amp;gt; future) {&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testNotCoordinator() {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // not_coordinator will mark coordinator as unknown&lt;br/&gt;
         time.sleep(sessionTimeoutMs);&lt;br/&gt;
@@ -280,7 +280,7 @@ public void testNotCoordinator() {&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testIllegalGeneration() {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // illegal_generation will cause re-partition&lt;br/&gt;
         subscriptions.subscribe(singleton(topic1), rebalanceListener);&lt;br/&gt;
@@ -298,13 +298,13 @@ public void testIllegalGeneration() &lt;/p&gt;
{
         assertTrue(future.isDone());
         assertTrue(future.failed());
         assertEquals(Errors.ILLEGAL_GENERATION.exception(), future.exception());
-        assertTrue(coordinator.needRejoin());
+        assertTrue(coordinator.rejoinNeededOrPending());
     }

&lt;p&gt;     @Test&lt;br/&gt;
     public void testUnknownConsumerId() {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // illegal_generation will cause re-partition&lt;br/&gt;
         subscriptions.subscribe(singleton(topic1), rebalanceListener);&lt;br/&gt;
@@ -322,13 +322,13 @@ public void testUnknownConsumerId() &lt;/p&gt;
{
         assertTrue(future.isDone());
         assertTrue(future.failed());
         assertEquals(Errors.UNKNOWN_MEMBER_ID.exception(), future.exception());
-        assertTrue(coordinator.needRejoin());
+        assertTrue(coordinator.rejoinNeededOrPending());
     }

&lt;p&gt;     @Test&lt;br/&gt;
     public void testCoordinatorDisconnect() {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // coordinator disconnect will mark coordinator as unknown&lt;br/&gt;
         time.sleep(sessionTimeoutMs);&lt;br/&gt;
@@ -357,11 +357,11 @@ public void testJoinGroupInvalidGroupId() &lt;/p&gt;
{
         metadata.update(cluster, Collections.&amp;lt;String&amp;gt;emptySet(), time.milliseconds());
 
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));
-        coordinator.ensureCoordinatorReady();
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);
 
         client.prepareResponse(joinGroupLeaderResponse(0, consumerId, Collections.&amp;lt;String, List&amp;lt;String&amp;gt;&amp;gt;emptyMap(),
                 Errors.INVALID_GROUP_ID));
-        coordinator.poll(time.milliseconds(), Long.MAX_VALUE);
+        coordinator.poll(Long.MAX_VALUE);
     }

&lt;p&gt;     @Test&lt;br/&gt;
@@ -375,7 +375,7 @@ public void testNormalJoinGroupLeader() {&lt;br/&gt;
         metadata.update(cluster, Collections.&amp;lt;String&amp;gt;emptySet(), time.milliseconds());&lt;/p&gt;

&lt;p&gt;         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // normal join group&lt;br/&gt;
         Map&amp;lt;String, List&amp;lt;String&amp;gt;&amp;gt; memberSubscriptions = singletonMap(consumerId, singletonList(topic1));&lt;br/&gt;
@@ -391,9 +391,9 @@ public boolean matches(AbstractRequest body) &lt;/p&gt;
{
                         sync.groupAssignment().containsKey(consumerId);
             }
&lt;p&gt;         }, syncGroupResponse(singletonList(t1p), Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.poll(time.milliseconds(), Long.MAX_VALUE);&lt;br/&gt;
+        coordinator.poll(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertFalse(coordinator.needRejoin());&lt;br/&gt;
+        assertFalse(coordinator.rejoinNeededOrPending());&lt;br/&gt;
         assertEquals(singleton(t1p), subscriptions.assignedPartitions());&lt;br/&gt;
         assertEquals(singleton(topic1), subscriptions.groupSubscription());&lt;br/&gt;
         assertEquals(1, rebalanceListener.revokedCount);&lt;br/&gt;
@@ -414,7 +414,7 @@ public void testPatternJoinGroupLeader() {&lt;br/&gt;
         metadata.update(TestUtils.singletonCluster(topic1, 1), Collections.&amp;lt;String&amp;gt;emptySet(), time.milliseconds());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // normal join group&lt;br/&gt;
         Map&amp;lt;String, List&amp;lt;String&amp;gt;&amp;gt; memberSubscriptions = singletonMap(consumerId, singletonList(topic1));&lt;br/&gt;
@@ -433,9 +433,9 @@ public boolean matches(AbstractRequest body) {&lt;br/&gt;
         // expect client to force updating the metadata, if yes gives it both topics&lt;br/&gt;
         client.prepareMetadataUpdate(cluster, Collections.&amp;lt;String&amp;gt;emptySet());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.poll(time.milliseconds(), Long.MAX_VALUE);&lt;br/&gt;
+        coordinator.poll(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertFalse(coordinator.needRejoin());&lt;br/&gt;
+        assertFalse(coordinator.rejoinNeededOrPending());&lt;br/&gt;
         assertEquals(2, subscriptions.assignedPartitions().size());&lt;br/&gt;
         assertEquals(2, subscriptions.groupSubscription().size());&lt;br/&gt;
         assertEquals(2, subscriptions.subscription().size());&lt;br/&gt;
@@ -456,7 +456,7 @@ public void testMetadataRefreshDuringRebalance() {&lt;br/&gt;
         assertEquals(singleton(topic1), subscriptions.subscription());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         Map&amp;lt;String, List&amp;lt;String&amp;gt;&amp;gt; initialSubscription = singletonMap(consumerId, singletonList(topic1));&lt;br/&gt;
         partitionAssignor.prepare(singletonMap(consumerId, singletonList(t1p)));&lt;br/&gt;
@@ -496,9 +496,9 @@ public boolean matches(AbstractRequest body) {&lt;br/&gt;
         }, joinGroupLeaderResponse(2, consumerId, updatedSubscriptions, Errors.NONE));&lt;br/&gt;
         client.prepareResponse(syncGroupResponse(newAssignment, Errors.NONE));&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.poll(time.milliseconds(), Long.MAX_VALUE);&lt;br/&gt;
+        coordinator.poll(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertFalse(coordinator.needRejoin());&lt;br/&gt;
+        assertFalse(coordinator.rejoinNeededOrPending());&lt;br/&gt;
         assertEquals(updatedSubscriptionSet, subscriptions.subscription());&lt;br/&gt;
         assertEquals(newAssignmentSet, subscriptions.assignedPartitions());&lt;br/&gt;
         assertEquals(2, rebalanceListener.revokedCount);&lt;br/&gt;
@@ -518,7 +518,7 @@ public void testWakeupDuringJoin() {&lt;br/&gt;
         metadata.update(cluster, Collections.&amp;lt;String&amp;gt;emptySet(), time.milliseconds());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         Map&amp;lt;String, List&amp;lt;String&amp;gt;&amp;gt; memberSubscriptions = singletonMap(consumerId, singletonList(topic1));&lt;br/&gt;
         partitionAssignor.prepare(singletonMap(consumerId, singletonList(t1p)));&lt;br/&gt;
@@ -528,16 +528,16 @@ public void testWakeupDuringJoin() {&lt;br/&gt;
         consumerClient.wakeup();&lt;/p&gt;

&lt;p&gt;         try &lt;/p&gt;
{
-            coordinator.poll(time.milliseconds(), Long.MAX_VALUE);
+            coordinator.poll(Long.MAX_VALUE);
         }
&lt;p&gt; catch (WakeupException e) &lt;/p&gt;
{
             // ignore
         }

&lt;p&gt;         // now complete the second half&lt;br/&gt;
         client.prepareResponse(syncGroupResponse(singletonList(t1p), Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.poll(time.milliseconds(), Long.MAX_VALUE);&lt;br/&gt;
+        coordinator.poll(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertFalse(coordinator.needRejoin());&lt;br/&gt;
+        assertFalse(coordinator.rejoinNeededOrPending());&lt;br/&gt;
         assertEquals(singleton(t1p), subscriptions.assignedPartitions());&lt;br/&gt;
         assertEquals(1, rebalanceListener.revokedCount);&lt;br/&gt;
         assertEquals(Collections.emptySet(), rebalanceListener.revoked);&lt;br/&gt;
@@ -552,7 +552,7 @@ public void testNormalJoinGroupFollower() {&lt;br/&gt;
         subscriptions.subscribe(singleton(topic1), rebalanceListener);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // normal join group&lt;br/&gt;
         client.prepareResponse(joinGroupFollowerResponse(1, consumerId, &quot;leader&quot;, Errors.NONE));&lt;br/&gt;
@@ -566,9 +566,9 @@ public boolean matches(AbstractRequest body) {&lt;br/&gt;
             }&lt;br/&gt;
         }, syncGroupResponse(singletonList(t1p), Errors.NONE));&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.joinGroupIfNeeded();&lt;br/&gt;
+        coordinator.joinGroupIfNeeded(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertFalse(coordinator.needRejoin());&lt;br/&gt;
+        assertFalse(coordinator.rejoinNeededOrPending());&lt;br/&gt;
         assertEquals(singleton(t1p), subscriptions.assignedPartitions());&lt;br/&gt;
         assertEquals(singleton(topic1), subscriptions.groupSubscription());&lt;br/&gt;
         assertEquals(1, rebalanceListener.revokedCount);&lt;br/&gt;
@@ -589,7 +589,7 @@ public void testPatternJoinGroupFollower() {&lt;br/&gt;
         metadata.update(TestUtils.singletonCluster(topic1, 1), Collections.&amp;lt;String&amp;gt;emptySet(), time.milliseconds());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // normal join group&lt;br/&gt;
         client.prepareResponse(joinGroupFollowerResponse(1, consumerId, &quot;leader&quot;, Errors.NONE));&lt;br/&gt;
@@ -605,9 +605,9 @@ public boolean matches(AbstractRequest body) {&lt;br/&gt;
         // expect client to force updating the metadata, if yes gives it both topics&lt;br/&gt;
         client.prepareMetadataUpdate(cluster, Collections.&amp;lt;String&amp;gt;emptySet());&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.joinGroupIfNeeded();&lt;br/&gt;
+        coordinator.joinGroupIfNeeded(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertFalse(coordinator.needRejoin());&lt;br/&gt;
+        assertFalse(coordinator.rejoinNeededOrPending());&lt;br/&gt;
         assertEquals(2, subscriptions.assignedPartitions().size());&lt;br/&gt;
         assertEquals(2, subscriptions.subscription().size());&lt;br/&gt;
         assertEquals(1, rebalanceListener.revokedCount);&lt;br/&gt;
@@ -667,12 +667,12 @@ public void testUnexpectedErrorOnSyncGroup() 
{
         subscriptions.subscribe(singleton(topic1), rebalanceListener);
 
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));
-        coordinator.ensureCoordinatorReady();
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);
 
         // join initially, but let coordinator rebalance on sync
         client.prepareResponse(joinGroupFollowerResponse(1, consumerId, &quot;leader&quot;, Errors.NONE));
         client.prepareResponse(syncGroupResponse(Collections.&amp;lt;TopicPartition&amp;gt;emptyList(), Errors.UNKNOWN_SERVER_ERROR));
-        coordinator.joinGroupIfNeeded();
+        coordinator.joinGroupIfNeeded(Long.MAX_VALUE);
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @Test&lt;br/&gt;
@@ -682,7 +682,7 @@ public void testUnknownMemberIdOnSyncGroup() {&lt;br/&gt;
         subscriptions.subscribe(singleton(topic1), rebalanceListener);&lt;/p&gt;

&lt;p&gt;         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // join initially, but let coordinator returns unknown member id&lt;br/&gt;
         client.prepareResponse(joinGroupFollowerResponse(1, consumerId, &quot;leader&quot;, Errors.NONE));&lt;br/&gt;
@@ -698,9 +698,9 @@ public boolean matches(AbstractRequest body) {&lt;br/&gt;
         }, joinGroupFollowerResponse(2, consumerId, &quot;leader&quot;, Errors.NONE));&lt;br/&gt;
         client.prepareResponse(syncGroupResponse(singletonList(t1p), Errors.NONE));&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.joinGroupIfNeeded();&lt;br/&gt;
+        coordinator.joinGroupIfNeeded(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertFalse(coordinator.needRejoin());&lt;br/&gt;
+        assertFalse(coordinator.rejoinNeededOrPending());&lt;br/&gt;
         assertEquals(singleton(t1p), subscriptions.assignedPartitions());&lt;br/&gt;
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -711,7 +711,7 @@ public void testRebalanceInProgressOnSyncGroup() {&lt;br/&gt;
         subscriptions.subscribe(singleton(topic1), rebalanceListener);&lt;/p&gt;

&lt;p&gt;         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // join initially, but let coordinator rebalance on sync&lt;br/&gt;
         client.prepareResponse(joinGroupFollowerResponse(1, consumerId, &quot;leader&quot;, Errors.NONE));&lt;br/&gt;
@@ -721,9 +721,9 @@ public void testRebalanceInProgressOnSyncGroup() &lt;/p&gt;
{
         client.prepareResponse(joinGroupFollowerResponse(2, consumerId, &quot;leader&quot;, Errors.NONE));
         client.prepareResponse(syncGroupResponse(singletonList(t1p), Errors.NONE));
 
-        coordinator.joinGroupIfNeeded();
+        coordinator.joinGroupIfNeeded(Long.MAX_VALUE);
 
-        assertFalse(coordinator.needRejoin());
+        assertFalse(coordinator.rejoinNeededOrPending());
         assertEquals(singleton(t1p), subscriptions.assignedPartitions());
     }

&lt;p&gt;@@ -734,7 +734,7 @@ public void testIllegalGenerationOnSyncGroup() {&lt;br/&gt;
         subscriptions.subscribe(singleton(topic1), rebalanceListener);&lt;/p&gt;

&lt;p&gt;         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // join initially, but let coordinator rebalance on sync&lt;br/&gt;
         client.prepareResponse(joinGroupFollowerResponse(1, consumerId, &quot;leader&quot;, Errors.NONE));&lt;br/&gt;
@@ -750,9 +750,9 @@ public boolean matches(AbstractRequest body) {&lt;br/&gt;
         }, joinGroupFollowerResponse(2, consumerId, &quot;leader&quot;, Errors.NONE));&lt;br/&gt;
         client.prepareResponse(syncGroupResponse(singletonList(t1p), Errors.NONE));&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.joinGroupIfNeeded();&lt;br/&gt;
+        coordinator.joinGroupIfNeeded(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertFalse(coordinator.needRejoin());&lt;br/&gt;
+        assertFalse(coordinator.rejoinNeededOrPending());&lt;br/&gt;
         assertEquals(singleton(t1p), subscriptions.assignedPartitions());&lt;br/&gt;
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -767,7 +767,7 @@ public void testMetadataChangeTriggersRebalance() {&lt;br/&gt;
         subscriptions.subscribe(singleton(topic1), rebalanceListener);&lt;/p&gt;

&lt;p&gt;         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         Map&amp;lt;String, List&amp;lt;String&amp;gt;&amp;gt; memberSubscriptions = singletonMap(consumerId, singletonList(topic1));&lt;br/&gt;
         partitionAssignor.prepare(singletonMap(consumerId, singletonList(t1p)));&lt;br/&gt;
@@ -776,15 +776,15 @@ public void testMetadataChangeTriggersRebalance() &lt;/p&gt;
{
         client.prepareResponse(joinGroupLeaderResponse(1, consumerId, memberSubscriptions, Errors.NONE));
         client.prepareResponse(syncGroupResponse(singletonList(t1p), Errors.NONE));
 
-        coordinator.poll(time.milliseconds(), Long.MAX_VALUE);
+        coordinator.poll(Long.MAX_VALUE);
 
-        assertFalse(coordinator.needRejoin());
+        assertFalse(coordinator.rejoinNeededOrPending());
 
         // a new partition is added to the topic
         metadata.update(TestUtils.singletonCluster(topic1, 2), Collections.&amp;lt;String&amp;gt;emptySet(), time.milliseconds());
 
         // we should detect the change and ask for reassignment
-        assertTrue(coordinator.needRejoin());
+        assertTrue(coordinator.rejoinNeededOrPending());
     }

&lt;p&gt;     @Test&lt;br/&gt;
@@ -804,7 +804,7 @@ public void testUpdateMetadataDuringRebalance() {&lt;br/&gt;
         metadata.update(TestUtils.singletonCluster(topic1, 1), Collections.&amp;lt;String&amp;gt;emptySet(), time.milliseconds());&lt;/p&gt;

&lt;p&gt;         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // prepare initial rebalance&lt;br/&gt;
         Map&amp;lt;String, List&amp;lt;String&amp;gt;&amp;gt; memberSubscriptions = singletonMap(consumerId, topics);&lt;br/&gt;
@@ -833,9 +833,9 @@ public boolean matches(AbstractRequest body) &lt;/p&gt;
{
         client.prepareResponse(joinGroupLeaderResponse(2, consumerId, memberSubscriptions, Errors.NONE));
         client.prepareResponse(syncGroupResponse(Arrays.asList(tp1, tp2), Errors.NONE));
 
-        coordinator.poll(time.milliseconds(), Long.MAX_VALUE);
+        coordinator.poll(Long.MAX_VALUE);
 
-        assertFalse(coordinator.needRejoin());
+        assertFalse(coordinator.rejoinNeededOrPending());
         assertEquals(new HashSet&amp;lt;&amp;gt;(Arrays.asList(tp1, tp2)), subscriptions.assignedPartitions());
     }

&lt;p&gt;@@ -873,16 +873,16 @@ else if (patternSubscribe)&lt;br/&gt;
             subscriptions.subscribe(singleton(topic1), rebalanceListener);&lt;/p&gt;

&lt;p&gt;         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         Map&amp;lt;String, List&amp;lt;String&amp;gt;&amp;gt; memberSubscriptions = singletonMap(consumerId, singletonList(topic1));&lt;br/&gt;
         partitionAssignor.prepare(Collections.&amp;lt;String, List&amp;lt;TopicPartition&amp;gt;&amp;gt;emptyMap());&lt;/p&gt;

&lt;p&gt;         client.prepareResponse(joinGroupLeaderResponse(1, consumerId, memberSubscriptions, Errors.NONE));&lt;br/&gt;
         client.prepareResponse(syncGroupResponse(Collections.&amp;lt;TopicPartition&amp;gt;emptyList(), Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.poll(time.milliseconds(), Long.MAX_VALUE);&lt;br/&gt;
+        coordinator.poll(Long.MAX_VALUE);&lt;br/&gt;
         if (!assign) 
{
-            assertFalse(coordinator.needRejoin());
+            assertFalse(coordinator.rejoinNeededOrPending());
             assertEquals(Collections.&amp;lt;TopicPartition&amp;gt;emptySet(), rebalanceListener.assigned);
         }
&lt;p&gt;         assertTrue(&quot;Metadata refresh not requested for unavailable partitions&quot;, metadata.updateRequested());&lt;br/&gt;
@@ -891,11 +891,11 @@ else if (patternSubscribe)&lt;br/&gt;
         client.poll(0, time.milliseconds());&lt;br/&gt;
         client.prepareResponse(joinGroupLeaderResponse(2, consumerId, memberSubscriptions, Errors.NONE));&lt;br/&gt;
         client.prepareResponse(syncGroupResponse(singletonList(t1p), Errors.NONE));&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;coordinator.poll(time.milliseconds(), Long.MAX_VALUE);&lt;br/&gt;
+        coordinator.poll(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertFalse(&quot;Metadata refresh requested unnecessarily&quot;, metadata.updateRequested());&lt;br/&gt;
         if (!assign) &lt;/p&gt;
{
-            assertFalse(coordinator.needRejoin());
+            assertFalse(coordinator.rejoinNeededOrPending());
             assertEquals(singleton(t1p), rebalanceListener.assigned);
         }
&lt;p&gt;     }&lt;br/&gt;
@@ -937,7 +937,7 @@ public void testRejoinGroup() {&lt;br/&gt;
         subscriptions.subscribe(new HashSet&amp;lt;&amp;gt;(Arrays.asList(topic1, otherTopic)), rebalanceListener);&lt;br/&gt;
         client.prepareResponse(joinGroupFollowerResponse(2, &quot;consumer&quot;, &quot;leader&quot;, Errors.NONE));&lt;br/&gt;
         client.prepareResponse(syncGroupResponse(singletonList(t1p), Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.joinGroupIfNeeded();&lt;br/&gt;
+        coordinator.joinGroupIfNeeded(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertEquals(2, rebalanceListener.revokedCount);&lt;br/&gt;
         assertEquals(singleton(t1p), rebalanceListener.revoked);&lt;br/&gt;
@@ -950,16 +950,16 @@ public void testDisconnectInJoin() {&lt;br/&gt;
         subscriptions.subscribe(singleton(topic1), rebalanceListener);&lt;/p&gt;

&lt;p&gt;         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // disconnected from original coordinator will cause re-discover and join again&lt;br/&gt;
         client.prepareResponse(joinGroupFollowerResponse(1, &quot;consumer&quot;, &quot;leader&quot;, Errors.NONE), true);&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;br/&gt;
         client.prepareResponse(joinGroupFollowerResponse(1, &quot;consumer&quot;, &quot;leader&quot;, Errors.NONE));&lt;br/&gt;
         client.prepareResponse(syncGroupResponse(singletonList(t1p), Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.joinGroupIfNeeded();&lt;br/&gt;
+        coordinator.joinGroupIfNeeded(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertFalse(coordinator.needRejoin());&lt;br/&gt;
+        assertFalse(coordinator.rejoinNeededOrPending());&lt;br/&gt;
         assertEquals(singleton(t1p), subscriptions.assignedPartitions());&lt;br/&gt;
         assertEquals(1, rebalanceListener.revokedCount);&lt;br/&gt;
         assertEquals(1, rebalanceListener.assignedCount);&lt;br/&gt;
@@ -971,11 +971,11 @@ public void testInvalidSessionTimeout() 
{
         subscriptions.subscribe(singleton(topic1), rebalanceListener);
 
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));
-        coordinator.ensureCoordinatorReady();
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);
 
         // coordinator doesn&apos;t like the session timeout
         client.prepareResponse(joinGroupFollowerResponse(0, &quot;consumer&quot;, &quot;&quot;, Errors.INVALID_SESSION_TIMEOUT));
-        coordinator.joinGroupIfNeeded();
+        coordinator.joinGroupIfNeeded(Long.MAX_VALUE);
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @Test&lt;br/&gt;
@@ -983,7 +983,7 @@ public void testCommitOffsetOnly() {&lt;br/&gt;
         subscriptions.assignFromUser(singleton(t1p));&lt;/p&gt;

&lt;p&gt;         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         prepareOffsetCommitRequest(singletonMap(t1p, 100L), Errors.NONE);&lt;/p&gt;

&lt;p&gt;@@ -1005,7 +1005,7 @@ public void testCoordinatorDisconnectAfterCoordinatorNotAvailableError() {&lt;/p&gt;

&lt;p&gt;     private void testInFlightRequestsFailedAfterCoordinatorMarkedDead(Errors error) {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // Send two async commits and fail the first one with an error.&lt;br/&gt;
         // This should cause a coordinator disconnect which will cancel the second request.&lt;br/&gt;
@@ -1038,7 +1038,7 @@ public void testAutoCommitDynamicAssignment() &lt;/p&gt;
{
 
         prepareOffsetCommitRequest(singletonMap(t1p, 100L), Errors.NONE);
         time.sleep(autoCommitIntervalMs);
-        coordinator.poll(time.milliseconds(), Long.MAX_VALUE);
+        coordinator.poll(Long.MAX_VALUE);
         assertFalse(client.hasPendingResponses());
     }

&lt;p&gt;@@ -1055,23 +1055,23 @@ public void testAutoCommitRetryBackoff() &lt;/p&gt;
{
 
         // Send an offset commit, but let it fail with a retriable error
         prepareOffsetCommitRequest(singletonMap(t1p, 100L), Errors.NOT_COORDINATOR);
-        coordinator.poll(time.milliseconds(), Long.MAX_VALUE);
+        coordinator.poll(Long.MAX_VALUE);
         assertTrue(coordinator.coordinatorUnknown());
 
         // After the disconnect, we should rediscover the coordinator
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));
-        coordinator.poll(time.milliseconds(), Long.MAX_VALUE);
+        coordinator.poll(Long.MAX_VALUE);
 
         subscriptions.seek(t1p, 200);
 
         // Until the retry backoff has expired, we should not retry the offset commit
         time.sleep(retryBackoffMs / 2);
-        coordinator.poll(time.milliseconds(), Long.MAX_VALUE);
+        coordinator.poll(Long.MAX_VALUE);
         assertEquals(0, client.inFlightRequestCount());
 
         // Once the backoff expires, we should retry
         time.sleep(retryBackoffMs / 2);
-        coordinator.poll(time.milliseconds(), Long.MAX_VALUE);
+        coordinator.poll(Long.MAX_VALUE);
         assertEquals(1, client.inFlightRequestCount());
         respondToOffsetCommitRequest(singletonMap(t1p, 200L), Errors.NONE);
     }
&lt;p&gt;@@ -1088,28 +1088,28 @@ public void testAutoCommitAwaitsInterval() &lt;/p&gt;
{
         time.sleep(autoCommitIntervalMs);
 
         // Send the offset commit request, but do not respond
-        coordinator.poll(time.milliseconds(), Long.MAX_VALUE);
+        coordinator.poll(Long.MAX_VALUE);
         assertEquals(1, client.inFlightRequestCount());
 
         time.sleep(autoCommitIntervalMs / 2);
 
         // Ensure that no additional offset commit is sent
-        coordinator.poll(time.milliseconds(), Long.MAX_VALUE);
+        coordinator.poll(Long.MAX_VALUE);
         assertEquals(1, client.inFlightRequestCount());
 
         respondToOffsetCommitRequest(singletonMap(t1p, 100L), Errors.NONE);
-        coordinator.poll(time.milliseconds(), Long.MAX_VALUE);
+        coordinator.poll(Long.MAX_VALUE);
         assertEquals(0, client.inFlightRequestCount());
 
         subscriptions.seek(t1p, 200);
 
         // If we poll again before the auto-commit interval, there should be no new sends
-        coordinator.poll(time.milliseconds(), Long.MAX_VALUE);
+        coordinator.poll(Long.MAX_VALUE);
         assertEquals(0, client.inFlightRequestCount());
 
         // After the remainder of the interval passes, we send a new offset commit
         time.sleep(autoCommitIntervalMs / 2);
-        coordinator.poll(time.milliseconds(), Long.MAX_VALUE);
+        coordinator.poll(Long.MAX_VALUE);
         assertEquals(1, client.inFlightRequestCount());
         respondToOffsetCommitRequest(singletonMap(t1p, 200L), Errors.NONE);
     }
&lt;p&gt;@@ -1124,7 +1124,7 @@ public void testAutoCommitDynamicAssignmentRebalance() {&lt;br/&gt;
         subscriptions.subscribe(singleton(topic1), rebalanceListener);&lt;/p&gt;

&lt;p&gt;         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // haven&apos;t joined, so should not cause a commit&lt;br/&gt;
         time.sleep(autoCommitIntervalMs);&lt;br/&gt;
@@ -1132,13 +1132,13 @@ public void testAutoCommitDynamicAssignmentRebalance() &lt;/p&gt;
{
 
         client.prepareResponse(joinGroupFollowerResponse(1, consumerId, &quot;leader&quot;, Errors.NONE));
         client.prepareResponse(syncGroupResponse(singletonList(t1p), Errors.NONE));
-        coordinator.joinGroupIfNeeded();
+        coordinator.joinGroupIfNeeded(Long.MAX_VALUE);
 
         subscriptions.seek(t1p, 100);
 
         prepareOffsetCommitRequest(singletonMap(t1p, 100L), Errors.NONE);
         time.sleep(autoCommitIntervalMs);
-        coordinator.poll(time.milliseconds(), Long.MAX_VALUE);
+        coordinator.poll(Long.MAX_VALUE);
         assertFalse(client.hasPendingResponses());
     }

&lt;p&gt;@@ -1151,11 +1151,11 @@ public void testAutoCommitManualAssignment() &lt;/p&gt;
{
         subscriptions.seek(t1p, 100);
 
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));
-        coordinator.ensureCoordinatorReady();
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);
 
         prepareOffsetCommitRequest(singletonMap(t1p, 100L), Errors.NONE);
         time.sleep(autoCommitIntervalMs);
-        coordinator.poll(time.milliseconds(), Long.MAX_VALUE);
+        coordinator.poll(Long.MAX_VALUE);
         assertFalse(client.hasPendingResponses());
     }

&lt;p&gt;@@ -1174,12 +1174,12 @@ public void testAutoCommitManualAssignmentCoordinatorUnknown() &lt;/p&gt;
{
 
         // now find the coordinator
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));
-        coordinator.ensureCoordinatorReady();
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);
 
         // sleep only for the retry backoff
         time.sleep(retryBackoffMs);
         prepareOffsetCommitRequest(singletonMap(t1p, 100L), Errors.NONE);
-        coordinator.poll(time.milliseconds(), Long.MAX_VALUE);
+        coordinator.poll(Long.MAX_VALUE);
         assertFalse(client.hasPendingResponses());
     }

&lt;p&gt;@@ -1188,7 +1188,7 @@ public void testCommitOffsetMetadata() {&lt;br/&gt;
         subscriptions.assignFromUser(singleton(t1p));&lt;/p&gt;

&lt;p&gt;         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         prepareOffsetCommitRequest(singletonMap(t1p, 100L), Errors.NONE);&lt;/p&gt;

&lt;p&gt;@@ -1204,7 +1204,7 @@ public void testCommitOffsetMetadata() {&lt;br/&gt;
     public void testCommitOffsetAsyncWithDefaultCallback() {&lt;br/&gt;
         int invokedBeforeTest = mockOffsetCommitCallback.invoked;&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;br/&gt;
         prepareOffsetCommitRequest(singletonMap(t1p, 100L), Errors.NONE);&lt;br/&gt;
         coordinator.commitOffsetsAsync(singletonMap(t1p, new OffsetAndMetadata(100L)), mockOffsetCommitCallback);&lt;br/&gt;
         coordinator.invokeCompletedOffsetCommitCallbacks();&lt;br/&gt;
@@ -1245,7 +1245,7 @@ public boolean matches(AbstractRequest body) {&lt;br/&gt;
     public void testCommitOffsetAsyncFailedWithDefaultCallback() {&lt;br/&gt;
         int invokedBeforeTest = mockOffsetCommitCallback.invoked;&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/li&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;br/&gt;
         prepareOffsetCommitRequest(singletonMap(t1p, 100L), Errors.COORDINATOR_NOT_AVAILABLE);&lt;br/&gt;
         coordinator.commitOffsetsAsync(singletonMap(t1p, new OffsetAndMetadata(100L)), mockOffsetCommitCallback);&lt;br/&gt;
         coordinator.invokeCompletedOffsetCommitCallbacks();&lt;br/&gt;
@@ -1256,7 +1256,7 @@ public void testCommitOffsetAsyncFailedWithDefaultCallback() {&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testCommitOffsetAsyncCoordinatorNotAvailable() {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/li&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // async commit with coordinator not available&lt;br/&gt;
         MockCommitCallback cb = new MockCommitCallback();&lt;br/&gt;
@@ -1272,7 +1272,7 @@ public void testCommitOffsetAsyncCoordinatorNotAvailable() {&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testCommitOffsetAsyncNotCoordinator() {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // async commit with not coordinator&lt;br/&gt;
         MockCommitCallback cb = new MockCommitCallback();&lt;br/&gt;
@@ -1288,7 +1288,7 @@ public void testCommitOffsetAsyncNotCoordinator() {&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testCommitOffsetAsyncDisconnected() {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // async commit with coordinator disconnected&lt;br/&gt;
         MockCommitCallback cb = new MockCommitCallback();&lt;br/&gt;
@@ -1304,7 +1304,7 @@ public void testCommitOffsetAsyncDisconnected() {&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testCommitOffsetSyncNotCoordinator() {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // sync commit with coordinator disconnected (should connect, get metadata, and then submit the commit request)&lt;br/&gt;
         prepareOffsetCommitRequest(singletonMap(t1p, 100L), Errors.NOT_COORDINATOR);&lt;br/&gt;
@@ -1316,7 +1316,7 @@ public void testCommitOffsetSyncNotCoordinator() {&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testCommitOffsetSyncCoordinatorNotAvailable() {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // sync commit with coordinator disconnected (should connect, get metadata, and then submit the commit request)&lt;br/&gt;
         prepareOffsetCommitRequest(singletonMap(t1p, 100L), Errors.COORDINATOR_NOT_AVAILABLE);&lt;br/&gt;
@@ -1328,7 +1328,7 @@ public void testCommitOffsetSyncCoordinatorNotAvailable() {&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testCommitOffsetSyncCoordinatorDisconnected() {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // sync commit with coordinator disconnected (should connect, get metadata, and then submit the commit request)&lt;br/&gt;
         prepareOffsetCommitRequestDisconnect(singletonMap(t1p, 100L));&lt;br/&gt;
@@ -1340,7 +1340,7 @@ public void testCommitOffsetSyncCoordinatorDisconnected() {&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testAsyncCommitCallbacksInvokedPriorToSyncCommitCompletion() throws Exception {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         final List&amp;lt;OffsetAndMetadata&amp;gt; committedOffsets = Collections.synchronizedList(new ArrayList&amp;lt;OffsetAndMetadata&amp;gt;());&lt;br/&gt;
         final OffsetAndMetadata firstOffset = new OffsetAndMetadata(0L);&lt;br/&gt;
@@ -1376,7 +1376,7 @@ public void run() {&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testRetryCommitUnknownTopicOrPartition() {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         client.prepareResponse(offsetCommitResponse(singletonMap(t1p, Errors.UNKNOWN_TOPIC_OR_PARTITION)));&lt;br/&gt;
         client.prepareResponse(offsetCommitResponse(singletonMap(t1p, Errors.NONE)));&lt;br/&gt;
@@ -1388,7 +1388,7 @@ public void testRetryCommitUnknownTopicOrPartition() {&lt;br/&gt;
     public void testCommitOffsetMetadataTooLarge() {&lt;br/&gt;
         // since offset metadata is provided by the user, we have to propagate the exception so they can handle it&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         prepareOffsetCommitRequest(singletonMap(t1p, 100L), Errors.OFFSET_METADATA_TOO_LARGE);&lt;br/&gt;
         coordinator.commitOffsetsSync(singletonMap(t1p, new OffsetAndMetadata(100L, &quot;metadata&quot;)), Long.MAX_VALUE);&lt;br/&gt;
@@ -1398,7 +1398,7 @@ public void testCommitOffsetMetadataTooLarge() {&lt;br/&gt;
     public void testCommitOffsetIllegalGeneration() {&lt;br/&gt;
         // we cannot retry if a rebalance occurs before the commit completed&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         prepareOffsetCommitRequest(singletonMap(t1p, 100L), Errors.ILLEGAL_GENERATION);&lt;br/&gt;
         coordinator.commitOffsetsSync(singletonMap(t1p, new OffsetAndMetadata(100L, &quot;metadata&quot;)), Long.MAX_VALUE);&lt;br/&gt;
@@ -1408,7 +1408,7 @@ public void testCommitOffsetIllegalGeneration() {&lt;br/&gt;
     public void testCommitOffsetUnknownMemberId() {&lt;br/&gt;
         // we cannot retry if a rebalance occurs before the commit completed&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         prepareOffsetCommitRequest(singletonMap(t1p, 100L), Errors.UNKNOWN_MEMBER_ID);&lt;br/&gt;
         coordinator.commitOffsetsSync(singletonMap(t1p, new OffsetAndMetadata(100L, &quot;metadata&quot;)), Long.MAX_VALUE);&lt;br/&gt;
@@ -1418,7 +1418,7 @@ public void testCommitOffsetUnknownMemberId() {&lt;br/&gt;
     public void testCommitOffsetRebalanceInProgress() {&lt;br/&gt;
         // we cannot retry if a rebalance occurs before the commit completed&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         prepareOffsetCommitRequest(singletonMap(t1p, 100L), Errors.REBALANCE_IN_PROGRESS);&lt;br/&gt;
         coordinator.commitOffsetsSync(singletonMap(t1p, new OffsetAndMetadata(100L, &quot;metadata&quot;)), Long.MAX_VALUE);&lt;br/&gt;
@@ -1427,7 +1427,7 @@ public void testCommitOffsetRebalanceInProgress() {&lt;br/&gt;
     @Test(expected = KafkaException.class)&lt;br/&gt;
     public void testCommitOffsetSyncCallbackWithNonRetriableException() {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // sync commit with invalid partitions should throw if we have no callback&lt;br/&gt;
         prepareOffsetCommitRequest(singletonMap(t1p, 100L), Errors.UNKNOWN_SERVER_ERROR);&lt;br/&gt;
@@ -1453,18 +1453,18 @@ public void testCommitAsyncNegativeOffset() {&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testCommitOffsetSyncWithoutFutureGetsCompleted() &lt;/p&gt;
{
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));
-        coordinator.ensureCoordinatorReady();
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);
         assertFalse(coordinator.commitOffsetsSync(singletonMap(t1p, new OffsetAndMetadata(100L)), 0));
     }

&lt;p&gt;     @Test&lt;br/&gt;
     public void testRefreshOffset() {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         subscriptions.assignFromUser(singleton(t1p));&lt;br/&gt;
         client.prepareResponse(offsetFetchResponse(t1p, Errors.NONE, &quot;&quot;, 100L));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.refreshCommittedOffsetsIfNeeded();&lt;br/&gt;
+        coordinator.refreshCommittedOffsetsIfNeeded(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertEquals(Collections.emptySet(), subscriptions.missingFetchPositions());&lt;br/&gt;
         assertTrue(subscriptions.hasAllFetchPositions());&lt;br/&gt;
@@ -1474,12 +1474,12 @@ public void testRefreshOffset() {&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testRefreshOffsetLoadInProgress() {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         subscriptions.assignFromUser(singleton(t1p));&lt;br/&gt;
         client.prepareResponse(offsetFetchResponse(Errors.COORDINATOR_LOAD_IN_PROGRESS));&lt;br/&gt;
         client.prepareResponse(offsetFetchResponse(t1p, Errors.NONE, &quot;&quot;, 100L));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.refreshCommittedOffsetsIfNeeded();&lt;br/&gt;
+        coordinator.refreshCommittedOffsetsIfNeeded(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertEquals(Collections.emptySet(), subscriptions.missingFetchPositions());&lt;br/&gt;
         assertTrue(subscriptions.hasAllFetchPositions());&lt;br/&gt;
@@ -1489,12 +1489,12 @@ public void testRefreshOffsetLoadInProgress() {&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testRefreshOffsetsGroupNotAuthorized() {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         subscriptions.assignFromUser(singleton(t1p));&lt;br/&gt;
         client.prepareResponse(offsetFetchResponse(Errors.GROUP_AUTHORIZATION_FAILED));&lt;br/&gt;
         try &lt;/p&gt;
{
-            coordinator.refreshCommittedOffsetsIfNeeded();
+            coordinator.refreshCommittedOffsetsIfNeeded(Long.MAX_VALUE);
             fail(&quot;Expected group authorization error&quot;);
         }
&lt;p&gt; catch (GroupAuthorizationException e) {&lt;br/&gt;
             assertEquals(groupId, e.groupId());&lt;br/&gt;
@@ -1504,23 +1504,23 @@ public void testRefreshOffsetsGroupNotAuthorized() {&lt;br/&gt;
     @Test(expected = KafkaException.class)&lt;br/&gt;
     public void testRefreshOffsetUnknownTopicOrPartition() &lt;/p&gt;
{
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));
-        coordinator.ensureCoordinatorReady();
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);
 
         subscriptions.assignFromUser(singleton(t1p));
         client.prepareResponse(offsetFetchResponse(t1p, Errors.UNKNOWN_TOPIC_OR_PARTITION, &quot;&quot;, 100L));
-        coordinator.refreshCommittedOffsetsIfNeeded();
+        coordinator.refreshCommittedOffsetsIfNeeded(Long.MAX_VALUE);
     }

&lt;p&gt;     @Test&lt;br/&gt;
     public void testRefreshOffsetNotCoordinatorForConsumer() {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         subscriptions.assignFromUser(singleton(t1p));&lt;br/&gt;
         client.prepareResponse(offsetFetchResponse(Errors.NOT_COORDINATOR));&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;br/&gt;
         client.prepareResponse(offsetFetchResponse(t1p, Errors.NONE, &quot;&quot;, 100L));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.refreshCommittedOffsetsIfNeeded();&lt;br/&gt;
+        coordinator.refreshCommittedOffsetsIfNeeded(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertEquals(Collections.emptySet(), subscriptions.missingFetchPositions());&lt;br/&gt;
         assertTrue(subscriptions.hasAllFetchPositions());&lt;br/&gt;
@@ -1530,11 +1530,11 @@ public void testRefreshOffsetNotCoordinatorForConsumer() {&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testRefreshOffsetWithNoFetchableOffsets() {&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         subscriptions.assignFromUser(singleton(t1p));&lt;br/&gt;
         client.prepareResponse(offsetFetchResponse(t1p, Errors.NONE, &quot;&quot;, -1L));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.refreshCommittedOffsetsIfNeeded();&lt;br/&gt;
+        coordinator.refreshCommittedOffsetsIfNeeded(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertEquals(Collections.singleton(t1p), subscriptions.missingFetchPositions());&lt;br/&gt;
         assertEquals(Collections.emptySet(), subscriptions.partitionsNeedingReset(time.milliseconds()));&lt;br/&gt;
@@ -1548,7 +1548,7 @@ public void testNoCoordinatorDiscoveryIfPositionsKnown() {&lt;/p&gt;

&lt;p&gt;         subscriptions.assignFromUser(singleton(t1p));&lt;br/&gt;
         subscriptions.seek(t1p, 500L);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.refreshCommittedOffsetsIfNeeded();&lt;br/&gt;
+        coordinator.refreshCommittedOffsetsIfNeeded(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertEquals(Collections.emptySet(), subscriptions.missingFetchPositions());&lt;br/&gt;
         assertTrue(subscriptions.hasAllFetchPositions());&lt;br/&gt;
@@ -1562,7 +1562,7 @@ public void testNoCoordinatorDiscoveryIfPartitionAwaitingReset() {&lt;/p&gt;

&lt;p&gt;         subscriptions.assignFromUser(singleton(t1p));&lt;br/&gt;
         subscriptions.requestOffsetReset(t1p, OffsetResetStrategy.EARLIEST);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.refreshCommittedOffsetsIfNeeded();&lt;br/&gt;
+        coordinator.refreshCommittedOffsetsIfNeeded(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         assertEquals(Collections.emptySet(), subscriptions.missingFetchPositions());&lt;br/&gt;
         assertFalse(subscriptions.hasAllFetchPositions());&lt;br/&gt;
@@ -1741,17 +1741,17 @@ private ConsumerCoordinator prepareCoordinatorForCloseTest(final boolean useGrou&lt;br/&gt;
         ConsumerCoordinator coordinator = buildCoordinator(new Metrics(), assignors,&lt;br/&gt;
                 ConsumerConfig.DEFAULT_EXCLUDE_INTERNAL_TOPICS, autoCommit, leaveGroup);&lt;br/&gt;
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;br/&gt;
         if (useGroupManagement) 
{
             subscriptions.subscribe(singleton(topic1), rebalanceListener);
             client.prepareResponse(joinGroupFollowerResponse(1, consumerId, &quot;leader&quot;, Errors.NONE));
             client.prepareResponse(syncGroupResponse(singletonList(t1p), Errors.NONE));
-            coordinator.joinGroupIfNeeded();
+            coordinator.joinGroupIfNeeded(Long.MAX_VALUE);
         }
&lt;p&gt; else&lt;br/&gt;
             subscriptions.assignFromUser(singleton(t1p));&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         subscriptions.seek(t1p, 100);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.poll(time.milliseconds(), Long.MAX_VALUE);&lt;br/&gt;
+        coordinator.poll(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         return coordinator;&lt;br/&gt;
     }&lt;br/&gt;
@@ -1910,10 +1910,10 @@ private void joinAsFollowerAndReceiveAssignment(String consumerId,&lt;br/&gt;
                                                     ConsumerCoordinator coordinator,&lt;br/&gt;
                                                     List&amp;lt;TopicPartition&amp;gt; assignment) &lt;/p&gt;
{
         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));
-        coordinator.ensureCoordinatorReady();
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);
         client.prepareResponse(joinGroupFollowerResponse(1, consumerId, &quot;leader&quot;, Errors.NONE));
         client.prepareResponse(syncGroupResponse(assignment, Errors.NONE));
-        coordinator.joinGroupIfNeeded();
+        coordinator.joinGroupIfNeeded(Long.MAX_VALUE);
     }

&lt;p&gt;     private void prepareOffsetCommitRequest(Map&amp;lt;TopicPartition, Long&amp;gt; expectedOffsets, Errors error) {&lt;br/&gt;
diff --git a/clients/src/test/java/org/apache/kafka/common/security/authenticator/ClientAuthenticationFailureTest.java b/clients/src/test/java/org/apache/kafka/common/security/authenticator/ClientAuthenticationFailureTest.java&lt;br/&gt;
index c64597b7e8b..413997f2931 100644&lt;br/&gt;
&amp;#8212; a/clients/src/test/java/org/apache/kafka/common/security/authenticator/ClientAuthenticationFailureTest.java&lt;br/&gt;
+++ b/clients/src/test/java/org/apache/kafka/common/security/authenticator/ClientAuthenticationFailureTest.java&lt;br/&gt;
@@ -38,6 +38,7 @@&lt;br/&gt;
 import org.junit.Before;&lt;br/&gt;
 import org.junit.Test;&lt;/p&gt;

&lt;p&gt;+import java.time.Duration;&lt;br/&gt;
 import java.util.Arrays;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
 import java.util.HashMap;&lt;br/&gt;
@@ -85,12 +86,12 @@ public void testConsumerWithInvalidCredentials() {&lt;/p&gt;

&lt;p&gt;         try (KafkaConsumer&amp;lt;String, String&amp;gt; consumer = new KafkaConsumer&amp;lt;&amp;gt;(props, deserializer, deserializer)) &lt;/p&gt;
{
             consumer.subscribe(Arrays.asList(topic));
-            consumer.poll(100);
+            consumer.poll(Duration.ofSeconds(10));
             fail(&quot;Expected an authentication error!&quot;);
         }
&lt;p&gt; catch (SaslAuthenticationException e) &lt;/p&gt;
{
             // OK
         }
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
-            fail(&quot;Expected only an authentication error, but another error occurred: &quot; + e.getMessage());
+            throw new AssertionError(&quot;Expected only an authentication error, but another error occurred.&quot;, e);
         }
&lt;p&gt;     }&lt;/p&gt;

&lt;p&gt;diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/WorkerCoordinator.java b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/WorkerCoordinator.java&lt;br/&gt;
index 60407c1d0dc..796ecdf2dfe 100644&lt;br/&gt;
&amp;#8212; a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/WorkerCoordinator.java&lt;br/&gt;
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/WorkerCoordinator.java&lt;br/&gt;
@@ -103,6 +103,12 @@ public String protocolType() &lt;/p&gt;
{
         return &quot;connect&quot;;
     }

&lt;p&gt;+    // expose for tests&lt;br/&gt;
+    @Override&lt;br/&gt;
+    protected synchronized boolean ensureCoordinatorReady(final long timeoutMs) &lt;/p&gt;
{
+        return super.ensureCoordinatorReady(timeoutMs);
+    }
&lt;p&gt;+&lt;br/&gt;
     public void poll(long timeout) {&lt;br/&gt;
         // poll for io until the timeout expires&lt;br/&gt;
         final long start = time.milliseconds();&lt;br/&gt;
@@ -111,11 +117,11 @@ public void poll(long timeout) {&lt;/p&gt;

&lt;p&gt;         do {&lt;br/&gt;
             if (coordinatorUnknown()) &lt;/p&gt;
{
-                ensureCoordinatorReady();
+                ensureCoordinatorReady(Long.MAX_VALUE);
                 now = time.milliseconds();
             }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (needRejoin()) {&lt;br/&gt;
+            if (rejoinNeededOrPending()) 
{
                 ensureActiveGroup();
                 now = time.milliseconds();
             }
&lt;p&gt;@@ -282,8 +288,8 @@ protected void onJoinPrepare(int generation, String memberId) {&lt;br/&gt;
     }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @Override&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;protected boolean needRejoin() {&lt;/li&gt;
	&lt;li&gt;return super.needRejoin() || (assignmentSnapshot == null || assignmentSnapshot.failed()) || rejoinRequested;&lt;br/&gt;
+    protected boolean rejoinNeededOrPending() 
{
+        return super.rejoinNeededOrPending() || (assignmentSnapshot == null || assignmentSnapshot.failed()) || rejoinRequested;
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     public String memberId() {&lt;br/&gt;
@@ -298,13 +304,13 @@ private boolean isLeader() {&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;     public String ownerUrl(String connector) &lt;/p&gt;
{
-        if (needRejoin() || !isLeader())
+        if (rejoinNeededOrPending() || !isLeader())
             return null;
         return leaderState.ownerUrl(connector);
     }

&lt;p&gt;     public String ownerUrl(ConnectorTaskId task) &lt;/p&gt;
{
-        if (needRejoin() || !isLeader())
+        if (rejoinNeededOrPending() || !isLeader())
             return null;
         return leaderState.ownerUrl(task);
     }
&lt;p&gt;diff --git a/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/WorkerCoordinatorTest.java b/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/WorkerCoordinatorTest.java&lt;br/&gt;
index 154b1df5e73..e1017f2654f 100644&lt;br/&gt;
&amp;#8212; a/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/WorkerCoordinatorTest.java&lt;br/&gt;
+++ b/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/WorkerCoordinatorTest.java&lt;br/&gt;
@@ -208,7 +208,7 @@ public void testNormalJoinGroupLeader() {&lt;br/&gt;
         final String consumerId = &quot;leader&quot;;&lt;/p&gt;

&lt;p&gt;         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // normal join group&lt;br/&gt;
         Map&amp;lt;String, Long&amp;gt; memberConfigOffsets = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
@@ -227,7 +227,7 @@ public boolean matches(AbstractRequest body) {&lt;br/&gt;
                 Collections.&amp;lt;ConnectorTaskId&amp;gt;emptyList(), Errors.NONE));&lt;br/&gt;
         coordinator.ensureActiveGroup();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertFalse(coordinator.needRejoin());&lt;br/&gt;
+        assertFalse(coordinator.rejoinNeededOrPending());&lt;br/&gt;
         assertEquals(0, rebalanceListener.revokedCount);&lt;br/&gt;
         assertEquals(1, rebalanceListener.assignedCount);&lt;br/&gt;
         assertFalse(rebalanceListener.assignment.failed());&lt;br/&gt;
@@ -248,7 +248,7 @@ public void testNormalJoinGroupFollower() {&lt;br/&gt;
         final String memberId = &quot;member&quot;;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // normal join group&lt;br/&gt;
         client.prepareResponse(joinGroupFollowerResponse(1, memberId, &quot;leader&quot;, Errors.NONE));&lt;br/&gt;
@@ -264,7 +264,7 @@ public boolean matches(AbstractRequest body) {&lt;br/&gt;
                 Collections.singletonList(taskId1x0), Errors.NONE));&lt;br/&gt;
         coordinator.ensureActiveGroup();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertFalse(coordinator.needRejoin());&lt;br/&gt;
+        assertFalse(coordinator.rejoinNeededOrPending());&lt;br/&gt;
         assertEquals(0, rebalanceListener.revokedCount);&lt;br/&gt;
         assertEquals(1, rebalanceListener.assignedCount);&lt;br/&gt;
         assertFalse(rebalanceListener.assignment.failed());&lt;br/&gt;
@@ -289,7 +289,7 @@ public void testJoinLeaderCannotAssign() {&lt;br/&gt;
         final String memberId = &quot;member&quot;;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // config mismatch results in assignment error&lt;br/&gt;
         client.prepareResponse(joinGroupFollowerResponse(1, memberId, &quot;leader&quot;, Errors.NONE));&lt;br/&gt;
@@ -320,7 +320,7 @@ public void testRejoinGroup() {&lt;br/&gt;
         PowerMock.replayAll();&lt;/p&gt;

&lt;p&gt;         client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;coordinator.ensureCoordinatorReady();&lt;br/&gt;
+        coordinator.ensureCoordinatorReady(Long.MAX_VALUE);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         // join the group once&lt;br/&gt;
         client.prepareResponse(joinGroupFollowerResponse(1, &quot;consumer&quot;, &quot;leader&quot;, Errors.NONE));&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/zk/ZooKeeperTestHarness.scala b/core/src/test/scala/unit/kafka/zk/ZooKeeperTestHarness.scala&lt;br/&gt;
index a1222977751..034557e8a2a 100755&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/zk/ZooKeeperTestHarness.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/zk/ZooKeeperTestHarness.scala&lt;br/&gt;
@@ -121,6 +121,10 @@ object ZooKeeperTestHarness {&lt;br/&gt;
     val (threads, noUnexpected) = TestUtils.computeUntilTrue(allThreads) &lt;/p&gt;
{ threads =&amp;gt;
       threads.forall(t =&amp;gt; unexpectedThreadNames.forall(s =&amp;gt; !t.contains(s)))
     }
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertTrue(s&quot;Found unexpected threads during $context, allThreads=$threads&quot;, noUnexpected)&lt;br/&gt;
+    assertTrue(&lt;br/&gt;
+      s&quot;Found unexpected threads during $context, allThreads=$threads, &quot; +&lt;br/&gt;
+        s&quot;unexpected=${threads.filterNot(t =&amp;gt; unexpectedThreadNames.forall(s =&amp;gt; !t.contains(s)))}&quot;,&lt;br/&gt;
+      noUnexpected&lt;br/&gt;
+    )&lt;br/&gt;
   }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/test/MockRestoreConsumer.java b/streams/src/test/java/org/apache/kafka/test/MockRestoreConsumer.java&lt;br/&gt;
index ce889170bbf..3070e36482f 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/test/MockRestoreConsumer.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/test/MockRestoreConsumer.java&lt;br/&gt;
@@ -85,6 +85,7 @@ public synchronized void assign(Collection&amp;lt;TopicPartition&amp;gt; partitions) 
{
         super.assign(partitions);
     }&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+    @Deprecated&lt;br/&gt;
     @Override&lt;br/&gt;
     public ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; poll(long timeout) {&lt;br/&gt;
         // add buffered records to MockConsumer&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16496754" author="githubbot" created="Thu, 31 May 2018 15:57:14 +0000"  >&lt;p&gt;vvcephei opened a new pull request #5107: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5697&quot; title=&quot;StreamThread.shutdown() need to interrupt the stream threads to break the loop&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5697&quot;&gt;&lt;del&gt;KAFKA-5697&lt;/del&gt;&lt;/a&gt;: Use nonblocking poll in Streams&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5107&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5107&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Make use of the new `Consumer#poll(Duration)` to avoid getting stuck in `poll` when the broker is unavailable.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16506329" author="githubbot" created="Fri, 8 Jun 2018 17:54:29 +0000"  >&lt;p&gt;guozhangwang closed pull request #5107: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5697&quot; title=&quot;StreamThread.shutdown() need to interrupt the stream threads to break the loop&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5697&quot;&gt;&lt;del&gt;KAFKA-5697&lt;/del&gt;&lt;/a&gt;: Use nonblocking poll in Streams&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5107&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5107&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java&lt;br/&gt;
index e8ec5e9fe5f..4fd7a591eb6 100644&lt;br/&gt;
&amp;#8212; a/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java&lt;br/&gt;
@@ -38,6 +38,7 @@&lt;/p&gt;

&lt;p&gt; import java.io.File;&lt;br/&gt;
 import java.io.IOException;&lt;br/&gt;
+import java.time.Duration;&lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
 import java.util.Collection;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
@@ -60,6 +61,7 @@&lt;br/&gt;
     private InternalProcessorContext processorContext;&lt;br/&gt;
     private final int retries;&lt;br/&gt;
     private final long retryBackoffMs;&lt;br/&gt;
+    private final Duration pollTime;&lt;/p&gt;

&lt;p&gt;     public GlobalStateManagerImpl(final LogContext logContext,&lt;br/&gt;
                                   final ProcessorTopology topology,&lt;br/&gt;
@@ -76,6 +78,7 @@ public GlobalStateManagerImpl(final LogContext logContext,&lt;br/&gt;
         this.stateRestoreListener = stateRestoreListener;&lt;br/&gt;
         this.retries = config.getInt(StreamsConfig.RETRIES_CONFIG);&lt;br/&gt;
         this.retryBackoffMs = config.getLong(StreamsConfig.RETRY_BACKOFF_MS_CONFIG);&lt;br/&gt;
+        this.pollTime = Duration.ofMillis(config.getLong(StreamsConfig.POLL_MS_CONFIG));&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;     @Override&lt;br/&gt;
@@ -262,7 +265,7 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,&lt;/p&gt;

&lt;p&gt;             while (offset &amp;lt; highWatermark) {&lt;br/&gt;
                 try {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = globalConsumer.poll(100);&lt;br/&gt;
+                    final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = globalConsumer.poll(pollTime);&lt;br/&gt;
                     final List&amp;lt;KeyValue&amp;lt;byte[], byte[]&amp;gt;&amp;gt; restoreRecords = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
                     for (ConsumerRecord&amp;lt;byte[], byte[]&amp;gt; record : records) {&lt;br/&gt;
                         if (record.key() != null) {&lt;br/&gt;
diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java&lt;br/&gt;
index 112011f47b8..9d529c5455c 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java&lt;br/&gt;
@@ -36,6 +36,7 @@&lt;br/&gt;
 import org.slf4j.Logger;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import java.io.IOException;&lt;br/&gt;
+import java.time.Duration;&lt;br/&gt;
 import java.util.Arrays;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
 import java.util.HashSet;&lt;br/&gt;
@@ -200,7 +201,7 @@ public GlobalStreamThread(final ProcessorTopology topology,&lt;br/&gt;
         private final Consumer&amp;lt;byte[], byte[]&amp;gt; globalConsumer;&lt;br/&gt;
         private final GlobalStateMaintainer stateMaintainer;&lt;br/&gt;
         private final Time time;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final long pollMs;&lt;br/&gt;
+        private final Duration pollTime;&lt;br/&gt;
         private final long flushInterval;&lt;br/&gt;
         private final Logger log;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -210,13 +211,13 @@ public GlobalStreamThread(final ProcessorTopology topology,&lt;br/&gt;
                       final Consumer&amp;lt;byte[], byte[]&amp;gt; globalConsumer,&lt;br/&gt;
                       final GlobalStateMaintainer stateMaintainer,&lt;br/&gt;
                       final Time time,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final long pollMs,&lt;br/&gt;
+                      final Duration pollTime,&lt;br/&gt;
                       final long flushInterval) 
{
             this.log = logContext.logger(getClass());
             this.globalConsumer = globalConsumer;
             this.stateMaintainer = stateMaintainer;
             this.time = time;
-            this.pollMs = pollMs;
+            this.pollTime = pollTime;
             this.flushInterval = flushInterval;
         }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -235,7 +236,7 @@ void initialize() {&lt;/p&gt;

&lt;p&gt;         void pollAndUpdate() {&lt;br/&gt;
             try {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; received = globalConsumer.poll(pollMs);&lt;br/&gt;
+                final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; received = globalConsumer.poll(pollTime);&lt;br/&gt;
                 for (final ConsumerRecord&amp;lt;byte[], byte[]&amp;gt; record : received) 
{
                     stateMaintainer.update(record);
                 }
&lt;p&gt;@@ -338,8 +339,9 @@ private StateConsumer initialize() {&lt;br/&gt;
                     logContext&lt;br/&gt;
                 ),&lt;br/&gt;
                 time,&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;config.getLong(StreamsConfig.POLL_MS_CONFIG),&lt;/li&gt;
	&lt;li&gt;config.getLong(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG));&lt;br/&gt;
+                Duration.ofMillis(config.getLong(StreamsConfig.POLL_MS_CONFIG)),&lt;br/&gt;
+                config.getLong(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG)&lt;br/&gt;
+            );&lt;br/&gt;
             stateConsumer.initialize();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             return stateConsumer;&lt;br/&gt;
diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreChangelogReader.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreChangelogReader.java&lt;br/&gt;
index bb0ed069670..07af8019aef 100644&lt;br/&gt;
&amp;#8212; a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreChangelogReader.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreChangelogReader.java&lt;br/&gt;
@@ -29,6 +29,7 @@&lt;br/&gt;
 import org.apache.kafka.streams.processor.StateRestoreListener;&lt;br/&gt;
 import org.slf4j.Logger;&lt;/p&gt;

&lt;p&gt;+import java.time.Duration;&lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
 import java.util.Collection;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
@@ -49,11 +50,14 @@&lt;br/&gt;
     private final Map&amp;lt;TopicPartition, StateRestorer&amp;gt; stateRestorers = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
     private final Map&amp;lt;TopicPartition, StateRestorer&amp;gt; needsRestoring = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
     private final Map&amp;lt;TopicPartition, StateRestorer&amp;gt; needsInitializing = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
+    private final Duration pollTime;&lt;/p&gt;

&lt;p&gt;     public StoreChangelogReader(final Consumer&amp;lt;byte[], byte[]&amp;gt; restoreConsumer,&lt;br/&gt;
+                                final Duration pollTime,&lt;br/&gt;
                                 final StateRestoreListener userStateRestoreListener,&lt;br/&gt;
                                 final LogContext logContext) &lt;/p&gt;
{
         this.restoreConsumer = restoreConsumer;
+        this.pollTime = pollTime;
         this.log = logContext.logger(getClass());
         this.userStateRestoreListener = userStateRestoreListener;
     }
&lt;p&gt;@@ -76,7 +80,7 @@ public void register(final StateRestorer restorer) {&lt;br/&gt;
         }&lt;/p&gt;

&lt;p&gt;         try {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = restoreConsumer.poll(10);&lt;br/&gt;
+            final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = restoreConsumer.poll(pollTime);&lt;br/&gt;
             final Iterator&amp;lt;TopicPartition&amp;gt; iterator = needsRestoring.keySet().iterator();&lt;br/&gt;
             while (iterator.hasNext()) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {                 final TopicPartition partition = iterator.next();@@ -295,6 +299,7 @@ private boolean hasPartition(final TopicPartition topicPartition) {
                 return true;
             }         }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;+&lt;br/&gt;
         return false;&lt;br/&gt;
     }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java&lt;br/&gt;
index e72c4a5de94..a159e7b6c7a 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java&lt;br/&gt;
+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java&lt;br/&gt;
@@ -50,6 +50,7 @@&lt;br/&gt;
 import org.apache.kafka.streams.state.internals.ThreadCache;&lt;br/&gt;
 import org.slf4j.Logger;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+import java.time.Duration;&lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
 import java.util.Arrays;&lt;br/&gt;
 import java.util.Collection;&lt;br/&gt;
@@ -212,7 +213,7 @@ State setState(final State newState) {&lt;br/&gt;
             if (newState == State.RUNNING) &lt;/p&gt;
{
                 updateThreadMetadata(taskManager.activeTasks(), taskManager.standbyTasks());
             }
&lt;p&gt; else &lt;/p&gt;
{
-                updateThreadMetadata(Collections.&amp;lt;TaskId, StreamTask&amp;gt;emptyMap(), Collections.&amp;lt;TaskId, StandbyTask&amp;gt;emptyMap());
+                updateThreadMetadata(Collections.emptyMap(), Collections.emptyMap());
             }
&lt;p&gt;         }&lt;/p&gt;

&lt;p&gt;@@ -555,7 +556,7 @@ StandbyTask createTask(final Consumer&amp;lt;byte[], byte[]&amp;gt; consumer,&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;     private final Time time;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final long pollTimeMs;&lt;br/&gt;
+    private final Duration pollTime;&lt;br/&gt;
     private final long commitTimeMs;&lt;br/&gt;
     private final Object stateLock;&lt;br/&gt;
     private final Logger log;&lt;br/&gt;
@@ -602,7 +603,8 @@ public static StreamThread create(final InternalTopologyBuilder builder,&lt;br/&gt;
         log.info(&quot;Creating restore consumer client&quot;);&lt;br/&gt;
         final Map&amp;lt;String, Object&amp;gt; restoreConsumerConfigs = config.getRestoreConsumerConfigs(threadClientId);&lt;br/&gt;
         final Consumer&amp;lt;byte[], byte[]&amp;gt; restoreConsumer = clientSupplier.getRestoreConsumer(restoreConsumerConfigs);&lt;/li&gt;
	&lt;li&gt;final StoreChangelogReader changelogReader = new StoreChangelogReader(restoreConsumer, userStateRestoreListener, logContext);&lt;br/&gt;
+        final Duration pollTime = Duration.ofMillis(config.getLong(StreamsConfig.POLL_MS_CONFIG));&lt;br/&gt;
+        final StoreChangelogReader changelogReader = new StoreChangelogReader(restoreConsumer, pollTime, userStateRestoreListener, logContext);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         Producer&amp;lt;byte[], byte[]&amp;gt; threadProducer = null;&lt;br/&gt;
         final boolean eosEnabled = StreamsConfig.EXACTLY_ONCE.equals(config.getString(StreamsConfig.PROCESSING_GUARANTEE_CONFIG));&lt;br/&gt;
@@ -710,10 +712,10 @@ public StreamThread(final Time time,&lt;br/&gt;
         this.originalReset = originalReset;&lt;br/&gt;
         this.versionProbingFlag = versionProbingFlag;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;this.pollTimeMs = config.getLong(StreamsConfig.POLL_MS_CONFIG);&lt;br/&gt;
+        this.pollTime = Duration.ofMillis(config.getLong(StreamsConfig.POLL_MS_CONFIG));&lt;br/&gt;
         this.commitTimeMs = config.getLong(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;updateThreadMetadata(Collections.&amp;lt;TaskId, StreamTask&amp;gt;emptyMap(), Collections.&amp;lt;TaskId, StandbyTask&amp;gt;emptyMap());&lt;br/&gt;
+        updateThreadMetadata(Collections.emptyMap(), Collections.emptyMap());&lt;br/&gt;
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;br/&gt;
@@ -801,14 +803,14 @@ long runOnce(final long recordsProcessedBeforeCommit) {&lt;br/&gt;
         if (state == State.PARTITIONS_ASSIGNED) {&lt;br/&gt;
             // try to fetch some records with zero poll millis&lt;br/&gt;
             // to unblock the restoration as soon as possible&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;records = pollRequests(0L);&lt;br/&gt;
+            records = pollRequests(Duration.ZERO);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             if (taskManager.updateNewAndRestoringTasks()) &lt;/p&gt;
{
                 setState(State.RUNNING);
             }
&lt;p&gt;         } else {&lt;br/&gt;
             // try to fetch some records if necessary&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;records = pollRequests(pollTimeMs);&lt;br/&gt;
+            records = pollRequests(pollTime);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             // if state changed after the poll call,&lt;br/&gt;
             // try to initialize the assigned tasks again&lt;br/&gt;
@@ -843,15 +845,15 @@ long runOnce(final long recordsProcessedBeforeCommit) {&lt;br/&gt;
     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Get the next batch of records by polling.&lt;br/&gt;
      *&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* @param pollTimeMs poll time millis parameter for the consumer poll&lt;br/&gt;
+     * @param pollTime how long to block in Consumer#poll&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@return Next batch of records or null if no records available.&lt;/li&gt;
	&lt;li&gt;@throws TaskMigratedException if the task producer got fenced (EOS only)&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; pollRequests(final long pollTimeMs) {&lt;br/&gt;
+    private ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; pollRequests(final Duration pollTime) {&lt;br/&gt;
         ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = null;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         try &lt;/p&gt;
{
-            records = consumer.poll(pollTimeMs);
+            records = consumer.poll(pollTime);
         }
&lt;p&gt; catch (final InvalidOffsetException e) &lt;/p&gt;
{
             resetInvalidOffsets(e);
         }
&lt;p&gt;@@ -1078,7 +1080,11 @@ private void maybeUpdateStandbyTasks(final long now) {&lt;br/&gt;
             }&lt;/p&gt;

&lt;p&gt;             try {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = restoreConsumer.poll(0);&lt;br/&gt;
+                // poll(0): Since this is during the normal processing, not during restoration.&lt;br/&gt;
+                // We can afford to have slower restore (because we don&apos;t wait inside poll for results).&lt;br/&gt;
+                // Instead, we want to proceed to the next iteration to call the main consumer#poll()&lt;br/&gt;
+                // as soon as possible so as to not be kicked out of the group.&lt;br/&gt;
+                final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = restoreConsumer.poll(Duration.ZERO);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;                 if (!records.isEmpty()) {&lt;br/&gt;
                     for (final TopicPartition partition : records.partitions()) {&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java b/streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java&lt;br/&gt;
index 297b2434c06..8635b94544e 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java&lt;br/&gt;
@@ -16,6 +16,8 @@&lt;br/&gt;
  */&lt;br/&gt;
 package org.apache.kafka.streams;&lt;/p&gt;

&lt;p&gt;+import org.apache.kafka.clients.CommonClientConfigs;&lt;br/&gt;
+import org.apache.kafka.clients.consumer.ConsumerConfig;&lt;br/&gt;
 import org.apache.kafka.clients.producer.MockProducer;&lt;br/&gt;
 import org.apache.kafka.common.Cluster;&lt;br/&gt;
 import org.apache.kafka.common.Node;&lt;br/&gt;
@@ -25,6 +27,7 @@&lt;br/&gt;
 import org.apache.kafka.common.serialization.Serdes;&lt;br/&gt;
 import org.apache.kafka.common.serialization.StringSerializer;&lt;br/&gt;
 import org.apache.kafka.common.utils.Utils;&lt;br/&gt;
+import org.apache.kafka.streams.errors.StreamsException;&lt;br/&gt;
 import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;&lt;br/&gt;
 import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;&lt;br/&gt;
 import org.apache.kafka.streams.kstream.Consumed;&lt;br/&gt;
@@ -42,7 +45,6 @@&lt;br/&gt;
 import org.junit.Assert;&lt;br/&gt;
 import org.junit.Before;&lt;br/&gt;
 import org.junit.ClassRule;&lt;br/&gt;
-import org.junit.Ignore;&lt;br/&gt;
 import org.junit.Test;&lt;br/&gt;
 import org.junit.experimental.categories.Category;&lt;/p&gt;

&lt;p&gt;@@ -234,9 +236,8 @@ public boolean conditionMet() &lt;/p&gt;
{
         assertEquals(streams.state(), KafkaStreams.State.NOT_RUNNING);
     }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Ignore // this test cannot pass as long as GST blocks KS.start()&lt;br/&gt;
     @Test&lt;/li&gt;
	&lt;li&gt;public void testGlobalThreadCloseWithoutConnectingToBroker() {&lt;br/&gt;
+    public void globalThreadShouldTimeoutWhenBrokerConnectionCannotBeEstablished() {&lt;br/&gt;
         final Properties props = new Properties();&lt;br/&gt;
         props.setProperty(StreamsConfig.APPLICATION_ID_CONFIG, &quot;appId&quot;);&lt;br/&gt;
         props.setProperty(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:1&quot;);&lt;br/&gt;
@@ -244,16 +245,26 @@ public void testGlobalThreadCloseWithoutConnectingToBroker() {&lt;br/&gt;
         props.setProperty(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());&lt;br/&gt;
         props.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, NUM_THREADS);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+        // We want to configure request.timeout.ms, but it must be larger than a&lt;br/&gt;
+        // few other configs.&lt;br/&gt;
+        props.put(ConsumerConfig.FETCH_MAX_WAIT_MS_CONFIG, 200);&lt;br/&gt;
+        props.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 200);&lt;br/&gt;
+        props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 201);&lt;br/&gt;
+        props.put(CommonClientConfigs.REQUEST_TIMEOUT_MS_CONFIG, 202);&lt;br/&gt;
+&lt;br/&gt;
         final StreamsBuilder builder = new StreamsBuilder();&lt;br/&gt;
         // make sure we have the global state thread running too&lt;br/&gt;
         builder.globalTable(&quot;anyTopic&quot;);&lt;br/&gt;
         final KafkaStreams streams = new KafkaStreams(builder.build(), props);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;streams.start();&lt;/li&gt;
	&lt;li&gt;streams.close();&lt;br/&gt;
+        try 
{
+            streams.start();
+            fail(&quot;expected start() to time out and throw an exception.&quot;);
+        }
&lt;p&gt; catch (final StreamsException expected) &lt;/p&gt;
{
+            // This is a result of not being able to connect to the broker.
+        }
&lt;p&gt;         // There&apos;s nothing to assert... We&apos;re testing that this operation actually completes.&lt;br/&gt;
     }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Ignore // this test cannot pass until we implement KIP-266&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testLocalThreadCloseWithoutConnectingToBroker() {&lt;br/&gt;
         final Properties props = new Properties();&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java b/streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java&lt;br/&gt;
index fe897c7ac30..86cb331956c 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java&lt;br/&gt;
@@ -44,6 +44,7 @@&lt;br/&gt;
 import java.io.File;&lt;br/&gt;
 import java.io.IOException;&lt;br/&gt;
 import java.nio.file.Paths;&lt;br/&gt;
+import java.time.Duration;&lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
 import java.util.Collection;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
@@ -464,7 +465,7 @@ public boolean conditionMet() {&lt;br/&gt;
         while (totalPollTimeMs &amp;lt; waitTime &amp;amp;&amp;amp;&lt;br/&gt;
             continueConsuming(consumerRecords.size(), maxMessages)) {&lt;br/&gt;
             totalPollTimeMs += pollIntervalMs;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;K, V&amp;gt; records = consumer.poll(pollIntervalMs);&lt;br/&gt;
+            final ConsumerRecords&amp;lt;K, V&amp;gt; records = consumer.poll(Duration.ofMillis(pollIntervalMs));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             for (final ConsumerRecord&amp;lt;K, V&amp;gt; record : records) {&lt;br/&gt;
                 consumerRecords.add(record);&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/perf/SimpleBenchmark.java b/streams/src/test/java/org/apache/kafka/streams/perf/SimpleBenchmark.java&lt;br/&gt;
index 8187467aaa6..7179293200e 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/perf/SimpleBenchmark.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/perf/SimpleBenchmark.java&lt;br/&gt;
@@ -54,6 +54,7 @@&lt;br/&gt;
 import org.apache.kafka.streams.state.WindowStore;&lt;/p&gt;

&lt;p&gt; import java.io.IOException;&lt;br/&gt;
+import java.time.Duration;&lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
 import java.util.List;&lt;br/&gt;
 import java.util.Locale;&lt;br/&gt;
@@ -334,7 +335,7 @@ private void consumeAndProduce(final String topic) {&lt;br/&gt;
             consumer.seekToBeginning(partitions);&lt;/p&gt;

&lt;p&gt;             while (true) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;Integer, byte[]&amp;gt; records = consumer.poll(POLL_MS);&lt;br/&gt;
+                final ConsumerRecords&amp;lt;Integer, byte[]&amp;gt; records = consumer.poll(Duration.ofMillis(POLL_MS));&lt;br/&gt;
                 if (records.isEmpty()) {&lt;br/&gt;
                     if (processedRecords == numRecords) {&lt;br/&gt;
                         break;&lt;br/&gt;
@@ -372,7 +373,7 @@ private void consume(final String topic) {&lt;br/&gt;
             consumer.seekToBeginning(partitions);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             while (true) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;Integer, byte[]&amp;gt; records = consumer.poll(POLL_MS);&lt;br/&gt;
+                final ConsumerRecords&amp;lt;Integer, byte[]&amp;gt; records = consumer.poll(Duration.ofMillis(POLL_MS));&lt;br/&gt;
                 if (records.isEmpty()) {&lt;br/&gt;
                     if (processedRecords == numRecords) {&lt;br/&gt;
                         break;&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/AbstractTaskTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/AbstractTaskTest.java&lt;br/&gt;
index 347e9c4fd75..4ed44be47f2 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/processor/internals/AbstractTaskTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/AbstractTaskTest.java&lt;br/&gt;
@@ -42,6 +42,7 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import java.io.File;&lt;br/&gt;
 import java.io.IOException;&lt;br/&gt;
+import java.time.Duration;&lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
 import java.util.Collection;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
@@ -233,7 +234,7 @@ private AbstractTask createTask(final Consumer consumer,&lt;br/&gt;
                                 storeTopicPartitions,&lt;br/&gt;
                                 ProcessorTopology.withLocalStores(new ArrayList&amp;lt;&amp;gt;(stateStoresToChangelogTopics.keySet()), storeNamesToChangelogTopics),&lt;br/&gt;
                                 consumer,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new StoreChangelogReader(consumer, new MockStateRestoreListener(), new LogContext(&quot;stream-task-test &quot;)),&lt;br/&gt;
+                                new StoreChangelogReader(consumer, Duration.ZERO, new MockStateRestoreListener(), new LogContext(&quot;stream-task-test &quot;)),&lt;br/&gt;
                                 false,&lt;br/&gt;
                                 stateDirectory,&lt;br/&gt;
                                 config) {&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java&lt;br/&gt;
index 93d6a0d931b..05d0e3d04ee 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java&lt;br/&gt;
@@ -50,6 +50,7 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import java.io.File;&lt;br/&gt;
 import java.io.IOException;&lt;br/&gt;
+import java.time.Duration;&lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
 import java.util.Arrays;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
@@ -122,7 +123,12 @@ private StreamsConfig createConfig(final File baseDir) throws IOException {&lt;/p&gt;

&lt;p&gt;     private final MockConsumer&amp;lt;byte[], byte[]&amp;gt; consumer = new MockConsumer&amp;lt;&amp;gt;(OffsetResetStrategy.EARLIEST);&lt;br/&gt;
     private final MockRestoreConsumer restoreStateConsumer = new MockRestoreConsumer();&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final StoreChangelogReader changelogReader = new StoreChangelogReader(restoreStateConsumer, stateRestoreListener, new LogContext(&quot;standby-task-test &quot;));&lt;br/&gt;
+    private final StoreChangelogReader changelogReader = new StoreChangelogReader(&lt;br/&gt;
+        restoreStateConsumer,&lt;br/&gt;
+        Duration.ZERO,&lt;br/&gt;
+        stateRestoreListener,&lt;br/&gt;
+        new LogContext(&quot;standby-task-test &quot;)&lt;br/&gt;
+    );&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     private final byte[] recordValue = intSerializer.serialize(null, 10);&lt;br/&gt;
     private final byte[] recordKey = intSerializer.serialize(null, 1);&lt;br/&gt;
@@ -188,7 +194,7 @@ public void testUpdate() throws IOException {&lt;br/&gt;
         }&lt;/p&gt;

&lt;p&gt;         restoreStateConsumer.seekToBeginning(partition);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;task.update(partition2, restoreStateConsumer.poll(100).records(partition2));&lt;br/&gt;
+        task.update(partition2, restoreStateConsumer.poll(Duration.ofMillis(100)).records(partition2));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         StandbyContextImpl context = (StandbyContextImpl) task.context();&lt;br/&gt;
         MockStateStore store1 = (MockStateStore) context.getStateMgr().getStore(storeName1);&lt;br/&gt;
@@ -245,7 +251,7 @@ public void testUpdateKTable() throws IOException {&lt;br/&gt;
         }&lt;/p&gt;

&lt;p&gt;         // The commit offset is at 0L. Records should not be processed&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;List&amp;lt;ConsumerRecord&amp;lt;byte[], byte[]&amp;gt;&amp;gt; remaining = task.update(globalTopicPartition, restoreStateConsumer.poll(100).records(globalTopicPartition));&lt;br/&gt;
+        List&amp;lt;ConsumerRecord&amp;lt;byte[], byte[]&amp;gt;&amp;gt; remaining = task.update(globalTopicPartition, restoreStateConsumer.poll(Duration.ofMillis(100)).records(globalTopicPartition));&lt;br/&gt;
         assertEquals(5, remaining.size());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         committedOffsets.put(new TopicPartition(globalTopicPartition.topic(), globalTopicPartition.partition()), new OffsetAndMetadata(10L));&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StateConsumerTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StateConsumerTest.java&lt;br/&gt;
index 725211dd268..140f7056199 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StateConsumerTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StateConsumerTest.java&lt;br/&gt;
@@ -27,6 +27,7 @@&lt;br/&gt;
 import org.junit.Test;&lt;/p&gt;

&lt;p&gt; import java.io.IOException;&lt;br/&gt;
+import java.time.Duration;&lt;br/&gt;
 import java.util.HashMap;&lt;br/&gt;
 import java.util.Map;&lt;/p&gt;

&lt;p&gt;@@ -52,7 +53,7 @@ public void setUp() &lt;/p&gt;
{
         partitionOffsets.put(topicOne, 20L);
         partitionOffsets.put(topicTwo, 30L);
         stateMaintainer = new StateMaintainerStub(partitionOffsets);
-        stateConsumer = new GlobalStreamThread.StateConsumer(logContext, consumer, stateMaintainer, time, 10L, FLUSH_INTERVAL);
+        stateConsumer = new GlobalStreamThread.StateConsumer(logContext, consumer, stateMaintainer, time, Duration.ofMillis(10L), FLUSH_INTERVAL);
     }

&lt;p&gt;     @Test&lt;br/&gt;
@@ -109,7 +110,7 @@ public void shouldNotFlushOffsetsWhenFlushIntervalHasNotLapsed() {&lt;/p&gt;

&lt;p&gt;     @Test&lt;br/&gt;
     public void shouldNotFlushWhenFlushIntervalIsZero() {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;stateConsumer = new GlobalStreamThread.StateConsumer(logContext, consumer, stateMaintainer, time, 10L, -1);&lt;br/&gt;
+        stateConsumer = new GlobalStreamThread.StateConsumer(logContext, consumer, stateMaintainer, time, Duration.ofMillis(10L), -1);&lt;br/&gt;
         stateConsumer.initialize();&lt;br/&gt;
         time.sleep(100);&lt;br/&gt;
         stateConsumer.pollAndUpdate();&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StoreChangelogReaderTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StoreChangelogReaderTest.java&lt;br/&gt;
index aabe7ff6313..90abf32477f 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StoreChangelogReaderTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StoreChangelogReaderTest.java&lt;br/&gt;
@@ -39,6 +39,7 @@&lt;br/&gt;
 import org.junit.Test;&lt;br/&gt;
 import org.junit.runner.RunWith;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+import java.time.Duration;&lt;br/&gt;
 import java.util.Collection;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
 import java.util.List;&lt;br/&gt;
@@ -71,7 +72,7 @@&lt;br/&gt;
     private final StateRestoreListener stateRestoreListener = new MockStateRestoreListener();&lt;br/&gt;
     private final TopicPartition topicPartition = new TopicPartition(&quot;topic&quot;, 0);&lt;br/&gt;
     private final LogContext logContext = new LogContext(&quot;test-reader &quot;);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final StoreChangelogReader changelogReader = new StoreChangelogReader(consumer, stateRestoreListener, logContext);&lt;br/&gt;
+    private final StoreChangelogReader changelogReader = new StoreChangelogReader(consumer, Duration.ZERO, stateRestoreListener, logContext);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @Before&lt;br/&gt;
     public void setUp() {&lt;br/&gt;
@@ -89,7 +90,7 @@ public void shouldRequestTopicsAndHandleTimeoutException() {&lt;br/&gt;
             }&lt;br/&gt;
         };&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final StoreChangelogReader changelogReader = new StoreChangelogReader(consumer, stateRestoreListener, logContext);&lt;br/&gt;
+        final StoreChangelogReader changelogReader = new StoreChangelogReader(consumer, Duration.ZERO, stateRestoreListener, logContext);&lt;br/&gt;
         changelogReader.register(new StateRestorer(topicPartition, restoreListener, null, Long.MAX_VALUE, true, &quot;storeName&quot;));&lt;br/&gt;
         changelogReader.restore(active);&lt;br/&gt;
         assertTrue(functionCalled.get());&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java&lt;br/&gt;
index 3a0fc4eb1cd..5537335b221 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java&lt;br/&gt;
@@ -56,6 +56,7 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import java.io.File;&lt;br/&gt;
 import java.io.IOException;&lt;br/&gt;
+import java.time.Duration;&lt;br/&gt;
 import java.util.Arrays;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
@@ -116,7 +117,7 @@ public void close() {&lt;br/&gt;
     private final MockProducer&amp;lt;byte[], byte[]&amp;gt; producer = new MockProducer&amp;lt;&amp;gt;(false, bytesSerializer, bytesSerializer);&lt;br/&gt;
     private final MockConsumer&amp;lt;byte[], byte[]&amp;gt; restoreStateConsumer = new MockConsumer&amp;lt;&amp;gt;(OffsetResetStrategy.EARLIEST);&lt;br/&gt;
     private final StateRestoreListener stateRestoreListener = new MockStateRestoreListener();&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final StoreChangelogReader changelogReader = new StoreChangelogReader(restoreStateConsumer, stateRestoreListener, new LogContext(&quot;stream-task-test &quot;)) {&lt;br/&gt;
+    private final StoreChangelogReader changelogReader = new StoreChangelogReader(restoreStateConsumer, Duration.ZERO, stateRestoreListener, new LogContext(&quot;stream-task-test &quot;)) {&lt;br/&gt;
         @Override&lt;br/&gt;
         public Map&amp;lt;TopicPartition, Long&amp;gt; restoredOffsets() {&lt;br/&gt;
             return Collections.singletonMap(changelogPartition, offset);&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/state/internals/StreamThreadStateStoreProviderTest.java b/streams/src/test/java/org/apache/kafka/streams/state/internals/StreamThreadStateStoreProviderTest.java&lt;br/&gt;
index c24122abd13..66ea3c42779 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/state/internals/StreamThreadStateStoreProviderTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/state/internals/StreamThreadStateStoreProviderTest.java&lt;br/&gt;
@@ -49,6 +49,7 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import java.io.File;&lt;br/&gt;
 import java.io.IOException;&lt;br/&gt;
+import java.time.Duration;&lt;br/&gt;
 import java.util.Arrays;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
 import java.util.HashMap;&lt;br/&gt;
@@ -177,7 +178,7 @@ private StreamTask createStreamsTask(final StreamsConfig streamsConfig,&lt;br/&gt;
             Collections.singletonList(new TopicPartition(topicName, taskId.partition)),&lt;br/&gt;
             topology,&lt;br/&gt;
             clientSupplier.consumer,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new StoreChangelogReader(clientSupplier.restoreConsumer, new MockStateRestoreListener(), new LogContext(&quot;test-stream-task &quot;)),&lt;br/&gt;
+            new StoreChangelogReader(clientSupplier.restoreConsumer, Duration.ZERO, new MockStateRestoreListener(), new LogContext(&quot;test-stream-task &quot;)),&lt;br/&gt;
             streamsConfig,&lt;br/&gt;
             new MockStreamsMetrics(metrics),&lt;br/&gt;
             stateDirectory,&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/tests/BrokerCompatibilityTest.java b/streams/src/test/java/org/apache/kafka/streams/tests/BrokerCompatibilityTest.java&lt;br/&gt;
index e897088beca..3c8446ca466 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/tests/BrokerCompatibilityTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/tests/BrokerCompatibilityTest.java&lt;br/&gt;
@@ -37,6 +37,7 @@&lt;br/&gt;
 import org.apache.kafka.streams.kstream.ValueMapper;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import java.io.IOException;&lt;br/&gt;
+import java.time.Duration;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
 import java.util.Locale;&lt;br/&gt;
 import java.util.Properties;&lt;br/&gt;
@@ -153,7 +154,7 @@ private static void loopUntilRecordReceived(final String kafka, final boolean eo&lt;br/&gt;
             consumer.subscribe(Collections.singletonList(SINK_TOPIC));&lt;/p&gt;

&lt;p&gt;             while (true) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(100);&lt;br/&gt;
+                final ConsumerRecords&amp;lt;String, String&amp;gt; records = consumer.poll(Duration.ofMillis(100));&lt;br/&gt;
                 for (final ConsumerRecord&amp;lt;String, String&amp;gt; record : records) {&lt;br/&gt;
                     if (record.key().equals(&quot;key&quot;) &amp;amp;&amp;amp; record.value().equals(&quot;1&quot;)) {&lt;br/&gt;
                         return;&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/tests/EosTestDriver.java b/streams/src/test/java/org/apache/kafka/streams/tests/EosTestDriver.java&lt;br/&gt;
index 752cdd696ed..0b18864d4ab 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/tests/EosTestDriver.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/tests/EosTestDriver.java&lt;br/&gt;
@@ -16,16 +16,18 @@&lt;br/&gt;
  */&lt;br/&gt;
 package org.apache.kafka.streams.tests;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;-import kafka.admin.AdminClient;&lt;br/&gt;
+import org.apache.kafka.clients.admin.AdminClient;&lt;br/&gt;
+import org.apache.kafka.clients.admin.ConsumerGroupDescription;&lt;br/&gt;
+import org.apache.kafka.clients.admin.KafkaAdminClient;&lt;br/&gt;
+import org.apache.kafka.clients.admin.ListConsumerGroupOffsetsResult;&lt;br/&gt;
 import org.apache.kafka.clients.consumer.ConsumerConfig;&lt;br/&gt;
 import org.apache.kafka.clients.consumer.ConsumerRecord;&lt;br/&gt;
 import org.apache.kafka.clients.consumer.ConsumerRecords;&lt;br/&gt;
 import org.apache.kafka.clients.consumer.KafkaConsumer;&lt;br/&gt;
-import org.apache.kafka.clients.producer.Callback;&lt;br/&gt;
+import org.apache.kafka.clients.consumer.OffsetAndMetadata;&lt;br/&gt;
 import org.apache.kafka.clients.producer.KafkaProducer;&lt;br/&gt;
 import org.apache.kafka.clients.producer.ProducerConfig;&lt;br/&gt;
 import org.apache.kafka.clients.producer.ProducerRecord;&lt;br/&gt;
-import org.apache.kafka.clients.producer.RecordMetadata;&lt;br/&gt;
 import org.apache.kafka.common.PartitionInfo;&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition;&lt;br/&gt;
 import org.apache.kafka.common.errors.SerializationException;&lt;br/&gt;
@@ -40,17 +42,18 @@&lt;br/&gt;
 import org.apache.kafka.common.utils.Exit;&lt;br/&gt;
 import org.apache.kafka.common.utils.Utils;&lt;/p&gt;

&lt;p&gt;+import java.time.Duration;&lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
 import java.util.HashMap;&lt;br/&gt;
-import java.util.HashSet;&lt;br/&gt;
 import java.util.Iterator;&lt;br/&gt;
 import java.util.List;&lt;br/&gt;
 import java.util.Locale;&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
 import java.util.Properties;&lt;br/&gt;
 import java.util.Random;&lt;br/&gt;
-import java.util.Set;&lt;br/&gt;
+import java.util.concurrent.ExecutionException;&lt;br/&gt;
+import java.util.concurrent.TimeUnit;&lt;/p&gt;

&lt;p&gt; public class EosTestDriver extends SmokeTestUtil {&lt;/p&gt;

&lt;p&gt;@@ -59,22 +62,19 @@&lt;/p&gt;

&lt;p&gt;     private static boolean isRunning = true;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;static int numRecordsProduced = 0;&lt;br/&gt;
+    private static int numRecordsProduced = 0;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;static synchronized void updateNumRecordsProduces(final int delta) {&lt;br/&gt;
+    private static synchronized void updateNumRecordsProduces(final int delta) 
{
         numRecordsProduced += delta;
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     static void generate(final String kafka) {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Runtime.getRuntime().addShutdownHook(new Thread() {&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void run() 
{
-                System.out.println(&quot;Terminating&quot;);
-                System.out.flush();
-                isRunning = false;
-            }&lt;/li&gt;
	&lt;li&gt;});&lt;br/&gt;
+        Runtime.getRuntime().addShutdownHook(new Thread(() -&amp;gt; 
{
+            System.out.println(&quot;Terminating&quot;);
+            System.out.flush();
+            isRunning = false;
+        }
&lt;p&gt;));&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         final Properties producerProps = new Properties();&lt;br/&gt;
         producerProps.put(ProducerConfig.CLIENT_ID_CONFIG, &quot;EosTest&quot;);&lt;br/&gt;
@@ -93,19 +93,16 @@ public void run() {&lt;/p&gt;

&lt;p&gt;             final ProducerRecord&amp;lt;String, Integer&amp;gt; record = new ProducerRecord&amp;lt;&amp;gt;(&quot;data&quot;, key, value);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;producer.send(record, new Callback() {&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void onCompletion(final RecordMetadata metadata, final Exception exception) {&lt;/li&gt;
	&lt;li&gt;if (exception != null) {&lt;/li&gt;
	&lt;li&gt;exception.printStackTrace(System.err);&lt;/li&gt;
	&lt;li&gt;System.err.flush();&lt;/li&gt;
	&lt;li&gt;if (exception instanceof TimeoutException) {&lt;/li&gt;
	&lt;li&gt;try 
{
-                                // message == org.apache.kafka.common.errors.TimeoutException: Expiring 4 record(s) for data-0: 30004 ms has passed since last attempt plus backoff time
-                                final int expired = Integer.parseInt(exception.getMessage().split(&quot; &quot;)[2]);
-                                updateNumRecordsProduces(-expired);
-                            }
&lt;p&gt; catch (Exception ignore) { }&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
+            producer.send(record, (metadata, exception) -&amp;gt; {&lt;br/&gt;
+                if (exception != null) {&lt;br/&gt;
+                    exception.printStackTrace(System.err);&lt;br/&gt;
+                    System.err.flush();&lt;br/&gt;
+                    if (exception instanceof TimeoutException) {&lt;br/&gt;
+                        try 
{
+                            // message == org.apache.kafka.common.errors.TimeoutException: Expiring 4 record(s) for data-0: 30004 ms has passed since last attempt plus backoff time
+                            final int expired = Integer.parseInt(exception.getMessage().split(&quot; &quot;)[2]);
+                            updateNumRecordsProduces(-expired);
+                        }
&lt;p&gt; catch (final Exception ignore) { }&lt;br/&gt;
                     }&lt;br/&gt;
                 }&lt;br/&gt;
             });&lt;br/&gt;
@@ -141,10 +138,6 @@ public void onCompletion(final RecordMetadata metadata, final Exception exceptio&lt;br/&gt;
     }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     public static void verify(final String kafka, final boolean withRepartitioning) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ensureStreamsApplicationDown(kafka);&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;final Map&amp;lt;TopicPartition, Long&amp;gt; committedOffsets = getCommittedOffsets(kafka, withRepartitioning);&lt;br/&gt;
-&lt;br/&gt;
         final Properties props = new Properties();&lt;br/&gt;
         props.put(ConsumerConfig.CLIENT_ID_CONFIG, &quot;verifier&quot;);&lt;br/&gt;
         props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafka);&lt;br/&gt;
@@ -152,6 +145,13 @@ public static void verify(final String kafka, final boolean withRepartitioning)&lt;br/&gt;
         props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ByteArrayDeserializer.class);&lt;br/&gt;
         props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase(Locale.ROOT));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+        final Map&amp;lt;TopicPartition, Long&amp;gt; committedOffsets;&lt;br/&gt;
+        try (final AdminClient adminClient = KafkaAdminClient.create(props)) &lt;/p&gt;
{
+            ensureStreamsApplicationDown(adminClient);
+
+            committedOffsets = getCommittedOffsets(adminClient, withRepartitioning);
+        }
&lt;p&gt;+&lt;br/&gt;
         final String[] allInputTopics;&lt;br/&gt;
         final String[] allOutputTopics;&lt;br/&gt;
         if (withRepartitioning) &lt;/p&gt;
{
@@ -218,54 +218,42 @@ public static void verify(final String kafka, final boolean withRepartitioning)
         System.out.flush();
     }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static void ensureStreamsApplicationDown(final String kafka) {&lt;/li&gt;
	&lt;li&gt;AdminClient adminClient = null;&lt;/li&gt;
	&lt;li&gt;try {&lt;/li&gt;
	&lt;li&gt;adminClient = AdminClient.createSimplePlaintext(kafka);&lt;br/&gt;
+    private static void ensureStreamsApplicationDown(final AdminClient adminClient) {&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final long maxWaitTime = System.currentTimeMillis() + MAX_IDLE_TIME_MS;&lt;/li&gt;
	&lt;li&gt;while (!adminClient.describeConsumerGroup(EosTestClient.APP_ID, 10000).consumers().get().isEmpty()) {&lt;/li&gt;
	&lt;li&gt;if (System.currentTimeMillis() &amp;gt; maxWaitTime) 
{
-                    throw new RuntimeException(&quot;Streams application not down after &quot; + (MAX_IDLE_TIME_MS / 1000) + &quot; seconds.&quot;);
-                }&lt;/li&gt;
	&lt;li&gt;sleep(1000);&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;} finally {&lt;/li&gt;
	&lt;li&gt;if (adminClient != null) {&lt;/li&gt;
	&lt;li&gt;adminClient.close();&lt;br/&gt;
+        final long maxWaitTime = System.currentTimeMillis() + MAX_IDLE_TIME_MS;&lt;br/&gt;
+        ConsumerGroupDescription description;&lt;br/&gt;
+        do {&lt;br/&gt;
+            description = getConsumerGroupDescription(adminClient);&lt;br/&gt;
+&lt;br/&gt;
+            if (System.currentTimeMillis() &amp;gt; maxWaitTime &amp;amp;&amp;amp; !description.members().isEmpty()) 
{
+                throw new RuntimeException(
+                    &quot;Streams application not down after &quot; + (MAX_IDLE_TIME_MS / 1000) + &quot; seconds. &quot; +
+                        &quot;Group: &quot; + description
+                );
             }&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
+            sleep(1000);&lt;br/&gt;
+        } while (!description.members().isEmpty());&lt;br/&gt;
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static Map&amp;lt;TopicPartition, Long&amp;gt; getCommittedOffsets(final String kafka,&lt;br/&gt;
+&lt;br/&gt;
+    private static Map&amp;lt;TopicPartition, Long&amp;gt; getCommittedOffsets(final AdminClient adminClient,&lt;br/&gt;
                                                                  final boolean withRepartitioning) {&lt;/li&gt;
	&lt;li&gt;final Properties props = new Properties();&lt;/li&gt;
	&lt;li&gt;props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafka);&lt;/li&gt;
	&lt;li&gt;props.put(ConsumerConfig.GROUP_ID_CONFIG, EosTestClient.APP_ID);&lt;/li&gt;
	&lt;li&gt;props.put(ConsumerConfig.CLIENT_ID_CONFIG, &quot;OffsetsClient&quot;);&lt;/li&gt;
	&lt;li&gt;props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, ByteArrayDeserializer.class);&lt;/li&gt;
	&lt;li&gt;props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ByteArrayDeserializer.class);&lt;br/&gt;
+        final Map&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt; topicPartitionOffsetAndMetadataMap;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final Map&amp;lt;TopicPartition, Long&amp;gt; committedOffsets = new HashMap&amp;lt;&amp;gt;();&lt;/li&gt;
	&lt;li&gt;try (final KafkaConsumer&amp;lt;byte[], byte[]&amp;gt; consumer = new KafkaConsumer&amp;lt;&amp;gt;(props)) {&lt;/li&gt;
	&lt;li&gt;final Set&amp;lt;String&amp;gt; topics = new HashSet&amp;lt;&amp;gt;();&lt;/li&gt;
	&lt;li&gt;topics.add(&quot;data&quot;);&lt;/li&gt;
	&lt;li&gt;if (withRepartitioning) 
{
-                topics.add(&quot;repartition&quot;);
-            }&lt;/li&gt;
	&lt;li&gt;consumer.subscribe(topics);&lt;/li&gt;
	&lt;li&gt;consumer.poll(0);&lt;br/&gt;
+        try 
{
+            final ListConsumerGroupOffsetsResult listConsumerGroupOffsetsResult = adminClient.listConsumerGroupOffsets(EosTestClient.APP_ID);
+            topicPartitionOffsetAndMetadataMap = listConsumerGroupOffsetsResult.partitionsToOffsetAndMetadata().get(10, TimeUnit.SECONDS);
+        }
&lt;p&gt; catch (final InterruptedException | ExecutionException | java.util.concurrent.TimeoutException e) &lt;/p&gt;
{
+            e.printStackTrace();
+            throw new RuntimeException(e);
+        }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final Set&amp;lt;TopicPartition&amp;gt; partitions = new HashSet&amp;lt;&amp;gt;();&lt;/li&gt;
	&lt;li&gt;for (final String topic : topics) {&lt;/li&gt;
	&lt;li&gt;for (final PartitionInfo partition : consumer.partitionsFor(topic)) 
{
-                    partitions.add(new TopicPartition(partition.topic(), partition.partition()));
-                }&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
+        final Map&amp;lt;TopicPartition, Long&amp;gt; committedOffsets = new HashMap&amp;lt;&amp;gt;();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for (final TopicPartition tp : partitions) {&lt;/li&gt;
	&lt;li&gt;final long offset = consumer.position(tp);&lt;/li&gt;
	&lt;li&gt;committedOffsets.put(tp, offset);&lt;br/&gt;
+        for (final Map.Entry&amp;lt;TopicPartition, OffsetAndMetadata&amp;gt; entry : topicPartitionOffsetAndMetadataMap.entrySet()) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+            final String topic = entry.getKey().topic();+            if (topic.equals(&amp;quot;data&amp;quot;) || withRepartitioning &amp;amp;&amp;amp; topic.equals(&amp;quot;repartition&amp;quot;)) {
+                committedOffsets.put(entry.getKey(), entry.getValue().offset());
             }         }&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -284,7 +272,7 @@ private static void ensureStreamsApplicationDown(final String kafka) {&lt;br/&gt;
         long maxWaitTime = System.currentTimeMillis() + MAX_IDLE_TIME_MS;&lt;br/&gt;
         boolean allRecordsReceived = false;&lt;br/&gt;
         while (!allRecordsReceived &amp;amp;&amp;amp; System.currentTimeMillis() &amp;lt; maxWaitTime) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; receivedRecords = consumer.poll(100);&lt;br/&gt;
+            final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; receivedRecords = consumer.poll(Duration.ofMillis(100));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             for (final ConsumerRecord&amp;lt;byte[], byte[]&amp;gt; record : receivedRecords) {&lt;br/&gt;
                 maxWaitTime = System.currentTimeMillis() + MAX_IDLE_TIME_MS;&lt;br/&gt;
@@ -327,19 +315,12 @@ private static void addRecord(final ConsumerRecord&amp;lt;byte[], byte[]&amp;gt; record,&lt;br/&gt;
         final TopicPartition partition = new TopicPartition(topic, record.partition());&lt;/p&gt;

&lt;p&gt;         if (verifyTopic(topic, withRepartitioning)) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Map&amp;lt;TopicPartition, List&amp;lt;ConsumerRecord&amp;lt;byte[], byte[]&amp;gt;&amp;gt;&amp;gt; topicRecordsPerPartition&lt;/li&gt;
	&lt;li&gt;= recordPerTopicPerPartition.get(topic);&lt;br/&gt;
+            final Map&amp;lt;TopicPartition, List&amp;lt;ConsumerRecord&amp;lt;byte[], byte[]&amp;gt;&amp;gt;&amp;gt; topicRecordsPerPartition =&lt;br/&gt;
+                recordPerTopicPerPartition.computeIfAbsent(topic, k -&amp;gt; new HashMap&amp;lt;&amp;gt;());&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (topicRecordsPerPartition == null) 
{
-                topicRecordsPerPartition = new HashMap&amp;lt;&amp;gt;();
-                recordPerTopicPerPartition.put(topic, topicRecordsPerPartition);
-            }
&lt;p&gt;+            final List&amp;lt;ConsumerRecord&amp;lt;byte[], byte[]&amp;gt;&amp;gt; records =&lt;br/&gt;
+                topicRecordsPerPartition.computeIfAbsent(partition, k -&amp;gt; new ArrayList&amp;lt;&amp;gt;());&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;List&amp;lt;ConsumerRecord&amp;lt;byte[], byte[]&amp;gt;&amp;gt; records = topicRecordsPerPartition.get(partition);&lt;/li&gt;
	&lt;li&gt;if (records == null) 
{
-                records = new ArrayList&amp;lt;&amp;gt;();
-                topicRecordsPerPartition.put(partition, records);
-            }
&lt;p&gt;             records.add(record);&lt;br/&gt;
         } else {&lt;br/&gt;
             throw new RuntimeException(&quot;FAIL: received data from unexpected topic: &quot; + record);&lt;br/&gt;
@@ -397,7 +378,7 @@ private static void verifyMin(final Map&amp;lt;TopicPartition, List&amp;lt;ConsumerRecord&amp;lt;byte&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             if (partitionInput.size() != partitionMin.size()) &lt;/p&gt;
{
                 throw new RuntimeException(&quot;Result verification failed: expected &quot; + partitionInput.size() + &quot; records for &quot;
-                    +  partitionRecords.getKey() + &quot; but received &quot; + partitionMin.size());
+                    + partitionRecords.getKey() + &quot; but received &quot; + partitionMin.size());
             }

&lt;p&gt;             final Iterator&amp;lt;ConsumerRecord&amp;lt;byte[], byte[]&amp;gt;&amp;gt; inputRecords = partitionInput.iterator();&lt;br/&gt;
@@ -439,7 +420,7 @@ private static void verifySum(final Map&amp;lt;TopicPartition, List&amp;lt;ConsumerRecord&amp;lt;byte&lt;/p&gt;

&lt;p&gt;             if (partitionInput.size() != partitionSum.size()) &lt;/p&gt;
{
                 throw new RuntimeException(&quot;Result verification failed: expected &quot; + partitionInput.size() + &quot; records for &quot;
-                    +  partitionRecords.getKey() + &quot; but received &quot; + partitionSum.size());
+                    + partitionRecords.getKey() + &quot; but received &quot; + partitionSum.size());
             }

&lt;p&gt;             final Iterator&amp;lt;ConsumerRecord&amp;lt;byte[], byte[]&amp;gt;&amp;gt; inputRecords = partitionInput.iterator();&lt;br/&gt;
@@ -480,7 +461,7 @@ private static void verifyMax(final Map&amp;lt;TopicPartition, List&amp;lt;ConsumerRecord&amp;lt;byte&lt;/p&gt;

&lt;p&gt;             if (partitionInput.size() != partitionMax.size()) &lt;/p&gt;
{
                 throw new RuntimeException(&quot;Result verification failed: expected &quot; + partitionInput.size() + &quot; records for &quot;
-                    +  partitionRecords.getKey() + &quot; but received &quot; + partitionMax.size());
+                    + partitionRecords.getKey() + &quot; but received &quot; + partitionMax.size());
             }

&lt;p&gt;             final Iterator&amp;lt;ConsumerRecord&amp;lt;byte[], byte[]&amp;gt;&amp;gt; inputRecords = partitionInput.iterator();&lt;br/&gt;
@@ -501,7 +482,7 @@ private static void verifyMax(final Map&amp;lt;TopicPartition, List&amp;lt;ConsumerRecord&amp;lt;byte&lt;br/&gt;
                 max = Math.max(max, value);&lt;br/&gt;
                 currentMinPerKey.put(key, max);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (!receivedKey.equals(key) || receivedValue != max.intValue()) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+                if (!receivedKey.equals(key) || receivedValue != max) {
                     throw new RuntimeException(&quot;Result verification failed for &quot; + receivedRecord + &quot; expected &amp;lt;&quot; + key + &quot;,&quot; + max + &quot;&amp;gt; but was &amp;lt;&quot; + receivedKey + &quot;,&quot; + receivedValue + &quot;&amp;gt;&quot;);
                 }             }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;@@ -521,7 +502,7 @@ private static void verifyCnt(final Map&amp;lt;TopicPartition, List&amp;lt;ConsumerRecord&amp;lt;byte&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;             if (partitionInput.size() != partitionCnt.size()) &lt;/p&gt;
{
                 throw new RuntimeException(&quot;Result verification failed: expected &quot; + partitionInput.size() + &quot; records for &quot;
-                    +  partitionRecords.getKey() + &quot; but received &quot; + partitionCnt.size());
+                    + partitionRecords.getKey() + &quot; but received &quot; + partitionCnt.size());
             }

&lt;p&gt;             final Iterator&amp;lt;ConsumerRecord&amp;lt;byte[], byte[]&amp;gt;&amp;gt; inputRecords = partitionInput.iterator();&lt;br/&gt;
@@ -539,7 +520,7 @@ private static void verifyCnt(final Map&amp;lt;TopicPartition, List&amp;lt;ConsumerRecord&amp;lt;byte&lt;br/&gt;
                 }&lt;br/&gt;
                 currentSumPerKey.put(key, ++cnt);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (!receivedKey.equals(key) || receivedValue != cnt.longValue()) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+                if (!receivedKey.equals(key) || receivedValue != cnt) {
                     throw new RuntimeException(&quot;Result verification failed for &quot; + receivedRecord + &quot; expected &amp;lt;&quot; + key + &quot;,&quot; + cnt + &quot;&amp;gt; but was &amp;lt;&quot; + receivedKey + &quot;,&quot; + receivedValue + &quot;&amp;gt;&quot;);
                 }             }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;@@ -574,14 +555,11 @@ private static void verifyAllTransactionFinished(final KafkaConsumer&amp;lt;byte[], byt&lt;br/&gt;
             for (final TopicPartition tp : partitions) {&lt;br/&gt;
                 final ProducerRecord&amp;lt;String, String&amp;gt; record = new ProducerRecord&amp;lt;&amp;gt;(tp.topic(), tp.partition(), &quot;key&quot;, &quot;value&quot;);&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;producer.send(record, new Callback() {&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void onCompletion(final RecordMetadata metadata, final Exception exception) {&lt;/li&gt;
	&lt;li&gt;if (exception != null) 
{
-                            exception.printStackTrace(System.err);
-                            System.err.flush();
-                            Exit.exit(1);
-                        }
&lt;p&gt;+                producer.send(record, (metadata, exception) -&amp;gt; &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+                    if (exception != null) {
+                        exception.printStackTrace(System.err);
+                        System.err.flush();
+                        Exit.exit(1);
                     }                 }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;);&lt;br/&gt;
             }&lt;br/&gt;
@@ -591,7 +569,7 @@ public void onCompletion(final RecordMetadata metadata, final Exception exceptio&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         long maxWaitTime = System.currentTimeMillis() + MAX_IDLE_TIME_MS;&lt;br/&gt;
         while (!partitions.isEmpty() &amp;amp;&amp;amp; System.currentTimeMillis() &amp;lt; maxWaitTime) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(100);&lt;br/&gt;
+            final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(Duration.ofMillis(100));&lt;br/&gt;
             if (records.isEmpty()) {&lt;br/&gt;
                 System.out.println(&quot;No data received.&quot;);&lt;br/&gt;
                 for (final TopicPartition tp : partitions) 
{
@@ -638,4 +616,18 @@ public void onCompletion(final RecordMetadata metadata, final Exception exceptio
         return partitions;
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+&lt;br/&gt;
+    private static ConsumerGroupDescription getConsumerGroupDescription(final AdminClient adminClient) {&lt;br/&gt;
+        final ConsumerGroupDescription description;&lt;br/&gt;
+        try &lt;/p&gt;
{
+            description = adminClient.describeConsumerGroups(Collections.singleton(EosTestClient.APP_ID))
+                .describedGroups()
+                .get(EosTestClient.APP_ID)
+                .get(10, TimeUnit.SECONDS);
+        }
&lt;p&gt; catch (final InterruptedException | ExecutionException | java.util.concurrent.TimeoutException e) &lt;/p&gt;
{
+            e.printStackTrace();
+            throw new RuntimeException(&quot;Unexpected Exception getting group description&quot;, e);
+        }
&lt;p&gt;+        return description;&lt;br/&gt;
+    }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestDriver.java b/streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestDriver.java&lt;br/&gt;
index 50330a08e61..7533fdd0858 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestDriver.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/tests/SmokeTestDriver.java&lt;br/&gt;
@@ -36,6 +36,7 @@&lt;br/&gt;
 import org.apache.kafka.test.TestUtils;&lt;/p&gt;

&lt;p&gt; import java.io.File;&lt;br/&gt;
+import java.time.Duration;&lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
 import java.util.HashMap;&lt;br/&gt;
@@ -289,7 +290,7 @@ public static void verify(String kafka, Map&amp;lt;String, Set&amp;lt;Integer&amp;gt;&amp;gt; allData, int m&lt;br/&gt;
         int retry = 0;&lt;br/&gt;
         final long start = System.currentTimeMillis();&lt;br/&gt;
         while (System.currentTimeMillis() - start &amp;lt; TimeUnit.MINUTES.toMillis(6)) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);&lt;br/&gt;
+            ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(Duration.ofMillis(500));&lt;br/&gt;
             if (records.isEmpty() &amp;amp;&amp;amp; recordsProcessed &amp;gt;= recordsGenerated) {&lt;br/&gt;
                 if (verifyMin(min, allData, false)&lt;br/&gt;
                     &amp;amp;&amp;amp; verifyMax(max, allData, false)&lt;br/&gt;
diff --git a/streams/src/test/java/org/apache/kafka/streams/tools/StreamsResetterTest.java b/streams/src/test/java/org/apache/kafka/streams/tools/StreamsResetterTest.java&lt;br/&gt;
index ad19f32fd1d..33cf1fa34bc 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/src/test/java/org/apache/kafka/streams/tools/StreamsResetterTest.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/streams/tools/StreamsResetterTest.java&lt;br/&gt;
@@ -32,6 +32,7 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import java.text.ParseException;&lt;br/&gt;
 import java.text.SimpleDateFormat;&lt;br/&gt;
+import java.time.Duration;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
 import java.util.Date;&lt;br/&gt;
 import java.util.HashMap;&lt;br/&gt;
@@ -74,7 +75,7 @@ public void testResetToSpecificOffsetWhenBetweenBeginningAndEndOffset() &lt;/p&gt;
{
 
         streamsResetter.resetOffsetsTo(consumer, inputTopicPartitions, 2L);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(Duration.ofMillis(500));
         assertEquals(3, records.count());
     }

&lt;p&gt;@@ -90,7 +91,7 @@ public void testResetToSpecificOffsetWhenBeforeBeginningOffset() &lt;/p&gt;
{
 
         streamsResetter.resetOffsetsTo(consumer, inputTopicPartitions, 2L);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(Duration.ofMillis(500));
         assertEquals(2, records.count());
     }

&lt;p&gt;@@ -106,7 +107,7 @@ public void testResetToSpecificOffsetWhenAfterEndOffset() &lt;/p&gt;
{
 
         streamsResetter.resetOffsetsTo(consumer, inputTopicPartitions, 4L);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(Duration.ofMillis(500));
         assertEquals(2, records.count());
     }

&lt;p&gt;@@ -122,7 +123,7 @@ public void testShiftOffsetByWhenBetweenBeginningAndEndOffset() &lt;/p&gt;
{
 
         streamsResetter.shiftOffsetsBy(consumer, inputTopicPartitions, 3L);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(Duration.ofMillis(500));
         assertEquals(2, records.count());
     }

&lt;p&gt;@@ -138,7 +139,7 @@ public void testShiftOffsetByWhenBeforeBeginningOffset() &lt;/p&gt;
{
 
         streamsResetter.shiftOffsetsBy(consumer, inputTopicPartitions, -3L);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(Duration.ofMillis(500));
         assertEquals(5, records.count());
     }

&lt;p&gt;@@ -154,7 +155,7 @@ public void testShiftOffsetByWhenAfterEndOffset() &lt;/p&gt;
{
 
         streamsResetter.shiftOffsetsBy(consumer, inputTopicPartitions, 5L);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(Duration.ofMillis(500));
         assertEquals(2, records.count());
     }

&lt;p&gt;@@ -172,7 +173,7 @@ public void testResetUsingPlanWhenBetweenBeginningAndEndOffset() &lt;/p&gt;
{
         topicPartitionsAndOffset.put(topicPartition, 3L);
         streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(Duration.ofMillis(500));
         assertEquals(2, records.count());
     }

&lt;p&gt;@@ -190,7 +191,7 @@ public void testResetUsingPlanWhenBeforeBeginningOffset() &lt;/p&gt;
{
         topicPartitionsAndOffset.put(topicPartition, 1L);
         streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(Duration.ofMillis(500));
         assertEquals(2, records.count());
     }

&lt;p&gt;@@ -208,7 +209,7 @@ public void testResetUsingPlanWhenAfterEndOffset() &lt;/p&gt;
{
         topicPartitionsAndOffset.put(topicPartition, 5L);
         streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(Duration.ofMillis(500));
         assertEquals(2, records.count());
     }

&lt;p&gt;@@ -226,7 +227,7 @@ public void shouldSeekToEndOffset() &lt;/p&gt;
{
         intermediateTopicPartitions.add(topicPartition);
         streamsResetter.maybeSeekToEnd(&quot;g1&quot;, consumer, intermediateTopicPartitions);
 
-        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(500);
+        final ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; records = consumer.poll(Duration.ofMillis(500));
         assertEquals(2, records.count());
     }

&lt;p&gt;diff --git a/streams/src/test/java/org/apache/kafka/test/MockRestoreConsumer.java b/streams/src/test/java/org/apache/kafka/test/MockRestoreConsumer.java&lt;br/&gt;
index 3070e36482f..00788fd2f98 100644&lt;br/&gt;
&amp;#8212; a/streams/src/test/java/org/apache/kafka/test/MockRestoreConsumer.java&lt;br/&gt;
+++ b/streams/src/test/java/org/apache/kafka/test/MockRestoreConsumer.java&lt;br/&gt;
@@ -25,6 +25,7 @@&lt;br/&gt;
 import org.apache.kafka.common.serialization.IntegerSerializer;&lt;br/&gt;
 import org.apache.kafka.common.serialization.Serializer;&lt;/p&gt;

&lt;p&gt;+import java.time.Duration;&lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
 import java.util.Collection;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
@@ -85,9 +86,8 @@ public synchronized void assign(Collection&amp;lt;TopicPartition&amp;gt; partitions) &lt;/p&gt;
{
         super.assign(partitions);
     }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Deprecated&lt;br/&gt;
     @Override&lt;/li&gt;
	&lt;li&gt;public ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; poll(long timeout) {&lt;br/&gt;
+    public ConsumerRecords&amp;lt;byte[], byte[]&amp;gt; poll(final Duration timeout) {&lt;br/&gt;
         // add buffered records to MockConsumer&lt;br/&gt;
         for (ConsumerRecord&amp;lt;byte[], byte[]&amp;gt; record : recordBuffer) {&lt;br/&gt;
             super.addRecord(record);&lt;br/&gt;
diff --git a/streams/test-utils/src/main/java/org/apache/kafka/streams/TopologyTestDriver.java b/streams/test-utils/src/main/java/org/apache/kafka/streams/TopologyTestDriver.java&lt;br/&gt;
index 773cbb4c323..7f752652da4 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/test-utils/src/main/java/org/apache/kafka/streams/TopologyTestDriver.java&lt;br/&gt;
+++ b/streams/test-utils/src/main/java/org/apache/kafka/streams/TopologyTestDriver.java&lt;br/&gt;
@@ -66,6 +66,7 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import java.io.Closeable;&lt;br/&gt;
 import java.io.IOException;&lt;br/&gt;
+import java.time.Duration;&lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
 import java.util.Collection;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
@@ -327,6 +328,7 @@ public void onRestoreEnd(final TopicPartition topicPartition, final String store&lt;br/&gt;
                 consumer,&lt;br/&gt;
                 new StoreChangelogReader(&lt;br/&gt;
                     createRestoreConsumer(processorTopology.storeToChangelogTopic()),&lt;br/&gt;
+                    Duration.ZERO,&lt;br/&gt;
                     stateRestoreListener,&lt;br/&gt;
                     new LogContext(&quot;topology-test-driver &quot;)),&lt;br/&gt;
                 streamsConfig,&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="13164324">KAFKA-7000</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310660">
                    <name>Completes</name>
                                            <outwardlinks description="fixes">
                                        <issuelink>
            <issuekey id="13164369">KAFKA-7004</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13151993">KAFKA-6783</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 23 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3iebb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>