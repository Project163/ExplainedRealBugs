<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:14:00 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6343] OOM as the result of creation of 5k topics</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6343</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;&lt;b&gt;Reproducing&lt;/b&gt;: Create 5k topics &lt;b&gt;from the code&lt;/b&gt; quickly, without any delays. Wait until brokers will finish loading them. This will actually never happen, since all brokers will go down one by one after approx 10-15 minutes or more, depending on the hardware.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Heap&lt;/b&gt;: -Xmx/Xms: 5G, 10G, 50G, 256G, 512G&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Topology&lt;/b&gt;: 3 brokers, 3 zk.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Code for 5k topic creation:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt; kafka
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; kafka.admin.AdminUtils
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; kafka.utils.{Logging, ZkUtils}

object TestCreateTopics &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; App with Logging {

  val zkConnect = &lt;span class=&quot;code-quote&quot;&gt;&quot;grid978:2185&quot;&lt;/span&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt; zkUtils = ZkUtils(zkConnect, 6000, 6000, isZkSecurityEnabled = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)

  &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (topic &amp;lt;- 1 to 5000) {
    AdminUtils.createTopic(
      topic             = s&lt;span class=&quot;code-quote&quot;&gt;&quot;${topic.toString}&quot;&lt;/span&gt;,
      partitions        = 10,
      replicationFactor = 2,
      zkUtils           = zkUtils
    )
    logger.info(s&lt;span class=&quot;code-quote&quot;&gt;&quot;Created topic ${topic.toString}&quot;&lt;/span&gt;)
  }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;b&gt;Cause of death:&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    java.io.IOException: Map failed
        at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:920)
        at kafka.log.AbstractIndex.&amp;lt;init&amp;gt;(AbstractIndex.scala:61)
        at kafka.log.OffsetIndex.&amp;lt;init&amp;gt;(OffsetIndex.scala:52)
        at kafka.log.LogSegment.&amp;lt;init&amp;gt;(LogSegment.scala:67)
        at kafka.log.Log.loadSegments(Log.scala:255)
        at kafka.log.Log.&amp;lt;init&amp;gt;(Log.scala:108)
        at kafka.log.LogManager.createLog(LogManager.scala:362)
        at kafka.cluster.Partition.getOrCreateReplica(Partition.scala:94)
        at kafka.cluster.Partition$$anonfun$4$$anonfun$apply$2.apply(Partition.scala:174)
        at kafka.cluster.Partition$$anonfun$4$$anonfun$apply$2.apply(Partition.scala:174)
        at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
        at kafka.cluster.Partition$$anonfun$4.apply(Partition.scala:174)
        at kafka.cluster.Partition$$anonfun$4.apply(Partition.scala:168)
        at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:234)
        at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:242)
        at kafka.cluster.Partition.makeLeader(Partition.scala:168)
        at kafka.server.ReplicaManager$$anonfun$makeLeaders$4.apply(ReplicaManager.scala:758)
        at kafka.server.ReplicaManager$$anonfun$makeLeaders$4.apply(ReplicaManager.scala:757)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
        at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
        at scala.collection.mutable.HashTable$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreachEntry(HashTable.scala:230)
        at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
        at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
        at kafka.server.ReplicaManager.makeLeaders(ReplicaManager.scala:757)
        at kafka.server.ReplicaManager.becomeLeaderOrFollower(ReplicaManager.scala:703)
        at kafka.server.KafkaApis.handleLeaderAndIsrRequest(KafkaApis.scala:148)
        at kafka.server.KafkaApis.handle(KafkaApis.scala:82)
        at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: java.lang.OutOfMemoryError: Map failed
        at sun.nio.ch.FileChannelImpl.map0(Native Method)
        at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:917)
        ... 28 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;Broker restart results the same OOM issues. All brokers will not be able to start again. &lt;/p&gt;</description>
                <environment>RHEL 7, RAM 755GB per host</environment>
        <key id="13124109">KAFKA-6343</key>
            <summary>OOM as the result of creation of 5k topics</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="alex.dunayevsky">Alex Dunayevsky</assignee>
                                    <reporter username="alex.dunayevsky">Alex Dunayevsky</reporter>
                        <labels>
                    </labels>
                <created>Mon, 11 Dec 2017 11:32:44 +0000</created>
                <updated>Wed, 22 Aug 2018 18:26:15 +0000</updated>
                            <resolved>Wed, 22 Aug 2018 17:15:35 +0000</resolved>
                                    <version>0.10.1.1</version>
                    <version>0.10.2.0</version>
                    <version>0.10.2.1</version>
                    <version>0.11.0.1</version>
                    <version>0.11.0.2</version>
                    <version>1.0.0</version>
                                    <fixVersion>2.1.0</fixVersion>
                                    <component>core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                                                                <comments>
                            <comment id="16285802" author="ijuma" created="Mon, 11 Dec 2017 11:38:19 +0000"  >&lt;p&gt;Looks like you are running out of file handles. So increasing the heap won&apos;t help.&lt;/p&gt;</comment>
                            <comment id="16285817" author="alex.dunayevsky" created="Mon, 11 Dec 2017 11:53:19 +0000"  >&lt;p&gt;Ismael Juma, thank you for the answer. What I currently see is 300000 file handles according to /proc/sys/fs/file-max. Isn&apos;t this enough? If not then, perhaps, is there a way to calculate this somehow? &lt;/p&gt;</comment>
                            <comment id="16285834" author="alex.dunayevsky" created="Mon, 11 Dec 2017 12:22:21 +0000"  >&lt;p&gt;Ismael Juma, we have just reproduced the issue once again while keeping track of open file handles. Here are the results:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;; &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; cat /proc/sys/fs/file-nr; sleep 1; done

3024   0  300000      &amp;lt;--- starting topic creation 
...                               
66192  0  300000      &amp;lt;--- all 5k topics created
...                   &amp;lt;--- broker continues topic loading
98560  0  300000      &amp;lt;--- breaks here, &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; is where broker dies
1568   0  300000      &amp;lt;--- after broker death

Where: the first column stands &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;open file handles&quot;&lt;/span&gt; and the last column (300000) stands &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; total file handles available in the system. 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16285841" author="omkreddy" created="Mon, 11 Dec 2017 12:35:15 +0000"  >&lt;p&gt;Can you post the output of  &quot;ulimit -a&quot;  and  &quot;ps -ef | grep Kafka&quot;  commands?&lt;/p&gt;</comment>
                            <comment id="16285862" author="alex.dunayevsky" created="Mon, 11 Dec 2017 13:02:25 +0000"  >&lt;p&gt;Manikumar, sure&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ ulimit -a
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 3093521
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 256000
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 256000
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited

$ ps -ef | grep Kafka
pprbusr  30147     1 99 15:44 pts/4    00:02:31 java -Xmx512G -Xms512G -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+DisableExplicitGC -Djava.awt.headless=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; -Dcom.sun.management.jmxremote.ssl=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; -Dkafka.logs.dir=/home/pprbusr/kafka/bin/../logs -Dlog4j.configuration=file:/home/pprbusr/kafka/config/log4j.properties -Dcom.sun.management.config.file=/home/pprbusr/kafka/config/jmx/kafka_jmx.properties kafka.Kafka config/server.properties
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16285865" author="ijuma" created="Mon, 11 Dec 2017 13:03:05 +0000"  >&lt;p&gt;Thanks for the additional information. The issue seems similar to &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-1145&quot; title=&quot;Memory mapping with many small blocks can cause JVM allocation failures&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-1145&quot;&gt;&lt;del&gt;SPARK-1145&lt;/del&gt;&lt;/a&gt; where a large number of memory map operations eventually causes the memory map to fail. Maybe you&apos;ve reached the maximum number of memory maps (vm.max_map_count)? See the following for more details:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/43042144/kafka-server-failed-to-start-java-io-ioexception-map-failed&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://stackoverflow.com/questions/43042144/kafka-server-failed-to-start-java-io-ioexception-map-failed&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16285968" author="alex.dunayevsky" created="Mon, 11 Dec 2017 14:19:35 +0000"  >&lt;p&gt;Ismael Juma, once again, thank you! This time it looks like the core problem.&lt;/p&gt;

&lt;p&gt;Reproducing: &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;

&lt;span class=&quot;code-comment&quot;&gt;// Max number of memory map operations is:
&lt;/span&gt;$ /sbin/sysctl vm.max_map_count
vm.max_map_count = 65530

&lt;span class=&quot;code-comment&quot;&gt;// Tracking vm map size:
&lt;/span&gt;$ cat /proc/&amp;lt;KAFKA_PID&amp;gt;/maps | wc -l
898     &amp;lt;--- grows from &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; value
...
65532   &amp;lt;--- up to &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; value (it&apos;s even a bit larger than m.max_map_count=65530). This is the point where broker fails... So you are right!

&lt;span class=&quot;code-comment&quot;&gt;// Then all we have to &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; is to increase vm.max_map size to a larger value (ex., by 65536 * 4):
&lt;/span&gt;$ /sbin/sysctl -w vm.max_map_count=262144

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Ismael, awesome job!&lt;/p&gt;</comment>
                            <comment id="16285985" author="ijuma" created="Mon, 11 Dec 2017 14:33:26 +0000"  >&lt;p&gt;Great! Would you be interested in submitting a PR to add this information to the following documentation section?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://kafka.apache.org/documentation/#os&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://kafka.apache.org/documentation/#os&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16287362" author="alex.dunayevsky" created="Tue, 12 Dec 2017 09:56:16 +0000"  >&lt;p&gt;Ismael Juma, good idea, what should I do? &lt;/p&gt;</comment>
                            <comment id="16287371" author="ijuma" created="Tue, 12 Dec 2017 10:02:16 +0000"  >&lt;p&gt;Update &lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/docs/ops.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/trunk/docs/ops.html&lt;/a&gt; and submit a pull request.&lt;/p&gt;</comment>
                            <comment id="16287435" author="alex.dunayevsky" created="Tue, 12 Dec 2017 10:53:40 +0000"  >&lt;p&gt;Ismael, I mean are there any initial steps or rules to follow before submitting a pull request? &lt;br/&gt;
As it says in /contributing section: &quot;If you are interested in becoming a committer, let one of the existing committers know and they can help guide you through the process&quot;.&lt;/p&gt;</comment>
                            <comment id="16303859" author="githubbot" created="Tue, 26 Dec 2017 13:54:18 +0000"  >&lt;p&gt;rootex- opened a new pull request #4358: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6343&quot; title=&quot;OOM as the result of creation of 5k topics&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6343&quot;&gt;&lt;del&gt;KAFKA-6343&lt;/del&gt;&lt;/a&gt; Documentation update in OS-level tuning section: add vm.ma&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4358&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4358&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Documentation update in OS-level tuning section: add vm.max_map_count bullet point&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;x&amp;#93;&lt;/span&gt; Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16589131" author="githubbot" created="Wed, 22 Aug 2018 17:13:13 +0000"  >&lt;p&gt;junrao closed pull request #4358: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6343&quot; title=&quot;OOM as the result of creation of 5k topics&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6343&quot;&gt;&lt;del&gt;KAFKA-6343&lt;/del&gt;&lt;/a&gt; Documentation update in OS-level tuning section: add vm.ma&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4358&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4358&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/docs/ops.html b/docs/ops.html&lt;br/&gt;
index b9e3a4b32a1..c97d31f978d 100644&lt;br/&gt;
&amp;#8212; a/docs/ops.html&lt;br/&gt;
+++ b/docs/ops.html&lt;br/&gt;
@@ -668,10 +668,11 @@ &amp;lt;h4&amp;gt;&amp;lt;a id=&quot;os&quot; href=&quot;#os&quot;&amp;gt;OS&amp;lt;/a&amp;gt;&amp;lt;/h4&amp;gt;&lt;br/&gt;
   &amp;lt;p&amp;gt;&lt;br/&gt;
   We have seen a few issues running on Windows and Windows is not currently a well supported platform though we would be happy to change that.&lt;br/&gt;
   &amp;lt;p&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;It is unlikely to require much OS-level tuning, but there are two potentially important OS-level configurations:&lt;br/&gt;
+  It is unlikely to require much OS-level tuning, but there are three potentially important OS-level configurations:&lt;br/&gt;
   &amp;lt;ul&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;li&amp;gt;File descriptor limits: Kafka uses file descriptors for log segments and open connections.  If a broker hosts many partitions, consider that the broker needs at least (number_of_partitions)*(partition_size/segment_size) to track all log segments in addition to the number of connections the broker makes.  We recommend at least 100000 allowed file descriptors for the broker processes as a starting point.&lt;br/&gt;
+      &amp;lt;li&amp;gt;File descriptor limits: Kafka uses file descriptors for log segments and open connections.  If a broker hosts many partitions, consider that the broker needs at least (number_of_partitions)*(partition_size/segment_size) to track all log segments in addition to the number of connections the broker makes. We recommend at least 100000 allowed file descriptors for the broker processes as a starting point. Note: The mmap() function adds an extra reference to the file associated with the file descriptor fildes which is not removed by a subsequent close() on that file descriptor. This reference is removed when there are no more mappings to the file.&lt;br/&gt;
       &amp;lt;li&amp;gt;Max socket buffer size: can be increased to enable high-performance data transfer between data centers as &amp;lt;a href=&quot;http://www.psc.edu/index.php/networking/641-tcp-tune&quot;&amp;gt;described here&amp;lt;/a&amp;gt;.&lt;br/&gt;
+      &amp;lt;li&amp;gt;Maximum number of memory map areas a process may have (aka vm.max_map_count). &amp;lt;a href=&quot;http://kernel.org/doc/Documentation/sysctl/vm.txt&quot;&amp;gt;See the Linux kernel documentation&amp;lt;/a&amp;gt;. You should keep an eye at this OS-level property when considering the maximum number of partitions a broker may have. By default, on a number of Linux systems, the value of vm.max_map_count is somewhere around 65535. Each log segment, allocated per partition, requires a pair of index/timeindex files, and each of these files consumes 1 map area. In other words, each log segment uses 2 map areas. Thus, each partition requires minimum 2 map areas, as long as it hosts a single log segment. That is to say, creating 50000 partitions on a broker will result allocation of 100000 map areas and likely cause broker crash with OutOfMemoryError (Map failed) on a system with default vm.max_map_count. Keep in mind that the number of log segments per partition varies depending on the segment size, load intensity, retention policy and, generally, tends to be more than one.&lt;br/&gt;
   &amp;lt;/ul&amp;gt;&lt;br/&gt;
   &amp;lt;p&amp;gt;&lt;/li&gt;
&lt;/ul&gt;






&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16589138" author="junrao" created="Wed, 22 Aug 2018 17:15:35 +0000"  >&lt;p&gt;Merged the PR to trunk.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13176817">KAFKA-7244</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 12 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3nre7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>