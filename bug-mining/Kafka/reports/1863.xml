<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:08:37 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6710] Streams integration tests hang during shutdown</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6710</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Builds have been timing out a lot recently and many of the logs show streams integration tests being run, but not completed. While running tests locally, I saw a failure during shutdown of &lt;tt&gt;TableTableJoinIntegrationTest&lt;/tt&gt;. The test was stuck waiting for a broker to shutdown when a &lt;tt&gt;KafkaScheduler&lt;/tt&gt; was attemping to delete logs. &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6624&quot; title=&quot;log segment deletion could cause a disk to be marked offline incorrectly&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6624&quot;&gt;&lt;del&gt;KAFKA-6624&lt;/del&gt;&lt;/a&gt; (Commit #1ea07b993d75ed68f4c04282eb177bf84156e0b2) added a &lt;em&gt;Thread.sleep&lt;/em&gt; to wait for the time to delete each log segment inside the scheduled delete task. The failing streams test had 62 logs to delete and since MockTime doesn&apos;t get updated during the test, it would have waited for 62 minutes to complete. This blocks shutdown of the broker for 62 minutes. This is an issue if a streams integration test takes more than 30 seconds when the first delayed delete task is scheduled to be run.&lt;/p&gt;

&lt;p&gt;Changing &lt;em&gt;Thread.sleep&lt;/em&gt; to &lt;em&gt;time.sleep&lt;/em&gt; fixes this test issue. But it will be good to know why we have a &lt;em&gt;sleep&lt;/em&gt; on a &lt;em&gt;Scheduler&lt;/em&gt; at all. With the default &lt;em&gt;log.segment.delete.delay.ms&lt;/em&gt; of one minute, this potentially blocks a scheduler thread for upto a minute when there are logs to be deleted. Couldn&apos;t we just break out of the loop if it is not yet time to delete the first log segment in the list? The log would then get deleted when the broker checks next time. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lindong&quot; class=&quot;user-hover&quot; rel=&quot;lindong&quot;&gt;lindong&lt;/a&gt; ?&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Stack trace from failing test&lt;/b&gt;:&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;&quot;kafka-scheduler-8&quot; daemon prio=5 tid=0x00007fe58dc16800 nid=0x9603 waiting on condition &lt;span class=&quot;error&quot;&gt;&amp;#91;0x0000700003f25000&amp;#93;&lt;/span&gt;&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160; java.lang.Thread.State: TIMED_WAITING (sleeping)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at java.lang.Thread.sleep(Native Method)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at kafka.log.LogManager.kafka$log$LogManager$$deleteLogs(LogManager.scala:717)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at kafka.log.LogManager$$anonfun$3.apply$mcV$sp(LogManager.scala:406)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:62)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at java.util.concurrent.FutureTask.run(FutureTask.java:262)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at java.lang.Thread.run(Thread.java:745)&lt;/tt&gt;{{}}&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;}}{{&quot;Test worker&quot; prio=5 tid=0x00007fe58db72000 nid=0x5203 waiting on condition &lt;span class=&quot;error&quot;&gt;&amp;#91;0x0000700001cbd000&amp;#93;&lt;/span&gt;&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160; java.lang.Thread.State: TIMED_WAITING (parking)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at sun.misc.Unsafe.park(Native Method)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; - parking to wait for&#160; &amp;lt;0x0000000780fb8918&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1468)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at kafka.utils.KafkaScheduler.shutdown(KafkaScheduler.scala:98)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at kafka.server.KafkaServer$$anonfun$shutdown$5.apply$mcV$sp(KafkaServer.scala:569)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:85)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at kafka.server.KafkaServer.shutdown(KafkaServer.scala:569)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.kafka.streams.integration.utils.KafkaEmbedded.stop(KafkaEmbedded.java:129)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster.stop(EmbeddedKafkaCluster.java:126)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster.after(EmbeddedKafkaCluster.java:158)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:50)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.junit.rules.RunRules.evaluate(RunRules.java:20)&lt;/tt&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13147718">KAFKA-6710</key>
            <summary>Streams integration tests hang during shutdown</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rsivaram">Rajini Sivaram</assignee>
                                    <reporter username="rsivaram">Rajini Sivaram</reporter>
                        <labels>
                    </labels>
                <created>Sat, 24 Mar 2018 15:28:38 +0000</created>
                <updated>Wed, 25 Apr 2018 09:42:28 +0000</updated>
                            <resolved>Sat, 24 Mar 2018 21:12:05 +0000</resolved>
                                    <version>1.1.0</version>
                                    <fixVersion>2.0.0</fixVersion>
                                    <component>core</component>
                    <component>streams</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16412663" author="githubbot" created="Sat, 24 Mar 2018 15:39:29 +0000"  >&lt;p&gt;rajinisivaram opened a new pull request #4771: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6710&quot; title=&quot;Streams integration tests hang during shutdown&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6710&quot;&gt;&lt;del&gt;KAFKA-6710&lt;/del&gt;&lt;/a&gt;: Remove Thread.sleep from LogManager.deleteLogs&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4771&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4771&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   `Thread.sleep` in `LogManager.deleteLogs` potentially blocks a scheduler thread for up to `log.segment.delete.delay.ms` with a default value of a minute. This PR skips delete when the first log is not yet ready to be deleted, freeing the scheduler thread. Logs are then deleted on the next delete iteration.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16412790" author="githubbot" created="Sat, 24 Mar 2018 20:54:12 +0000"  >&lt;p&gt;rajinisivaram closed pull request #4771: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6710&quot; title=&quot;Streams integration tests hang during shutdown&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6710&quot;&gt;&lt;del&gt;KAFKA-6710&lt;/del&gt;&lt;/a&gt;: Remove Thread.sleep from LogManager.deleteLogs&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4771&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4771&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/core/src/main/scala/kafka/log/LogManager.scala b/core/src/main/scala/kafka/log/LogManager.scala&lt;br/&gt;
index 7aa5bcd88d8..f26a84c6244 100755&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/log/LogManager.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/log/LogManager.scala&lt;br/&gt;
@@ -79,13 +79,15 @@ class LogManager(logDirs: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;File&amp;#93;&lt;/span&gt;,&lt;br/&gt;
   private val logsToBeDeleted = new LinkedBlockingQueue&lt;span class=&quot;error&quot;&gt;&amp;#91;(Log, Long)&amp;#93;&lt;/span&gt;()&lt;/p&gt;

&lt;p&gt;   private val _liveLogDirs: ConcurrentLinkedQueue&lt;span class=&quot;error&quot;&gt;&amp;#91;File&amp;#93;&lt;/span&gt; = createAndValidateLogDirs(logDirs, initialOfflineDirs)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@volatile var currentDefaultConfig = initialDefaultConfig&lt;br/&gt;
+  @volatile private var _currentDefaultConfig = initialDefaultConfig&lt;br/&gt;
   @volatile private var numRecoveryThreadsPerDataDir = recoveryThreadsPerDataDir&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def reconfigureDefaultLogConfig(logConfig: LogConfig): Unit = &lt;/p&gt;
{
-    this.currentDefaultConfig = logConfig
+    this._currentDefaultConfig = logConfig
   }

&lt;p&gt;+  def currentDefaultConfig: LogConfig = _currentDefaultConfig&lt;br/&gt;
+&lt;br/&gt;
   def liveLogDirs: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;File&amp;#93;&lt;/span&gt; = &lt;/p&gt;
{
     if (_liveLogDirs.size == logDirs.size)
       logDirs
@@ -245,6 +247,9 @@ class LogManager(logDirs: Seq[File],
     this.logsToBeDeleted.add((log, time.milliseconds()))
   }

&lt;p&gt;+  // Only for testing&lt;br/&gt;
+  private&lt;span class=&quot;error&quot;&gt;&amp;#91;log&amp;#93;&lt;/span&gt; def hasLogsToBeDeleted: Boolean = !logsToBeDeleted.isEmpty&lt;br/&gt;
+&lt;br/&gt;
   private def loadLog(logDir: File, recoveryPoints: Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, Long&amp;#93;&lt;/span&gt;, logStartOffsets: Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, Long&amp;#93;&lt;/span&gt;): Unit = &lt;/p&gt;
{
     debug(&quot;Loading log &apos;&quot; + logDir.getName + &quot;&apos;&quot;)
     val topicPartition = Log.parseTopicPartitionName(logDir)
@@ -704,17 +709,27 @@ class LogManager(logDirs: Seq[File],
   }

&lt;p&gt;   /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;*  Delete logs marked for deletion.&lt;br/&gt;
+   *  Delete logs marked for deletion. Delete all logs for which `currentDefaultConfig.fileDeleteDelayMs`&lt;br/&gt;
+   *  has elapsed after the delete was scheduled. Logs for which this interval has not yet elapsed will be&lt;br/&gt;
+   *  considered for deletion in the next iteration of `deleteLogs`. The next iteration will be executed&lt;br/&gt;
+   *  after the remaining time for the first log that is not deleted. If there are no more `logsToBeDeleted`,&lt;br/&gt;
+   *  `deleteLogs` will be executed after `currentDefaultConfig.fileDeleteDelayMs`.&lt;br/&gt;
    */&lt;br/&gt;
   private def deleteLogs(): Unit = {&lt;br/&gt;
+    var nextDelayMs = 0L&lt;br/&gt;
     try {&lt;/li&gt;
	&lt;li&gt;while (!logsToBeDeleted.isEmpty) {&lt;/li&gt;
	&lt;li&gt;val (removedLog, scheduleTimeMs) = logsToBeDeleted.take()&lt;br/&gt;
+      def nextDeleteDelayMs: Long = 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+        if (!logsToBeDeleted.isEmpty) {
+          val (_, scheduleTimeMs) = logsToBeDeleted.peek()
+          scheduleTimeMs + currentDefaultConfig.fileDeleteDelayMs - time.milliseconds()
+        } else+          currentDefaultConfig.fileDeleteDelayMs+      }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;+&lt;br/&gt;
+      while (&lt;/p&gt;
{nextDelayMs = nextDeleteDelayMs; nextDelayMs &amp;lt;= 0}
&lt;p&gt;) {&lt;br/&gt;
+        val (removedLog, _) = logsToBeDeleted.take()&lt;br/&gt;
         if (removedLog != null) {&lt;br/&gt;
           try {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;val waitingTimeMs = scheduleTimeMs + currentDefaultConfig.fileDeleteDelayMs - time.milliseconds()&lt;/li&gt;
	&lt;li&gt;if (waitingTimeMs &amp;gt; 0)&lt;/li&gt;
	&lt;li&gt;Thread.sleep(waitingTimeMs)&lt;br/&gt;
             removedLog.delete()&lt;br/&gt;
             info(s&quot;Deleted log for partition ${removedLog.topicPartition} in ${removedLog.dir.getAbsolutePath}.&quot;)&lt;br/&gt;
           } catch {&lt;br/&gt;
@@ -730,7 +745,7 @@ class LogManager(logDirs: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;File&amp;#93;&lt;/span&gt;,&lt;br/&gt;
       try 
{
         scheduler.schedule(&quot;kafka-delete-logs&quot;,
           deleteLogs _,
-          delay = currentDefaultConfig.fileDeleteDelayMs,
+          delay = nextDelayMs,
           unit = TimeUnit.MILLISECONDS)
       }
&lt;p&gt; catch {&lt;br/&gt;
         case e: Throwable =&amp;gt;&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/log/LogManagerTest.scala b/core/src/test/scala/unit/kafka/log/LogManagerTest.scala&lt;br/&gt;
index 2fdda6b8827..d9efc236780 100755&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/test/scala/unit/kafka/log/LogManagerTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/log/LogManagerTest.scala&lt;br/&gt;
@@ -332,5 +332,10 @@ class LogManagerTest 
{
       assertNotEquals(&quot;File reference was not updated in index&quot;, fileBeforeDelete.getAbsolutePath,
         fileInIndex.get.getAbsolutePath)
     }
&lt;p&gt;+&lt;br/&gt;
+    time.sleep(logManager.InitialTaskDelayMs)&lt;br/&gt;
+    assertTrue(&quot;Logs deleted too early&quot;, logManager.hasLogsToBeDeleted)&lt;br/&gt;
+    time.sleep(logManager.currentDefaultConfig.fileDeleteDelayMs - logManager.InitialTaskDelayMs)&lt;br/&gt;
+    assertFalse(&quot;Logs not deleted&quot;, logManager.hasLogsToBeDeleted)&lt;br/&gt;
   }&lt;br/&gt;
 }&lt;/p&gt;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 34 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3rqv3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>junrao</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>