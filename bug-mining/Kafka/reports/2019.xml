<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:13:58 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-5891] Cast transformation fails if record schema contains timestamp field</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-5891</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;I have the following simple type cast transformation:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;name=postgresql-source-simple
connector.class=io.confluent.connect.jdbc.JdbcSourceConnector
tasks.max=1

connection.url=jdbc:postgresql:&lt;span class=&quot;code-comment&quot;&gt;//localhost:5432/testdb?user=postgres&amp;amp;password=mysecretpassword
&lt;/span&gt;query=SELECT 1::INT as a, &lt;span class=&quot;code-quote&quot;&gt;&apos;2017-09-14 10:23:54&apos;&lt;/span&gt;::TIMESTAMP as b

transforms=Cast
transforms.Cast.type=org.apache.kafka.connect.transforms.Cast$Value
transforms.Cast.spec=a:&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;

mode=bulk
topic.prefix=clients
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Which fails with the following exception in runtime:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[2017-09-14 16:51:01,885] ERROR Task postgresql-source-simple-0 threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:148)
org.apache.kafka.connect.errors.DataException: Invalid Java object &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; schema type INT64: &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.sql.Timestamp &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; field: &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;&quot;&lt;/span&gt;
	at org.apache.kafka.connect.data.ConnectSchema.validateValue(ConnectSchema.java:239)
	at org.apache.kafka.connect.data.ConnectSchema.validateValue(ConnectSchema.java:209)
	at org.apache.kafka.connect.data.Struct.put(Struct.java:214)
	at org.apache.kafka.connect.transforms.Cast.applyWithSchema(Cast.java:152)
	at org.apache.kafka.connect.transforms.Cast.apply(Cast.java:108)
	at org.apache.kafka.connect.runtime.TransformationChain.apply(TransformationChain.java:38)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.sendRecords(WorkerSourceTask.java:190)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.execute(WorkerSourceTask.java:168)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:146)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:190)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If I remove the  transforms.* part of the connector it will work correctly. Actually, it doesn&apos;t really matter which types I use in the transformation for field &apos;a&apos;, just the existence of a timestamp field brings the exception.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13102268">KAFKA-5891</key>
            <summary>Cast transformation fails if record schema contains timestamp field</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="maver1ck">Maciej Bry&#324;ski</assignee>
                                    <reporter username="broartem">Artem Plotnikov</reporter>
                        <labels>
                    </labels>
                <created>Thu, 14 Sep 2017 14:14:44 +0000</created>
                <updated>Wed, 31 Oct 2018 09:02:37 +0000</updated>
                            <resolved>Mon, 20 Aug 2018 23:50:14 +0000</resolved>
                                    <version>0.11.0.0</version>
                                    <fixVersion>1.0.3</fixVersion>
                    <fixVersion>1.1.2</fixVersion>
                    <fixVersion>2.0.1</fixVersion>
                                    <component>connect</component>
                        <due></due>
                            <votes>3</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="16167493" author="broartem" created="Fri, 15 Sep 2017 07:58:52 +0000"  >&lt;p&gt;Seems like Kafka Connect&apos;s Cast transformation loses schema information (basically, schema name) while doing type casting. I was able to reproduce this problem with the following test in org.apache.kafka.connect.transforms.CastTest for current trunk repository branch:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;@SuppressWarnings(&lt;span class=&quot;code-quote&quot;&gt;&quot;unchecked&quot;&lt;/span&gt;)
@Test
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void castWholeRecordValueWithSchemaBooleanAndTimestampField() {
    &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Cast&amp;lt;SourceRecord&amp;gt; xform = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Cast.Value&amp;lt;&amp;gt;();
    xform.configure(Collections.singletonMap(Cast.SPEC_CONFIG, &lt;span class=&quot;code-quote&quot;&gt;&quot;int64:&lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;&quot;&lt;/span&gt;));

    SchemaBuilder builder = SchemaBuilder.struct();
    builder.field(&lt;span class=&quot;code-quote&quot;&gt;&quot;int64&quot;&lt;/span&gt;, Schema.INT64_SCHEMA);
    builder.field(&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;, Timestamp.SCHEMA);
    Schema supportedTypesSchema = builder.build();

    Struct recordValue = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Struct(supportedTypesSchema);
    recordValue.put(&lt;span class=&quot;code-quote&quot;&gt;&quot;int64&quot;&lt;/span&gt;, (&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;) 64);
    recordValue.put(&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; java.sql.Timestamp(0L));

    SourceRecord transformed = xform.apply(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SourceRecord(&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;topic&quot;&lt;/span&gt;, 0,
            supportedTypesSchema, recordValue));

    assertEquals(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, ((Struct) transformed.value()).get(&lt;span class=&quot;code-quote&quot;&gt;&quot;int64&quot;&lt;/span&gt;));
    assertEquals(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; java.sql.Timestamp(0L), ((Struct) transformed.value()).get(&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;));
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The problem is that Timestamp.SCHEMA has schema.type = &apos;INT64&apos; and schema.name = &quot;org.apache.kafka.connect.data.Timestamp&quot;, but org.apache.kafka.connect.transforms.Cast#getOrBuildSchema method copies schema.type only:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;SchemaBuilder fieldBuilder =
    convertFieldType(casts.containsKey(field.name()) ? casts.get(field.name()) : field.schema().type());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16254822" author="srpradhan" created="Thu, 16 Nov 2017 06:33:53 +0000"  >&lt;p&gt;I am facing same issue when consuming from KAFKA to HDFS with CAST TRANSFORMS. Any pointer please.&lt;/p&gt;

&lt;p&gt;My Connector :&lt;br/&gt;
*********************&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
{
 &lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;hdfs-sink-avro-&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;-test-stndln&quot;&lt;/span&gt;,
 &lt;span class=&quot;code-quote&quot;&gt;&quot;config&quot;&lt;/span&gt;: {
  &lt;span class=&quot;code-quote&quot;&gt;&quot;key.converter&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;io.confluent.connect.avro.AvroConverter&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;key.converter.schema.registry.url&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;http:&lt;span class=&quot;code-comment&quot;&gt;//localhost:8081&quot;&lt;/span&gt;,
&lt;/span&gt;  &lt;span class=&quot;code-quote&quot;&gt;&quot;value.converter&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;io.confluent.connect.avro.AvroConverter&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;value.converter.schema.registry.url&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;http:&lt;span class=&quot;code-comment&quot;&gt;//localhost:8081&quot;&lt;/span&gt;,
&lt;/span&gt;  &lt;span class=&quot;code-quote&quot;&gt;&quot;key.converter.schemas.enable&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;value.converter.schemas.enable&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;internal.key.converter&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.kafka.connect.json.JsonConverter&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;internal.value.converter&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.kafka.connect.json.JsonConverter&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;internal.key.converter.schemas.enable&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;internal.value.converter.schemas.enable&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;offset.storage.file.filename&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/connect.offsets.avroHdfsConsumer.casttest.stndln&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;offset.flush.interval.ms&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;500&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;parse.key&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;connector.class&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;io.confluent.connect.hdfs.HdfsSinkConnector&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;hadoop.home&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;/usr/lib/hadoop&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;hdfs.url&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;hdfs:&lt;span class=&quot;code-comment&quot;&gt;//ip-127-34-56-789.us-east-1.compute.interna:8020&quot;&lt;/span&gt;,
&lt;/span&gt;  &lt;span class=&quot;code-quote&quot;&gt;&quot;topics&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;avro_raw_KFK_SRP_USER_TEST_V,avro_raw_KFK_SRP_PG_HITS_TEST_V&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;tasks.max&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;1&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;topics.dir&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;/home/hadoop/kafka/data/streams/in/raw/casttest1&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;logs.dir&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;/home/hadoop/kafka/wal/streams/in/raw/casttest1&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;hive.integration&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;hive.metastore.uris&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;thrift:&lt;span class=&quot;code-comment&quot;&gt;//ip-127-34-56-789.us-east-1.compute.internal:9083&quot;&lt;/span&gt;,
&lt;/span&gt;  &lt;span class=&quot;code-quote&quot;&gt;&quot;schema.compatibility&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;BACKWARD&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;flush.size&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;10000&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;rotate.interval.ms&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;1000&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;mode&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;transforms&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;Cast&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;transforms.Cast.type&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.kafka.connect.transforms.Cast$Value&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;transforms.Cast.spec&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;residuals:float64,comp:float64&quot;&lt;/span&gt;
 }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[2017-11-16 01:14:39,719] ERROR Task hdfs-sink-avro-&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;-test-stndln-0 threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:148)
org.apache.kafka.connect.errors.DataException: Invalid Java object &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; schema type INT64: &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.util.Date &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; field: &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;&quot;&lt;/span&gt;
        at org.apache.kafka.connect.data.ConnectSchema.validateValue(ConnectSchema.java:239)
        at org.apache.kafka.connect.data.ConnectSchema.validateValue(ConnectSchema.java:209)
        at org.apache.kafka.connect.data.Struct.put(Struct.java:214)
        at org.apache.kafka.connect.transforms.Cast.applyWithSchema(Cast.java:152)
        at org.apache.kafka.connect.transforms.Cast.apply(Cast.java:108)
        at org.apache.kafka.connect.runtime.TransformationChain.apply(TransformationChain.java:38)
        at org.apache.kafka.connect.runtime.WorkerSinkTask.convertMessages(WorkerSinkTask.java:414)
        at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:250)
        at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:180)
        at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:148)
        at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:146)
        at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:190)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
[2017-11-16 01:14:39,719] ERROR Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:149)
[2017-11-16 01:14:39,719] INFO Shutting down Hive executor service. (io.confluent.connect.hdfs.DataWriter:309)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16382629" author="githubbot" created="Thu, 1 Mar 2018 20:55:54 +0000"  >&lt;p&gt;maver1ck opened a new pull request #4633: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5891&quot; title=&quot;Cast transformation fails if record schema contains timestamp field&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5891&quot;&gt;&lt;del&gt;KAFKA-5891&lt;/del&gt;&lt;/a&gt; Proper handling of LogicalTypes in Cast&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4633&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4633&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Currently logical types are dropped during Cast Transformation.&lt;br/&gt;
   This patch fixes this behaviour.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;X&amp;#93;&lt;/span&gt; Verify design and implementation&lt;/li&gt;
	&lt;li&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;X&amp;#93;&lt;/span&gt; Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;X&amp;#93;&lt;/span&gt; Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16383227" author="maver1ck" created="Fri, 2 Mar 2018 06:15:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=broartem&quot; class=&quot;user-hover&quot; rel=&quot;broartem&quot;&gt;broartem&lt;/a&gt;&lt;br/&gt;
Could you test my patch ?&lt;/p&gt;</comment>
                            <comment id="16406667" author="rhauch" created="Tue, 20 Mar 2018 16:45:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6290&quot; title=&quot;Kafka Connect cast transformation should support logical types&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6290&quot;&gt;&lt;del&gt;KAFKA-6290&lt;/del&gt;&lt;/a&gt; is another issue related to the CAST transformation, but deals with actually being able to CAST fields that use logical types.&lt;/p&gt;

&lt;p&gt;This issue, OTOH, is simply that the record&apos;s Struct can only contain fields that have a castable (i.e., currently primitive) type.&lt;/p&gt;</comment>
                            <comment id="16586573" author="githubbot" created="Mon, 20 Aug 2018 21:56:43 +0000"  >&lt;p&gt;rayokota opened a new pull request #5537: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5891&quot; title=&quot;Cast transformation fails if record schema contains timestamp field&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5891&quot;&gt;&lt;del&gt;KAFKA-5891&lt;/del&gt;&lt;/a&gt;: Adapts #4633 with schema tests&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5537&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5537&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   This adapts PR #4633 from @maver1ck with suggested unit test from @rhauch&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16586665" author="githubbot" created="Mon, 20 Aug 2018 23:43:14 +0000"  >&lt;p&gt;hachikuji closed pull request #4633: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5891&quot; title=&quot;Cast transformation fails if record schema contains timestamp field&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5891&quot;&gt;&lt;del&gt;KAFKA-5891&lt;/del&gt;&lt;/a&gt;: Proper handling of LogicalTypes in Cast&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4633&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4633&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/connect/transforms/src/main/java/org/apache/kafka/connect/transforms/Cast.java b/connect/transforms/src/main/java/org/apache/kafka/connect/transforms/Cast.java&lt;br/&gt;
index d94f8f648b3..22b19722c47 100644&lt;br/&gt;
&amp;#8212; a/connect/transforms/src/main/java/org/apache/kafka/connect/transforms/Cast.java&lt;br/&gt;
+++ b/connect/transforms/src/main/java/org/apache/kafka/connect/transforms/Cast.java&lt;br/&gt;
@@ -164,13 +164,17 @@ private Schema getOrBuildSchema(Schema valueSchema) {&lt;br/&gt;
         } else {&lt;br/&gt;
             builder = SchemaUtil.copySchemaBasics(valueSchema, SchemaBuilder.struct());&lt;br/&gt;
             for (Field field : valueSchema.fields()) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;SchemaBuilder fieldBuilder =&lt;/li&gt;
	&lt;li&gt;convertFieldType(casts.containsKey(field.name()) ? casts.get(field.name()) : field.schema().type());&lt;/li&gt;
	&lt;li&gt;if (field.schema().isOptional())&lt;/li&gt;
	&lt;li&gt;fieldBuilder.optional();&lt;/li&gt;
	&lt;li&gt;if (field.schema().defaultValue() != null)&lt;/li&gt;
	&lt;li&gt;fieldBuilder.defaultValue(castValueToType(field.schema().defaultValue(), fieldBuilder.type()));&lt;/li&gt;
	&lt;li&gt;builder.field(field.name(), fieldBuilder.build());&lt;br/&gt;
+                if (casts.containsKey(field.name())) 
{
+                    SchemaBuilder fieldBuilder = convertFieldType(casts.get(field.name()));
+                    if (field.schema().isOptional())
+                        fieldBuilder.optional();
+                    if (field.schema().defaultValue() != null)
+                        fieldBuilder.defaultValue(castValueToType(field.schema().defaultValue(), fieldBuilder.type()));
+                    builder.field(field.name(), fieldBuilder.build());
+                }
&lt;p&gt; else &lt;/p&gt;
{
+                    builder.field(field.name(), field.schema());
+                }
&lt;p&gt;+&lt;br/&gt;
             }&lt;br/&gt;
         }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;diff --git a/connect/transforms/src/test/java/org/apache/kafka/connect/transforms/CastTest.java b/connect/transforms/src/test/java/org/apache/kafka/connect/transforms/CastTest.java&lt;br/&gt;
index b190189b35d..decd043b1db 100644&lt;br/&gt;
&amp;#8212; a/connect/transforms/src/test/java/org/apache/kafka/connect/transforms/CastTest.java&lt;br/&gt;
+++ b/connect/transforms/src/test/java/org/apache/kafka/connect/transforms/CastTest.java&lt;br/&gt;
@@ -21,12 +21,14 @@&lt;br/&gt;
 import org.apache.kafka.connect.data.Schema;&lt;br/&gt;
 import org.apache.kafka.connect.data.SchemaBuilder;&lt;br/&gt;
 import org.apache.kafka.connect.data.Struct;&lt;br/&gt;
+import org.apache.kafka.connect.data.Timestamp;&lt;br/&gt;
 import org.apache.kafka.connect.errors.DataException;&lt;br/&gt;
 import org.apache.kafka.connect.source.SourceRecord;&lt;br/&gt;
 import org.junit.After;&lt;br/&gt;
 import org.junit.Test;&lt;/p&gt;

&lt;p&gt; import java.util.Collections;&lt;br/&gt;
+import java.util.Date;&lt;br/&gt;
 import java.util.HashMap;&lt;br/&gt;
 import java.util.Map;&lt;/p&gt;

&lt;p&gt;@@ -304,6 +306,7 @@ public void castFieldsWithSchema() {&lt;br/&gt;
         builder.field(&quot;boolean&quot;, Schema.BOOLEAN_SCHEMA);&lt;br/&gt;
         builder.field(&quot;string&quot;, Schema.STRING_SCHEMA);&lt;br/&gt;
         builder.field(&quot;optional&quot;, Schema.OPTIONAL_FLOAT32_SCHEMA);&lt;br/&gt;
+        builder.field(&quot;timestamp&quot;, Timestamp.SCHEMA);&lt;br/&gt;
         Schema supportedTypesSchema = builder.build();&lt;/p&gt;

&lt;p&gt;         Struct recordValue = new Struct(supportedTypesSchema);&lt;br/&gt;
@@ -315,6 +318,7 @@ public void castFieldsWithSchema() {&lt;br/&gt;
         recordValue.put(&quot;float64&quot;, -64.);&lt;br/&gt;
         recordValue.put(&quot;boolean&quot;, true);&lt;br/&gt;
         recordValue.put(&quot;string&quot;, &quot;42&quot;);&lt;br/&gt;
+        recordValue.put(&quot;timestamp&quot;, new Date(0));&lt;br/&gt;
         // optional field intentionally omitted&lt;/p&gt;

&lt;p&gt;         SourceRecord transformed = xformValue.apply(new SourceRecord(null, null, &quot;topic&quot;, 0,&lt;br/&gt;
@@ -331,6 +335,7 @@ public void castFieldsWithSchema() &lt;/p&gt;
{
         assertEquals(true, ((Struct) transformed.value()).schema().field(&quot;float64&quot;).schema().defaultValue());
         assertEquals((byte) 1, ((Struct) transformed.value()).get(&quot;boolean&quot;));
         assertEquals(42, ((Struct) transformed.value()).get(&quot;string&quot;));
+        assertEquals(new Date(0), ((Struct) transformed.value()).get(&quot;timestamp&quot;));
         assertNull(((Struct) transformed.value()).get(&quot;optional&quot;));
     }





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16587583" author="githubbot" created="Tue, 21 Aug 2018 15:21:49 +0000"  >&lt;p&gt;hachikuji closed pull request #5537: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5891&quot; title=&quot;Cast transformation fails if record schema contains timestamp field&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5891&quot;&gt;&lt;del&gt;KAFKA-5891&lt;/del&gt;&lt;/a&gt;: Adapts #4633 with schema tests&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5537&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5537&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/connect/transforms/src/main/java/org/apache/kafka/connect/transforms/Cast.java b/connect/transforms/src/main/java/org/apache/kafka/connect/transforms/Cast.java&lt;br/&gt;
index 22b19722c47..a593c7b3934 100644&lt;br/&gt;
&amp;#8212; a/connect/transforms/src/main/java/org/apache/kafka/connect/transforms/Cast.java&lt;br/&gt;
+++ b/connect/transforms/src/main/java/org/apache/kafka/connect/transforms/Cast.java&lt;br/&gt;
@@ -174,7 +174,6 @@ private Schema getOrBuildSchema(Schema valueSchema) {&lt;br/&gt;
                 } else &lt;/p&gt;
{
                     builder.field(field.name(), field.schema());
                 }
&lt;p&gt;-&lt;br/&gt;
             }&lt;br/&gt;
         }&lt;/p&gt;

&lt;p&gt;diff --git a/connect/transforms/src/test/java/org/apache/kafka/connect/transforms/CastTest.java b/connect/transforms/src/test/java/org/apache/kafka/connect/transforms/CastTest.java&lt;br/&gt;
index decd043b1db..06fbe311c16 100644&lt;br/&gt;
&amp;#8212; a/connect/transforms/src/test/java/org/apache/kafka/connect/transforms/CastTest.java&lt;br/&gt;
+++ b/connect/transforms/src/test/java/org/apache/kafka/connect/transforms/CastTest.java&lt;br/&gt;
@@ -337,6 +337,19 @@ public void castFieldsWithSchema() &lt;/p&gt;
{
         assertEquals(42, ((Struct) transformed.value()).get(&quot;string&quot;));
         assertEquals(new Date(0), ((Struct) transformed.value()).get(&quot;timestamp&quot;));
         assertNull(((Struct) transformed.value()).get(&quot;optional&quot;));
+
+        Schema transformedSchema = ((Struct) transformed.value()).schema();
+        assertEquals(Schema.INT16_SCHEMA.type(), transformedSchema.field(&quot;int8&quot;).schema().type());
+        assertEquals(Schema.OPTIONAL_INT32_SCHEMA.type(), transformedSchema.field(&quot;int16&quot;).schema().type());
+        assertEquals(Schema.INT64_SCHEMA.type(), transformedSchema.field(&quot;int32&quot;).schema().type());
+        assertEquals(Schema.BOOLEAN_SCHEMA.type(), transformedSchema.field(&quot;int64&quot;).schema().type());
+        assertEquals(Schema.FLOAT64_SCHEMA.type(), transformedSchema.field(&quot;float32&quot;).schema().type());
+        assertEquals(Schema.BOOLEAN_SCHEMA.type(), transformedSchema.field(&quot;float64&quot;).schema().type());
+        assertEquals(Schema.INT8_SCHEMA.type(), transformedSchema.field(&quot;boolean&quot;).schema().type());
+        assertEquals(Schema.INT32_SCHEMA.type(), transformedSchema.field(&quot;string&quot;).schema().type());
+        assertEquals(Schema.OPTIONAL_INT32_SCHEMA.type(), transformedSchema.field(&quot;optional&quot;).schema().type());
+        // The following fields are not changed
+        assertEquals(Timestamp.SCHEMA.type(), transformedSchema.field(&quot;timestamp&quot;).schema().type());
     }

&lt;p&gt;     @SuppressWarnings(&quot;unchecked&quot;)&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13122107">KAFKA-6290</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 13 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3k2jz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>