<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:25:52 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-10455] Probing rebalances are not guaranteed to be triggered by non-leader members</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-10455</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Apparently, if a consumer rejoins the group with the same subscription userdata that it previously sent, it will not trigger a rebalance. The one exception here is that the group leader will always trigger a rebalance when it rejoins the group.&lt;/p&gt;

&lt;p&gt;This has implications for KIP-441, where we rely on asking an arbitrary thread to enforce the followup probing rebalances. Technically we do ask a thread living on the same instance as the leader, so the odds that the leader will be chosen aren&apos;t completely abysmal, but for any multithreaded application they are still at best only 50%.&lt;/p&gt;

&lt;p&gt;Of course in general the userdata will have changed within a span of 10 minutes, so the actual likelihood of hitting this is much lower &#8211;&#160;&#160;it can only happen if the member&apos;s task offset sums remained unchanged. Realistically, this probably requires that the member only have fully-restored active tasks (encoded with the constant sentinel -2) and that no tasks be added or removed.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;One solution would be to make sure the leader is responsible for the probing rebalance. To do this, we would need to somehow expose the memberId of the thread&apos;s main consumer to the partition assignor. I&apos;m actually not sure if that&apos;s currently possible to figure out or not. If not, we could just assign the probing rebalance to every thread on the leader&apos;s instance. This shouldn&apos;t result in multiple followup rebalances as the rebalance schedule will be updated/reset on the first followup rebalance.&lt;/p&gt;

&lt;p&gt;Another solution would be to make sure the userdata is always different. We could encode an extra bit that flip-flops, but then we&apos;d have to persist the latest value somewhere/somehow. Alternatively we could just encode the next probing rebalance time in the subscription userdata, since that is guaranteed to always be different from the previous rebalance. This might get tricky though, and certainly wastes space in the subscription userdata. Also, this would only solve the problem for KIP-441 probing rebalances, meaning we&apos;d have to individually ensure the userdata has changed for every type of followup rebalance (see related issue below). So the first proposal, requiring the leader trigger the rebalance, would be preferable.&lt;/p&gt;

&lt;p&gt;Note that, imho, we should just allow anyone to trigger a rebalance by rejoining the group. But this would presumably require a broker-side change and thus we would still need a workaround for KIP-441 to work with brokers.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Related issue:&lt;br/&gt;
This also means the Streams workaround for &lt;a href=&quot;http://example.com&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;KAFKA-9821&lt;/a&gt; is not airtight, as we encode the followup rebalance in the member who is supposed to &lt;em&gt;receive&lt;/em&gt; a revoked partition, rather than the member who is actually revoking said partition. While the member doing the revoking will be guaranteed to have different userdata, the member receiving the partition may not. Making it the responsibility of the leader to trigger &lt;em&gt;any&lt;/em&gt; type of followup rebalance would solve this issue as well.&lt;/p&gt;

&lt;p&gt;Note that other types of followup rebalance (version probing, static membership with host info change) are guaranteed to have a change in the subscription userdata, and will not hit this bug&lt;/p&gt;</description>
                <environment></environment>
        <key id="13325570">KAFKA-10455</key>
            <summary>Probing rebalances are not guaranteed to be triggered by non-leader members</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lthomas">Leah Thomas</assignee>
                                    <reporter username="ableegoldman">A. Sophie Blee-Goldman</reporter>
                        <labels>
                    </labels>
                <created>Tue, 1 Sep 2020 17:45:51 +0000</created>
                <updated>Thu, 7 Jan 2021 19:51:33 +0000</updated>
                            <resolved>Mon, 19 Oct 2020 19:49:13 +0000</resolved>
                                    <version>2.6.0</version>
                                    <fixVersion>2.6.1</fixVersion>
                    <fixVersion>2.7.0</fixVersion>
                                    <component>streams</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="17188804" author="vvcephei" created="Tue, 1 Sep 2020 20:31:57 +0000"  >&lt;p&gt;Thanks, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ableegoldman&quot; class=&quot;user-hover&quot; rel=&quot;ableegoldman&quot;&gt;ableegoldman&lt;/a&gt; . This is a bummer.&lt;/p&gt;

&lt;p&gt;It seems like when we want to force a rebalance, we just have to make sure the user-data changes in some way. IIUC, each consumer gets a PartitionAssignor instance with the same lifecycle as the consumer itself. Therefore, we can just initialize a single `byte`, which we&apos;ll just slap onto the subscription userdata and ignore when deserializing. We can just increment it for each forced rebalance and let it roll over.&lt;/p&gt;</comment>
                            <comment id="17188864" author="ableegoldman" created="Tue, 1 Sep 2020 23:47:31 +0000"  >&lt;p&gt;Yeah ok, that sounds reasonable. Initially I was thinking that we should avoid relying on any kind of in-memory counter to enforce a change in the userdata, to avoid losing the counter in the event of a restart and having it get initialized back to the previous value. However, presumably upon rejoining after a restart the member would send in a new subscription, and the broker would save that as the latest subscription userdata, so incrementing the counter upon every subscription should be ok.&#160;&lt;/p&gt;

&lt;p&gt;I&apos;ll try to look around in the broker code to verify that it actually updates the member&apos;s subscription metadata, even if eg static membership is used&lt;/p&gt;</comment>
                            <comment id="17189843" author="guozhang" created="Thu, 3 Sep 2020 05:23:47 +0000"  >&lt;p&gt;I&apos;m trying to assess statistically how large this may impact probing rebalances: my understanding is that since in Streams&apos; subscription info we encode `taskOffsetSumsCache`, its value is highly likely to change in each new join-group&apos;s subscription, the chance that we will have exactly the same serialized bytes should be small?&lt;/p&gt;</comment>
                            <comment id="17190338" author="ableegoldman" created="Thu, 3 Sep 2020 18:02:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt;&#160;if the triggering member has only active (and running) tasks, they will always be encoded with a sentinel offset sum of &quot;-2&quot; which would not change between rebalances. I do think that if the member has any standbys however, the odds of this happening are small (it could still be the case that the task offset sums remain unchanged, for example if the standbys are completely starved by the active tasks, but this seems like a pretty rare edge case. So realistically it&apos;s just the purely-active assignment that we have to worry about)&lt;/p&gt;</comment>
                            <comment id="17192371" author="guozhang" created="Tue, 8 Sep 2020 18:13:13 +0000"  >&lt;p&gt;Thanks for the info &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ableegoldman&quot; class=&quot;user-hover&quot; rel=&quot;ableegoldman&quot;&gt;ableegoldman&lt;/a&gt;. I think we can have two approaches here which are not necessarily conflicting with each other (i.e. we can probably do both):&lt;/p&gt;

&lt;p&gt;1. We a) modify client to always refresh metadata before re-joining the group to reduce the probability of rebalance storm, and then b) modify brokers to just allow any join request to trigger a rebalance. But this depends on brokers and hence people who do not upgrade their brokers would not get this fix.&lt;/p&gt;

&lt;p&gt;2. Based on the fact that only consumers from the same instance of the leader thread would trigger rebalances, we can take it as a by-product of multi-threading proposal such that each instance would only have one consumer instead of one-consumer per thread. And with a single consumer per instance, we can avoid this issue as well as simplifying our two-phase assignment algorithm to single-phase as well.&lt;/p&gt;</comment>
                            <comment id="17194469" author="ableegoldman" created="Fri, 11 Sep 2020 17:54:55 +0000"  >&lt;p&gt;Yeah, I think you&apos;re touching on a related issue&#160;&#8211; fast detection of source topic deletion &#8211; which I agree can/should be solved along the same lines as the probing rebalance bug in this ticket.&lt;/p&gt;

&lt;p&gt;Just for some context, to avoid accidental data corruption/loss, we of course want to react as fast as possible on source topic deletion. Currently we detect the absence of source topics during a rebalance and send an error code to all members to shut down. The problem is that there may be a gap of up to the metadata.max.age (default 5min) between the topic deletion and the reaction, ie triggering a rebalance and informing all members to shut down. Since only the leader is guaranteed to trigger a rebalance upon sending a JoinGroup, unless the leader happens to be assigned one of the partitions of the deleted tasks, it will not notice the topic deletion until it refreshes its metadata. If non-leaders are assigned to these deleted partitions and notice the topic deletion, they may not be able to trigger a rebalance even if they rejoin the group.&lt;/p&gt;

&lt;p&gt;Both problems could be solved by modifying the userdata to ensure any member&apos;s JoinGroup results in a rebalance. We could just add a single byte to the SubscriptionInfo and bump it when rejoining. This actually seems like a better all-around solution, since members of Streams should not be haphazardly sending JoinGroups for no reason &#8211; if they do, it must be because they want a rebalance. This way we don&apos;t have to worry about changing any broker side code and finding a workaround for older brokers.&#160;&lt;/p&gt;

&lt;p&gt;We could also take the approach of making sure the leader is responsible&#160;for triggering the rebalance, but this doesn&apos;t solve the source topic deletion problem. It also wouldn&apos;t help us in any new feature we wanted to add that required arbitrary&#160;members to trigger a rebalance. So I think we should just go with bumping a byte in the SubscriptionInfo&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310660">
                    <name>Completes</name>
                                            <outwardlinks description="fixes">
                                        <issuelink>
            <issuekey id="13336789">KAFKA-10633</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 9 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0i9ew:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>