<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:39:01 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-1030] Addition of partitions requires bouncing all the consumers of that topic</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-1030</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Consumer may not notice new partitions because the propagation of the metadata to servers can be delayed. &lt;/p&gt;

&lt;p&gt;Options:&lt;br/&gt;
1. As Jun suggested on &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-956&quot; title=&quot;High-level consumer fails to check topic metadata response for errors&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-956&quot;&gt;&lt;del&gt;KAFKA-956&lt;/del&gt;&lt;/a&gt;, the easiest fix would be to read the new partition data from zookeeper instead of a kafka server.&lt;br/&gt;
2. Run a fetch metadata loop in consumer, and set auto.offset.reset to smallest once the consumer has started.&lt;/p&gt;

&lt;p&gt;1 sounds easier to do. If 1 causes long delays in reading all partitions at the start of every rebalance, 2 may be worth considering.&lt;/p&gt;

&lt;p&gt;The same issue affects MirrorMaker when new topics are created, MirrorMaker may not notice all partitions of the new topics until the next rebalance.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12665845">KAFKA-1030</key>
            <summary>Addition of partitions requires bouncing all the consumers of that topic</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="guozhang">Guozhang Wang</assignee>
                                    <reporter username="swapnilghike">Swapnil Ghike</reporter>
                        <labels>
                    </labels>
                <created>Wed, 28 Aug 2013 04:58:04 +0000</created>
                <updated>Tue, 17 Sep 2013 21:24:46 +0000</updated>
                            <resolved>Tue, 17 Sep 2013 21:24:46 +0000</resolved>
                                    <version>0.8.0</version>
                                    <fixVersion>0.8.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="13752102" author="swapnilghike" created="Wed, 28 Aug 2013 05:02:04 +0000"  >&lt;p&gt;As Jun suggested on &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-956&quot; title=&quot;High-level consumer fails to check topic metadata response for errors&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-956&quot;&gt;&lt;del&gt;KAFKA-956&lt;/del&gt;&lt;/a&gt;, the easiest fix would be to read the new partition data from zookeeper instead of a kafka server.&lt;/p&gt;</comment>
                            <comment id="13752619" author="nehanarkhede" created="Wed, 28 Aug 2013 17:45:10 +0000"  >&lt;p&gt;One alternative is to change the topic metadata request handling on the controller broker and let the consumer re-issue a metadata request to the controller broker when the partition change listener fires. If the broker is the controller, it should serve the metadata request by reading from the controller cache directly. If not, it can rely on leaderCache that is updated via the UpdateMetadata request. Upside of this approach is that it won&apos;t kill performance and will solve the problem. Downside is that it might make the metadata request handling on the controller broker somewhat slower since it invovlves locking on the controller lock.&lt;/p&gt;</comment>
                            <comment id="13752679" author="swapnilghike" created="Wed, 28 Aug 2013 18:27:23 +0000"  >&lt;p&gt;Hmm, this will mean that the consumer client will cease to be controller agnostic. Is that a good idea? Plus if there is a controller failover at the same time as a consumer trying to fetch metadata, the broker the consumer was talking to for fetching metadata may have stale metadata. So, we may need to implement a controller failover watcher on consumer to trigger fetching metadata. Thoughts?&lt;/p&gt;</comment>
                            <comment id="13752793" author="nehanarkhede" created="Wed, 28 Aug 2013 20:05:12 +0000"  >&lt;p&gt;Longer term, the right fix will be to move rebalancing to the controller and let it co-ordinate state changes for the consumer. Until then, it will be some sort of a work around to get the latest state changes. To your point, if controller failover is happening, the rebalance attempt will fail. This is no different from leadership changes. I don&apos;t see why we need controller failover watch. This controller metadata is only required when partitions change, so it is on-demand.&lt;/p&gt;</comment>
                            <comment id="13753146" author="guozhang" created="Thu, 29 Aug 2013 01:06:02 +0000"  >&lt;p&gt;I think the first option might work just okay, since the consumer do not actually needs the partition leader id, etc. All it needs is the map of topic -&amp;gt; list of partition ids. This can be done by just reading one ZK path per topic: /brokers/topics/&lt;span class=&quot;error&quot;&gt;&amp;#91;topic&amp;#93;&lt;/span&gt;. Of course this will put more pressure on MirrorMaker though, but we should really not do full rebalance for added partition or topic anyways..&lt;/p&gt;</comment>
                            <comment id="13769744" author="guozhang" created="Tue, 17 Sep 2013 18:00:31 +0000"  >&lt;p&gt;Updated reviewboard &lt;a href=&quot;https://reviews.apache.org/r/14041/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.apache.org/r/14041/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13769879" author="guozhang" created="Tue, 17 Sep 2013 20:15:09 +0000"  >&lt;p&gt;Here are the performance testing results:&lt;/p&gt;

&lt;p&gt;Setup: 1) 5 instances of mirror maker consuming from around 3800 topic/partitions, 2) 1 instance of console consumer consuming from around 300 topic/partitions.&lt;/p&gt;

&lt;p&gt;1). Bouncing mirror makers:&lt;/p&gt;

&lt;p&gt;ZK-located-in-same-DC: 4 minutes and 20 seconds with the fix&lt;/p&gt;

&lt;p&gt;ZK-located-in-same-DC: 3 minutes 50 secs without the fix&lt;/p&gt;

&lt;p&gt;ZK-located-in-other-DC: 8 minutes 2 seconds with the fix&lt;/p&gt;

&lt;p&gt;ZK-located-in-other-DC: 7 minutes 6 seconds without the fix&lt;/p&gt;

&lt;p&gt;2). Bouncing console consumer &lt;/p&gt;

&lt;p&gt;ZK-located-in-same-DC: 15 seconds with the fix&lt;/p&gt;

&lt;p&gt;ZK-located-in-same-DC: 15 seconds without the fix&lt;/p&gt;

&lt;p&gt;---------------&lt;/p&gt;

&lt;p&gt;Given the results, I think it worth pushing this approach (read-from-ZK) in 0.8 and we can later pursue the other approach Joel proposed in the reviewboard in trunk.&lt;/p&gt;</comment>
                            <comment id="13769884" author="swapnilghike" created="Tue, 17 Sep 2013 20:18:53 +0000"  >&lt;p&gt;+1 that Guozhang, thanks for running the tests.&lt;/p&gt;</comment>
                            <comment id="13769994" author="nehanarkhede" created="Tue, 17 Sep 2013 21:24:42 +0000"  >&lt;p&gt;Thanks for the updated patch and the performance comparison analysis. I agree that the ideal change might prove to be too large for 0.8 and will require non-trivial amount of time stabilizing it since it is fairly tricky. We can just do it properly on trunk and live with this minor performance hit for consumer rebalancing on 0.8.&lt;/p&gt;</comment>
                            <comment id="13769995" author="nehanarkhede" created="Tue, 17 Sep 2013 21:24:46 +0000"  >&lt;p&gt;&lt;br/&gt;
Checked in the latest patch to 0.8&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12603632" name="KAFKA-1030-v1.patch" size="1742" author="guozhang" created="Tue, 17 Sep 2013 18:00:26 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>345784</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            12 years, 9 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nmmv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>346085</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>