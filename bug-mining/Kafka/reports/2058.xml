<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:15:09 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-7434] DeadLetterQueueReporter throws NPE if transform throws NPE</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-7434</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;A NPE thrown from a transform in a connector configured with&lt;/p&gt;

&lt;p&gt;errors.deadletterqueue.context.headers.enable=true&lt;/p&gt;

&lt;p&gt;causes&#160;DeadLetterQueueReporter to break with a NPE.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Executing stage &lt;span class=&quot;code-quote&quot;&gt;&apos;TRANSFORMATION&apos;&lt;/span&gt; with class &lt;span class=&quot;code-quote&quot;&gt;&apos;org.apache.kafka.connect.transforms.Flatten$Value&apos;&lt;/span&gt;, where consumed record is {topic=&lt;span class=&quot;code-quote&quot;&gt;&apos;****&apos;&lt;/span&gt;, partition=1, offset=0, timestamp=1537370573366, timestampType=CreateTime}. (org.apache.kafka.connect.runtime.errors.LogReporter)
java.lang.NullPointerException
Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask)
java.lang.NullPointerException
	at org.apache.kafka.connect.runtime.errors.DeadLetterQueueReporter.toBytes(DeadLetterQueueReporter.java:202)
	at org.apache.kafka.connect.runtime.errors.DeadLetterQueueReporter.populateContextHeaders(DeadLetterQueueReporter.java:172)
	at org.apache.kafka.connect.runtime.errors.DeadLetterQueueReporter.report(DeadLetterQueueReporter.java:146)
	at org.apache.kafka.connect.runtime.errors.ProcessingContext.report(ProcessingContext.java:137)
	at org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execute(RetryWithToleranceOperator.java:108)
	at org.apache.kafka.connect.runtime.TransformationChain.apply(TransformationChain.java:44)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.convertAndTransformRecord(WorkerSinkTask.java:532)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.convertMessages(WorkerSinkTask.java:490)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:321)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:193)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:175)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:219)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;This is caused by populateContextHeaders only checking if the Throwable is not null, but not checking that the message in the Throwable is not null before trying to serialize the message:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/kafka/blob/cfd33b313c9856ae2b4b45ed3d4aac41d6ef5a6b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/errors/DeadLetterQueueReporter.java#L170-L177&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/cfd33b313c9856ae2b4b45ed3d4aac41d6ef5a6b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/errors/DeadLetterQueueReporter.java#L170-L177&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (context.error() != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
 &#160; &#160; headers.add(ERROR_HEADER_EXCEPTION, toBytes(context.error().getClass().getName()));
 &#160; &#160; headers.add(ERROR_HEADER_EXCEPTION_MESSAGE, toBytes(context.error().getMessage()));
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;toBytes throws an NPE if passed null as the parameter.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment>jdk 8</environment>
        <key id="13186991">KAFKA-7434</key>
            <summary>DeadLetterQueueReporter throws NPE if transform throws NPE</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mihbor">Michal Borowiecki</assignee>
                                    <reporter username="mihbor">Michal Borowiecki</reporter>
                        <labels>
                    </labels>
                <created>Mon, 24 Sep 2018 11:15:34 +0000</created>
                <updated>Sat, 29 Sep 2018 17:26:12 +0000</updated>
                            <resolved>Sat, 29 Sep 2018 17:19:43 +0000</resolved>
                                    <version>2.0.0</version>
                                    <fixVersion>2.0.1</fixVersion>
                    <fixVersion>2.1.0</fixVersion>
                                    <component>connect</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="16629413" author="githubbot" created="Wed, 26 Sep 2018 21:08:30 +0000"  >&lt;p&gt;mihbor opened a new pull request #5700: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7434&quot; title=&quot;DeadLetterQueueReporter throws NPE if transform throws NPE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7434&quot;&gt;&lt;del&gt;KAFKA-7434&lt;/del&gt;&lt;/a&gt; fix NPE in DeadLetterQueueReporter&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5700&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5700&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   *More detailed description of your change,&lt;br/&gt;
   if necessary. The PR title and PR message become&lt;br/&gt;
   the squashed commit message, so use a separate&lt;br/&gt;
   comment to ping reviewers.*&lt;/p&gt;

&lt;p&gt;   *Summary of testing strategy (including rationale)&lt;br/&gt;
   for the feature or bug fix. Unit and/or integration&lt;br/&gt;
   tests are expected for any behaviour change and&lt;br/&gt;
   system tests should be considered for larger changes.*&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16629427" author="githubbot" created="Wed, 26 Sep 2018 21:20:48 +0000"  >&lt;p&gt;mihbor opened a new pull request #5701: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7434&quot; title=&quot;DeadLetterQueueReporter throws NPE if transform throws NPE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7434&quot;&gt;&lt;del&gt;KAFKA-7434&lt;/del&gt;&lt;/a&gt; fix NPE in DeadLetterQueueReporter - backport to 2.0&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5701&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5701&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   *More detailed description of your change,&lt;br/&gt;
   if necessary. The PR title and PR message become&lt;br/&gt;
   the squashed commit message, so use a separate&lt;br/&gt;
   comment to ping reviewers.*&lt;/p&gt;

&lt;p&gt;   *Summary of testing strategy (including rationale)&lt;br/&gt;
   for the feature or bug fix. Unit and/or integration&lt;br/&gt;
   tests are expected for any behaviour change and&lt;br/&gt;
   system tests should be considered for larger changes.*&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16629428" author="mihbor" created="Wed, 26 Sep 2018 21:21:52 +0000"  >&lt;p&gt;Submitted PR for trunk: &lt;a href=&quot;https://github.com/apache/kafka/pull/5700&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5700&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;and a backport to 2.0 branch: &lt;a href=&quot;https://github.com/apache/kafka/pull/5701&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5701&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="16633064" author="ewencp" created="Sat, 29 Sep 2018 17:19:43 +0000"  >&lt;p&gt;Issue resolved by pull request 5700&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/pull/5700&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5700&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16633066" author="githubbot" created="Sat, 29 Sep 2018 17:21:12 +0000"  >&lt;p&gt;ewencp closed pull request #5700: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7434&quot; title=&quot;DeadLetterQueueReporter throws NPE if transform throws NPE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7434&quot;&gt;&lt;del&gt;KAFKA-7434&lt;/del&gt;&lt;/a&gt; fix NPE in DeadLetterQueueReporter&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5700&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5700&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/errors/DeadLetterQueueReporter.java b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/errors/DeadLetterQueueReporter.java&lt;br/&gt;
index c059dcff793..23122699783 100644&lt;br/&gt;
&amp;#8212; a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/errors/DeadLetterQueueReporter.java&lt;br/&gt;
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/errors/DeadLetterQueueReporter.java&lt;br/&gt;
@@ -199,6 +199,10 @@ void populateContextHeaders(ProducerRecord&amp;lt;byte[], byte[]&amp;gt; producerRecord, Proce&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;     private byte[] toBytes(String value) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return value.getBytes(StandardCharsets.UTF_8);&lt;br/&gt;
+        if (value != null) 
{
+            return value.getBytes(StandardCharsets.UTF_8);
+        }
&lt;p&gt; else &lt;/p&gt;
{
+            return null;
+        }
&lt;p&gt;     }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/errors/ErrorReporterTest.java b/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/errors/ErrorReporterTest.java&lt;br/&gt;
index fa628b09840..00a922f76ad 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/errors/ErrorReporterTest.java&lt;br/&gt;
+++ b/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/errors/ErrorReporterTest.java&lt;br/&gt;
@@ -59,6 +59,7 @@&lt;br/&gt;
 import static org.apache.kafka.connect.runtime.errors.DeadLetterQueueReporter.ERROR_HEADER_TASK_ID;&lt;br/&gt;
 import static org.easymock.EasyMock.replay;&lt;br/&gt;
 import static org.junit.Assert.assertEquals;&lt;br/&gt;
+import static org.junit.Assert.assertNull;&lt;br/&gt;
 import static org.junit.Assert.assertTrue;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; @RunWith(PowerMockRunner.class)&lt;br/&gt;
@@ -205,6 +206,7 @@ public void testSetDLQConfigs() &lt;/p&gt;
{
         assertEquals(configuration.dlqTopicReplicationFactor(), 7);
     }

&lt;p&gt;+    @Test&lt;br/&gt;
     public void testDlqHeaderConsumerRecord() {&lt;br/&gt;
         Map&amp;lt;String, String&amp;gt; props = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
         props.put(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG, DLQ_TOPIC);&lt;br/&gt;
@@ -232,6 +234,34 @@ public void testDlqHeaderConsumerRecord() &lt;/p&gt;
{
         assertTrue(headerValue(producerRecord, ERROR_HEADER_EXCEPTION_STACK_TRACE).startsWith(&quot;org.apache.kafka.connect.errors.ConnectException: Test Exception&quot;));
     }

&lt;p&gt;+    @Test&lt;br/&gt;
+    public void testDlqHeaderOnNullExceptionMessage() &lt;/p&gt;
{
+        Map&amp;lt;String, String&amp;gt; props = new HashMap&amp;lt;&amp;gt;();
+        props.put(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG, DLQ_TOPIC);
+        props.put(SinkConnectorConfig.DLQ_CONTEXT_HEADERS_ENABLE_CONFIG, &quot;true&quot;);
+        DeadLetterQueueReporter deadLetterQueueReporter = new DeadLetterQueueReporter(producer, config(props), TASK_ID, errorHandlingMetrics);
+
+        ProcessingContext context = new ProcessingContext();
+        context.consumerRecord(new ConsumerRecord&amp;lt;&amp;gt;(&quot;source-topic&quot;, 7, 10, &quot;source-key&quot;.getBytes(), &quot;source-value&quot;.getBytes()));
+        context.currentContext(Stage.TRANSFORMATION, Transformation.class);
+        context.error(new NullPointerException());
+
+        ProducerRecord&amp;lt;byte[], byte[]&amp;gt; producerRecord = new ProducerRecord&amp;lt;&amp;gt;(DLQ_TOPIC, &quot;source-key&quot;.getBytes(), &quot;source-value&quot;.getBytes());
+
+        deadLetterQueueReporter.populateContextHeaders(producerRecord, context);
+        assertEquals(&quot;source-topic&quot;, headerValue(producerRecord, ERROR_HEADER_ORIG_TOPIC));
+        assertEquals(&quot;7&quot;, headerValue(producerRecord, ERROR_HEADER_ORIG_PARTITION));
+        assertEquals(&quot;10&quot;, headerValue(producerRecord, ERROR_HEADER_ORIG_OFFSET));
+        assertEquals(TASK_ID.connector(), headerValue(producerRecord, ERROR_HEADER_CONNECTOR_NAME));
+        assertEquals(String.valueOf(TASK_ID.task()), headerValue(producerRecord, ERROR_HEADER_TASK_ID));
+        assertEquals(Stage.TRANSFORMATION.name(), headerValue(producerRecord, ERROR_HEADER_STAGE));
+        assertEquals(Transformation.class.getName(), headerValue(producerRecord, ERROR_HEADER_EXECUTING_CLASS));
+        assertEquals(NullPointerException.class.getName(), headerValue(producerRecord, ERROR_HEADER_EXCEPTION));
+        assertNull(producerRecord.headers().lastHeader(ERROR_HEADER_EXCEPTION_MESSAGE).value());
+        assertTrue(headerValue(producerRecord, ERROR_HEADER_EXCEPTION_STACK_TRACE).length() &amp;gt; 0);
+        assertTrue(headerValue(producerRecord, ERROR_HEADER_EXCEPTION_STACK_TRACE).startsWith(&quot;java.lang.NullPointerException&quot;));
+    }
&lt;p&gt;+&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testDlqHeaderIsAppended() {&lt;br/&gt;
         Map&amp;lt;String, String&amp;gt; props = new HashMap&amp;lt;&amp;gt;();&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16633070" author="githubbot" created="Sat, 29 Sep 2018 17:26:12 +0000"  >&lt;p&gt;mihbor closed pull request #5701: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7434&quot; title=&quot;DeadLetterQueueReporter throws NPE if transform throws NPE&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7434&quot;&gt;&lt;del&gt;KAFKA-7434&lt;/del&gt;&lt;/a&gt; fix NPE in DeadLetterQueueReporter - backport to 2.0&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5701&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5701&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/errors/DeadLetterQueueReporter.java b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/errors/DeadLetterQueueReporter.java&lt;br/&gt;
index c059dcff793..23122699783 100644&lt;br/&gt;
&amp;#8212; a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/errors/DeadLetterQueueReporter.java&lt;br/&gt;
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/errors/DeadLetterQueueReporter.java&lt;br/&gt;
@@ -199,6 +199,10 @@ void populateContextHeaders(ProducerRecord&amp;lt;byte[], byte[]&amp;gt; producerRecord, Proce&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;     private byte[] toBytes(String value) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return value.getBytes(StandardCharsets.UTF_8);&lt;br/&gt;
+        if (value != null) 
{
+            return value.getBytes(StandardCharsets.UTF_8);
+        }
&lt;p&gt; else &lt;/p&gt;
{
+            return null;
+        }
&lt;p&gt;     }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/errors/ErrorReporterTest.java b/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/errors/ErrorReporterTest.java&lt;br/&gt;
index fa628b09840..00a922f76ad 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/errors/ErrorReporterTest.java&lt;br/&gt;
+++ b/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/errors/ErrorReporterTest.java&lt;br/&gt;
@@ -59,6 +59,7 @@&lt;br/&gt;
 import static org.apache.kafka.connect.runtime.errors.DeadLetterQueueReporter.ERROR_HEADER_TASK_ID;&lt;br/&gt;
 import static org.easymock.EasyMock.replay;&lt;br/&gt;
 import static org.junit.Assert.assertEquals;&lt;br/&gt;
+import static org.junit.Assert.assertNull;&lt;br/&gt;
 import static org.junit.Assert.assertTrue;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; @RunWith(PowerMockRunner.class)&lt;br/&gt;
@@ -205,6 +206,7 @@ public void testSetDLQConfigs() &lt;/p&gt;
{
         assertEquals(configuration.dlqTopicReplicationFactor(), 7);
     }

&lt;p&gt;+    @Test&lt;br/&gt;
     public void testDlqHeaderConsumerRecord() {&lt;br/&gt;
         Map&amp;lt;String, String&amp;gt; props = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
         props.put(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG, DLQ_TOPIC);&lt;br/&gt;
@@ -232,6 +234,34 @@ public void testDlqHeaderConsumerRecord() &lt;/p&gt;
{
         assertTrue(headerValue(producerRecord, ERROR_HEADER_EXCEPTION_STACK_TRACE).startsWith(&quot;org.apache.kafka.connect.errors.ConnectException: Test Exception&quot;));
     }

&lt;p&gt;+    @Test&lt;br/&gt;
+    public void testDlqHeaderOnNullExceptionMessage() &lt;/p&gt;
{
+        Map&amp;lt;String, String&amp;gt; props = new HashMap&amp;lt;&amp;gt;();
+        props.put(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG, DLQ_TOPIC);
+        props.put(SinkConnectorConfig.DLQ_CONTEXT_HEADERS_ENABLE_CONFIG, &quot;true&quot;);
+        DeadLetterQueueReporter deadLetterQueueReporter = new DeadLetterQueueReporter(producer, config(props), TASK_ID, errorHandlingMetrics);
+
+        ProcessingContext context = new ProcessingContext();
+        context.consumerRecord(new ConsumerRecord&amp;lt;&amp;gt;(&quot;source-topic&quot;, 7, 10, &quot;source-key&quot;.getBytes(), &quot;source-value&quot;.getBytes()));
+        context.currentContext(Stage.TRANSFORMATION, Transformation.class);
+        context.error(new NullPointerException());
+
+        ProducerRecord&amp;lt;byte[], byte[]&amp;gt; producerRecord = new ProducerRecord&amp;lt;&amp;gt;(DLQ_TOPIC, &quot;source-key&quot;.getBytes(), &quot;source-value&quot;.getBytes());
+
+        deadLetterQueueReporter.populateContextHeaders(producerRecord, context);
+        assertEquals(&quot;source-topic&quot;, headerValue(producerRecord, ERROR_HEADER_ORIG_TOPIC));
+        assertEquals(&quot;7&quot;, headerValue(producerRecord, ERROR_HEADER_ORIG_PARTITION));
+        assertEquals(&quot;10&quot;, headerValue(producerRecord, ERROR_HEADER_ORIG_OFFSET));
+        assertEquals(TASK_ID.connector(), headerValue(producerRecord, ERROR_HEADER_CONNECTOR_NAME));
+        assertEquals(String.valueOf(TASK_ID.task()), headerValue(producerRecord, ERROR_HEADER_TASK_ID));
+        assertEquals(Stage.TRANSFORMATION.name(), headerValue(producerRecord, ERROR_HEADER_STAGE));
+        assertEquals(Transformation.class.getName(), headerValue(producerRecord, ERROR_HEADER_EXECUTING_CLASS));
+        assertEquals(NullPointerException.class.getName(), headerValue(producerRecord, ERROR_HEADER_EXCEPTION));
+        assertNull(producerRecord.headers().lastHeader(ERROR_HEADER_EXCEPTION_MESSAGE).value());
+        assertTrue(headerValue(producerRecord, ERROR_HEADER_EXCEPTION_STACK_TRACE).length() &amp;gt; 0);
+        assertTrue(headerValue(producerRecord, ERROR_HEADER_EXCEPTION_STACK_TRACE).startsWith(&quot;java.lang.NullPointerException&quot;));
+    }
&lt;p&gt;+&lt;br/&gt;
     @Test&lt;br/&gt;
     public void testDlqHeaderIsAppended() {&lt;br/&gt;
         Map&amp;lt;String, String&amp;gt; props = new HashMap&amp;lt;&amp;gt;();&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 7 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3yeyf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>