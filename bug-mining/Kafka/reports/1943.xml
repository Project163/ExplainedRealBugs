<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:11:52 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-7029] ReplicaVerificationTool should not use the deprecated SimpleConsumer</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-7029</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Unless there&apos;s a reason not to, the simplest would be to use KafkaConsumer.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13165142">KAFKA-7029</key>
            <summary>ReplicaVerificationTool should not use the deprecated SimpleConsumer</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="omkreddy">Manikumar</assignee>
                                    <reporter username="ijuma">Ismael Juma</reporter>
                        <labels>
                    </labels>
                <created>Sat, 9 Jun 2018 17:22:34 +0000</created>
                <updated>Tue, 12 Jun 2018 07:50:27 +0000</updated>
                            <resolved>Tue, 12 Jun 2018 07:50:27 +0000</resolved>
                                                    <fixVersion>2.0.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="16507081" author="ijuma" created="Sat, 9 Jun 2018 17:22:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=omkreddy&quot; class=&quot;user-hover&quot; rel=&quot;omkreddy&quot;&gt;omkreddy&lt;/a&gt;, would you be interested in picking this up?&lt;/p&gt;</comment>
                            <comment id="16508472" author="githubbot" created="Mon, 11 Jun 2018 18:15:29 +0000"  >&lt;p&gt;omkreddy opened a new pull request #5188: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7029&quot; title=&quot;ReplicaVerificationTool should not use the deprecated SimpleConsumer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7029&quot;&gt;&lt;del&gt;KAFKA-7029&lt;/del&gt;&lt;/a&gt;: Update ReplicaVerificationTool to use Java Consumer&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5188&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5188&lt;/a&gt;&lt;/p&gt;




&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16509302" author="githubbot" created="Tue, 12 Jun 2018 07:46:28 +0000"  >&lt;p&gt;ijuma closed pull request #5188: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7029&quot; title=&quot;ReplicaVerificationTool should not use the deprecated SimpleConsumer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7029&quot;&gt;&lt;del&gt;KAFKA-7029&lt;/del&gt;&lt;/a&gt;: Update ReplicaVerificationTool to use Java Consumer&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5188&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5188&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/core/src/main/scala/kafka/server/ReplicaFetcherBlockingSend.scala b/core/src/main/scala/kafka/server/ReplicaFetcherBlockingSend.scala&lt;br/&gt;
index 0bf2bd3c9ff..4c7adfbe9cd 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/server/ReplicaFetcherBlockingSend.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/server/ReplicaFetcherBlockingSend.scala&lt;br/&gt;
@@ -86,7 +86,7 @@ class ReplicaFetcherBlockingSend(sourceBroker: BrokerEndPoint,&lt;br/&gt;
     )&lt;br/&gt;
   }&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;override def sendRequest(requestBuilder: Builder&lt;span class=&quot;error&quot;&gt;&amp;#91;_ &amp;lt;: AbstractRequest&amp;#93;&lt;/span&gt;): ClientResponse =  {&lt;br/&gt;
+  override def sendRequest(requestBuilder: Builder&lt;span class=&quot;error&quot;&gt;&amp;#91;_ &amp;lt;: AbstractRequest&amp;#93;&lt;/span&gt;): ClientResponse = {&lt;br/&gt;
     try {&lt;br/&gt;
       if (!NetworkClientUtils.awaitReady(networkClient, sourceNode, time, socketTimeout))&lt;br/&gt;
         throw new SocketTimeoutException(s&quot;Failed to connect within $socketTimeout ms&quot;)&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/tools/ReplicaVerificationTool.scala b/core/src/main/scala/kafka/tools/ReplicaVerificationTool.scala&lt;br/&gt;
index 0408e9212a3..b1e694688b7 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/main/scala/kafka/tools/ReplicaVerificationTool.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/tools/ReplicaVerificationTool.scala&lt;br/&gt;
@@ -17,25 +17,35 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; package kafka.tools&lt;/p&gt;

&lt;p&gt;+import java.net.SocketTimeoutException&lt;br/&gt;
 import java.text.SimpleDateFormat&lt;br/&gt;
-import java.util.Date&lt;br/&gt;
+import java.util&lt;br/&gt;
 import java.util.concurrent.CountDownLatch&lt;br/&gt;
-import java.util.concurrent.atomic.AtomicReference&lt;br/&gt;
+import java.util.concurrent.atomic.&lt;/p&gt;
{AtomicInteger, AtomicReference}
&lt;p&gt; import java.util.regex.&lt;/p&gt;
{Pattern, PatternSyntaxException}
&lt;p&gt;+import java.util.&lt;/p&gt;
{Date, Properties}

&lt;p&gt; import joptsimple.OptionParser&lt;br/&gt;
 import kafka.api._&lt;br/&gt;
-import kafka.client.ClientUtils&lt;br/&gt;
-import kafka.cluster.BrokerEndPoint&lt;br/&gt;
-import kafka.common.TopicAndPartition&lt;br/&gt;
-import kafka.consumer.&lt;/p&gt;
{ConsumerConfig, SimpleConsumer, Whitelist}
&lt;p&gt;-import kafka.message.&lt;/p&gt;
{ByteBufferMessageSet, MessageSet}
&lt;p&gt;+import kafka.consumer.Whitelist&lt;br/&gt;
 import kafka.utils._&lt;br/&gt;
-import org.apache.kafka.common.protocol.Errors&lt;br/&gt;
-import org.apache.kafka.common.utils.Time&lt;br/&gt;
+import org.apache.kafka.clients._&lt;br/&gt;
+import org.apache.kafka.clients.admin.&lt;/p&gt;
{ListTopicsOptions, TopicDescription}
&lt;p&gt;+import org.apache.kafka.clients.consumer.&lt;/p&gt;
{ConsumerConfig, KafkaConsumer}
&lt;p&gt;+import org.apache.kafka.common.metrics.Metrics&lt;br/&gt;
+import org.apache.kafka.common.network.&lt;/p&gt;
{NetworkReceive, Selectable, Selector}
&lt;p&gt;+import org.apache.kafka.common.protocol.&lt;/p&gt;
{ApiKeys, Errors}
&lt;p&gt;+import org.apache.kafka.common.record.MemoryRecords&lt;br/&gt;
+import org.apache.kafka.common.requests.AbstractRequest.Builder&lt;br/&gt;
+import org.apache.kafka.common.requests.&lt;/p&gt;
{AbstractRequest, FetchResponse, ListOffsetRequest, FetchRequest =&amp;gt; JFetchRequest}
&lt;p&gt;+import org.apache.kafka.common.serialization.StringDeserializer&lt;br/&gt;
+import org.apache.kafka.common.utils.&lt;/p&gt;
{LogContext, Time}
&lt;p&gt;+import org.apache.kafka.common.&lt;/p&gt;
{Node, TopicPartition}
&lt;p&gt;+&lt;br/&gt;
+import scala.collection.JavaConverters._&lt;/p&gt;

&lt;p&gt; /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;*  For verifying the consistency among replicas.&lt;br/&gt;
+ * For verifying the consistency among replicas.&lt;br/&gt;
  *&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;1. start a fetcher on every broker.&lt;/li&gt;
	&lt;li&gt;2. each fetcher does the following&lt;br/&gt;
@@ -44,11 +54,11 @@ import org.apache.kafka.common.utils.Time&lt;/li&gt;
	&lt;li&gt;2.3 waits for all other fetchers to finish step 2.2&lt;/li&gt;
	&lt;li&gt;2.4 one of the fetchers verifies the consistency of fetched results among replicas&lt;br/&gt;
  *&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;*  The consistency verification is up to the high watermark. The tool reports the&lt;/li&gt;
	&lt;li&gt;*  max lag between the verified offset and the high watermark among all partitions.&lt;br/&gt;
+ * The consistency verification is up to the high watermark. The tool reports the&lt;br/&gt;
+ * max lag between the verified offset and the high watermark among all partitions.&lt;br/&gt;
  *&lt;/li&gt;
	&lt;li&gt;*  If a broker goes down, the verification of the partitions on that broker is delayed&lt;/li&gt;
	&lt;li&gt;*  until the broker is up again.&lt;br/&gt;
+ * If a broker goes down, the verification of the partitions on that broker is delayed&lt;br/&gt;
+ * until the broker is up again.&lt;br/&gt;
  *&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;Caveats:&lt;/li&gt;
	&lt;li&gt;1. The tools needs all brokers to be up at startup time.&lt;br/&gt;
@@ -56,7 +66,7 @@ import org.apache.kafka.common.utils.Time&lt;br/&gt;
  */&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; object ReplicaVerificationTool extends Logging {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val clientId= &quot;replicaVerificationTool&quot;&lt;br/&gt;
+  val clientId = &quot;replicaVerificationTool&quot;&lt;br/&gt;
   val dateFormatString = &quot;yyyy-MM-dd HH:mm:ss,SSS&quot;&lt;br/&gt;
   val dateFormat = new SimpleDateFormat(dateFormatString)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -74,7 +84,7 @@ object ReplicaVerificationTool extends Logging {&lt;br/&gt;
                          .withRequiredArg&lt;br/&gt;
                          .describedAs(&quot;bytes&quot;)&lt;br/&gt;
                          .ofType(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;java.lang.Integer&amp;#93;&lt;/span&gt;)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;.defaultsTo(ConsumerConfig.FetchSize)&lt;br/&gt;
+                         .defaultsTo(ConsumerConfig.DEFAULT_MAX_PARTITION_FETCH_BYTES)&lt;br/&gt;
     val maxWaitMsOpt = parser.accepts(&quot;max-wait-ms&quot;, &quot;The max amount of time each fetch request waits.&quot;)&lt;br/&gt;
                          .withRequiredArg&lt;br/&gt;
                          .describedAs(&quot;ms&quot;)&lt;br/&gt;
@@ -96,18 +106,16 @@ object ReplicaVerificationTool extends Logging {&lt;br/&gt;
                          .ofType(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;java.lang.Long&amp;#93;&lt;/span&gt;)&lt;br/&gt;
                          .defaultsTo(30 * 1000L)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if(args.length == 0)&lt;br/&gt;
+    if (args.length == 0)&lt;br/&gt;
       CommandLineUtils.printUsageAndDie(parser, &quot;Validate that all replicas for a set of topics have the same data.&quot;)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val options = parser.parse(args : _*)&lt;br/&gt;
+    val options = parser.parse(args: _*)&lt;br/&gt;
     CommandLineUtils.checkRequiredArgs(parser, options, brokerListOpt)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val regex = options.valueOf(topicWhiteListOpt)&lt;br/&gt;
     val topicWhiteListFiler = new Whitelist(regex)&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;try 
{
-      Pattern.compile(regex)
-    }
&lt;p&gt;+    try Pattern.compile(regex)&lt;br/&gt;
     catch {&lt;br/&gt;
       case _: PatternSyntaxException =&amp;gt;&lt;br/&gt;
         throw new RuntimeException(regex + &quot; is an invalid regex.&quot;)&lt;br/&gt;
@@ -120,68 +128,68 @@ object ReplicaVerificationTool extends Logging {&lt;br/&gt;
     // getting topic metadata&lt;br/&gt;
     info(&quot;Getting topic metadata...&quot;)&lt;br/&gt;
     val brokerList = options.valueOf(brokerListOpt)&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;ToolsUtils.validatePortOrDie(parser,brokerList)&lt;/li&gt;
	&lt;li&gt;val metadataTargetBrokers = ClientUtils.parseBrokerList(brokerList)&lt;/li&gt;
	&lt;li&gt;val topicsMetadataResponse = ClientUtils.fetchTopicMetadata(Set&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;(), metadataTargetBrokers, clientId, maxWaitMs)&lt;/li&gt;
	&lt;li&gt;val brokerMap = topicsMetadataResponse.brokers.map(b =&amp;gt; (b.id, b)).toMap&lt;/li&gt;
	&lt;li&gt;val filteredTopicMetadata = topicsMetadataResponse.topicsMetadata.filter(&lt;/li&gt;
	&lt;li&gt;topicMetadata =&amp;gt; if (topicWhiteListFiler.isTopicAllowed(topicMetadata.topic, excludeInternalTopics = false))&lt;/li&gt;
	&lt;li&gt;true&lt;/li&gt;
	&lt;li&gt;else&lt;/li&gt;
	&lt;li&gt;false&lt;/li&gt;
	&lt;li&gt;)&lt;br/&gt;
+    ToolsUtils.validatePortOrDie(parser, brokerList)&lt;br/&gt;
+&lt;br/&gt;
+    val (topicsMetadata, brokerInfo) = 
{
+      val adminClient = createAdminClient(brokerList)
+      try ((listTopicsMetadata(adminClient), brokerDetails(adminClient)))
+      finally CoreUtils.swallow(adminClient.close(), this)
+    }
&lt;p&gt;+&lt;br/&gt;
+    val filteredTopicMetadata = topicsMetadata.filter &lt;/p&gt;
{ topicMetaData =&amp;gt;
+      topicWhiteListFiler.isTopicAllowed(topicMetaData.name, excludeInternalTopics = false)
+    }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     if (filteredTopicMetadata.isEmpty) &lt;/p&gt;
{
-      error(&quot;No topics found. &quot; + topicWhiteListOpt + &quot;, if specified, is either filtering out all topics or there is no topic.&quot;)
+      error(s&quot;No topics found. $topicWhiteListOpt if specified, is either filtering out all topics or there is no topic.&quot;)
       Exit.exit(1)
     }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val topicPartitionReplicaList: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartitionReplica&amp;#93;&lt;/span&gt; = filteredTopicMetadata.flatMap(&lt;/li&gt;
	&lt;li&gt;topicMetadataResponse =&amp;gt;&lt;/li&gt;
	&lt;li&gt;topicMetadataResponse.partitionsMetadata.flatMap(&lt;/li&gt;
	&lt;li&gt;partitionMetadata =&amp;gt;&lt;/li&gt;
	&lt;li&gt;partitionMetadata.replicas.map(broker =&amp;gt;&lt;/li&gt;
	&lt;li&gt;TopicPartitionReplica(topic = topicMetadataResponse.topic, partitionId = partitionMetadata.partitionId, replicaId = broker.id))&lt;/li&gt;
	&lt;li&gt;)&lt;/li&gt;
	&lt;li&gt;)&lt;/li&gt;
	&lt;li&gt;debug(&quot;Selected topic partitions: &quot; + topicPartitionReplicaList)&lt;/li&gt;
	&lt;li&gt;val topicAndPartitionsPerBroker: Map[Int, Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicAndPartition&amp;#93;&lt;/span&gt;] = topicPartitionReplicaList.groupBy(_.replicaId)&lt;/li&gt;
	&lt;li&gt;.map { case (brokerId, partitions) =&amp;gt;&lt;/li&gt;
	&lt;li&gt;brokerId -&amp;gt; partitions.map 
{ partition =&amp;gt; TopicAndPartition(partition.topic, partition.partitionId) }
&lt;p&gt; }&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;debug(&quot;Topic partitions per broker: &quot; + topicAndPartitionsPerBroker)&lt;/li&gt;
	&lt;li&gt;val expectedReplicasPerTopicAndPartition: Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicAndPartition, Int&amp;#93;&lt;/span&gt; =&lt;/li&gt;
	&lt;li&gt;topicPartitionReplicaList.groupBy(replica =&amp;gt; TopicAndPartition(replica.topic, replica.partitionId))&lt;/li&gt;
	&lt;li&gt;.map 
{ case (topicAndPartition, replicaSet) =&amp;gt; topicAndPartition -&amp;gt; replicaSet.size }&lt;br/&gt;
-    debug(&quot;Expected replicas per topic partition: &quot; + expectedReplicasPerTopicAndPartition)&lt;br/&gt;
-    val leadersPerBroker: Map[Int, Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicAndPartition&amp;#93;&lt;/span&gt;] = filteredTopicMetadata.flatMap { topicMetadataResponse =&amp;gt;&lt;br/&gt;
-      topicMetadataResponse.partitionsMetadata.map { partitionMetadata =&amp;gt;&lt;br/&gt;
-        (TopicAndPartition(topicMetadataResponse.topic, partitionMetadata.partitionId), partitionMetadata.leader.get.id)&lt;br/&gt;
+    val topicPartitionReplicas = filteredTopicMetadata.flatMap { topicMetadata =&amp;gt;&lt;br/&gt;
+      topicMetadata.partitions.asScala.flatMap { partitionMetadata =&amp;gt;&lt;br/&gt;
+        partitionMetadata.replicas.asScala.map { node =&amp;gt;
+          TopicPartitionReplica(topic = topicMetadata.name, partitionId = partitionMetadata.partition, replicaId = node.id)
+        }&lt;br/&gt;
+      }&lt;br/&gt;
+    }&lt;br/&gt;
+    debug(s&quot;Selected topic partitions: $topicPartitionReplicas&quot;)&lt;br/&gt;
+    val brokerToTopicPartitions = topicPartitionReplicas.groupBy(_.replicaId).map { case (brokerId, partitions) =&amp;gt;&lt;br/&gt;
+      brokerId -&amp;gt; partitions.map { partition =&amp;gt; new TopicPartition(partition.topic, partition.partitionId) }&lt;br/&gt;
+    }&lt;br/&gt;
+    debug(s&quot;Topic partitions per broker: $brokerToTopicPartitions&quot;)&lt;br/&gt;
+    val expectedReplicasPerTopicPartition = topicPartitionReplicas.groupBy { replica =&amp;gt;
+      new TopicPartition(replica.topic, replica.partitionId)
+    }.map { case (topicAndPartition, replicaSet) =&amp;gt; topicAndPartition -&amp;gt; replicaSet.size }
&lt;p&gt;+    debug(s&quot;Expected replicas per topic partition: $expectedReplicasPerTopicPartition&quot;)&lt;br/&gt;
+&lt;br/&gt;
+    val topicPartitions = filteredTopicMetadata.flatMap { topicMetaData =&amp;gt;&lt;br/&gt;
+      topicMetaData.partitions.asScala.map &lt;/p&gt;
{ partitionMetadata =&amp;gt;
+        new TopicPartition(topicMetaData.name, partitionMetadata.partition)
       }&lt;/li&gt;
	&lt;li&gt;}.groupBy(_._2).mapValues(topicAndPartitionAndLeaderIds =&amp;gt; topicAndPartitionAndLeaderIds.map 
{ case (topicAndPartition, _) =&amp;gt;
-       topicAndPartition
-     }
&lt;p&gt;)&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;debug(&quot;Leaders per broker: &quot; + leadersPerBroker)&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;val replicaBuffer = new ReplicaBuffer(expectedReplicasPerTopicAndPartition,&lt;/li&gt;
	&lt;li&gt;leadersPerBroker,&lt;/li&gt;
	&lt;li&gt;topicAndPartitionsPerBroker.size,&lt;/li&gt;
	&lt;li&gt;brokerMap,&lt;/li&gt;
	&lt;li&gt;initialOffsetTime,&lt;/li&gt;
	&lt;li&gt;reportInterval)&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    val consumerProps = consumerConfig(brokerList)&lt;br/&gt;
+&lt;br/&gt;
+    val replicaBuffer = new ReplicaBuffer(expectedReplicasPerTopicPartition,&lt;br/&gt;
+      initialOffsets(topicPartitions, consumerProps, initialOffsetTime),&lt;br/&gt;
+      brokerToTopicPartitions.size,&lt;br/&gt;
+      reportInterval)&lt;br/&gt;
     // create all replica fetcher threads&lt;/li&gt;
	&lt;li&gt;val verificationBrokerId = topicAndPartitionsPerBroker.head._1&lt;/li&gt;
	&lt;li&gt;val fetcherThreads: Iterable&lt;span class=&quot;error&quot;&gt;&amp;#91;ReplicaFetcher&amp;#93;&lt;/span&gt; = topicAndPartitionsPerBroker.map {&lt;/li&gt;
	&lt;li&gt;case (brokerId, topicAndPartitions) =&amp;gt;&lt;/li&gt;
	&lt;li&gt;new ReplicaFetcher(name = &quot;ReplicaFetcher-&quot; + brokerId,&lt;/li&gt;
	&lt;li&gt;sourceBroker = brokerMap(brokerId),&lt;/li&gt;
	&lt;li&gt;topicAndPartitions = topicAndPartitions,&lt;/li&gt;
	&lt;li&gt;replicaBuffer = replicaBuffer,&lt;/li&gt;
	&lt;li&gt;socketTimeout = 30000,&lt;/li&gt;
	&lt;li&gt;socketBufferSize = 256000,&lt;/li&gt;
	&lt;li&gt;fetchSize = fetchSize,&lt;/li&gt;
	&lt;li&gt;maxWait = maxWaitMs,&lt;/li&gt;
	&lt;li&gt;minBytes = 1,&lt;/li&gt;
	&lt;li&gt;doVerification = brokerId == verificationBrokerId)&lt;br/&gt;
+    val verificationBrokerId = brokerToTopicPartitions.head._1&lt;br/&gt;
+    val counter = new AtomicInteger(0)&lt;br/&gt;
+    val fetcherThreads: Iterable&lt;span class=&quot;error&quot;&gt;&amp;#91;ReplicaFetcher&amp;#93;&lt;/span&gt; = brokerToTopicPartitions.map 
{ case (brokerId, topicPartitions) =&amp;gt;
+      new ReplicaFetcher(name = s&quot;ReplicaFetcher-$brokerId&quot;,
+        sourceBroker = brokerInfo(brokerId),
+        topicPartitions = topicPartitions,
+        replicaBuffer = replicaBuffer,
+        socketTimeout = 30000,
+        socketBufferSize = 256000,
+        fetchSize = fetchSize,
+        maxWait = maxWaitMs,
+        minBytes = 1,
+        doVerification = brokerId == verificationBrokerId,
+        consumerProps,
+        fetcherId = counter.incrementAndGet())
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     Runtime.getRuntime.addShutdownHook(new Thread() {&lt;br/&gt;
@@ -194,87 +202,112 @@ object ReplicaVerificationTool extends Logging &lt;/p&gt;
{
     println(ReplicaVerificationTool.getCurrentTimeString() + &quot;: verification process is started.&quot;)
 
   }
&lt;p&gt;+&lt;br/&gt;
+  private def listTopicsMetadata(adminClient: admin.AdminClient): Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicDescription&amp;#93;&lt;/span&gt; = &lt;/p&gt;
{
+    val topics = adminClient.listTopics(new ListTopicsOptions().listInternal(true)).names.get
+    adminClient.describeTopics(topics).all.get.values.asScala.toBuffer
+  }
&lt;p&gt;+&lt;br/&gt;
+  private def brokerDetails(adminClient: admin.AdminClient): Map&lt;span class=&quot;error&quot;&gt;&amp;#91;Int, Node&amp;#93;&lt;/span&gt; = &lt;/p&gt;
{
+    adminClient.describeCluster.nodes.get.asScala.map(n =&amp;gt; (n.id, n)).toMap
+  }
&lt;p&gt;+&lt;br/&gt;
+  private def createAdminClient(brokerUrl: String): admin.AdminClient = &lt;/p&gt;
{
+    val props = new Properties()
+    props.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, brokerUrl)
+    admin.AdminClient.create(props)
+  }
&lt;p&gt;+&lt;br/&gt;
+  private def initialOffsets(topicPartitions: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition&amp;#93;&lt;/span&gt;, consumerConfig: Properties,&lt;br/&gt;
+                             initialOffsetTime: Long): Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, Long&amp;#93;&lt;/span&gt; = {&lt;br/&gt;
+    val consumer = createConsumer(consumerConfig)&lt;br/&gt;
+    try {&lt;br/&gt;
+      if (ListOffsetRequest.LATEST_TIMESTAMP == initialOffsetTime)&lt;br/&gt;
+        consumer.endOffsets(topicPartitions.asJava).asScala.mapValues(_.longValue).toMap&lt;br/&gt;
+      else if (ListOffsetRequest.EARLIEST_TIMESTAMP == initialOffsetTime)&lt;br/&gt;
+        consumer.beginningOffsets(topicPartitions.asJava).asScala.mapValues(_.longValue).toMap&lt;br/&gt;
+      else &lt;/p&gt;
{
+        val timestampsToSearch = topicPartitions.map(tp =&amp;gt; tp -&amp;gt; (initialOffsetTime: java.lang.Long)).toMap
+        consumer.offsetsForTimes(timestampsToSearch.asJava).asScala.mapValues(v =&amp;gt; v.offset).toMap
+      }
&lt;p&gt;+    } finally consumer.close()&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  private def consumerConfig(brokerUrl: String): Properties = &lt;/p&gt;
{
+    val properties = new Properties()
+    properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerUrl)
+    properties.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;ReplicaVerification&quot;)
+    properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, classOf[StringDeserializer])
+    properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, classOf[StringDeserializer])
+    properties
+  }
&lt;p&gt;+&lt;br/&gt;
+  private def createConsumer(consumerConfig: Properties): KafkaConsumer&lt;span class=&quot;error&quot;&gt;&amp;#91;String, String&amp;#93;&lt;/span&gt; =&lt;br/&gt;
+    new KafkaConsumer(consumerConfig)&lt;br/&gt;
 }&lt;/p&gt;

&lt;p&gt;-private case class TopicPartitionReplica(topic: String,  partitionId: Int,  replicaId: Int)&lt;br/&gt;
+private case class TopicPartitionReplica(topic: String, partitionId: Int, replicaId: Int)&lt;/p&gt;

&lt;p&gt; private case class MessageInfo(replicaId: Int, offset: Long, nextOffset: Long, checksum: Long)&lt;/p&gt;

&lt;p&gt;-private class ReplicaBuffer(expectedReplicasPerTopicAndPartition: Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicAndPartition, Int&amp;#93;&lt;/span&gt;,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;leadersPerBroker: Map[Int, Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicAndPartition&amp;#93;&lt;/span&gt;],&lt;br/&gt;
+private class ReplicaBuffer(expectedReplicasPerTopicPartition: Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, Int&amp;#93;&lt;/span&gt;,&lt;br/&gt;
+                            initialOffsets: Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, Long&amp;#93;&lt;/span&gt;,&lt;br/&gt;
                             expectedNumFetchers: Int,&lt;/li&gt;
	&lt;li&gt;brokerMap: Map&lt;span class=&quot;error&quot;&gt;&amp;#91;Int, BrokerEndPoint&amp;#93;&lt;/span&gt;,&lt;/li&gt;
	&lt;li&gt;initialOffsetTime: Long,&lt;br/&gt;
                             reportInterval: Long) extends Logging {&lt;/li&gt;
	&lt;li&gt;private val fetchOffsetMap = new Pool&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicAndPartition, Long&amp;#93;&lt;/span&gt;&lt;/li&gt;
	&lt;li&gt;private val messageSetCache = new Pool[TopicAndPartition, Pool&lt;span class=&quot;error&quot;&gt;&amp;#91;Int, FetchResponsePartitionData&amp;#93;&lt;/span&gt;]&lt;br/&gt;
+  private val fetchOffsetMap = new Pool&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, Long&amp;#93;&lt;/span&gt;&lt;br/&gt;
+  private val recordsCache = new Pool[TopicPartition, Pool[Int, FetchResponse.PartitionData&lt;span class=&quot;error&quot;&gt;&amp;#91;MemoryRecords&amp;#93;&lt;/span&gt;]]&lt;br/&gt;
   private val fetcherBarrier = new AtomicReference(new CountDownLatch(expectedNumFetchers))&lt;br/&gt;
   private val verificationBarrier = new AtomicReference(new CountDownLatch(1))&lt;br/&gt;
   @volatile private var lastReportTime = Time.SYSTEM.milliseconds&lt;br/&gt;
   private var maxLag: Long = -1L&lt;br/&gt;
   private var offsetWithMaxLag: Long = -1L&lt;/li&gt;
	&lt;li&gt;private var maxLagTopicAndPartition: TopicAndPartition = null&lt;br/&gt;
+  private var maxLagTopicAndPartition: TopicPartition = null&lt;br/&gt;
   initialize()&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def createNewFetcherBarrier() &lt;/p&gt;
{
     fetcherBarrier.set(new CountDownLatch(expectedNumFetchers))
   }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def getFetcherBarrier() = fetcherBarrier.get()&lt;br/&gt;
+  def getFetcherBarrier() = fetcherBarrier.get&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def createNewVerificationBarrier() &lt;/p&gt;
{
     verificationBarrier.set(new CountDownLatch(1))
   }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def getVerificationBarrier() = verificationBarrier.get()&lt;br/&gt;
+  def getVerificationBarrier() = verificationBarrier.get&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   private def initialize() &lt;/p&gt;
{
-    for (topicAndPartition &amp;lt;- expectedReplicasPerTopicAndPartition.keySet)
-      messageSetCache.put(topicAndPartition, new Pool[Int, FetchResponsePartitionData])
+    for (topicPartition &amp;lt;- expectedReplicasPerTopicPartition.keySet)
+      recordsCache.put(topicPartition, new Pool[Int, FetchResponse.PartitionData[MemoryRecords]])
     setInitialOffsets()
   }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private def offsetResponseStringWithError(offsetResponse: OffsetResponse): String = {&lt;/li&gt;
	&lt;li&gt;offsetResponse.partitionErrorAndOffsets.filter 
{ case (_, partitionOffsetsResponse) =&amp;gt;
-      partitionOffsetsResponse.error != Errors.NONE
-    }
&lt;p&gt;.mkString&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   private def setInitialOffsets() {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for ((brokerId, topicAndPartitions) &amp;lt;- leadersPerBroker) {&lt;/li&gt;
	&lt;li&gt;val broker = brokerMap(brokerId)&lt;/li&gt;
	&lt;li&gt;val consumer = new SimpleConsumer(broker.host, broker.port, 10000, 100000, ReplicaVerificationTool.clientId)&lt;/li&gt;
	&lt;li&gt;val initialOffsetMap: Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicAndPartition, PartitionOffsetRequestInfo&amp;#93;&lt;/span&gt; =&lt;/li&gt;
	&lt;li&gt;topicAndPartitions.map(topicAndPartition =&amp;gt; topicAndPartition -&amp;gt; PartitionOffsetRequestInfo(initialOffsetTime, 1)).toMap&lt;/li&gt;
	&lt;li&gt;val offsetRequest = OffsetRequest(initialOffsetMap)&lt;/li&gt;
	&lt;li&gt;val offsetResponse = consumer.getOffsetsBefore(offsetRequest)&lt;/li&gt;
	&lt;li&gt;assert(!offsetResponse.hasError, offsetResponseStringWithError(offsetResponse))&lt;/li&gt;
	&lt;li&gt;offsetResponse.partitionErrorAndOffsets.foreach 
{ case (topicAndPartition, partitionOffsetResponse) =&amp;gt;
-        fetchOffsetMap.put(topicAndPartition, partitionOffsetResponse.offsets.head)
-      }&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
+    for ((tp, offset) &amp;lt;- initialOffsets)&lt;br/&gt;
+      fetchOffsetMap.put(tp, offset)&lt;br/&gt;
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def addFetchedData(topicAndPartition: TopicAndPartition, replicaId: Int, partitionData: FetchResponsePartitionData) {&lt;/li&gt;
	&lt;li&gt;messageSetCache.get(topicAndPartition).put(replicaId, partitionData)&lt;br/&gt;
+  def addFetchedData(topicAndPartition: TopicPartition, replicaId: Int, partitionData: FetchResponse.PartitionData&lt;span class=&quot;error&quot;&gt;&amp;#91;MemoryRecords&amp;#93;&lt;/span&gt;) 
{
+    recordsCache.get(topicAndPartition).put(replicaId, partitionData)
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def getOffset(topicAndPartition: TopicAndPartition) = {&lt;br/&gt;
+  def getOffset(topicAndPartition: TopicPartition) = 
{
     fetchOffsetMap.get(topicAndPartition)
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def verifyCheckSum(println: String =&amp;gt; Unit) {&lt;br/&gt;
     debug(&quot;Begin verification&quot;)&lt;br/&gt;
     maxLag = -1L&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for ((topicAndPartition, fetchResponsePerReplica) &amp;lt;- messageSetCache) {&lt;/li&gt;
	&lt;li&gt;debug(&quot;Verifying &quot; + topicAndPartition)&lt;/li&gt;
	&lt;li&gt;assert(fetchResponsePerReplica.size == expectedReplicasPerTopicAndPartition(topicAndPartition),&lt;/li&gt;
	&lt;li&gt;&quot;fetched &quot; + fetchResponsePerReplica.size + &quot; replicas for &quot; + topicAndPartition + &quot;, but expected &quot;&lt;/li&gt;
	&lt;li&gt;+ expectedReplicasPerTopicAndPartition(topicAndPartition) + &quot; replicas&quot;)&lt;br/&gt;
+    for ((topicPartition, fetchResponsePerReplica) &amp;lt;- recordsCache) {&lt;br/&gt;
+      debug(&quot;Verifying &quot; + topicPartition)&lt;br/&gt;
+      assert(fetchResponsePerReplica.size == expectedReplicasPerTopicPartition(topicPartition),&lt;br/&gt;
+        &quot;fetched &quot; + fetchResponsePerReplica.size + &quot; replicas for &quot; + topicPartition + &quot;, but expected &quot;&lt;br/&gt;
+          + expectedReplicasPerTopicPartition(topicPartition) + &quot; replicas&quot;)&lt;br/&gt;
       val recordBatchIteratorMap = fetchResponsePerReplica.map 
{ case (replicaId, fetchResponse) =&amp;gt;
-        replicaId -&amp;gt; fetchResponse.messages.asInstanceOf[ByteBufferMessageSet].asRecords.batches.iterator
+        replicaId -&amp;gt; fetchResponse.records.batches.iterator
       }&lt;/li&gt;
	&lt;li&gt;val maxHw = fetchResponsePerReplica.values.map(_.hw).max&lt;br/&gt;
+      val maxHw = fetchResponsePerReplica.values.map(_.highWatermark).max&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;       // Iterate one message at a time from every replica, until high watermark is reached.&lt;br/&gt;
       var isMessageInAllReplicas = true&lt;br/&gt;
@@ -286,7 +319,7 @@ private class ReplicaBuffer(expectedReplicasPerTopicAndPartition: Map[TopicAndPa&lt;br/&gt;
               val batch = recordBatchIterator.next()&lt;/p&gt;

&lt;p&gt;               // only verify up to the high watermark&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (batch.lastOffset &amp;gt;= fetchResponsePerReplica.get(replicaId).hw)&lt;br/&gt;
+              if (batch.lastOffset &amp;gt;= fetchResponsePerReplica.get(replicaId).highWatermark)&lt;br/&gt;
                 isMessageInAllReplicas = false&lt;br/&gt;
               else {&lt;br/&gt;
                 messageInfoFromFirstReplicaOpt match {&lt;br/&gt;
@@ -295,7 +328,7 @@ private class ReplicaBuffer(expectedReplicasPerTopicAndPartition: Map[TopicAndPa&lt;br/&gt;
                       MessageInfo(replicaId, batch.lastOffset, batch.nextOffset, batch.checksum))&lt;br/&gt;
                   case Some(messageInfoFromFirstReplica) =&amp;gt;&lt;br/&gt;
                     if (messageInfoFromFirstReplica.offset != batch.lastOffset) 
{
-                      println(ReplicaVerificationTool.getCurrentTimeString + &quot;: partition &quot; + topicAndPartition
+                      println(ReplicaVerificationTool.getCurrentTimeString + &quot;: partition &quot; + topicPartition
                         + &quot;: replica &quot; + messageInfoFromFirstReplica.replicaId + &quot;&apos;s offset &quot;
                         + messageInfoFromFirstReplica.offset + &quot; doesn&apos;t match replica &quot;
                         + replicaId + &quot;&apos;s offset &quot; + batch.lastOffset)
@@ -303,7 +336,7 @@ private class ReplicaBuffer(expectedReplicasPerTopicAndPartition: Map[TopicAndPa
                     }
&lt;p&gt;                     if (messageInfoFromFirstReplica.checksum != batch.checksum)&lt;br/&gt;
                       println(ReplicaVerificationTool.getCurrentTimeString + &quot;: partition &quot;&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;+ topicAndPartition + &quot; has unmatched checksum at offset &quot; + batch.lastOffset + &quot;; replica &quot;&lt;br/&gt;
+                        + topicPartition + &quot; has unmatched checksum at offset &quot; + batch.lastOffset + &quot;; replica &quot;&lt;br/&gt;
                         + messageInfoFromFirstReplica.replicaId + &quot;&apos;s checksum &quot; + messageInfoFromFirstReplica.checksum&lt;br/&gt;
                         + &quot;; replica &quot; + replicaId + &quot;&apos;s checksum &quot; + batch.checksum)&lt;br/&gt;
                 }&lt;br/&gt;
@@ -313,20 +346,20 @@ private class ReplicaBuffer(expectedReplicasPerTopicAndPartition: Map[TopicAndPa&lt;br/&gt;
           } catch 
{
             case t: Throwable =&amp;gt;
               throw new RuntimeException(&quot;Error in processing replica %d in partition %s at offset %d.&quot;
-              .format(replicaId, topicAndPartition, fetchOffsetMap.get(topicAndPartition)), t)
+                .format(replicaId, topicPartition, fetchOffsetMap.get(topicPartition)), t)
           }
&lt;p&gt;         }&lt;br/&gt;
         if (isMessageInAllReplicas) &lt;/p&gt;
{
           val nextOffset = messageInfoFromFirstReplicaOpt.get.nextOffset
-          fetchOffsetMap.put(topicAndPartition, nextOffset)
-          debug(expectedReplicasPerTopicAndPartition(topicAndPartition) + &quot; replicas match at offset &quot; +
-                nextOffset + &quot; for &quot; + topicAndPartition)
+          fetchOffsetMap.put(topicPartition, nextOffset)
+          debug(expectedReplicasPerTopicPartition(topicPartition) + &quot; replicas match at offset &quot; +
+            nextOffset + &quot; for &quot; + topicPartition)
         }
&lt;p&gt;       }&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;if (maxHw - fetchOffsetMap.get(topicAndPartition) &amp;gt; maxLag) {&lt;/li&gt;
	&lt;li&gt;offsetWithMaxLag = fetchOffsetMap.get(topicAndPartition)&lt;br/&gt;
+      if (maxHw - fetchOffsetMap.get(topicPartition) &amp;gt; maxLag) 
{
+        offsetWithMaxLag = fetchOffsetMap.get(topicPartition)
         maxLag = maxHw - offsetWithMaxLag
-        maxLagTopicAndPartition = topicAndPartition
+        maxLagTopicAndPartition = topicPartition
       }
&lt;p&gt;       fetchResponsePerReplica.clear()&lt;br/&gt;
     }&lt;br/&gt;
@@ -334,51 +367,54 @@ private class ReplicaBuffer(expectedReplicasPerTopicAndPartition: Map[TopicAndPa&lt;br/&gt;
     if (currentTimeMs - lastReportTime &amp;gt; reportInterval) &lt;/p&gt;
{
       println(ReplicaVerificationTool.dateFormat.format(new Date(currentTimeMs)) + &quot;: max lag is &quot;
         + maxLag + &quot; for partition &quot; + maxLagTopicAndPartition + &quot; at offset &quot; + offsetWithMaxLag
-        + &quot; among &quot; + messageSetCache.size + &quot; partitions&quot;)
+        + &quot; among &quot; + recordsCache.size + &quot; partitions&quot;)
       lastReportTime = currentTimeMs
     }
&lt;p&gt;   }&lt;br/&gt;
 }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;-private class ReplicaFetcher(name: String, sourceBroker: BrokerEndPoint, topicAndPartitions: Iterable&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicAndPartition&amp;#93;&lt;/span&gt;,&lt;br/&gt;
+private class ReplicaFetcher(name: String, sourceBroker: Node, topicPartitions: Iterable&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition&amp;#93;&lt;/span&gt;,&lt;br/&gt;
                              replicaBuffer: ReplicaBuffer, socketTimeout: Int, socketBufferSize: Int,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;fetchSize: Int, maxWait: Int, minBytes: Int, doVerification: Boolean)&lt;br/&gt;
+                             fetchSize: Int, maxWait: Int, minBytes: Int, doVerification: Boolean, consumerConfig: Properties,&lt;br/&gt;
+                             fetcherId: Int)&lt;br/&gt;
   extends ShutdownableThread(name) {&lt;/li&gt;
	&lt;li&gt;val simpleConsumer = new SimpleConsumer(sourceBroker.host, sourceBroker.port, socketTimeout, socketBufferSize, ReplicaVerificationTool.clientId)&lt;/li&gt;
	&lt;li&gt;val fetchRequestBuilder = new FetchRequestBuilder().&lt;/li&gt;
	&lt;li&gt;clientId(ReplicaVerificationTool.clientId).&lt;/li&gt;
	&lt;li&gt;replicaId(Request.DebuggingConsumerId).&lt;/li&gt;
	&lt;li&gt;maxWait(maxWait).&lt;/li&gt;
	&lt;li&gt;minBytes(minBytes)&lt;br/&gt;
+&lt;br/&gt;
+  private val fetchEndpoint = new ReplicaFetcherBlockingSend(sourceBroker, new ConsumerConfig(consumerConfig), new Metrics(), Time.SYSTEM, fetcherId,&lt;br/&gt;
+    s&quot;broker-${Request.DebuggingConsumerId}&lt;del&gt;fetcher&lt;/del&gt;$fetcherId&quot;)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   override def doWork() {&lt;/p&gt;

&lt;p&gt;     val fetcherBarrier = replicaBuffer.getFetcherBarrier()&lt;br/&gt;
     val verificationBarrier = replicaBuffer.getVerificationBarrier()&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for (topicAndPartition &amp;lt;- topicAndPartitions)&lt;/li&gt;
	&lt;li&gt;fetchRequestBuilder.addFetch(topicAndPartition.topic, topicAndPartition.partition,&lt;/li&gt;
	&lt;li&gt;replicaBuffer.getOffset(topicAndPartition), fetchSize)&lt;br/&gt;
+    val requestMap = new util.LinkedHashMap&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, JFetchRequest.PartitionData&amp;#93;&lt;/span&gt;&lt;br/&gt;
+    for (topicPartition &amp;lt;- topicPartitions)&lt;br/&gt;
+      requestMap.put(topicPartition, new JFetchRequest.PartitionData(replicaBuffer.getOffset(topicPartition), 0L, fetchSize))&lt;br/&gt;
+&lt;br/&gt;
+    val fetchRequestBuilder = JFetchRequest.Builder.&lt;br/&gt;
+      forReplica(ApiKeys.FETCH.latestVersion, Request.DebuggingConsumerId, maxWait, minBytes, requestMap)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val fetchRequest = fetchRequestBuilder.build()&lt;/li&gt;
	&lt;li&gt;debug(&quot;Issuing fetch request &quot; + fetchRequest)&lt;br/&gt;
+    debug(&quot;Issuing fetch request &quot;)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;var response: FetchResponse = null&lt;br/&gt;
+    var fetchResponse: FetchResponse&lt;span class=&quot;error&quot;&gt;&amp;#91;MemoryRecords&amp;#93;&lt;/span&gt; = null&lt;br/&gt;
     try 
{
-      response = simpleConsumer.fetch(fetchRequest)
+      val clientResponse = fetchEndpoint.sendRequest(fetchRequestBuilder)
+      fetchResponse = clientResponse.responseBody.asInstanceOf[FetchResponse[MemoryRecords]]
     }
&lt;p&gt; catch &lt;/p&gt;
{
       case t: Throwable =&amp;gt;
         if (!isRunning)
           throw t
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (response != null) {&lt;/li&gt;
	&lt;li&gt;response.data.foreach { case (topicAndPartition, partitionData) =&amp;gt;&lt;/li&gt;
	&lt;li&gt;replicaBuffer.addFetchedData(topicAndPartition, sourceBroker.id, partitionData)&lt;br/&gt;
+    if (fetchResponse != null) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+      fetchResponse.responseData.asScala.foreach { case (tp, partitionData) =&amp;gt;
+        replicaBuffer.addFetchedData(tp, sourceBroker.id, partitionData)
       }     }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt; else &lt;/p&gt;
{
-      for (topicAndPartition &amp;lt;- topicAndPartitions)
-        replicaBuffer.addFetchedData(topicAndPartition, sourceBroker.id, new FetchResponsePartitionData(messages = MessageSet.Empty))
+      val emptyResponse = new FetchResponse.PartitionData(Errors.NONE, FetchResponse.INVALID_HIGHWATERMARK,
+        FetchResponse.INVALID_LAST_STABLE_OFFSET, FetchResponse.INVALID_LOG_START_OFFSET, null, MemoryRecords.EMPTY)
+      for (topicAndPartition &amp;lt;- topicPartitions)
+        replicaBuffer.addFetchedData(topicAndPartition, sourceBroker.id, emptyResponse)
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     fetcherBarrier.countDown()&lt;br/&gt;
@@ -402,3 +438,64 @@ private class ReplicaFetcher(name: String, sourceBroker: BrokerEndPoint, topicAn&lt;br/&gt;
     debug(&quot;Done verification&quot;)&lt;br/&gt;
   }&lt;br/&gt;
 }&lt;br/&gt;
+&lt;br/&gt;
+private class ReplicaFetcherBlockingSend(sourceNode: Node,&lt;br/&gt;
+                                         consumerConfig: ConsumerConfig,&lt;br/&gt;
+                                         metrics: Metrics,&lt;br/&gt;
+                                         time: Time,&lt;br/&gt;
+                                         fetcherId: Int,&lt;br/&gt;
+                                         clientId: String) {&lt;br/&gt;
+&lt;br/&gt;
+  private val socketTimeout: Int = consumerConfig.getInt(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG)&lt;br/&gt;
+&lt;br/&gt;
+  private val networkClient = &lt;/p&gt;
{
+    val channelBuilder = org.apache.kafka.clients.ClientUtils.createChannelBuilder(consumerConfig)
+    val selector = new Selector(
+      NetworkReceive.UNLIMITED,
+      consumerConfig.getLong(ConsumerConfig.CONNECTIONS_MAX_IDLE_MS_CONFIG),
+      metrics,
+      time,
+      &quot;replica-fetcher&quot;,
+      Map(&quot;broker-id&quot; -&amp;gt; sourceNode.id.toString, &quot;fetcher-id&quot; -&amp;gt; fetcherId.toString).asJava,
+      false,
+      channelBuilder,
+      new LogContext
+    )
+    new NetworkClient(
+      selector,
+      new ManualMetadataUpdater(),
+      clientId,
+      1,
+      0,
+      0,
+      Selectable.USE_DEFAULT_BUFFER_SIZE,
+      consumerConfig.getInt(ConsumerConfig.RECEIVE_BUFFER_CONFIG),
+      consumerConfig.getInt(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG),
+      time,
+      false,
+      new ApiVersions,
+      new LogContext
+    )
+  }
&lt;p&gt;+&lt;br/&gt;
+  def sendRequest(requestBuilder: Builder&lt;span class=&quot;error&quot;&gt;&amp;#91;_ &amp;lt;: AbstractRequest&amp;#93;&lt;/span&gt;): ClientResponse = {&lt;br/&gt;
+    try {&lt;br/&gt;
+      if (!NetworkClientUtils.awaitReady(networkClient, sourceNode, time, socketTimeout))&lt;br/&gt;
+        throw new SocketTimeoutException(s&quot;Failed to connect within $socketTimeout ms&quot;)&lt;br/&gt;
+      else &lt;/p&gt;
{
+        val clientRequest = networkClient.newClientRequest(sourceNode.id.toString, requestBuilder,
+          time.milliseconds(), true)
+        NetworkClientUtils.sendAndReceive(networkClient, clientRequest, time)
+      }
&lt;p&gt;+    }&lt;br/&gt;
+    catch &lt;/p&gt;
{
+      case e: Throwable =&amp;gt;
+        networkClient.close(sourceNode.id.toString)
+        throw e
+    }
&lt;p&gt;+  }&lt;br/&gt;
+&lt;br/&gt;
+  def close(): Unit = &lt;/p&gt;
{
+    networkClient.close()
+  }
&lt;p&gt;+}&lt;br/&gt;
diff --git a/core/src/test/scala/kafka/tools/ReplicaVerificationToolTest.scala b/core/src/test/scala/kafka/tools/ReplicaVerificationToolTest.scala&lt;br/&gt;
index 211413a341f..f69c9092265 100644&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/kafka/tools/ReplicaVerificationToolTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/kafka/tools/ReplicaVerificationToolTest.scala&lt;br/&gt;
@@ -17,11 +17,10 @@&lt;/p&gt;

&lt;p&gt; package kafka.tools&lt;/p&gt;

&lt;p&gt;-import kafka.api.FetchResponsePartitionData&lt;br/&gt;
-import kafka.common.TopicAndPartition&lt;br/&gt;
-import kafka.message.ByteBufferMessageSet&lt;br/&gt;
+import org.apache.kafka.common.TopicPartition&lt;br/&gt;
 import org.apache.kafka.common.protocol.Errors&lt;br/&gt;
-import org.apache.kafka.common.record.&lt;/p&gt;
{CompressionType, SimpleRecord, MemoryRecords}
&lt;p&gt;+import org.apache.kafka.common.record.&lt;/p&gt;
{CompressionType, MemoryRecords, SimpleRecord}
&lt;p&gt;+import org.apache.kafka.common.requests.FetchResponse&lt;br/&gt;
 import org.junit.Test&lt;br/&gt;
 import org.junit.Assert.assertTrue&lt;/p&gt;

&lt;p&gt;@@ -32,12 +31,12 @@ class ReplicaVerificationToolTest {&lt;br/&gt;
     val sb = new StringBuilder&lt;/p&gt;

&lt;p&gt;     val expectedReplicasPerTopicAndPartition = Map(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;TopicAndPartition(&quot;a&quot;, 0) -&amp;gt; 3,&lt;/li&gt;
	&lt;li&gt;TopicAndPartition(&quot;a&quot;, 1) -&amp;gt; 3,&lt;/li&gt;
	&lt;li&gt;TopicAndPartition(&quot;b&quot;, 0) -&amp;gt; 2&lt;br/&gt;
+      new TopicPartition(&quot;a&quot;, 0) -&amp;gt; 3,&lt;br/&gt;
+      new TopicPartition(&quot;a&quot;, 1) -&amp;gt; 3,&lt;br/&gt;
+      new TopicPartition(&quot;b&quot;, 0) -&amp;gt; 2&lt;br/&gt;
     )&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val replicaBuffer = new ReplicaBuffer(expectedReplicasPerTopicAndPartition, Map.empty, 2, Map.empty, 0, 0)&lt;br/&gt;
+    val replicaBuffer = new ReplicaBuffer(expectedReplicasPerTopicAndPartition, Map.empty, 2, 0)&lt;br/&gt;
     expectedReplicasPerTopicAndPartition.foreach { case (tp, numReplicas) =&amp;gt;&lt;br/&gt;
       (0 until numReplicas).foreach { replicaId =&amp;gt;&lt;br/&gt;
         val records = (0 to 5).map { index =&amp;gt;&lt;br/&gt;
@@ -45,8 +44,9 @@ class ReplicaVerificationToolTest {&lt;br/&gt;
         }&lt;br/&gt;
         val initialOffset = 4&lt;br/&gt;
         val memoryRecords = MemoryRecords.withRecords(initialOffset, CompressionType.NONE, records: _*)&lt;/li&gt;
	&lt;li&gt;replicaBuffer.addFetchedData(tp, replicaId, new FetchResponsePartitionData(Errors.NONE, hw = 20,&lt;/li&gt;
	&lt;li&gt;new ByteBufferMessageSet(memoryRecords.buffer)))&lt;br/&gt;
+        val partitionData = new FetchResponse.PartitionData(Errors.NONE, 20, 20, 0L, null, memoryRecords)&lt;br/&gt;
+&lt;br/&gt;
+        replicaBuffer.addFetchedData(tp, replicaId, partitionData)&lt;br/&gt;
       }&lt;br/&gt;
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -55,7 +55,7 @@ class ReplicaVerificationToolTest &lt;/p&gt;
{
 
     // If you change this assertion, you should verify that the replica_verification_test.py system test still passes
     assertTrue(s&quot;Max lag information should be in output: `$output`&quot;,
-      output.endsWith(&quot;: max lag is 10 for partition a-0 at offset 10 among 3 partitions&quot;))
+      output.endsWith(&quot;: max lag is 10 for partition a-1 at offset 10 among 3 partitions&quot;))
   }

&lt;p&gt; }&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 23 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3up4f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>