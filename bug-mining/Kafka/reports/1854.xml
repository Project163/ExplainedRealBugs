<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:08:15 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6661] Sink connectors that explicitly &apos;resume&apos; topic partitions can resume a paused task</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6661</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Sink connectors are allowed to use the &lt;tt&gt;SinkTaskContext&lt;/tt&gt;&apos;s methods to explicitly pause and resume topic partitions. This is useful when connectors need additional time processing the records for specific topic partitions (e.g., the external system has an outage).&lt;/p&gt;

&lt;p&gt;However, when the sink connector has been paused via the REST API, the worker for the sink tasks pause the consumer. When the connector is polled, the poll request might timeout and return no records. Connect then calls the task&apos;s &lt;tt&gt;put(...)&lt;/tt&gt; method (with no records), and this allows the task to optionally call any of the &lt;tt&gt;SinkTaskContext&lt;/tt&gt;&apos;s pause or resume methods. If it calls resume, this will unexpectedly resume the paused consumer, causing the consumer to return messages and the connector to process those messages &amp;#8211;  despite the connector still being paused.&lt;/p&gt;

&lt;p&gt;This is reported against 1.0, but the affected code has not been changed since at least 0.9.0.0.&lt;/p&gt;

&lt;p&gt;A workaround is to remove rather than pause a connector. It&apos;s inconvenient, but it works.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13145205">KAFKA-6661</key>
            <summary>Sink connectors that explicitly &apos;resume&apos; topic partitions can resume a paused task</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rhauch">Randall Hauch</assignee>
                                    <reporter username="rhauch">Randall Hauch</reporter>
                        <labels>
                    </labels>
                <created>Wed, 14 Mar 2018 22:53:37 +0000</created>
                <updated>Mon, 19 Mar 2018 23:18:30 +0000</updated>
                            <resolved>Mon, 19 Mar 2018 23:18:30 +0000</resolved>
                                    <version>0.9.0.0</version>
                    <version>0.10.0.0</version>
                    <version>0.11.0.0</version>
                    <version>1.0.0</version>
                                    <fixVersion>0.10.0.2</fixVersion>
                    <fixVersion>0.10.1.2</fixVersion>
                    <fixVersion>0.10.2.2</fixVersion>
                    <fixVersion>0.11.0.3</fixVersion>
                    <fixVersion>1.0.2</fixVersion>
                    <fixVersion>1.1.1</fixVersion>
                                    <component>connect</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="16399567" author="rhauch" created="Wed, 14 Mar 2018 22:57:25 +0000"  >&lt;p&gt;After a connector is paused, the sink task worker will call &lt;tt&gt;consumer.poll(long)&lt;/tt&gt;, which blocks and then times out after the configurable timeout period, returning 0 records:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[2018-03-13 18:21:33,756] TRACE WorkerSinkTask{id=s3-sink-0} Polling consumer with timeout 76631 ms (org.apache.kafka.connect.runtime.WorkerSinkTask:282)
...
[2018-03-13 18:21:33,758] DEBUG WorkerSinkTask{id=s3-sink-0} Finished offset commit successfully in 6 ms for sequence number 1: {s3_topic-0=OffsetAndMetadata{offset=27300, metadata=&apos;&apos;}} (org.apache.kafka.connect.runtime.WorkerSinkTask:238)
[2018-03-13 18:21:33,758] DEBUG WorkerSinkTask{id=s3-sink-0} Setting last committed offsets to {s3_topic-0=OffsetAndMetadata{offset=27300, metadata=&apos;&apos;}} (org.apache.kafka.connect.runtime.WorkerSinkTask:241)
...
[2018-03-13 18:22:50,391] TRACE WorkerSinkTask{id=s3-sink-0} Polling returned 0 messages (org.apache.kafka.connect.runtime.WorkerSinkTask:285)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The worker then processes and delivers the 0 messages to the connector, at which point the connector might ultimately call a method that calls &lt;tt&gt;WorkerSinkTaskContext.resume(...)&lt;/tt&gt;, which currently &lt;b&gt;&lt;em&gt;resumes the consumer regardless whether the connector is paused&lt;/em&gt;&lt;/b&gt;.&lt;/p&gt;

&lt;p&gt;Here&apos;s a stack trace showing this:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;&quot;pool-1-thread-1@4159&quot; prio=5 tid=0x1b nid=NA runnable
  java.lang.Thread.State: RUNNABLE
	  at org.apache.kafka.clients.consumer.KafkaConsumer.resume(KafkaConsumer.java:1542)
	  at org.apache.kafka.connect.runtime.WorkerSinkTaskContext.resume(WorkerSinkTaskContext.java:109)
	  at io.confluent.connect.s3.TopicPartitionWriter.resume(TopicPartitionWriter.java:405)
	  at io.confluent.connect.s3.TopicPartitionWriter.commitOnTimeIfNoData(TopicPartitionWriter.java:295)
	  at io.confluent.connect.s3.TopicPartitionWriter.write(TopicPartitionWriter.java:177)
	  at io.confluent.connect.s3.S3SinkTask.put(S3SinkTask.java:195)
	  at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:495)
	  at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:288)
	  at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:198)
	  at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:166)
	  at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:170)
	  at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:214)
	  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	  at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	  at java.lang.Thread.run(Thread.java:748)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16399573" author="rhauch" created="Wed, 14 Mar 2018 23:01:35 +0000"  >&lt;p&gt;The &lt;tt&gt;WorkerSinkTask&lt;/tt&gt; and &lt;tt&gt;WorkerSinkTaskContext&lt;/tt&gt; both deal with pausing and resuming the consumer. Most of this logic is correct:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;tt&gt;WorkerSinkTaskContext&lt;/tt&gt; is already tracking the topic partitions that have been explicitly paused or resumed by the connector&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;WorkerSinkTaskContext.pause(TopicPartition...)&lt;/tt&gt; adds the topic partitions to its paused set and always pauses those topic partitions in the consumer&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;WorkerSinkTaskContext.resume(TopicPartition...)&lt;/tt&gt; removes the topic partitions from its paused set and &lt;b&gt;&lt;em&gt;always&lt;/em&gt;&lt;/b&gt; resumes those topic partitions in the consumer. &lt;b&gt;The &lt;em&gt;always&lt;/em&gt; part is what is incorrect; it should still remove the topic partitions from its set but should only tell the consumer to resume the topic partitions &lt;em&gt;when the consumer is not paused&lt;/em&gt;.&lt;/b&gt;&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;WorkerSinkTask.pauseAll()&lt;/tt&gt; currently pauses all of the partitions, but does not use or change the context&apos;s set of paused partitions&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;WorkerSinkTask.resumeAll()&lt;/tt&gt; currently resumes all topic partitions &lt;b&gt;&lt;em&gt;except&lt;/em&gt;&lt;/b&gt; those that are still explicitly paused in the context&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;So, I think the only change that needs to be made is that &lt;tt&gt;WorkerSinkTaskContext.resume(TopicPartition...)&lt;/tt&gt; should still remove the topic partitions from its set but should only tell the consumer to resume the topic partitions &lt;em&gt;when the consumer is not paused&lt;/em&gt;.&lt;/p&gt;</comment>
                            <comment id="16399681" author="githubbot" created="Thu, 15 Mar 2018 00:44:30 +0000"  >&lt;p&gt;rhauch opened a new pull request #4716: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6661&quot; title=&quot;Sink connectors that explicitly &amp;#39;resume&amp;#39; topic partitions can resume a paused task&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6661&quot;&gt;&lt;del&gt;KAFKA-6661&lt;/del&gt;&lt;/a&gt;: Ensure sink connectors don&#8217;t resume consumer when task is paused&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4716&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4716&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Changed WorkerSinkTaskContext to only resume the consumer topic partitions when the connector/task is not in the paused state.&lt;/p&gt;

&lt;p&gt;   The context tracks the set of topic partitions that are explicitly paused/resumed by the connector, and when the WorkerSinkTask resumes the tasks it currently resumes all topic partitions &lt;b&gt;except&lt;/b&gt; those that are still explicitly paused in the context. Therefore, the change above should result in the desired behavior.&lt;/p&gt;

&lt;p&gt;   Several debug statements were added to record when the context is called by the connector.&lt;/p&gt;

&lt;p&gt;   This can be backported to older releases, since this bug goes back to 0.10 or 0.9.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16401219" author="githubbot" created="Thu, 15 Mar 2018 22:54:27 +0000"  >&lt;p&gt;ewencp closed pull request #4716: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6661&quot; title=&quot;Sink connectors that explicitly &amp;#39;resume&amp;#39; topic partitions can resume a paused task&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6661&quot;&gt;&lt;del&gt;KAFKA-6661&lt;/del&gt;&lt;/a&gt;: Ensure sink connectors don&#8217;t resume consumer when task is paused&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4716&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4716&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java&lt;br/&gt;
index 2995a4e813a..2ba785c4668 100644&lt;br/&gt;
&amp;#8212; a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java&lt;br/&gt;
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java&lt;br/&gt;
@@ -130,7 +130,7 @@ public void initialize(TaskConfig taskConfig) {&lt;br/&gt;
         try &lt;/p&gt;
{
             this.taskConfig = taskConfig.originalsStrings();
             this.consumer = createConsumer();
-            this.context = new WorkerSinkTaskContext(consumer);
+            this.context = new WorkerSinkTaskContext(consumer, this);
         }
&lt;p&gt; catch (Throwable t) {&lt;br/&gt;
             log.error(&quot;{} Task failed initialization and will not be started.&quot;, this, t);&lt;br/&gt;
             onFailure(t);&lt;br/&gt;
@@ -601,7 +601,7 @@ SinkTaskMetricsGroup sinkTaskMetricsGroup() {&lt;br/&gt;
     private class HandleRebalance implements ConsumerRebalanceListener {&lt;br/&gt;
         @Override&lt;br/&gt;
         public void onPartitionsAssigned(Collection&amp;lt;TopicPartition&amp;gt; partitions) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;log.debug(&quot;{} Partitions assigned&quot;, WorkerSinkTask.this);&lt;br/&gt;
+            log.debug(&quot;{} Partitions assigned {}&quot;, WorkerSinkTask.this, partitions);&lt;br/&gt;
             lastCommittedOffsets = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
             currentOffsets = new HashMap&amp;lt;&amp;gt;();&lt;br/&gt;
             for (TopicPartition tp : partitions) {&lt;br/&gt;
diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTaskContext.java b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTaskContext.java&lt;br/&gt;
index 08789497645..386f992e82a 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTaskContext.java&lt;br/&gt;
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTaskContext.java&lt;br/&gt;
@@ -20,6 +20,8 @@&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition;&lt;br/&gt;
 import org.apache.kafka.connect.errors.IllegalWorkerStateException;&lt;br/&gt;
 import org.apache.kafka.connect.sink.SinkTaskContext;&lt;br/&gt;
+import org.slf4j.Logger;&lt;br/&gt;
+import org.slf4j.LoggerFactory;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import java.util.Arrays;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
@@ -29,26 +31,32 @@&lt;br/&gt;
 import java.util.Set;&lt;/p&gt;

&lt;p&gt; public class WorkerSinkTaskContext implements SinkTaskContext {&lt;br/&gt;
+&lt;br/&gt;
+    private final Logger log = LoggerFactory.getLogger(getClass());&lt;br/&gt;
     private Map&amp;lt;TopicPartition, Long&amp;gt; offsets;&lt;br/&gt;
     private long timeoutMs;&lt;br/&gt;
     private KafkaConsumer&amp;lt;byte[], byte[]&amp;gt; consumer;&lt;br/&gt;
+    private final WorkerSinkTask sinkTask;&lt;br/&gt;
     private final Set&amp;lt;TopicPartition&amp;gt; pausedPartitions;&lt;br/&gt;
     private boolean commitRequested;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public WorkerSinkTaskContext(KafkaConsumer&amp;lt;byte[], byte[]&amp;gt; consumer) {&lt;br/&gt;
+    public WorkerSinkTaskContext(KafkaConsumer&amp;lt;byte[], byte[]&amp;gt; consumer, WorkerSinkTask sinkTask) 
{
         this.offsets = new HashMap&amp;lt;&amp;gt;();
         this.timeoutMs = -1L;
         this.consumer = consumer;
+        this.sinkTask = sinkTask;
         this.pausedPartitions = new HashSet&amp;lt;&amp;gt;();
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @Override&lt;br/&gt;
     public void offset(Map&amp;lt;TopicPartition, Long&amp;gt; offsets) {&lt;br/&gt;
+        log.debug(&quot;{} Setting offsets for topic partitions {}&quot;, this, offsets);&lt;br/&gt;
         this.offsets.putAll(offsets);&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;     @Override&lt;br/&gt;
     public void offset(TopicPartition tp, long offset) {&lt;br/&gt;
+        log.debug(&quot;{} Setting offset for topic partition {} to {}&quot;, this, tp, offset);&lt;br/&gt;
         offsets.put(tp, offset);&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;@@ -66,6 +74,7 @@ public void clearOffsets() {&lt;/p&gt;

&lt;p&gt;     @Override&lt;br/&gt;
     public void timeout(long timeoutMs) {&lt;br/&gt;
+        log.debug(&quot;{} Setting timeout to {} ms&quot;, this, timeoutMs);&lt;br/&gt;
         this.timeoutMs = timeoutMs;&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;@@ -92,7 +101,12 @@ public void pause(TopicPartition... partitions) {&lt;br/&gt;
         }&lt;br/&gt;
         try {&lt;br/&gt;
             Collections.addAll(pausedPartitions, partitions);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;consumer.pause(Arrays.asList(partitions));&lt;br/&gt;
+            if (sinkTask.shouldPause()) {&lt;br/&gt;
+                log.debug(&quot;{} Connector is paused, so not pausing consumer&apos;s partitions {}&quot;, this, partitions);&lt;br/&gt;
+            } else {&lt;br/&gt;
+                consumer.pause(Arrays.asList(partitions));&lt;br/&gt;
+                log.debug(&quot;{} Pausing partitions {}. Connector is not paused.&quot;, this, partitions);&lt;br/&gt;
+            }&lt;br/&gt;
         } catch (IllegalStateException e) 
{
             throw new IllegalWorkerStateException(&quot;SinkTasks may not pause partitions that are not currently assigned to them.&quot;, e);
         }
&lt;p&gt;@@ -105,7 +119,12 @@ public void resume(TopicPartition... partitions) {&lt;br/&gt;
         }&lt;br/&gt;
         try {&lt;br/&gt;
             pausedPartitions.removeAll(Arrays.asList(partitions));&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;consumer.resume(Arrays.asList(partitions));&lt;br/&gt;
+            if (sinkTask.shouldPause()) {&lt;br/&gt;
+                log.debug(&quot;{} Connector is paused, so not resuming consumer&apos;s partitions {}&quot;, this, partitions);&lt;br/&gt;
+            } else {&lt;br/&gt;
+                consumer.resume(Arrays.asList(partitions));&lt;br/&gt;
+                log.debug(&quot;{} Resuming partitions: {}&quot;, this, partitions);&lt;br/&gt;
+            }&lt;br/&gt;
         } catch (IllegalStateException e) 
{
             throw new IllegalWorkerStateException(&quot;SinkTasks may not resume partitions that are not currently assigned to them.&quot;, e);
         }
&lt;p&gt;@@ -117,6 +136,7 @@ public void resume(TopicPartition... partitions) {&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @Override&lt;br/&gt;
     public void requestCommit() {&lt;br/&gt;
+        log.debug(&quot;{} Requesting commit&quot;, this);&lt;br/&gt;
         commitRequested = true;&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;@@ -128,4 +148,10 @@ public void clearCommitRequest() &lt;/p&gt;
{
         commitRequested = false;
     }

&lt;p&gt;+    @Override&lt;br/&gt;
+    public String toString() {&lt;br/&gt;
+        return &quot;WorkerSinkTaskContext&lt;/p&gt;
{&quot; +
+               &quot;id=&quot; + sinkTask.id +
+               &apos;}
&lt;p&gt;&apos;;&lt;br/&gt;
+    }&lt;br/&gt;
 }&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16401254" author="ewencp" created="Thu, 15 Mar 2018 23:23:10 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rhauch&quot; class=&quot;user-hover&quot; rel=&quot;rhauch&quot;&gt;rhauch&lt;/a&gt; Got this cherry-picked back to 0.10.0. If we want 0.9.0 as well, we probably need a separate PR since there was enough code movement to make it non-trivial.&lt;/p&gt;

&lt;p&gt;On a related note, it wasn&apos;t too bad in this case, but for things we want to backport its better to separate the must-have stuff from the nice-to-have improvements. It&apos;s not so much the risk (in this case it was just a toString and some log statements), but that the larger the patch, the less likely we get a clean cherry-pick and that&apos;s a lot more time consuming in cases where we want to cherry-pick through a bunch of release branches. In this case the pain was really caused by a different commit that mostly made cosmetic improvements that make cherry-picking encounter conflicts, but something to keep in mind in the future.&lt;/p&gt;</comment>
                            <comment id="16401255" author="ewencp" created="Thu, 15 Mar 2018 23:23:43 +0000"  >&lt;p&gt;Oh, also, I marked it as 1.1.1 release, but if we end up doing another RC we&apos;ll want to adjust this to 1.1.0.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 35 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3rbdr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>