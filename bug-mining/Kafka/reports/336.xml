<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:39:02 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-946] Kafka Hadoop Consumer fails when verifying message checksum</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-946</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;The code tries to verify the checksum, but fails because the data available isn&apos;t the same. In KafkaETLContext:&lt;/p&gt;

&lt;p&gt;    protected boolean get(KafkaETLKey key, BytesWritable value) throws IOException {&lt;br/&gt;
	if (_messageIt != null &amp;amp;&amp;amp; _messageIt.hasNext()) &lt;/p&gt;
{
            MessageAndOffset messageAndOffset = _messageIt.next();

            ByteBuffer buf = messageAndOffset.message().payload();
            int origSize = buf.remaining();
            byte[] bytes = new byte[origSize];
          buf.get(bytes, buf.position(), origSize);
            value.set(bytes, 0, origSize);

            key.set(_index, _offset, messageAndOffset.message().checksum());

            _offset = messageAndOffset.nextOffset();  //increase offset                                                                                                                                  
            _count ++;  //increase count                                                                                                                                                                 

            return true;
        }
&lt;p&gt;        else return false;&lt;br/&gt;
    }&lt;/p&gt;

&lt;p&gt;Note that the message payload is used and the message checksum is included in the key. The in SimpleKafkaETLMapper:&lt;/p&gt;

&lt;p&gt;    @Override&lt;br/&gt;
    public void map(KafkaETLKey key, BytesWritable val,&lt;br/&gt;
            OutputCollector&amp;lt;LongWritable, Text&amp;gt; collector,&lt;br/&gt;
            Reporter reporter) throws IOException {&lt;/p&gt;


&lt;p&gt;	byte[] bytes = KafkaETLUtils.getBytes(val);&lt;/p&gt;

&lt;p&gt;        //check the checksum of message                                                                                                                                                                  &lt;br/&gt;
        Message message = new Message(bytes);&lt;br/&gt;
        long checksum = key.getChecksum();&lt;br/&gt;
	if (checksum != message.checksum())&lt;br/&gt;
            throw new IOException (&quot;Invalid message checksum &quot;&lt;br/&gt;
                                            + message.checksum() + &quot;. Expected &quot; + key + &quot;.&quot;);&lt;/p&gt;

&lt;p&gt;the Message object is initialized with the payload bytes and a new checksum is calculated. The problem is that the original message checksum also contains the key so checksum verification fails...&lt;/p&gt;</description>
                <environment></environment>
        <key id="12653547">KAFKA-946</key>
            <summary>Kafka Hadoop Consumer fails when verifying message checksum</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="smeder">Sam Meder</assignee>
                                    <reporter username="smeder">Sam Meder</reporter>
                        <labels>
                    </labels>
                <created>Tue, 18 Jun 2013 18:28:38 +0000</created>
                <updated>Tue, 24 Sep 2013 15:32:06 +0000</updated>
                            <resolved>Tue, 24 Sep 2013 15:31:54 +0000</resolved>
                                    <version>0.8.0</version>
                                    <fixVersion>0.8.0</fixVersion>
                                    <component>contrib</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="13687046" author="smeder" created="Tue, 18 Jun 2013 18:33:49 +0000"  >&lt;p&gt;Attached a patch that simply passes the full message buffer instead of just the payload...&lt;/p&gt;</comment>
                            <comment id="13698427" author="jkreps" created="Wed, 3 Jul 2013 00:10:04 +0000"  >&lt;p&gt;Ack, well that&apos;s broken.&lt;/p&gt;

&lt;p&gt;Richard--is this a reasonable thing to do?&lt;br/&gt;
Jun--any concern with this going in 0.8?&lt;/p&gt;

&lt;p&gt;A meta question is how to handle the poor state of maintenance of this Hadoop code. Started a discussion on that on the mailing list...&lt;/p&gt;</comment>
                            <comment id="13706465" author="jkreps" created="Thu, 11 Jul 2013 23:41:05 +0000"  >&lt;p&gt;From Richard:&lt;/p&gt;

&lt;p&gt;Sorry, It took a while to remember the context.&lt;br/&gt;
In a Kafka Message, the checksum is created on the whole message: header and payload included.&lt;/p&gt;

&lt;p&gt;The contrib code passes only the Message payload to the mapper, and not the whole buffer. I believe the reason for this is that we wanted to pass just the message data (not any of the kafka special bits) for the mapper handle. The Message that is created in the SimpleKafkaETLMapper is then creating using the incorrect payload bytes. It can be argued that this is desirable. For instance, Mappers can decode the byte buffer directly into Avro without stripping away the header or dealing with kafka Messages at all.&lt;/p&gt;

&lt;p&gt;Also, changing the KafakETLContext code could be affect a lot of users. This is definitely not a backwards compatible change. It can also be argued that the BytesWriteable only contains the payload code, and that checksum-ing of the message should&apos;ve occurred well before the Mapper gets the message.&lt;/p&gt;

&lt;p&gt;However, I think that Sam&apos;s fix still has merit. It would be good for the KafkaETLContext to pass the Message buffer instead of the payload and the RecordReader could strip away the kafka bits before giving the payload to the Mapper. Perhaps put in a config switch to either get just payload or the whole kafka message buffer?&lt;/p&gt;

&lt;p&gt;Additional thoughts:&lt;br/&gt;
I assume there are plenty of users of this code. If there&apos;s anyone who uses the KafkaETLContext directly, they&apos;ll find the patch&apos;s changes to break their stuff. However, for those who are using KafkaETLContext through the KafkaETLRecordReader (as they should), then there is a way to make it backwards compatible.&lt;/p&gt;

&lt;p&gt;The checksumming and payload stripping code could go into the RecordReader rather than the KafkaETLContext.&lt;/p&gt;

&lt;p&gt;If the scope of these changes are too big, I&apos;d just fix the SimpleKafkaETLMapper to not parse the payload bytes.&lt;/p&gt;</comment>
                            <comment id="13774707" author="junrao" created="Mon, 23 Sep 2013 16:41:38 +0000"  >&lt;p&gt;Sorry for not looking at this earlier. I think that we can include the fix in 0.8 since it&apos;s simple enough. It doesn&apos;t apply to 0.8 though. Could you rebase?&lt;/p&gt;</comment>
                            <comment id="13775988" author="smeder" created="Tue, 24 Sep 2013 04:43:02 +0000"  >&lt;p&gt;Rebased patch attached.&lt;/p&gt;</comment>
                            <comment id="13776391" author="junrao" created="Tue, 24 Sep 2013 15:31:54 +0000"  >&lt;p&gt;Thanks for the rebased patch. +1 and committed to 0.8.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12604734" name="hadoop_consumer_1.patch" size="2149" author="smeder" created="Tue, 24 Sep 2013 04:42:34 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>333824</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            12 years, 9 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1ll47:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>334151</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>