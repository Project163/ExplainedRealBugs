<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:59:58 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-4885] processstreamwithcachedstatestore and other streams benchmarks fail occasionally</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-4885</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;test_id:    kafkatest.benchmarks.streams.streams_simple_benchmark_test.StreamsSimpleBenchmarkTest.test_simple_benchmark.test=processstreamwithcachedstatestore.scale=2&lt;br/&gt;
status:     FAIL&lt;br/&gt;
run time:   14 minutes 58.069 seconds&lt;/p&gt;


&lt;p&gt;    Streams Test process on ubuntu@worker5 took too long to exit&lt;br/&gt;
Traceback (most recent call last):&lt;br/&gt;
  File &quot;/var/lib/jenkins/workspace/system-test-kafka/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.6.0-py2.7.egg/ducktape/tests/runner_client.py&quot;, line 123, in run&lt;br/&gt;
    data = self.run_test()&lt;br/&gt;
  File &quot;/var/lib/jenkins/workspace/system-test-kafka/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.6.0-py2.7.egg/ducktape/tests/runner_client.py&quot;, line 176, in run_test&lt;br/&gt;
    return self.test_context.function(self.test)&lt;br/&gt;
  File &quot;/var/lib/jenkins/workspace/system-test-kafka/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.6.0-py2.7.egg/ducktape/mark/_mark.py&quot;, line 321, in wrapper&lt;br/&gt;
    return functools.partial(f, *args, **kwargs)(*w_args, **w_kwargs)&lt;br/&gt;
  File &quot;/var/lib/jenkins/workspace/system-test-kafka/kafka/tests/kafkatest/benchmarks/streams/streams_simple_benchmark_test.py&quot;, line 86, in test_simple_benchmark&lt;br/&gt;
    self.driver&lt;span class=&quot;error&quot;&gt;&amp;#91;num&amp;#93;&lt;/span&gt;.wait()&lt;br/&gt;
  File &quot;/var/lib/jenkins/workspace/system-test-kafka/kafka/tests/kafkatest/services/streams.py&quot;, line 102, in wait&lt;br/&gt;
    self.wait_node(node, timeout_sec)&lt;br/&gt;
  File &quot;/var/lib/jenkins/workspace/system-test-kafka/kafka/tests/kafkatest/services/streams.py&quot;, line 106, in wait_node&lt;br/&gt;
    wait_until(lambda: not node.account.alive(pid), timeout_sec=timeout_sec, err_msg=&quot;Streams Test process on &quot; + str(node.account) + &quot; took too long to exit&quot;)&lt;br/&gt;
  File &quot;/var/lib/jenkins/workspace/system-test-kafka/kafka/venv/local/lib/python2.7/site-packages/ducktape-0.6.0-py2.7.egg/ducktape/utils/util.py&quot;, line 36, in wait_until&lt;br/&gt;
    raise TimeoutError(err_msg)&lt;br/&gt;
TimeoutError: Streams Test process on ubuntu@worker5 took too long to exit&lt;/p&gt;

&lt;p&gt;The log contains several lines like:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2017-03-11 04:52:59,080&amp;#93;&lt;/span&gt; DEBUG Attempt to heartbeat failed for group simple-benchmark-streams-with-storetrue since it is rebalancing. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2017-03-11 04:53:01,987&amp;#93;&lt;/span&gt; DEBUG Sending Heartbeat request for group simple-benchmark-streams-with-storetrue to coordinator worker10:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2017-03-11 04:53:02,088&amp;#93;&lt;/span&gt; DEBUG Attempt to heartbeat failed for group simple-benchmark-streams-with-storetrue since it is rebalancing. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2017-03-11 04:53:04,995&amp;#93;&lt;/span&gt; DEBUG Sending Heartbeat request for group simple-benchmark-streams-with-storetrue to coordinator worker10:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)&lt;/p&gt;

&lt;p&gt;Other tests that fail the same way include:&lt;br/&gt;
test_id:    kafkatest.benchmarks.streams.streams_simple_benchmark_test.StreamsSimpleBenchmarkTest.test_simple_benchmark.test=count.scale=2&lt;br/&gt;
test_id:    kafkatest.benchmarks.streams.streams_simple_benchmark_test.StreamsSimpleBenchmarkTest.test_simple_benchmark.test=processstreamwithsink.scale=1&lt;br/&gt;
test_id:    kafkatest.tests.streams.streams_bounce_test.StreamsBounceTest.test_bounce&lt;/p&gt;</description>
                <environment></environment>
        <key id="13050243">KAFKA-4885</key>
            <summary>processstreamwithcachedstatestore and other streams benchmarks fail occasionally</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="guozhang">Guozhang Wang</assignee>
                                    <reporter username="enothereska">Eno Thereska</reporter>
                        <labels>
                    </labels>
                <created>Sat, 11 Mar 2017 11:38:13 +0000</created>
                <updated>Sun, 18 Jun 2017 20:46:46 +0000</updated>
                            <resolved>Fri, 17 Mar 2017 05:34:05 +0000</resolved>
                                    <version>0.10.2.0</version>
                                    <fixVersion>0.11.0.0</fixVersion>
                                    <component>streams</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="15925516" author="guozhang" created="Wed, 15 Mar 2017 05:07:47 +0000"  >&lt;p&gt;Looked into the logs, the root cause is actually because the broker got into an bad state:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[2017-03-14 04:59:10,795] ERROR Processor got uncaught exception. (kafka.network.Processor)
java.util.ConcurrentModificationException
	at java.util.HashMap$HashIterator.nextEntry(HashMap.java:922)
	at java.util.HashMap$EntryIterator.next(HashMap.java:962)
	at java.util.HashMap$EntryIterator.next(HashMap.java:960)
	at org.apache.kafka.common.utils.CollectionUtils.groupDataByTopic(CollectionUtils.java:35)
	at org.apache.kafka.common.requests.ProduceRequest.toStruct(ProduceRequest.java:113)
	at org.apache.kafka.common.requests.AbstractRequest.toString(AbstractRequest.java:84)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;.valueOf(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;.java:2849)
	at java.lang.StringBuilder.append(StringBuilder.java:128)
	at scala.StringContext.standardInterpolator(StringContext.scala:122)
	at scala.StringContext.s(StringContext.scala:90)
	at kafka.network.RequestChannel$Request.requestDesc(RequestChannel.scala:111)
	at kafka.network.RequestChannel$Request.updateRequestMetrics(RequestChannel.scala:169)
	at kafka.network.Processor$$anonfun$processCompletedSends$1.apply(SocketServer.scala:532)
	at kafka.network.Processor$$anonfun$processCompletedSends$1.apply(SocketServer.scala:528)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.IterableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at kafka.network.Processor.processCompletedSends(SocketServer.scala:528)
	at kafka.network.Processor.run(SocketServer.scala:434)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Looked at the existing JIRAs, there are some similar ones but seem none of the are exactly the same as this one. If that is really the case we can file a new JIRA. cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Because of that, producer request will not be handled and hence eventually be expired and aborted:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[2017-03-14 04:59:45,266] ERROR task [0_0] Error sending record to topic simpleBenchmarkSinkTopic. No more offsets will be recorded &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; task and the exception will eventually be thrown (org.apache.kafka.streams.processor.internals.RecordCollectorImpl)
org.apache.kafka.common.errors.TimeoutException: Expiring 118 record(s) &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; simpleBenchmarkSinkTopic-0: 30266 ms has passed since last append
[2017-03-14 04:59:45,266] ERROR task [0_0] Error sending record to topic simpleBenchmarkSinkTopic. No more offsets will be recorded &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; task and the exception will eventually be thrown (org.apache.kafka.streams.processor.internals.RecordCollectorImpl)
org.apache.kafka.common.errors.TimeoutException: Expiring 118 record(s) &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; simpleBenchmarkSinkTopic-0: 30266 ms has passed since last append
[2017-03-14 04:59:45,267] ERROR task [0_0] Error sending record to topic simpleBenchmarkSinkTopic. No more offsets will be recorded &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; task and the exception will eventually be thrown (org.apache.kafka.streams.processor.internals.RecordCollectorImpl)
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This logic is added in &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-4473&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/KAFKA-4473&lt;/a&gt; (&lt;a href=&quot;https://github.com/apache/kafka/pull/2249&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/2249&lt;/a&gt;), and because of that, the thread would be shutdown in the finally block of &lt;tt&gt;StreamThread&lt;/tt&gt;, at a much earlier time (we do not have the uncaught exception handler):&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[2017-03-14 04:59:45,873] ERROR stream-thread [simple-benchmark-streams-with-sink-b59e4280-9953-439e-93cd-0e46d46c2cea-StreamThread-1] Failed to commit StreamTask 0_0 state:  (org.apache.kafka.streams.processor.internals.StreamThread)
org.apache.kafka.streams.errors.StreamsException: task [0_0] exception caught when producing
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.checkForException(RecordCollectorImpl.java:118)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.flush(RecordCollectorImpl.java:126)
	at org.apache.kafka.streams.processor.internals.StreamTask$1.run(StreamTask.java:77)
	at org.apache.kafka.streams.processor.internals.StreamsMetricsImpl.measureLatencyNs(StreamsMetricsImpl.java:187)
	at org.apache.kafka.streams.processor.internals.StreamTask.commit(StreamTask.java:282)
	at org.apache.kafka.streams.processor.internals.StreamThread.commitOne(StreamThread.java:727)
	at org.apache.kafka.streams.processor.internals.StreamThread.commitAll(StreamThread.java:714)
	at org.apache.kafka.streams.processor.internals.StreamThread.maybeCommit(StreamThread.java:690)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:613)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:318)
Caused by: org.apache.kafka.common.errors.TimeoutException: Expiring 118 record(s) &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; simpleBenchmarkSinkTopic-0: 30075 ms has passed since last append
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And hence we the services tries to shutdown the instance later (two minutes later), there is no thread any more, hence it will be timed out and fail.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[INFO  - 2017-03-14 05:11:08,281 - runner_client - log - lineno:221]: RunnerClient: kafkatest.benchmarks.streams.streams_simple_benchmark_test.StreamsSimpleBenchmarkTest.test_simple_benchmark.test=processstreamwithsink.scale=1: Summary: Streams Test process on ubuntu@worker1 took too &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; to exit
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15925521" author="guozhang" created="Wed, 15 Mar 2017 05:10:52 +0000"  >&lt;p&gt;As for the fix, I think it could be quite complicated and would like to discuss with people about such error handling (&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mjsax&quot; class=&quot;user-hover&quot; rel=&quot;mjsax&quot;&gt;mjsax&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=damianguy&quot; class=&quot;user-hover&quot; rel=&quot;damianguy&quot;&gt;damianguy&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enothereska&quot; class=&quot;user-hover&quot; rel=&quot;enothereska&quot;&gt;enothereska&lt;/a&gt;):&lt;/p&gt;

&lt;p&gt;1. we should consider if we ever would want to shutdown the thread in the finally block when there is any unexpected exception thrown; or should we close the whole instance instead of only silently shutting down this thread.&lt;br/&gt;
2. as for this specific issue, do we want to set the num.retry to infinity so that we would rather block forever than fail and die.&lt;/p&gt;</comment>
                            <comment id="15925825" author="damianguy" created="Wed, 15 Mar 2017 10:00:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;1. We give users a chance to shutdown the whole instance via the UncaughtExceptionHandler, right? &lt;br/&gt;
2. Perhaps this should be configurable? Personally in apps i write i&apos;d prefer to fail fast as failing will usually raise alerts that will help get to the root cause of the problem earlier. Retrying forever may mean that such issues go unnoticed for long periods of time.&lt;/p&gt;</comment>
                            <comment id="15926571" author="guozhang" created="Wed, 15 Mar 2017 16:58:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=damianguy&quot; class=&quot;user-hover&quot; rel=&quot;damianguy&quot;&gt;damianguy&lt;/a&gt; Well, as for the general solution in terms of error handling. I think there is a difference between &quot;streams app has an issue, e.g. divide by zero, serde exception&quot; and &quot;broker cluster has an issue, and no data can be produced / fetched&quot;. In the former case I agree that we should usually fail fast; whereas for the latter case I&apos;m not sure if we want Streams app to stop and die whenever there is a (temporary?) broker unavailability. Imagine cross-DC replication / MirrorMaker cases, we usually want such services to keep alive and idle when brokers are unavailable rather than logging a fatal error and shutdown itself.&lt;/p&gt;

&lt;p&gt;As for the system test itself, I agree that setting a exception handler in streams would be better than setting num.retries to infinity.&lt;/p&gt;</comment>
                            <comment id="15927080" author="githubbot" created="Wed, 15 Mar 2017 22:10:08 +0000"  >&lt;p&gt;GitHub user guozhangwang opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/2693&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/2693&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-4885&quot; title=&quot;processstreamwithcachedstatestore and other streams benchmarks fail occasionally&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-4885&quot;&gt;&lt;del&gt;KAFKA-4885&lt;/del&gt;&lt;/a&gt;: Add client.close as exception handler in streams system tests&lt;/p&gt;



&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/guozhangwang/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/guozhangwang/kafka&lt;/a&gt; K4885-system-test-unexpected-exception-handler&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/2693.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/2693.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #2693&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 756b26836d40a8836ed2e04f5860ac6e90e4c9e7&lt;br/&gt;
Author: Guozhang Wang &amp;lt;wangguoz@gmail.com&amp;gt;&lt;br/&gt;
Date:   2017-03-15T22:09:01Z&lt;/p&gt;

&lt;p&gt;    add close exception handler&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15929442" author="guozhang" created="Fri, 17 Mar 2017 05:34:05 +0000"  >&lt;p&gt;Issue resolved by pull request 2693&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/pull/2693&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/2693&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15929443" author="githubbot" created="Fri, 17 Mar 2017 05:34:39 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/2693&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/2693&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 35 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3ba1b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>