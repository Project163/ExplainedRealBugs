<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:05:27 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6260] AbstractCoordinator not clearly handles NULL Exception</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6260</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;The error reporting is not clear. But it seems that Kafka Heartbeat shuts down application due to NULL exception caused by &quot;fake&quot; disconnections.&lt;/p&gt;

&lt;p&gt;One more comment. We are processing messages in the stream, but sometimes we have to block processing for minutes, as consumers are not handling too much load. Is it possibble that when stream is waiting, then heartbeat is as well blocked?&lt;/p&gt;

&lt;p&gt;Can you check that?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2017-11-23 23:54:47 DEBUG AbstractCoordinator:177 - [Consumer clientId=kafka-endpoint-be51569b-8795-4709-8ec8-28c9cd099a31-StreamThread-1-consumer, groupId=kafka-endpoint] Received successful Heartbeat response
2017-11-23 23:54:50 DEBUG AbstractCoordinator:183 - [Consumer clientId=kafka-endpoint-be51569b-8795-4709-8ec8-28c9cd099a31-StreamThread-1-consumer, groupId=kafka-endpoint] Sending Heartbeat request to coordinator cljp01.eb.lan.at:9093 (id: 2147483646 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)
2017-11-23 23:54:50 TRACE NetworkClient:135 - [Consumer clientId=kafka-endpoint-be51569b-8795-4709-8ec8-28c9cd099a31-StreamThread-1-consumer, groupId=kafka-endpoint] Sending HEARTBEAT {group_id=kafka-endpoint,generation_id=3834,member_id=kafka-endpoint-be51569b-8795-4709-8ec8-28c9cd099a31-StreamThread-1-consumer-94f18be5-e49a-4817-9e5a-fe82a64e0b08} with correlation id 24 to node 2147483646
2017-11-23 23:54:50 TRACE NetworkClient:135 - [Consumer clientId=kafka-endpoint-be51569b-8795-4709-8ec8-28c9cd099a31-StreamThread-1-consumer, groupId=kafka-endpoint] Completed receive from node 2147483646 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; HEARTBEAT with correlation id 24, received {throttle_time_ms=0,error_code=0}
2017-11-23 23:54:50 DEBUG AbstractCoordinator:177 - [Consumer clientId=kafka-endpoint-be51569b-8795-4709-8ec8-28c9cd099a31-StreamThread-1-consumer, groupId=kafka-endpoint] Received successful Heartbeat response
2017-11-23 23:54:52 DEBUG NetworkClient:183 - [Consumer clientId=kafka-endpoint-be51569b-8795-4709-8ec8-28c9cd099a31-StreamThread-1-consumer, groupId=kafka-endpoint] Disconnecting from node 1 due to request timeout.
2017-11-23 23:54:52 TRACE NetworkClient:135 - [Consumer clientId=kafka-endpoint-be51569b-8795-4709-8ec8-28c9cd099a31-StreamThread-1-consumer, groupId=kafka-endpoint] Cancelled request {replica_id=-1,max_wait_time=6000,min_bytes=1,max_bytes=52428800,isolation_level=0,topics=[{topic=clj_internal_topic,partitions=[{partition=6,fetch_offset=211558395,log_start_offset=-1,max_bytes=1048576},{partition=8,fetch_offset=210178209,log_start_offset=-1,max_bytes=1048576},{partition=0,fetch_offset=209353523,log_start_offset=-1,max_bytes=1048576},{partition=2,fetch_offset=209291462,log_start_offset=-1,max_bytes=1048576},{partition=4,fetch_offset=210728595,log_start_offset=-1,max_bytes=1048576}]}]} with correlation id 21 due to node 1 being disconnected
2017-11-23 23:54:52 DEBUG ConsumerNetworkClient:195 - [Consumer clientId=kafka-endpoint-be51569b-8795-4709-8ec8-28c9cd099a31-StreamThread-1-consumer, groupId=kafka-endpoint] Cancelled FETCH request RequestHeader(apiKey=FETCH, apiVersion=6, clientId=kafka-endpoint-be51569b-8795-4709-8ec8-28c9cd099a31-StreamThread-1-consumer, correlationId=21) with correlation id 21 due to node 1 being disconnected
2017-11-23 23:54:52 DEBUG Fetcher:195 - [Consumer clientId=kafka-endpoint-be51569b-8795-4709-8ec8-28c9cd099a31-StreamThread-1-consumer, groupId=kafka-endpoint] Fetch request {clj_internal_topic-6=(offset=211558395, logStartOffset=-1, maxBytes=1048576), clj_internal_topic-8=(offset=210178209, logStartOffset=-1, maxBytes=1048576), clj_internal_topic-0=(offset=209353523, logStartOffset=-1, maxBytes=1048576), clj_internal_topic-2=(offset=209291462, logStartOffset=-1, maxBytes=1048576), clj_internal_topic-4=(offset=210728595, logStartOffset=-1, maxBytes=1048576)} to cljp01.eb.lan.at:9093 (id: 1 rack: DC-1) failed org.apache.kafka.common.errors.DisconnectException: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
2017-11-23 23:54:52 TRACE NetworkClient:123 - [Consumer clientId=kafka-endpoint-be51569b-8795-4709-8ec8-28c9cd099a31-StreamThread-1-consumer, groupId=kafka-endpoint] Found least loaded node cljp01.eb.lan.at:9093 (id: 1 rack: DC-1)
2017-11-23 23:54:52 DEBUG NetworkClient:183 - [Consumer clientId=kafka-endpoint-be51569b-8795-4709-8ec8-28c9cd099a31-StreamThread-1-consumer, groupId=kafka-endpoint] Initialize connection to node cljp01.eb.lan.at:9093 (id: 1 rack: DC-1) &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; sending metadata request
2017-11-23 23:54:52 DEBUG NetworkClient:183 - [Consumer clientId=kafka-endpoint-be51569b-8795-4709-8ec8-28c9cd099a31-StreamThread-1-consumer, groupId=kafka-endpoint] Initiating connection to node cljp01.eb.lan.at:9093 (id: 1 rack: DC-1)
2017-11-23 23:54:52 ERROR AbstractCoordinator:296 - [Consumer clientId=kafka-endpoint-be51569b-8795-4709-8ec8-28c9cd099a31-StreamThread-1-consumer, groupId=kafka-endpoint] Heartbeat thread &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; group kafka-endpoint failed due to unexpected error
java.lang.NullPointerException: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
        at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:436) ~[my-kafka-endpoint.jar:?]
        at org.apache.kafka.common.network.Selector.poll(Selector.java:395) ~[my-kafka-endpoint.jar:?]
        at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:460) ~[my-kafka-endpoint.jar:?]
        at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:238) ~[my-kafka-endpoint.jar:?]
        at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.pollNoWakeup(ConsumerNetworkClient.java:275) ~[my-kafka-endpoint.jar:?]
        at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatThread.run(AbstractCoordinator.java:934) [my-kafka-endpoint.jar:?]
2017-11-23 23:54:52 DEBUG AbstractCoordinator:177 - [Consumer clientId=kafka-endpoint-be51569b-8795-4709-8ec8-28c9cd099a31-StreamThread-1-consumer, groupId=kafka-endpoint] Heartbeat thread has closed
2017-11-23 23:55:16 INFO  KafkaElasticsearchEndpoint:61 - Got shutdown requests ...
2017-11-23 23:55:16 INFO  StreamProcessor:106 - Streams closing ...
2017-11-23 23:55:16 INFO  StreamProcessor:111 - with 5 [s] timeout
2017-11-23 23:55:16 DEBUG KafkaStreams:183 - stream-client [kafka-endpoint-be51569b-8795-4709-8ec8-28c9cd099a31]Stopping Streams client with timeoutMillis = 5000 ms.
2017-11-23 23:55:16 INFO  KafkaStreams:346 - stream-client [kafka-endpoint-be51569b-8795-4709-8ec8-28c9cd099a31]State transition from RUNNING to PENDING_SHUTDOWN
2017-11-23 23:55:16 INFO  StreamThread:336 - stream-thread [kafka-endpoint-be51569b-8795-4709-8ec8-28c9cd099a31-StreamThread-1] Informed to shut down
2017-11-23 23:55:16 INFO  StreamThread:346 - stream-thread [kafka-endpoint-be51569b-8795-4709-8ec8-28c9cd099a31-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Kafka settings:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
        auto.commit.interval.ms = 5000
        auto.offset.reset = earliest
        bootstrap.servers = [xxx:9093, yyy:9093]
        check.crcs = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
        client.id = kafka-endpoint-be51569b-8795-4709-8ec8-28c9cd099a31-StreamThread-1-consumer
        connections.max.idle.ms = 540000
        enable.auto.commit = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        exclude.internal.topics = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
        fetch.max.bytes = 52428800
        fetch.max.wait.ms = 6000
        fetch.min.bytes = 1
        group.id = kafka-endpoint
        heartbeat.interval.ms = 3000
        interceptor.classes = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
        internal.leave.group.on.close = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        isolation.level = read_uncommitted
        key.deserializer = &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.kafka.common.serialization.ByteArrayDeserializer
        max.partition.fetch.bytes = 1048576
        max.poll.interval.ms = 10000000
        max.poll.records = 2000
        metadata.max.age.ms = 300000
        metric.reporters = []
        metrics.num.samples = 2
        metrics.recording.level = INFO
        metrics.sample.window.ms = 30000
        partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
        receive.buffer.bytes = 65536
        reconnect.backoff.max.ms = 1000
        reconnect.backoff.ms = 50
        request.timeout.ms = 7000
        retry.backoff.ms = 100
        sasl.jaas.config = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
        sasl.kerberos.kinit.cmd = /usr/bin/kinit
        sasl.kerberos.min.time.before.relogin = 60000
        sasl.kerberos.service.name = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
        sasl.kerberos.ticket.renew.jitter = 0.05
        sasl.kerberos.ticket.renew.window.factor = 0.8
        sasl.mechanism = GSSAPI
        security.protocol = SSL
        send.buffer.bytes = 131072
        session.timeout.ms = 6000
        ssl.cipher.suites = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
        ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
        ssl.endpoint.identification.algorithm = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
        ssl.key.password = [hidden]
        ssl.keymanager.algorithm = SunX509
        ssl.keystore.location = /data/my/etc/kafka/client-keystore
        ssl.keystore.password = [hidden]
        ssl.keystore.type = JKS
        ssl.protocol = TLS
        ssl.provider = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
        ssl.secure.random.implementation = SHA1PRNG
        ssl.trustmanager.algorithm = PKIX
        ssl.truststore.location = /data/my/etc/kafka/truststore
        ssl.truststore.password = [hidden]
        ssl.truststore.type = JKS
        value.deserializer = &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.kafka.common.serialization.ByteArrayDeserializer
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment>RedHat Linux</environment>
        <key id="13120259">KAFKA-6260</key>
            <summary>AbstractCoordinator not clearly handles NULL Exception</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hachikuji">Jason Gustafson</assignee>
                                    <reporter username="habdank">Seweryn Habdank-Wojewodzki</reporter>
                        <labels>
                    </labels>
                <created>Wed, 22 Nov 2017 15:52:10 +0000</created>
                <updated>Fri, 7 Sep 2018 05:24:13 +0000</updated>
                            <resolved>Fri, 1 Dec 2017 19:37:48 +0000</resolved>
                                    <version>1.0.0</version>
                                    <fixVersion>1.0.1</fixVersion>
                    <fixVersion>1.1.0</fixVersion>
                                    <component>consumer</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>9</watches>
                                                                                                                <comments>
                            <comment id="16262849" author="guozhang" created="Wed, 22 Nov 2017 16:10:42 +0000"  >&lt;p&gt;Is this consistently producible at starting up?&lt;/p&gt;</comment>
                            <comment id="16262869" author="ijuma" created="Wed, 22 Nov 2017 16:22:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rsivaram&quot; class=&quot;user-hover&quot; rel=&quot;rsivaram&quot;&gt;rsivaram&lt;/a&gt;, the Selector NPE above looks odd. Seems like the channel could be null below:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
void pollSelectionKeys(Set&amp;lt;SelectionKey&amp;gt; selectionKeys,
                                   &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; isImmediatelyConnected,
                                   &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; currentTimeNanos) {
        Iterator&amp;lt;SelectionKey&amp;gt; iterator = determineHandlingOrder(selectionKeys).iterator();
        &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (iterator.hasNext()) {
            SelectionKey key = iterator.next();
            KafkaChannel channel = channel(key);
            &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; channelStartTimeNanos = recordTimePerConnection ? time.nanoseconds() : 0;

            &lt;span class=&quot;code-comment&quot;&gt;// register all per-connection metrics at once
&lt;/span&gt;            sensors.maybeRegisterConnectionMetrics(channel.id());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16262887" author="habdank" created="Wed, 22 Nov 2017 16:33:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt;: at my place/code yes. It is always the same.&lt;/p&gt;</comment>
                            <comment id="16262904" author="rsivaram" created="Wed, 22 Nov 2017 16:46:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt; Typically we have a single thread that removes the channel from the selection key and also cancels the key. Perhaps there is some missing synchronization in the consumer?&lt;/p&gt;</comment>
                            <comment id="16263585" author="mjsax" created="Wed, 22 Nov 2017 23:53:03 +0000"  >&lt;p&gt;I did a quick test locally but could not reproduce this: downloaded `kafka_2.12-0.11.0.1.tgz` from AK webpage. Start ZK, broker, create topics for AK WordCount example. Using current &lt;tt&gt;trunk&lt;/tt&gt; I ran WordCount and it just worked. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=habdank&quot; class=&quot;user-hover&quot; rel=&quot;habdank&quot;&gt;habdank&lt;/a&gt; What is your environment that hits this issue?&lt;/p&gt;</comment>
                            <comment id="16265125" author="habdank" created="Fri, 24 Nov 2017 10:07:54 +0000"  >&lt;p&gt;Thanks for the response. I had updated content of the ticket. We are using Kafka 1.0.0 with SSL - settings dumped from logs are in ticket.&lt;/p&gt;</comment>
                            <comment id="16265306" author="habdank" created="Fri, 24 Nov 2017 14:05:36 +0000"  >&lt;p&gt;It is getting funnier and funnier &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. Now we had changed some settings.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
fetch.max.wait.ms=6000
max.block.ms=1000
max.poll.interval.ms=10000000
max.poll.records=2000
num.stream.threads=1
poll.ms=100
request.timeout.ms=7000
session.timeout.ms=6000
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With this settings and DEBUG log level in org.apache.kafka:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&amp;lt;Logger name=&lt;span class=&quot;code-quote&quot;&gt;&quot;at.sitsolutions.clj.KafkaConfigurator&quot;&lt;/span&gt; level=&lt;span class=&quot;code-quote&quot;&gt;&quot;DEBUG&quot;&lt;/span&gt; additivity=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;&amp;gt;
      &amp;lt;AppenderRef ref=&lt;span class=&quot;code-quote&quot;&gt;&quot;RollingFile&quot;&lt;/span&gt;/&amp;gt;
&amp;lt;/Logger&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It works! &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/biggrin.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;But when we set log level to INFO apllication crashes with the same NULL exception &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.&lt;/p&gt;

&lt;p&gt;There is definitive some timing issue between Heartbeat and AbstractCoordinator or Replication.&lt;/p&gt;</comment>
                            <comment id="16265327" author="ijuma" created="Fri, 24 Nov 2017 14:24:55 +0000"  >&lt;p&gt;Definitely a timing issue involved. Would you be able to include a reproducible example?&lt;/p&gt;</comment>
                            <comment id="16266883" author="habdank" created="Mon, 27 Nov 2017 14:37:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt; Include some reproducible example is pretty hard for me, as we have some servers and at two of them this happend (continuously). &lt;br/&gt;
The other are working well, but the definitive difference is load. At those two we have pretty high load in comparison to others.&lt;br/&gt;
Also the problem is that our Kafka uses SSL and ACLs, which are changing timing and this part I cannot attach.&lt;br/&gt;
Kafka and Log4j settings I had already included.&lt;/p&gt;

&lt;p&gt;Kafka code itself is pretty easy. It looks like (a bit compacted, as we have it spread in some methods):&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
StreamsBuilder kBuilder = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StreamsBuilder();
&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.kafkaAndStreamsProperties = kafkaAndStreamsProperties;

&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.kafkaAndStreamsProperties.put( StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;().getClass() );
&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.kafkaAndStreamsProperties.put( StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;().getClass() );

StreamsConfig streamsConfig = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StreamsConfig( kafkaAndStreamsProperties );
KafkaInputConfiguration kic = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KafkaInputConfiguration();

&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; inTopicName = kic.getInputTopicParameters().getTopicName();

KStream&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; stringInput = kBuilder.stream( inTopicName );

stringInput.foreach( ( k, v ) -&amp;gt; {
	&lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
		MyRecordRto lrr = objectMapper.readValue( v, MyRecordRto.class );
		
		&lt;span class=&quot;code-comment&quot;&gt;// it could take much time as sometimes we are wating here until the processors are finishing own work
&lt;/span&gt;		&lt;span class=&quot;code-comment&quot;&gt;// at high load here we could wait up to minute
&lt;/span&gt;		myStreamProcessor.process( lrr );
		
	} &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; ( IOException pe ) {
		LOG.warn( &lt;span class=&quot;code-quote&quot;&gt;&quot;Parsing JSON encountered error: {}&quot;&lt;/span&gt;, pe.getMessage() );
		LOG.trace( &lt;span class=&quot;code-quote&quot;&gt;&quot;Error: {}&quot;&lt;/span&gt;, pe );
	} &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; ( Exception e ) {
		LOG.warn( &lt;span class=&quot;code-quote&quot;&gt;&quot;Processing message encountered error: {}&quot;&lt;/span&gt;, e.getMessage() );
		LOG.trace( &lt;span class=&quot;code-quote&quot;&gt;&quot;Error: {}&quot;&lt;/span&gt;, e );
	}
} );

KafkaStreams streams = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KafkaStreams( kBuilder.build(), streamsConfig );
streams.setUncaughtExceptionHandler( ( &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; t, Throwable e ) -&amp;gt; {
			&lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; ( &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; ) {
				LOG.fatal( &lt;span class=&quot;code-quote&quot;&gt;&quot;Caught unhandled exception: {}; {} in thread {}&quot;&lt;/span&gt;,
						e.getMessage(), e.getStackTrace(), t.getName() );
				&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.stop( 5L );
				&lt;span class=&quot;code-comment&quot;&gt;// seems to be asymmetric shutdown hook shall not contains &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.exit()
&lt;/span&gt;				&lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; v. 0.11.0.0 see official report KAFKA-4366
&lt;/span&gt;				&lt;span class=&quot;code-comment&quot;&gt;// but setUncaughtExceptionHandler without &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.exit() hangs.
&lt;/span&gt;				&lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.exit( 1 );
			}
		}
);
streams.cleanUp();
streams.start();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I have new trace level logs. I will rework them and attach.&lt;/p&gt;</comment>
                            <comment id="16270342" author="habdank" created="Wed, 29 Nov 2017 07:56:11 +0000"  >&lt;p&gt;BTW the other bug: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5882&quot; title=&quot;NullPointerException in StreamTask&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5882&quot;&gt;&lt;del&gt;KAFKA-5882&lt;/del&gt;&lt;/a&gt; happens also in the same environment.&lt;/p&gt;</comment>
                            <comment id="16271190" author="cmccabe" created="Wed, 29 Nov 2017 17:39:12 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=habdank&quot; class=&quot;user-hover&quot; rel=&quot;habdank&quot;&gt;habdank&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;Can you try this pull request to see if it prevents the problem?  This is just a guess.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/kafka/pull/4275/files&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4275/files&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16271269" author="hachikuji" created="Wed, 29 Nov 2017 18:08:33 +0000"  >&lt;p&gt;I think I may have spotted a possible cause. Interestingly, the NPE is hit when we process selection keys from the locally maintained &lt;tt&gt;keysWithBufferedRead&lt;/tt&gt; set. As far as I can tell, a socket could still be present in this set when a connection is closed, and we do not remove it from that set explicitly. When we call &lt;tt&gt;poll&lt;/tt&gt; again, the key would still be present, but we would have removed the attached channel, which would trigger the NPE.&lt;/p&gt;</comment>
                            <comment id="16271321" author="guozhang" created="Wed, 29 Nov 2017 18:37:15 +0000"  >&lt;p&gt;Thanks for the investigation &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt;. Just curious if this is the root cause, what makes it not exposed until in 1.0.0? Did we change anything that could relate to it?&lt;/p&gt;</comment>
                            <comment id="16271352" author="hachikuji" created="Wed, 29 Nov 2017 18:58:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt; The collection mentioned above was only available in 1.0.0. See the commit here: &lt;a href=&quot;https://github.com/apache/kafka/commit/47ee8e954df62b9a79099e944ec4be29afe046f6&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/commit/47ee8e954df62b9a79099e944ec4be29afe046f6&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="16271380" author="githubbot" created="Wed, 29 Nov 2017 19:17:13 +0000"  >&lt;p&gt;GitHub user hachikuji opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/4276&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4276&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6260&quot; title=&quot;AbstractCoordinator not clearly handles NULL Exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6260&quot;&gt;&lt;del&gt;KAFKA-6260&lt;/del&gt;&lt;/a&gt;: Ensure selection keys are removed from all collections on socket close&lt;/p&gt;

&lt;p&gt;    When a socket is closed, we must remove corresponding selection keys from internal collections. This fixes an NPE which is caused by attempting to access the selection key&apos;s attached channel after it had been cleared after disconnecting.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/hachikuji/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/hachikuji/kafka&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6260&quot; title=&quot;AbstractCoordinator not clearly handles NULL Exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6260&quot;&gt;&lt;del&gt;KAFKA-6260&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/4276.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4276.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #4276&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit e715e673b7bca14e2a26a998348528d27ac8a9c8&lt;br/&gt;
Author: Jason Gustafson &amp;lt;jason@confluent.io&amp;gt;&lt;br/&gt;
Date:   2017-11-29T19:10:39Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6260&quot; title=&quot;AbstractCoordinator not clearly handles NULL Exception&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6260&quot;&gt;&lt;del&gt;KAFKA-6260&lt;/del&gt;&lt;/a&gt;: Ensure selection keys are removed from all collections on socket close&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="16271393" author="guozhang" created="Wed, 29 Nov 2017 19:25:32 +0000"  >&lt;p&gt;Ack, thanks!!&lt;/p&gt;</comment>
                            <comment id="16271400" author="hachikuji" created="Wed, 29 Nov 2017 19:30:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=habdank&quot; class=&quot;user-hover&quot; rel=&quot;habdank&quot;&gt;habdank&lt;/a&gt; If possible, can you test with the patch above?&lt;/p&gt;</comment>
                            <comment id="16271756" author="hachikuji" created="Wed, 29 Nov 2017 23:18:09 +0000"  >&lt;p&gt;I think this issue is probably not as severe as we initially feared. It requires that we have buffered data on the client at the time that a request is timed out. Typically request timeouts are on the order of 30s or more, so it is unlikely in practice that a request would return right at the end of that window. However, in this case, the request timeout has been configured to 7s while the fetch max wait time is 6s. That leaves just one second for the fetch request and response transmission. Considering the latency of the network and SSL overhead, I can imagine that could get tight. It would be better to use a request timeout which is at least 5-10 seconds larger than the max wait time.&lt;/p&gt;</comment>
                            <comment id="16272570" author="ijuma" created="Thu, 30 Nov 2017 11:54:06 +0000"  >&lt;p&gt;Thanks for the investigation of the impact &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt;. The fact that a combination of settings is required probably explains why others are not seeing the issue.&lt;/p&gt;</comment>
                            <comment id="16272741" author="habdank" created="Thu, 30 Nov 2017 14:43:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt; &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Can you tell me exactly (exact setting name), which settings are logically combined, so I can set them respectively to our timings including our wait for end-clients results, please?&lt;/li&gt;
	&lt;li&gt;Yes I can test any hot fixes, the only matter is how can I get them into our build process &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="16274827" author="hachikuji" created="Fri, 1 Dec 2017 19:30:32 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=habdank&quot; class=&quot;user-hover&quot; rel=&quot;habdank&quot;&gt;habdank&lt;/a&gt; The configs I mentioned above are &lt;tt&gt;request.timeout.ms&lt;/tt&gt; and &lt;tt&gt;fetch.max.wait.ms&lt;/tt&gt;. The request timeout controls how long the client is willing to wait for a response from the broker. The fetch wait time controls how long the server should hold onto the fetch request if no data is available. Since they are set to 7 and 6 seconds respectively in the configs posted above, there is not much margin for any additional network delays. The condition for this bug is that we have buffered (but incomplete) response data on the client at the time of the request timeout, which is more likely to happen given these settings. &lt;/p&gt;</comment>
                            <comment id="16274835" author="githubbot" created="Fri, 1 Dec 2017 19:36:18 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/4276&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4276&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16274837" author="hachikuji" created="Fri, 1 Dec 2017 19:37:48 +0000"  >&lt;p&gt;Issue resolved by pull request 4276&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/pull/4276&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4276&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16281481" author="habdank" created="Thu, 7 Dec 2017 08:07:58 +0000"  >&lt;p&gt;Thanks a lot!&lt;/p&gt;

&lt;p&gt;When releases will be ready, I will test them.&lt;br/&gt;
I am not sure if and how I can get lib earlier before they are relased &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.&lt;/p&gt;</comment>
                            <comment id="16282274" author="mjsax" created="Thu, 7 Dec 2017 18:28:01 +0000"  >&lt;p&gt;You could check out &lt;tt&gt;&lt;a href=&quot;https://github.com/apache/kafka/tree/1.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/tree/1.0&lt;/a&gt;&lt;/tt&gt; and build it yourself. Than update your application dependencies to use the new client jars.&lt;/p&gt;</comment>
                            <comment id="16290783" author="rgevers" created="Thu, 14 Dec 2017 12:41:30 +0000"  >&lt;p&gt;We ran into this issue as well. In our situation the consumer was fine until something slowed down processing and caused us to pause consumption. Our config is very different, though. We are using the default request.timeout.ms which is 10 seconds, but our fetch.max.wait.ms is set to 1 second. That seems like a pretty significant margin so i&apos;m not sure that the two configs being too close together is the problem for us. Once our consumers were blocked the issue was persistent and created a lot of problems since the NPE appears to have dropped that batch of messages but subsequent attempts still succeeded, creating out of order processing. I still have some more investigation to do but I think it will prevent us from using the 1.0.0 release as is.&lt;/p&gt;</comment>
                            <comment id="16316179" author="habdank" created="Mon, 8 Jan 2018 12:02:41 +0000"  >&lt;p&gt;Short question. When will those fixes released? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
Unfortunately at &lt;a href=&quot;https://issues.apache.org/jira/projects/KAFKA?selectedItem=com.atlassian.jira.jira-projects-plugin:release-page&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;Relase&lt;/a&gt; page there are no dates.&lt;/p&gt;</comment>
                            <comment id="16330599" author="habdank" created="Thu, 18 Jan 2018 14:57:22 +0000"  >&lt;p&gt;&lt;font color=&quot;#333333&quot;&gt;Very important remark.&lt;/font&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;#FF0000&quot;&gt;The code downgraded to Kafka Streams 0.11.0.2, stabilize the situation drastically.&lt;/font&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;#333333&quot;&gt;I mean statistically under load Kafka Streams 1.0.0 are crashing in our environment, but 0.11.0.2 not at all. &lt;br/&gt;
It must be some reason in the new code intorduced. In our tests we only replace the factory classes of KStreamBuilder and StreamBuilder having the exactly the same environments and configuration, by using 1.0.0 have have crashes and with 0.11.0.2 no crashes.&lt;/font&gt;&lt;/p&gt;</comment>
                            <comment id="16598296" author="habdank" created="Fri, 31 Aug 2018 06:14:55 +0000"  >&lt;p&gt;Verified with Kafka 1.1.0&lt;/p&gt;</comment>
                            <comment id="16601215" author="mjsax" created="Sun, 2 Sep 2018 13:54:50 +0000"  >&lt;p&gt;Do you mean that you could verify that it is fixed in 1.1.0 ?&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310361">
                    <name>Blocked</name>
                                            <outwardlinks description="Blocked">
                                        <issuelink>
            <issuekey id="13131826">KAFKA-6459</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13131576">KAFKA-6457</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 11 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3n3r3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>