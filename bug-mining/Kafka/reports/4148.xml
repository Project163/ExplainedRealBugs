<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:42:36 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-19047] Broker registrations are slow if previously fenced or shutdown</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-19047</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;BrokerLifecycleManager prevents registration of a broker w/ an id it has seen before with a different incarnation id if the broker session expires. On clean shutdown and restart of a broker this can cause an unnecessary delay in re-registration while the quorum controller waits for the session to expire.&lt;/p&gt;

&lt;p&gt;```&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;BrokerLifecycleManager id=1&amp;#93;&lt;/span&gt; Unable to register broker 1 because the controller returned error DUPLICATE_BROKER_REGISTRATION&lt;br/&gt;
```&lt;/p&gt;</description>
                <environment></environment>
        <key id="13613231">KAFKA-19047</key>
            <summary>Broker registrations are slow if previously fenced or shutdown</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="alyssahuang">Alyssa Huang</assignee>
                                    <reporter username="alyssahuang">Alyssa Huang</reporter>
                        <labels>
                    </labels>
                <created>Thu, 27 Mar 2025 02:33:36 +0000</created>
                <updated>Wed, 2 Jul 2025 20:40:53 +0000</updated>
                            <resolved>Mon, 30 Jun 2025 16:29:11 +0000</resolved>
                                    <version>4.0.0</version>
                                    <fixVersion>4.1.0</fixVersion>
                                    <component>controller</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="17939055" author="gunnar.morling" created="Thu, 27 Mar 2025 19:41:33 +0000"  >&lt;p&gt;For reference, here are the logs I&apos;ve observed in that situation:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
bin/kafka-server-start.sh config/server.properties
[2025-03-27 20:40:54,651] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-03-27 20:40:54,803] INFO Registered signal handlers &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2025-03-27 20:40:54,804] INFO [ControllerServer id=1] Starting controller (kafka.server.ControllerServer)
[2025-03-27 20:40:54,932] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-03-27 20:40:54,947] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Created data-plane acceptor and processors &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; endpoint : ListenerName(CONTROLLER) (kafka.network.SocketServer)
[2025-03-27 20:40:54,950] INFO authorizerStart completed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; endpoint CONTROLLER. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2025-03-27 20:40:54,951] INFO [SharedServer id=1] Starting SharedServer (kafka.server.SharedServer)
[2025-03-27 20:40:54,971] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kraft-combined-logs] Recovering unflushed segment 0. 0 recovered &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; __cluster_metadata-0. (org.apache.kafka.storage.internals.log.LogLoader)
[2025-03-27 20:40:54,977] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kraft-combined-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
[2025-03-27 20:40:54,978] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
[2025-03-27 20:40:54,978] INFO Deleted producer state snapshot /tmp/kraft-combined-logs/__cluster_metadata-0/00000000000000005680.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-03-27 20:40:54,978] INFO Deleted producer state snapshot /tmp/kraft-combined-logs/__cluster_metadata-0/00000000000000005844.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2025-03-27 20:40:54,979] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kraft-combined-logs] Producer state recovery took 1ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; snapshot load and 0ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
[2025-03-27 20:40:55,014] INFO [ProducerStateManager partition=__cluster_metadata-0] Wrote producer snapshot at offset 5844 with 0 producer ids in 9 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-03-27 20:40:55,017] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kraft-combined-logs] Loading producer state till offset 5844 (org.apache.kafka.storage.internals.log.UnifiedLog)
[2025-03-27 20:40:55,017] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kraft-combined-logs] Reloading from producer snapshot and rebuilding producer state from offset 5844 (org.apache.kafka.storage.internals.log.UnifiedLog)
[2025-03-27 20:40:55,017] INFO [ProducerStateManager partition=__cluster_metadata-0] Loading producer state from snapshot file &lt;span class=&quot;code-quote&quot;&gt;&apos;SnapshotFile(offset=5844, file=/tmp/kraft-combined-logs/__cluster_metadata-0/00000000000000005844.snapshot)&apos;&lt;/span&gt; (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-03-27 20:40:55,018] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kraft-combined-logs] Producer state recovery took 1ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; snapshot load and 0ms &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; segment recovery from offset 5844 (org.apache.kafka.storage.internals.log.UnifiedLog)
[2025-03-27 20:40:55,034] INFO Initialized snapshots with IDs SortedSet(OffsetAndEpoch(offset=0, epoch=0)) from /tmp/kraft-combined-logs/__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
[2025-03-27 20:40:55,039] INFO [raft-expiration-reaper]: Starting (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2025-03-27 20:40:55,043] INFO [RaftManager id=1] Starting request manager with bootstrap servers: [localhost:9093 (id: -2 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; isFenced: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)] (org.apache.kafka.raft.KafkaRaftClient)
[2025-03-27 20:40:55,045] INFO [RaftManager id=1] Reading KRaft snapshot and log as part of the initialization (org.apache.kafka.raft.KafkaRaftClient)
[2025-03-27 20:40:55,046] INFO [RaftManager id=1] Loading snapshot (OffsetAndEpoch(offset=0, epoch=0)) since log start offset (0) is greater than the internal listener&apos;s next offset (-1) (org.apache.kafka.raft.internals.KRaftControlRecordStateMachine)
[2025-03-27 20:40:55,048] INFO [RaftManager id=1] Latest kraft.version is KRAFT_VERSION_1 at offset -1 (org.apache.kafka.raft.internals.KRaftControlRecordStateMachine)
[2025-03-27 20:40:55,049] INFO [RaftManager id=1] Latest set of voters is VoterSet(voters=\{1=VoterNode(voterKey=ReplicaKey(id=1, directoryId=mRnAMtoIReCGVWGS_Q2tnA), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=localhost/&amp;lt;unresolved&amp;gt;:9093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:1])}) at offset -1 (org.apache.kafka.raft.internals.KRaftControlRecordStateMachine)
[2025-03-27 20:40:55,051] INFO [RaftManager id=1] Latest kraft.version is KRAFT_VERSION_1 at offset 1 (org.apache.kafka.raft.internals.KRaftControlRecordStateMachine)
[2025-03-27 20:40:55,051] INFO [RaftManager id=1] Latest set of voters is VoterSet(voters=\{1=VoterNode(voterKey=ReplicaKey(id=1, directoryId=mRnAMtoIReCGVWGS_Q2tnA), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=localhost/&amp;lt;unresolved&amp;gt;:9093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:1])}) at offset 2 (org.apache.kafka.raft.internals.KRaftControlRecordStateMachine)
[2025-03-27 20:40:55,062] INFO [RaftManager id=1] Starting voters are VoterSet(voters=\{1=VoterNode(voterKey=ReplicaKey(id=1, directoryId=mRnAMtoIReCGVWGS_Q2tnA), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=localhost/&amp;lt;unresolved&amp;gt;:9093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:1])}) (org.apache.kafka.raft.KafkaRaftClient)
[2025-03-27 20:40:55,067] INFO [RaftManager id=1] Attempting durable transition to ResignedState(localId=1, epoch=3, voters=[1], electionTimeoutMs=1002, unackedVoters=[], preferredSuccessors=[]) from &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; (org.apache.kafka.raft.QuorumState)
[2025-03-27 20:40:55,077] INFO [RaftManager id=1] Completed transition to ResignedState(localId=1, epoch=3, voters=[1], electionTimeoutMs=1002, unackedVoters=[], preferredSuccessors=[]) from &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; (org.apache.kafka.raft.QuorumState)
[2025-03-27 20:40:55,080] INFO [RaftManager id=1] Completed transition to ProspectiveState(epoch=3, leaderId=OptionalInt[1], retries=1, votedKey=Optional.empty, epochElection=EpochElection(voterStates=\{1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=mRnAMtoIReCGVWGS_Q2tnA), state=GRANTED)}), electionTimeoutMs=1397, highWatermark=Optional.empty) from ResignedState(localId=1, epoch=3, voters=[1], electionTimeoutMs=1002, unackedVoters=[], preferredSuccessors=[]) (org.apache.kafka.raft.QuorumState)
[2025-03-27 20:40:55,081] INFO [RaftManager id=1] Attempting durable transition to CandidateState(localId=1, localDirectoryId=mRnAMtoIReCGVWGS_Q2tnA, epoch=4, retries=1, epochElection=EpochElection(voterStates=\{1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=mRnAMtoIReCGVWGS_Q2tnA), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1199) from ProspectiveState(epoch=3, leaderId=OptionalInt[1], retries=1, votedKey=Optional.empty, epochElection=EpochElection(voterStates=\{1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=mRnAMtoIReCGVWGS_Q2tnA), state=GRANTED)}), electionTimeoutMs=1397, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2025-03-27 20:40:55,086] INFO [RaftManager id=1] Completed transition to CandidateState(localId=1, localDirectoryId=mRnAMtoIReCGVWGS_Q2tnA, epoch=4, retries=1, epochElection=EpochElection(voterStates=\{1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=mRnAMtoIReCGVWGS_Q2tnA), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1199) from ProspectiveState(epoch=3, leaderId=OptionalInt[1], retries=1, votedKey=Optional.empty, epochElection=EpochElection(voterStates=\{1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=mRnAMtoIReCGVWGS_Q2tnA), state=GRANTED)}), electionTimeoutMs=1397, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2025-03-27 20:40:55,087] INFO [RaftManager id=1] Attempting durable transition to Leader(localReplicaKey=ReplicaKey(id=1, directoryId=mRnAMtoIReCGVWGS_Q2tnA), epoch=4, epochStartOffset=5844, highWatermark=Optional.empty, voterStates=\{1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=mRnAMtoIReCGVWGS_Q2tnA), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)}) from CandidateState(localId=1, localDirectoryId=mRnAMtoIReCGVWGS_Q2tnA, epoch=4, retries=1, epochElection=EpochElection(voterStates=\{1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=mRnAMtoIReCGVWGS_Q2tnA), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1199) (org.apache.kafka.raft.QuorumState)
[2025-03-27 20:40:55,092] INFO [RaftManager id=1] Completed transition to Leader(localReplicaKey=ReplicaKey(id=1, directoryId=mRnAMtoIReCGVWGS_Q2tnA), epoch=4, epochStartOffset=5844, highWatermark=Optional.empty, voterStates=\{1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=mRnAMtoIReCGVWGS_Q2tnA), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)}) from CandidateState(localId=1, localDirectoryId=mRnAMtoIReCGVWGS_Q2tnA, epoch=4, retries=1, epochElection=EpochElection(voterStates=\{1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=mRnAMtoIReCGVWGS_Q2tnA), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1199) (org.apache.kafka.raft.QuorumState)
[2025-03-27 20:40:55,099] INFO [kafka-1-raft-io-thread]: Starting (org.apache.kafka.raft.KafkaRaftClientDriver)
[2025-03-27 20:40:55,099] INFO [kafka-1-raft-outbound-request-thread]: Starting (org.apache.kafka.raft.KafkaNetworkChannel$SendThread)
[2025-03-27 20:40:55,104] INFO [MetadataLoader id=1] initializeNewPublishers: the loader is still catching up because we still don&apos;t know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-03-27 20:40:55,105] INFO [ControllerServer id=1] Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; controller quorum voters &lt;span class=&quot;code-keyword&quot;&gt;future&lt;/span&gt; (kafka.server.ControllerServer)
[2025-03-27 20:40:55,105] INFO [ControllerServer id=1] Finished waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; controller quorum voters &lt;span class=&quot;code-keyword&quot;&gt;future&lt;/span&gt; (kafka.server.ControllerServer)
[2025-03-27 20:40:55,107] INFO [RaftManager id=1] High watermark set to LogOffsetMetadata(offset=5845, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=421756)]) &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the first time &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; epoch 4 based on indexOfHw 0 and voters [ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=mRnAMtoIReCGVWGS_Q2tnA), endOffset=Optional[LogOffsetMetadata(offset=5845, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=421756)])], lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)] (org.apache.kafka.raft.LeaderState)
[2025-03-27 20:40:55,118] INFO [RaftManager id=1] Registered the listener org.apache.kafka.image.loader.MetadataLoader@1660053996 (org.apache.kafka.raft.KafkaRaftClient)
[2025-03-27 20:40:55,118] INFO [MetadataLoader id=1] handleLoadSnapshot(00000000000000000000-0000000000): incrementing HandleLoadSnapshotCount to 1. (org.apache.kafka.image.loader.MetadataLoader)
[2025-03-27 20:40:55,120] INFO [MetadataLoader id=1] handleLoadSnapshot(00000000000000000000-0000000000): generated a metadata delta between offset -1 and &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; snapshot in 1409 us. (org.apache.kafka.image.loader.MetadataLoader)
[2025-03-27 20:40:55,120] INFO [MetadataLoader id=1] maybePublishMetadata(SNAPSHOT): The loader is still catching up because we have loaded up to offset -1, but the high water mark is 5845 (org.apache.kafka.image.loader.MetadataLoader)
[2025-03-27 20:40:55,120] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have loaded up to offset 2, but the high water mark is 5845 (org.apache.kafka.image.loader.MetadataLoader)
[2025-03-27 20:40:55,124] INFO [RaftManager id=1] Registered the listener org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@1391447477 (org.apache.kafka.raft.KafkaRaftClient)
[2025-03-27 20:40:55,127] INFO [controller-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-03-27 20:40:55,127] INFO [controller-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-03-27 20:40:55,128] INFO [controller-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-03-27 20:40:55,128] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-03-27 20:40:55,135] INFO [ExpirationReaper-0-&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-03-27 20:40:55,143] INFO [ControllerServer id=1] Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2025-03-27 20:40:55,145] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader finished catching up to the current high water mark of 5845 (org.apache.kafka.image.loader.MetadataLoader)
[2025-03-27 20:40:55,146] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 5844 (org.apache.kafka.image.loader.MetadataLoader)
[2025-03-27 20:40:55,146] INFO [ControllerServer id=1] Finished waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2025-03-27 20:40:55,146] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing KRaftMetadataCachePublisher with a snapshot at offset 5844 (org.apache.kafka.image.loader.MetadataLoader)
[2025-03-27 20:40:55,146] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing FeaturesPublisher with a snapshot at offset 5844 (org.apache.kafka.image.loader.MetadataLoader)
[2025-03-27 20:40:55,146] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-03-27 20:40:55,147] INFO [ControllerServer id=1] Loaded &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; metadata Features(metadataVersion=4.0-IV3, finalizedFeatures=\{group.version=1, transaction.version=2, metadata.version=25}, finalizedFeaturesEpoch=5844). (org.apache.kafka.metadata.publisher.FeaturesPublisher)
[2025-03-27 20:40:55,147] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationsPublisher with a snapshot at offset 5844 (org.apache.kafka.image.loader.MetadataLoader)
[2025-03-27 20:40:55,147] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationManager with a snapshot at offset 5844 (org.apache.kafka.image.loader.MetadataLoader)
[2025-03-27 20:40:55,147] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicConfigPublisher controller id=1 with a snapshot at offset 5844 (org.apache.kafka.image.loader.MetadataLoader)
[2025-03-27 20:40:55,148] INFO [ControllerRegistrationManager id=1 incarnation=JyRNnk_XQx-SK2c6gpcqUw] Found registration &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 6X6DBx4SR5mUuzRfYNKOjQ instead of our incarnation. (kafka.server.ControllerRegistrationManager)
[2025-03-27 20:40:55,148] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicClientQuotaPublisher controller id=1 with a snapshot at offset 5844 (org.apache.kafka.image.loader.MetadataLoader)
[2025-03-27 20:40:55,148] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicTopicClusterQuotaPublisher controller id=1 with a snapshot at offset 5844 (org.apache.kafka.image.loader.MetadataLoader)
[2025-03-27 20:40:55,148] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ScramPublisher controller id=1 with a snapshot at offset 5844 (org.apache.kafka.image.loader.MetadataLoader)
[2025-03-27 20:40:55,149] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.DataPlaneAcceptor)
[2025-03-27 20:40:55,149] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DelegationTokenPublisher controller id=1 with a snapshot at offset 5844 (org.apache.kafka.image.loader.MetadataLoader)
[2025-03-27 20:40:55,149] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerMetadataMetricsPublisher with a snapshot at offset 5844 (org.apache.kafka.image.loader.MetadataLoader)
[2025-03-27 20:40:55,149] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing AclPublisher controller id=1 with a snapshot at offset 5844 (org.apache.kafka.image.loader.MetadataLoader)
[2025-03-27 20:40:55,153] INFO [controller-1-to-controller-registration-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-03-27 20:40:55,153] INFO [ControllerRegistrationManager id=1 incarnation=JyRNnk_XQx-SK2c6gpcqUw] initialized channel manager. (kafka.server.ControllerRegistrationManager)
[2025-03-27 20:40:55,153] INFO [ControllerServer id=1] Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2025-03-27 20:40:55,153] INFO [ControllerServer id=1] Finished waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2025-03-27 20:40:55,153] INFO [controller-1-to-controller-registration-channel-manager]: Recorded &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KRaft controller, from now on will use node localhost:9093 (id: 1 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; isFenced: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;) (kafka.server.NodeToControllerRequestThread)
[2025-03-27 20:40:55,153] INFO [ControllerServer id=1] Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2025-03-27 20:40:55,153] INFO [ControllerServer id=1] Finished waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2025-03-27 20:40:55,153] INFO [BrokerServer id=1] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
[2025-03-27 20:40:55,153] INFO [BrokerServer id=1] Starting broker (kafka.server.BrokerServer)
[2025-03-27 20:40:55,154] INFO [ControllerRegistrationManager id=1 incarnation=JyRNnk_XQx-SK2c6gpcqUw] sendControllerRegistration: attempting to send ControllerRegistrationRequestData(controllerId=1, incarnationId=JyRNnk_XQx-SK2c6gpcqUw, zkMigrationReady=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, listeners=[Listener(name=&lt;span class=&quot;code-quote&quot;&gt;&apos;CONTROLLER&apos;&lt;/span&gt;, host=&lt;span class=&quot;code-quote&quot;&gt;&apos;localhost&apos;&lt;/span&gt;, port=9093, securityProtocol=0)], features=[Feature(name=&lt;span class=&quot;code-quote&quot;&gt;&apos;group.version&apos;&lt;/span&gt;, minSupportedVersion=0, maxSupportedVersion=1), Feature(name=&lt;span class=&quot;code-quote&quot;&gt;&apos;transaction.version&apos;&lt;/span&gt;, minSupportedVersion=0, maxSupportedVersion=2), Feature(name=&lt;span class=&quot;code-quote&quot;&gt;&apos;eligible.leader.replicas.version&apos;&lt;/span&gt;, minSupportedVersion=0, maxSupportedVersion=1), Feature(name=&lt;span class=&quot;code-quote&quot;&gt;&apos;kraft.version&apos;&lt;/span&gt;, minSupportedVersion=0, maxSupportedVersion=1), Feature(name=&lt;span class=&quot;code-quote&quot;&gt;&apos;metadata.version&apos;&lt;/span&gt;, minSupportedVersion=7, maxSupportedVersion=25)]) (kafka.server.ControllerRegistrationManager)
[2025-03-27 20:40:55,155] INFO [broker-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-03-27 20:40:55,155] INFO [broker-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-03-27 20:40:55,155] INFO [broker-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-03-27 20:40:55,155] INFO [broker-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-03-27 20:40:55,165] INFO [BrokerServer id=1] Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; controller quorum voters &lt;span class=&quot;code-keyword&quot;&gt;future&lt;/span&gt; (kafka.server.BrokerServer)
[2025-03-27 20:40:55,165] INFO [BrokerServer id=1] Finished waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; controller quorum voters &lt;span class=&quot;code-keyword&quot;&gt;future&lt;/span&gt; (kafka.server.BrokerServer)
[2025-03-27 20:40:55,166] INFO [broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-03-27 20:40:55,166] INFO [broker-1-to-controller-forwarding-channel-manager]: Recorded &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KRaft controller, from now on will use node localhost:9093 (id: 1 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; isFenced: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;) (kafka.server.NodeToControllerRequestThread)
[2025-03-27 20:40:55,169] INFO [client-metrics-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
[2025-03-27 20:40:55,176] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-03-27 20:40:55,177] INFO [SocketServer listenerType=BROKER, nodeId=1] Created data-plane acceptor and processors &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-03-27 20:40:55,179] INFO [broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-03-27 20:40:55,179] INFO [broker-1-to-controller-alter-partition-channel-manager]: Recorded &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KRaft controller, from now on will use node localhost:9093 (id: 1 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; isFenced: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;) (kafka.server.NodeToControllerRequestThread)
[2025-03-27 20:40:55,182] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-03-27 20:40:55,183] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Recorded &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KRaft controller, from now on will use node localhost:9093 (id: 1 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; isFenced: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;) (kafka.server.NodeToControllerRequestThread)
[2025-03-27 20:40:55,189] INFO [ExpirationReaper-0-&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-03-27 20:40:55,189] INFO [ExpirationReaper-0-&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-03-27 20:40:55,190] INFO [ExpirationReaper-0-&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-03-27 20:40:55,190] INFO [ExpirationReaper-0-&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-03-27 20:40:55,190] INFO [ExpirationReaper-0-&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-03-27 20:40:55,190] INFO [ExpirationReaper-0-&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-03-27 20:40:55,197] INFO [BrokerServer id=1] Using no op persister (kafka.server.BrokerServer)
[2025-03-27 20:40:55,197] INFO [group-coordinator-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
[2025-03-27 20:40:55,207] INFO [ControllerRegistrationManager id=1 incarnation=JyRNnk_XQx-SK2c6gpcqUw] Our registration has been persisted to the metadata log. (kafka.server.ControllerRegistrationManager)
[2025-03-27 20:40:55,208] INFO [ControllerRegistrationManager id=1 incarnation=JyRNnk_XQx-SK2c6gpcqUw] RegistrationResponseHandler: controller acknowledged ControllerRegistrationRequest. (kafka.server.ControllerRegistrationManager)
[2025-03-27 20:40:55,208] INFO [group-coordinator-event-processor-0]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
[2025-03-27 20:40:55,208] INFO [group-coordinator-event-processor-1]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
[2025-03-27 20:40:55,208] INFO [group-coordinator-event-processor-2]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
[2025-03-27 20:40:55,208] INFO [group-coordinator-event-processor-3]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
[2025-03-27 20:40:55,234] INFO [broker-1-to-controller-heartbeat-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-03-27 20:40:55,234] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KRaft controller, from now on will use node localhost:9093 (id: 1 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; isFenced: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;) (kafka.server.NodeToControllerRequestThread)
[2025-03-27 20:40:55,235] INFO [BrokerLifecycleManager id=1] Incarnation dXYWi31WSr-QyZzpsF7Aww of broker 1 in cluster lnPmGrhbRoq03yW06IptOg is now STARTING. (kafka.server.BrokerLifecycleManager)
[2025-03-27 20:40:55,239] INFO [BrokerLifecycleManager id=1] Unable to register broker 1 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-03-27 20:40:55,241] INFO [share-group-lock-timeout-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
[2025-03-27 20:40:55,247] INFO [ExpirationReaper-0-&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-03-27 20:40:55,255] INFO [BrokerServer id=1] Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2025-03-27 20:40:55,255] INFO [BrokerServer id=1] Finished waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2025-03-27 20:40:55,255] INFO [BrokerServer id=1] Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2025-03-27 20:40:55,255] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing MetadataVersionPublisher(id=1) with a snapshot at offset 5845 (org.apache.kafka.image.loader.MetadataLoader)
[2025-03-27 20:40:55,255] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 5845 (org.apache.kafka.image.loader.MetadataLoader)
[2025-03-27 20:40:55,255] INFO [BrokerMetadataPublisher id=1] Publishing initial metadata at offset OffsetAndEpoch(offset=5845, epoch=4) with metadata.version Optional[4.0-IV3]. (kafka.server.metadata.BrokerMetadataPublisher)
[2025-03-27 20:40:55,256] INFO Loading logs from log dirs ArrayBuffer(/tmp/kraft-combined-logs) (kafka.log.LogManager)
[2025-03-27 20:40:55,257] INFO No logs found to be loaded in /tmp/kraft-combined-logs (kafka.log.LogManager)
[2025-03-27 20:40:55,260] INFO Loaded 0 logs in 4ms (kafka.log.LogManager)
[2025-03-27 20:40:55,260] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-03-27 20:40:55,261] INFO Starting log flusher with a &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-03-27 20:40:55,276] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-03-27 20:40:55,277] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-03-27 20:40:55,277] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-03-27 20:40:55,278] INFO [GroupCoordinator id=1] Starting up. (org.apache.kafka.coordinator.group.GroupCoordinatorService)
[2025-03-27 20:40:55,278] INFO [GroupCoordinator id=1] Startup complete. (org.apache.kafka.coordinator.group.GroupCoordinatorService)
[2025-03-27 20:40:55,279] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-03-27 20:40:55,279] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-03-27 20:40:55,280] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-03-27 20:40:55,283] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerRegistrationTracker(id=1) with a snapshot at offset 5845 (org.apache.kafka.image.loader.MetadataLoader)
[2025-03-27 20:40:55,347] INFO [BrokerLifecycleManager id=1] Unable to register broker 1 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-03-27 20:40:55,552] INFO [BrokerLifecycleManager id=1] Unable to register broker 1 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-03-27 20:40:55,959] INFO [BrokerLifecycleManager id=1] Unable to register broker 1 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-03-27 20:40:56,777] INFO [BrokerLifecycleManager id=1] Unable to register broker 1 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-03-27 20:40:58,391] INFO [BrokerLifecycleManager id=1] Unable to register broker 1 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-03-27 20:41:01,604] INFO [BrokerLifecycleManager id=1] Unable to register broker 1 because the controller returned error DUPLICATE_BROKER_REGISTRATION (kafka.server.BrokerLifecycleManager)
[2025-03-27 20:41:06,077] INFO [BrokerLifecycleManager id=1] Successfully registered broker 1 with broker epoch 5868 (kafka.server.BrokerLifecycleManager)
[2025-03-27 20:41:06,087] INFO [BrokerLifecycleManager id=1] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
[2025-03-27 20:41:06,088] INFO [BrokerServer id=1] Finished waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2025-03-27 20:41:06,088] INFO [BrokerServer id=1] Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the initial broker metadata update to be published (kafka.server.BrokerServer)
[2025-03-27 20:41:06,088] INFO [BrokerServer id=1] Finished waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the initial broker metadata update to be published (kafka.server.BrokerServer)
[2025-03-27 20:41:06,089] INFO KafkaConfig values:
&#160; &#160; add.partitions.to.txn.retry.backoff.max.ms = 100
&#160; &#160; add.partitions.to.txn.retry.backoff.ms = 20
&#160; &#160; advertised.listeners = PLAINTEXT:&lt;span class=&quot;code-comment&quot;&gt;//localhost:9092,CONTROLLER://localhost:9093
&lt;/span&gt;&#160; &#160; alter.config.policy.&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;name = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; alter.log.dirs.replication.quota.window.num = 11
&#160; &#160; alter.log.dirs.replication.quota.window.size.seconds = 1
&#160; &#160; authorizer.&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;name =
&#160; &#160; auto.create.topics.enable = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
&#160; &#160; auto.leader.rebalance.enable = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
&#160; &#160; background.threads = 10
&#160; &#160; broker.heartbeat.interval.ms = 2000
&#160; &#160; broker.id = 1
&#160; &#160; broker.rack = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; broker.session.timeout.ms = 9000
&#160; &#160; client.quota.callback.class = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; compression.gzip.level = -1
&#160; &#160; compression.lz4.level = 9
&#160; &#160; compression.type = producer
&#160; &#160; compression.zstd.level = 3
&#160; &#160; connection.failed.authentication.delay.ms = 100
&#160; &#160; connections.max.idle.ms = 600000
&#160; &#160; connections.max.reauth.ms = 0
&#160; &#160; controlled.shutdown.enable = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
&#160; &#160; controller.listener.names = CONTROLLER
&#160; &#160; controller.performance.always.log.threshold.ms = 2000
&#160; &#160; controller.performance.sample.period.ms = 60000
&#160; &#160; controller.quorum.append.linger.ms = 25
&#160; &#160; controller.quorum.bootstrap.servers = [localhost:9093]
&#160; &#160; controller.quorum.election.backoff.max.ms = 1000
&#160; &#160; controller.quorum.election.timeout.ms = 1000
&#160; &#160; controller.quorum.fetch.timeout.ms = 2000
&#160; &#160; controller.quorum.request.timeout.ms = 2000
&#160; &#160; controller.quorum.retry.backoff.ms = 20
&#160; &#160; controller.quorum.voters = []
&#160; &#160; controller.quota.window.num = 11
&#160; &#160; controller.quota.window.size.seconds = 1
&#160; &#160; controller.socket.timeout.ms = 30000
&#160; &#160; create.topic.policy.&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;name = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;.replication.factor = 1
&#160; &#160; delegation.token.expiry.check.interval.ms = 3600000
&#160; &#160; delegation.token.expiry.time.ms = 86400000
&#160; &#160; delegation.token.max.lifetime.ms = 604800000
&#160; &#160; delegation.token.secret.key = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; delete.records.purgatory.purge.interval.requests = 1
&#160; &#160; delete.topic.enable = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
&#160; &#160; early.start.listeners = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; fetch.max.bytes = 57671680
&#160; &#160; fetch.purgatory.purge.interval.requests = 1000
&#160; &#160; group.consumer.assignors = [uniform, range]
&#160; &#160; group.consumer.heartbeat.interval.ms = 5000
&#160; &#160; group.consumer.max.heartbeat.interval.ms = 15000
&#160; &#160; group.consumer.max.session.timeout.ms = 60000
&#160; &#160; group.consumer.max.size = 2147483647
&#160; &#160; group.consumer.migration.policy = bidirectional
&#160; &#160; group.consumer.min.heartbeat.interval.ms = 5000
&#160; &#160; group.consumer.min.session.timeout.ms = 45000
&#160; &#160; group.consumer.session.timeout.ms = 45000
&#160; &#160; group.coordinator.append.linger.ms = 5
&#160; &#160; group.coordinator.&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt;.enable = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
&#160; &#160; group.coordinator.rebalance.protocols = [classic, consumer]
&#160; &#160; group.coordinator.threads = 4
&#160; &#160; group.initial.rebalance.delay.ms = 3000
&#160; &#160; group.max.session.timeout.ms = 1800000
&#160; &#160; group.max.size = 2147483647
&#160; &#160; group.min.session.timeout.ms = 6000
&#160; &#160; group.share.delivery.count.limit = 5
&#160; &#160; group.share.enable = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
&#160; &#160; group.share.heartbeat.interval.ms = 5000
&#160; &#160; group.share.max.groups = 10
&#160; &#160; group.share.max.heartbeat.interval.ms = 15000
&#160; &#160; group.share.max.record.lock.duration.ms = 60000
&#160; &#160; group.share.max.session.timeout.ms = 60000
&#160; &#160; group.share.max.size = 200
&#160; &#160; group.share.min.heartbeat.interval.ms = 5000
&#160; &#160; group.share.min.record.lock.duration.ms = 15000
&#160; &#160; group.share.min.session.timeout.ms = 45000
&#160; &#160; group.share.partition.max.record.locks = 200
&#160; &#160; group.share.persister.&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;name = org.apache.kafka.server.share.persister.DefaultStatePersister
&#160; &#160; group.share.record.lock.duration.ms = 30000
&#160; &#160; group.share.session.timeout.ms = 45000
&#160; &#160; initial.broker.registration.timeout.ms = 60000
&#160; &#160; inter.broker.listener.name = PLAINTEXT
&#160; &#160; kafka.metrics.polling.interval.secs = 10
&#160; &#160; kafka.metrics.reporters = []
&#160; &#160; leader.imbalance.check.interval.seconds = 300
&#160; &#160; listener.security.protocol.map = CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
&#160; &#160; listeners = PLAINTEXT:&lt;span class=&quot;code-comment&quot;&gt;//:9092,CONTROLLER://:9093
&lt;/span&gt;&#160; &#160; log.cleaner.backoff.ms = 15000
&#160; &#160; log.cleaner.dedupe.buffer.size = 134217728
&#160; &#160; log.cleaner.delete.retention.ms = 86400000
&#160; &#160; log.cleaner.enable = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
&#160; &#160; log.cleaner.io.buffer.load.factor = 0.9
&#160; &#160; log.cleaner.io.buffer.size = 524288
&#160; &#160; log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
&#160; &#160; log.cleaner.max.compaction.lag.ms = 9223372036854775807
&#160; &#160; log.cleaner.min.cleanable.ratio = 0.5
&#160; &#160; log.cleaner.min.compaction.lag.ms = 0
&#160; &#160; log.cleaner.threads = 1
&#160; &#160; log.cleanup.policy = [delete]
&#160; &#160; log.dir = /tmp/kafka-logs
&#160; &#160; log.dir.failure.timeout.ms = 30000
&#160; &#160; log.dirs = /tmp/kraft-combined-logs
&#160; &#160; log.flush.interval.messages = 9223372036854775807
&#160; &#160; log.flush.interval.ms = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; log.flush.offset.checkpoint.interval.ms = 60000
&#160; &#160; log.flush.scheduler.interval.ms = 9223372036854775807
&#160; &#160; log.flush.start.offset.checkpoint.interval.ms = 60000
&#160; &#160; log.index.interval.bytes = 4096
&#160; &#160; log.index.size.max.bytes = 10485760
&#160; &#160; log.initial.task.delay.ms = 30000
&#160; &#160; log.local.retention.bytes = -2
&#160; &#160; log.local.retention.ms = -2
&#160; &#160; log.message.timestamp.after.max.ms = 3600000
&#160; &#160; log.message.timestamp.before.max.ms = 9223372036854775807
&#160; &#160; log.message.timestamp.type = CreateTime
&#160; &#160; log.preallocate = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
&#160; &#160; log.retention.bytes = -1
&#160; &#160; log.retention.check.interval.ms = 300000
&#160; &#160; log.retention.hours = 168
&#160; &#160; log.retention.minutes = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; log.retention.ms = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; log.roll.hours = 168
&#160; &#160; log.roll.jitter.hours = 0
&#160; &#160; log.roll.jitter.ms = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; log.roll.ms = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; log.segment.bytes = 1073741824
&#160; &#160; log.segment.delete.delay.ms = 60000
&#160; &#160; max.connection.creation.rate = 2147483647
&#160; &#160; max.connections = 2147483647
&#160; &#160; max.connections.per.ip = 2147483647
&#160; &#160; max.connections.per.ip.overrides =
&#160; &#160; max.incremental.fetch.session.cache.slots = 1000
&#160; &#160; max.request.partition.size.limit = 2000
&#160; &#160; message.max.bytes = 1048588
&#160; &#160; metadata.log.dir = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; metadata.log.max.record.bytes.between.snapshots = 20971520
&#160; &#160; metadata.log.max.snapshot.interval.ms = 3600000
&#160; &#160; metadata.log.segment.bytes = 1073741824
&#160; &#160; metadata.log.segment.min.bytes = 8388608
&#160; &#160; metadata.log.segment.ms = 604800000
&#160; &#160; metadata.max.idle.interval.ms = 500
&#160; &#160; metadata.max.retention.bytes = 104857600
&#160; &#160; metadata.max.retention.ms = 604800000
&#160; &#160; metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
&#160; &#160; metrics.num.samples = 2
&#160; &#160; metrics.recording.level = INFO
&#160; &#160; metrics.sample.window.ms = 30000
&#160; &#160; min.insync.replicas = 1
&#160; &#160; node.id = 1
&#160; &#160; num.io.threads = 8
&#160; &#160; num.network.threads = 3
&#160; &#160; num.partitions = 1
&#160; &#160; num.recovery.threads.per.data.dir = 1
&#160; &#160; num.replica.alter.log.dirs.threads = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; num.replica.fetchers = 1
&#160; &#160; offset.metadata.max.bytes = 4096
&#160; &#160; offsets.commit.timeout.ms = 5000
&#160; &#160; offsets.load.buffer.size = 5242880
&#160; &#160; offsets.retention.check.interval.ms = 600000
&#160; &#160; offsets.retention.minutes = 10080
&#160; &#160; offsets.topic.compression.codec = 0
&#160; &#160; offsets.topic.num.partitions = 50
&#160; &#160; offsets.topic.replication.factor = 1
&#160; &#160; offsets.topic.segment.bytes = 104857600
&#160; &#160; principal.builder.class = &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
&#160; &#160; process.roles = [broker, controller]
&#160; &#160; producer.id.expiration.check.interval.ms = 600000
&#160; &#160; producer.id.expiration.ms = 86400000
&#160; &#160; producer.purgatory.purge.interval.requests = 1000
&#160; &#160; queued.max.request.bytes = -1
&#160; &#160; queued.max.requests = 500
&#160; &#160; quota.window.num = 11
&#160; &#160; quota.window.size.seconds = 1
&#160; &#160; remote.fetch.max.wait.ms = 500
&#160; &#160; remote.list.offsets.request.timeout.ms = 30000
&#160; &#160; remote.log.index.file.cache.total.size.bytes = 1073741824
&#160; &#160; remote.log.manager.copier.thread.pool.size = 10
&#160; &#160; remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
&#160; &#160; remote.log.manager.copy.quota.window.num = 11
&#160; &#160; remote.log.manager.copy.quota.window.size.seconds = 1
&#160; &#160; remote.log.manager.expiration.thread.pool.size = 10
&#160; &#160; remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
&#160; &#160; remote.log.manager.fetch.quota.window.num = 11
&#160; &#160; remote.log.manager.fetch.quota.window.size.seconds = 1
&#160; &#160; remote.log.manager.task.interval.ms = 30000
&#160; &#160; remote.log.manager.task.retry.backoff.max.ms = 30000
&#160; &#160; remote.log.manager.task.retry.backoff.ms = 500
&#160; &#160; remote.log.manager.task.retry.jitter = 0.2
&#160; &#160; remote.log.manager.thread.pool.size = 2
&#160; &#160; remote.log.metadata.custom.metadata.max.bytes = 128
&#160; &#160; remote.log.metadata.manager.&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
&#160; &#160; remote.log.metadata.manager.&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;path = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; remote.log.metadata.manager.impl.prefix = rlmm.config.
&#160; &#160; remote.log.metadata.manager.listener.name = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; remote.log.reader.max.pending.tasks = 100
&#160; &#160; remote.log.reader.threads = 10
&#160; &#160; remote.log.storage.manager.&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;name = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; remote.log.storage.manager.&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;path = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; remote.log.storage.manager.impl.prefix = rsm.config.
&#160; &#160; remote.log.storage.system.enable = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
&#160; &#160; replica.fetch.backoff.ms = 1000
&#160; &#160; replica.fetch.max.bytes = 1048576
&#160; &#160; replica.fetch.min.bytes = 1
&#160; &#160; replica.fetch.response.max.bytes = 10485760
&#160; &#160; replica.fetch.wait.max.ms = 500
&#160; &#160; replica.high.watermark.checkpoint.interval.ms = 5000
&#160; &#160; replica.lag.time.max.ms = 30000
&#160; &#160; replica.selector.class = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; replica.socket.receive.buffer.bytes = 65536
&#160; &#160; replica.socket.timeout.ms = 30000
&#160; &#160; replication.quota.window.num = 11
&#160; &#160; replication.quota.window.size.seconds = 1
&#160; &#160; request.timeout.ms = 30000
&#160; &#160; sasl.client.callback.handler.class = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; sasl.enabled.mechanisms = [GSSAPI]
&#160; &#160; sasl.jaas.config = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; sasl.kerberos.kinit.cmd = /usr/bin/kinit
&#160; &#160; sasl.kerberos.min.time.before.relogin = 60000
&#160; &#160; sasl.kerberos.principal.to.local.rules = [DEFAULT]
&#160; &#160; sasl.kerberos.service.name = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; sasl.kerberos.ticket.renew.jitter = 0.05
&#160; &#160; sasl.kerberos.ticket.renew.window.factor = 0.8
&#160; &#160; sasl.login.callback.handler.class = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; sasl.login.class = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; sasl.login.connect.timeout.ms = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; sasl.login.read.timeout.ms = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; sasl.login.refresh.buffer.seconds = 300
&#160; &#160; sasl.login.refresh.min.period.seconds = 60
&#160; &#160; sasl.login.refresh.window.factor = 0.8
&#160; &#160; sasl.login.refresh.window.jitter = 0.05
&#160; &#160; sasl.login.retry.backoff.max.ms = 10000
&#160; &#160; sasl.login.retry.backoff.ms = 100
&#160; &#160; sasl.mechanism.controller.protocol = GSSAPI
&#160; &#160; sasl.mechanism.inter.broker.protocol = GSSAPI
&#160; &#160; sasl.oauthbearer.clock.skew.seconds = 30
&#160; &#160; sasl.oauthbearer.expected.audience = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; sasl.oauthbearer.expected.issuer = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
&#160; &#160; sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
&#160; &#160; sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
&#160; &#160; sasl.oauthbearer.jwks.endpoint.url = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; sasl.oauthbearer.scope.claim.name = scope
&#160; &#160; sasl.oauthbearer.sub.claim.name = sub
&#160; &#160; sasl.oauthbearer.token.endpoint.url = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; sasl.server.callback.handler.class = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; sasl.server.max.receive.size = 524288
&#160; &#160; security.inter.broker.protocol = PLAINTEXT
&#160; &#160; security.providers = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; server.max.startup.time.ms = 9223372036854775807
&#160; &#160; share.coordinator.append.linger.ms = 10
&#160; &#160; share.coordinator.load.buffer.size = 5242880
&#160; &#160; share.coordinator.snapshot.update.records.per.snapshot = 500
&#160; &#160; share.coordinator.state.topic.compression.codec = 0
&#160; &#160; share.coordinator.state.topic.min.isr = 1
&#160; &#160; share.coordinator.state.topic.num.partitions = 50
&#160; &#160; share.coordinator.state.topic.prune.interval.ms = 300000
&#160; &#160; share.coordinator.state.topic.replication.factor = 1
&#160; &#160; share.coordinator.state.topic.segment.bytes = 104857600
&#160; &#160; share.coordinator.threads = 1
&#160; &#160; share.coordinator.write.timeout.ms = 5000
&#160; &#160; share.fetch.max.fetch.records = 2147483647
&#160; &#160; share.fetch.purgatory.purge.interval.requests = 1000
&#160; &#160; socket.connection.setup.timeout.max.ms = 30000
&#160; &#160; socket.connection.setup.timeout.ms = 10000
&#160; &#160; socket.listen.backlog.size = 50
&#160; &#160; socket.receive.buffer.bytes = 102400
&#160; &#160; socket.request.max.bytes = 104857600
&#160; &#160; socket.send.buffer.bytes = 102400
&#160; &#160; ssl.allow.dn.changes = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
&#160; &#160; ssl.allow.san.changes = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
&#160; &#160; ssl.cipher.suites = []
&#160; &#160; ssl.client.auth = none
&#160; &#160; ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
&#160; &#160; ssl.endpoint.identification.algorithm = https
&#160; &#160; ssl.engine.factory.class = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; ssl.key.password = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; ssl.keymanager.algorithm = SunX509
&#160; &#160; ssl.keystore.certificate.chain = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; ssl.keystore.key = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; ssl.keystore.location = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; ssl.keystore.password = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; ssl.keystore.type = JKS
&#160; &#160; ssl.principal.mapping.rules = DEFAULT
&#160; &#160; ssl.protocol = TLSv1.3
&#160; &#160; ssl.provider = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; ssl.secure.random.implementation = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; ssl.trustmanager.algorithm = PKIX
&#160; &#160; ssl.truststore.certificates = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; ssl.truststore.location = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; ssl.truststore.password = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&#160; &#160; ssl.truststore.type = JKS
&#160; &#160; telemetry.max.bytes = 1048576
&#160; &#160; transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
&#160; &#160; transaction.max.timeout.ms = 900000
&#160; &#160; transaction.partition.verification.enable = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
&#160; &#160; transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
&#160; &#160; transaction.state.log.load.buffer.size = 5242880
&#160; &#160; transaction.state.log.min.isr = 1
&#160; &#160; transaction.state.log.num.partitions = 50
&#160; &#160; transaction.state.log.replication.factor = 1
&#160; &#160; transaction.state.log.segment.bytes = 104857600
&#160; &#160; transactional.id.expiration.ms = 604800000
&#160; &#160; unclean.leader.election.enable = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
&#160; &#160; unclean.leader.election.interval.ms = 300000
&#160; &#160; unstable.api.versions.enable = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
&#160; &#160; unstable.feature.versions.enable = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
&#160;(org.apache.kafka.common.config.AbstractConfig)
[2025-03-27 20:41:06,094] INFO [BrokerServer id=1] Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the broker to be unfenced (kafka.server.BrokerServer)
[2025-03-27 20:41:06,127] INFO [BrokerLifecycleManager id=1] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
[2025-03-27 20:41:06,131] INFO [BrokerServer id=1] Finished waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the broker to be unfenced (kafka.server.BrokerServer)
[2025-03-27 20:41:06,131] INFO authorizerStart completed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; endpoint PLAINTEXT. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2025-03-27 20:41:06,131] INFO [SocketServer listenerType=BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-03-27 20:41:06,132] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2025-03-27 20:41:06,132] INFO [BrokerServer id=1] Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2025-03-27 20:41:06,132] INFO [BrokerServer id=1] Finished waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2025-03-27 20:41:06,132] INFO [BrokerServer id=1] Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2025-03-27 20:41:06,132] INFO [BrokerServer id=1] Finished waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2025-03-27 20:41:06,132] INFO [BrokerServer id=1] Transition from STARTING to STARTED (kafka.server.BrokerServer)
[2025-03-27 20:41:06,133] INFO Kafka version: 4.0.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-03-27 20:41:06,133] INFO Kafka commitId: 985bc99521dd22bb (org.apache.kafka.common.utils.AppInfoParser)
[2025-03-27 20:41:06,133] INFO Kafka startTimeMs: 1743104466132 (org.apache.kafka.common.utils.AppInfoParser)
[2025-03-27 20:41:06,134] INFO [KafkaRaftServer nodeId=1] Kafka Server started (kafka.server.KafkaRaftServer)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17986097" author="mimaison" created="Wed, 25 Jun 2025 10:36:33 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=alyssahuang&quot; class=&quot;user-hover&quot; rel=&quot;alyssahuang&quot;&gt;alyssahuang&lt;/a&gt; I see that &lt;a href=&quot;https://github.com/apache/kafka/pull/19296&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/19296&lt;/a&gt; has been merged. Can we now resolve this ticket or is there more work to do?&lt;/p&gt;</comment>
                            <comment id="17986994" author="alyssahuang" created="Mon, 30 Jun 2025 16:34:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-19130&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/KAFKA-19130&lt;/a&gt; is a dupe of this Jira, and &lt;a href=&quot;https://github.com/apache/kafka/pull/19454&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/19454&lt;/a&gt; was the final fix&#160;&lt;/p&gt;</comment>
                            <comment id="17986999" author="mimaison" created="Mon, 30 Jun 2025 16:49:32 +0000"  >&lt;p&gt;So we can close &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-19130&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/KAFKA-19130&lt;/a&gt; too, right?&lt;/p&gt;</comment>
                            <comment id="17987001" author="mimaison" created="Mon, 30 Jun 2025 16:51:16 +0000"  >&lt;p&gt;Also this is marked as fixed in 4.0.1 but I don&apos;t see &lt;a href=&quot;https://github.com/apache/kafka/commit/c465abc45825c8cd150738774a9dfeddb7e90467&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/commit/c465abc45825c8cd150738774a9dfeddb7e90467&lt;/a&gt; in the 4.0 tree?&lt;/p&gt;</comment>
                            <comment id="17987984" author="alyssahuang" created="Wed, 2 Jul 2025 20:40:53 +0000"  >&lt;p&gt;Thanks Mickael, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jsancio&quot; class=&quot;user-hover&quot; rel=&quot;jsancio&quot;&gt;jsancio&lt;/a&gt; had noticed that as well and believe he&apos;s working on that cherry-pick&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="13615035">KAFKA-19130</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            18 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1v0kg:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>