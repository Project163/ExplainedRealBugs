<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:30:00 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-13600] Rebalances while streams is in degraded state can cause stores to be reassigned and restore from scratch</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-13600</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Consider this scenario:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;A node is lost from the cluster.&lt;/li&gt;
	&lt;li&gt;A rebalance is kicked off with a new &quot;target assignment&quot;&apos;s(ie the rebalance is attempting to move a lot of tasks - see &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-10121&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/KAFKA-10121&lt;/a&gt;).&lt;/li&gt;
	&lt;li&gt;The kafka cluster is now a bit more sluggish from the increased load.&lt;/li&gt;
	&lt;li&gt;A Rolling Deploy happens triggering rebalances, during the rebalance processing continues but offsets can&apos;t be committed(Or nodes are restarted but fail to commit offsets)&lt;/li&gt;
	&lt;li&gt;The most caught up nodes now aren&apos;t within `acceptableRecoveryLag` and so the task is started in it&apos;s &quot;target assignment&quot; location, restoring all state from scratch and delaying further processing instead of using the &quot;almost caught up&quot; node.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;We&apos;ve hit this a few times and having lots of state (~25TB worth) and being heavy users of IQ this is not ideal for us.&lt;/p&gt;

&lt;p&gt;While we can increase `acceptableRecoveryLag` to larger values to try get around this that causes other issues (ie a warmup becoming active when its still quite far behind)&lt;/p&gt;



&lt;p&gt;The solution seems to be to balance &quot;balanced assignment&quot; with &quot;most caught up nodes&quot;.&lt;/p&gt;

&lt;p&gt;We&apos;ve got a fork where we do just this and it&apos;s made a huge difference to the reliability of our cluster.&lt;/p&gt;

&lt;p&gt;Our change is to simply use the most caught up node if the &quot;target node&quot; is more than `acceptableRecoveryLag` behind.&lt;br/&gt;
This gives up some of the load balancing type behaviour of the existing code but in practise doesn&apos;t seem to matter too much.&lt;/p&gt;

&lt;p&gt;I guess maybe an algorithm that identified candidate nodes as those being within `acceptableRecoveryLag` of the most caught up node might allow the best of both worlds.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Our fork is&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/kafka/compare/trunk...tim-patterson:fix_balance_uncaughtup?expand=1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/compare/trunk...tim-patterson:fix_balance_uncaughtup?expand=1&lt;/a&gt;&lt;br/&gt;
(We also moved the capacity constraint code to happen after all the stateful assignment to prioritise standby tasks over warmup tasks)&lt;/p&gt;

&lt;p&gt;Ideally we don&apos;t want to maintain a fork of kafka streams going forward so are hoping to get a bit of discussion / agreement on the best way to handle this.&lt;br/&gt;
More than happy to contribute code/test different algo&apos;s in production system or anything else to help with this issue&lt;/p&gt;</description>
                <environment></environment>
        <key id="13423382">KAFKA-13600</key>
            <summary>Rebalances while streams is in degraded state can cause stores to be reassigned and restore from scratch</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="tim.patterson">Tim Patterson</reporter>
                        <labels>
                    </labels>
                <created>Wed, 19 Jan 2022 00:05:15 +0000</created>
                <updated>Mon, 28 Mar 2022 14:57:21 +0000</updated>
                            <resolved>Mon, 28 Mar 2022 14:57:21 +0000</resolved>
                                    <version>2.8.1</version>
                    <version>3.0.0</version>
                    <version>3.1.0</version>
                                    <fixVersion>3.2.0</fixVersion>
                                    <component>streams</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="17479619" author="guozhang" created="Thu, 20 Jan 2022 19:17:31 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tim.patterson&quot; class=&quot;user-hover&quot; rel=&quot;tim.patterson&quot;&gt;tim.patterson&lt;/a&gt; Thanks for filing this ticket.&lt;/p&gt;

&lt;p&gt;I&apos;d like to clarify a few things to help my own understanding here: in step 5, &quot;The most caught up nodes now aren&apos;t within `acceptableRecoveryLag` and so the task is started in it&apos;s &quot;target assignment&quot; location&quot; could you explain a bit more about this? For a specific task, let&apos;s say it has an ongoing active host say A a.k.a. the most caught up node, and then a target host B which is not yet caught up. Let&apos;s say due to commit failure the active host A fails out of the `acceptableRecoveryLag`, A&apos;s lag should still be smaller than B so that the task would stay with A until B&apos;s within the `acceptableRecoveryLag`. Am I reading it wrong?&lt;/p&gt;</comment>
                            <comment id="17479626" author="tim.patterson" created="Thu, 20 Jan 2022 19:29:43 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt; Thats the desired result and the change I&apos;ve made.&lt;br/&gt;
The current Implementation in Master only considers placing the task on nodes returned by this method&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java#L235&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/trunk/streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/HighAvailabilityTaskAssignor.java#L235&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So as soon as active hosts A falls out of the `acceptableRecoveryLag` in your example it will jump to target host B, even if the lag on target host B is far far behind(ie just starting to restore)&lt;/p&gt;</comment>
                            <comment id="17479678" author="tim.patterson" created="Thu, 20 Jan 2022 21:15:58 +0000"  >&lt;p&gt;Thinking about it, the same problem can be hit when we lose a node and some of the standby tasks for the lost actives have fallen a bit behind for whatever reason, In this case it wont promote the standbys to actives but instead start restoring those tasks from scratch on some other node&lt;/p&gt;</comment>
                            <comment id="17480081" author="cadonna" created="Fri, 21 Jan 2022 13:50:42 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tim.patterson&quot; class=&quot;user-hover&quot; rel=&quot;tim.patterson&quot;&gt;tim.patterson&lt;/a&gt; I checked the assignor code and I agree with you that we only distinguish between caught-up and not caught-up. IIRC, we decided to go that way since considering task load and the rank of non caught-up clients turned out to be more complicated that we wanted to make the assignment algorithm, at that time.&lt;br/&gt;
If you have found a good trade-off between those dimensions, the best thing is to write up your proposal in a KIP. Although this change would not affect the public API, we usually discuss changes to the assignment algorithms in KIPs because they imply important behavioral changes. &lt;a href=&quot;https://cwiki.apache.org/confluence/x/0i4lBg&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;KIP-441&lt;/a&gt; and &lt;a href=&quot;https://cwiki.apache.org/confluence/x/UQ5RCg&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;KIP-708&lt;/a&gt; are examples for such KIPs.&lt;/p&gt;</comment>
                            <comment id="17482079" author="tim.patterson" created="Tue, 25 Jan 2022 20:01:21 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cadonna&quot; class=&quot;user-hover&quot; rel=&quot;cadonna&quot;&gt;cadonna&lt;/a&gt; &lt;br/&gt;
I&apos;m not sure I have the perfect solution either, more just raising this to point out a bit of a hole in the existing implementation.&lt;br/&gt;
I do wonder if simply changing the definition of &quot;caught up&quot; in `tasksToCaughtUpClients` from &quot;within acceptableRecoveryLag of the head of the changelog topic&quot; to &quot;within acceptableRecoveryLag of the most caught up client&quot; might solve 80% of the issues with 20% of the effort/risk...&lt;/p&gt;

&lt;p&gt;I&apos;ll have a bit of a read through the KIP process and have a bit more of a think.&lt;/p&gt;</comment>
                            <comment id="17485343" author="cadonna" created="Tue, 1 Feb 2022 16:11:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tim.patterson&quot; class=&quot;user-hover&quot; rel=&quot;tim.patterson&quot;&gt;tim.patterson&lt;/a&gt; To come up with a perfect solution is not easy with such an optimization problem. If you think your solution is a good trade-off and you have good arguments then I think it is worth discussing on a KIP.&lt;/p&gt;

&lt;p&gt;I am not sure that changing the definition of caught-up as you proposed is so straight forward. For example, in the case where all clients have no or little state all clients would be considered caught-up and the balance might suffer. What I want to say is that it is probably not just a change of a definition.&lt;/p&gt;

&lt;p&gt;If you are interested, in the past I looked at the &lt;a href=&quot;https://en.wikipedia.org/wiki/Assignment_problem#Balanced_assignment&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;linear balanced assignment problem&lt;/a&gt;. I considered the &lt;a href=&quot;https://en.wikipedia.org/wiki/Hungarian_algorithm&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Hungarian algorithm&lt;/a&gt; for a solution, more specifically I looked at &lt;a href=&quot;https://link.springer.com/article/10.1007%2FBF02278710&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;one of the most popular variants&lt;/a&gt;. But I did not have time to go deep enough.&lt;/p&gt;</comment>
                            <comment id="17486714" author="vvcephei" created="Thu, 3 Feb 2022 21:38:41 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tim.patterson&quot; class=&quot;user-hover&quot; rel=&quot;tim.patterson&quot;&gt;tim.patterson&lt;/a&gt; , thanks for the report and the patch!&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;It sounds like you&apos;re reporting two things here:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;a bug around the acceptable recovery lag.&lt;/li&gt;
	&lt;li&gt;an improvement on assignment balance&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;If we can discuss those things independently, then we can definitely merge the bugfix immediately. Depending on the impact of the improvement, it might also fall into the category of a simple ticket, or it might be more appropriate to have a KIP as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cadonna&quot; class=&quot;user-hover&quot; rel=&quot;cadonna&quot;&gt;cadonna&lt;/a&gt; suggested.&lt;/p&gt;

&lt;p&gt;Regarding the bug, I find it completely plausible that we have a bug, but I have to confess that I&apos;m not 100% sure I understand the report. Is the situation that there&apos;s an active that&apos;s happens to be processing quite a bit ahead of the replicas, such that when the active goes offline, there&apos;s no &quot;caught-up&quot; node, and instead of failing the task over to the least-lagging node, we just assign it to a fresh node? If that&apos;s it, then it is certainly not the desired behavior.&lt;/p&gt;

&lt;p&gt;The notion of acceptableRecoveryLag was introduced because follower replicas will always lag the active task, by definition. We want task ownership to be able to swap over from the active to a warm-up when it&apos;s caught up, but it will never be 100% caught up (because it is a follower until it takes over). acceptableRecoveryLag is a way to define a small amount of lag that &quot;acceptable&quot; so that when a warm-up is only lagging by that amount, we can consider it to be effectively caught up and move the active to the warm-up node.&lt;/p&gt;

&lt;p&gt;As you can see, this has nothing at all to do with which nodes are eligible to take over when an active exits the cluster. In that case, it was always the intent that the most-caught-up node should take over active processing, regardless of its lag.&lt;/p&gt;

&lt;p&gt;I&apos;ve been squinting at our existing code, and also your patch (&lt;a href=&quot;https://github.com/apache/kafka/commit/a4b622685423fbfd68b1291dad85cc1f44b086f1)&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/commit/a4b622685423fbfd68b1291dad85cc1f44b086f1)&lt;/a&gt; . It looks to me like the flaw in the existing implementation is essentially just here:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/kafka/commit/a4b622685423fbfd68b1291dad85cc1f44b086f1#diff-83a301514ee18b410df40a91595f6f1afd51f6152ff813b5789516cf5c3605baL92-L96&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/commit/a4b622685423fbfd68b1291dad85cc1f44b086f1#diff-83a301514ee18b410df40a91595f6f1afd51f6152ff813b5789516cf5c3605baL92-L96&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; the desired client is not caught up, and there is another client that _is_ caught up, then
&lt;/span&gt;&lt;span class=&quot;code-comment&quot;&gt;// we schedule a movement, so we can move the active task to the caught-up client. We&apos;ll &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; to
&lt;/span&gt;&lt;span class=&quot;code-comment&quot;&gt;// assign a warm-up to the desired client so that we can move it later on.&lt;/span&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;which should indeed be just like what you described:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; the desired client is not caught up, and there is another client that _is_ more caught up,
&lt;/span&gt;&lt;span class=&quot;code-comment&quot;&gt;// then we schedule a movement [to] move the active task to the [most] caught-up client. 
&lt;/span&gt;&lt;span class=&quot;code-comment&quot;&gt;// We&apos;ll &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; to assign a warm-up to the desired client so that we can move it later on.&lt;/span&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;On the other hand, we should not lose this important predicate to determine whether a task is considered &quot;caught up:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/kafka/commit/a4b622685423fbfd68b1291dad85cc1f44b086f1#diff-e50a755ba2a4d2f7306d1016d079018cba22f9f32993ef5dd64408d1a94d79acL245&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/commit/a4b622685423fbfd68b1291dad85cc1f44b086f1#diff-e50a755ba2a4d2f7306d1016d079018cba22f9f32993ef5dd64408d1a94d79acL245&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
activeRunning(taskLag) || unbounded(acceptableRecoveryLag) || acceptable(acceptableRecoveryLag, taskLag) &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This captures a couple of subtleties in addition to the obvious &quot;a task is caught up if it&apos;s under the acceptable recovery lag&quot;:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;A running, active task doesn&apos;t have a real lag at all, but instead its &quot;lag&quot; is the sentinel value `-2`&lt;/li&gt;
	&lt;li&gt;You can disable the &quot;warm up&quot; phase completely by setting acceptableRecoveryLag to `Long.MAX_VALUE`, in which case, we ignore lags completely and consider all nodes to be caught up, even if they didn&apos;t report a lag at all.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;One extra thing I like about your patch is this:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/kafka/commit/a4b622685423fbfd68b1291dad85cc1f44b086f1#diff-83a301514ee18b410df40a91595f6f1afd51f6152ff813b5789516cf5c3605baR54-R56&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/commit/a4b622685423fbfd68b1291dad85cc1f44b086f1#diff-83a301514ee18b410df40a91595f6f1afd51f6152ff813b5789516cf5c3605baR54-R56&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// Even &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; there is a more caught up client, as &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; as we&apos;re within allowable lag then
&lt;/span&gt;&lt;span class=&quot;code-comment&quot;&gt;// its best just to stick with what we&apos;ve got &lt;/span&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I agree that, if two nodes are within the acceptableRecoveryLag of each other, we should consider their lags to be effectively the same. That&apos;s something I wanted to do when we wrote this code, but couldn&apos;t figure out a good way to do it.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;One thing I&apos;d need more time on is the TaskMovementTest. At first glance, it looks like those changes are just about the slightly different method signature, but I&apos;d want to be very sure that we&apos;re still testing the same invariants that we wanted to test.&lt;/p&gt;

&lt;p&gt;Would you be willing to submit this bugfix as a PR so that we can formally review and merge it?&lt;/p&gt;</comment>
                            <comment id="17486744" author="tim.patterson" created="Thu, 3 Feb 2022 23:19:09 +0000"  >&lt;p&gt;Thanks&#160; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cadonna&quot; class=&quot;user-hover&quot; rel=&quot;cadonna&quot;&gt;cadonna&lt;/a&gt;&lt;br/&gt;
yeah I had a bit of a think and I think you&apos;re right, it also gets a bit weird when dealing with replicas..&lt;br/&gt;
Like you almost have to decide what&apos;s &quot;caught up&quot;, assign the actives, remove those node/partitions from the candidates and then recalc for the replicas to handle the case where theres a large gab between the most caught up and second most caught up.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vvcephei&quot; class=&quot;user-hover&quot; rel=&quot;vvcephei&quot;&gt;vvcephei&lt;/a&gt;&#160;&lt;br/&gt;
&amp;gt; Is the situation that there&apos;s an active that&apos;s happens to be processing quite a bit ahead of the replicas, such that when the active goes offline, there&apos;s no &quot;caught-up&quot; node, and instead of failing the task over to the least-lagging node, we just assign it to a fresh node&lt;br/&gt;
Yeah that&apos;s it!.&lt;br/&gt;
Although what we also hit a couple of times is a variation on clusters with no replicas where the active is restarted but its failed to locally checkpoint in a couple of minutes, when it comes back up its seen as not being caught up and so the task is assigned to a fresh(ish) node&lt;br/&gt;
(of course this only occurs when the cluster is already wanting to move that task to a new home due to a node being added/removed recently)&lt;/p&gt;



&lt;p&gt;One thing I haven&apos;t really taken into consideration/thought about is clusters with more than one replica, I&apos;m not entirely convinced it works there although the unit tests do pass.&lt;br/&gt;
&#160;&lt;/p&gt;

&lt;p&gt;Did you mean submit as is,&#160; or to create a minimal PR where I only try to address that flaw you&apos;ve identified here&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/commit/a4b622685423fbfd68b1291dad85cc1f44b086f1#diff-83a301514ee18b410df40a91595f6f1afd51f6152ff813b5789516cf5c3605baL92-L96&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/commit/a4b622685423fbfd68b1291dad85cc1f44b086f1#diff-83a301514ee18b410df40a91595f6f1afd51f6152ff813b5789516cf5c3605baL92-L96&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I can certainly have a go at that (it was a few months ago that I patched this so it might take me a bit to wrap my head around it again lol).&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Tim&lt;/p&gt;</comment>
                            <comment id="17486808" author="guozhang" created="Fri, 4 Feb 2022 03:47:12 +0000"  >&lt;p&gt;Thanks guys for the great discussion here.&lt;/p&gt;

&lt;p&gt;I think just changing (and of course still maintaining the subtlety of those edge cases) the behavior of &quot;if we cannot find any caught-up node, assign to a fresh node&quot; to &quot;if we cannot find any caught-up node, pick one that is closest to head&quot; as a general principal should be okay for just the scope of this ticket. We can leave further improvements of the assignment algorithm (I know Bruno/John already have some ideas) to a larger scoped KIP. WDYT?&lt;/p&gt;</comment>
                            <comment id="17487148" author="cadonna" created="Fri, 4 Feb 2022 16:04:11 +0000"  >&lt;p&gt;I am fine with discussing the improvement on the PR and not in a KIP. I actually realized that the other improvements to the assignment algorithm included changes to the public API and therefore a KIP was needed. For me it is just important that we look really careful at the improvements because the assignment algorithm is a quite critical part of the system. &lt;/p&gt;

&lt;p&gt;Additionally, I did not want to discuss about a totally new assignment algorithm. I just linked the information for general interest.&lt;/p&gt;

&lt;p&gt;Looking forward to the PR.&lt;/p&gt;</comment>
                            <comment id="17492530" author="tim.patterson" created="Tue, 15 Feb 2022 10:46:59 +0000"  >&lt;p&gt;Hey sorry about the delay, I&apos;ve finally been able to get a few hours in a row to be able to concentrate on this.&lt;br/&gt;
Trying to just fix &quot;if we cannot find any caught-up node, pick one that is closest to head&quot; with minimal other changes.&lt;br/&gt;
&#160;&lt;br/&gt;
While it doesn&apos;t change much algorithmically, unfortunately its more than the 5-10 line change I was hoping for.&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/pull/11760/files&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/11760/files&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 39 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0ypi0:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>