<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:13:46 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-7250] Kafka-Streams-Scala DSL transform shares transformer instance</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-7250</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;The new Kafka Streams Scala DSL provides transform function with following signature&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;def transform&lt;span class=&quot;error&quot;&gt;&amp;#91;K1, V1&amp;#93;&lt;/span&gt;(transformer: Transformer&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V, (K1, V1)&amp;#93;&lt;/span&gt;, stateStoreNames: String*): KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;K1, V1&amp;#93;&lt;/span&gt;&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;the provided &apos;transformer&apos; (will refer to it as scala-transformer)&#160; instance is than used to derive java Transformer instance and in turn a TransformerSupplier that is passed to the underlying java DSL. However that causes all the tasks to share the same instance of the scala-transformer. This introduce all sort of issues. The simplest way to reproduce is to implement simplest transformer of the following shape:&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;.transform(new Transformer&lt;span class=&quot;error&quot;&gt;&amp;#91;String, String, (String, String)&amp;#93;&lt;/span&gt; {&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;&#160; &#160; var context: ProcessorContext = _&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;&#160; def init(pc: ProcessorContext) = { context = pc&lt;/tt&gt;}&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;&#160; def transform(k: String, v: String): (String, String) = {&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;&#160; &#160; &#160; &#160; context.timestamp()&#160;&lt;/p&gt;

&lt;p&gt;&#160; &#160; &#160; &#160; ...&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;&#160; }}}{{})&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;the call to timestmap will die with exception &quot;This should not happen as timestamp() should only be called while a record is processed&quot; due to record context not being set - while the update of record context was actually performed, but due to shared nature of the scala-transformer the local reference to the processor context is pointing to the one of the last initialized task rather than the current task.&#160;&lt;/p&gt;

&lt;p&gt;The solution is to accept a function in following manner:&#160;&lt;/p&gt;

&lt;p&gt;def transform&lt;span class=&quot;error&quot;&gt;&amp;#91;K1, V1&amp;#93;&lt;/span&gt;(getTransformer: () =&amp;gt; Transformer&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V, (K1, V1)&amp;#93;&lt;/span&gt;, stateStoreNames: String*): KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;K1, V1&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&#160;or TransformerSupplier - like the transformValues DSL function does.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13177085">KAFKA-7250</key>
            <summary>Kafka-Streams-Scala DSL transform shares transformer instance</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mdziemianko">Michal Dziemianko</assignee>
                                    <reporter username="michald">Michal</reporter>
                        <labels>
                            <label>scala</label>
                    </labels>
                <created>Mon, 6 Aug 2018 11:48:46 +0000</created>
                <updated>Thu, 14 Feb 2019 17:47:24 +0000</updated>
                            <resolved>Tue, 7 Aug 2018 15:03:15 +0000</resolved>
                                    <version>2.0.0</version>
                                    <fixVersion>2.0.1</fixVersion>
                    <fixVersion>2.1.0</fixVersion>
                                    <component>streams</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="16570549" author="guozhang" created="Mon, 6 Aug 2018 17:54:27 +0000"  >&lt;p&gt;I looked at the code and can confirm it is the issue:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
def transform[K1, V1](transformer: Transformer[K, V, (K1, V1)],
    stateStoreNames: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;*): KStream[K1, V1] = {
    val transformerSupplierJ: TransformerSupplier[K, V, KeyValue[K1, V1]] = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TransformerSupplier[K, V, KeyValue[K1, V1]] {
      override def get(): Transformer[K, V, KeyValue[K1, V1]] = {
        &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Transformer[K, V, KeyValue[K1, V1]] {
          override def transform(key: K, value: V): KeyValue[K1, V1] = {
            transformer.transform(key, value) match {
              &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; (k1, v1) =&amp;gt; KeyValue.pair(k1, v1)
              &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; _ =&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
            }
          }

          override def init(context: ProcessorContext): Unit = transformer.init(context)

          override def close(): Unit = transformer.close()
        }
      }
    }
    &lt;span class=&quot;code-keyword&quot;&gt;inner&lt;/span&gt;.transform(transformerSupplierJ, stateStoreNames: _*)
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The API itself is actually buggy: we should not take a Transform object, but a TransformSupplier as we did in transformValues call.&lt;/p&gt;</comment>
                            <comment id="16570551" author="guozhang" created="Mon, 6 Aug 2018 17:55:12 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=michald&quot; class=&quot;user-hover&quot; rel=&quot;michald&quot;&gt;michald&lt;/a&gt; Do you want to submit a PR to fix this issue?&lt;/p&gt;</comment>
                            <comment id="16570566" author="mdziemianko" created="Mon, 6 Aug 2018 18:02:00 +0000"  >&lt;p&gt;Absolutely, no problem&lt;/p&gt;

</comment>
                            <comment id="16570608" author="guozhang" created="Mon, 6 Aug 2018 18:34:26 +0000"  >&lt;p&gt;Great! I&apos;ve assigned you to the ticket, please feel free to follow the PR guidelines: &lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/Contributing+Code+Changes#ContributingCodeChanges-PullRequest&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://cwiki.apache.org/confluence/display/KAFKA/Contributing+Code+Changes#ContributingCodeChanges-PullRequest&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16570896" author="githubbot" created="Mon, 6 Aug 2018 23:00:34 +0000"  >&lt;p&gt;mdziemianko opened a new pull request #5468: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7250&quot; title=&quot;Kafka-Streams-Scala DSL transform shares transformer instance&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7250&quot;&gt;&lt;del&gt;KAFKA-7250&lt;/del&gt;&lt;/a&gt;: fix transform function in scala DSL to accept TranformerS&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5468&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5468&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   &#8230;upplier&lt;/p&gt;

&lt;p&gt;   Restructuring scala DSL transform function to accept TransformerSupplier instead of a single&lt;br/&gt;
   instance of Transformer that was shared across tasks.&lt;/p&gt;

&lt;p&gt;   Updated scaladoc.&lt;/p&gt;

&lt;p&gt;   Added a unit test to ensure created topology corresponds to equivalent java definition.&lt;/p&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16570897" author="mdziemianko" created="Mon, 6 Aug 2018 23:02:48 +0000"  >&lt;p&gt;&lt;tt&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt; it seems like the API is really inconsistent:&lt;/tt&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
def transform[K1, V1](transformer: Transformer[K, V, (K1, V1)], stateStoreNames: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;*): KStream[K1, V1]&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;versus:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
def transformValues[VR](valueTransformerSupplier: ValueTransformerSupplier[V, VR],stateStoreNames: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;*): KStream[K, VR]
def transformValues[VR](valueTransformerSupplier: ValueTransformerWithKeySupplier[K, V, VR], stateStoreNames: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;*): KStream[K, VR]&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;versus&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
def process(processorSupplier: () =&amp;gt; Processor[K, V], stateStoreNames: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;*): Unit&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Personally, I think the `process` &#160;is the best option (and it matches all other operations like map, join, aggregate etc.)&lt;/p&gt;

&lt;p&gt;I tried a quick implementation but there are some issues with transformValues due to type erasure so I just did PR for the transform as it is currently not very usable, while &#160;I will go over the API and try to make it a bit more consistent later...&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="16570964" author="guozhang" created="Tue, 7 Aug 2018 00:33:39 +0000"  >&lt;p&gt;Ack, thanks!&lt;/p&gt;</comment>
                            <comment id="16571800" author="githubbot" created="Tue, 7 Aug 2018 15:00:26 +0000"  >&lt;p&gt;guozhangwang closed pull request #5468: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7250&quot; title=&quot;Kafka-Streams-Scala DSL transform shares transformer instance&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7250&quot;&gt;&lt;del&gt;KAFKA-7250&lt;/del&gt;&lt;/a&gt;: fix transform function in scala DSL to accept TranformerS&#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5468&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5468&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/FunctionConversions.scala b/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/FunctionConversions.scala&lt;br/&gt;
index 4a4c3b0ee44..65ea4903326 100644&lt;br/&gt;
&amp;#8212; a/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/FunctionConversions.scala&lt;br/&gt;
+++ b/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/FunctionConversions.scala&lt;br/&gt;
@@ -105,4 +105,10 @@ object FunctionConversions &lt;/p&gt;
{
       override def apply(): VA = f()
     }
&lt;p&gt;   }&lt;br/&gt;
+&lt;br/&gt;
+  implicit class TransformerSupplierFromFunction&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V, VO&amp;#93;&lt;/span&gt;(val f: () =&amp;gt; Transformer&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V, VO&amp;#93;&lt;/span&gt;) extends AnyVal {&lt;br/&gt;
+    def asTransformerSupplier: TransformerSupplier&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V, VO&amp;#93;&lt;/span&gt; = new TransformerSupplier&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V, VO&amp;#93;&lt;/span&gt; &lt;/p&gt;
{
+      override def get(): Transformer[K, V, VO] = f()
+    }
&lt;p&gt;+  }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KStream.scala b/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KStream.scala&lt;br/&gt;
index 8f6aab86e2e..c02939aeab7 100644&lt;br/&gt;
&amp;#8212; a/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KStream.scala&lt;br/&gt;
+++ b/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KStream.scala&lt;br/&gt;
@@ -22,7 +22,7 @@ package kstream&lt;/p&gt;

&lt;p&gt; import org.apache.kafka.streams.KeyValue&lt;br/&gt;
 import org.apache.kafka.streams.kstream.&lt;/p&gt;
{KStream =&amp;gt; KStreamJ, _}
&lt;p&gt;-import org.apache.kafka.streams.processor.&lt;/p&gt;
{Processor, ProcessorContext, ProcessorSupplier, TopicNameExtractor}
&lt;p&gt;+import org.apache.kafka.streams.processor.&lt;/p&gt;
{Processor, ProcessorSupplier, TopicNameExtractor}
&lt;p&gt; import org.apache.kafka.streams.scala.ImplicitConversions._&lt;br/&gt;
 import org.apache.kafka.streams.scala.FunctionConversions._&lt;/p&gt;

&lt;p&gt;@@ -284,33 +284,21 @@ class KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(val inner: KStreamJ&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
   /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Transform each record of the input stream into zero or more records in the output stream (both key and value type&lt;/li&gt;
	&lt;li&gt;can be altered arbitrarily).&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* A `Transformer` is applied to each input record and computes zero or more output records. In order to assign a&lt;/li&gt;
	&lt;li&gt;* state, the state must be created and registered beforehand via stores added via `addStateStore` or `addGlobalStore`&lt;br/&gt;
+   * A `Transformer` (provided by the given `TransformerSupplier`) is applied to each input record&lt;br/&gt;
+   * and computes zero or more output records.&lt;br/&gt;
+   * In order to assign a state, the state must be created and registered&lt;br/&gt;
+   * beforehand via stores added via `addStateStore` or `addGlobalStore`&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;before they can be connected to the `Transformer`&lt;br/&gt;
    *&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* @param transformer the `Transformer` instance&lt;br/&gt;
+   * @param transformerSupplier the `TransformerSuplier` that generates `Transformer`&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param stateStoreNames     the names of the state stores used by the processor&lt;/li&gt;
	&lt;li&gt;@return a [&lt;span class=&quot;error&quot;&gt;&amp;#91;KStream&amp;#93;&lt;/span&gt;] that contains more or less records with new key and value (possibly of different type)&lt;/li&gt;
	&lt;li&gt;@see `org.apache.kafka.streams.kstream.KStream#transform`&lt;br/&gt;
    */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def transform&lt;span class=&quot;error&quot;&gt;&amp;#91;K1, V1&amp;#93;&lt;/span&gt;(transformer: Transformer&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V, (K1, V1)&amp;#93;&lt;/span&gt;, stateStoreNames: String*): KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;K1, V1&amp;#93;&lt;/span&gt; = {&lt;/li&gt;
	&lt;li&gt;val transformerSupplierJ: TransformerSupplier[K, V, KeyValue&lt;span class=&quot;error&quot;&gt;&amp;#91;K1, V1&amp;#93;&lt;/span&gt;] =&lt;/li&gt;
	&lt;li&gt;new TransformerSupplier[K, V, KeyValue&lt;span class=&quot;error&quot;&gt;&amp;#91;K1, V1&amp;#93;&lt;/span&gt;] {&lt;/li&gt;
	&lt;li&gt;override def get(): Transformer[K, V, KeyValue&lt;span class=&quot;error&quot;&gt;&amp;#91;K1, V1&amp;#93;&lt;/span&gt;] =&lt;/li&gt;
	&lt;li&gt;new Transformer[K, V, KeyValue&lt;span class=&quot;error&quot;&gt;&amp;#91;K1, V1&amp;#93;&lt;/span&gt;] {&lt;/li&gt;
	&lt;li&gt;override def transform(key: K, value: V): KeyValue&lt;span class=&quot;error&quot;&gt;&amp;#91;K1, V1&amp;#93;&lt;/span&gt; =&lt;/li&gt;
	&lt;li&gt;transformer.transform(key, value) match 
{
-                case (k1, v1) =&amp;gt; KeyValue.pair(k1, v1)
-                case _        =&amp;gt; null
-              }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;override def init(context: ProcessorContext): Unit = transformer.init(context)&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;override def close(): Unit = transformer.close()&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;inner.transform(transformerSupplierJ, stateStoreNames: _*)&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
+  def transform&lt;span class=&quot;error&quot;&gt;&amp;#91;K1, V1&amp;#93;&lt;/span&gt;(transformerSupplier: () =&amp;gt; Transformer[K, V, KeyValue&lt;span class=&quot;error&quot;&gt;&amp;#91;K1, V1&amp;#93;&lt;/span&gt;],&lt;br/&gt;
+                        stateStoreNames: String*): KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;K1, V1&amp;#93;&lt;/span&gt; =&lt;br/&gt;
+    inner.transform(transformerSupplier.asTransformerSupplier, stateStoreNames: _*)&lt;br/&gt;
+&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Transform the value of each input record into a new value (with possible new type) of the output record.&lt;br/&gt;
diff --git a/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/TopologyTest.scala b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/TopologyTest.scala&lt;br/&gt;
index f04ec5dcb04..194abf5e3ba 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/TopologyTest.scala&lt;br/&gt;
+++ b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/TopologyTest.scala&lt;br/&gt;
@@ -31,6 +31,8 @@ import ImplicitConversions._&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import org.apache.kafka.streams.&lt;/p&gt;
{StreamsBuilder =&amp;gt; StreamsBuilderJ, _}
&lt;p&gt; import org.apache.kafka.streams.kstream.&lt;/p&gt;
{KTable =&amp;gt; KTableJ, KStream =&amp;gt; KStreamJ, KGroupedStream =&amp;gt; KGroupedStreamJ, _}
&lt;p&gt;+import org.apache.kafka.streams.processor.ProcessorContext&lt;br/&gt;
+&lt;br/&gt;
 import collection.JavaConverters._&lt;/p&gt;

&lt;p&gt; /**&lt;br/&gt;
@@ -194,4 +196,61 @@ class TopologyTest extends JUnitSuite &lt;/p&gt;
{
     // should match
     assertEquals(getTopologyScala(), getTopologyJava())
   }
&lt;p&gt;+&lt;br/&gt;
+  @Test def shouldBuildIdenticalTopologyInJavaNScalaTransform() = {&lt;br/&gt;
+&lt;br/&gt;
+    // build the Scala topology&lt;br/&gt;
+    def getTopologyScala(): TopologyDescription = {&lt;br/&gt;
+&lt;br/&gt;
+      import Serdes._&lt;br/&gt;
+&lt;br/&gt;
+      val streamBuilder = new StreamsBuilder&lt;br/&gt;
+      val textLines = streamBuilder.stream&lt;span class=&quot;error&quot;&gt;&amp;#91;String, String&amp;#93;&lt;/span&gt;(inputTopic)&lt;br/&gt;
+&lt;br/&gt;
+      val _: KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;String, Long&amp;#93;&lt;/span&gt; =&lt;br/&gt;
+        textLines&lt;br/&gt;
+          .transform(() =&amp;gt; new Transformer[String, String, KeyValue&lt;span class=&quot;error&quot;&gt;&amp;#91;String, String&amp;#93;&lt;/span&gt;] &lt;/p&gt;
{
+              override def init(context: ProcessorContext): Unit = Unit
+              override def transform(key: String, value: String): KeyValue[String, String] =
+                new KeyValue(key, value.toLowerCase)
+              override def close(): Unit = Unit
+          }
&lt;p&gt;)&lt;br/&gt;
+          .groupBy((k, v) =&amp;gt; v)&lt;br/&gt;
+          .count()&lt;br/&gt;
+&lt;br/&gt;
+      streamBuilder.build().describe()&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    // build the Java topology&lt;br/&gt;
+    def getTopologyJava(): TopologyDescription = {&lt;br/&gt;
+&lt;br/&gt;
+      val streamBuilder = new StreamsBuilderJ&lt;br/&gt;
+      val textLines: KStreamJ&lt;span class=&quot;error&quot;&gt;&amp;#91;String, String&amp;#93;&lt;/span&gt; = streamBuilder.stream&lt;span class=&quot;error&quot;&gt;&amp;#91;String, String&amp;#93;&lt;/span&gt;(inputTopic)&lt;br/&gt;
+&lt;br/&gt;
+      val lowered: KStreamJ&lt;span class=&quot;error&quot;&gt;&amp;#91;String, String&amp;#93;&lt;/span&gt; = textLines&lt;br/&gt;
+        .transform(new TransformerSupplier[String, String, KeyValue&lt;span class=&quot;error&quot;&gt;&amp;#91;String, String&amp;#93;&lt;/span&gt;] {&lt;br/&gt;
+        override def get(): Transformer[String, String, KeyValue&lt;span class=&quot;error&quot;&gt;&amp;#91;String, String&amp;#93;&lt;/span&gt;] = new Transformer[String, String, KeyValue&lt;span class=&quot;error&quot;&gt;&amp;#91;String, String&amp;#93;&lt;/span&gt;] &lt;/p&gt;
{
+          override def init(context: ProcessorContext): Unit = Unit
+
+          override def transform(key: String, value: String): KeyValue[String, String] =
+            new KeyValue(key, value.toLowerCase)
+
+          override def close(): Unit = Unit
+        }
&lt;p&gt;+      })&lt;br/&gt;
+&lt;br/&gt;
+      val grouped: KGroupedStreamJ&lt;span class=&quot;error&quot;&gt;&amp;#91;String, String&amp;#93;&lt;/span&gt; = lowered.groupBy {&lt;br/&gt;
+        new KeyValueMapper&lt;span class=&quot;error&quot;&gt;&amp;#91;String, String, String&amp;#93;&lt;/span&gt; &lt;/p&gt;
{
+          def apply(k: String, v: String): String = v
+        }
&lt;p&gt;+      }&lt;br/&gt;
+&lt;br/&gt;
+      val wordCounts: KTableJ&lt;span class=&quot;error&quot;&gt;&amp;#91;String, java.lang.Long&amp;#93;&lt;/span&gt; = grouped.count()&lt;br/&gt;
+&lt;br/&gt;
+      streamBuilder.build().describe()&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    // should match&lt;br/&gt;
+    assertEquals(getTopologyScala(), getTopologyJava())&lt;br/&gt;
+  }&lt;br/&gt;
 }&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16574974" author="vvcephei" created="Thu, 9 Aug 2018 15:09:17 +0000"  >&lt;p&gt;I&apos;ve created &lt;a href=&quot;https://github.com/apache/kafka/pull/5481&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5481&lt;/a&gt;&#160;to make transform expect a TransformerSupplier instead of a Function&lt;span class=&quot;error&quot;&gt;&amp;#91;Transformer&amp;#93;&lt;/span&gt;. This is a super minor change, but it does move us toward having one pattern for these methods instead of two.&lt;/p&gt;

&lt;p&gt;( I started the PR because I thought there was a way to fix the bug without breaking the API, but instead my dreams were broken. Nevertheless, I think just moving toward Supplier is still beneficial. )&lt;/p&gt;</comment>
                            <comment id="16575146" author="githubbot" created="Thu, 9 Aug 2018 17:12:02 +0000"  >&lt;p&gt;guozhangwang closed pull request #5481: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7250&quot; title=&quot;Kafka-Streams-Scala DSL transform shares transformer instance&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7250&quot;&gt;&lt;del&gt;KAFKA-7250&lt;/del&gt;&lt;/a&gt;: switch scala transform to TransformSupplier&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5481&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5481&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/build.gradle b/build.gradle&lt;br/&gt;
index 83b169b0a51..7f5a1d9e83c 100644&lt;br/&gt;
&amp;#8212; a/build.gradle&lt;br/&gt;
+++ b/build.gradle&lt;br/&gt;
@@ -1015,6 +1015,7 @@ project(&apos;:streams:streams-scala&apos;) &lt;/p&gt;
{
 
     testCompile libs.junit
     testCompile libs.scalatest
+    testCompile libs.easymock
 
     testRuntime libs.slf4jlog4j
   }
&lt;p&gt;diff --git a/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KStream.scala b/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KStream.scala&lt;br/&gt;
index a8766bd3566..adc1850dc32 100644&lt;br/&gt;
&amp;#8212; a/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KStream.scala&lt;br/&gt;
+++ b/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KStream.scala&lt;br/&gt;
@@ -22,7 +22,7 @@ package kstream&lt;/p&gt;

&lt;p&gt; import org.apache.kafka.streams.KeyValue&lt;br/&gt;
 import org.apache.kafka.streams.kstream.&lt;/p&gt;
{KStream =&amp;gt; KStreamJ, _}
&lt;p&gt;-import org.apache.kafka.streams.processor.&lt;/p&gt;
{Processor, ProcessorSupplier, TopicNameExtractor}
&lt;p&gt;+import org.apache.kafka.streams.processor.&lt;/p&gt;
{Processor, ProcessorContext, ProcessorSupplier, TopicNameExtractor}
&lt;p&gt; import org.apache.kafka.streams.scala.ImplicitConversions._&lt;br/&gt;
 import org.apache.kafka.streams.scala.FunctionConversions._&lt;/p&gt;

&lt;p&gt;@@ -31,8 +31,8 @@ import scala.collection.JavaConverters._&lt;br/&gt;
 /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Wraps the Java class [&lt;span class=&quot;error&quot;&gt;&amp;#91;org.apache.kafka.streams.kstream.KStream&amp;#93;&lt;/span&gt;] and delegates method calls to the underlying Java object.&lt;br/&gt;
  *&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* @param &lt;span class=&quot;error&quot;&gt;&amp;#91;K&amp;#93;&lt;/span&gt; Type of keys&lt;/li&gt;
	&lt;li&gt;* @param &lt;span class=&quot;error&quot;&gt;&amp;#91;V&amp;#93;&lt;/span&gt; Type of values&lt;br/&gt;
+ * @tparam K Type of keys&lt;br/&gt;
+ * @tparam V Type of values&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param inner The underlying Java abstraction for KStream&lt;br/&gt;
  *&lt;/li&gt;
	&lt;li&gt;@see `org.apache.kafka.streams.kstream.KStream`&lt;br/&gt;
@@ -167,7 +167,7 @@ class KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(val inner: KStreamJ&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
   def print(printed: Printed&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;): Unit = inner.print(printed)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Perform an action on each record of &apos;KStream`&lt;br/&gt;
+   * Perform an action on each record of `KStream`&lt;br/&gt;
    *&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param action an action to perform on each record&lt;/li&gt;
	&lt;li&gt;@see `org.apache.kafka.streams.kstream.KStream#foreach`&lt;br/&gt;
@@ -176,14 +176,15 @@ class KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(val inner: KStreamJ&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
     inner.foreach((k: K, v: V) =&amp;gt; action(k, v))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Creates an array of 
{@code KStream} from this stream by branching the records in the original stream based on&lt;br/&gt;
+   * Creates an array of `KStream` from this stream by branching the records in the original stream based on&lt;br/&gt;
    * the supplied predicates.&lt;br/&gt;
    *&lt;br/&gt;
    * @param predicates the ordered list of functions that return a Boolean&lt;br/&gt;
    * @return multiple distinct substreams of this [&lt;span class=&quot;error&quot;&gt;&amp;#91;KStream&amp;#93;&lt;/span&gt;]&lt;br/&gt;
    * @see `org.apache.kafka.streams.kstream.KStream#branch`&lt;br/&gt;
    */&lt;br/&gt;
-  def branch(predicates: (K, V) =&amp;gt; Boolean*): Array[KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;] =&lt;br/&gt;
+  //noinspection ScalaUnnecessaryParentheses&lt;br/&gt;
+  def branch(predicates: ((K, V) =&amp;gt; Boolean)*): Array[KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;] =&lt;br/&gt;
     inner.branch(predicates.map(_.asPredicate): _*).map(kstream =&amp;gt; wrapKStream(kstream))&lt;br/&gt;
 &lt;br/&gt;
   /**&lt;br/&gt;
@@ -211,7 +212,7 @@ class KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(val inner: KStreamJ&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;) {
    * }}}&lt;br/&gt;
    *&lt;br/&gt;
    * @param topic the topic name&lt;br/&gt;
-   * @param (implicit) produced the instance of Produced that gives the serdes and `StreamPartitioner`&lt;br/&gt;
+   * @param produced the instance of Produced that gives the serdes and `StreamPartitioner`&lt;br/&gt;
    * @return a [&lt;span class=&quot;error&quot;&gt;&amp;#91;KStream&amp;#93;&lt;/span&gt;] that contains the exact same (and potentially repartitioned) records as this [&lt;span class=&quot;error&quot;&gt;&amp;#91;KStream&amp;#93;&lt;/span&gt;]&lt;br/&gt;
    * @see `org.apache.kafka.streams.kstream.KStream#through`&lt;br/&gt;
    */&lt;br/&gt;
@@ -243,7 +244,7 @@ class KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(val inner: KStreamJ&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;) {    * }}}&lt;br/&gt;
    *&lt;br/&gt;
    * @param topic the topic name&lt;br/&gt;
-   * @param (implicit) produced the instance of Produced that gives the serdes and `StreamPartitioner`&lt;br/&gt;
+   * @param produced the instance of Produced that gives the serdes and `StreamPartitioner`&lt;br/&gt;
    * @see `org.apache.kafka.streams.kstream.KStream#to`&lt;br/&gt;
    */&lt;br/&gt;
   def to(topic: String)(implicit produced: Produced&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;): Unit =&lt;br/&gt;
@@ -275,7 +276,7 @@ class KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(val inner: KStreamJ&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;) {
    * }}}&lt;br/&gt;
    *&lt;br/&gt;
    * @param extractor the extractor to determine the name of the Kafka topic to write to for reach record&lt;br/&gt;
-   * @param (implicit) produced the instance of Produced that gives the serdes and `StreamPartitioner`&lt;br/&gt;
+   * @param produced the instance of Produced that gives the serdes and `StreamPartitioner`&lt;br/&gt;
    * @see `org.apache.kafka.streams.kstream.KStream#to`&lt;br/&gt;
    */&lt;br/&gt;
   def to(extractor: TopicNameExtractor&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;)(implicit produced: Produced&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;): Unit =&lt;br/&gt;
@@ -295,9 +296,9 @@ class KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(val inner: KStreamJ&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
    * @return a [&lt;span class=&quot;error&quot;&gt;&amp;#91;KStream&amp;#93;&lt;/span&gt;] that contains more or less records with new key and value (possibly of different type)&lt;br/&gt;
    * @see `org.apache.kafka.streams.kstream.KStream#transform`&lt;br/&gt;
    */&lt;br/&gt;
-  def transform&lt;span class=&quot;error&quot;&gt;&amp;#91;K1, V1&amp;#93;&lt;/span&gt;(transformerSupplier: () =&amp;gt; Transformer[K, V, KeyValue&lt;span class=&quot;error&quot;&gt;&amp;#91;K1, V1&amp;#93;&lt;/span&gt;],&lt;br/&gt;
+  def transform&lt;span class=&quot;error&quot;&gt;&amp;#91;K1, V1&amp;#93;&lt;/span&gt;(transformerSupplier: TransformerSupplier[K, V, KeyValue&lt;span class=&quot;error&quot;&gt;&amp;#91;K1, V1&amp;#93;&lt;/span&gt;],&lt;br/&gt;
                         stateStoreNames: String*): KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;K1, V1&amp;#93;&lt;/span&gt; =&lt;br/&gt;
-    inner.transform(transformerSupplier.asTransformerSupplier, stateStoreNames: _*)&lt;br/&gt;
+    inner.transform(transformerSupplier, stateStoreNames: _*)&lt;br/&gt;
 &lt;br/&gt;
   /**&lt;br/&gt;
    * Transform the value of each input record into a new value (with possible new type) of the output record.&lt;br/&gt;
@@ -337,11 +338,12 @@ class KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(val inner: KStreamJ&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
    * In order to assign a state, the state must be created and registered&lt;br/&gt;
    * beforehand via stores added via `addStateStore` or `addGlobalStore` before they can be connected to the `Transformer`&lt;br/&gt;
    *&lt;br/&gt;
-   * @param processorSupplier a function that generates a [&lt;span class=&quot;error&quot;&gt;&amp;#91;org.apache.kafka.stream.Processor&amp;#93;&lt;/span&gt;]&lt;br/&gt;
+   * @param processorSupplier a function that generates a [&lt;span class=&quot;error&quot;&gt;&amp;#91;org.apache.kafka.streams.processor.Processor&amp;#93;&lt;/span&gt;]&lt;br/&gt;
    * @param stateStoreNames   the names of the state store used by the processor&lt;br/&gt;
    * @see `org.apache.kafka.streams.kstream.KStream#process`&lt;br/&gt;
    */&lt;br/&gt;
   def process(processorSupplier: () =&amp;gt; Processor&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;, stateStoreNames: String*): Unit = {&lt;br/&gt;
+    //noinspection ConvertExpressionToSAM // because of the 2.11 build&lt;br/&gt;
     val processorSupplierJ: ProcessorSupplier&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt; = new ProcessorSupplier&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt; {
       override def get(): Processor[K, V] = processorSupplier()
     }&lt;br/&gt;
@@ -374,7 +376,7 @@ class KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(val inner: KStreamJ&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;) {
    * // to the groupByKey call
    * }}}&lt;br/&gt;
    *&lt;br/&gt;
-   * @param (implicit) serialized the instance of Serialized that gives the serdes&lt;br/&gt;
+   * @param serialized the instance of Serialized that gives the serdes&lt;br/&gt;
    * @return a [&lt;span class=&quot;error&quot;&gt;&amp;#91;KGroupedStream&amp;#93;&lt;/span&gt;] that contains the grouped records of the original [&lt;span class=&quot;error&quot;&gt;&amp;#91;KStream&amp;#93;&lt;/span&gt;]&lt;br/&gt;
    * @see `org.apache.kafka.streams.kstream.KStream#groupByKey`&lt;br/&gt;
    */&lt;br/&gt;
@@ -564,7 +566,7 @@ class KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(val inner: KStreamJ&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;) {&lt;br/&gt;
   def merge(stream: KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;): KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt; = inner.merge(stream.inner)&lt;br/&gt;
 &lt;br/&gt;
   /**&lt;br/&gt;
-   * Perform an action on each record of {@code KStream}
&lt;p&gt;.&lt;br/&gt;
+   * Perform an action on each record of `KStream`.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;&amp;lt;p&amp;gt;&lt;/li&gt;
	&lt;li&gt;Peek is a non-terminal operation that triggers a side effect (such as logging or statistics collection)&lt;/li&gt;
	&lt;li&gt;and returns an unchanged stream.&lt;br/&gt;
diff --git a/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/TopologyTest.scala b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/TopologyTest.scala&lt;br/&gt;
index 8a0eabb3af4..b596dd37fa6 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/TopologyTest.scala&lt;br/&gt;
+++ b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/TopologyTest.scala&lt;br/&gt;
@@ -21,19 +21,16 @@ package org.apache.kafka.streams.scala&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import java.util.regex.Pattern&lt;/p&gt;

&lt;p&gt;-import org.scalatest.junit.JUnitSuite&lt;br/&gt;
-import org.junit.Assert._&lt;br/&gt;
-import org.junit._&lt;br/&gt;
-&lt;br/&gt;
+import org.apache.kafka.streams.kstream.&lt;/p&gt;
{KGroupedStream =&amp;gt; KGroupedStreamJ, KStream =&amp;gt; KStreamJ, KTable =&amp;gt; KTableJ, _}
&lt;p&gt;+import org.apache.kafka.streams.processor.ProcessorContext&lt;br/&gt;
+import org.apache.kafka.streams.scala.ImplicitConversions._&lt;br/&gt;
 import org.apache.kafka.streams.scala.kstream._&lt;br/&gt;
-&lt;br/&gt;
-import ImplicitConversions._&lt;br/&gt;
-&lt;br/&gt;
 import org.apache.kafka.streams.&lt;/p&gt;
{StreamsBuilder =&amp;gt; StreamsBuilderJ, _}
&lt;p&gt;-import org.apache.kafka.streams.kstream.&lt;/p&gt;
{KTable =&amp;gt; KTableJ, KStream =&amp;gt; KStreamJ, KGroupedStream =&amp;gt; KGroupedStreamJ, _}
&lt;p&gt;-import org.apache.kafka.streams.processor.ProcessorContext&lt;br/&gt;
+import org.junit.Assert._&lt;br/&gt;
+import org.junit._&lt;br/&gt;
+import org.scalatest.junit.JUnitSuite&lt;/p&gt;

&lt;p&gt;-import collection.JavaConverters._&lt;br/&gt;
+import &lt;em&gt;root&lt;/em&gt;.scala.collection.JavaConverters._&lt;/p&gt;

&lt;p&gt; /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Test suite that verifies that the topology built by the Java and Scala APIs match.&lt;br/&gt;
@@ -207,17 +204,20 @@ class TopologyTest extends JUnitSuite {&lt;br/&gt;
       val streamBuilder = new StreamsBuilder&lt;br/&gt;
       val textLines = streamBuilder.stream&lt;span class=&quot;error&quot;&gt;&amp;#91;String, String&amp;#93;&lt;/span&gt;(inputTopic)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+      //noinspection ConvertExpressionToSAM due to 2.11 build&lt;br/&gt;
       val _: KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;String, Long&amp;#93;&lt;/span&gt; =&lt;br/&gt;
         textLines&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;.transform(&lt;/li&gt;
	&lt;li&gt;() =&amp;gt;&lt;br/&gt;
+          .transform(new TransformerSupplier[String, String, KeyValue&lt;span class=&quot;error&quot;&gt;&amp;#91;String, String&amp;#93;&lt;/span&gt;] {&lt;br/&gt;
+            override def get(): Transformer[String, String, KeyValue&lt;span class=&quot;error&quot;&gt;&amp;#91;String, String&amp;#93;&lt;/span&gt;] =&lt;br/&gt;
               new Transformer[String, String, KeyValue&lt;span class=&quot;error&quot;&gt;&amp;#91;String, String&amp;#93;&lt;/span&gt;] 
{
                 override def init(context: ProcessorContext): Unit = Unit
+
                 override def transform(key: String, value: String): KeyValue[String, String] =
                   new KeyValue(key, value.toLowerCase)
+
                 override def close(): Unit = Unit
-            }&lt;/li&gt;
	&lt;li&gt;)&lt;br/&gt;
+              }&lt;br/&gt;
+          })&lt;br/&gt;
           .groupBy((k, v) =&amp;gt; v)&lt;br/&gt;
           .count()&lt;/li&gt;
&lt;/ul&gt;






&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13212595">KAFKA-7882</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 14 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3wq7j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>