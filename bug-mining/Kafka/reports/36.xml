<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:34:52 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-171] Kafka producer should do a single write to send message sets</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-171</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;From email thread: &lt;br/&gt;
&lt;a href=&quot;http://mail-archives.apache.org/mod_mbox/incubator-kafka-dev/201110.mbox/%3cCAFbh0Q1PYUj32thBaYQ29E6J4wT_mrG5SuUsfdeGWj6rmEx9Gw@mail.gmail.com%3e&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://mail-archives.apache.org/mod_mbox/incubator-kafka-dev/201110.mbox/%3cCAFbh0Q1PYUj32thBaYQ29E6J4wT_mrG5SuUsfdeGWj6rmEx9Gw@mail.gmail.com%3e&lt;/a&gt;&lt;br/&gt;
&amp;gt; Before sending an actual message, kafka producer do send a (control) message of 4 bytes to the server. Kafka producer always does this action before send some message to the server.&lt;/p&gt;

&lt;p&gt;I think this is because in BoundedByteBufferSend.scala we do essentially&lt;br/&gt;
 channel.write(sizeBuffer)&lt;br/&gt;
 channel.write(dataBuffer)&lt;/p&gt;

&lt;p&gt;The correct solution is to use vector I/O and instead do&lt;br/&gt;
 channel.write(Array(sizeBuffer, dataBuffer))&lt;/p&gt;</description>
                <environment></environment>
        <key id="12528928">KAFKA-171</key>
            <summary>Kafka producer should do a single write to send message sets</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jkreps">Jay Kreps</assignee>
                                    <reporter username="jkreps">Jay Kreps</reporter>
                        <labels>
                    </labels>
                <created>Wed, 26 Oct 2011 17:52:10 +0000</created>
                <updated>Wed, 23 Nov 2011 07:30:02 +0000</updated>
                            <resolved>Wed, 23 Nov 2011 07:30:02 +0000</resolved>
                                    <version>0.7</version>
                    <version>0.8.0</version>
                                    <fixVersion>0.8.0</fixVersion>
                                    <component>core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>0</watches>
                                                                                                                <comments>
                            <comment id="13136193" author="jkreps" created="Wed, 26 Oct 2011 18:25:01 +0000"  >&lt;p&gt;Attached is a draft patch which turns the request into a single write. This is just a draft if this actually improves performance we should change Receive to use ScatteringByteChannel for consistency and also clean up a few more files with the same trick.&lt;/p&gt;

&lt;p&gt;On my mac laptop I do see a change in tcpdump which seems to eliminate the 4 byte send. However I don&apos;t see any positive result in performance for synchronous single-threaded sends of 10 byte messages (which should be the worst case for this). I think this may just be because I am testing over localhost.&lt;/p&gt;

&lt;p&gt;Here are the details on the results I have:&lt;/p&gt;

&lt;p&gt;TRUNK:&lt;br/&gt;
jkreps-mn:kafka-git jkreps$ sudo tcpdump -i lo0 port 9093 &lt;br/&gt;
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode&lt;br/&gt;
listening on lo0, link-type NULL (BSD loopback), capture size 96 bytes&lt;br/&gt;
10:32:30.128938 IP jkreps-mn.linkedin.biz.56953 &amp;gt; jkreps-mn.linkedin.biz.9093: S 323648854:323648854(0) win 65535 &amp;lt;mss 16344,nop,wscale 3,nop,nop,timestamp 377871870 0,sackOK,eol&amp;gt;&lt;br/&gt;
10:32:30.129004 IP jkreps-mn.linkedin.biz.9093 &amp;gt; jkreps-mn.linkedin.biz.56953: S 526915069:526915069(0) ack 323648855 win 65535 &amp;lt;mss 16344,nop,wscale 3,nop,nop,timestamp 377871870 377871870,sackOK,eol&amp;gt;&lt;br/&gt;
10:32:30.129013 IP jkreps-mn.linkedin.biz.56953 &amp;gt; jkreps-mn.linkedin.biz.9093: . ack 1 win 65535 &amp;lt;nop,nop,timestamp 377871870 377871870&amp;gt;&lt;br/&gt;
10:32:30.129022 IP jkreps-mn.linkedin.biz.9093 &amp;gt; jkreps-mn.linkedin.biz.56953: . ack 1 win 65535 &amp;lt;nop,nop,timestamp 377871870 377871870&amp;gt;&lt;br/&gt;
10:32:30.129306 IP jkreps-mn.linkedin.biz.56953 &amp;gt; jkreps-mn.linkedin.biz.9093: P 1:5(4) ack 1 win 65535 &amp;lt;nop,nop,timestamp 377871870 377871870&amp;gt;&lt;br/&gt;
10:32:30.129319 IP jkreps-mn.linkedin.biz.9093 &amp;gt; jkreps-mn.linkedin.biz.56953: . ack 5 win 65535 &amp;lt;nop,nop,timestamp 377871870 377871870&amp;gt;&lt;br/&gt;
10:32:30.129339 IP jkreps-mn.linkedin.biz.56953 &amp;gt; jkreps-mn.linkedin.biz.9093: P 5:41(36) ack 1 win 65535 &amp;lt;nop,nop,timestamp 377871870 377871870&amp;gt;&lt;br/&gt;
10:32:30.129350 IP jkreps-mn.linkedin.biz.9093 &amp;gt; jkreps-mn.linkedin.biz.56953: . ack 41 win 65535 &amp;lt;nop,nop,timestamp 377871870 377871870&amp;gt;&lt;br/&gt;
10:32:30.151892 IP jkreps-mn.linkedin.biz.56953 &amp;gt; jkreps-mn.linkedin.biz.9093: F 41:41(0) ack 1 win 65535 &amp;lt;nop,nop,timestamp 377871870 377871870&amp;gt;&lt;br/&gt;
10:32:30.151938 IP jkreps-mn.linkedin.biz.9093 &amp;gt; jkreps-mn.linkedin.biz.56953: . ack 42 win 65535 &amp;lt;nop,nop,timestamp 377871870 377871870&amp;gt;&lt;br/&gt;
10:32:30.151946 IP jkreps-mn.linkedin.biz.56953 &amp;gt; jkreps-mn.linkedin.biz.9093: . ack 1 win 65535 &amp;lt;nop,nop,timestamp 377871870 377871870&amp;gt;&lt;br/&gt;
10:32:30.152554 IP jkreps-mn.linkedin.biz.9093 &amp;gt; jkreps-mn.linkedin.biz.56953: F 1:1(0) ack 42 win 65535 &amp;lt;nop,nop,timestamp 377871870 377871870&amp;gt;&lt;br/&gt;
10:32:30.152571 IP jkreps-mn.linkedin.biz.56953 &amp;gt; jkreps-mn.linkedin.biz.9093: . ack 2 win 65535 &amp;lt;nop,nop,timestamp 377871870 377871870&amp;gt;&lt;/p&gt;

&lt;p&gt;PATCHED:&lt;br/&gt;
jkreps-mn:kafka-git jkreps$ sudo tcpdump -i lo0 port 9093 &lt;br/&gt;
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode&lt;br/&gt;
listening on lo0, link-type NULL (BSD loopback), capture size 96 bytes&lt;br/&gt;
10:35:40.637220 IP jkreps-mn.linkedin.biz.56993 &amp;gt; jkreps-mn.linkedin.biz.9093: S 1456363353:1456363353(0) win 65535 &amp;lt;mss 16344,nop,wscale 3,nop,nop,timestamp 377873772 0,sackOK,eol&amp;gt;&lt;br/&gt;
10:35:40.637287 IP jkreps-mn.linkedin.biz.9093 &amp;gt; jkreps-mn.linkedin.biz.56993: S 1260172914:1260172914(0) ack 1456363354 win 65535 &amp;lt;mss 16344,nop,wscale 3,nop,nop,timestamp 377873772 377873772,sackOK,eol&amp;gt;&lt;br/&gt;
10:35:40.637296 IP jkreps-mn.linkedin.biz.56993 &amp;gt; jkreps-mn.linkedin.biz.9093: . ack 1 win 65535 &amp;lt;nop,nop,timestamp 377873772 377873772&amp;gt;&lt;br/&gt;
10:35:40.637306 IP jkreps-mn.linkedin.biz.9093 &amp;gt; jkreps-mn.linkedin.biz.56993: . ack 1 win 65535 &amp;lt;nop,nop,timestamp 377873772 377873772&amp;gt;&lt;br/&gt;
10:35:40.657848 IP jkreps-mn.linkedin.biz.56993 &amp;gt; jkreps-mn.linkedin.biz.9093: P 1:41(40) ack 1 win 65535 &amp;lt;nop,nop,timestamp 377873773 377873772&amp;gt;&lt;br/&gt;
10:35:40.657886 IP jkreps-mn.linkedin.biz.9093 &amp;gt; jkreps-mn.linkedin.biz.56993: . ack 41 win 65535 &amp;lt;nop,nop,timestamp 377873773 377873773&amp;gt;&lt;br/&gt;
10:35:40.711399 IP jkreps-mn.linkedin.biz.56993 &amp;gt; jkreps-mn.linkedin.biz.9093: F 41:41(0) ack 1 win 65535 &amp;lt;nop,nop,timestamp 377873773 377873773&amp;gt;&lt;br/&gt;
10:35:40.711430 IP jkreps-mn.linkedin.biz.9093 &amp;gt; jkreps-mn.linkedin.biz.56993: . ack 42 win 65535 &amp;lt;nop,nop,timestamp 377873773 377873773&amp;gt;&lt;br/&gt;
10:35:40.711437 IP jkreps-mn.linkedin.biz.56993 &amp;gt; jkreps-mn.linkedin.biz.9093: . ack 1 win 65535 &amp;lt;nop,nop,timestamp 377873773 377873773&amp;gt;&lt;br/&gt;
10:35:40.762640 IP jkreps-mn.linkedin.biz.9093 &amp;gt; jkreps-mn.linkedin.biz.56993: F 1:1(0) ack 42 win 65535 &amp;lt;nop,nop,timestamp 377873774 377873773&amp;gt;&lt;br/&gt;
10:35:40.762678 IP jkreps-mn.linkedin.biz.56993 &amp;gt; jkreps-mn.linkedin.biz.9093: . ack 2 win 65535 &amp;lt;nop,nop,timestamp 377873774 377873774&amp;gt;&lt;/p&gt;

&lt;p&gt;TRUNK:&lt;br/&gt;
bin/kafka-producer-perf-test.sh --topic test --brokerinfo zk.connect=localhost:2181 --messages 300000 --message-size 10 --batch-size 1 --threads 1&lt;br/&gt;
...&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2011-10-26 10:33:58,458&amp;#93;&lt;/span&gt; INFO Total Num Messages: 300000 bytes: 3000000 in 13.636 secs (kafka.tools.ProducerPerformance$)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2011-10-26 10:33:58,459&amp;#93;&lt;/span&gt; INFO Messages/sec: 22000.5867 (kafka.tools.ProducerPerformance$)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2011-10-26 10:33:58,459&amp;#93;&lt;/span&gt; INFO MB/sec: 0.2098 (kafka.tools.ProducerPerformance$)&lt;/p&gt;

&lt;p&gt;PATCHED:&lt;br/&gt;
jkreps-mn:kafka-git jkreps$ bin/kafka-producer-perf-test.sh --topic test --brokerinfo zk.connect=localhost:2181 --messages 300000 --message-size 10 --batch-size 1 --threads 1&lt;br/&gt;
...&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2011-10-26 10:38:03,965&amp;#93;&lt;/span&gt; INFO Total Num Messages: 300000 bytes: 3000000 in 13.254 secs (kafka.tools.ProducerPerformance$)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2011-10-26 10:38:03,965&amp;#93;&lt;/span&gt; INFO Messages/sec: 22634.6763 (kafka.tools.ProducerPerformance$)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2011-10-26 10:38:03,966&amp;#93;&lt;/span&gt; INFO MB/sec: 0.2159 (kafka.tools.ProducerPerformance$)&lt;/p&gt;
</comment>
                            <comment id="13136201" author="nehanarkhede" created="Wed, 26 Oct 2011 18:30:18 +0000"  >&lt;p&gt;This is a good change to make. A couple of comments -&lt;/p&gt;

&lt;p&gt;1. Since we are changing WritableByteChannel to GatheringByteChannel, it is better to change the return type of writeTo and writeCompletely to return long, instead of int. This will avoid the coercion to Int in BoundedByteBufferSend.scala.&lt;/p&gt;

&lt;p&gt;2. There are a couple of other places, where we do these double writes, e.g. OffsetArraySend, MessageSetSend etc.  We might as well fix those ? &lt;/p&gt;</comment>
                            <comment id="13136223" author="jkreps" created="Wed, 26 Oct 2011 18:59:59 +0000"  >&lt;p&gt;Moving off localhost between my mac laptop and dev workstation (linux) I see similar results:&lt;/p&gt;

&lt;p&gt;TRUNK:&lt;br/&gt;
jkreps-mn:kafka-git jkreps$ bin/kafka-producer-perf-test.sh --topic test --brokerinfo zk.connect=jkreps-ld:2181 --messages 500000 --message-size 10 --batch-size 1 --threads 1&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2011-10-26 11:59:51,795&amp;#93;&lt;/span&gt; INFO Total Num Messages: 500000 bytes: 5000000 in 13.046 secs (kafka.tools.ProducerPerformance$)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2011-10-26 11:59:51,795&amp;#93;&lt;/span&gt; INFO Messages/sec: 38325.9237 (kafka.tools.ProducerPerformance$)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2011-10-26 11:59:51,795&amp;#93;&lt;/span&gt; INFO MB/sec: 0.3655 (kafka.tools.ProducerPerformance$)&lt;/p&gt;

&lt;p&gt;PATCHED:&lt;br/&gt;
jkreps-mn:kafka-git jkreps$ bin/kafka-producer-perf-test.sh --topic test --brokerinfo zk.connect=jkreps-ld:2181 --messages 500000 --message-size 10 --batch-size 1 --threads 1&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2011-10-26 11:58:42,335&amp;#93;&lt;/span&gt; INFO Total Num Messages: 500000 bytes: 5000000 in 13.125 secs (kafka.tools.ProducerPerformance$)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2011-10-26 11:58:42,335&amp;#93;&lt;/span&gt; INFO Messages/sec: 38095.2381 (kafka.tools.ProducerPerformance$)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2011-10-26 11:58:42,335&amp;#93;&lt;/span&gt; INFO MB/sec: 0.3633 (kafka.tools.ProducerPerformance$)&lt;/p&gt;</comment>
                            <comment id="13136622" author="cburroughs" created="Thu, 27 Oct 2011 00:07:40 +0000"  >&lt;p&gt;Even if this doesn&apos;t measurably improve node to node performance (and I&apos;m not sure we should expect it to since we don&apos;t have to wait for an ACK to send the next packet), isn&apos;t it definitely making life better for network engineer?&lt;/p&gt;</comment>
                            <comment id="13136662" author="jkreps" created="Thu, 27 Oct 2011 01:07:55 +0000"  >&lt;p&gt;Yes, I think we should do it. My concern was just that I might be misunderstanding tcpdump or something since I find this a little counter-intuitive..&lt;/p&gt;</comment>
                            <comment id="13139940" author="jkreps" created="Mon, 31 Oct 2011 05:55:56 +0000"  >&lt;p&gt;Okay this patch completes the conversion to GatheringByteChannel. I recommend we take this even though there doesn&apos;t seem to be real perf difference just because the network profile is better.&lt;/p&gt;</comment>
                            <comment id="13140857" author="nehanarkhede" created="Tue, 1 Nov 2011 02:20:06 +0000"  >&lt;p&gt;Since we are changing WritableByteChannel to GatheringByteChannel, would it be better to change the return type of writeTo and writeCompletely to return long, instead of int. This will avoid the coercion to Int in BoundedByteBufferSend.scala.&lt;/p&gt;
</comment>
                            <comment id="13140914" author="jkreps" created="Tue, 1 Nov 2011 04:33:52 +0000"  >&lt;p&gt;I actually don&apos;t think we should make the writeTo method return a long since we use 4 byte ints in the protocol to delimit size of request so we really can&apos;t take a buffer &amp;gt; Int.MaxValue. I added a check on this to avoid an overflow if the size is &amp;gt; Int.MaxValue - 4, which is unlikely but possible.&lt;/p&gt;</comment>
                            <comment id="13140935" author="nehanarkhede" created="Tue, 1 Nov 2011 05:10:10 +0000"  >&lt;p&gt;nnarkhed-mn:kafka-171 nnarkhed$ find . -name &quot;*scala&quot; -exec grep -Hi &quot;asInstanceOf[Int]&quot; {} \;&lt;br/&gt;
./core/src/main/scala/kafka/api/OffsetRequest.scala:  header.putInt(size.asInstanceOf&lt;span class=&quot;error&quot;&gt;&amp;#91;Int&amp;#93;&lt;/span&gt; + 2)&lt;br/&gt;
./core/src/main/scala/kafka/api/ProducerRequest.scala:  def sizeInBytes(): Int = 2 + topic.length + 4 + 4 + messages.sizeInBytes.asInstanceOf&lt;span class=&quot;error&quot;&gt;&amp;#91;Int&amp;#93;&lt;/span&gt;&lt;br/&gt;
./core/src/main/scala/kafka/network/BoundedByteBufferSend.scala:    written.asInstanceOf&lt;span class=&quot;error&quot;&gt;&amp;#91;Int&amp;#93;&lt;/span&gt;&lt;br/&gt;
./core/src/main/scala/kafka/producer/SyncProducer.scala:    val setSize = messages.sizeInBytes.asInstanceOf&lt;span class=&quot;error&quot;&gt;&amp;#91;Int&amp;#93;&lt;/span&gt;&lt;br/&gt;
./core/src/main/scala/kafka/server/MessageSetSend.scala:  header.putInt(size.asInstanceOf&lt;span class=&quot;error&quot;&gt;&amp;#91;Int&amp;#93;&lt;/span&gt; + 2)&lt;br/&gt;
./core/src/main/scala/kafka/server/MessageSetSend.scala:      written += fileBytesSent.asInstanceOf&lt;span class=&quot;error&quot;&gt;&amp;#91;Int&amp;#93;&lt;/span&gt;&lt;br/&gt;
./core/src/main/scala/kafka/server/MessageSetSend.scala:  def sendSize: Int = size.asInstanceOf&lt;span class=&quot;error&quot;&gt;&amp;#91;Int&amp;#93;&lt;/span&gt; + header.capacity&lt;br/&gt;
./core/src/main/scala/kafka/utils/Utils.scala:    buffer.putInt((value &amp;amp; 0xffffffffL).asInstanceOf&lt;span class=&quot;error&quot;&gt;&amp;#91;Int&amp;#93;&lt;/span&gt;)&lt;br/&gt;
./core/src/main/scala/kafka/utils/Utils.scala:    buffer.putInt(index, (value &amp;amp; 0xffffffffL).asInstanceOf&lt;span class=&quot;error&quot;&gt;&amp;#91;Int&amp;#93;&lt;/span&gt;)&lt;/p&gt;

&lt;p&gt;Its not great that we have so many places where we need to worry about coercion, but we can clean this up the next time we change the on wire protocol.&lt;/p&gt;

&lt;p&gt;+1 on the latest patch&lt;/p&gt;</comment>
                            <comment id="13141272" author="junrao" created="Tue, 1 Nov 2011 16:10:28 +0000"  >&lt;p&gt;MessageSet has a couple of unused imports. Other than that, the patch looks good. &lt;/p&gt;</comment>
                            <comment id="13141295" author="jkreps" created="Tue, 1 Nov 2011 16:27:38 +0000"  >&lt;p&gt;Cool, will clean up imports before checking in. I am going to hold off on this until after 0.7 goes out.&lt;/p&gt;</comment>
                            <comment id="13141374" author="nehanarkhede" created="Tue, 1 Nov 2011 17:37:41 +0000"  >&lt;p&gt;You can check it into trunk. 0.7 is going off its own branch&lt;/p&gt;</comment>
                            <comment id="13155735" author="jkreps" created="Wed, 23 Nov 2011 07:30:02 +0000"  >&lt;p&gt;Committed.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12500925" name="KAFKA-171-draft.patch" size="4289" author="jkreps" created="Wed, 26 Oct 2011 17:57:25 +0000"/>
                            <attachment id="12501735" name="KAFKA-171-v2.patch" size="8072" author="jkreps" created="Tue, 1 Nov 2011 04:33:52 +0000"/>
                            <attachment id="12501570" name="KAFKA-171.patch" size="7355" author="jkreps" created="Mon, 31 Oct 2011 05:55:56 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>214788</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            14 years, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i09mbb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>54048</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>