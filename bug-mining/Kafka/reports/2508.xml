<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:22:19 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6266] Kafka 1.0.0 : Repeated occurrence of WARN Resetting first dirty offset of __consumer_offsets-xx to log start offset 203569 since the checkpointed offset 120955 is invalid. (kafka.log.LogCleanerManager$)</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6266</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;I upgraded Kafka from 0.10.2.1 to 1.0.0 version. From then, I see the below warnings in the log.&lt;br/&gt;
 I&apos;m seeing these continuously in the log, and want these to be fixed- so that they wont repeat. Can someone please help me in fixing the below warnings.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
WARN Resetting first dirty offset of __consumer_offsets-17 to log start offset 3346 since the checkpointed offset 3332 is invalid. (kafka.log.LogCleanerManager$)
 WARN Resetting first dirty offset of __consumer_offsets-23 to log start offset 4 since the checkpointed offset 1 is invalid. (kafka.log.LogCleanerManager$)
 WARN Resetting first dirty offset of __consumer_offsets-19 to log start offset 203569 since the checkpointed offset 120955 is invalid. (kafka.log.LogCleanerManager$)
 WARN Resetting first dirty offset of __consumer_offsets-35 to log start offset 16957 since the checkpointed offset 7 is invalid. (kafka.log.LogCleanerManager$)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment>CentOS 7, Apache kafka_2.12-1.0.0</environment>
        <key id="13120491">KAFKA-6266</key>
            <summary>Kafka 1.0.0 : Repeated occurrence of WARN Resetting first dirty offset of __consumer_offsets-xx to log start offset 203569 since the checkpointed offset 120955 is invalid. (kafka.log.LogCleanerManager$)</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="david.mao">David Mao</assignee>
                                    <reporter username="Vinayzxzx">VinayKumar</reporter>
                        <labels>
                    </labels>
                <created>Thu, 23 Nov 2017 14:37:11 +0000</created>
                <updated>Tue, 12 Jan 2021 08:08:43 +0000</updated>
                            <resolved>Fri, 21 Feb 2020 02:15:35 +0000</resolved>
                                    <version>1.0.0</version>
                    <version>1.0.1</version>
                                    <fixVersion>2.4.1</fixVersion>
                    <fixVersion>2.6.0</fixVersion>
                                    <component>offset manager</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>16</watches>
                                                                                                                <comments>
                            <comment id="16264420" author="ijuma" created="Thu, 23 Nov 2017 14:45:01 +0000"  >&lt;p&gt;The errors don&apos;t go away after a while?&lt;/p&gt;</comment>
                            <comment id="16264653" author="vinayzxzx" created="Thu, 23 Nov 2017 17:48:37 +0000"  >&lt;p&gt;Thank you for the reply.&lt;br/&gt;
The errors don&apos;t go away, they are continuously seen repeating in the log ever.&lt;/p&gt;</comment>
                            <comment id="16264728" author="michal.klempa" created="Thu, 23 Nov 2017 19:34:19 +0000"  >&lt;p&gt;I am experiencing this with Kafka 0.10.2.1 (confluent platform), CentOS6&lt;/p&gt;</comment>
                            <comment id="16268257" author="michal.klempa" created="Tue, 28 Nov 2017 07:06:08 +0000"  >&lt;p&gt;I ran into the situation, where my log segment is 0 in byt length:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
__consumer_offsets-35]# ls -l
total 0
-rw-r--r--. 1 kafka kafka 10485760 nov 27 20:20 00000000000000000183.index
-rw-r--r--. 1 kafka kafka        0 nov  1 12:39 00000000000000000183.log
-rw-r--r--. 1 kafka kafka 10485756 nov 27 20:20 00000000000000000183.timeindex
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The base offset of the segment is 183 (as the file name says).&lt;br/&gt;
Debugging the LogCleanerManager shows me, that:&lt;br/&gt;
1. LogCleanerManager.grabFilthiestCompactedLog if called&lt;br/&gt;
2. then, line 99 (Kafka 0.10.0.2 version tag in git):&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  val (firstDirtyOffset, firstUncleanableDirtyOffset) = LogCleanerManager.cleanableOffsets(log, topicPartition,
            lastClean, now)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;call the cleanableOffsets method.&lt;br/&gt;
3. in cleanableOffsets, i see the&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
      val offset = lastCleanOffset.getOrElse(logStartOffset)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;value 138 is returned as the last cleaned offset.&lt;br/&gt;
4. as this value is lower than the base offset, the logStartOffset is set as the firstDirtyOffset.&lt;br/&gt;
5. then, the&lt;br/&gt;
    val dirtyNonActiveSegments = log.logSegments(firstDirtyOffset, log.activeSegment.baseOffset)&lt;br/&gt;
tries to select segments between 183 and 183, which returns 0 segments (shouldn&apos;t it return at least the active segment?).&lt;br/&gt;
6. even if it returned something, this segment is active, so it is not cleaned&lt;/p&gt;

&lt;p&gt;and the process repeats on timely manner.&lt;br/&gt;
The error would probably go aways if I was able to produce messages to Kafka. But I am not able to produce any message, no new offset get commited. Also replication stopeed working in my case (although I have min.insync = 1 so this would probably not block producing).&lt;br/&gt;
Consumer offsets are under-replicated and this is not going to be fixed automatically.&lt;/p&gt;

&lt;p&gt;This situation happened after several downtimes. Is it somehow possible to get out of this?&lt;/p&gt;</comment>
                            <comment id="16272422" author="huxi_2b" created="Thu, 30 Nov 2017 09:20:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=VinayKumar&quot; class=&quot;user-hover&quot; rel=&quot;VinayKumar&quot;&gt;VinayKumar&lt;/a&gt; what&apos;s the value for broker-side config `log.cleanup.policy`?&lt;/p&gt;</comment>
                            <comment id="16272553" author="vinayzxzx" created="Thu, 30 Nov 2017 11:39:17 +0000"  >&lt;p&gt;Hi,&lt;br/&gt;
The log.cleanup.policy is &apos;delete&apos;&lt;/p&gt;

&lt;p&gt;log.cleanup.policy = &lt;span class=&quot;error&quot;&gt;&amp;#91;delete&amp;#93;&lt;/span&gt;&lt;/p&gt;</comment>
                            <comment id="16283358" author="ijuma" created="Fri, 8 Dec 2017 10:51:01 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16440212" author="jeffwidman" created="Tue, 17 Apr 2018 00:38:25 +0000"  >&lt;p&gt;I am hitting this after upgrading a 0.10.0.1 broker to 1.0.1. &lt;/p&gt;

&lt;p&gt;the __consumer_offsets topic has the following config:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Topic:__consumer_offsets	PartitionCount:157	ReplicationFactor:2	Configs:segment.bytes=104857600,cleanup.policy=compact,compression.type=producer
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Ignore the non-standard partition count, that is a byproduct of a bug from years ago. In this case, I think the only effect is that it makes it less likely that a partition within the __consumer_offsets topic gets produced to, which it sounds like would clear this error.&lt;/p&gt;

&lt;p&gt;As described above, the external symptoms were a zero-byte log file that has a name like 00000000000000012526.log. &lt;/p&gt;

&lt;p&gt;Since this particular cluster has significantly more partitions in __consumer_offsets than it does consumer groups, it will not clear the error anytime soon because no consumer groups offsets are being hashed onto the problem partitions.&lt;/p&gt;

&lt;p&gt;So to get out of the situation, I shutdown all brokers that have replicas of the partition, then deleted the logfiles for that partition, then restarted the brokers. This cleared the filename so that it matched the zero-byte contents.&lt;/p&gt;

&lt;p&gt;Note that doing this in production will require downtime as you are taking a partition in the __consumer_offsets topic completely offline. On the flip side, you are only likely to hit this on somewhat underloaded clusters that can likely afford downtime... typically busy production clusters will clear themselves automatically through consumer groups producing to this partition.&lt;/p&gt;</comment>
                            <comment id="16745701" author="zkobza" created="Fri, 18 Jan 2019 01:41:56 +0000"  >&lt;p&gt;We recently encountered the same issue of a broker continuously logging:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Resetting first dirty offset of __consumer_offsets-33 to log start offset 97771750116 since the checkpointed offset 97760913467 is invalid. (kafka.log.LogCleanerManager$)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;And the broker&apos;s log cleaner stuck in a loop reprocessing __consumer_offsets-33 without moving onto other topic-partitions.&lt;/p&gt;

&lt;p&gt;I verified the contents of the &lt;tt&gt;cleaner-offset-checkpoint&lt;/tt&gt; file, used by the log cleaner manager, and discovered the last cleaned offset in the file is different than what was reported:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ grep &quot;__consumer_offsets 33&quot; /data/2/kafka/cleaner-offset-checkpoint
__consumer_offsets 33 97771750116 #&amp;gt;&amp;gt;&amp;gt; offset from log message 97760913467
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I found a duplicate entry in another &lt;tt&gt;cleaner-offset-checkpoint&lt;/tt&gt; file:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ find /data -name cleaner-offset-checkpoint | xargs grep &quot;__consumer_offsets 33&quot;
/data/2/kafka/cleaner-offset-checkpoint:__consumer_offsets 33 97771750116
/data/3/kafka/cleaner-offset-checkpoint:__consumer_offsets 33 97760913467
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I deleted the duplicate entry in &lt;tt&gt;/data/3/kafka/cleaner-offset-checkpoint&lt;/tt&gt;, because the __consumer_offsets-33 logs are located in &lt;tt&gt;/data/2/kafka&lt;/tt&gt;, also updating the entries size value and restarted the broker. No WARNs were logged and the log cleaner successfully cleaned all consumer offsets partitions.&lt;/p&gt;

&lt;p&gt;I do not know how the duplicate entry was created. We also upgraded from Kafka 0.11.0.1 to 1.1.1 recently.&lt;/p&gt;</comment>
                            <comment id="16987550" author="junrao" created="Wed, 4 Dec 2019 05:37:23 +0000"  >&lt;p&gt;Looking at the code where the &quot;Resetting first dirty offset &quot; warning is emitted.&#160;It seems that when we only return the new cleaning offset based on log start offset but not writing the new value to the cleaner offset checkpoint file. So, it the case when there is nothing to clean, this warning will repeat every time the log cleaner checks for logs to clean. To fix this, we should overwrite the cleaner offset checkpoint file as well.&lt;/p&gt;</comment>
                            <comment id="17034701" author="githubbot" created="Tue, 11 Feb 2020 18:34:46 +0000"  >&lt;p&gt;splett2 commented on pull request #8089: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6266&quot; title=&quot;Kafka 1.0.0 : Repeated occurrence of WARN Resetting first dirty offset of __consumer_offsets-xx to log start offset 203569 since the checkpointed offset 120955 is invalid. (kafka.log.LogCleanerManager$)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6266&quot;&gt;&lt;del&gt;KAFKA-6266&lt;/del&gt;&lt;/a&gt;: Repeated occurrence of WARN Resetting first dirty offset&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/8089&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/8089&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Previously, checkpointed offsets for a log were only updated if the log was chosen for cleaning once the cleaning job completes. This caused issues in cases where logs with invalid checkpointed offsets would repeatedly emit warnings if the log with an invalid cleaning checkpoint wasn&apos;t chosen for cleaning.&lt;/p&gt;

&lt;p&gt;   Proposed fix is to update the checkpointed offset for logs with invalid checkpoints regardless of whether it gets chosen for cleaning.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on to GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="17039518" author="githubbot" created="Tue, 18 Feb 2020 22:35:37 +0000"  >&lt;p&gt;junrao commented on pull request #8089: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6266&quot; title=&quot;Kafka 1.0.0 : Repeated occurrence of WARN Resetting first dirty offset of __consumer_offsets-xx to log start offset 203569 since the checkpointed offset 120955 is invalid. (kafka.log.LogCleanerManager$)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6266&quot;&gt;&lt;del&gt;KAFKA-6266&lt;/del&gt;&lt;/a&gt;: Repeated occurrence of WARN Resetting first dirty offset&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/8089&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/8089&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on to GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="17039522" author="junrao" created="Tue, 18 Feb 2020 22:42:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=david.mao&quot; class=&quot;user-hover&quot; rel=&quot;david.mao&quot;&gt;david.mao&lt;/a&gt;: I merged the PR to trunk. However, it doesn&apos;t apply to 2.4. Could you submit a separate PR for the 2.4 branch? Thanks.&lt;/p&gt;</comment>
                            <comment id="17039568" author="githubbot" created="Tue, 18 Feb 2020 23:56:38 +0000"  >&lt;p&gt;splett2 commented on pull request #8136: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6266&quot; title=&quot;Kafka 1.0.0 : Repeated occurrence of WARN Resetting first dirty offset of __consumer_offsets-xx to log start offset 203569 since the checkpointed offset 120955 is invalid. (kafka.log.LogCleanerManager$)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6266&quot;&gt;&lt;del&gt;KAFKA-6266&lt;/del&gt;&lt;/a&gt;: Repeated occurrence of WARN Resetting first dirty offset &#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/8136&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/8136&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   &#8230;(#8089)&lt;/p&gt;

&lt;p&gt;   Previously, checkpointed offsets for a log were only updated if the log was chosen for cleaning once the cleaning job completes. This caused issues in cases where logs with invalid checkpointed offsets would repeatedly emit warnings if the log with an invalid cleaning checkpoint wasn&apos;t chosen for cleaning.&lt;/p&gt;

&lt;p&gt;   Proposed fix is to update the checkpointed offset for logs with invalid checkpoints regardless of whether it gets chosen for cleaning.&lt;/p&gt;

&lt;p&gt;   Reviewers: Anna Povzner &amp;lt;anna@confluent.io&amp;gt;, Jun Rao &amp;lt;junrao@gmail.com&amp;gt;&lt;/p&gt;

&lt;p&gt;   *More detailed description of your change,&lt;br/&gt;
   if necessary. The PR title and PR message become&lt;br/&gt;
   the squashed commit message, so use a separate&lt;br/&gt;
   comment to ping reviewers.*&lt;/p&gt;

&lt;p&gt;   *Summary of testing strategy (including rationale)&lt;br/&gt;
   for the feature or bug fix. Unit and/or integration&lt;br/&gt;
   tests are expected for any behaviour change and&lt;br/&gt;
   system tests should be considered for larger changes.*&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on to GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="17041456" author="githubbot" created="Fri, 21 Feb 2020 02:14:31 +0000"  >&lt;p&gt;junrao commented on pull request #8136: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6266&quot; title=&quot;Kafka 1.0.0 : Repeated occurrence of WARN Resetting first dirty offset of __consumer_offsets-xx to log start offset 203569 since the checkpointed offset 120955 is invalid. (kafka.log.LogCleanerManager$)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6266&quot;&gt;&lt;del&gt;KAFKA-6266&lt;/del&gt;&lt;/a&gt;: Repeated occurrence of WARN Resetting first dirty offset &#8230;&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/8136&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/8136&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on to GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="17041458" author="junrao" created="Fri, 21 Feb 2020 02:15:35 +0000"  >&lt;p&gt;Merged into 2.4 and trunk.&lt;/p&gt;</comment>
                            <comment id="17085625" author="william_reynolds" created="Fri, 17 Apr 2020 10:24:45 +0000"  >&lt;p&gt;If anyone runs into this and needs a workaround before getting 2.4.1/trunk. Might need some tweaking based on where/how you log and obviously different if you aren&apos;t using systemd, will need user/dirs tweaked to be a general workaround&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
journalctl -u kafka --since &lt;span class=&quot;code-quote&quot;&gt;&apos;yesterday&apos;&lt;/span&gt; | grep &lt;span class=&quot;code-quote&quot;&gt;&apos;Resetting first dirty offset of&apos;&lt;/span&gt; | awk &lt;span class=&quot;code-quote&quot;&gt;&apos;{print $14 ,$19}&apos;&lt;/span&gt; | sort -u &amp;gt; /home/user/checkpoints
cp /kafka-topic-data/cleaner-offset-checkpoint /home/user
cat /home/user/checkpoints | sed -r &lt;span class=&quot;code-quote&quot;&gt;&apos;s/(.*)-/\1 /g&apos;&lt;/span&gt; &amp;gt; /home/user/checkpoints-processed
cat /home/user/checkpoints-processed cleaner-offset-checkpoint | sort --key=1,2 -u &amp;gt; /home/user/cleaner-offset-checkpoint.clean
sudo systemctl stop kafka; sudo mv /kafka-topic-data/cleaner-offset-checkpoint /home/user/; sudo mv /home/user/cleaner-offset-checkpoint.clean /kafka-topic-data/cleaner-offset-checkpoint; sudo chown -R kafka:kafka /kafka-topic-data/cleaner-offset-checkpoint; sleep 5; sudo systemctl start kafka
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17263146" author="akatona" created="Tue, 12 Jan 2021 08:08:43 +0000"  >&lt;p&gt;I had to modify the fix version, the commit landed on trunk is not included on 2.5.0, 2.5.1, but it is in 2.6.0.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 44 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3n56n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>