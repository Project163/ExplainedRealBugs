<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:14:01 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-7316] Use of filter method in KTable.scala may result in StackOverflowError</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-7316</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;In this thread:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://search-hadoop.com/m/Kafka/uyzND1dNbYKXzC4F1?subj=Issue+in+Kafka+2+0+0+&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://search-hadoop.com/m/Kafka/uyzND1dNbYKXzC4F1?subj=Issue+in+Kafka+2+0+0+&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Druhin reported seeing StackOverflowError when using filter method from KTable.scala&lt;/p&gt;

&lt;p&gt;This can be reproduced with the following change:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
diff --git a/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/StreamToTableJoinScalaIntegrationTestImplicitSerdes.scala b/streams/streams-scala/src/test/scala
index 3d1bab5..e0a06f2 100644
--- a/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/StreamToTableJoinScalaIntegrationTestImplicitSerdes.scala
+++ b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/StreamToTableJoinScalaIntegrationTestImplicitSerdes.scala
@@ -58,6 +58,7 @@ &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;StreamToTableJoinScalaIntegrationTestImplicitSerdes &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; StreamToTableJ
     val userClicksStream: KStream[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;] = builder.stream(userClicksTopic)

     val userRegionsTable: KTable[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;] = builder.table(userRegionsTopic)
+    userRegionsTable.filter { &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; (_, count) =&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; }

     &lt;span class=&quot;code-comment&quot;&gt;// Compute the total per region by summing the individual click counts per region.
&lt;/span&gt;     val clicksPerRegion: KTable[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;] =
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13180099">KAFKA-7316</key>
            <summary>Use of filter method in KTable.scala may result in StackOverflowError</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="joan@goyeau.com">Joan Goyeau</assignee>
                                    <reporter username="yuzhihong@gmail.com">Ted Yu</reporter>
                        <labels>
                            <label>scala</label>
                    </labels>
                <created>Tue, 21 Aug 2018 00:16:08 +0000</created>
                <updated>Wed, 31 Oct 2018 08:58:13 +0000</updated>
                            <resolved>Mon, 17 Sep 2018 16:25:32 +0000</resolved>
                                    <version>2.0.0</version>
                                    <fixVersion>2.0.1</fixVersion>
                    <fixVersion>2.1.0</fixVersion>
                                    <component>streams</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="16586909" author="yuzhihong@gmail.com" created="Tue, 21 Aug 2018 04:09:42 +0000"  >&lt;p&gt;Patch v4 makes the code compile.&lt;/p&gt;

&lt;p&gt;Just leaving it here showing one potential approach where there is no chance of Scala API having stack overflow error.&lt;/p&gt;</comment>
                            <comment id="16586927" author="githubbot" created="Tue, 21 Aug 2018 04:50:32 +0000"  >&lt;p&gt;tedyu opened a new pull request #5543: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7316&quot; title=&quot;Use of filter method in KTable.scala may result in StackOverflowError&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7316&quot;&gt;&lt;del&gt;KAFKA-7316&lt;/del&gt;&lt;/a&gt; Use of filter method in KTable.scala may result in StackOverflowError&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5543&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5543&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Due to lack of conversion to kstream Predicate, existing filter method in KTable.scala would result in StackOverflowError.&lt;/p&gt;

&lt;p&gt;   This PR fixes the bug and adds calls in StreamToTableJoinScalaIntegrationTestImplicitSerdes.testShouldCountClicksPerRegion to prevent regression.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16587959" author="githubbot" created="Tue, 21 Aug 2018 20:25:09 +0000"  >&lt;p&gt;tedyu closed pull request #5543: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7316&quot; title=&quot;Use of filter method in KTable.scala may result in StackOverflowError&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7316&quot;&gt;&lt;del&gt;KAFKA-7316&lt;/del&gt;&lt;/a&gt; Use of filter method in KTable.scala may result in StackOverflowError&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5543&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5543&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/FunctionConversions.scala b/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/FunctionConversions.scala&lt;br/&gt;
index 65ea4903326..ab0c5d2aebd 100644&lt;br/&gt;
&amp;#8212; a/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/FunctionConversions.scala&lt;br/&gt;
+++ b/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/FunctionConversions.scala&lt;br/&gt;
@@ -40,6 +40,12 @@ object FunctionConversions {&lt;br/&gt;
     }&lt;br/&gt;
   }&lt;/p&gt;

&lt;p&gt;+  implicit class ForeachActionFromFunction&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(val fa: (K, V) =&amp;gt; Unit) extends AnyVal {&lt;br/&gt;
+    def asForeachAction: ForeachAction&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt; = new ForeachAction&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt; &lt;/p&gt;
{
+      override def apply(key: K, value: V): Unit = fa(key, value)
+    }
&lt;p&gt;+  }&lt;br/&gt;
+&lt;br/&gt;
   implicit class MapperFromFunction&lt;span class=&quot;error&quot;&gt;&amp;#91;T, U, VR&amp;#93;&lt;/span&gt;(val f: (T, U) =&amp;gt; VR) extends AnyVal {&lt;br/&gt;
     def asKeyValueMapper: KeyValueMapper&lt;span class=&quot;error&quot;&gt;&amp;#91;T, U, VR&amp;#93;&lt;/span&gt; = new KeyValueMapper&lt;span class=&quot;error&quot;&gt;&amp;#91;T, U, VR&amp;#93;&lt;/span&gt; {&lt;br/&gt;
       override def apply(key: T, value: U): VR = f(key, value)&lt;br/&gt;
diff --git a/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KStream.scala b/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KStream.scala&lt;br/&gt;
index adc1850dc32..436a0c75d6a 100644&lt;br/&gt;
&amp;#8212; a/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KStream.scala&lt;br/&gt;
+++ b/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KStream.scala&lt;br/&gt;
@@ -173,7 +173,7 @@ class KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(val inner: KStreamJ&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;) {&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see `org.apache.kafka.streams.kstream.KStream#foreach`&lt;br/&gt;
    */&lt;br/&gt;
   def foreach(action: (K, V) =&amp;gt; Unit): Unit =&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;inner.foreach((k: K, v: V) =&amp;gt; action(k, v))&lt;br/&gt;
+    inner.foreach(action.asForeachAction)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Creates an array of `KStream` from this stream by branching the records in the original stream based on&lt;br/&gt;
@@ -575,5 +575,5 @@ class KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(val inner: KStreamJ&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;) 
{
    * @see `org.apache.kafka.streams.kstream.KStream#peek`
    */
   def peek(action: (K, V) =&amp;gt; Unit): KStream[K, V] =
-    inner.peek((k: K, v: V) =&amp;gt; action(k, v))
+    inner.peek(action.asForeachAction)
 }
&lt;p&gt;diff --git a/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KTable.scala b/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KTable.scala&lt;br/&gt;
index b66977193e1..42e7d4054ce 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KTable.scala&lt;br/&gt;
+++ b/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KTable.scala&lt;br/&gt;
@@ -46,7 +46,7 @@ class KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(val inner: KTableJ&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;) {&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;@see `org.apache.kafka.streams.kstream.KTable#filter`&lt;br/&gt;
    */&lt;br/&gt;
   def filter(predicate: (K, V) =&amp;gt; Boolean): KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt; =&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;inner.filter(predicate(_, _))&lt;br/&gt;
+    inner.filter(predicate.asPredicate)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Create a new [&lt;span class=&quot;error&quot;&gt;&amp;#91;KTable&amp;#93;&lt;/span&gt;] that consists all records of this [&lt;span class=&quot;error&quot;&gt;&amp;#91;KTable&amp;#93;&lt;/span&gt;] which satisfies the given&lt;br/&gt;
@@ -70,7 +70,7 @@ class KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(val inner: KTableJ&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;) {&lt;/li&gt;
	&lt;li&gt;@see `org.apache.kafka.streams.kstream.KTable#filterNot`&lt;br/&gt;
    */&lt;br/&gt;
   def filterNot(predicate: (K, V) =&amp;gt; Boolean): KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt; =&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;inner.filterNot(predicate(_, _))&lt;br/&gt;
+    inner.filterNot(predicate.asPredicate)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Create a new [&lt;span class=&quot;error&quot;&gt;&amp;#91;KTable&amp;#93;&lt;/span&gt;] that consists all records of this [&lt;span class=&quot;error&quot;&gt;&amp;#91;KTable&amp;#93;&lt;/span&gt;] which do &amp;lt;em&amp;gt;not&amp;lt;/em&amp;gt; satisfy the given&lt;br/&gt;
diff --git a/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/StreamToTableJoinScalaIntegrationTestImplicitSerdes.scala b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/StreamToTableJoinScalaIntegrationTestImplicitSerdes.scala&lt;br/&gt;
index 3d1bab5d086..da5e154e96d 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/StreamToTableJoinScalaIntegrationTestImplicitSerdes.scala&lt;br/&gt;
+++ b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/StreamToTableJoinScalaIntegrationTestImplicitSerdes.scala&lt;br/&gt;
@@ -58,6 +58,12 @@ class StreamToTableJoinScalaIntegrationTestImplicitSerdes extends StreamToTableJ&lt;br/&gt;
     val userClicksStream: KStream&lt;span class=&quot;error&quot;&gt;&amp;#91;String, Long&amp;#93;&lt;/span&gt; = builder.stream(userClicksTopic)&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val userRegionsTable: KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;String, String&amp;#93;&lt;/span&gt; = builder.table(userRegionsTopic)&lt;br/&gt;
+    userRegionsTable.filter &lt;/p&gt;
{ (_, _) =&amp;gt;
+      true
+    }
&lt;p&gt;+    userRegionsTable.filterNot &lt;/p&gt;
{ (_, _) =&amp;gt;
+      false
+    }

&lt;p&gt;     // Compute the total per region by summing the individual click counts per region.&lt;br/&gt;
     val clicksPerRegion: KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;String, Long&amp;#93;&lt;/span&gt; =&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16587961" author="yuzhihong@gmail.com" created="Tue, 21 Aug 2018 20:26:20 +0000"  >&lt;p&gt;I closed my PR since there was an earlier PR addressing the same problem:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/kafka/pull/5538&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5538&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I will handle peek method in another PR.&lt;/p&gt;</comment>
                            <comment id="16589389" author="joan@goyeau.com" created="Wed, 22 Aug 2018 21:53:54 +0000"  >&lt;p&gt;This &lt;a href=&quot;https://github.com/apache/kafka/pull/5539&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5539&lt;/a&gt;&#160;also fixes a similar issue on `foreach`.&lt;/p&gt;</comment>
                            <comment id="16590442" author="githubbot" created="Thu, 23 Aug 2018 16:15:29 +0000"  >&lt;p&gt;guozhangwang closed pull request #5538: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7316&quot; title=&quot;Use of filter method in KTable.scala may result in StackOverflowError&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7316&quot;&gt;&lt;del&gt;KAFKA-7316&lt;/del&gt;&lt;/a&gt; Fix Streams Scala filter recursive call&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5538&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5538&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KTable.scala b/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KTable.scala&lt;br/&gt;
index a78d321c941..d41496fb21c 100644&lt;br/&gt;
&amp;#8212; a/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KTable.scala&lt;br/&gt;
+++ b/streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/kstream/KTable.scala&lt;br/&gt;
@@ -47,7 +47,7 @@ class KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(val inner: KTableJ&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;) {&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@see `org.apache.kafka.streams.kstream.KTable#filter`&lt;br/&gt;
    */&lt;br/&gt;
   def filter(predicate: (K, V) =&amp;gt; Boolean): KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt; =&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;inner.filter(predicate(_, _))&lt;br/&gt;
+    inner.filter(predicate.asPredicate)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Create a new [&lt;span class=&quot;error&quot;&gt;&amp;#91;KTable&amp;#93;&lt;/span&gt;] that consists all records of this [&lt;span class=&quot;error&quot;&gt;&amp;#91;KTable&amp;#93;&lt;/span&gt;] which satisfies the given&lt;br/&gt;
@@ -71,7 +71,7 @@ class KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;(val inner: KTableJ&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;) {&lt;/li&gt;
	&lt;li&gt;@see `org.apache.kafka.streams.kstream.KTable#filterNot`&lt;br/&gt;
    */&lt;br/&gt;
   def filterNot(predicate: (K, V) =&amp;gt; Boolean): KTable&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt; =&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;inner.filterNot(predicate(_, _))&lt;br/&gt;
+    inner.filterNot(predicate.asPredicate)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Create a new [&lt;span class=&quot;error&quot;&gt;&amp;#91;KTable&amp;#93;&lt;/span&gt;] that consists all records of this [&lt;span class=&quot;error&quot;&gt;&amp;#91;KTable&amp;#93;&lt;/span&gt;] which do &amp;lt;em&amp;gt;not&amp;lt;/em&amp;gt; satisfy the given&lt;br/&gt;
diff --git a/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/KStreamTest.scala b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/KStreamTest.scala&lt;br/&gt;
index 6a302b207a9..2e2132d14eb 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/KStreamTest.scala&lt;br/&gt;
+++ b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/KStreamTest.scala&lt;br/&gt;
@@ -29,6 +29,52 @@ import org.scalatest.
{FlatSpec, Matchers}&lt;br/&gt;
 @RunWith(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;JUnitRunner&amp;#93;&lt;/span&gt;)&lt;br/&gt;
 class KStreamTest extends FlatSpec with Matchers with TestDriver {&lt;br/&gt;
 &lt;br/&gt;
+  &quot;filter a KStream&quot; should &quot;filter records satisfying the predicate&quot; in {
+    val builder = new StreamsBuilder()
+    val sourceTopic = &quot;source&quot;
+    val sinkTopic = &quot;sink&quot;
+
+    builder.stream[String, String](sourceTopic).filter((_, value) =&amp;gt; value != &quot;value2&quot;).to(sinkTopic)
+
+    val testDriver = createTestDriver(builder)
+
+    testDriver.pipeRecord(sourceTopic, (&quot;1&quot;, &quot;value1&quot;))
+    testDriver.readRecord[String, String](sinkTopic).value shouldBe &quot;value1&quot;
+
+    testDriver.pipeRecord(sourceTopic, (&quot;2&quot;, &quot;value2&quot;))
+    testDriver.readRecord[String, String](sinkTopic) shouldBe null
+
+    testDriver.pipeRecord(sourceTopic, (&quot;3&quot;, &quot;value3&quot;))
+    testDriver.readRecord[String, String](sinkTopic).value shouldBe &quot;value3&quot;
+
+    testDriver.readRecord[String, String](sinkTopic) shouldBe null
+
+    testDriver.close()
+  }&lt;br/&gt;
+&lt;br/&gt;
+  &quot;filterNot a KStream&quot; should &quot;filter records not satisfying the predicate&quot; in {
+    val builder = new StreamsBuilder()
+    val sourceTopic = &quot;source&quot;
+    val sinkTopic = &quot;sink&quot;
+
+    builder.stream[String, String](sourceTopic).filterNot((_, value) =&amp;gt; value == &quot;value2&quot;).to(sinkTopic)
+
+    val testDriver = createTestDriver(builder)
+
+    testDriver.pipeRecord(sourceTopic, (&quot;1&quot;, &quot;value1&quot;))
+    testDriver.readRecord[String, String](sinkTopic).value shouldBe &quot;value1&quot;
+
+    testDriver.pipeRecord(sourceTopic, (&quot;2&quot;, &quot;value2&quot;))
+    testDriver.readRecord[String, String](sinkTopic) shouldBe null
+
+    testDriver.pipeRecord(sourceTopic, (&quot;3&quot;, &quot;value3&quot;))
+    testDriver.readRecord[String, String](sinkTopic).value shouldBe &quot;value3&quot;
+
+    testDriver.readRecord[String, String](sinkTopic) shouldBe null
+
+    testDriver.close()
+  }&lt;br/&gt;
+&lt;br/&gt;
   &quot;selectKey a KStream&quot; should &quot;select a new key&quot; in {&lt;br/&gt;
     val builder = new StreamsBuilder()&lt;br/&gt;
     val sourceTopic = &quot;source&quot;&lt;br/&gt;
@@ -44,6 +90,8 @@ class KStreamTest extends FlatSpec with Matchers with TestDriver {
     testDriver.pipeRecord(sourceTopic, (&quot;1&quot;, &quot;value2&quot;))
     testDriver.readRecord[String, String](sinkTopic).key shouldBe &quot;value2&quot;
 
+    testDriver.readRecord[String, String](sinkTopic) shouldBe null
+
     testDriver.close()
   }&lt;br/&gt;
 &lt;br/&gt;
diff --git a/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/KTableTest.scala b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/KTableTest.scala&lt;br/&gt;
index 8c88ff5066f..2e9c821ed80 100644&lt;br/&gt;
&amp;#8212; a/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/KTableTest.scala&lt;br/&gt;
+++ b/streams/streams-scala/src/test/scala/org/apache/kafka/streams/scala/KTableTest.scala&lt;br/&gt;
@@ -29,6 +29,72 @@ import org.scalatest.{FlatSpec, Matchers}
&lt;p&gt; @RunWith(classOf&lt;span class=&quot;error&quot;&gt;&amp;#91;JUnitRunner&amp;#93;&lt;/span&gt;)&lt;br/&gt;
 class KTableTest extends FlatSpec with Matchers with TestDriver {&lt;/p&gt;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+  &quot;filter a KTable&quot; should &quot;filter records satisfying the predicate&quot; in {&lt;br/&gt;
+    val builder = new StreamsBuilder()&lt;br/&gt;
+    val sourceTopic = &quot;source&quot;&lt;br/&gt;
+    val sinkTopic = &quot;sink&quot;&lt;br/&gt;
+&lt;br/&gt;
+    val table = builder.stream&lt;span class=&quot;error&quot;&gt;&amp;#91;String, String&amp;#93;&lt;/span&gt;(sourceTopic).groupBy((key, _) =&amp;gt; key).count()&lt;br/&gt;
+    table.filter((_, value) =&amp;gt; value &amp;gt; 1).toStream.to(sinkTopic)&lt;br/&gt;
+&lt;br/&gt;
+    val testDriver = createTestDriver(builder)&lt;br/&gt;
+&lt;br/&gt;
+    &lt;/p&gt;
{
+      testDriver.pipeRecord(sourceTopic, (&quot;1&quot;, &quot;value1&quot;))
+      val record = testDriver.readRecord[String, Long](sinkTopic)
+      record.key shouldBe &quot;1&quot;
+      record.value shouldBe (null: java.lang.Long)
+    }
&lt;p&gt;+    &lt;/p&gt;
{
+      testDriver.pipeRecord(sourceTopic, (&quot;1&quot;, &quot;value2&quot;))
+      val record = testDriver.readRecord[String, Long](sinkTopic)
+      record.key shouldBe &quot;1&quot;
+      record.value shouldBe 2
+    }
&lt;p&gt;+    &lt;/p&gt;
{
+      testDriver.pipeRecord(sourceTopic, (&quot;2&quot;, &quot;value1&quot;))
+      val record = testDriver.readRecord[String, Long](sinkTopic)
+      record.key shouldBe &quot;2&quot;
+      record.value shouldBe (null: java.lang.Long)
+    }
&lt;p&gt;+    testDriver.readRecord&lt;span class=&quot;error&quot;&gt;&amp;#91;String, Long&amp;#93;&lt;/span&gt;(sinkTopic) shouldBe null&lt;br/&gt;
+&lt;br/&gt;
+    testDriver.close()&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  &quot;filterNot a KTable&quot; should &quot;filter records not satisfying the predicate&quot; in {&lt;br/&gt;
+    val builder = new StreamsBuilder()&lt;br/&gt;
+    val sourceTopic = &quot;source&quot;&lt;br/&gt;
+    val sinkTopic = &quot;sink&quot;&lt;br/&gt;
+&lt;br/&gt;
+    val table = builder.stream&lt;span class=&quot;error&quot;&gt;&amp;#91;String, String&amp;#93;&lt;/span&gt;(sourceTopic).groupBy((key, _) =&amp;gt; key).count()&lt;br/&gt;
+    table.filterNot((_, value) =&amp;gt; value &amp;gt; 1).toStream.to(sinkTopic)&lt;br/&gt;
+&lt;br/&gt;
+    val testDriver = createTestDriver(builder)&lt;br/&gt;
+&lt;br/&gt;
+    &lt;/p&gt;
{
+      testDriver.pipeRecord(sourceTopic, (&quot;1&quot;, &quot;value1&quot;))
+      val record = testDriver.readRecord[String, Long](sinkTopic)
+      record.key shouldBe &quot;1&quot;
+      record.value shouldBe 1
+    }
&lt;p&gt;+    &lt;/p&gt;
{
+      testDriver.pipeRecord(sourceTopic, (&quot;1&quot;, &quot;value2&quot;))
+      val record = testDriver.readRecord[String, Long](sinkTopic)
+      record.key shouldBe &quot;1&quot;
+      record.value shouldBe (null: java.lang.Long)
+    }
&lt;p&gt;+    &lt;/p&gt;
{
+      testDriver.pipeRecord(sourceTopic, (&quot;2&quot;, &quot;value1&quot;))
+      val record = testDriver.readRecord[String, Long](sinkTopic)
+      record.key shouldBe &quot;2&quot;
+      record.value shouldBe 1
+    }
&lt;p&gt;+    testDriver.readRecord&lt;span class=&quot;error&quot;&gt;&amp;#91;String, Long&amp;#93;&lt;/span&gt;(sinkTopic) shouldBe null&lt;br/&gt;
+&lt;br/&gt;
+    testDriver.close()&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
   &quot;join 2 KTables&quot; should &quot;join correctly records&quot; in {&lt;br/&gt;
     val builder = new StreamsBuilder()&lt;br/&gt;
     val sourceTopic1 = &quot;source1&quot;&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16590446" author="guozhang" created="Thu, 23 Aug 2018 16:17:14 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yuzhihong%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;yuzhihong@gmail.com&quot;&gt;yuzhihong@gmail.com&lt;/a&gt; the other PR has been merged, I will wait for resolving this ticket until the PR for &lt;tt&gt;peek&lt;/tt&gt; is merged too.&lt;/p&gt;</comment>
                            <comment id="16590450" author="yuzhihong@gmail.com" created="Thu, 23 Aug 2018 16:20:23 +0000"  >&lt;p&gt;When would PR #5539 be merged ?&lt;/p&gt;</comment>
                            <comment id="16590456" author="guozhang" created="Thu, 23 Aug 2018 16:22:25 +0000"  >&lt;p&gt;The PR needs to be rebased &amp;#8212; you can follow its status on the PR itself.&lt;/p&gt;</comment>
                            <comment id="16590581" author="mjsax" created="Thu, 23 Aug 2018 17:38:30 +0000"  >&lt;p&gt;Meta question: it seems we hit multiple issues with Scala API in 2.0.0 &#8211; to what extend do we need to update the docs for 2.0.1 and 2.1.0? It seems the current PRs don&apos;t include any docs updates.&lt;/p&gt;</comment>
                            <comment id="16616834" author="yuzhihong@gmail.com" created="Sun, 16 Sep 2018 18:13:34 +0000"  >&lt;p&gt;Can this be resolved ?&lt;/p&gt;</comment>
                            <comment id="16617175" author="joan@goyeau.com" created="Mon, 17 Sep 2018 07:42:52 +0000"  >&lt;p&gt;The PR #5539 is now merged.&lt;/p&gt;

&lt;p&gt;There is no documentation change needed here since it&apos;s an internal change to fix the issue.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13192832">KAFKA-7521</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12936373" name="7316.v4.txt" size="20128" author="yuzhihong@gmail.com" created="Tue, 21 Aug 2018 04:09:27 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 9 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3x8rr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>