<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:57:03 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-4024] First metadata update always take retry.backoff.ms milliseconds to complete</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-4024</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Recently I updated our KafkaProducer configuration, specifically we adjusted &lt;tt&gt;retry.backoff.ms&lt;/tt&gt; from default(100ms) to 1000ms.&lt;br/&gt;
After that we observed that the first &lt;tt&gt;send()&lt;/tt&gt; start taking longer than before, investigated then found following facts.&lt;/p&gt;

&lt;p&gt;Environment:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Kafka broker 0.9.0.1&lt;/li&gt;
	&lt;li&gt;Kafka producer 0.9.0.1&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Our current version is 0.9.0.1 but it reproduced with latest build from trunk branch as well.&lt;/p&gt;

&lt;h2&gt;&lt;a name=&quot;TL%3BDR&quot;&gt;&lt;/a&gt;TL;DR&lt;/h2&gt;
&lt;p&gt;The first &lt;tt&gt;KafkaProducer.send()&lt;/tt&gt; always blocked &lt;tt&gt;retry.backoff.ms&lt;/tt&gt; milliseconds, due to unintentionally applied backoff on first metadata update.&lt;/p&gt;


&lt;h2&gt;&lt;a name=&quot;Proof&quot;&gt;&lt;/a&gt;Proof&lt;/h2&gt;
&lt;p&gt;I wrote following test code and placed under the clients/main/java/&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.util.Properties;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.util.concurrent.TimeUnit;

&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.kafka.clients.producer.KafkaProducer;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.kafka.clients.producer.Producer;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.kafka.clients.producer.ProducerConfig;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.kafka.common.serialization.ByteArraySerializer;

&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;KafkaProducerMetadataUpdateDurationTest {
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; void main(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] args) {
        Properties props = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Properties();
        props.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &lt;span class=&quot;code-quote&quot;&gt;&quot;localhost:9092&quot;&lt;/span&gt;);
        props.setProperty(ProducerConfig.MAX_BLOCK_MS_CONFIG, &lt;span class=&quot;code-quote&quot;&gt;&quot;30000&quot;&lt;/span&gt;);
        &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; retryBackoffMs = &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.getProperty(&lt;span class=&quot;code-quote&quot;&gt;&quot;retry.backoff.ms&quot;&lt;/span&gt;);
        &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.err.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;Experimenting with retry.backoff.ms = &quot;&lt;/span&gt; + retryBackoffMs);
        props.setProperty(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, retryBackoffMs);

        Producer&amp;lt;&lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[], &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[]&amp;gt; producer =
                &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KafkaProducer&amp;lt;&amp;gt;(props, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ByteArraySerializer(), &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ByteArraySerializer());

        &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; t0 = &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.nanoTime();
        &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
            producer.partitionsFor(&lt;span class=&quot;code-quote&quot;&gt;&quot;test&quot;&lt;/span&gt;);
            &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; duration = &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.nanoTime() - t0;
            &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.err.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;Duration = &quot;&lt;/span&gt; + TimeUnit.NANOSECONDS.toMillis(duration) + &lt;span class=&quot;code-quote&quot;&gt;&quot; ms&quot;&lt;/span&gt;);
        } &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
            producer.close();
        }
    }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here&apos;s experiment log:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;# Start zookeeper &amp;amp; kafka broker
./bin/zookeeper-server-start.sh config/zookeeper.properties
./bin/kafka-server-start.sh config/server.properties

# Create test topic
./bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic test --replication-factor 1 --partitions 1

$ ./bin/kafka-run-&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;sh -Dretry.backoff.ms=100 KafkaProducerMetadataUpdateDurationTest
Experimenting with retry.backoff.ms = 100
Duration = 175 ms

$ ./bin/kafka-run-&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;sh -Dretry.backoff.ms=1000 KafkaProducerMetadataUpdateDurationTest
Experimenting with retry.backoff.ms = 1000
Duration = 1066 ms

$ ./bin/kafka-run-&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;sh -Dretry.backoff.ms=10000 KafkaProducerMetadataUpdateDurationTest
Experimenting with retry.backoff.ms = 10000
Duration = 10070 ms
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As you can see, duration of &lt;tt&gt;partitionsFor()&lt;/tt&gt; increases linearly in proportion to the value of &lt;tt&gt;retry.backoff.ms&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Here I describe the scenario that leads this behavior:&lt;br/&gt;
1. KafkaProducer initializes metadata with giving &lt;tt&gt;bootstrap.servers&lt;/tt&gt; and the current timestamp: &lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java#L276&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java#L276&lt;/a&gt;&lt;br/&gt;
2. On the first &lt;tt&gt;send()&lt;/tt&gt;, KafkaProducer requests metadata update due to missing partition info: &lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java#L527&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java#L527&lt;/a&gt;&lt;br/&gt;
3. But, DefaultMetadataUpdater doesn&apos;t actually send MetadataRequest, because &lt;tt&gt;metadata.timeToNextUpdate&lt;/tt&gt; returns a value lager than zero: &lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/NetworkClient.java#L541-L548&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/NetworkClient.java#L541-L548&lt;/a&gt;&lt;br/&gt;
4. &lt;tt&gt;Metadata.timeToNextUpdate&lt;/tt&gt; returns lager one of time till metadata expiration or time till backing off expiration but practially needUpdate is always true at the first time so here the timeToAllowUpdate is always adopted, which never be zero until &lt;tt&gt;retry.backoff.ms&lt;/tt&gt; elapsed since the first &lt;tt&gt;metadata.update()&lt;/tt&gt;: &lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/Metadata.java#L116&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/Metadata.java#L116&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;This is because of kafka client tries to keep interval configured by &lt;tt&gt;retry.backoff.ms&lt;/tt&gt; between each metadata update so it&apos;s basically works fine from the second update but for the first time, since it could never have the actual metadata(which is obtained by MetadaUpdate request), this backing off isn&apos;t making sense and in fact it&apos;s harming our application by blocking the first &lt;tt&gt;send()&lt;/tt&gt; insanely long.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12995429">KAFKA-4024</key>
            <summary>First metadata update always take retry.backoff.ms milliseconds to complete</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="kawamuray">Yuto Kawamura</assignee>
                                    <reporter username="kawamuray">Yuto Kawamura</reporter>
                        <labels>
                    </labels>
                <created>Sat, 6 Aug 2016 09:14:58 +0000</created>
                <updated>Fri, 4 Nov 2016 06:20:41 +0000</updated>
                            <resolved>Fri, 4 Nov 2016 06:20:17 +0000</resolved>
                                    <version>0.9.0.1</version>
                    <version>0.10.0.0</version>
                                    <fixVersion>0.10.2.0</fixVersion>
                                    <component>clients</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="15410560" author="kawamuray" created="Sat, 6 Aug 2016 09:17:56 +0000"  >&lt;p&gt;I guess this problem is fairly easy to fix, just by giving 0 as a timestamp for the first metadata update which is done by KafkaProducer constructor.&lt;br/&gt;
In fact, KafkaConsumer already does this, which makes much sense than giving the current timestamp at the initialization with &lt;tt&gt;bootstrap.servers&lt;/tt&gt;: &lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/consumer/KafkaConsumer.java#L621&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/consumer/KafkaConsumer.java#L621&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15410563" author="githubbot" created="Sat, 6 Aug 2016 09:27:39 +0000"  >&lt;p&gt;GitHub user kawamuray opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1707&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1707&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-4024&quot; title=&quot;First metadata update always take retry.backoff.ms milliseconds to complete&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-4024&quot;&gt;&lt;del&gt;KAFKA-4024&lt;/del&gt;&lt;/a&gt; KafkaProducer should not initialize metadata with current timestamp&lt;/p&gt;

&lt;p&gt;    Issue: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-4024&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/KAFKA-4024&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    Solves the problem that the first metadata update of KafkaProducer takes `retry.backoff.ms` to complete.&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/kawamuray/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/kawamuray/kafka&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-4024&quot; title=&quot;First metadata update always take retry.backoff.ms milliseconds to complete&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-4024&quot;&gt;&lt;del&gt;KAFKA-4024&lt;/del&gt;&lt;/a&gt;-metadata-backoff&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1707.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1707.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #1707&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit fc02b2381c9eb90a75fd0da338596679bd764a31&lt;br/&gt;
Author: Yuto Kawamura &amp;lt;kawamuray.dadada@gmail.com&amp;gt;&lt;br/&gt;
Date:   2016-08-06T09:25:29Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-4024&quot; title=&quot;First metadata update always take retry.backoff.ms milliseconds to complete&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-4024&quot;&gt;&lt;del&gt;KAFKA-4024&lt;/del&gt;&lt;/a&gt; KafkaProducer should not initialize metadata with current timestamp&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15410571" author="kawamuray" created="Sat, 6 Aug 2016 09:41:11 +0000"  >&lt;p&gt;Submitted a patch. It actually leads a side effect that introduces minor change on KafkaProducer&apos;s behavior. Currently KafkaProducer issues the first Metadata request at either one of at the first send() or at the first metadata expiration configured by metadata.max.age.ms, but after this change KafkaProducer will issue Metadata request immediately after its construction.&lt;br/&gt;
As &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3358&quot; title=&quot;Only request metadata updates once we have topics or a pattern subscription&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3358&quot;&gt;&lt;del&gt;KAFKA-3358&lt;/del&gt;&lt;/a&gt; fixed already, I don&apos;t see any problem to introduce this change but let me know if you have another thoughts.&lt;/p&gt;</comment>
                            <comment id="15410572" author="kawamuray" created="Sat, 6 Aug 2016 09:45:43 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt; or &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt; PTAL.&lt;/p&gt;</comment>
                            <comment id="15458639" author="kawamuray" created="Fri, 2 Sep 2016 14:12:00 +0000"  >&lt;p&gt;I reconsidered this issue and think I found that this is much worse than I explained before.&lt;/p&gt;

&lt;p&gt;IIUC, in short, setting &lt;tt&gt;retry.backoff.ms&lt;/tt&gt; to lager value can delays KafkaProducer to update outdated metadata.&lt;br/&gt;
That is, when we set &lt;tt&gt;retry.backoff.ms&lt;/tt&gt; to 1 second for example, and a partition leadership failover happens, the producer will take 1 seconds to fire metadata request in the worst case, even though it could detect broker disconnection or outdated partition leadership information.&lt;/p&gt;

&lt;p&gt;Here&apos;s the result of my experiment. I modified &lt;tt&gt;KafkaProducerMetadataUpdateDurationTest&lt;/tt&gt; and observed DEBUG logs of NetworkClient and Metadata.&lt;/p&gt;

&lt;p&gt;clients/src/main/java/KafkaProducerMetadataUpdateDurationTest.java:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.util.Properties;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.util.concurrent.TimeUnit;

&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.kafka.clients.producer.Callback;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.kafka.clients.producer.KafkaProducer;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.kafka.clients.producer.Producer;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.kafka.clients.producer.ProducerConfig;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.kafka.clients.producer.ProducerRecord;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.kafka.clients.producer.RecordMetadata;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.kafka.common.serialization.StringSerializer;

&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;KafkaProducerMetadataUpdateDurationTest {
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; void main(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] args) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; InterruptedException {
        Properties props = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Properties();
        props.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &lt;span class=&quot;code-quote&quot;&gt;&quot;HOST-1:9092,HOST-2:9092,HOST-3:9092&quot;&lt;/span&gt;);
        props.setProperty(ProducerConfig.RECONNECT_BACKOFF_MS_CONFIG, &lt;span class=&quot;code-quote&quot;&gt;&quot;1000&quot;&lt;/span&gt;);
        props.setProperty(ProducerConfig.RETRIES_CONFIG, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;.valueOf(&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;.MAX_VALUE));
        &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; retryBackoffMs = &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.getProperty(&lt;span class=&quot;code-quote&quot;&gt;&quot;retry.backoff.ms&quot;&lt;/span&gt;);
        &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.err.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;Experimenting with retry.backoff.ms = &quot;&lt;/span&gt; + retryBackoffMs);
        props.setProperty(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, retryBackoffMs);

        Producer&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; producer =
                &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; KafkaProducer&amp;lt;&amp;gt;(props, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StringSerializer(), &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StringSerializer());

        &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
            &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; i = 0;
            &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;) {
                &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; produceSeq = i++;
                &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; t0 = &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.nanoTime();
                producer.send(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ProducerRecord&amp;lt;&amp;gt;(&lt;span class=&quot;code-quote&quot;&gt;&quot;test&quot;&lt;/span&gt;, produceSeq % 3, &lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;value&quot;&lt;/span&gt;),
                              &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Callback() {
                                  @Override
                                  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void onCompletion(RecordMetadata metadata, Exception exception) {
                                      &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; produceDuration = TimeUnit.NANOSECONDS.toMillis(&lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.nanoTime() - t0);
                                      &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.err.printf(&lt;span class=&quot;code-quote&quot;&gt;&quot;Produce[%d]: duration=%d, exception=%s\n&quot;&lt;/span&gt;, produceSeq, produceDuration, exception);
                                  }
                              });
                &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; sendDuration = TimeUnit.NANOSECONDS.toMillis(&lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.nanoTime() - t0);
                &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.err.printf(&lt;span class=&quot;code-quote&quot;&gt;&quot;Send[%d]: duration=%d\n&quot;&lt;/span&gt;, produceSeq, sendDuration);
                &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.sleep(1000);
            }
        } &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
            producer.close();
        }
    }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;log4j.properties:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;log4j.rootLogger=INFO, stdout

log4j.logger.org.apache.kafka.clients.Metadata=DEBUG, stdout
log4j.additivity.org.apache.kafka.clients.Metadata=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
log4j.logger.org.apache.kafka.clients.NetworkClient=DEBUG, stdout
log4j.additivity.org.apache.kafka.clients.NetworkClient=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
log4j.logger.org.apache.kafka.clients.producer.internals.Sender=DEBUG, stdout
log4j.additivity.org.apache.kafka.clients.producer.internals.Sender=DEBUG, stdout

log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=[%d] %p %m (%c)%n
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Topic &quot;test&quot; has 3 replicas and 3 partitions.&lt;br/&gt;
Then I started KafkaProducerMetadataUpdateDurationTest, and stopped broker 1 manually at (*2). Here&apos;s the log:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;./bin/kafka-run-&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;sh -Dlog4j.configuration=file:./log4j.properties -Dretry.backoff.ms=10000 KafkaProducerMetadataUpdateDurationTest
Experimenting with retry.backoff.ms = 10000
...
[2016-09-02 22:36:29,839] INFO Kafka version : 0.10.1.0-SNAPSHOT (org.apache.kafka.common.utils.AppInfoParser)
[2016-09-02 22:36:29,839] INFO Kafka commitId : 8f3462552fa4d6a6 (org.apache.kafka.common.utils.AppInfoParser)
[2016-09-02 22:36:39,826] DEBUG Initialize connection to node -2 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; sending metadata request (org.apache.kafka.clients.NetworkClient)
[2016-09-02 22:36:39,826] DEBUG Initiating connection to node -2 at HOST-2:9092. (org.apache.kafka.clients.NetworkClient)
[2016-09-02 22:36:39,883] DEBUG Completed connection to node -2 (org.apache.kafka.clients.NetworkClient)

# *1 The first metadata request
[2016-09-02 22:36:39,902] DEBUG Sending metadata request {topics=[test]} to node -2 (org.apache.kafka.clients.NetworkClient)
[2016-09-02 22:36:39,929] DEBUG Updated cluster metadata version 2 to Cluster(nodes = [HOST-2:9092 (id: 2 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;), HOST-1:9092 (id: 1 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;), HOST-3:9092 (id: 3 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)], partitions = [Partition(topic = test, partition = 1, leader = 1, replicas = [1,2,3,], isr = [2,3,1,]), Partition(topic = test, partition = 0, leader = 3, replicas = [1,2,3,], isr = [3,2,1,]), Partition(topic = test, partition = 2, leader = 2, replicas = [1,2,3,], isr = [3,2,1,])]) (org.apache.kafka.clients.Metadata)
Send[0]: duration=10104
[2016-09-02 22:36:39,944] DEBUG Initiating connection to node 3 at HOST-3:9092. (org.apache.kafka.clients.NetworkClient)
[2016-09-02 22:36:39,947] DEBUG Completed connection to node 3 (org.apache.kafka.clients.NetworkClient)
Produce[0]: duration=10117, exception=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
Send[1]: duration=0
[2016-09-02 22:36:40,950] DEBUG Initiating connection to node 1 at HOST-1:9092. (org.apache.kafka.clients.NetworkClient)
[2016-09-02 22:36:40,952] DEBUG Completed connection to node 1 (org.apache.kafka.clients.NetworkClient)
Produce[1]: duration=12, exception=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
Send[2]: duration=0
[2016-09-02 22:36:41,955] DEBUG Initiating connection to node 2 at HOST-2:9092. (org.apache.kafka.clients.NetworkClient)
[2016-09-02 22:36:41,958] DEBUG Completed connection to node 2 (org.apache.kafka.clients.NetworkClient)
Produce[2]: duration=5, exception=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
Send[3]: duration=0
Produce[3]: duration=4, exception=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;

# *2 I stopped broker 1 at &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; moment

[2016-09-02 22:36:43,134] DEBUG Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
Send[4]: duration=0
[2016-09-02 22:36:44,137] DEBUG Initiating connection to node 1 at HOST-1:9092. (org.apache.kafka.clients.NetworkClient)
[2016-09-02 22:36:44,139] DEBUG Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
Send[5]: duration=0
Produce[5]: duration=4, exception=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
[2016-09-02 22:36:45,141] DEBUG Initiating connection to node 1 at HOST-1:9092. (org.apache.kafka.clients.NetworkClient)
[2016-09-02 22:36:45,143] DEBUG Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
Send[6]: duration=0
Produce[6]: duration=3, exception=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
[2016-09-02 22:36:46,148] DEBUG Initiating connection to node 1 at HOST-1:9092. (org.apache.kafka.clients.NetworkClient)
[2016-09-02 22:36:46,150] DEBUG Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
Send[7]: duration=0
[2016-09-02 22:36:47,154] DEBUG Initiating connection to node 1 at HOST-1:9092. (org.apache.kafka.clients.NetworkClient)
[2016-09-02 22:36:47,156] DEBUG Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
Send[8]: duration=0
Produce[8]: duration=5, exception=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
[2016-09-02 22:36:48,159] DEBUG Initiating connection to node 1 at HOST-1:9092. (org.apache.kafka.clients.NetworkClient)
[2016-09-02 22:36:48,161] DEBUG Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
Send[9]: duration=0
Produce[9]: duration=3, exception=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
[2016-09-02 22:36:49,165] DEBUG Initiating connection to node 1 at HOST-1:9092. (org.apache.kafka.clients.NetworkClient)
[2016-09-02 22:36:49,168] DEBUG Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)

# *3 The second metadata update exactly after 10 seconds since the first update.
[2016-09-02 22:36:49,914] DEBUG Sending metadata request {topics=[test]} to node 3 (org.apache.kafka.clients.NetworkClient)
[2016-09-02 22:36:49,918] DEBUG Updated cluster metadata version 3 to Cluster(nodes = [HOST-2:9092 (id: 2 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;), HOST-3:9092 (id: 3 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)], partitions = [Partition(topic = test, partition = 1, leader = 2, replicas = [1,2,3,], isr = [2,3,]), Partition(topic = test, partition = 0, leader = 3, replicas = [1,2,3,], isr = [3,2,]), Partition(topic = test, partition = 2, leader = 2, replicas = [1,2,3,], isr = [3,2,])]) (org.apache.kafka.clients.Metadata)
Produce[4]: duration=5957, exception=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
Produce[7]: duration=2946, exception=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
Send[10]: duration=0
Produce[10]: duration=4, exception=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;First, as I explained already, the first send() blocked insanely long due to not intentionally applied refreshBackoffMs (*1).&lt;br/&gt;
Then I stopped broker 1 at (*2). I think what we expect here is that KafkaProducer immediately tries to update metadata in order to failover producing target to the new leader, but it doesn&apos;t until 10 seconds(=retry.backoff.ms) elapsed since the first update at (*3).&lt;/p&gt;

&lt;p&gt;This leads following bad effects:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Producing latency&lt;/li&gt;
	&lt;li&gt;Buffer full due to accumulated records&lt;/li&gt;
	&lt;li&gt;Batch expiration by elapsing &lt;tt&gt;request.timeout.ms&lt;/tt&gt; : &lt;a href=&quot;https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/RecordBatch.java#L153-L156&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/RecordBatch.java#L153-L156&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15458699" author="kawamuray" created="Fri, 2 Sep 2016 14:36:15 +0000"  >&lt;p&gt;Updated PR to fix this issue not only about the first metadata update but also for cases I just explained in the above comment.&lt;br/&gt;
After applying my patch, the first send() is no longer blocked by the first metadata update (*4), and the second metadata update happens immediately after the KafkaProducer detects broker disconnection (*5, *6).&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Experimenting with retry.backoff.ms = 10000
...
[2016-09-02 22:48:22,936] INFO Kafka version : 0.10.1.0-SNAPSHOT (org.apache.kafka.common.utils.AppInfoParser)
[2016-09-02 22:48:22,936] INFO Kafka commitId : 8f3462552fa4d6a6 (org.apache.kafka.common.utils.AppInfoParser)
[2016-09-02 22:48:22,939] DEBUG Initialize connection to node -2 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; sending metadata request (org.apache.kafka.clients.NetworkClient)
[2016-09-02 22:48:22,939] DEBUG Initiating connection to node -2 at HOST-2:9092. (org.apache.kafka.clients.NetworkClient)
[2016-09-02 22:48:23,001] DEBUG Completed connection to node -2 (org.apache.kafka.clients.NetworkClient)

# *4 The first metadata update happenes immediately.
[2016-09-02 22:48:23,020] DEBUG Sending metadata request {topics=[test]} to node -2 (org.apache.kafka.clients.NetworkClient)
[2016-09-02 22:48:23,043] DEBUG Updated cluster metadata version 2 to Cluster(nodes = [HOST-1:9092 (id: 1 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;), HOST-2:9092 (id: 2 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;), HOST-3:9092 (id: 3 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)], partitions = [Partition(topic = test, partition = 1, leader = 1, replicas = [1,2,3,], isr = [2,3,1,]), Partition(topic = test, partition = 0, leader = 3, replicas = [1,2,3,], isr = [3,2,1,]), Partition(topic = test, partition = 2, leader = 2, replicas = [1,2,3,], isr = [3,2,1,])]) (org.apache.kafka.clients.Metadata)
Send[0]: duration=119
[2016-09-02 22:48:23,057] DEBUG Initiating connection to node 3 at HOST-3:9092. (org.apache.kafka.clients.NetworkClient)
[2016-09-02 22:48:23,060] DEBUG Completed connection to node 3 (org.apache.kafka.clients.NetworkClient)
Produce[0]: duration=129, exception=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
Send[1]: duration=0
[2016-09-02 22:48:24,060] DEBUG Initiating connection to node 1 at HOST-1:9092. (org.apache.kafka.clients.NetworkClient)
[2016-09-02 22:48:24,062] DEBUG Completed connection to node 1 (org.apache.kafka.clients.NetworkClient)
Produce[1]: duration=10, exception=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
Send[2]: duration=0
[2016-09-02 22:48:25,066] DEBUG Initiating connection to node 2 at HOST-2:9092. (org.apache.kafka.clients.NetworkClient)
[2016-09-02 22:48:25,068] DEBUG Completed connection to node 2 (org.apache.kafka.clients.NetworkClient)
Produce[2]: duration=6, exception=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
Send[3]: duration=0
Produce[3]: duration=4, exception=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;

# *5 I stopped broker 1 at &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; moment
[2016-09-02 22:48:26,301] DEBUG Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)

# *6 Metadata updated immediately after the producer detects broker disconnection
[2016-09-02 22:48:26,301] DEBUG Sending metadata request {topics=[test]} to node 2 (org.apache.kafka.clients.NetworkClient)
[2016-09-02 22:48:26,308] DEBUG Updated cluster metadata version 3 to Cluster(nodes = [HOST-3:9092 (id: 3 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;), HOST-1:9092 (id: 1 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;), HOST-2:9092 (id: 2 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)], partitions = [Partition(topic = test, partition = 1, leader = 2, replicas = [1,2,3,], isr = [2,3,]), Partition(topic = test, partition = 0, leader = 3, replicas = [1,2,3,], isr = [3,2,]), Partition(topic = test, partition = 2, leader = 2, replicas = [1,2,3,], isr = [3,2,])]) (org.apache.kafka.clients.Metadata)
Send[4]: duration=0
Produce[4]: duration=4, exception=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15635409" author="hachikuji" created="Fri, 4 Nov 2016 06:20:20 +0000"  >&lt;p&gt;Issue resolved by pull request 1707&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/pull/1707&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1707&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15635411" author="githubbot" created="Fri, 4 Nov 2016 06:20:41 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1707&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1707&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 2 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i31zzz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>