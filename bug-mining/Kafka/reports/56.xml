<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:35:10 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-371] Creating topic of empty string puts broker in a bad state</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-371</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Using the Java client library, I accidentally published a message where the topic name was the empty string. This put the broker in a bad state where publishing became impossible, and the following exception was logged 10-20 times per second:&lt;/p&gt;

&lt;p&gt;2012-06-21 00:41:30,324 &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-processor-3&amp;#93;&lt;/span&gt; ERROR kafka.network.Processor  - Closing socket for /127.0.0.1 because of er&lt;br/&gt;
ror&lt;br/&gt;
kafka.common.InvalidTopicException: topic name can&apos;t be empty&lt;br/&gt;
        at kafka.log.LogManager.getOrCreateLog(LogManager.scala:165)&lt;br/&gt;
        at kafka.server.KafkaRequestHandlers.kafka$server$KafkaRequestHandlers$$handleProducerRequest(KafkaRequestHandle&lt;br/&gt;
rs.scala:75)&lt;br/&gt;
        at kafka.server.KafkaRequestHandlers.handleProducerRequest(KafkaRequestHandlers.scala:58)&lt;br/&gt;
        at kafka.server.KafkaRequestHandlers$$anonfun$handlerFor$1.apply(KafkaRequestHandlers.scala:43)&lt;br/&gt;
        at kafka.server.KafkaRequestHandlers$$anonfun$handlerFor$1.apply(KafkaRequestHandlers.scala:43)&lt;br/&gt;
        at kafka.network.Processor.handle(SocketServer.scala:289)&lt;br/&gt;
        at kafka.network.Processor.read(SocketServer.scala:312)&lt;br/&gt;
        at kafka.network.Processor.run(SocketServer.scala:207)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:679)&lt;/p&gt;

&lt;p&gt;Restarting Kafka did not help. I had to manually clear out the bad state in Zookeeper to resolve the problem.&lt;/p&gt;

&lt;p&gt;The broker should not accept a message that would put it in such a bad state.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12595368">KAFKA-371</key>
            <summary>Creating topic of empty string puts broker in a bad state</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jkreps">Jay Kreps</assignee>
                                    <reporter username="martinkl">Martin Kleppmann</reporter>
                        <labels>
                    </labels>
                <created>Thu, 21 Jun 2012 01:09:43 +0000</created>
                <updated>Tue, 14 Aug 2012 17:23:27 +0000</updated>
                            <resolved>Tue, 14 Aug 2012 17:23:27 +0000</resolved>
                                    <version>0.6</version>
                    <version>0.7</version>
                                    <fixVersion>0.8.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="13416792" author="jcreasy" created="Wed, 18 Jul 2012 01:25:51 +0000"  >&lt;p&gt;Modifed createLog() to fail if it has been asked to create a log that would fail on the getLogPool() function.&lt;/p&gt;

&lt;p&gt;I am not sure if the partition check is correct here, it appears that the partition could be any &amp;gt;0 partition and be OK since the file would get created. If there is no where else that partition would need to exist that would be OK, I think that this may not be the case though as it would need to be in Zk if my current understanding is correct. &lt;/p&gt;</comment>
                            <comment id="13416793" author="jcreasy" created="Wed, 18 Jul 2012 01:27:20 +0000"  >&lt;p&gt;Probably should set fix version to 0.7.1&lt;/p&gt;</comment>
                            <comment id="13417268" author="jkreps" created="Wed, 18 Jul 2012 17:17:31 +0000"  >&lt;p&gt;Committed the 0.8 patch. Thanks.&lt;/p&gt;

&lt;p&gt;At the moment I don&apos;t know if we are doing a 0.7.2 so I am going to hold off on the 0.7.1 patch.&lt;/p&gt;</comment>
                            <comment id="13417288" author="nehanarkhede" created="Wed, 18 Jul 2012 17:34:23 +0000"  >&lt;p&gt;I think in the 0.8 patch, the changes to createLog are unnecessary. This is because the same check happens inside getLogPool, which is always called before createLog in getOrCreateLog, no ?&lt;/p&gt;</comment>
                            <comment id="13417383" author="jcreasy" created="Wed, 18 Jul 2012 19:10:12 +0000"  >&lt;p&gt;Well, I didn&apos;t see any way for the bug to have occurred unless createLog was being called outside of where getLogPool gets called. So, it does appear to be unnecessary, perhaps these checks were added and the ticket was never updated? &lt;/p&gt;
</comment>
                            <comment id="13417647" author="jkreps" created="Wed, 18 Jul 2012 20:26:39 +0000"  >&lt;p&gt;Hmm, good point. This is a little odd, though, no? Why would getting a log pool check the validity of a partition? Not sure how that came about. I recommend we delete that and keep the check in create--if you can&apos;t create a bad log you don&apos;t need to check on every access. Objections?&lt;/p&gt;

&lt;p&gt;Actually I have a bunch of clean-ups I would like to do in LogManager. Let me post a patch with all these while I am in there.&lt;/p&gt;</comment>
                            <comment id="13417656" author="nehanarkhede" created="Wed, 18 Jul 2012 20:32:35 +0000"  >&lt;p&gt;Yes, that will work too. I guess the API was added so that every access to the log was guarded with the check. But if we ensure that you can&apos;t create one in the first place, we can get rid of the check in getLogPool and keep the one in createLog. &lt;/p&gt;</comment>
                            <comment id="13417660" author="jkreps" created="Wed, 18 Jul 2012 20:40:42 +0000"  >&lt;p&gt;Reopening for cleanups of LogManager&lt;/p&gt;</comment>
                            <comment id="13417704" author="jkreps" created="Wed, 18 Jul 2012 21:30:25 +0000"  >&lt;p&gt;Neha can you sanity check this? Here are the changes:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Remove some unneeded getter getServerConfig&lt;/li&gt;
	&lt;li&gt;Rename getTopicIterator to topics()&lt;/li&gt;
	&lt;li&gt;Simplify getLogIterator() and rename to allLogs()&lt;/li&gt;
	&lt;li&gt;Remove awaitStartup latch and awaitStartup latch acquisition. The comment on startup() says it registers in zookeeper, but this doesn&apos;t seem to be true&lt;/li&gt;
	&lt;li&gt;Remove getLogPool. createLog checks correctness of creation, and fails if it fails. getLog returns null if the log doesn&apos;t exist, as per the contract. getOrCreateLog will fail when createLog fails. I think this is more sensible, and elimantes the getter&lt;/li&gt;
	&lt;li&gt;Remove the word &quot;Map&quot; from things of type Map&lt;/li&gt;
	&lt;li&gt;MS should be Ms by our usual conventions&lt;/li&gt;
	&lt;li&gt;Remove helper getLogRetentionMSMap&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I think the latch was there because log manager was somehow doing zk registration (according to comments). But I don&apos;t see that code there at all now, and logManager shouldn&apos;t be talking to zk, so i think it got cleaned up. So now theoretically we shouldn&apos;t need that and the weird ordering where we take requests before log manager is initiatialized but then block should not be needed. &lt;/p&gt;

&lt;p&gt;Also, I removed the EasyMock verification on logmanager (I think all it does is check that the config was fetched), which I don&apos;t think is useful? But EasyMock is kind of a blackbox to me.&lt;/p&gt;</comment>
                            <comment id="13418586" author="nehanarkhede" created="Thu, 19 Jul 2012 19:11:16 +0000"  >&lt;p&gt;+1. &lt;/p&gt;

&lt;p&gt;Minor comment -&lt;/p&gt;

&lt;p&gt;Change logCleanupThresholdMS to logCleanupThresholdMs while you&apos;re in there&lt;/p&gt;</comment>
                            <comment id="13418632" author="jcreasy" created="Thu, 19 Jul 2012 20:15:40 +0000"  >&lt;p&gt;Does it make sense to have a function to &quot;validate a log&quot; and call that any time you want to validate that the log you are reading/writing is valid? Potentially some of the validation would be redundant and called at times it didn&apos;t need to be, reducing capacity. &lt;/p&gt;

&lt;p&gt;So the balance is between consistent checking and efficient execution.&lt;/p&gt;</comment>
                            <comment id="13418736" author="jkreps" created="Thu, 19 Jul 2012 22:34:09 +0000"  >&lt;p&gt;Got it, committed.&lt;/p&gt;</comment>
                            <comment id="13418745" author="jkreps" created="Thu, 19 Jul 2012 22:44:41 +0000"  >&lt;p&gt;Hey Jonathan, I don&apos;t think so, but I may have misunderstood. Basically a log has two states&lt;br/&gt;
 OPEN&lt;br/&gt;
 CLOSED&lt;/p&gt;

&lt;p&gt;Every time we create a log object we run recovery on it which validates any messages since the last know flush point and truncates any partial writes to put the log in a known state. This is done as part of log construction so there is no way to have a reference to a log until it is known to be valid and ready for writes.&lt;/p&gt;

&lt;p&gt;Our policy is that we actually kill the instance of the broker if we see an IOException while writing to disk (STONITH, if you will), so there is effectively no invalid state. The reason for this is that an IO error is effectively the same as a broker failure in that it indicates a potentially partial or corrupt write. You cannot append to the log in this state, so continuing to accept traffic only makes thing worse, the best policy is to die and let the other brokers cover things.&lt;/p&gt;

&lt;p&gt;Attempt to read or write to a closed log would be a programming error in the broker, and should just give an exception about the file being closed, so I don&apos;t know if we need additional checks there.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12536938" name="KAFKA-371-0.7.1.patch" size="1053" author="jcreasy" created="Wed, 18 Jul 2012 01:27:20 +0000"/>
                            <attachment id="12537072" name="KAFKA-371-0.8-v2.patch" size="11269" author="jkreps" created="Wed, 18 Jul 2012 21:30:25 +0000"/>
                            <attachment id="12536937" name="KAFKA-371-0.8.patch" size="1053" author="jcreasy" created="Wed, 18 Jul 2012 01:20:06 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>248166</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            13 years, 18 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i09lxz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>53988</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>