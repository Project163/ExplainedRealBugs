<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:36:15 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-576] SimpleConsumer throws UnsupportedOperationException: empty.head </title>
                <link>https://issues.apache.org/jira/browse/KAFKA-576</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;ul&gt;
	&lt;li&gt;In this case, there are 15 log segment files in broker-1 data dir:&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;ls -l /tmp/kafka_server_1_logs/test_1-0/&lt;br/&gt;
total 240&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;- 1 jfung eng    16 Oct 16 10:41 00000000000000000000.index&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;- 1 jfung eng 10440 Oct 16 10:40 00000000000000000000.log&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;- 1 jfung eng     8 Oct 16 10:41 00000000000000000020.index&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;- 1 jfung eng 10440 Oct 16 10:40 00000000000000000020.log&lt;br/&gt;
. . .&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;- 1 jfung eng     8 Oct 16 10:41 00000000000000000280.index&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;- 1 jfung eng 10440 Oct 16 10:41 00000000000000000280.log&lt;/p&gt;


&lt;ul&gt;
	&lt;li&gt;The following are the dump log segment of the first log segment file&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;bin/kafka-run-class.sh kafka.tools.DumpLogSegments /tmp/kafka_server_1_logs/test_1-0/00000000000000000000.log &lt;br/&gt;
Dumping /tmp/kafka_server_1_logs/test_1-0/00000000000000000000.log&lt;br/&gt;
Starting offset: 0&lt;br/&gt;
offset: 0 isvalid: true payloadsize: 500 magic: 2 compresscodec: NoCompressionCodec crc: 1663889063&lt;br/&gt;
offset: 1 isvalid: true payloadsize: 500 magic: 2 compresscodec: NoCompressionCodec crc: 2803454828&lt;br/&gt;
offset: 2 isvalid: true payloadsize: 500 magic: 2 compresscodec: NoCompressionCodec crc: 683347625&lt;br/&gt;
. . .&lt;br/&gt;
offset: 18 isvalid: true payloadsize: 500 magic: 2 compresscodec: NoCompressionCodec crc: 1892511043&lt;br/&gt;
offset: 19 isvalid: true payloadsize: 500 magic: 2 compresscodec: NoCompressionCodec crc: 601297044&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Output of SimpleConsumerShell:&lt;br/&gt;
. . .&lt;br/&gt;
next offset = 16&lt;br/&gt;
Topic:test_1:ThreadID:2:MessageID:0000000043:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx &lt;br/&gt;
next offset = 17&lt;br/&gt;
Topic:test_1:ThreadID:3:MessageID:0000000063:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx &lt;br/&gt;
next offset = 18&lt;br/&gt;
Topic:test_1:ThreadID:4:MessageID:0000000083:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx &lt;br/&gt;
next offset = 19&lt;br/&gt;
Topic:test_1:ThreadID:0:MessageID:0000000003:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx &lt;br/&gt;
next offset = 19&lt;br/&gt;
Topic:test_1:ThreadID:0:MessageID:0000000003:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx &lt;br/&gt;
next offset = 19&lt;br/&gt;
Topic:test_1:ThreadID:0:MessageID:0000000003:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx &lt;br/&gt;
next offset = 19&lt;br/&gt;
Topic:test_1:ThreadID:0:MessageID:0000000003:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx &lt;br/&gt;
. . .&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;It appears that SimpleConsumerShell doesn&apos;t advance to the next log segment file&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;It should probably block inside the while loop to prevent infinite looping&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment></environment>
        <key id="12612074">KAFKA-576</key>
            <summary>SimpleConsumer throws UnsupportedOperationException: empty.head </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="yeyangever">Yang Ye</assignee>
                                    <reporter username="jfung">John Fung</reporter>
                        <labels>
                    </labels>
                <created>Tue, 16 Oct 2012 17:54:00 +0000</created>
                <updated>Wed, 24 Oct 2012 14:21:39 +0000</updated>
                            <resolved>Wed, 24 Oct 2012 14:21:35 +0000</resolved>
                                                    <fixVersion>0.8.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="13480291" author="jfung" created="Fri, 19 Oct 2012 19:25:54 +0000"  >&lt;p&gt;This is a minor fix which is needed in kafka-571-v1.patch. Therefore, it is included in that patch.&lt;/p&gt;</comment>
                            <comment id="13481558" author="jfung" created="Mon, 22 Oct 2012 18:01:00 +0000"  >&lt;p&gt;1. SimpleConsumerShell will receive data from 1 of the broker in a 3-broker cluster with this change:&lt;/p&gt;

&lt;p&gt;$ svn diff core/src/main/scala/kafka/tools/SimpleConsumerShell.scala&lt;br/&gt;
Index: core/src/main/scala/kafka/tools/SimpleConsumerShell.scala&lt;br/&gt;
===================================================================&lt;br/&gt;
&amp;#8212; core/src/main/scala/kafka/tools/SimpleConsumerShell.scala	(revision 1400944)&lt;br/&gt;
+++ core/src/main/scala/kafka/tools/SimpleConsumerShell.scala	(working copy)&lt;br/&gt;
@@ -186,7 +186,7 @@&lt;br/&gt;
             var consumed = 0&lt;br/&gt;
             for(messageAndOffset &amp;lt;- messageSet) {&lt;br/&gt;
               try &lt;/p&gt;
{
-                offset = messageAndOffset.offset
+                offset = messageAndOffset.nextOffset
                 if(printOffsets)
                   System.out.println(&quot;next offset = &quot; + offset)
                 formatter.writeTo(messageAndOffset.message, System.out)


2. By printing out the producedOffset in SimpleConsumer and showing -1:

$ svn diff core/src/main/scala/kafka/consumer/SimpleConsumer.scala
Index: core/src/main/scala/kafka/consumer/SimpleConsumer.scala
===================================================================
--- core/src/main/scala/kafka/consumer/SimpleConsumer.scala	(revision 1400944)
+++ core/src/main/scala/kafka/consumer/SimpleConsumer.scala	(working copy)
@@ -50,6 +50,7 @@
       if (simpleConsumer != null)
         simpleConsumer.close()
     }
&lt;p&gt;+    System.out.println(&quot;====&amp;gt; producedOffset : &quot; + producedOffset)&lt;br/&gt;
     producedOffset&lt;br/&gt;
   }&lt;/p&gt;


&lt;p&gt;3. Exception is thrown from SimpleConsumer.earliestOrLatestOffset( ):&lt;/p&gt;

&lt;p&gt;$ bin/kafka-run-class.sh kafka.tools.SimpleConsumerShell --broker-list localhost:9093 --topic test_1 --partition 0 --replica 3&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;2012-10-22 10:41:56,525&amp;#93;&lt;/span&gt; INFO Getting topic metatdata... (kafka.tools.SimpleConsumerShell$)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2012-10-22 10:41:56,583&amp;#93;&lt;/span&gt; INFO Fetching metadata for topic Set(test_1) (kafka.client.ClientUtils$)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2012-10-22 10:41:56,589&amp;#93;&lt;/span&gt; INFO Connected to localhost:9093 for producing (kafka.producer.SyncProducer)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2012-10-22 10:41:56,751&amp;#93;&lt;/span&gt; INFO Disconnecting from localhost:9093 (kafka.producer.SyncProducer)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2012-10-22 10:41:56,784&amp;#93;&lt;/span&gt; ERROR error in earliestOrLatestOffset()  (kafka.consumer.SimpleConsumer$)&lt;br/&gt;
java.lang.UnsupportedOperationException: empty.head&lt;br/&gt;
	at scala.collection.immutable.Vector.head(Vector.scala:162)&lt;br/&gt;
	at kafka.consumer.SimpleConsumer$.earliestOrLatestOffset(SimpleConsumer.scala:45)&lt;br/&gt;
	at kafka.tools.SimpleConsumerShell$.main(SimpleConsumerShell.scala:169)&lt;br/&gt;
	at kafka.tools.SimpleConsumerShell.main(SimpleConsumerShell.scala)&lt;br/&gt;
====&amp;gt; producedOffset : -1&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2012-10-22 10:41:56,786&amp;#93;&lt;/span&gt; INFO Starting simple consumer shell to partition &lt;span class=&quot;error&quot;&gt;&amp;#91;test_1, 0&amp;#93;&lt;/span&gt;, replica &lt;span class=&quot;error&quot;&gt;&amp;#91;3&amp;#93;&lt;/span&gt;, host and port: &lt;span class=&quot;error&quot;&gt;&amp;#91;127.0.0.1, 9093&amp;#93;&lt;/span&gt;, from offset &lt;span class=&quot;error&quot;&gt;&amp;#91;-1&amp;#93;&lt;/span&gt; (kafka.tools.SimpleConsumerShell$)&lt;/p&gt;</comment>
                            <comment id="13481635" author="jfung" created="Mon, 22 Oct 2012 18:57:03 +0000"  >&lt;p&gt;Attached a server log4j messages file&lt;/p&gt;</comment>
                            <comment id="13482868" author="yeyangever" created="Wed, 24 Oct 2012 00:38:42 +0000"  >
&lt;p&gt;1. add --no-wait-logend command line option&lt;/p&gt;

&lt;p&gt;2. bug found, before in SimpleConsumer line 40:&lt;br/&gt;
      val request = if(isFromOrdinaryConsumer)&lt;br/&gt;
        OffsetRequest(immutable.Map(topicAndPartition -&amp;gt; PartitionOffsetRequestInfo(earliestOrLatest, 1)))&lt;br/&gt;
      else&lt;br/&gt;
        OffsetRequest(immutable.Map(topicAndPartition -&amp;gt; PartitionOffsetRequestInfo(earliestOrLatest, 1)), Request.DebuggingConsumerId)&lt;/p&gt;

&lt;p&gt;In the else branch, we are intending to use another constructor, but it turned out if we used this way, it&apos;s the same constructor. By using &quot;new OffsetRequest(...&quot;, we uses the constructor we want, as bellow:&lt;/p&gt;

&lt;p&gt;      val request = if(isFromOrdinaryConsumer)&lt;br/&gt;
        OffsetRequest(immutable.Map(topicAndPartition -&amp;gt; PartitionOffsetRequestInfo(earliestOrLatest, 1)))&lt;br/&gt;
      else&lt;br/&gt;
        new OffsetRequest(immutable.Map(topicAndPartition -&amp;gt; PartitionOffsetRequestInfo(earliestOrLatest, 1)), Request.DebuggingConsumerId)&lt;/p&gt;
</comment>
                            <comment id="13483264" author="junrao" created="Wed, 24 Oct 2012 14:21:35 +0000"  >&lt;p&gt;Thanks for the patch. Committed to 0.8 with the following minor changes:&lt;/p&gt;

&lt;p&gt;1. Use nextOffset instead of offset +1 to advance the offset.&lt;br/&gt;
2. Removed unused imports and variables.&lt;br/&gt;
3. Break long lines into multiple lines.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310060">
                    <name>Container</name>
                                                                <inwardlinks description="Is contained by">
                                        <issuelink>
            <issuekey id="12611642">KAFKA-571</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12550565" name="kafka_576_v1.diff" size="3147" author="yeyangever" created="Wed, 24 Oct 2012 00:38:42 +0000"/>
                            <attachment id="12550331" name="kafka_server_9093.log.gz" size="2998" author="jfung" created="Mon, 22 Oct 2012 18:57:03 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>249077</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            13 years, 4 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0a4lz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>57020</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>