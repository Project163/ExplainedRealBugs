<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:37:20 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-757] System Test Hard Failure cases : &quot;Fatal error during KafkaServerStable startup&quot; when hard-failed broker is re-started</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-757</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description></description>
                <environment></environment>
        <key id="12632021">KAFKA-757</key>
            <summary>System Test Hard Failure cases : &quot;Fatal error during KafkaServerStable startup&quot; when hard-failed broker is re-started</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="swapnilghike">Swapnil Ghike</assignee>
                                    <reporter username="jfung">John Fung</reporter>
                        <labels>
                            <label>0.8</label>
                            <label>replication-testing</label>
                    </labels>
                <created>Tue, 12 Feb 2013 18:16:06 +0000</created>
                <updated>Fri, 8 Nov 2013 13:21:14 +0000</updated>
                            <resolved>Wed, 13 Feb 2013 22:02:39 +0000</resolved>
                                                    <fixVersion>0.8.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="13576856" author="jfung" created="Tue, 12 Feb 2013 18:20:24 +0000"  >&lt;p&gt;This is happening in all Hard-failure testcases in System Test: testcase_015&lt;span class=&quot;error&quot;&gt;&amp;#91;1-9&amp;#93;&lt;/span&gt; &lt;/p&gt;

&lt;p&gt;The following error is thrown when a hard-failed broker (kill -9) is re-started:&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;2013-02-12 10:07:15,015&amp;#93;&lt;/span&gt; INFO Started Kafka CSV metrics reporter with polling period 5 seconds (kafka.metrics.KafkaCSVMetricsReporter)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2013-02-12 10:07:15,020&amp;#93;&lt;/span&gt; INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Kafka Server 3&amp;#93;&lt;/span&gt;, starting (kafka.server.KafkaServer)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2013-02-12 10:07:15,046&amp;#93;&lt;/span&gt; INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Log Manager on Broker 3&amp;#93;&lt;/span&gt; Loading log &apos;test_1-2&apos; (kafka.log.LogManager)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2013-02-12 10:07:15,062&amp;#93;&lt;/span&gt; INFO Creating or reloading log segment /tmp/kafka_server_3_logs/test_1-2/00000000000000000000.log (kafka.log.FileMessageSet)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2013-02-12 10:07:15,066&amp;#93;&lt;/span&gt; INFO Loaded index file /tmp/kafka_server_3_logs/test_1-2/00000000000000000000.index with maxEntries = 1310720, maxIndexSize = 10485760, entries = 1310720, lastOffset = 0, file position = 10485760 (kafka.log.OffsetIndex)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2013-02-12 10:07:15,068&amp;#93;&lt;/span&gt; FATAL Fatal error during KafkaServerStable startup. Prepare to shutdown (kafka.server.KafkaServerStartable)&lt;br/&gt;
java.lang.IllegalArgumentException: requirement failed: Corrupt index found, index file (/tmp/kafka_server_3_logs/test_1-2/00000000000000000000.index) has non-zero size but last offset is 0.&lt;br/&gt;
        at scala.Predef$.require(Predef.scala:145)&lt;br/&gt;
        at kafka.log.OffsetIndex.&amp;lt;init&amp;gt;(OffsetIndex.scala:95)&lt;br/&gt;
        at kafka.log.LogSegment.&amp;lt;init&amp;gt;(LogSegment.scala:36)&lt;br/&gt;
        at kafka.log.Log$$anonfun$loadSegments$2.apply(Log.scala:163)&lt;br/&gt;
        at kafka.log.Log$$anonfun$loadSegments$2.apply(Log.scala:147)&lt;br/&gt;
        at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:827)&lt;br/&gt;
        at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:34)&lt;br/&gt;
        at scala.collection.mutable.ArrayOps.foreach(ArrayOps.scala:34)&lt;br/&gt;
        at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:826)&lt;br/&gt;
        at kafka.log.Log.loadSegments(Log.scala:147)&lt;br/&gt;
        at kafka.log.Log.&amp;lt;init&amp;gt;(Log.scala:125)&lt;br/&gt;
        at kafka.log.LogManager$$anonfun$loadLogs$1$$anonfun$apply$3.apply(LogManager.scala:115)&lt;br/&gt;
        at kafka.log.LogManager$$anonfun$loadLogs$1$$anonfun$apply$3.apply(LogManager.scala:109)&lt;br/&gt;
        at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:34)&lt;br/&gt;
        at scala.collection.mutable.ArrayOps.foreach(ArrayOps.scala:34)&lt;br/&gt;
        at kafka.log.LogManager$$anonfun$loadLogs$1.apply(LogManager.scala:109)&lt;br/&gt;
        at kafka.log.LogManager$$anonfun$loadLogs$1.apply(LogManager.scala:101)&lt;br/&gt;
        at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:34)&lt;br/&gt;
        at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:32)&lt;br/&gt;
        at kafka.log.LogManager.loadLogs(LogManager.scala:101)&lt;br/&gt;
        at kafka.log.LogManager.&amp;lt;init&amp;gt;(LogManager.scala:62)&lt;br/&gt;
        at kafka.server.KafkaServer.startup(KafkaServer.scala:59)&lt;br/&gt;
        at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:34)&lt;br/&gt;
        at kafka.Kafka$.main(Kafka.scala:46)&lt;br/&gt;
        at kafka.Kafka.main(Kafka.scala)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2013-02-12 10:07:15,069&amp;#93;&lt;/span&gt; INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;Kafka Server 3&amp;#93;&lt;/span&gt;, shutting down (kafka.server.KafkaServer)&lt;/p&gt;</comment>
                            <comment id="13577447" author="swapnilghike" created="Wed, 13 Feb 2013 09:50:17 +0000"  >&lt;p&gt;There are two parts to this patch :&lt;/p&gt;

&lt;p&gt;A. Move the sanity check to detect corrupt index files from OffsetIndex constructor to Log constructor below the recovery logic. In case of a hard kill, checking for corrupt index files before the last segment has been recovered will fail the require() assertion.&lt;/p&gt;

&lt;p&gt;B. The following corner case is possible:&lt;br/&gt;
1. A broker rolled a new log segment file and an index file of non-zero size, and got hard killed before any appends to the index file were flushed. &lt;br/&gt;
2. When the broker reboots and tries to load existing log segments, it will encounter this index file that has non-zero size, but has no data. &lt;br/&gt;
3. Since the broker was hard killed, it will enter the recovery logic in Log.loadLogSegments(). &lt;br/&gt;
4. The recovery logic will try to truncate the index file to the base offset of the segment. It will try to find the indexSlotFor(baseOffset). indexForSlot() will return a non- zero value, because the relativeOffset(idx, mid) == relOffset == 0. &lt;br/&gt;
5. This will set the size of index file to a non-zero value (which will be half of its original size which was maxIndexSize * 8). &lt;br/&gt;
6. Thus, the require() check for corrupted index file in Log constructor will not pass since we have #entries == size != 0 &amp;amp;&amp;amp; lastOffset == baseOffset. &lt;/p&gt;

&lt;p&gt;The solution is to modify indexSlotFor() such that it returns -1 for non&#8211;zero sized index file whose lastOffset is 0 (assuming that setLength() will set empty bytes to 0), so that the index file is truncated to #entries == size == 0. &lt;/p&gt;


&lt;p&gt;Testing done: &lt;br/&gt;
1. Unit tests passed.&lt;br/&gt;
2. Change the flush interval and index append interval to really low values. Produce data using console producer (index file will have flushed entries), hard kill the broker, restart the broker. Should see the exception without A. Should pass with A, ctrl+C the broker.&lt;br/&gt;
3. Cleanup the kafka-logs directory, don&apos;t cleanup the zookeeper. Restart the broker (to create empty log and index files for topics created in 2 above), it will boot up, hard kill it. Restart the broker again, it should fail without B, should boot successfully with B.&lt;/p&gt;</comment>
                            <comment id="13577463" author="swapnilghike" created="Wed, 13 Feb 2013 10:05:53 +0000"  >&lt;p&gt;Sorry, in indexSlotFor() we should check if lastOffset is the same as or less than baseOffset. Attached patch v2.&lt;/p&gt;</comment>
                            <comment id="13577681" author="junrao" created="Wed, 13 Feb 2013 16:23:48 +0000"  >&lt;p&gt;Thanks for the patch. Good catch. I think problem B can explain item 2 in &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-750&quot; title=&quot;inconsistent index offset during broker startup&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-750&quot;&gt;&lt;del&gt;KAFKA-750&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I am not so sure about the fix in OffsetIndex though. indexSlotFor() assumes that the index is valid. However, when truncate() is called, the index may not be valid. Instead of changing the assumption in indexSlotFor(), it&apos;s probably better to implement truncate() directly without relying on index lookups.&lt;/p&gt;</comment>
                            <comment id="13577895" author="swapnilghike" created="Wed, 13 Feb 2013 20:17:03 +0000"  >&lt;p&gt;Yes, your point is valid. Jay also suggested to implement truncate() directly without calling indexSlotFor(). Patch v3 contains the change.&lt;/p&gt;</comment>
                            <comment id="13577965" author="junrao" created="Wed, 13 Feb 2013 22:02:39 +0000"  >&lt;p&gt;Thanks for patch v3. Committed to 0.8.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12677081">KAFKA-1112</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12569165" name="kafka-757-v1.patch" size="2089" author="swapnilghike" created="Wed, 13 Feb 2013 09:50:17 +0000"/>
                            <attachment id="12569167" name="kafka-757-v2.patch" size="2098" author="swapnilghike" created="Wed, 13 Feb 2013 10:05:53 +0000"/>
                            <attachment id="12569257" name="kafka-757-v3.patch" size="3419" author="swapnilghike" created="Wed, 13 Feb 2013 20:17:03 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>312517</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            12 years, 40 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1hxjr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>312863</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>