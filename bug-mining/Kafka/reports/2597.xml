<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:23:29 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-9826] Log cleaning repeatedly picks same segment with no effect when first dirty offset is past start of active segment</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-9826</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Seen on a system where a given partition had a single segment, and for whatever reason (deleteRecords?), the logStartOffset was greater than the base segment of the log, there were a continuous series of&#160;&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;2020-03-03 16:56:31,374&amp;#93;&lt;/span&gt; WARN Resetting first dirty offset of&#160; FOO-3 to log start offset 55649 since the checkpointed offset 0 is invalid. (kafka.log.LogCleanerManager$)&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;messages (partition name changed, it wasn&apos;t really FOO). This was expected to be resolved by &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6266&quot; title=&quot;Kafka 1.0.0 : Repeated occurrence of WARN Resetting first dirty offset of __consumer_offsets-xx to log start offset 203569 since the checkpointed offset 120955 is invalid. (kafka.log.LogCleanerManager$)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6266&quot;&gt;&lt;del&gt;KAFKA-6266&lt;/del&gt;&lt;/a&gt; but clearly wasn&apos;t.&#160;&lt;/p&gt;

&lt;p&gt;Further investigation revealed that&#160; a few segments were continuously cleaning and generating messages in the `log-cleaner.log` of the form:&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;2020-03-31 13:34:50,924&amp;#93;&lt;/span&gt; INFO Cleaner 1: Beginning cleaning of log FOO-3 (kafka.log.LogCleaner)&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;2020-03-31 13:34:50,924&amp;#93;&lt;/span&gt; INFO Cleaner 1: Building offset map for FOO-3... (kafka.log.LogCleaner)&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;2020-03-31 13:34:50,927&amp;#93;&lt;/span&gt; INFO Cleaner 1: Building offset map for log FOO-3 for 0 segments in offset range [55287, 54237). (kafka.log.LogCleaner)&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;2020-03-31 13:34:50,927&amp;#93;&lt;/span&gt; INFO Cleaner 1: Offset map for log FOO-3 complete. (kafka.log.LogCleaner)&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;2020-03-31 13:34:50,927&amp;#93;&lt;/span&gt; INFO Cleaner 1: Cleaning log FOO-3 (cleaning prior to Wed Dec 31 19:00:00 EST 1969, discarding tombstones prior to Tue Dec 10 13:39:08 EST 2019)... (kafka.log.LogCleaner)&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;2020-03-31 13:34:50,927&amp;#93;&lt;/span&gt; INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-log-cleaner-thread-1&amp;#93;&lt;/span&gt;: Log cleaner thread 1 cleaned log FOO-3 (dirty section = &lt;span class=&quot;error&quot;&gt;&amp;#91;55287, 55287&amp;#93;&lt;/span&gt;)&lt;/p&gt;

&lt;p&gt;0.0 MB of log processed in 0.0 seconds (0.0 MB/sec).&lt;/p&gt;

&lt;p&gt;Indexed 0.0 MB in 0.0 seconds (0.0 Mb/sec, 100.0% of total time)&lt;/p&gt;

&lt;p&gt;Buffer utilization: 0.0%&lt;/p&gt;

&lt;p&gt;Cleaned 0.0 MB in 0.0 seconds (NaN Mb/sec, 0.0% of total time)&lt;/p&gt;

&lt;p&gt;Start size: 0.0 MB (0 messages)&lt;/p&gt;

&lt;p&gt;End size: 0.0 MB (0 messages) NaN% size reduction (NaN% fewer messages) (kafka.log.LogCleaner)&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;What seems to have happened here (data determined for a different partition) is:&lt;/p&gt;

&lt;p&gt;There exist a number of partitions here which get relatively low traffic, including our friend FOO-5.&#160;For whatever reason, LogStartOffset of this partition has moved beyond the baseOffset of the active segment. (Notes in other issues indicate that this is a reasonable scenario.) So there&#8217;s one segment, starting at 166266, and a log start of 166301.&lt;/p&gt;

&lt;p&gt;grabFilthiestCompactedLog runs and reads the checkpoint file. We see that this topicpartition needs to be cleaned, and call cleanableOffsets on it which returns an OffsetsToClean with firstDirtyOffset == logStartOffset == 166301 and firstUncleanableOffset = max(logStart, activeSegment.baseOffset) = 116301, and forceCheckpoint = true.&lt;/p&gt;

&lt;p&gt;The checkpoint file is updated in grabFilthiestCompactedLog (this is the fix for &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6266&quot; title=&quot;Kafka 1.0.0 : Repeated occurrence of WARN Resetting first dirty offset of __consumer_offsets-xx to log start offset 203569 since the checkpointed offset 120955 is invalid. (kafka.log.LogCleanerManager$)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6266&quot;&gt;&lt;del&gt;KAFKA-6266&lt;/del&gt;&lt;/a&gt;). We then create a LogToClean object based on the firstDirtyOffset and firstUncleanableOffset of 166301 (past the active segment&#8217;s base offset).&lt;/p&gt;

&lt;p&gt;The LogToClean object has cleanBytes = logSegments(-1, firstDirtyOffset).map(_.size).sum &#8594; the size of this segment. It has firstUncleanableOffset and cleanableBytes determined by calculateCleanableBytes. calculateCleanableBytes returns:&lt;br/&gt;
{{}}&lt;br/&gt;
&lt;tt&gt;val firstUncleanableSegment = log.nonActiveLogSegmentsFrom(uncleanableOffset).headOption.getOrElse(log.activeSegment)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;val firstUncleanableOffset = firstUncleanableSegment.baseOffset&lt;/tt&gt;&lt;br/&gt;
{{val cleanableBytes = log.logSegments(firstDirtyOffset, math.max(firstDirtyOffset, firstUncleanableOffset)).map(_.size.toLong).sum&lt;/p&gt;

&lt;p&gt;(firstUncleanableOffset, cleanableBytes)}}&lt;br/&gt;
firstUncleanableSegment is activeSegment. firstUncleanableOffset is the base offset, 166266. cleanableBytes is looking for logSegments(166301, max(166301, 166266) &#8594; which &lt;em&gt;is the active segment&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;So there are &#8220;cleanableBytes&#8221; &amp;gt; 0.&lt;/p&gt;

&lt;p&gt;We then filter out segments with totalbytes (clean + cleanable) &amp;gt; 0. This segment has totalBytes &amp;gt; 0, and it has cleanablebytes, so great! It&#8217;s filthiest.&lt;/p&gt;

&lt;p&gt;The cleaner picks it, calls cleanLog on it, which then does cleaner.clean, which returns nextDirtyOffset and cleaner stats. cleaner.clean callls doClean, which builds an offsetMap. The offsetMap looks at non-active segments, when building, but there aren&#8217;t any. So the endOffset of the offsetMap is lastOffset (default -1) + 1 &#8594; 0. We record the stats (including logging to log-cleaner.log). After this we call cleanerManager.doneCleaning, which writes the checkpoint file with the latest value&#8230; of 0.&lt;/p&gt;

&lt;p&gt;And then the process starts all over.&lt;/p&gt;

&lt;p&gt;It appears that there&apos;s at least one bug here, where `log.logSegments(from, to)` will return an empty list if from == to and both are segment-aligned, but &lt;em&gt;not&lt;/em&gt; if they are in the middle of a segment, and possibly that LogToClean does start=firstDirtyOffset, end = max(firstDirtyOffset, firstUncleanableOffset) &#8211; it can move the firstUncleanableOffset even when the firstDirtyOffset is past firstUncleanable.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13296671">KAFKA-9826</key>
            <summary>Log cleaning repeatedly picks same segment with no effect when first dirty offset is past start of active segment</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="steverod">Steve Rodrigues</assignee>
                                    <reporter username="steverod">Steve Rodrigues</reporter>
                        <labels>
                    </labels>
                <created>Mon, 6 Apr 2020 22:36:39 +0000</created>
                <updated>Thu, 24 Mar 2022 03:54:19 +0000</updated>
                            <resolved>Wed, 15 Apr 2020 05:28:43 +0000</resolved>
                                    <version>2.4.1</version>
                                    <fixVersion>2.4.2</fixVersion>
                    <fixVersion>2.5.1</fixVersion>
                    <fixVersion>2.6.0</fixVersion>
                                    <component>log cleaner</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="17081607" author="githubbot" created="Sun, 12 Apr 2020 01:44:56 +0000"  >&lt;p&gt;steverod commented on pull request #8469: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-9826&quot; title=&quot;Log cleaning repeatedly picks same segment with no effect when first dirty offset is past start of active segment&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-9826&quot;&gt;&lt;del&gt;KAFKA-9826&lt;/del&gt;&lt;/a&gt; Handle an unaligned first dirty offset during log cleaning.&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/8469&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/8469&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   What&lt;br/&gt;
   ====&lt;br/&gt;
   In &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-9826&quot; title=&quot;Log cleaning repeatedly picks same segment with no effect when first dirty offset is past start of active segment&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-9826&quot;&gt;&lt;del&gt;KAFKA-9826&lt;/del&gt;&lt;/a&gt;, a log whose first dirty offset was past the start of the active segment and past the last cleaned point resulted in an endless cycle of picking the segment to clean and discarding it. Though this didn&apos;t interfere with cleaning other log segments, it kept the log cleaner thread continuously busy (potentially wasting CPU and impacting other running threads) and filled the logs with lots of extraneous messages.&lt;/p&gt;

&lt;p&gt;   This was determined to be because the active segment was getting mistakenly picked for cleaning, and because the `logSegments` code handles (start == end) cases only for (start, end) on a segment boundary: the intent is to return a null list, but if they&apos;re not on a segment boundary, the routine returns that segment.&lt;/p&gt;

&lt;p&gt;   This fix has two parts:&lt;br/&gt;
   1. It changes logSegments to handle start==end by returning an empty List always.&lt;br/&gt;
   2. It changes the definition of calculateCleanableBytes to not consider anything past the UncleanableOffset; previously, it would potentially shift the UncleanableOffset to match the firstDirtyOffset even if the firstDirtyOffset was past the firstUncleanableOffset. This has no real effect now in the context of the fix for (1) but it makes the code read more like the model that the code is attempting to follow.&lt;/p&gt;

&lt;p&gt;   These changes require modifications to a few test cases that handled this particular test case; they were introduced in the context of &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-8764&quot; title=&quot;LogCleanerManager endless loop while compacting/cleaning segments&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-8764&quot;&gt;&lt;del&gt;KAFKA-8764&lt;/del&gt;&lt;/a&gt;. Those situations are now handled elsewhere in code, but the tests themselves allowed a DirtyOffset in the active segment, and expected an active segment to be selected for cleaning.&lt;/p&gt;

&lt;p&gt;   An additional unit test for the logSegments call is added. &lt;/p&gt;

&lt;p&gt;   *Summary of testing strategy (including rationale)&lt;br/&gt;
   for the feature or bug fix. Unit and/or integration&lt;br/&gt;
   tests are expected for any behaviour change and&lt;br/&gt;
   system tests should be considered for larger changes.*&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on to GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="17083810" author="githubbot" created="Wed, 15 Apr 2020 05:27:55 +0000"  >&lt;p&gt;junrao commented on pull request #8469: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-9826&quot; title=&quot;Log cleaning repeatedly picks same segment with no effect when first dirty offset is past start of active segment&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-9826&quot;&gt;&lt;del&gt;KAFKA-9826&lt;/del&gt;&lt;/a&gt; Handle an unaligned first dirty offset during log cleaning.&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/8469&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/8469&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on to GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="17083811" author="junrao" created="Wed, 15 Apr 2020 05:28:43 +0000"  >&lt;p&gt;merged the PR to trunk&lt;/p&gt;</comment>
                            <comment id="17101644" author="fekelund" created="Thu, 7 May 2020 12:57:18 +0000"  >&lt;p&gt;Hello, we have also hit this issue in one of our environments. Is the fix planned to be included in 2.4.2?&lt;/p&gt;</comment>
                            <comment id="17101751" author="junrao" created="Thu, 7 May 2020 15:01:28 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fekelund&quot; class=&quot;user-hover&quot; rel=&quot;fekelund&quot;&gt;fekelund&lt;/a&gt;: Yes. Updated the fix versions.&lt;/p&gt;</comment>
                            <comment id="17342571" author="zhangzs" created="Tue, 11 May 2021 13:36:33 +0000"  >&lt;p&gt;we have same problems&#65292;kafka version 2.12_2.4.1&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// code placeholder
&lt;/span&gt;[2021-05-11 18:31:33,329] WARN Resetting first dirty offset of __consumer_offsets-30 to log start offset 4187979634 since the checkpointed offset 4187569609 is invalid. (kafka.log.LogCleanerManager$)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17342904" author="junrao" created="Tue, 11 May 2021 22:37:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhangzs&quot; class=&quot;user-hover&quot; rel=&quot;zhangzs&quot;&gt;zhangzs&lt;/a&gt;&#160;: The issue was fixed in 2.4.2. Could you try that version?&lt;/p&gt;</comment>
                            <comment id="17511576" author="zhangzs" created="Thu, 24 Mar 2022 03:54:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt;&#160; kafka version from 2.4.1 to 2.8.1&#65292;the issue has sloved&#65292;tks&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 33 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0dc8o:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>