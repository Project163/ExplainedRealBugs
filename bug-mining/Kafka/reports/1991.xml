<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:13:22 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6897] Mirrormaker waits to shut down forever on produce failure with abort.on.send.failure=true </title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6897</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Mirrormaker never shuts down after a produce failure when abort.on.send.failure=true&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[2018-05-07 08:29:32,417]&#160;ERROR Error when sending message to topic test with key: 52 bytes, value: 32615 bytes with error: (org.apache.kafka.clients.producer.internals.ErrorLoggingCallback)
org.apache.kafka.common.errors.TimeoutException: Expiring 1 record(s) &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; test-11: 45646 ms has passed since last append
[2018-05-07 08:29:32,434]&#160;INFO Closing producer due to send failure. (kafka.tools.MirrorMaker$)
[2018-05-07 08:29:32,434]&#160;INFO&#160;[Producer clientId=producer-1]&#160;Closing the Kafka producer with timeoutMillis = 0 ms. (org.apache.kafka.clients.producer.KafkaProducer)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;A stack trace of this mirrormaker process 9 hours later shows that the main thread is still active and it is waiting for metadata that it will never get since the producer send thread is no longer running.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13158638">KAFKA-6897</key>
            <summary>Mirrormaker waits to shut down forever on produce failure with abort.on.send.failure=true </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dhruvilshah">Dhruvil Shah</assignee>
                                    <reporter username="Koelli">Koelli Mungee</reporter>
                        <labels>
                    </labels>
                <created>Fri, 11 May 2018 04:31:03 +0000</created>
                <updated>Sat, 21 Jul 2018 21:12:14 +0000</updated>
                            <resolved>Sat, 21 Jul 2018 21:12:14 +0000</resolved>
                                    <version>1.1.0</version>
                                    <fixVersion>2.0.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16478369" author="githubbot" created="Thu, 17 May 2018 01:46:51 +0000"  >&lt;p&gt;dhruvilshah3 opened a new pull request #5027: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6897&quot; title=&quot;Mirrormaker waits to shut down forever on produce failure with abort.on.send.failure=true &quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6897&quot;&gt;&lt;del&gt;KAFKA-6897&lt;/del&gt;&lt;/a&gt;: Prevent producer from blocking indefinitely on close&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5027&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5027&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   After successful completion of KafkaProducer#close, it is possible that an application calls KafkaProducer#send. If the send is invoked for a topic for which we do not have any metadata, the producer will block until `max.block.ms` elapses - we do not expect to receive any metadata update in this case because Sender (and NetworkClient) has already exited. It is only when RecordAccumulator#append is invoked that we notice that the producer has already exited. If `max.block.ms` is set to Long.MaxValue (or a sufficiently high value in general), the producer could this block infinitely.&lt;/p&gt;

&lt;p&gt;   This patch introduces the concept of &quot;poisoned metadata&quot;. In NetworkClient#close, we poison the metadata to indicate that no further metadata updates are possible. Any consumer that is currently waiting on (or could wait for in future) for metadata updates could check the poison state of metadata and exit early, if required.&lt;/p&gt;

&lt;p&gt;   This is an early upload to get some feedback on the direction of this patch. If we agree this is the correct way to fix this issue, I will add unit tests.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16512070" author="rsivaram" created="Thu, 14 Jun 2018 07:23:21 +0000"  >&lt;p&gt;Moving this out to 2.1.0 since it is not ready for 2.0.0&lt;/p&gt;</comment>
                            <comment id="16551829" author="githubbot" created="Sat, 21 Jul 2018 21:03:17 +0000"  >&lt;p&gt;hachikuji closed pull request #5027: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6897&quot; title=&quot;Mirrormaker waits to shut down forever on produce failure with abort.on.send.failure=true &quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6897&quot;&gt;&lt;del&gt;KAFKA-6897&lt;/del&gt;&lt;/a&gt;: Prevent producer from blocking indefinitely after close&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5027&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5027&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/clients/src/main/java/org/apache/kafka/clients/ManualMetadataUpdater.java b/clients/src/main/java/org/apache/kafka/clients/ManualMetadataUpdater.java&lt;br/&gt;
index 8252cf3a9cd..ec007a69668 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/ManualMetadataUpdater.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/ManualMetadataUpdater.java&lt;br/&gt;
@@ -89,4 +89,8 @@ public void handleCompletedMetadataResponse(RequestHeader requestHeader, long no&lt;br/&gt;
     public void requestUpdate() &lt;/p&gt;
{
         // Do nothing
     }
&lt;p&gt;+&lt;br/&gt;
+    @Override&lt;br/&gt;
+    public void close() &lt;/p&gt;
{
+    }
&lt;p&gt; }&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/clients/Metadata.java b/clients/src/main/java/org/apache/kafka/clients/Metadata.java&lt;br/&gt;
index 91b15875cd0..6c663cfac93 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/Metadata.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/Metadata.java&lt;br/&gt;
@@ -17,6 +17,7 @@&lt;br/&gt;
 package org.apache.kafka.clients;&lt;/p&gt;

&lt;p&gt; import org.apache.kafka.common.Cluster;&lt;br/&gt;
+import org.apache.kafka.common.KafkaException;&lt;br/&gt;
 import org.apache.kafka.common.internals.ClusterResourceListeners;&lt;br/&gt;
 import org.apache.kafka.common.Node;&lt;br/&gt;
 import org.apache.kafka.common.PartitionInfo;&lt;br/&gt;
@@ -25,6 +26,7 @@&lt;br/&gt;
 import org.slf4j.Logger;&lt;br/&gt;
 import org.slf4j.LoggerFactory;&lt;/p&gt;

&lt;p&gt;+import java.io.Closeable;&lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
 import java.util.Collection;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
@@ -48,7 +50,7 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;is removed from the metadata refresh set after an update. Consumers disable topic expiry since they explicitly&lt;/li&gt;
	&lt;li&gt;manage topics while producers rely on topic expiry to limit the refresh set.&lt;br/&gt;
  */&lt;br/&gt;
-public final class Metadata {&lt;br/&gt;
+public final class Metadata implements Closeable {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     private static final Logger log = LoggerFactory.getLogger(Metadata.class);&lt;/p&gt;

&lt;p&gt;@@ -70,6 +72,7 @@&lt;br/&gt;
     private boolean needMetadataForAllTopics;&lt;br/&gt;
     private final boolean allowAutoTopicCreation;&lt;br/&gt;
     private final boolean topicExpiryEnabled;&lt;br/&gt;
+    private boolean isClosed;&lt;/p&gt;

&lt;p&gt;     public Metadata(long refreshBackoffMs, long metadataExpireMs, boolean allowAutoTopicCreation) &lt;/p&gt;
{
         this(refreshBackoffMs, metadataExpireMs, allowAutoTopicCreation, false, new ClusterResourceListeners());
@@ -100,6 +103,7 @@ public Metadata(long refreshBackoffMs, long metadataExpireMs, boolean allowAutoT
         this.listeners = new ArrayList&amp;lt;&amp;gt;();
         this.clusterResourceListeners = clusterResourceListeners;
         this.needMetadataForAllTopics = false;
+        this.isClosed = false;
     }

&lt;p&gt;     /**&lt;br/&gt;
@@ -164,12 +168,12 @@ public synchronized AuthenticationException getAndClearAuthenticationException()&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Wait for metadata update until the current version is larger than the last version we know of&lt;br/&gt;
      */&lt;br/&gt;
     public synchronized void awaitUpdate(final int lastVersion, final long maxWaitMs) throws InterruptedException {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (maxWaitMs &amp;lt; 0) 
{
+        if (maxWaitMs &amp;lt; 0)
             throw new IllegalArgumentException(&quot;Max time to wait for metadata updates should not be &amp;lt; 0 milliseconds&quot;);
-        }
&lt;p&gt;+&lt;br/&gt;
         long begin = System.currentTimeMillis();&lt;br/&gt;
         long remainingWaitMs = maxWaitMs;&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;while (this.version &amp;lt;= lastVersion) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+        while ((this.version &amp;lt;= lastVersion) &amp;amp;&amp;amp; !isClosed()) {
             AuthenticationException ex = getAndClearAuthenticationException();
             if (ex != null)
                 throw ex;
@@ -180,6 +184,8 @@ public synchronized void awaitUpdate(final int lastVersion, final long maxWaitMs
                 throw new TimeoutException(&quot;Failed to update metadata after &quot; + maxWaitMs + &quot; ms.&quot;);
             remainingWaitMs = maxWaitMs - elapsed;
         }+        if (isClosed())+            throw new KafkaException(&amp;quot;Requested metadata update after close&amp;quot;);     }&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;br/&gt;
@@ -224,6 +230,8 @@ public synchronized boolean containsTopic(String topic) {&lt;br/&gt;
      */&lt;br/&gt;
     public synchronized void update(Cluster newCluster, Set&amp;lt;String&amp;gt; unavailableTopics, long now) {&lt;br/&gt;
         Objects.requireNonNull(newCluster, &quot;cluster should not be null&quot;);&lt;br/&gt;
+        if (isClosed())&lt;br/&gt;
+            throw new IllegalStateException(&quot;Update requested after metadata close&quot;);&lt;/p&gt;

&lt;p&gt;         this.needUpdate = false;&lt;br/&gt;
         this.lastRefreshMs = now;&lt;br/&gt;
@@ -331,6 +339,25 @@ public synchronized void removeListener(Listener listener) &lt;/p&gt;
{
         this.listeners.remove(listener);
     }

&lt;p&gt;+    /**&lt;br/&gt;
+     * &quot;Close&quot; this metadata instance to indicate that metadata updates are no longer possible. This is typically used&lt;br/&gt;
+     * when the thread responsible for performing metadata updates is exiting and needs a way to relay this information&lt;br/&gt;
+     * to any other thread(s) that could potentially wait on metadata update to come through.&lt;br/&gt;
+     */&lt;br/&gt;
+    @Override&lt;br/&gt;
+    public synchronized void close() &lt;/p&gt;
{
+        this.isClosed = true;
+        this.notifyAll();
+    }
&lt;p&gt;+&lt;br/&gt;
+    /**&lt;br/&gt;
+     * Check if this metadata instance has been closed. See &lt;/p&gt;
{@link #close()}
&lt;p&gt; for more information.&lt;br/&gt;
+     * @return True if this instance has been closed; false otherwise&lt;br/&gt;
+     */&lt;br/&gt;
+    public synchronized boolean isClosed() &lt;/p&gt;
{
+        return this.isClosed;
+    }
&lt;p&gt;+&lt;br/&gt;
     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;MetadataUpdate Listener&lt;br/&gt;
      */&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/clients/MetadataUpdater.java b/clients/src/main/java/org/apache/kafka/clients/MetadataUpdater.java&lt;br/&gt;
index 09ed995d14c..de765db5a8d 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/clients/src/main/java/org/apache/kafka/clients/MetadataUpdater.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/MetadataUpdater.java&lt;br/&gt;
@@ -21,6 +21,7 @@&lt;br/&gt;
 import org.apache.kafka.common.requests.MetadataResponse;&lt;br/&gt;
 import org.apache.kafka.common.requests.RequestHeader;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+import java.io.Closeable;&lt;br/&gt;
 import java.util.List;&lt;/p&gt;

&lt;p&gt; /**&lt;br/&gt;
@@ -29,7 +30,7 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&amp;lt;p&amp;gt;&lt;/li&gt;
	&lt;li&gt;This class is not thread-safe!&lt;br/&gt;
  */&lt;br/&gt;
-public interface MetadataUpdater {&lt;br/&gt;
+public interface MetadataUpdater extends Closeable 
{
 
     /**
      * Gets the current cluster info without blocking.
@@ -82,4 +83,10 @@
      * start of the update if possible (see `maybeUpdate` for more information).
      */
     void requestUpdate();
+
+    /**
+     * Close this updater.
+     */
+    @Override
+    void close();
 }
&lt;p&gt;diff --git a/clients/src/main/java/org/apache/kafka/clients/NetworkClient.java b/clients/src/main/java/org/apache/kafka/clients/NetworkClient.java&lt;br/&gt;
index 720a7814752..fd16fe608e3 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/clients/src/main/java/org/apache/kafka/clients/NetworkClient.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/NetworkClient.java&lt;br/&gt;
@@ -581,6 +581,7 @@ public void wakeup() {&lt;br/&gt;
     @Override&lt;br/&gt;
     public void close() 
{
         this.selector.close();
+        this.metadataUpdater.close();
     }&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;br/&gt;
@@ -981,6 +982,11 @@ public void requestUpdate() &lt;/p&gt;
{
             this.metadata.requestUpdate();
         }

&lt;p&gt;+        @Override&lt;br/&gt;
+        public void close() &lt;/p&gt;
{
+            this.metadata.close();
+        }
&lt;p&gt;+&lt;br/&gt;
         /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Return true if there&apos;s at least one connection establishment is currently underway&lt;br/&gt;
          */&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/clients/admin/internals/AdminMetadataManager.java b/clients/src/main/java/org/apache/kafka/clients/admin/internals/AdminMetadataManager.java&lt;br/&gt;
index 85d3c28e8df..1ad3991ca24 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/clients/src/main/java/org/apache/kafka/clients/admin/internals/AdminMetadataManager.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/admin/internals/AdminMetadataManager.java&lt;br/&gt;
@@ -118,6 +118,10 @@ public void handleCompletedMetadataResponse(RequestHeader requestHeader, long no&lt;br/&gt;
         public void requestUpdate() 
{
             AdminMetadataManager.this.requestUpdate();
         }
&lt;p&gt;+&lt;br/&gt;
+        @Override&lt;br/&gt;
+        public void close() &lt;/p&gt;
{
+        }
&lt;p&gt;     }&lt;/p&gt;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java b/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java&lt;br/&gt;
index 3a6717b7676..3519947bf15 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java&lt;br/&gt;
@@ -790,12 +790,12 @@ public void abortTransaction() throws ProducerFencedException {&lt;br/&gt;
      *&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@throws AuthenticationException if authentication fails. See the exception for more details&lt;/li&gt;
	&lt;li&gt;@throws AuthorizationException fatal error indicating that the producer is not allowed to write&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* @throws IllegalStateException if a transactional.id has been configured and no transaction has been started&lt;br/&gt;
+     * @throws IllegalStateException if a transactional.id has been configured and no transaction has been started, or&lt;br/&gt;
+     *                               when send is invoked after producer has been closed.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@throws InterruptException If the thread is interrupted while blocked&lt;/li&gt;
	&lt;li&gt;@throws SerializationException If the key or value are not valid objects given the configured serializers&lt;/li&gt;
	&lt;li&gt;@throws TimeoutException If the time taken for fetching metadata or allocating memory for the record has surpassed &amp;lt;code&amp;gt;max.block.ms&amp;lt;/code&amp;gt;.&lt;/li&gt;
	&lt;li&gt;@throws KafkaException If a Kafka related error occurs that does not belong to the public API exceptions.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;*&lt;br/&gt;
      */&lt;br/&gt;
     @Override&lt;br/&gt;
     public Future&amp;lt;RecordMetadata&amp;gt; send(ProducerRecord&amp;lt;K, V&amp;gt; record, Callback callback) {&lt;br/&gt;
@@ -804,14 +804,29 @@ public void abortTransaction() throws ProducerFencedException 
{
         return doSend(interceptedRecord, callback);
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+    // Verify that this producer instance has not been closed. This method throws IllegalStateException if the producer&lt;br/&gt;
+    // has already been closed.&lt;br/&gt;
+    private void throwIfProducerClosed() &lt;/p&gt;
{
+        if (ioThread == null || !ioThread.isAlive())
+            throw new IllegalStateException(&quot;Cannot perform operation after producer has been closed&quot;);
+    }
&lt;p&gt;+&lt;br/&gt;
     /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Implementation of asynchronously send a record to a topic.&lt;br/&gt;
      */&lt;br/&gt;
     private Future&amp;lt;RecordMetadata&amp;gt; doSend(ProducerRecord&amp;lt;K, V&amp;gt; record, Callback callback) {&lt;br/&gt;
         TopicPartition tp = null;&lt;br/&gt;
         try {&lt;br/&gt;
+            throwIfProducerClosed();&lt;br/&gt;
             // first make sure the metadata for the topic is available&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ClusterAndWaitTime clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), maxBlockTimeMs);&lt;br/&gt;
+            ClusterAndWaitTime clusterAndWaitTime;&lt;br/&gt;
+            try 
{
+                clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), maxBlockTimeMs);
+            }
&lt;p&gt; catch (KafkaException e) &lt;/p&gt;
{
+                if (metadata.isClosed())
+                    throw new KafkaException(&quot;Producer closed while send in progress&quot;, e);
+                throw e;
+            }
&lt;p&gt;             long remainingWaitMs = Math.max(0, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs);&lt;br/&gt;
             Cluster cluster = clusterAndWaitTime.cluster;&lt;br/&gt;
             byte[] serializedKey;&lt;br/&gt;
@@ -896,6 +911,7 @@ private void setReadOnly(Headers headers) {&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param partition A specific partition expected to exist in metadata, or null if there&apos;s no preference&lt;/li&gt;
	&lt;li&gt;@param maxWaitMs The maximum time in ms for waiting on the metadata&lt;/li&gt;
	&lt;li&gt;@return The cluster containing topic metadata and the amount of time we waited in ms&lt;br/&gt;
+     * @throws KafkaException for all Kafka-related exceptions, including the case where this method is called after producer close&lt;br/&gt;
      */&lt;br/&gt;
     private ClusterAndWaitTime waitOnMetadata(String topic, Integer partition, long maxWaitMs) throws InterruptedException {&lt;br/&gt;
         // add topic to metadata topic list if it is not there already and reset expiry&lt;br/&gt;
@@ -1016,8 +1032,9 @@ public void flush() {&lt;/li&gt;
	&lt;li&gt;Get the partition metadata for the given topic. This can be used for custom partitioning.&lt;/li&gt;
	&lt;li&gt;@throws AuthenticationException if authentication fails. See the exception for more details&lt;/li&gt;
	&lt;li&gt;@throws AuthorizationException if not authorized to the specified topic. See the exception for more details&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* @throws InterruptException If the thread is interrupted while blocked&lt;br/&gt;
+     * @throws InterruptException if the thread is interrupted while blocked&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@throws TimeoutException if metadata could not be refreshed within 
{@code max.block.ms}
&lt;p&gt;+     * @throws KafkaException for all Kafka-related exceptions, including the case where this method is called after producer close&lt;br/&gt;
      */&lt;br/&gt;
     @Override&lt;br/&gt;
     public List&amp;lt;PartitionInfo&amp;gt; partitionsFor(String topic) {&lt;br/&gt;
diff --git a/clients/src/main/java/org/apache/kafka/clients/producer/MockProducer.java b/clients/src/main/java/org/apache/kafka/clients/producer/MockProducer.java&lt;br/&gt;
index 9e9869a7e48..dc00b473027 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/clients/src/main/java/org/apache/kafka/clients/producer/MockProducer.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/producer/MockProducer.java&lt;br/&gt;
@@ -311,9 +311,6 @@ public void close() {&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @Override&lt;br/&gt;
     public void close(long timeout, TimeUnit timeUnit) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (this.closed) 
{
-            throw new IllegalStateException(&quot;MockProducer is already closed.&quot;);
-        }
&lt;p&gt;         this.closed = true;&lt;br/&gt;
     }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;diff --git a/clients/src/main/java/org/apache/kafka/clients/producer/internals/RecordAccumulator.java b/clients/src/main/java/org/apache/kafka/clients/producer/internals/RecordAccumulator.java&lt;br/&gt;
index e2b58448dc9..31c6d754c9d 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/clients/producer/internals/RecordAccumulator.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/clients/producer/internals/RecordAccumulator.java&lt;br/&gt;
@@ -19,6 +19,7 @@&lt;br/&gt;
 import org.apache.kafka.clients.ApiVersions;&lt;br/&gt;
 import org.apache.kafka.clients.producer.Callback;&lt;br/&gt;
 import org.apache.kafka.common.Cluster;&lt;br/&gt;
+import org.apache.kafka.common.KafkaException;&lt;br/&gt;
 import org.apache.kafka.common.MetricName;&lt;br/&gt;
 import org.apache.kafka.common.Node;&lt;br/&gt;
 import org.apache.kafka.common.PartitionInfo;&lt;br/&gt;
@@ -195,7 +196,7 @@ public RecordAppendResult append(TopicPartition tp,&lt;br/&gt;
             Deque&amp;lt;ProducerBatch&amp;gt; dq = getOrCreateDeque(tp);&lt;br/&gt;
             synchronized (dq) {&lt;br/&gt;
                 if (closed)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;throw new IllegalStateException(&quot;Cannot send after the producer is closed.&quot;);&lt;br/&gt;
+                    throw new KafkaException(&quot;Producer closed while send in progress&quot;);&lt;br/&gt;
                 RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq);&lt;br/&gt;
                 if (appendResult != null)&lt;br/&gt;
                     return appendResult;&lt;br/&gt;
@@ -209,7 +210,7 @@ public RecordAppendResult append(TopicPartition tp,&lt;br/&gt;
             synchronized (dq) {&lt;br/&gt;
                 // Need to check if producer is closed again after grabbing the dequeue lock.&lt;br/&gt;
                 if (closed)&lt;/li&gt;
	&lt;li&gt;throw new IllegalStateException(&quot;Cannot send after the producer is closed.&quot;);&lt;br/&gt;
+                    throw new KafkaException(&quot;Producer closed while send in progress&quot;);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;                 RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq);&lt;br/&gt;
                 if (appendResult != null) {&lt;br/&gt;
@@ -700,7 +701,7 @@ public void abortIncompleteBatches() {&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Go through incomplete batches and abort them.&lt;br/&gt;
      */&lt;br/&gt;
     private void abortBatches() 
{
-        abortBatches(new IllegalStateException(&quot;Producer is closed forcefully.&quot;));
+        abortBatches(new KafkaException(&quot;Producer is closed forcefully.&quot;));
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;br/&gt;
diff --git a/clients/src/test/java/org/apache/kafka/clients/MetadataTest.java b/clients/src/test/java/org/apache/kafka/clients/MetadataTest.java&lt;br/&gt;
index 1188af776aa..969921eceeb 100644&lt;br/&gt;
&amp;#8212; a/clients/src/test/java/org/apache/kafka/clients/MetadataTest.java&lt;br/&gt;
+++ b/clients/src/test/java/org/apache/kafka/clients/MetadataTest.java&lt;br/&gt;
@@ -25,6 +25,7 @@&lt;br/&gt;
 import java.util.concurrent.atomic.AtomicReference;&lt;/p&gt;

&lt;p&gt; import org.apache.kafka.common.Cluster;&lt;br/&gt;
+import org.apache.kafka.common.KafkaException;&lt;br/&gt;
 import org.apache.kafka.common.internals.ClusterResourceListeners;&lt;br/&gt;
 import org.apache.kafka.common.Node;&lt;br/&gt;
 import org.apache.kafka.common.PartitionInfo;&lt;br/&gt;
@@ -46,7 +47,7 @@&lt;br/&gt;
     private long refreshBackoffMs = 100;&lt;br/&gt;
     private long metadataExpireMs = 1000;&lt;br/&gt;
     private Metadata metadata = new Metadata(refreshBackoffMs, metadataExpireMs, true);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private AtomicReference&amp;lt;String&amp;gt; backgroundError = new AtomicReference&amp;lt;&amp;gt;();&lt;br/&gt;
+    private AtomicReference&amp;lt;Exception&amp;gt; backgroundError = new AtomicReference&amp;lt;&amp;gt;();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @After&lt;br/&gt;
     public void tearDown() {&lt;br/&gt;
@@ -83,6 +84,30 @@ public void testMetadata() throws Exception &lt;/p&gt;
{
         assertTrue(&quot;Update needed due to stale metadata.&quot;, metadata.timeToNextUpdate(time) == 0);
     }

&lt;p&gt;+    @Test&lt;br/&gt;
+    public void testMetadataAwaitAfterClose() throws InterruptedException &lt;/p&gt;
{
+        long time = 0;
+        metadata.update(Cluster.empty(), Collections.&amp;lt;String&amp;gt;emptySet(), time);
+        assertFalse(&quot;No update needed.&quot;, metadata.timeToNextUpdate(time) == 0);
+        metadata.requestUpdate();
+        assertFalse(&quot;Still no updated needed due to backoff&quot;, metadata.timeToNextUpdate(time) == 0);
+        time += refreshBackoffMs;
+        assertTrue(&quot;Update needed now that backoff time expired&quot;, metadata.timeToNextUpdate(time) == 0);
+        String topic = &quot;my-topic&quot;;
+        metadata.close();
+        Thread t1 = asyncFetch(topic, 500);
+        t1.join();
+        assertTrue(backgroundError.get().getClass() == KafkaException.class);
+        assertTrue(backgroundError.get().toString().contains(&quot;Requested metadata update after close&quot;));
+        clearBackgroundError();
+    }
&lt;p&gt;+&lt;br/&gt;
+    @Test(expected = IllegalStateException.class)&lt;br/&gt;
+    public void testMetadataUpdateAfterClose() &lt;/p&gt;
{
+        metadata.close();
+        metadata.update(Cluster.empty(), Collections.&amp;lt;String&amp;gt;emptySet(), 1000);
+    }
&lt;p&gt;+&lt;br/&gt;
     private static void checkTimeToNextUpdate(long refreshBackoffMs, long metadataExpireMs) {&lt;br/&gt;
         long now = 10000;&lt;/p&gt;

&lt;p&gt;@@ -409,15 +434,18 @@ public void testNonExpiringMetadata() throws Exception &lt;/p&gt;
{
         assertTrue(&quot;Unused topic expired when expiry disabled&quot;, metadata.containsTopic(&quot;topic4&quot;));
     }

&lt;p&gt;+    private void clearBackgroundError() &lt;/p&gt;
{
+        backgroundError.set(null);
+    }
&lt;p&gt;+&lt;br/&gt;
     private Thread asyncFetch(final String topic, final long maxWaitMs) {&lt;br/&gt;
         Thread thread = new Thread() {&lt;br/&gt;
             public void run() {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;while (metadata.fetch().partitionsForTopic(topic).isEmpty()) {&lt;/li&gt;
	&lt;li&gt;try 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+                try {
+                    while (metadata.fetch().partitionsForTopic(topic).isEmpty())
                         metadata.awaitUpdate(metadata.requestUpdate(), maxWaitMs);
-                    } catch (Exception e) {
-                        backgroundError.set(e.toString());
-                    }+                }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
+                    backgroundError.set(e);
                 }
&lt;p&gt;             }&lt;br/&gt;
         };&lt;br/&gt;
diff --git a/clients/src/test/java/org/apache/kafka/clients/MockClient.java b/clients/src/test/java/org/apache/kafka/clients/MockClient.java&lt;br/&gt;
index 0f64f13ef60..6b41a9e8779 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/clients/src/test/java/org/apache/kafka/clients/MockClient.java&lt;br/&gt;
+++ b/clients/src/test/java/org/apache/kafka/clients/MockClient.java&lt;br/&gt;
@@ -533,6 +533,7 @@ public ClientRequest newClientRequest(String nodeId,&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @Override&lt;br/&gt;
     public void close() &lt;/p&gt;
{
+        metadata.close();
     }

&lt;p&gt;     @Override&lt;br/&gt;
diff --git a/clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java b/clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java&lt;br/&gt;
index bf03e46ec08..dd2dd896b28 100644&lt;br/&gt;
&amp;#8212; a/clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java&lt;br/&gt;
+++ b/clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java&lt;br/&gt;
@@ -632,8 +632,8 @@ public void testSendToInvalidTopic() throws Exception {&lt;br/&gt;
         client.setNode(node);&lt;/p&gt;

&lt;p&gt;         Producer&amp;lt;String, String&amp;gt; producer = new KafkaProducer&amp;lt;&amp;gt;(new ProducerConfig(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ProducerConfig.addSerializerToConfig(props, new StringSerializer(), new StringSerializer())),&lt;/li&gt;
	&lt;li&gt;new StringSerializer(), new StringSerializer(), metadata, client);&lt;br/&gt;
+                ProducerConfig.addSerializerToConfig(props, new StringSerializer(), new StringSerializer())),&lt;br/&gt;
+                new StringSerializer(), new StringSerializer(), metadata, client);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         String invalidTopicName = &quot;topic abc&quot;;          // Invalid topic name due to space&lt;br/&gt;
         ProducerRecord&amp;lt;String, String&amp;gt; record = new ProducerRecord&amp;lt;&amp;gt;(invalidTopicName, &quot;HelloKafka&quot;);&lt;br/&gt;
@@ -641,12 +641,12 @@ public void testSendToInvalidTopic() throws Exception {&lt;br/&gt;
         Set&amp;lt;String&amp;gt; invalidTopic = new HashSet&amp;lt;String&amp;gt;();&lt;br/&gt;
         invalidTopic.add(invalidTopicName);&lt;br/&gt;
         Cluster metaDataUpdateResponseCluster = new Cluster(cluster.clusterResource().clusterId(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;cluster.nodes(),&lt;/li&gt;
	&lt;li&gt;new ArrayList&amp;lt;PartitionInfo&amp;gt;(0),&lt;/li&gt;
	&lt;li&gt;Collections.&amp;lt;String&amp;gt;emptySet(),&lt;/li&gt;
	&lt;li&gt;invalidTopic,&lt;/li&gt;
	&lt;li&gt;cluster.internalTopics(),&lt;/li&gt;
	&lt;li&gt;cluster.controller());&lt;br/&gt;
+                cluster.nodes(),&lt;br/&gt;
+                new ArrayList&amp;lt;PartitionInfo&amp;gt;(0),&lt;br/&gt;
+                Collections.&amp;lt;String&amp;gt;emptySet(),&lt;br/&gt;
+                invalidTopic,&lt;br/&gt;
+                cluster.internalTopics(),&lt;br/&gt;
+                cluster.controller());&lt;br/&gt;
         client.prepareMetadataUpdate(metaDataUpdateResponseCluster, Collections.&amp;lt;String&amp;gt;emptySet());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         Future&amp;lt;RecordMetadata&amp;gt; future = producer.send(record);&lt;br/&gt;
@@ -654,4 +654,51 @@ public void testSendToInvalidTopic() throws Exception &lt;/p&gt;
{
         assertEquals(&quot;Cluster has incorrect invalid topic list.&quot;, metaDataUpdateResponseCluster.invalidTopics(), metadata.fetch().invalidTopics());
         TestUtils.assertFutureError(future, InvalidTopicException.class);
     }
&lt;p&gt;+&lt;br/&gt;
+    @Test&lt;br/&gt;
+    public void testCloseWhenWaitingForMetadataUpdate() throws InterruptedException {&lt;br/&gt;
+        Properties props = new Properties();&lt;br/&gt;
+        props.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, Long.MAX_VALUE);&lt;br/&gt;
+        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9000&quot;);&lt;br/&gt;
+&lt;br/&gt;
+        // Simulate a case where metadata for a particular topic is not available. This will cause KafkaProducer#send to&lt;br/&gt;
+        // block in Metadata#awaitUpdate for the configured max.block.ms. When close() is invoked, KafkaProducer#send should&lt;br/&gt;
+        // return with a KafkaException.&lt;br/&gt;
+        String topicName = &quot;test&quot;;&lt;br/&gt;
+        Time time = new MockTime();&lt;br/&gt;
+        Cluster cluster = TestUtils.singletonCluster();&lt;br/&gt;
+        Node node = cluster.nodes().get(0);&lt;br/&gt;
+        Metadata metadata = new Metadata(0, Long.MAX_VALUE, false);&lt;br/&gt;
+        metadata.update(cluster, Collections.&amp;lt;String&amp;gt;emptySet(), time.milliseconds());&lt;br/&gt;
+        MockClient client = new MockClient(time, metadata);&lt;br/&gt;
+        client.setNode(node);&lt;br/&gt;
+&lt;br/&gt;
+        Producer&amp;lt;String, String&amp;gt; producer = new KafkaProducer&amp;lt;&amp;gt;(&lt;br/&gt;
+                new ProducerConfig(ProducerConfig.addSerializerToConfig(props, new StringSerializer(), new StringSerializer())),&lt;br/&gt;
+                new StringSerializer(), new StringSerializer(), metadata, client);&lt;br/&gt;
+&lt;br/&gt;
+        ExecutorService executor = Executors.newSingleThreadExecutor();&lt;br/&gt;
+        final AtomicReference&amp;lt;Exception&amp;gt; sendException = new AtomicReference&amp;lt;&amp;gt;();&lt;br/&gt;
+&lt;br/&gt;
+        try {&lt;br/&gt;
+            executor.submit(() -&amp;gt; {&lt;br/&gt;
+                try &lt;/p&gt;
{
+                    // Metadata for topic &quot;test&quot; will not be available which will cause us to block indefinitely until
+                    // KafkaProducer#close is invoked.
+                    producer.send(new ProducerRecord&amp;lt;&amp;gt;(topicName, &quot;key&quot;, &quot;value&quot;));
+                    fail();
+                }
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
+                    sendException.set(e);
+                }
&lt;p&gt;+            });&lt;br/&gt;
+&lt;br/&gt;
+            // Wait until metadata update for the topic has been requested&lt;br/&gt;
+            TestUtils.waitForCondition(() -&amp;gt; metadata.containsTopic(topicName), &quot;Timeout when waiting for topic to be added to metadata&quot;);&lt;br/&gt;
+            producer.close(0, TimeUnit.MILLISECONDS);&lt;br/&gt;
+            TestUtils.waitForCondition(() -&amp;gt; sendException.get() != null, &quot;No producer exception within timeout&quot;);&lt;br/&gt;
+            assertEquals(KafkaException.class, sendException.get().getClass());&lt;br/&gt;
+        } finally &lt;/p&gt;
{
+            executor.shutdownNow();
+        }
&lt;p&gt;+    }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java b/clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java&lt;br/&gt;
index 27fac280afc..7a8c710b76b 100644&lt;br/&gt;
&amp;#8212; a/clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java&lt;br/&gt;
+++ b/clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java&lt;br/&gt;
@@ -636,16 +636,6 @@ public void shouldThrowOnAbortTransactionIfProducerIsClosed() {&lt;br/&gt;
         } catch (IllegalStateException e) { }&lt;br/&gt;
     }&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test&lt;/li&gt;
	&lt;li&gt;public void shouldThrowOnCloseIfProducerIsClosed() {&lt;/li&gt;
	&lt;li&gt;buildMockProducer(true);&lt;/li&gt;
	&lt;li&gt;producer.close();&lt;/li&gt;
	&lt;li&gt;try 
{
-            producer.close();
-            fail(&quot;Should have thrown as producer is already closed&quot;);
-        }
&lt;p&gt; catch (IllegalStateException e) { }&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;br/&gt;
     @Test&lt;br/&gt;
     public void shouldThrowOnFenceProducerIfProducerIsClosed() {&lt;br/&gt;
         buildMockProducer(true);&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/tools/MirrorMaker.scala b/core/src/main/scala/kafka/tools/MirrorMaker.scala&lt;br/&gt;
index 92396a7bdab..9cc6ebe1c86 100755
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/main/scala/kafka/tools/MirrorMaker.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/tools/MirrorMaker.scala&lt;br/&gt;
@@ -31,7 +31,7 @@ import kafka.utils.
{CommandLineUtils, CoreUtils, Logging, Whitelist}
&lt;p&gt; import org.apache.kafka.clients.consumer.&lt;/p&gt;
{CommitFailedException, Consumer, ConsumerConfig, ConsumerRebalanceListener, ConsumerRecord, KafkaConsumer, OffsetAndMetadata}
&lt;p&gt; import org.apache.kafka.clients.producer.internals.ErrorLoggingCallback&lt;br/&gt;
 import org.apache.kafka.clients.producer.&lt;/p&gt;
{KafkaProducer, ProducerConfig, ProducerRecord, RecordMetadata}
&lt;p&gt;-import org.apache.kafka.common.TopicPartition&lt;br/&gt;
+import org.apache.kafka.common.&lt;/p&gt;
{KafkaException, TopicPartition}
&lt;p&gt; import org.apache.kafka.common.serialization.ByteArrayDeserializer&lt;br/&gt;
 import org.apache.kafka.common.utils.Utils&lt;br/&gt;
 import org.apache.kafka.common.errors.WakeupException&lt;br/&gt;
@@ -357,6 +357,8 @@ object MirrorMaker extends Logging with KafkaMetricsGroup &lt;/p&gt;
{
               trace(&quot;Caught NoRecordsException, continue iteration.&quot;)
             case _: WakeupException =&amp;gt;
               trace(&quot;Caught WakeupException, continue iteration.&quot;)
+            case e: KafkaException if (shuttingDown || exitingOnSendFailure) =&amp;gt;
+              trace(s&quot;Ignoring caught KafkaException during shutdown. sendFailure: $exitingOnSendFailure.&quot;, e)
           }
&lt;p&gt;           maybeFlushAndCommitOffsets()&lt;br/&gt;
         }&lt;br/&gt;
diff --git a/core/src/test/scala/integration/kafka/api/BaseProducerSendTest.scala b/core/src/test/scala/integration/kafka/api/BaseProducerSendTest.scala&lt;br/&gt;
index ee0e90f1807..dc4041f1d63 100644&lt;/p&gt;&lt;/li&gt;
			&lt;li&gt;a/core/src/test/scala/integration/kafka/api/BaseProducerSendTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/integration/kafka/api/BaseProducerSendTest.scala&lt;br/&gt;
@@ -35,6 +35,7 @@ import org.junit.Assert._&lt;br/&gt;
 import org.junit.
{After, Before, Test}&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import scala.collection.mutable.&lt;/p&gt;
{ArrayBuffer, Buffer}
&lt;p&gt;+import scala.concurrent.ExecutionException&lt;/p&gt;

&lt;p&gt; abstract class BaseProducerSendTest extends KafkaServerTestHarness {&lt;/p&gt;

&lt;p&gt;@@ -446,8 +447,7 @@ abstract class BaseProducerSendTest extends KafkaServerTestHarness &lt;/p&gt;
{
           future.get()
           fail(&quot;No message should be sent successfully.&quot;)
         }
&lt;p&gt; catch &lt;/p&gt;
{
-          case e: Exception =&amp;gt;
-            assertEquals(&quot;java.lang.IllegalStateException: Producer is closed forcefully.&quot;, e.getMessage)
+          case e: ExecutionException =&amp;gt; assertEquals(classOf[KafkaException], e.getCause.getClass)
         }
&lt;p&gt;       }&lt;br/&gt;
       assertEquals(&quot;Fetch response should have no message returned.&quot;, 0, consumer.poll(50).count)&lt;br/&gt;
diff --git a/core/src/test/scala/integration/kafka/api/ProducerFailureHandlingTest.scala b/core/src/test/scala/integration/kafka/api/ProducerFailureHandlingTest.scala&lt;br/&gt;
index 7969485d81b..9b77c2d4169 100644&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/integration/kafka/api/ProducerFailureHandlingTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/integration/kafka/api/ProducerFailureHandlingTest.scala&lt;br/&gt;
@@ -205,7 +205,7 @@ class ProducerFailureHandlingTest extends KafkaServerTestHarness {&lt;br/&gt;
     // create topic&lt;br/&gt;
     createTopic(topic1, replicationFactor = numServers)&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val record = new ProducerRecord[Array&lt;span class=&quot;error&quot;&gt;&amp;#91;Byte&amp;#93;&lt;/span&gt;,Array&lt;span class=&quot;error&quot;&gt;&amp;#91;Byte&amp;#93;&lt;/span&gt;](topic1, null, &quot;key&quot;.getBytes, &quot;value&quot;.getBytes)&lt;br/&gt;
+    val record = new ProducerRecord[Array&lt;span class=&quot;error&quot;&gt;&amp;#91;Byte&amp;#93;&lt;/span&gt;, Array&lt;span class=&quot;error&quot;&gt;&amp;#91;Byte&amp;#93;&lt;/span&gt;](topic1, null, &quot;key&quot;.getBytes, &quot;value&quot;.getBytes)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // first send a message to make sure the metadata is refreshed&lt;br/&gt;
     producer1.send(record).get&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12922957" name="mirror_maker_thread_dump.log" size="10878" author="Koelli" created="Fri, 11 May 2018 04:32:17 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 17 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3tlhr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>