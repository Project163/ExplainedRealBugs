<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:01:01 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-5213] IllegalStateException in ensureOpenForRecordAppend</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-5213</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;i have a streams app that was working recently while pointing at trunk. this morning i ran it and now get&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[2017-05-10 14:29:26,266] ERROR stream-thread [_confluent-controlcenter-3-3-0-1-04624550-88f9-4557-a47f-3dfbec3bc3d1-StreamThread-4] Streams application error during processing: {} (org.apache.kafka.streams.processor.internals.StreamThread:518)
java.lang.IllegalStateException: Tried to append a record, but MemoryRecordsBuilder is closed for record appends
	at org.apache.kafka.common.record.MemoryRecordsBuilder.ensureOpenForRecordAppend(MemoryRecordsBuilder.java:607)
	at org.apache.kafka.common.record.MemoryRecordsBuilder.appendLegacyRecord(MemoryRecordsBuilder.java:567)
	at org.apache.kafka.common.record.MemoryRecordsBuilder.appendWithOffset(MemoryRecordsBuilder.java:353)
	at org.apache.kafka.common.record.MemoryRecordsBuilder.appendWithOffset(MemoryRecordsBuilder.java:382)
	at org.apache.kafka.common.record.MemoryRecordsBuilder.append(MemoryRecordsBuilder.java:440)
	at org.apache.kafka.common.record.MemoryRecordsBuilder.append(MemoryRecordsBuilder.java:463)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.tryAppend(ProducerBatch.java:83)
	at org.apache.kafka.clients.producer.internals.RecordAccumulator.tryAppend(RecordAccumulator.java:257)
	at org.apache.kafka.clients.producer.internals.RecordAccumulator.append(RecordAccumulator.java:210)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:645)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:598)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.send(RecordCollectorImpl.java:97)
	at org.apache.kafka.streams.state.internals.StoreChangeLogger.logChange(StoreChangeLogger.java:59)
	at org.apache.kafka.streams.state.internals.ChangeLoggingSegmentedBytesStore.put(ChangeLoggingSegmentedBytesStore.java:55)
	at org.apache.kafka.streams.state.internals.MeteredSegmentedBytesStore.put(MeteredSegmentedBytesStore.java:100)
	at org.apache.kafka.streams.state.internals.RocksDBWindowStore$RocksDBWindowBytesStore.put(RocksDBWindowStore.java:51)
	at org.apache.kafka.streams.state.internals.RocksDBWindowStore$RocksDBWindowBytesStore.put(RocksDBWindowStore.java:42)
	at org.apache.kafka.streams.state.internals.CachingWindowStore$1.apply(CachingWindowStore.java:90)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:145)
	at org.apache.kafka.streams.state.internals.NamedCache.evict(NamedCache.java:239)
	at org.apache.kafka.streams.state.internals.ThreadCache.maybeEvict(ThreadCache.java:214)
	at org.apache.kafka.streams.state.internals.ThreadCache.put(ThreadCache.java:122)
	at org.apache.kafka.streams.state.internals.CachingWindowStore.put(CachingWindowStore.java:143)
	at org.apache.kafka.streams.kstream.internals.KStreamWindowAggregate$KStreamWindowAggregateProcessor.process(KStreamWindowAggregate.java:111)
	at org.apache.kafka.streams.processor.internals.ProcessorNode$1.run(ProcessorNode.java:47)
	at org.apache.kafka.streams.processor.internals.StreamsMetricsImpl.measureLatencyNs(StreamsMetricsImpl.java:187)
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:133)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:82)
	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:69)
	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:175)
	at org.apache.kafka.streams.processor.internals.StreamThread.processAndPunctuate(StreamThread.java:657)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:540)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:511)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13070969">KAFKA-5213</key>
            <summary>IllegalStateException in ensureOpenForRecordAppend</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="apurva">Apurva Mehta</assignee>
                                    <reporter username="norwood">dan norwood</reporter>
                        <labels>
                    </labels>
                <created>Wed, 10 May 2017 21:39:39 +0000</created>
                <updated>Thu, 11 May 2017 01:20:02 +0000</updated>
                            <resolved>Thu, 11 May 2017 01:19:10 +0000</resolved>
                                                    <fixVersion>0.11.0.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="16005525" author="norwood" created="Wed, 10 May 2017 21:57:11 +0000"  >&lt;p&gt;turns out i was running trunk client against 0.10.2.1 brokers. currently rebuilding trunk locally to try all trunk everything.&lt;/p&gt;</comment>
                            <comment id="16005570" author="apurva" created="Wed, 10 May 2017 22:30:03 +0000"  >&lt;p&gt;I found the bug. The problem is that in a particular call to `RecordAccumulator.append`, we do two calls to `ProducerBatch.tryAppend`, with a gap in the middle where the lock is released.&lt;/p&gt;

&lt;p&gt;So it is possible that the first `ProducerBatch.tryAppend` closes the the `MemoryRecordsBuilder` for appends because the incoming record is too large for the batch. But then before we can allocate a new batch, another append comes along with a smaller size and which fits in the current batch. In this case the second append will see this exception. &lt;/p&gt;</comment>
                            <comment id="16005575" author="apurva" created="Wed, 10 May 2017 22:33:57 +0000"  >&lt;p&gt;The fix is to mark the builder as `full` if the append stream is closed. Currently, it is considered &apos;full&apos; once the records are built or if the incoming record is too large.&lt;/p&gt;</comment>
                            <comment id="16005578" author="ijuma" created="Wed, 10 May 2017 22:36:14 +0000"  >&lt;p&gt;Good catch.&lt;/p&gt;</comment>
                            <comment id="16005581" author="githubbot" created="Wed, 10 May 2017 22:37:00 +0000"  >&lt;p&gt;GitHub user apurvam opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/3015&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3015&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5213&quot; title=&quot;IllegalStateException in ensureOpenForRecordAppend&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5213&quot;&gt;&lt;del&gt;KAFKA-5213&lt;/del&gt;&lt;/a&gt;; Mark a MemoryRecordsBuilder as full as soon as the append stream is closed&lt;/p&gt;



&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/apurvam/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apurvam/kafka&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5213&quot; title=&quot;IllegalStateException in ensureOpenForRecordAppend&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5213&quot;&gt;&lt;del&gt;KAFKA-5213&lt;/del&gt;&lt;/a&gt;-illegalstateexception-in-ensureOpenForAppend&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/3015.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3015.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #3015&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 799fd8d3d60e3f8950bbe4b7d5e8865e6755f5aa&lt;br/&gt;
Author: Apurva Mehta &amp;lt;apurva@confluent.io&amp;gt;&lt;br/&gt;
Date:   2017-05-10T22:35:52Z&lt;/p&gt;

&lt;p&gt;    Mark a MemoryRecordsBuilder as full as soon as the append stream is closed&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="16005584" author="apurva" created="Wed, 10 May 2017 22:40:53 +0000"  >&lt;p&gt;This also explains why it wasn&apos;t seen till now: it only occurs when there is a race condition between two appends of very different sizes.&lt;/p&gt;</comment>
                            <comment id="16005651" author="norwood" created="Wed, 10 May 2017 23:25:49 +0000"  >&lt;p&gt;awesome we found a real problem.&lt;/p&gt;

&lt;p&gt;i did run this locally with everything pointed at trunk and i do not see the issue... not sure why that would matter. &lt;/p&gt;</comment>
                            <comment id="16005752" author="hachikuji" created="Thu, 11 May 2017 01:19:10 +0000"  >&lt;p&gt;Issue resolved by pull request 3015&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/pull/3015&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3015&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16005754" author="githubbot" created="Thu, 11 May 2017 01:20:02 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/3015&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3015&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 27 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3esvb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>