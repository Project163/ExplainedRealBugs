<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:36:42 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-654] Irrecoverable error while trying to roll a segment that already exists</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-654</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;I tried setting up a 5 broker 0.8 cluster and sending messages to 100s of topics on it. For a couple of topic partitions, the produce requests never succeed since they fail on the leader with the following error - &lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;2012-12-05 22:54:05,711&amp;#93;&lt;/span&gt; WARN &lt;span class=&quot;error&quot;&gt;&amp;#91;Kafka Log on Broker 2&amp;#93;&lt;/span&gt;, Newly rolled segment file 0000000000000000000&lt;br/&gt;
0.log already exists; deleting it first (kafka.log.Log)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2012-12-05 22:54:05,711&amp;#93;&lt;/span&gt; WARN &lt;span class=&quot;error&quot;&gt;&amp;#91;Kafka Log on Broker 2&amp;#93;&lt;/span&gt;, Newly rolled segment file 0000000000000000000&lt;br/&gt;
0.index already exists; deleting it first (kafka.log.Log)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2012-12-05 22:54:05,715&amp;#93;&lt;/span&gt; ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;ReplicaFetcherThread-1-0-on-broker-2&amp;#93;&lt;/span&gt;, Error due to  (kafka.server.R&lt;br/&gt;
eplicaFetcherThread)&lt;br/&gt;
kafka.common.KafkaException: Trying to roll a new log segment for topic partition NusWriteEvent-4 with start offset 0 while it already exsits&lt;br/&gt;
        at kafka.log.Log.rollToOffset(Log.scala:456)&lt;br/&gt;
        at kafka.log.Log.roll(Log.scala:434)&lt;br/&gt;
        at kafka.log.Log.maybeRoll(Log.scala:423)&lt;br/&gt;
        at kafka.log.Log.append(Log.scala:257)&lt;br/&gt;
        at kafka.server.ReplicaFetcherThread.processPartitionData(ReplicaFetcherThread.scala:51)&lt;br/&gt;
        at kafka.server.AbstractFetcherThread$$anonfun$doWork$5.apply(AbstractFetcherThread.scala:125)&lt;br/&gt;
        at kafka.server.AbstractFetcherThread$$anonfun$doWork$5.apply(AbstractFetcherThread.scala:108)&lt;br/&gt;
        at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:125)&lt;br/&gt;
        at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:344)&lt;br/&gt;
        at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:344)&lt;br/&gt;
        at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:108)&lt;br/&gt;
        at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:50)&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12618991">KAFKA-654</key>
            <summary>Irrecoverable error while trying to roll a segment that already exists</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="nehanarkhede">Neha Narkhede</assignee>
                                    <reporter username="nehanarkhede">Neha Narkhede</reporter>
                        <labels>
                    </labels>
                <created>Thu, 6 Dec 2012 06:19:04 +0000</created>
                <updated>Tue, 19 Dec 2017 23:43:16 +0000</updated>
                            <resolved>Mon, 10 Dec 2012 18:24:00 +0000</resolved>
                                    <version>0.8.0</version>
                                                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="13511579" author="jjkoshy" created="Thu, 6 Dec 2012 18:17:22 +0000"  >&lt;p&gt;FWIW, it should be easy to reproduce this - I just saw it on a two node cluster / one topic but am looking at another issue right now.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;2012-12-06 10:10:18,380&amp;#93;&lt;/span&gt; ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;ReplicaFetcherThread-0-0-on-broker-1&amp;#93;&lt;/span&gt;, Error due to  (kafka.server.ReplicaFetcherThread)&lt;br/&gt;
kafka.common.KafkaException: Trying to roll a new log segment for topic partition abc-0 with start offset 0 while it already exsits&lt;br/&gt;
        at kafka.log.Log.rollToOffset(Log.scala:456)&lt;br/&gt;
        at kafka.log.Log.roll(Log.scala:434)&lt;br/&gt;
        at kafka.log.Log.maybeRoll(Log.scala:423)&lt;br/&gt;
        at kafka.log.Log.append(Log.scala:257)&lt;br/&gt;
        at kafka.server.ReplicaFetcherThread.processPartitionData(ReplicaFetcherThread.scala:51)&lt;br/&gt;
        at kafka.server.AbstractFetcherThread$$anonfun$doWork$5.apply(AbstractFetcherThread.scala:125)&lt;br/&gt;
        at kafka.server.AbstractFetcherThread$$anonfun$doWork$5.apply(AbstractFetcherThread.scala:108)&lt;br/&gt;
        at scala.collection.immutable.Map$Map1.foreach(Map.scala:105)&lt;br/&gt;
        at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:108)&lt;br/&gt;
        at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:50)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2012-12-06 10:10:18,382&amp;#93;&lt;/span&gt; INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;ReplicaFetcherThread-0-0-on-broker-1&amp;#93;&lt;/span&gt;, Stopped  (kafka.server.ReplicaFetcherThread)&lt;/p&gt;</comment>
                            <comment id="13511601" author="jkreps" created="Thu, 6 Dec 2012 18:37:01 +0000"  >&lt;p&gt;I think this is almost certainly a bug in the log. I will come by and discuss.&lt;/p&gt;</comment>
                            <comment id="13512081" author="nehanarkhede" created="Thu, 6 Dec 2012 20:31:54 +0000"  >&lt;p&gt;The bug is inside Log.truncateAndStartWithNewOffset&lt;/p&gt;

&lt;p&gt;      val deletedSegments = segments.trunc(segments.view.size)&lt;br/&gt;
      segments.append(new LogSegment(dir,&lt;br/&gt;
                                     newOffset,&lt;br/&gt;
                                     indexIntervalBytes = indexIntervalBytes, &lt;br/&gt;
                                     maxIndexSize = maxIndexSize))&lt;br/&gt;
      deleteSegments(deletedSegments)&lt;/p&gt;

&lt;p&gt;The order of deleteSegments and segments.append is reversed. Due to this, we end up adding an already full index as the last entry in the segments array, but delete it later from disk. During maybeRoll, it finds the index to be full and errors on the rolling of the new log segment.&lt;/p&gt;

&lt;p&gt;However, in my testing, I saw this on the leader as well. I&apos;ve not been able to fix that yet.&lt;/p&gt;</comment>
                            <comment id="13527603" author="nehanarkhede" created="Sun, 9 Dec 2012 20:00:47 +0000"  >&lt;p&gt;Patch to fix the problem on the follower as explained above. However, I couldn&apos;t reproduce this issue on the leader. I guess we can file another JIRA if we are able to find that issue again&lt;/p&gt;</comment>
                            <comment id="13528087" author="jkreps" created="Mon, 10 Dec 2012 17:34:56 +0000"  >&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;I had fixed this on trunk:&lt;br/&gt;
&lt;a href=&quot;http://svn.apache.org/repos/asf/kafka/trunk/core/src/main/scala/kafka/log/Log.scala&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/repos/asf/kafka/trunk/core/src/main/scala/kafka/log/Log.scala&lt;/a&gt;&lt;br/&gt;
Double checked that it didn&apos;t get reintroduced in the async delete patch:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12559981/KAFKA-636-v1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12559981/KAFKA-636-v1.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So it looks like it was only on 0.8.&lt;/p&gt;</comment>
                            <comment id="13528129" author="nehanarkhede" created="Mon, 10 Dec 2012 18:24:00 +0000"  >&lt;p&gt;Thanks for the review, committed patch v1 to 0.8 branch.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10020">
                    <name>Cloners</name>
                                                                <inwardlinks description="is cloned by">
                                        <issuelink>
            <issuekey id="13126066">KAFKA-6388</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12560116" name="kafka-654-v1.patch" size="955" author="nehanarkhede" created="Sun, 9 Dec 2012 20:00:47 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>296279</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            12 years, 50 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1486n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>232789</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>