<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:07:10 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6578] Connect distributed and standalone worker &apos;main()&apos; methods should catch and log all exceptions</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6578</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Currently, the &lt;tt&gt;main&lt;/tt&gt; methods in &lt;tt&gt;ConnectDistributed&lt;/tt&gt; and &lt;tt&gt;ConnectStandalone&lt;/tt&gt; do not catch and log most of the potential exceptions. That means that when such an exception does occur, Java does terminate the process and report it to stderr, but does not log the exception in the log.&lt;/p&gt;

&lt;p&gt;We should add a try block around most of the existing code in the main method to catch any Throwable exception, log it, and either rethrow it or explicitly exit with a non-zero return code.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13140011">KAFKA-6578</key>
            <summary>Connect distributed and standalone worker &apos;main()&apos; methods should catch and log all exceptions</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="rhauch">Randall Hauch</reporter>
                        <labels>
                    </labels>
                <created>Wed, 21 Feb 2018 20:47:45 +0000</created>
                <updated>Fri, 23 Feb 2018 06:34:17 +0000</updated>
                            <resolved>Fri, 23 Feb 2018 06:34:17 +0000</resolved>
                                    <version>0.10.0.0</version>
                                    <fixVersion>1.1.0</fixVersion>
                                    <component>connect</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="16372221" author="githubbot" created="Wed, 21 Feb 2018 23:41:33 +0000"  >&lt;p&gt;rhauch opened a new pull request #4609: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6578&quot; title=&quot;Connect distributed and standalone worker &amp;#39;main()&amp;#39; methods should catch and log all exceptions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6578&quot;&gt;&lt;del&gt;KAFKA-6578&lt;/del&gt;&lt;/a&gt;: Changed the Connect distributed and standalone main method to log all exceptions&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4609&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4609&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Any exception thrown by calls within a `main()` method are not logged unless explicitly done so. This change simply adds a try-catch block around most of the content of the distributed and standalone `main()` methods.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16373981" author="githubbot" created="Fri, 23 Feb 2018 06:29:52 +0000"  >&lt;p&gt;hachikuji closed pull request #4609: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6578&quot; title=&quot;Connect distributed and standalone worker &amp;#39;main()&amp;#39; methods should catch and log all exceptions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6578&quot;&gt;&lt;del&gt;KAFKA-6578&lt;/del&gt;&lt;/a&gt;: Changed the Connect distributed and standalone main method to log all exceptions&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4609&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4609&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java b/connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java&lt;br/&gt;
index 3b7ec87f644..54854fe4b80 100644&lt;br/&gt;
&amp;#8212; a/connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java&lt;br/&gt;
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java&lt;br/&gt;
@@ -58,52 +58,59 @@ public static void main(String[] args) throws Exception &lt;/p&gt;
{
             Exit.exit(1);
         }&lt;br/&gt;
 &lt;br/&gt;
-        Time time = Time.SYSTEM;&lt;br/&gt;
-        log.info(&quot;Kafka Connect distributed worker initializing ...&quot;);&lt;br/&gt;
-        long initStart = time.hiResClockMs();&lt;br/&gt;
-        WorkerInfo initInfo = new WorkerInfo();&lt;br/&gt;
-        initInfo.logAll();&lt;br/&gt;
+        try {&lt;br/&gt;
+            Time time = Time.SYSTEM;&lt;br/&gt;
+            log.info(&quot;Kafka Connect distributed worker initializing ...&quot;);&lt;br/&gt;
+            long initStart = time.hiResClockMs();&lt;br/&gt;
+            WorkerInfo initInfo = new WorkerInfo();&lt;br/&gt;
+            initInfo.logAll();&lt;br/&gt;
 &lt;br/&gt;
-        String workerPropsFile = args&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;;&lt;br/&gt;
-        Map&amp;lt;String, String&amp;gt; workerProps = !workerPropsFile.isEmpty() ?&lt;br/&gt;
-                Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.&amp;lt;String, String&amp;gt;emptyMap();&lt;br/&gt;
+            String workerPropsFile = args&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;;&lt;br/&gt;
+            Map&amp;lt;String, String&amp;gt; workerProps = !workerPropsFile.isEmpty() ?&lt;br/&gt;
+                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.&amp;lt;String, String&amp;gt;emptyMap();&lt;br/&gt;
 &lt;br/&gt;
-        log.info(&quot;Scanning for plugin classes. This might take a moment ...&quot;);&lt;br/&gt;
-        Plugins plugins = new Plugins(workerProps);&lt;br/&gt;
-        plugins.compareAndSwapWithDelegatingLoader();&lt;br/&gt;
-        DistributedConfig config = new DistributedConfig(workerProps);&lt;br/&gt;
+            log.info(&quot;Scanning for plugin classes. This might take a moment ...&quot;);&lt;br/&gt;
+            Plugins plugins = new Plugins(workerProps);&lt;br/&gt;
+            plugins.compareAndSwapWithDelegatingLoader();&lt;br/&gt;
+            DistributedConfig config = new DistributedConfig(workerProps);&lt;br/&gt;
 &lt;br/&gt;
-        String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);&lt;br/&gt;
-        log.debug(&quot;Kafka cluster ID: {}&quot;, kafkaClusterId);&lt;br/&gt;
+            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);&lt;br/&gt;
+            log.debug(&quot;Kafka cluster ID: {}&quot;, kafkaClusterId);&lt;br/&gt;
 &lt;br/&gt;
-        RestServer rest = new RestServer(config);&lt;br/&gt;
-        URI advertisedUrl = rest.advertisedUrl();&lt;br/&gt;
-        String workerId = advertisedUrl.getHost() + &quot;:&quot; + advertisedUrl.getPort();&lt;br/&gt;
+            RestServer rest = new RestServer(config);&lt;br/&gt;
+            URI advertisedUrl = rest.advertisedUrl();&lt;br/&gt;
+            String workerId = advertisedUrl.getHost() + &quot;:&quot; + advertisedUrl.getPort();&lt;br/&gt;
 &lt;br/&gt;
-        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();&lt;br/&gt;
-        offsetBackingStore.configure(config);&lt;br/&gt;
+            KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();&lt;br/&gt;
+            offsetBackingStore.configure(config);&lt;br/&gt;
 &lt;br/&gt;
-        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore);&lt;br/&gt;
+            Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore);&lt;br/&gt;
 &lt;br/&gt;
-        Converter internalValueConverter = worker.getInternalValueConverter();&lt;br/&gt;
-        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter);&lt;br/&gt;
-        statusBackingStore.configure(config);&lt;br/&gt;
+            Converter internalValueConverter = worker.getInternalValueConverter();&lt;br/&gt;
+            StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter);&lt;br/&gt;
+            statusBackingStore.configure(config);&lt;br/&gt;
 &lt;br/&gt;
-        ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(internalValueConverter, config);&lt;br/&gt;
+            ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(internalValueConverter, config);&lt;br/&gt;
 &lt;br/&gt;
-        DistributedHerder herder = new DistributedHerder(config, time, worker,&lt;br/&gt;
-                kafkaClusterId, statusBackingStore, configBackingStore,&lt;br/&gt;
-                advertisedUrl.toString());&lt;br/&gt;
-        final Connect connect = new Connect(herder, rest);&lt;br/&gt;
-        log.info(&quot;Kafka Connect distributed worker initialization took {}ms&quot;, time.hiResClockMs() - initStart);&lt;br/&gt;
-        try {
-            connect.start();
-        } catch (Exception e) {
-            log.error(&quot;Failed to start Connect&quot;, e);
-            connect.stop();
-        }&lt;br/&gt;
+            DistributedHerder herder = new DistributedHerder(config, time, worker,&lt;br/&gt;
+                    kafkaClusterId, statusBackingStore, configBackingStore,&lt;br/&gt;
+                    advertisedUrl.toString());&lt;br/&gt;
+            final Connect connect = new Connect(herder, rest);&lt;br/&gt;
+            log.info(&quot;Kafka Connect distributed worker initialization took {}ms&quot;, time.hiResClockMs() - initStart);&lt;br/&gt;
+            try {
+                connect.start();
+            } catch (Exception e) {
+                log.error(&quot;Failed to start Connect&quot;, e);
+                connect.stop();
+                Exit.exit(3);
+            }&lt;br/&gt;
 &lt;br/&gt;
-        // Shutdown will be triggered by Ctrl-C or via HTTP shutdown request&lt;br/&gt;
-        connect.awaitStop();&lt;br/&gt;
+            // Shutdown will be triggered by Ctrl-C or via HTTP shutdown request&lt;br/&gt;
+            connect.awaitStop();&lt;br/&gt;
+&lt;br/&gt;
+        } catch (Throwable t) {
+            log.error(&quot;Stopping due to error&quot;, t);
+            Exit.exit(2);
+        }&lt;br/&gt;
     }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java b/connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java&lt;br/&gt;
index 413cb46cf28..aba9d9c32aa 100644&lt;br/&gt;
&amp;#8212; a/connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java&lt;br/&gt;
+++ b/connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java&lt;br/&gt;
@@ -62,58 +62,65 @@ public static void main(String[] args) throws Exception {             Exit.exit(1);         }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Time time = Time.SYSTEM;&lt;/li&gt;
	&lt;li&gt;log.info(&quot;Kafka Connect standalone worker initializing ...&quot;);&lt;/li&gt;
	&lt;li&gt;long initStart = time.hiResClockMs();&lt;/li&gt;
	&lt;li&gt;WorkerInfo initInfo = new WorkerInfo();&lt;/li&gt;
	&lt;li&gt;initInfo.logAll();&lt;br/&gt;
+        try {&lt;br/&gt;
+            Time time = Time.SYSTEM;&lt;br/&gt;
+            log.info(&quot;Kafka Connect standalone worker initializing ...&quot;);&lt;br/&gt;
+            long initStart = time.hiResClockMs();&lt;br/&gt;
+            WorkerInfo initInfo = new WorkerInfo();&lt;br/&gt;
+            initInfo.logAll();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;String workerPropsFile = args&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;;&lt;/li&gt;
	&lt;li&gt;Map&amp;lt;String, String&amp;gt; workerProps = !workerPropsFile.isEmpty() ?&lt;/li&gt;
	&lt;li&gt;Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.&amp;lt;String, String&amp;gt;emptyMap();&lt;br/&gt;
+            String workerPropsFile = args&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;;&lt;br/&gt;
+            Map&amp;lt;String, String&amp;gt; workerProps = !workerPropsFile.isEmpty() ?&lt;br/&gt;
+                    Utils.propsToStringMap(Utils.loadProps(workerPropsFile)) : Collections.&amp;lt;String, String&amp;gt;emptyMap();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;log.info(&quot;Scanning for plugin classes. This might take a moment ...&quot;);&lt;/li&gt;
	&lt;li&gt;Plugins plugins = new Plugins(workerProps);&lt;/li&gt;
	&lt;li&gt;plugins.compareAndSwapWithDelegatingLoader();&lt;/li&gt;
	&lt;li&gt;StandaloneConfig config = new StandaloneConfig(workerProps);&lt;br/&gt;
+            log.info(&quot;Scanning for plugin classes. This might take a moment ...&quot;);&lt;br/&gt;
+            Plugins plugins = new Plugins(workerProps);&lt;br/&gt;
+            plugins.compareAndSwapWithDelegatingLoader();&lt;br/&gt;
+            StandaloneConfig config = new StandaloneConfig(workerProps);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);&lt;/li&gt;
	&lt;li&gt;log.debug(&quot;Kafka cluster ID: {}&quot;, kafkaClusterId);&lt;br/&gt;
+            String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(config);&lt;br/&gt;
+            log.debug(&quot;Kafka cluster ID: {}&quot;, kafkaClusterId);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;RestServer rest = new RestServer(config);&lt;/li&gt;
	&lt;li&gt;URI advertisedUrl = rest.advertisedUrl();&lt;/li&gt;
	&lt;li&gt;String workerId = advertisedUrl.getHost() + &quot;:&quot; + advertisedUrl.getPort();&lt;br/&gt;
+            RestServer rest = new RestServer(config);&lt;br/&gt;
+            URI advertisedUrl = rest.advertisedUrl();&lt;br/&gt;
+            String workerId = advertisedUrl.getHost() + &quot;:&quot; + advertisedUrl.getPort();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());&lt;br/&gt;
+            Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore());&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Herder herder = new StandaloneHerder(worker, kafkaClusterId);&lt;/li&gt;
	&lt;li&gt;final Connect connect = new Connect(herder, rest);&lt;/li&gt;
	&lt;li&gt;log.info(&quot;Kafka Connect standalone worker initialization took {}ms&quot;, time.hiResClockMs() - initStart);&lt;br/&gt;
+            Herder herder = new StandaloneHerder(worker, kafkaClusterId);&lt;br/&gt;
+            final Connect connect = new Connect(herder, rest);&lt;br/&gt;
+            log.info(&quot;Kafka Connect standalone worker initialization took {}ms&quot;, time.hiResClockMs() - initStart);&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;try {&lt;/li&gt;
	&lt;li&gt;connect.start();&lt;/li&gt;
	&lt;li&gt;for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {&lt;/li&gt;
	&lt;li&gt;Map&amp;lt;String, String&amp;gt; connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));&lt;/li&gt;
	&lt;li&gt;FutureCallback&amp;lt;Herder.Created&amp;lt;ConnectorInfo&amp;gt;&amp;gt; cb = new FutureCallback&amp;lt;&amp;gt;(new Callback&amp;lt;Herder.Created&amp;lt;ConnectorInfo&amp;gt;&amp;gt;() {&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void onCompletion(Throwable error, Herder.Created&amp;lt;ConnectorInfo&amp;gt; info) {&lt;/li&gt;
	&lt;li&gt;if (error != null)&lt;/li&gt;
	&lt;li&gt;log.error(&quot;Failed to create job for {}&quot;, connectorPropsFile);&lt;/li&gt;
	&lt;li&gt;else&lt;/li&gt;
	&lt;li&gt;log.info(&quot;Created connector {}&quot;, info.result().name());&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;});&lt;/li&gt;
	&lt;li&gt;herder.putConnectorConfig(&lt;/li&gt;
	&lt;li&gt;connectorProps.get(ConnectorConfig.NAME_CONFIG),&lt;/li&gt;
	&lt;li&gt;connectorProps, false, cb);&lt;/li&gt;
	&lt;li&gt;cb.get();&lt;br/&gt;
+            try {&lt;br/&gt;
+                connect.start();&lt;br/&gt;
+                for (final String connectorPropsFile : Arrays.copyOfRange(args, 1, args.length)) {&lt;br/&gt;
+                    Map&amp;lt;String, String&amp;gt; connectorProps = Utils.propsToStringMap(Utils.loadProps(connectorPropsFile));&lt;br/&gt;
+                    FutureCallback&amp;lt;Herder.Created&amp;lt;ConnectorInfo&amp;gt;&amp;gt; cb = new FutureCallback&amp;lt;&amp;gt;(new Callback&amp;lt;Herder.Created&amp;lt;ConnectorInfo&amp;gt;&amp;gt;() {&lt;br/&gt;
+                        @Override&lt;br/&gt;
+                        public void onCompletion(Throwable error, Herder.Created&amp;lt;ConnectorInfo&amp;gt; info) {&lt;br/&gt;
+                            if (error != null)&lt;br/&gt;
+                                log.error(&quot;Failed to create job for {}&quot;, connectorPropsFile);&lt;br/&gt;
+                            else&lt;br/&gt;
+                                log.info(&quot;Created connector {}&quot;, info.result().name());&lt;br/&gt;
+                        }&lt;br/&gt;
+                    });&lt;br/&gt;
+                    herder.putConnectorConfig(&lt;br/&gt;
+                            connectorProps.get(ConnectorConfig.NAME_CONFIG),&lt;br/&gt;
+                            connectorProps, false, cb);&lt;br/&gt;
+                    cb.get();&lt;br/&gt;
+                }&lt;br/&gt;
+            } catch (Throwable t) 
{
+                log.error(&quot;Stopping after connector error&quot;, t);
+                connect.stop();
+                Exit.exit(3);
             }
&lt;p&gt;+&lt;br/&gt;
+            // Shutdown will be triggered by Ctrl-C or via HTTP shutdown request&lt;br/&gt;
+            connect.awaitStop();&lt;br/&gt;
+&lt;br/&gt;
         } catch (Throwable t) &lt;/p&gt;
{
-            log.error(&quot;Stopping after connector error&quot;, t);
-            connect.stop();
+            log.error(&quot;Stopping due to error&quot;, t);
+            Exit.exit(2);
         }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;// Shutdown will be triggered by Ctrl-C or via HTTP shutdown request&lt;/li&gt;
	&lt;li&gt;connect.awaitStop();&lt;br/&gt;
     }&lt;br/&gt;
 }&lt;/li&gt;
&lt;/ul&gt;





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13140009">KAFKA-6577</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 38 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3qftr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>