<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:53:48 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-3594] Kafka new producer retries doesn&apos;t work in 0.9.0.1</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-3594</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;I&apos;m encountering an issue with the new Producer on 0.9.0.1 client with a 0.9.0.1 Kafka broker when Kafka broker are offline for example. It seems the retries doesn&apos;t work anymore and I got the following error logs :&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;play.api.Application$$anon$1: Execution exception[[IllegalStateException: Memory records is not writable]]
        at play.api.Application$class.handleError(Application.scala:296) ~[com.typesafe.play.play_2.11-2.3.10.jar:2.3.10]
        at play.api.DefaultApplication.handleError(Application.scala:402) [com.typesafe.play.play_2.11-2.3.10.jar:2.3.10]
        at play.core.server.netty.PlayDefaultUpstreamHandler$$anonfun$3$$anonfun$applyOrElse$4.apply(PlayDefaultUpstreamHandler.scala:320) [com.typesafe.play.play_2.11-2.3.10.jar:2.3.10]
        at play.core.server.netty.PlayDefaultUpstreamHandler$$anonfun$3$$anonfun$applyOrElse$4.apply(PlayDefaultUpstreamHandler.scala:320) [com.typesafe.play.play_2.11-2.3.10.jar:2.3.10]
        at scala.Option.map(Option.scala:146) [org.scala-lang.scala-library-2.11.8.jar:na]
        at play.core.server.netty.PlayDefaultUpstreamHandler$$anonfun$3.applyOrElse(PlayDefaultUpstreamHandler.scala:320) [com.typesafe.play.play_2.11-2.3.10.jar:2.3.10]
        at play.core.server.netty.PlayDefaultUpstreamHandler$$anonfun$3.applyOrElse(PlayDefaultUpstreamHandler.scala:316) [com.typesafe.play.play_2.11-2.3.10.jar:2.3.10]
        at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346) [org.scala-lang.scala-library-2.11.8.jar:na]
        at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345) [org.scala-lang.scala-library-2.11.8.jar:na]
        at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32) [org.scala-lang.scala-library-2.11.8.jar:na]
        at play.api.libs.iteratee.Execution$trampoline$.execute(Execution.scala:46) [com.typesafe.play.play-iteratees_2.11-2.3.10.jar:2.3.10]
        at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40) [org.scala-lang.scala-library-2.11.8.jar:na]
        at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248) [org.scala-lang.scala-library-2.11.8.jar:na]
        at scala.concurrent.Promise$class.complete(Promise.scala:55) [org.scala-lang.scala-library-2.11.8.jar:na]
        at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153) [org.scala-lang.scala-library-2.11.8.jar:na]
        at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237) [org.scala-lang.scala-library-2.11.8.jar:na]
        at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237) [org.scala-lang.scala-library-2.11.8.jar:na]
        at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32) [org.scala-lang.scala-library-2.11.8.jar:na]
        at akka.dispatch.BatchingExecutor$Batch$$anonfun$run$1.processBatch$1(BatchingExecutor.scala:67) [com.typesafe.akka.akka-actor_2.11-2.3.4.jar:na]
        at akka.dispatch.BatchingExecutor$Batch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:82) [com.typesafe.akka.akka-actor_2.11-2.3.4.jar:na]
        at akka.dispatch.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:59) [com.typesafe.akka.akka-actor_2.11-2.3.4.jar:na]
        at akka.dispatch.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:59) [com.typesafe.akka.akka-actor_2.11-2.3.4.jar:na]
        at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72) [org.scala-lang.scala-library-2.11.8.jar:na]
        at akka.dispatch.BatchingExecutor$Batch.run(BatchingExecutor.scala:58) [com.typesafe.akka.akka-actor_2.11-2.3.4.jar:na]
        at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41) [com.typesafe.akka.akka-actor_2.11-2.3.4.jar:na]
        at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393) [com.typesafe.akka.akka-actor_2.11-2.3.4.jar:na]
        at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [org.scala-lang.scala-library-2.11.8.jar:na]
        at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [org.scala-lang.scala-library-2.11.8.jar:na]
        at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [org.scala-lang.scala-library-2.11.8.jar:na]
        at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [org.scala-lang.scala-library-2.11.8.jar:na]
Caused by: java.lang.IllegalStateException: Memory records is not writable
        at org.apache.kafka.common.record.MemoryRecords.append(MemoryRecords.java:93) ~[org.apache.kafka.kafka-clients-0.9.0.1-cp1.jar:na]
        at org.apache.kafka.clients.producer.internals.RecordBatch.tryAppend(RecordBatch.java:69) ~[org.apache.kafka.kafka-clients-0.9.0.1-cp1.jar:na]
        at org.apache.kafka.clients.producer.internals.RecordAccumulator.append(RecordAccumulator.java:168) ~[org.apache.kafka.kafka-clients-0.9.0.1-cp1.jar:na]
        at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:435) ~[org.apache.kafka.kafka-clients-0.9.0.1-cp1.jar:na]
        at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:339) ~[org.apache.kafka.kafka-clients-0.9.0.1-cp1.jar:na]
        at services.KafkaProducerService.sendToKafka(KafkaProducerService.scala:136) ~[fr.figarocms.tracker-fca-nextgen-2.58.jar:2.58]
        at services.KafkaProducerService$$anonfun$send$1.apply(KafkaProducerService.scala:55) ~[fr.figarocms.tracker-fca-nextgen-2.58.jar:2.58]
        at services.KafkaProducerService$$anonfun$send$1.apply(KafkaProducerService.scala:55) ~[fr.figarocms.tracker-fca-nextgen-2.58.jar:2.58]
        at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33) ~[org.scala-lang.scala-library-2.11.8.jar:na]
        at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35) ~[org.scala-lang.scala-library-2.11.8.jar:na]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We tried the same various breakdown (kafka(s), zookeeper) with 0.8.2.2 client and Kafka broker 0.8.2.2 and the retries work as expected on the older version. &lt;/p&gt;

&lt;p&gt;We tested this with 3 brokers with a replication factor 3 and in sync replica 2. The error log appear when we got only one broker left here on 0.9.0.1. Can this be related to &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3147&quot; title=&quot;Memory records is not writable in MirrorMaker&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3147&quot;&gt;&lt;del&gt;KAFKA-3147&lt;/del&gt;&lt;/a&gt; fix ?&lt;/p&gt;

&lt;p&gt;Regards,&lt;br/&gt;
Nicolas PHUNG&lt;/p&gt;</description>
                <environment>Debian 7.8 Wheezy / Kafka 0.9.0.1 (Confluent 2.0.1)</environment>
        <key id="12960477">KAFKA-3594</key>
            <summary>Kafka new producer retries doesn&apos;t work in 0.9.0.1</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="omkreddy">Manikumar</assignee>
                                    <reporter username="nphung">Nicolas PHUNG</reporter>
                        <labels>
                            <label>kafka</label>
                            <label>new</label>
                            <label>producer</label>
                            <label>replication</label>
                            <label>retry</label>
                    </labels>
                <created>Wed, 20 Apr 2016 20:45:04 +0000</created>
                <updated>Wed, 19 Apr 2017 14:54:27 +0000</updated>
                            <resolved>Thu, 21 Apr 2016 22:13:40 +0000</resolved>
                                    <version>0.9.0.1</version>
                                    <fixVersion>0.9.0.2</fixVersion>
                    <fixVersion>0.10.0.0</fixVersion>
                                    <component>producer </component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>12</watches>
                                                                                                                <comments>
                            <comment id="15251692" author="omkreddy" created="Thu, 21 Apr 2016 10:42:49 +0000"  >&lt;p&gt;Thanks for reporting this. I reproduced the error by creating producer retry scenario. &lt;br/&gt;
Below exception is occurring when producer is trying to append a record to a Re-enqueued record batch in the accumulator.  We should not allow to add a record to Re-enqueued record batch. This is happening due a bug in MemoryRecords.java/hasRooFor() method. After calling MemoryRecords.close() method, hasRooFor() method should return false. I will submit patch soon.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;java.lang.IllegalStateException: Memory records is not writable
	at org.apache.kafka.common.record.MemoryRecords.append(MemoryRecords.java:95)
	at org.apache.kafka.clients.producer.internals.RecordBatch.tryAppend(RecordBatch.java:70)
	at org.apache.kafka.clients.producer.internals.RecordAccumulator.append(RecordAccumulator.java:176)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:467)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:430)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15251696" author="githubbot" created="Thu, 21 Apr 2016 10:47:18 +0000"  >&lt;p&gt;GitHub user omkreddy opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1249&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1249&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3594&quot; title=&quot;Kafka new producer retries doesn&amp;#39;t work in 0.9.0.1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3594&quot;&gt;&lt;del&gt;KAFKA-3594&lt;/del&gt;&lt;/a&gt;; After calling MemoryRecords.close() method, hasRooFor() method should return false&lt;/p&gt;

&lt;p&gt;    This exception is occurring when producer is trying to append a record to a Re-enqueued record batch in the accumulator. We should not allow to add a record to Re-enqueued record batch. This is due a bug in MemoryRecords.java/hasRooFor() method. After calling MemoryRecords.close() method, hasRooFor() method should return false. &lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/omkreddy/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/omkreddy/kafka&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3594&quot; title=&quot;Kafka new producer retries doesn&amp;#39;t work in 0.9.0.1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3594&quot;&gt;&lt;del&gt;KAFKA-3594&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1249.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1249.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #1249&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 3f018abf2b7b570e220ffab285863eb4b8a55326&lt;br/&gt;
Author: Manikumar reddy O &amp;lt;manikumar.reddy@gmail.com&amp;gt;&lt;br/&gt;
Date:   2016-04-21T10:24:59Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3594&quot; title=&quot;Kafka new producer retries doesn&amp;#39;t work in 0.9.0.1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3594&quot;&gt;&lt;del&gt;KAFKA-3594&lt;/del&gt;&lt;/a&gt;; After calling MemoryRecords.close() method, hasRooFor() method should return false&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15252082" author="githubbot" created="Thu, 21 Apr 2016 15:48:43 +0000"  >&lt;p&gt;Github user omkreddy closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1249&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1249&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15252099" author="githubbot" created="Thu, 21 Apr 2016 15:57:54 +0000"  >&lt;p&gt;GitHub user omkreddy reopened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1249&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1249&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3594&quot; title=&quot;Kafka new producer retries doesn&amp;#39;t work in 0.9.0.1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3594&quot;&gt;&lt;del&gt;KAFKA-3594&lt;/del&gt;&lt;/a&gt;; After calling MemoryRecords.close() method, hasRoomFor() method should return false&lt;/p&gt;

&lt;p&gt;    This exception is occurring when producer is trying to append a record to a Re-enqueued record batch in the accumulator. We should not allow to add a record to Re-enqueued record batch. This is due a bug in MemoryRecords.java/hasRoomFor() method. After calling MemoryRecords.close() method, hasRoomFor() method should return false. &lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/omkreddy/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/omkreddy/kafka&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3594&quot; title=&quot;Kafka new producer retries doesn&amp;#39;t work in 0.9.0.1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3594&quot;&gt;&lt;del&gt;KAFKA-3594&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1249.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1249.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #1249&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 294a604114a02414887529d9b9025e11a527344a&lt;br/&gt;
Author: Manikumar reddy O &amp;lt;manikumar.reddy@gmail.com&amp;gt;&lt;br/&gt;
Date:   2016-04-21T10:24:59Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3594&quot; title=&quot;Kafka new producer retries doesn&amp;#39;t work in 0.9.0.1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3594&quot;&gt;&lt;del&gt;KAFKA-3594&lt;/del&gt;&lt;/a&gt;; After calling MemoryRecords.close() method, hasRooFor() method should return false&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15252865" author="guozhang" created="Thu, 21 Apr 2016 22:13:40 +0000"  >&lt;p&gt;Issue resolved by pull request 1249&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/pull/1249&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1249&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15252866" author="githubbot" created="Thu, 21 Apr 2016 22:13:54 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1249&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1249&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15324104" author="pnovotnik_szn" created="Fri, 10 Jun 2016 09:00:49 +0000"  >&lt;p&gt;Any chance for this to be back ported to a 0.9.0.x release?&lt;/p&gt;</comment>
                            <comment id="15347386" author="githubbot" created="Thu, 23 Jun 2016 23:02:05 +0000"  >&lt;p&gt;GitHub user ijuma opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1547&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1547&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3594&quot; title=&quot;Kafka new producer retries doesn&amp;#39;t work in 0.9.0.1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3594&quot;&gt;&lt;del&gt;KAFKA-3594&lt;/del&gt;&lt;/a&gt;; After calling MemoryRecords.close() method, hasRoomFor() method should return false&lt;/p&gt;

&lt;p&gt;    This exception is occurring when producer is trying to append a record to a Re-enqueued record batch in the accumulator. We should not allow to add a record to Re-enqueued record batch. This is due a bug in MemoryRecords.java/hasRoomFor() method. After calling MemoryRecords.close() method, hasRoomFor() method should return false.&lt;/p&gt;

&lt;p&gt;    This is a backport to the 0.9.0 branch.&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/ijuma/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/ijuma/kafka&lt;/a&gt; kafka-3594-for-0.9.0&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1547.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1547.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #1547&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 3e3e8a28d88f5d191bbdc0c35f086a925bc8c512&lt;br/&gt;
Author: Manikumar reddy O &amp;lt;manikumar.reddy@gmail.com&amp;gt;&lt;br/&gt;
Date:   2016-04-21T22:13:25Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3594&quot; title=&quot;Kafka new producer retries doesn&amp;#39;t work in 0.9.0.1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3594&quot;&gt;&lt;del&gt;KAFKA-3594&lt;/del&gt;&lt;/a&gt;; After calling MemoryRecords.close() method, hasRoomFor() method should return false&lt;/p&gt;

&lt;p&gt;    This exception is occurring when producer is trying to append a record to a Re-enqueued record batch in the accumulator. We should not allow to add a record to Re-enqueued record batch. This is due a bug in MemoryRecords.java/hasRoomFor() method. After calling MemoryRecords.close() method, hasRoomFor() method should return false.&lt;/p&gt;

&lt;p&gt;    Author: Manikumar reddy O &amp;lt;manikumar.reddy@gmail.com&amp;gt;&lt;/p&gt;

&lt;p&gt;    Reviewers: Ismael Juma, Grant Henke, Guozhang Wang&lt;/p&gt;

&lt;p&gt;    Closes #1249 from omkreddy/&lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3594&quot; title=&quot;Kafka new producer retries doesn&amp;#39;t work in 0.9.0.1&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3594&quot;&gt;&lt;del&gt;KAFKA-3594&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15348026" author="githubbot" created="Fri, 24 Jun 2016 08:57:58 +0000"  >&lt;p&gt;Github user ijuma closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1547&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1547&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15928059" author="padamstx" created="Thu, 16 Mar 2017 13:52:22 +0000"  >&lt;p&gt;What is the recommended way to get a fix for this issue?   I can&apos;t seem to find a pre-built 0.9.0.2 kafka-clients library, and I assume I can&apos;t use a v0.10.x kafka-clients library with a v0.9.0.1 broker.&lt;br/&gt;
If I need to download the source and build myself, what branch should I pull?&lt;br/&gt;
Thanks in advance for any help!&lt;br/&gt;
Phil&lt;/p&gt;</comment>
                            <comment id="15930084" author="padamstx" created="Fri, 17 Mar 2017 14:59:52 +0000"  >&lt;p&gt;I found out via the kafka users mailing list that this fix is in the 0.9.0 branch.  I pulled that from github and built locally.&lt;/p&gt;</comment>
                            <comment id="15974827" author="rehevkor5" created="Wed, 19 Apr 2017 14:54:27 +0000"  >&lt;p&gt;Does this problem result in failure to push messages to Kafka? Does the whole batch get lost, or what?&lt;/p&gt;

&lt;p&gt;Is there a workaround?&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13008623">KAFKA-4232</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 30 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2wein:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>