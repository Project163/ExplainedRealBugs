<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:56:12 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-3129] Console producer issue when request-required-acks=0</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-3129</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;I have been running a simple test case in which I have a text file &lt;tt&gt;messages.txt&lt;/tt&gt; with 1,000,000 lines (lines contain numbers from 1 to 1,000,000 in ascending order). I run the console consumer like this:&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;$ bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;Topic &lt;tt&gt;test&lt;/tt&gt; is on 1 partition with a replication factor of 1.&lt;/p&gt;

&lt;p&gt;Then I run the console producer like this:&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;$ bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test &amp;lt; messages.txt&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;Then the console starts receiving the messages. And about half the times it goes all the way to 1,000,000. But, in other cases, it stops short, usually at 999,735.&lt;/p&gt;

&lt;p&gt;I tried running another console consumer on another machine and both consumers behave the same way. I can&apos;t see anything related to this in the logs.&lt;/p&gt;

&lt;p&gt;I also ran the same experiment with a similar file of 10,000 lines, and am getting a similar behavior. When the consumer does not receive all the 10,000 messages it usually stops at 9,864.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12933206">KAFKA-3129</key>
            <summary>Console producer issue when request-required-acks=0</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="4" iconUrl="https://issues.apache.org/jira/images/icons/statuses/reopened.png" description="This issue was once resolved, but the resolution was deemed incorrect. From here issues are either marked assigned or resolved.">Reopened</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="cotedm">Dustin Cote</assignee>
                                    <reporter username="vahid">Vahid Hashemian</reporter>
                        <labels>
                            <label>windows</label>
                    </labels>
                <created>Thu, 21 Jan 2016 23:28:25 +0000</created>
                <updated>Sat, 24 Feb 2018 06:31:44 +0000</updated>
                                            <version>0.9.0.0</version>
                    <version>0.10.0.0</version>
                                                    <component>producer </component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                                                                <comments>
                            <comment id="15111608" author="ijuma" created="Thu, 21 Jan 2016 23:33:38 +0000"  >&lt;p&gt;Can you please test the 0.9.0 branch? This sounds familiar to an issue that has already been fixed.&lt;/p&gt;</comment>
                            <comment id="15111663" author="vahid" created="Fri, 22 Jan 2016 00:15:32 +0000"  >&lt;p&gt;I did run those test cases with the kafka_2.11-0.9.0.0 release.&lt;br/&gt;
I also tried the latest 0.9.0 branch and saw similar intermittent behavior. In fact, with the 0.9.0 branch most of the times the consumer does not receive all the 10,000 messages (stopping at 9,864).&lt;/p&gt;</comment>
                            <comment id="15111671" author="ijuma" created="Fri, 22 Jan 2016 00:19:25 +0000"  >&lt;p&gt;Oh, I thought you were using the new consumer, but I now notice that you are using the old consumer (the new consumer needs to be enabled via --new-consumer when using kafka-console-consumer).&lt;/p&gt;</comment>
                            <comment id="15111713" author="vahid" created="Fri, 22 Jan 2016 00:57:35 +0000"  >&lt;p&gt;I&apos;m afraid, it did not make much of a difference. I ran the consumer like this:&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --new-consumer&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;And still see intermittently that not all 1,000,000 or 10,000 messages are consumed by the new consumer. The rate of failure for 10,000 messages seems to be much higher than the rate for 1,000,000 messages.&lt;/p&gt;</comment>
                            <comment id="15112348" author="arunmahadevan" created="Fri, 22 Jan 2016 12:07:06 +0000"  >&lt;p&gt;Are you creating the topic beforehand? &lt;br/&gt;
It may have to do with when the console consumer fetches the offset for the topic. I think the messages published before the offset is fetched are not received by the console consumer.&lt;br/&gt;
Can you try running the consumer with --from-beginning ? For me if I pass the --for-beginning the console consumer always fetches all the messages but without that option sometimes it does not.&lt;/p&gt;</comment>
                            <comment id="15113016" author="vahid" created="Fri, 22 Jan 2016 20:41:42 +0000"  >&lt;p&gt;Yes, I&apos;m creating the topic before trying the scenario.&lt;br/&gt;
I tried the consumer with &lt;tt&gt;--from-beginning&lt;/tt&gt; and the consumption that stopped at 9864 still did not go beyond that. This tells me there is an issue with the producer intermittently not going through all the messages for some reason.&lt;/p&gt;</comment>
                            <comment id="15115773" author="vahid" created="Mon, 25 Jan 2016 19:01:56 +0000"  >&lt;p&gt;The observed behavior is different between when the producer is run in the console and when it is run via the IDE (eclipse).&lt;/p&gt;

&lt;p&gt;From console and with 10,000 messages, as described so far, about 50% of the times the consumer stops at 9,864 rather than going all the way to 10,000. When producer is run within the IDE, most of the times, the consumer goes up to 9,864, then pauses for a fraction of a second, and then it continues to consume the rest of the message, as shown in the attached video (kafka-3129.mov).&lt;/p&gt;</comment>
                            <comment id="15129021" author="vahid" created="Tue, 2 Feb 2016 21:00:04 +0000"  >&lt;p&gt;Further evidence that this is a producer issue:&lt;/p&gt;

&lt;p&gt;I ran the producer 6 times with the 10000 message file, and on the 6th try I noticed the consumer came back with 9864 (instead of 10000).&lt;br/&gt;
Then I ran this command:&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic test --time -1&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;And it returned this:&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;test:0:59864&lt;/tt&gt;&lt;/p&gt;</comment>
                            <comment id="15129382" author="hachikuji" created="Tue, 2 Feb 2016 23:58:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vahid&quot; class=&quot;user-hover&quot; rel=&quot;vahid&quot;&gt;vahid&lt;/a&gt; Are you using sync or async mode (I think async is the default)? I noticed that the console producer doesn&apos;t close the producer when it finishes, so it seems possible that some messages haven&apos;t been sent at the time the application shuts down. If you&apos;re not using sync already, you can enable it by adding &apos;--sync&apos; to the console producer&apos;s arguments.&lt;/p&gt;</comment>
                            <comment id="15129385" author="hachikuji" created="Tue, 2 Feb 2016 23:59:30 +0000"  >&lt;p&gt;Ah, my mistake. It actually is being closed in a shutdown hook. It still might be helpful to test using sync mode though.&lt;/p&gt;</comment>
                            <comment id="15129419" author="vahid" created="Wed, 3 Feb 2016 00:12:55 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt; for the suggestion. I tried it as you described but still saw the issue occur.&lt;/p&gt;</comment>
                            <comment id="15129427" author="hachikuji" created="Wed, 3 Feb 2016 00:18:25 +0000"  >&lt;p&gt;Are the missing messages always the last ones written? That definitely would suggest that the application is shutting down before all data gets pushed. I&apos;ll see if I can reproduce this locally.&lt;/p&gt;</comment>
                            <comment id="15129449" author="vahid" created="Wed, 3 Feb 2016 00:33:30 +0000"  >&lt;p&gt;As I mentioned, in the input file I have numbers from 1 to 10,000.&lt;br/&gt;
Sometimes when I run the producer all 10,000 of them are produced (I verify this by running a consumer and through GetOffsetShell).&lt;br/&gt;
But sometimes, messages from 1 to 9864 are produced and then it stops there. Usually 9864 is the magic number, but occasionally I see a different number.&lt;br/&gt;
Always messages from the end of the file are not produced when the issue occurs.&lt;/p&gt;</comment>
                            <comment id="15129499" author="hachikuji" created="Wed, 3 Feb 2016 01:03:48 +0000"  >&lt;p&gt;I haven&apos;t been able to reproduce this. It might be helpful to see some producer logs. Can you you turn the level up to DEBUG and attach the log from one of the failed cases?&lt;/p&gt;</comment>
                            <comment id="15130998" author="vahid" created="Wed, 3 Feb 2016 19:47:54 +0000"  >&lt;p&gt;Attached server.log.normal.txt, which is the server.log entries for a successful console producer of 10,000 entries.&lt;/p&gt;</comment>
                            <comment id="15131005" author="vahid" created="Wed, 3 Feb 2016 19:48:46 +0000"  >&lt;p&gt;Attached server.log.abnormal.txt, which is the server.log entries for an unsuccessful console producer of 10,000 entries. Only 9,864 entries out of 10,000 were produced.&lt;/p&gt;</comment>
                            <comment id="15131021" author="vahid" created="Wed, 3 Feb 2016 19:57:12 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt; I attached debug logs from server.log for both success and failure scenarios. If there are other logs I should also look at please let me know.&lt;/p&gt;</comment>
                            <comment id="15143527" author="vahid" created="Thu, 11 Feb 2016 21:23:50 +0000"  >&lt;p&gt;Some more information on this issue:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;It occurs only when &lt;tt&gt;request-required-acks&lt;/tt&gt; is set to &lt;tt&gt;0&lt;/tt&gt; (which is the default) in console producer. I.e. when the producer does not wait for an ack from any broker.&lt;/li&gt;
	&lt;li&gt;I have tried to reproduce it on Ubuntu, Windows, and Mac and have been able to do so on all of them. It seems to occur more frequently on Ubuntu (about 50%), then on Windows, and then on Mac (less than 1%).&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15147050" author="rsivaram" created="Mon, 15 Feb 2016 08:23:49 +0000"  >&lt;p&gt;At the moment &lt;tt&gt;PlaintextTransportLayer.close()&lt;/tt&gt; closes the socket channel and invalidates the selection key without blocking for output stream to be shutdown gracefully. Is this intentional?&lt;br/&gt;
&lt;tt&gt;close()&lt;/tt&gt; could either be a blocking version that shuts down gracefully or a non-blocking version with abrupt termination as it is now. It will be a bigger change to implement &lt;tt&gt;close()&lt;/tt&gt; with timeouts.&lt;/p&gt;</comment>
                            <comment id="15311048" author="vahid" created="Wed, 1 Jun 2016 20:27:59 +0000"  >&lt;p&gt;I can still produce this issue with the current trunk code, when &lt;tt&gt;request-required-acks&lt;/tt&gt; is the default &lt;tt&gt;0&lt;/tt&gt;.&lt;br/&gt;
I simply run the console producer like this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;tt&gt;seq 10000 | bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test&lt;/tt&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;And check the offset using&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;tt&gt;bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic test --time -1&lt;/tt&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;After a few tries I see that the returned offset falls behind.&lt;/p&gt;</comment>
                            <comment id="15439670" author="cotedm" created="Fri, 26 Aug 2016 19:44:17 +0000"  >&lt;p&gt;What I&apos;m seeing is that we are faking the callback &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;org.apache.kafka.clients.producer.internals.Sender#handleProduceResponse&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; for the case where acks=0.  This is a problem because the callback gets generated when we do &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;org.apache.kafka.clients.producer.internals.Sender#createProduceRequests&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; in the run loop but the actual send happens a bit later.  When close() comes in that window between createProduceRequests and the send, you get messages that are lost.  Funny thing is that if you slow down call stack a bit by turning on something like strace, the issue goes away so it&apos;s hard to tell which layer exactly is buffering the requests.&lt;/p&gt;

&lt;p&gt;So my question is, do we want to risk a small performance hit for all producers to be able to guarantee all messages with acks=0 actually make it out of the producer knowing full well that they aren&apos;t going to be verified to have made it to the broker?  I personally don&apos;t feel it&apos;s worth the extra locking complexity and could be documented known durability issue when you aren&apos;t using durability settings.  If we go that route, I feel like the console producer should have acks=1 by default.  That way, users who are getting started with the built-in tools have a cursory durability guarantee and can tune for performance instead.  What do you think &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vahid&quot; class=&quot;user-hover&quot; rel=&quot;vahid&quot;&gt;vahid&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="15439764" author="vahid" created="Fri, 26 Aug 2016 20:31:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cotedm&quot; class=&quot;user-hover&quot; rel=&quot;cotedm&quot;&gt;cotedm&lt;/a&gt; Thanks for looking into this. I think if we are going to accept the current behavior (which is fine to me) this defect should be documented and the default ack (as you mentioned) should be set to something else other than 0 so this issue is not revealed using default settings.&lt;/p&gt;</comment>
                            <comment id="15445771" author="githubbot" created="Mon, 29 Aug 2016 12:47:25 +0000"  >&lt;p&gt;GitHub user cotedm opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1795&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1795&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3129&quot; title=&quot;Console producer issue when request-required-acks=0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3129&quot;&gt;KAFKA-3129&lt;/a&gt;: Console producer issue when request-required-acks=0&lt;/p&gt;

&lt;p&gt;    change console producer default acks to 1, update acks docs.  Also added the -1 config to the acks docs since that question comes up often.  @ijuma and @vahidhashemian, does this look reasonable to you?&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/cotedm/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/cotedm/kafka&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-3129&quot; title=&quot;Console producer issue when request-required-acks=0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-3129&quot;&gt;KAFKA-3129&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1795.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1795.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #1795&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit bec755ffc4e4b779a6c6d45b144a7e3a87dc64d7&lt;br/&gt;
Author: Dustin Cote &amp;lt;dustin@confluent.io&amp;gt;&lt;br/&gt;
Date:   2016-08-29T12:44:37Z&lt;/p&gt;

&lt;p&gt;    change console producer default acks to 1, update acks docs&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="15471028" author="githubbot" created="Wed, 7 Sep 2016 16:09:37 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/1795&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/1795&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15471228" author="cotedm" created="Wed, 7 Sep 2016 17:24:11 +0000"  >&lt;p&gt;Reopening per &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt;&apos;s recommendation as acks=0 in general still has a problem somewhere along the way that isn&apos;t fully understood.&lt;/p&gt;</comment>
                            <comment id="16045812" author="pmishra01" created="Sun, 11 Jun 2017 04:49:24 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cotedm&quot; class=&quot;user-hover&quot; rel=&quot;cotedm&quot;&gt;cotedm&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vahid&quot; class=&quot;user-hover&quot; rel=&quot;vahid&quot;&gt;vahid&lt;/a&gt; I am also facing the same issue where my kafka console producer fails to write data. Please find below steps to recreate.&lt;/p&gt;

&lt;p&gt;1-Make a text file with 800 record. each line have record like &quot;Message 1&quot;  and the line 2 &quot;Message 2&quot; ........ &quot;Message 800&quot;&lt;br/&gt;
2- # start zookeeper server&lt;br/&gt;
.\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties&lt;/p&gt;

&lt;p&gt;3-# start broker&lt;br/&gt;
.\bin\windows\kafka-server-start.bat .\config\server.properties &lt;/p&gt;

&lt;p&gt;4-# create topic &#8220;test&#8221;&lt;br/&gt;
.\bin\windows\kafka-topics.bat --create --topic test --zookeeper localhost:2181 --partitions 1 --replication-factor 1&lt;/p&gt;

&lt;p&gt;5-#start consumer&lt;br/&gt;
.\bin\windows\kafka-console-consumer.bat --topic test --zookeeper localhost:2181&lt;/p&gt;

&lt;p&gt;6-sent file to producer&lt;br/&gt;
.\bin\windows&lt;br class=&quot;atl-forced-newline&quot; /&gt;kafka-console-producer.bat --broker-list localhost:9092 --topic test &amp;lt; my_file.txt&lt;/p&gt;

&lt;p&gt;I have executed all above steps with below configuration.(Windows 7, kafka_2.11-0.10.0.1)&lt;br/&gt;
1- Default kafka configuration- NOK(Sometimes it consumes 366 messages, sometimes 700 messages.)&lt;br/&gt;
2- Updating kafka producer.properties for acks=&quot;1&quot; or acks=&quot;all&quot;. both did not worked. still  NOK(Sometimes it consumes 366 messages, sometimes 700 messages.).&lt;/p&gt;

&lt;p&gt;Please suggest if this issue has been fixed. I&apos;m facing critical problem on production&lt;/p&gt;</comment>
                            <comment id="16047074" author="vahid" created="Mon, 12 Jun 2017 21:16:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pmishra01&quot; class=&quot;user-hover&quot; rel=&quot;pmishra01&quot;&gt;pmishra01&lt;/a&gt; I tried this on Ubuntu, Windows 7 and Windows 10 but were not able to reproduce it after a few tries.&lt;br/&gt;
Please note that the default &lt;tt&gt;acks&lt;/tt&gt; value has changed from 0 to 1 based on the &lt;a href=&quot;https://github.com/apache/kafka/pull/1795&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;this PR&lt;/a&gt;. So if you like to try producing with &lt;tt&gt;acks=0&lt;/tt&gt; you&apos;d have to overwrite the default.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12992671">KAFKA-3993</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12784204" name="kafka-3129.mov" size="814890" author="vahid" created="Mon, 25 Jan 2016 19:01:56 +0000"/>
                            <attachment id="12786086" name="server.log.abnormal.txt" size="15543" author="vahid" created="Wed, 3 Feb 2016 19:48:46 +0000"/>
                            <attachment id="12786085" name="server.log.normal.txt" size="16383" author="vahid" created="Wed, 3 Feb 2016 19:47:54 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 23 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2rtl3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>