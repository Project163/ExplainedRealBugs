<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:16:27 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-7549] Old ProduceRequest with zstd compression does not return error to client</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-7549</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Kafka broker v2.1.0rc0.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;KIP-110 states that:&lt;/p&gt;

&lt;p&gt;&quot;Zstd will only be allowed for the bumped produce API. That is, for older version clients(=below KAFKA_2_1_IV0), we return UNSUPPORTED_COMPRESSION_TYPE regardless of the message format.&quot;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;However, sending a ProduceRequest V3 with zstd compression (which is a client side bug) closes the connection with the following exception rather than returning UNSUPPORTED_COMPRESSION_TYPE in the ProduceResponse:&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[2018-10-25 11:40:31,813] ERROR Exception while processing request from 127.0.0.1:60723-127.0.0.1:60656-94 (kafka.network.Processor)
org.apache.kafka.common.errors.InvalidRequestException: Error getting request for apiKey: PRODUCE, apiVersion: 3, connectionId: 127.0.0.1:60723-127.0.0.1:60656-94, listenerName: ListenerName(PLAINTEXT), principal: User:ANONYMOUS
Caused by: org.apache.kafka.common.record.InvalidRecordException: Produce requests with version 3 are note allowed to use ZStandard compression
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13194110">KAFKA-7549</key>
            <summary>Old ProduceRequest with zstd compression does not return error to client</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dongjin">Dongjin Lee</assignee>
                                    <reporter username="edenhill">Magnus Edenhill</reporter>
                        <labels>
                    </labels>
                <created>Thu, 25 Oct 2018 09:50:38 +0000</created>
                <updated>Mon, 10 Dec 2018 17:48:52 +0000</updated>
                            <resolved>Mon, 10 Dec 2018 17:48:52 +0000</resolved>
                                                    <fixVersion>2.1.1</fixVersion>
                    <fixVersion>2.2.0</fixVersion>
                                    <component>compression</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="16663722" author="ijuma" created="Thu, 25 Oct 2018 13:14:05 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjin&quot; class=&quot;user-hover&quot; rel=&quot;dongjin&quot;&gt;dongjin&lt;/a&gt; would you have time to look into this?&lt;/p&gt;</comment>
                            <comment id="16663865" author="dongjin.lee.kr" created="Thu, 25 Oct 2018 15:08:32 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt; No problem. Let me have a look.&lt;/p&gt;</comment>
                            <comment id="16665396" author="dongjin.lee.kr" created="Fri, 26 Oct 2018 16:41:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt; I reviewed the problem. Here is the result:&lt;/p&gt;

&lt;p&gt;The KIP documentation states what broker returns for invalid Produce request (i.e., ZSTD compressed message with a Produce API version below 7), but not what happens when the user tries to instantiate an invalid ProducerRequest instance. Validation on ProducerRequest instantiation was &lt;a href=&quot;https://github.com/apache/kafka/pull/2267#discussion_r222913248&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;proposed and added&lt;/a&gt; after the KIP was accepted and the revision was under progress. It is why it is not in the KIP document - Sorry, I was updating the KIP following the discussion on PR but not completed yet.&lt;/p&gt;

&lt;p&gt;Here, we have three choices:&lt;/p&gt;

&lt;p&gt;1. Throw InvalidRecordException (current): It follows the consistency with other exceptions in ProduceRequest#validateRecords.&lt;br/&gt;
 2. Throw UnsupportedVersionException: &lt;a href=&quot;https://github.com/apache/kafka/pull/2267#pullrequestreview-162177303&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;What Jason proposed at first&lt;/a&gt;, but breaks consistency.&lt;br/&gt;
 3. Throw UnsupportedCompressionType: It follows what broker returns, but breaks consistency also.&lt;/p&gt;

&lt;p&gt;Which approach do you prefer?&lt;/p&gt;</comment>
                            <comment id="16666859" author="edenhill" created="Mon, 29 Oct 2018 08:47:55 +0000"  >&lt;p&gt;Even if option 2 is logically more correct, I believe option 3 is more helpful to the end user, so my vote is for 3.&lt;/p&gt;

&lt;p&gt;Seeing how this issue is only exposed by a buggy client, I don&apos;t have a strong opinion, but would prefer that the broker does not close the connection since it provides no clues.&lt;/p&gt;</comment>
                            <comment id="16667190" author="ijuma" created="Mon, 29 Oct 2018 13:28:12 +0000"  >&lt;p&gt;The user never instantiates an invalid ProducerRequest directly though. When we deserialize it and it turns out not to have expected parameters, we should return an error id and not simply disconnect the connection. cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt; who reviewed the PR.&lt;/p&gt;</comment>
                            <comment id="16667263" author="edenhill" created="Mon, 29 Oct 2018 14:12:01 +0000"  >&lt;p&gt;Right, but the producer client will hopefully expose the returned error code to the user in some fashion.&lt;/p&gt;</comment>
                            <comment id="16667272" author="ijuma" created="Mon, 29 Oct 2018 14:16:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=edenhill&quot; class=&quot;user-hover&quot; rel=&quot;edenhill&quot;&gt;edenhill&lt;/a&gt;, my comment was a response to the original question, i.e. option 1 looks wrong in general (even for the other exceptions). I did suggest returning a useful error code for the reason you state, i.e. your &quot;but&quot; should be &quot;and&quot;. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="16676115" author="dongjin.lee.kr" created="Tue, 6 Nov 2018 04:20:03 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt;&#160; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt;&#160;Ping!&lt;/p&gt;</comment>
                            <comment id="16678602" author="lindong" created="Wed, 7 Nov 2018 18:24:34 +0000"  >&lt;p&gt;I actually think it is reasonable for client to receive InvalidRequestException if client sends ProduceRequest V3 with zstd codec.&lt;/p&gt;

&lt;p&gt;We can not send UnsupportedCompressionTypeException because&#160;UNSUPPORTED_COMPRESSION_TYPE exception because if ProduceRequest is V3 then there is no guarantee that client library can&#160;understand the error code 76. The meaning of UnsupportedVersionException is currently &quot;The version of API is not supported&quot;, which does not match the scenario here because ProduceRequest V3 is actually supported by the broker.&#160;InvalidRequestException is reasonable because the issue here is that ProduceRequest V3 is used with zstd codec which makes the entire request invalid.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=edenhill&quot; class=&quot;user-hover&quot; rel=&quot;edenhill&quot;&gt;edenhill&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjin&quot; class=&quot;user-hover&quot; rel=&quot;dongjin&quot;&gt;dongjin&lt;/a&gt; By saying &quot;client side bug&quot; in the Jira description, is this bug in Apache Kafka or in another custom client library? If it is in Apache Kafka, is there Jira that tracks this issue?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt; Does this sound reasonable?&lt;/p&gt;</comment>
                            <comment id="16680509" author="lindong" created="Thu, 8 Nov 2018 22:33:07 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt;&#160;Given the reasoning provided above, are you OK with moving this issue out of 2.1 release?&lt;/p&gt;</comment>
                            <comment id="16681617" author="dongjin.lee.kr" created="Fri, 9 Nov 2018 15:47:33 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lindong&quot; class=&quot;user-hover&quot; rel=&quot;lindong&quot;&gt;lindong&lt;/a&gt; Well, it seems like the ProduceRequest was not actually sent to the brokers; That exception is thrown in ProducerRequest#validateRecords, which is called by the constructor of ProducerRequest only; In other words, it means the instantiation of ProducerRequest was failed. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=edenhill&quot; class=&quot;user-hover&quot; rel=&quot;edenhill&quot;&gt;edenhill&lt;/a&gt;&#160;Could you explain more in detail?&lt;/p&gt;</comment>
                            <comment id="16681635" author="ijuma" created="Fri, 9 Nov 2018 15:59:32 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lindong&quot; class=&quot;user-hover&quot; rel=&quot;lindong&quot;&gt;lindong&lt;/a&gt; yeah, we can move this to 2.2.0 and 2.1.1. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjin&quot; class=&quot;user-hover&quot; rel=&quot;dongjin&quot;&gt;dongjin&lt;/a&gt;, you are assuming that people use the Java client. What&apos;s happening here is different: Magnus is using another client and the broker deserializes the request and then triggers this issue when creating the ProduceRequest.&lt;/p&gt;</comment>
                            <comment id="16681636" author="ijuma" created="Fri, 9 Nov 2018 16:00:24 +0000"  >&lt;p&gt;With regards to the actual error, there was a discussion on the KIP about the error to be used. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt; looked at this closest, so it would be good to get his input.&lt;/p&gt;</comment>
                            <comment id="16681948" author="hachikuji" created="Fri, 9 Nov 2018 21:21:48 +0000"  >&lt;p&gt;Sorry for the late response. As I understand it, the main issue is that we close the connection. Which error code we return seems a matter of taste (I think my preference is probably option 1 since it should only be client developers seeing this error and not end users, but I don&apos;t have a strong preference). I think probably it is a mistake to do the message format validation inside the ProduceRequest constructor. The current error handling logic depends on having a request object in order to return the proper response. Perhaps we should consider moving that validation into LogValidator?&lt;/p&gt;</comment>
                            <comment id="16690978" author="githubbot" created="Sun, 18 Nov 2018 17:31:11 +0000"  >&lt;p&gt;dongjinleekr opened a new pull request #5925: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7549&quot; title=&quot;Old ProduceRequest with zstd compression does not return error to client&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7549&quot;&gt;&lt;del&gt;KAFKA-7549&lt;/del&gt;&lt;/a&gt;: Old ProduceRequest with zstd compression does not return error to client&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5925&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5925&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   As of current version (2.1.0), zstd-related validations are located in following spots:&lt;/p&gt;

&lt;p&gt;   1. *&lt;b&gt;ProduceRequest&lt;/b&gt;*&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;`MemoryRecordsBuilder`: can&apos;t create `MemoryRecords` with magic &amp;lt; 2 (`IllegalArgumentException`)&lt;/li&gt;
	&lt;li&gt;`ProduceRequest.Builder`: can&apos;t create `ProduceRequest` with api version below 7 (`InvalidRecordException`)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   2. *&lt;b&gt;FetchRequest&lt;/b&gt;*&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;`KafkaApis#handleFetchRequest`: Returns `FetchResponse` w/ `Errors#UNSUPPORTED_COMPRESSION_TYPE` if ...&lt;br/&gt;
           1. `FetchRequest` w/ API version &amp;lt; 10 is delivered to a zstd-compressed topic.&lt;br/&gt;
           2. Down-conversion failure: `LazyDownConversionRecords#makeNext` &#8594; `RecordsUtil#downConvert` throws `UnsupportedCompressionTypeException`.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   3. *&lt;b&gt;Etc&lt;/b&gt;*&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;`AbstractLegacyRecordBatch.DeepRecordsIterator`: A boilerplate validation for legacy record batches.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   *&lt;b&gt;In short, there is no broker-side validation for `ProduceRequest` w/ zstd compressed records.&lt;/b&gt;* This PR compensates this hole.&lt;/p&gt;

&lt;p&gt;   There is a reason why this validation can&apos;t be located in other class, e.g., `LogValidator`: it can&apos;t see the API version of `ProduceRequest.` The only method that can check both of `CompressionType` and API version is `KafkaApis#handleProduceRequest`; it&apos;s why.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16715218" author="githubbot" created="Mon, 10 Dec 2018 17:45:21 +0000"  >&lt;p&gt;hachikuji closed pull request #5925: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-7549&quot; title=&quot;Old ProduceRequest with zstd compression does not return error to client&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-7549&quot;&gt;&lt;del&gt;KAFKA-7549&lt;/del&gt;&lt;/a&gt;: Old ProduceRequest with zstd compression does not return error to client&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/5925&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/5925&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/clients/src/main/java/org/apache/kafka/common/requests/ProduceRequest.java b/clients/src/main/java/org/apache/kafka/common/requests/ProduceRequest.java&lt;br/&gt;
index f87090eba6a..9f9de42c866 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/common/requests/ProduceRequest.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/common/requests/ProduceRequest.java&lt;br/&gt;
@@ -17,6 +17,7 @@&lt;br/&gt;
 package org.apache.kafka.common.requests;&lt;/p&gt;

&lt;p&gt; import org.apache.kafka.common.TopicPartition;&lt;br/&gt;
+import org.apache.kafka.common.errors.UnsupportedCompressionTypeException;&lt;br/&gt;
 import org.apache.kafka.common.protocol.ApiKeys;&lt;br/&gt;
 import org.apache.kafka.common.protocol.CommonFields;&lt;br/&gt;
 import org.apache.kafka.common.protocol.Errors;&lt;br/&gt;
@@ -172,6 +173,21 @@ public Builder(short minVersion,&lt;/p&gt;

&lt;p&gt;         @Override&lt;br/&gt;
         public ProduceRequest build(short version) &lt;/p&gt;
{
+            return build(version, true);
+        }
&lt;p&gt;+&lt;br/&gt;
+        // Visible for testing only&lt;br/&gt;
+        public ProduceRequest buildUnsafe(short version) &lt;/p&gt;
{
+            return build(version, false);
+        }
&lt;p&gt;+&lt;br/&gt;
+        private ProduceRequest build(short version, boolean validate) {&lt;br/&gt;
+            if (validate) {&lt;br/&gt;
+                // Validate the given records first&lt;br/&gt;
+                for (MemoryRecords records : partitionRecords.values()) &lt;/p&gt;
{
+                    ProduceRequest.validateRecords(version, records);
+                }
&lt;p&gt;+            }&lt;br/&gt;
             return new ProduceRequest(version, acks, timeout, partitionRecords, transactionalId);&lt;br/&gt;
         }&lt;/p&gt;

&lt;p&gt;@@ -210,8 +226,9 @@ private ProduceRequest(short version, short acks, int timeout, Map&amp;lt;TopicPartitio&lt;br/&gt;
         this.partitionRecords = partitionRecords;&lt;br/&gt;
         this.partitionSizes = createPartitionSizes(partitionRecords);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for (MemoryRecords records : partitionRecords.values())&lt;/li&gt;
	&lt;li&gt;validateRecords(version, records);&lt;br/&gt;
+        for (MemoryRecords records : partitionRecords.values()) 
{
+            setFlags(records);
+        }
&lt;p&gt;     }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     private static Map&amp;lt;TopicPartition, Integer&amp;gt; createPartitionSizes(Map&amp;lt;TopicPartition, MemoryRecords&amp;gt; partitionRecords) {&lt;br/&gt;
@@ -231,7 +248,7 @@ public ProduceRequest(Struct struct, short version) &lt;/p&gt;
{
                 Struct partitionResponse = (Struct) partitionResponseObj;
                 int partition = partitionResponse.get(PARTITION_ID);
                 MemoryRecords records = (MemoryRecords) partitionResponse.getRecords(RECORD_SET_KEY_NAME);
-                validateRecords(version, records);
+                setFlags(records);
                 partitionRecords.put(new TopicPartition(topic, partition), records);
             }
&lt;p&gt;         }&lt;br/&gt;
@@ -241,32 +258,11 @@ public ProduceRequest(Struct struct, short version) &lt;/p&gt;
{
         transactionalId = struct.getOrElse(NULLABLE_TRANSACTIONAL_ID, null);
     }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private void validateRecords(short version, MemoryRecords records) {&lt;/li&gt;
	&lt;li&gt;if (version &amp;gt;= 3) {&lt;/li&gt;
	&lt;li&gt;Iterator&amp;lt;MutableRecordBatch&amp;gt; iterator = records.batches().iterator();&lt;/li&gt;
	&lt;li&gt;if (!iterator.hasNext())&lt;/li&gt;
	&lt;li&gt;throw new InvalidRecordException(&quot;Produce requests with version &quot; + version + &quot; must have at least &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;one record batch&quot;);&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;MutableRecordBatch entry = iterator.next();&lt;/li&gt;
	&lt;li&gt;if (entry.magic() != RecordBatch.MAGIC_VALUE_V2)&lt;/li&gt;
	&lt;li&gt;throw new InvalidRecordException(&quot;Produce requests with version &quot; + version + &quot; are only allowed to &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;contain record batches with magic version 2&quot;);&lt;/li&gt;
	&lt;li&gt;if (version &amp;lt; 7 &amp;amp;&amp;amp; entry.compressionType() == CompressionType.ZSTD) 
{
-                throw new InvalidRecordException(&quot;Produce requests with version &quot; + version + &quot; are note allowed to &quot; +
-                    &quot;use ZStandard compression&quot;);
-            }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;if (iterator.hasNext())&lt;/li&gt;
	&lt;li&gt;throw new InvalidRecordException(&quot;Produce requests with version &quot; + version + &quot; are only allowed to &quot; +&lt;/li&gt;
	&lt;li&gt;&quot;contain exactly one record batch&quot;);&lt;/li&gt;
	&lt;li&gt;idempotent = entry.hasProducerId();&lt;/li&gt;
	&lt;li&gt;transactional = entry.isTransactional();&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;// Note that we do not do similar validation for older versions to ensure compatibility with&lt;/li&gt;
	&lt;li&gt;// clients which send the wrong magic version in the wrong version of the produce request. The broker&lt;/li&gt;
	&lt;li&gt;// did not do this validation before, so we maintain that behavior here.&lt;br/&gt;
+    private void setFlags(MemoryRecords records) 
{
+        Iterator&amp;lt;MutableRecordBatch&amp;gt; iterator = records.batches().iterator();
+        MutableRecordBatch entry = iterator.next();
+        idempotent = entry.hasProducerId();
+        transactional = entry.isTransactional();
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /**&lt;br/&gt;
@@ -394,6 +390,32 @@ public void clearPartitionRecords() &lt;/p&gt;
{
         partitionRecords = null;
     }

&lt;p&gt;+    public static void validateRecords(short version, MemoryRecords records) {&lt;br/&gt;
+        if (version &amp;gt;= 3) {&lt;br/&gt;
+            Iterator&amp;lt;MutableRecordBatch&amp;gt; iterator = records.batches().iterator();&lt;br/&gt;
+            if (!iterator.hasNext())&lt;br/&gt;
+                throw new InvalidRecordException(&quot;Produce requests with version &quot; + version + &quot; must have at least &quot; +&lt;br/&gt;
+                    &quot;one record batch&quot;);&lt;br/&gt;
+&lt;br/&gt;
+            MutableRecordBatch entry = iterator.next();&lt;br/&gt;
+            if (entry.magic() != RecordBatch.MAGIC_VALUE_V2)&lt;br/&gt;
+                throw new InvalidRecordException(&quot;Produce requests with version &quot; + version + &quot; are only allowed to &quot; +&lt;br/&gt;
+                    &quot;contain record batches with magic version 2&quot;);&lt;br/&gt;
+            if (version &amp;lt; 7 &amp;amp;&amp;amp; entry.compressionType() == CompressionType.ZSTD) &lt;/p&gt;
{
+                throw new UnsupportedCompressionTypeException(&quot;Produce requests with version &quot; + version + &quot; are note allowed to &quot; +
+                    &quot;use ZStandard compression&quot;);
+            }
&lt;p&gt;+&lt;br/&gt;
+            if (iterator.hasNext())&lt;br/&gt;
+                throw new InvalidRecordException(&quot;Produce requests with version &quot; + version + &quot; are only allowed to &quot; +&lt;br/&gt;
+                    &quot;contain exactly one record batch&quot;);&lt;br/&gt;
+        }&lt;br/&gt;
+&lt;br/&gt;
+        // Note that we do not do similar validation for older versions to ensure compatibility with&lt;br/&gt;
+        // clients which send the wrong magic version in the wrong version of the produce request. The broker&lt;br/&gt;
+        // did not do this validation before, so we maintain that behavior here.&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
     public static ProduceRequest parse(ByteBuffer buffer, short version) &lt;/p&gt;
{
         return new ProduceRequest(ApiKeys.PRODUCE.parseRequest(version, buffer), version);
     }
&lt;p&gt;diff --git a/core/src/main/scala/kafka/server/KafkaApis.scala b/core/src/main/scala/kafka/server/KafkaApis.scala&lt;br/&gt;
index f2e3e01af83..1d786bbdf71 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/server/KafkaApis.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/server/KafkaApis.scala&lt;br/&gt;
@@ -46,7 +46,7 @@ import org.apache.kafka.common.internals.Topic.{GROUP_METADATA_TOPIC_NAME, TRANS&lt;br/&gt;
 import org.apache.kafka.common.metrics.Metrics&lt;br/&gt;
 import org.apache.kafka.common.network.&lt;/p&gt;
{ListenerName, Send}
&lt;p&gt; import org.apache.kafka.common.protocol.&lt;/p&gt;
{ApiKeys, Errors}
&lt;p&gt;-import org.apache.kafka.common.record.&lt;/p&gt;
{BaseRecords, ControlRecordType, EndTransactionMarker, LazyDownConversionRecords, MemoryRecords, MultiRecordsSend, RecordBatch, RecordConversionStats, Records}
&lt;p&gt;+import org.apache.kafka.common.record._&lt;br/&gt;
 import org.apache.kafka.common.requests.CreateAclsResponse.AclCreationResponse&lt;br/&gt;
 import org.apache.kafka.common.requests.CreateTopicsRequest.TopicDetails&lt;br/&gt;
 import org.apache.kafka.common.requests.DeleteAclsResponse.&lt;/p&gt;
{AclDeletionResult, AclFilterResponse}
&lt;p&gt;@@ -391,6 +391,7 @@ class KafkaApis(val requestChannel: RequestChannel,&lt;/p&gt;

&lt;p&gt;     val unauthorizedTopicResponses = mutable.Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, PartitionResponse&amp;#93;&lt;/span&gt;()&lt;br/&gt;
     val nonExistingTopicResponses = mutable.Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, PartitionResponse&amp;#93;&lt;/span&gt;()&lt;br/&gt;
+    val invalidRequestResponses = mutable.Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, PartitionResponse&amp;#93;&lt;/span&gt;()&lt;br/&gt;
     val authorizedRequestInfo = mutable.Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, MemoryRecords&amp;#93;&lt;/span&gt;()&lt;/p&gt;

&lt;p&gt;     for ((topicPartition, memoryRecords) &amp;lt;- produceRequest.partitionRecordsOrFail.asScala) {&lt;br/&gt;
@@ -399,12 +400,18 @@ class KafkaApis(val requestChannel: RequestChannel,&lt;br/&gt;
       else if (!metadataCache.contains(topicPartition))&lt;br/&gt;
         nonExistingTopicResponses += topicPartition -&amp;gt; new PartitionResponse(Errors.UNKNOWN_TOPIC_OR_PARTITION)&lt;br/&gt;
       else&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;authorizedRequestInfo += (topicPartition -&amp;gt; memoryRecords)&lt;br/&gt;
+        try 
{
+          ProduceRequest.validateRecords(request.header.apiVersion(), memoryRecords)
+          authorizedRequestInfo += (topicPartition -&amp;gt; memoryRecords)
+        }
&lt;p&gt; catch &lt;/p&gt;
{
+          case e: ApiException =&amp;gt;
+            invalidRequestResponses += topicPartition -&amp;gt; new PartitionResponse(Errors.forException(e))
+        }
&lt;p&gt;     }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // the callback for sending a produce response&lt;br/&gt;
     def sendResponseCallback(responseStatus: Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, PartitionResponse&amp;#93;&lt;/span&gt;) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val mergedResponseStatus = responseStatus ++ unauthorizedTopicResponses ++ nonExistingTopicResponses&lt;br/&gt;
+      val mergedResponseStatus = responseStatus ++ unauthorizedTopicResponses ++ nonExistingTopicResponses ++ invalidRequestResponses&lt;br/&gt;
       var errorInResponse = false&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;       mergedResponseStatus.foreach { case (topicPartition, status) =&amp;gt;&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/server/ProduceRequestTest.scala b/core/src/test/scala/unit/kafka/server/ProduceRequestTest.scala&lt;br/&gt;
index b1f3af145b9..906de71ecc6 100644&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/server/ProduceRequestTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/server/ProduceRequestTest.scala&lt;br/&gt;
@@ -133,11 +133,19 @@ class ProduceRequestTest extends BaseRequestTest &lt;/p&gt;
{
     // produce request with v7: works fine!
     val res1 = sendProduceRequest(leader,
       new ProduceRequest.Builder(7, 7, -1, 3000, partitionRecords.asJava, null).build())
-    val (tp, partitionResponse) = res1.responses.asScala.head
-    assertEquals(topicPartition, tp)
-    assertEquals(Errors.NONE, partitionResponse.error)
-    assertEquals(0, partitionResponse.baseOffset)
-    assertEquals(-1, partitionResponse.logAppendTime)
+    val (tp1, partitionResponse1) = res1.responses.asScala.head
+    assertEquals(topicPartition, tp1)
+    assertEquals(Errors.NONE, partitionResponse1.error)
+    assertEquals(0, partitionResponse1.baseOffset)
+    assertEquals(-1, partitionResponse1.logAppendTime)
+
+    // produce request with v3: returns Errors.UNSUPPORTED_COMPRESSION_TYPE.
+    val res2 = sendProduceRequest(leader,
+      new ProduceRequest.Builder(3, 3, -1, 3000, partitionRecords.asJava, null)
+        .buildUnsafe(3))
+    val (tp2, partitionResponse2) = res2.responses.asScala.head
+    assertEquals(topicPartition, tp2)
+    assertEquals(Errors.UNSUPPORTED_COMPRESSION_TYPE, partitionResponse2.error)
   }

&lt;p&gt;   private def sendProduceRequest(leaderId: Int, request: ProduceRequest): ProduceResponse = {&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 49 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3zmmv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>