<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:37:40 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-739] Handle null values in Message payload</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-739</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;Add tests for null message payloads in producer, server, and consumer.&lt;br/&gt;
Ensure log cleaner treats these as deletes.&lt;br/&gt;
Test that null keys are rejected on dedupe logs.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12629629">KAFKA-739</key>
            <summary>Handle null values in Message payload</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jkreps">Jay Kreps</assignee>
                                    <reporter username="jkreps">Jay Kreps</reporter>
                        <labels>
                    </labels>
                <created>Tue, 29 Jan 2013 03:14:10 +0000</created>
                <updated>Wed, 3 Jul 2013 04:02:07 +0000</updated>
                            <resolved>Wed, 3 Jul 2013 04:02:07 +0000</resolved>
                                                    <fixVersion>0.8.1</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="13592772" author="jkreps" created="Mon, 4 Mar 2013 22:55:25 +0000"  >&lt;p&gt;This patch is more extensive than I expected because I found a hole in the logic when handling deletes in the log compactor. The changes are as follows:&lt;/p&gt;

&lt;p&gt;1. Handle null properly in Message.scala and miscellaneous other places.&lt;br/&gt;
2. Fix the logic for handling deletes. Previously we guaranteed that we would retain delete records only in the dirty section of the log. This is not sufficient, because a bootstrapping consumer might see a message, but the subsequent delete message might be gc&apos;d before the consumer sees it.&lt;br/&gt;
3. OffsetMap.scala: make the map exact using a probing scheme. This means that the tail of the log is actually now fully deduplicated. The motivation for this is making delete-handling easier since to remove a delete tombstone you need to ensure that there are no prior occurrences of that message. Also added a counter on the number of collisions, just to help with any debugging.&lt;br/&gt;
4. Added a new configuration log.cleaner.delete.retention.ms that controls the length of time for which delete records are retained. This is implicitly a limit on the amount of time the consumer can spend bootstrapping and still get a consistent bootstrap. Once the topic-level config patch goes in, this will be made available at the topic level and can be set with the create topic tool&lt;br/&gt;
5. Added a peek() method to iterator template. Didn&apos;t end up using it, but it is a useful feature&lt;br/&gt;
6. Changed the integration test tool to issue deletes and changed the verification to handle delete records properly. Redid testing now with deletes included.&lt;br/&gt;
7. Added a variety of unit tests for null messages&lt;/p&gt;</comment>
                            <comment id="13593123" author="sriramsub" created="Tue, 5 Mar 2013 06:37:00 +0000"  >&lt;p&gt;I am not able to apply this patch using git apply. Was this created using git format-patch?&lt;/p&gt;</comment>
                            <comment id="13593523" author="jkreps" created="Tue, 5 Mar 2013 16:09:33 +0000"  >&lt;p&gt;No, actually it is just git diff against the base revision.&lt;/p&gt;</comment>
                            <comment id="13595011" author="nehanarkhede" created="Wed, 6 Mar 2013 19:26:13 +0000"  >&lt;p&gt;There was a conflict on DefaultEventHandler, but I reviewed the patch. &lt;/p&gt;

&lt;p&gt;1. KafkaConfig&lt;br/&gt;
Should the default for log.cleaner.delete.retention.ms be 24 hours instead of 1 hour ?&lt;/p&gt;

&lt;p&gt;2. LogCleaner&lt;br/&gt;
2.1 Should the check for dedup buffer be &lt;br/&gt;
config.dedupeBufferSize / config.numThreads &amp;gt; Int.MaxValue&lt;/p&gt;

&lt;p&gt;3. DefaultEventHandler (There was a conflict, maybe you already handled this)&lt;br/&gt;
Need to check for null payload in the following trace- &lt;br/&gt;
              trace(&quot;Successfully sent message: %s&quot;.format(Utils.readString(message.message.payload)))))&lt;/p&gt;

&lt;p&gt;4. DumpLogSegments&lt;br/&gt;
Should this be reading message.key instead ?&lt;br/&gt;
          print(&quot; key: &quot; + Utils.readString(messageAndOffset.message.payload, &quot;UTF-8&quot;))&lt;/p&gt;

&lt;p&gt;5. SimpleKafkaETLMapper&lt;br/&gt;
Should probably check for null here in getData well -&lt;br/&gt;
                ByteBuffer buf = message.payload();&lt;/p&gt;

&lt;p&gt;6. OffsetMap6.1 If I understand correctly from getPosition(), it seems that the probe length will change arbitrarily each time. What is the advantage of doing this VS picking a fixed probe length that is relatively prime to the total number of entries that the hash table can fit in ? The purpose of this property is so that every slot in the hash table can be eventually traversed.&lt;br/&gt;
6.2 Why does attempts increment by 1 and not by 4 ?&lt;/p&gt;

&lt;p&gt;7. TestLogCleaning&lt;br/&gt;
The purpose of dumpLogs config is not clear from the command line option description.&lt;/p&gt;</comment>
                            <comment id="13597422" author="jkreps" created="Fri, 8 Mar 2013 19:21:27 +0000"  >&lt;p&gt;New patch rebased to trunk and addresses Neha&apos;s comments:&lt;/p&gt;

&lt;p&gt;1. Changed delete retention to 24 hours&lt;br/&gt;
2. Fixed broken logic in warning statement so it warns when your buffer is too big.&lt;br/&gt;
3. Yes, that was in the patch, just got lost in the conflict?&lt;br/&gt;
4. Dump log segments was printing the value as the key, fixed.&lt;br/&gt;
5. SimpleKafkaETLMapper didn&apos;t handle null. This isn&apos;t an easy fix since the text format doesn&apos;t have an out of range marker to represent null. Returning empty string which is ambiguous but better than crashing.&lt;br/&gt;
6. Linear probing has the problem that it tends to lead to &quot;runs&quot;. I.e. if you have a fixed probing step size of N then if you have a collision the probability that the spot M slots over is full is going to be higher. So the ideal probing approach would be a sequence of fully random hashes which were completely uncorrelated with one another. That is the motivation for using the rest of the md5 before degrading to linear probing since we have already computed 16 bytes of random hash. The second question is wether it is legit to increment byte by byte or not since this effectively reuses bytes of the hash. I agree it is a little sketchy, though it does seem to work.&lt;br/&gt;
7. Clarified the purpose of dump logs.&lt;/p&gt;</comment>
                            <comment id="13597690" author="jkreps" created="Fri, 8 Mar 2013 23:31:25 +0000"  >&lt;p&gt;Patch version V3:&lt;br/&gt;
1. Rebased to include the dynamic config change.&lt;br/&gt;
2. Made delete retention a per-topic config &lt;/p&gt;</comment>
                            <comment id="13597771" author="sriramsub" created="Sat, 9 Mar 2013 01:02:22 +0000"  >&lt;p&gt;1. OffsetMap&lt;br/&gt;
    a. The way the probe is calculated, we could end up having the same probe multiple times. Starting with attempt = hashSize - 4 to attempt = hashSize the probe would be the same. &lt;br/&gt;
    val probe = Utils.readInt(hash, math.min(attempt, hashSize-4)) + math.max(0, attempt - hashSize)&lt;/p&gt;

&lt;p&gt;2. LogCleaner&lt;br/&gt;
    a. Cleaner doc comments need to be updated&lt;/p&gt;

&lt;p&gt;Will look at the test changes and provide comments if any.&lt;/p&gt;</comment>
                            <comment id="13597842" author="jkreps" created="Sat, 9 Mar 2013 04:44:04 +0000"  >&lt;p&gt;Nice catch Sriram, that actually drops the collision rate by 7%.&lt;/p&gt;

&lt;p&gt;Here is a new patch that fixes that bug, fixes the docs, exposes the cleaner buffer load factor as a configuration parameter.&lt;/p&gt;</comment>
                            <comment id="13598923" author="nehanarkhede" created="Mon, 11 Mar 2013 16:02:15 +0000"  >&lt;p&gt;+1 on patch v4&lt;/p&gt;</comment>
                            <comment id="13599338" author="junrao" created="Mon, 11 Mar 2013 21:29:07 +0000"  >&lt;p&gt;Thanks for patch v4. Looks good. Some minor comments:&lt;/p&gt;

&lt;p&gt;40. IteratorTemplate: Not sure that I understand how peek() is different from next(). If both cases, they call hasNext() and therefore move nextItem to the next item, right?&lt;/p&gt;

&lt;p&gt;41. LogCleaner:&lt;br/&gt;
41.1 Could you add some comments in the header to describe how delete retention works?&lt;br/&gt;
41.2 cleanSegments(): val now not used.&lt;/p&gt;

&lt;p&gt;42. Decoder:&lt;br/&gt;
42.1 Could we add a comment in the trait saying that bytes can be null?&lt;br/&gt;
42.2 We need to fix StringDecoder to return null if input is null.&lt;/p&gt;</comment>
                            <comment id="13600166" author="jkreps" created="Tue, 12 Mar 2013 16:46:51 +0000"  >&lt;p&gt;Jun, attached v5 patch to address your comments.&lt;br/&gt;
40. This is actually right, both peek, hasNext, and next will all call makeNext() if there isn&apos;t an item ready. But peek and hasNext are idempotent and next() isn&apos;t--it advances the iterator. I wrote a unit test that demonstrates this.&lt;br/&gt;
41. Added the comment and removed the stray variable.&lt;br/&gt;
42. Actually the handling of nulls is not done in the serializers, it is done in Kafka. That is no matter what serializer you use, null always deserializes to null. You could argue either way whether this is a good thing. The downside to pushing it isn&apos;t the serializer is that all serializers have to remember to handle null. The advantage is that the serializer could yield a different value for null if it wanted. Couldn&apos;t think of a use for the later so I went with the simple thing.&lt;/p&gt;</comment>
                            <comment id="13600222" author="junrao" created="Tue, 12 Mar 2013 17:38:58 +0000"  >&lt;p&gt;Thanks for patch v5. +1.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12629631">KAFKA-741</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12571977" name="KAFKA-739-v1.patch" size="54592" author="jkreps" created="Mon, 4 Mar 2013 22:55:25 +0000"/>
                            <attachment id="12572801" name="KAFKA-739-v2.patch" size="57196" author="jkreps" created="Fri, 8 Mar 2013 19:21:27 +0000"/>
                            <attachment id="12572856" name="KAFKA-739-v3.patch" size="59777" author="jkreps" created="Fri, 8 Mar 2013 23:31:25 +0000"/>
                            <attachment id="12572892" name="KAFKA-739-v4.patch" size="62495" author="jkreps" created="Sat, 9 Mar 2013 04:44:04 +0000"/>
                            <attachment id="12573365" name="KAFKA-739-v5.patch" size="64924" author="jkreps" created="Tue, 12 Mar 2013 16:46:51 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>310125</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            12 years, 36 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1hisn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>310470</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>