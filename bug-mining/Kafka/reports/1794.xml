<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:06:08 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-4897] LogCleaner#cleanSegments should not ignore failures to delete files</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-4897</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;LogCleaner#cleanSegments should not ignore failures to delete files.  Currently, it ignores the failure and does not even log an error message.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13056052">KAFKA-4897</key>
            <summary>LogCleaner#cleanSegments should not ignore failures to delete files</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="omkreddy">Manikumar</assignee>
                                    <reporter username="cmccabe">Colin McCabe</reporter>
                        <labels>
                    </labels>
                <created>Tue, 14 Mar 2017 19:38:32 +0000</created>
                <updated>Fri, 26 Jan 2018 04:32:04 +0000</updated>
                            <resolved>Thu, 25 Jan 2018 20:40:59 +0000</resolved>
                                                    <fixVersion>1.1.0</fixVersion>
                                    <component>core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="16312588" author="omkreddy" created="Fri, 5 Jan 2018 07:02:23 +0000"  >&lt;p&gt;looks like this got handled in &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6324&quot; title=&quot;Change LogSegment.delete to deleteIfExists and harden log recovery&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6324&quot;&gt;&lt;del&gt;KAFKA-6324&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16312627" author="githubbot" created="Fri, 5 Jan 2018 07:38:03 +0000"  >&lt;p&gt;omkreddy opened a new pull request #4393: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-4897&quot; title=&quot;LogCleaner#cleanSegments should not ignore failures to delete files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-4897&quot;&gt;&lt;del&gt;KAFKA-4897&lt;/del&gt;&lt;/a&gt;: Fix findbug issue and remove LogCleaner suppression from findbugs-exclude.xml&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4393&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4393&lt;/a&gt;&lt;/p&gt;



&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16339844" author="githubbot" created="Thu, 25 Jan 2018 20:39:24 +0000"  >&lt;p&gt;hachikuji closed pull request #4393: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-4897&quot; title=&quot;LogCleaner#cleanSegments should not ignore failures to delete files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-4897&quot;&gt;&lt;del&gt;KAFKA-4897&lt;/del&gt;&lt;/a&gt;: Add pause method to ShutdownableThread&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4393&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4393&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/core/src/main/scala/kafka/consumer/ConsumerFetcherManager.scala b/core/src/main/scala/kafka/consumer/ConsumerFetcherManager.scala&lt;br/&gt;
index 0a6b82e5fc1..23f53569a6b 100755&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/consumer/ConsumerFetcherManager.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/consumer/ConsumerFetcherManager.scala&lt;br/&gt;
@@ -83,7 +83,7 @@ class ConsumerFetcherManager(private val consumerIdString: String,&lt;br/&gt;
         }&lt;br/&gt;
       } catch {&lt;br/&gt;
         case t: Throwable =&amp;gt; &lt;/p&gt;
{
-            if (!isRunning.get())
+            if (!isRunning)
               throw t /* If this thread is stopped, propagate this exception to kill the thread. */
             else
               warn(&quot;Failed to find leader for %s&quot;.format(noLeaderPartitionSet), t)
@@ -98,7 +98,7 @@ class ConsumerFetcherManager(private val consumerIdString: String,
         )
       }
&lt;p&gt; catch {&lt;br/&gt;
         case t: Throwable =&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (!isRunning.get())&lt;br/&gt;
+          if (!isRunning)&lt;br/&gt;
             throw t /* If this thread is stopped, propagate this exception to kill the thread. */&lt;br/&gt;
           else {&lt;br/&gt;
             warn(&quot;Failed to add leader for partitions %s; will retry&quot;.format(leaderForPartitionsMap.keySet.mkString(&quot;,&quot;)), t)&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/controller/ControllerChannelManager.scala b/core/src/main/scala/kafka/controller/ControllerChannelManager.scala&lt;br/&gt;
index e389821ad3b..d5456bea9a8 100755
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/main/scala/kafka/controller/ControllerChannelManager.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/controller/ControllerChannelManager.scala&lt;br/&gt;
@@ -17,7 +17,7 @@&lt;br/&gt;
 package kafka.controller&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import java.net.SocketTimeoutException&lt;br/&gt;
-import java.util.concurrent.&lt;/p&gt;
{BlockingQueue, LinkedBlockingQueue}
&lt;p&gt;+import java.util.concurrent.&lt;/p&gt;
{BlockingQueue, LinkedBlockingQueue, TimeUnit}

&lt;p&gt; import com.yammer.metrics.core.Gauge&lt;br/&gt;
 import kafka.api._&lt;br/&gt;
@@ -213,13 +213,13 @@ class RequestSendThread(val controllerId: Int,&lt;/p&gt;

&lt;p&gt;   override def doWork(): Unit = {&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def backoff(): Unit = CoreUtils.swallow(Thread.sleep(100), this, Level.TRACE)&lt;br/&gt;
+    def backoff(): Unit = pause(100, TimeUnit.MILLISECONDS)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val QueueItem(apiKey, requestBuilder, callback) = queue.take()&lt;br/&gt;
     var clientResponse: ClientResponse = null&lt;br/&gt;
     try {&lt;br/&gt;
       var isSendSuccessful = false&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;while (isRunning.get() &amp;amp;&amp;amp; !isSendSuccessful) {&lt;br/&gt;
+      while (isRunning &amp;amp;&amp;amp; !isSendSuccessful) {&lt;br/&gt;
         // if a broker goes down for a long time, then at some point the controller&apos;s zookeeper listener will trigger a&lt;br/&gt;
         // removeBroker which will invoke shutdown() on this thread. At that point, we will stop retrying.&lt;br/&gt;
         try {&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/log/LogCleaner.scala b/core/src/main/scala/kafka/log/LogCleaner.scala&lt;br/&gt;
index c5c0d497318..637e24cb01d 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/main/scala/kafka/log/LogCleaner.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/log/LogCleaner.scala&lt;br/&gt;
@@ -21,7 +21,7 @@ import java.io.
{File, IOException}
&lt;p&gt; import java.nio._&lt;br/&gt;
 import java.nio.file.Files&lt;br/&gt;
 import java.util.Date&lt;br/&gt;
-import java.util.concurrent.&lt;/p&gt;
{CountDownLatch, TimeUnit}&lt;br/&gt;
+import java.util.concurrent.TimeUnit&lt;br/&gt;
 &lt;br/&gt;
 import com.yammer.metrics.core.Gauge&lt;br/&gt;
 import kafka.common._&lt;br/&gt;
@@ -233,10 +233,9 @@ class LogCleaner(val config: CleanerConfig,&lt;br/&gt;
                               checkDone = checkDone)&lt;br/&gt;
 &lt;br/&gt;
     @volatile var lastStats: CleanerStats = new CleanerStats()&lt;br/&gt;
-    private val backOffWaitLatch = new CountDownLatch(1)&lt;br/&gt;
 &lt;br/&gt;
     private def checkDone(topicPartition: TopicPartition) {
-      if (!isRunning.get())
+      if (!isRunning)
         throw new ThreadShutdownException
       cleanerManager.checkCleaningAborted(topicPartition)
     }&lt;br/&gt;
@@ -248,12 +247,6 @@ class LogCleaner(val config: CleanerConfig,&lt;br/&gt;
       cleanOrSleep()&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
-    override def shutdown() = {
-    	 initiateShutdown()
-    	 backOffWaitLatch.countDown()
-    	 awaitShutdown()
-     }&lt;br/&gt;
-&lt;br/&gt;
     /**&lt;br/&gt;
      * Clean a log if there is a dirty log available, otherwise sleep for a bit&lt;br/&gt;
      */&lt;br/&gt;
@@ -289,7 +282,7 @@ class LogCleaner(val config: CleanerConfig,&lt;br/&gt;
           }&lt;br/&gt;
       }&lt;br/&gt;
       if (!cleaned)&lt;br/&gt;
-        backOffWaitLatch.await(config.backOffMs, TimeUnit.MILLISECONDS)&lt;br/&gt;
+        pause(config.backOffMs, TimeUnit.MILLISECONDS)&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/server/AbstractFetcherThread.scala b/core/src/main/scala/kafka/server/AbstractFetcherThread.scala&lt;br/&gt;
index b078073ba03..925c33095a2 100755&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/server/AbstractFetcherThread.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/server/AbstractFetcherThread.scala&lt;br/&gt;
@@ -148,7 +148,7 @@ abstract class AbstractFetcherThread(name: String,&lt;br/&gt;
       responseData = fetch(fetchRequest)&lt;br/&gt;
     } catch {&lt;br/&gt;
       case t: Throwable =&amp;gt;&lt;br/&gt;
-        if (isRunning.get) {&lt;br/&gt;
+        if (isRunning) {&lt;br/&gt;
           warn(s&quot;Error in fetch to broker ${sourceBroker.id}, request $fetchRequest&quot;, t)&lt;br/&gt;
           inLock(partitionMapLock) {
             partitionsWithError ++= partitionStates.partitionSet.asScala
@@ -218,7 +218,7 @@ abstract class AbstractFetcherThread(name: String,
                       partitionsWithError += topicPartition
                   }&lt;br/&gt;
                 case _ =&amp;gt;&lt;br/&gt;
-                  if (isRunning.get) {&lt;br/&gt;
+                  if (isRunning) {&lt;br/&gt;
                     error(s&quot;Error for partition $topicPartition from broker ${sourceBroker.id}&quot;, partitionData.exception.get)&lt;br/&gt;
                     partitionsWithError += topicPartition&lt;br/&gt;
                   }&lt;br/&gt;
diff --git a/core/src/main/scala/kafka/tools/ReplicaVerificationTool.scala b/core/src/main/scala/kafka/tools/ReplicaVerificationTool.scala&lt;br/&gt;
index 71f33683dbe..0408e9212a3 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/tools/ReplicaVerificationTool.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/tools/ReplicaVerificationTool.scala&lt;br/&gt;
@@ -368,7 +368,7 @@ private class ReplicaFetcher(name: String, sourceBroker: BrokerEndPoint, topicAn&lt;br/&gt;
       response = simpleConsumer.fetch(fetchRequest)&lt;br/&gt;
     } catch {
       case t: Throwable =&amp;gt;
-        if (!isRunning.get)
+        if (!isRunning)
           throw t
     }&lt;br/&gt;
 &lt;br/&gt;
diff --git a/core/src/main/scala/kafka/utils/ShutdownableThread.scala b/core/src/main/scala/kafka/utils/ShutdownableThread.scala&lt;br/&gt;
index 0922d15e93a..13bbc90f2a5 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/utils/ShutdownableThread.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/utils/ShutdownableThread.scala&lt;br/&gt;
@@ -17,8 +17,7 @@&lt;br/&gt;
 &lt;br/&gt;
 package kafka.utils&lt;br/&gt;
 &lt;br/&gt;
-import java.util.concurrent.atomic.AtomicBoolean&lt;br/&gt;
-import java.util.concurrent.CountDownLatch&lt;br/&gt;
+import java.util.concurrent.{CountDownLatch, TimeUnit}&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import org.apache.kafka.common.internals.FatalExitError&lt;/p&gt;

&lt;p&gt;@@ -26,8 +25,8 @@ abstract class ShutdownableThread(val name: String, val isInterruptible: Boolean&lt;br/&gt;
         extends Thread(name) with Logging {&lt;br/&gt;
   this.setDaemon(false)&lt;br/&gt;
   this.logIdent = &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;&amp;quot; + name + &amp;quot;&amp;#93;&lt;/span&gt;: &quot;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val isRunning: AtomicBoolean = new AtomicBoolean(true)&lt;/li&gt;
	&lt;li&gt;private val shutdownLatch = new CountDownLatch(1)&lt;br/&gt;
+  private val shutdownInitiated = new CountDownLatch(1)&lt;br/&gt;
+  private val shutdownComplete = new CountDownLatch(1)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def shutdown(): Unit = &lt;/p&gt;
{
     initiateShutdown()
@@ -35,27 +34,42 @@ abstract class ShutdownableThread(val name: String, val isInterruptible: Boolean
   }

&lt;p&gt;   def isShutdownComplete: Boolean = &lt;/p&gt;
{
-    shutdownLatch.getCount == 0
+    shutdownComplete.getCount == 0
   }

&lt;p&gt;   def initiateShutdown(): Boolean = {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (isRunning.compareAndSet(true, false)) 
{
-      info(&quot;Shutting down&quot;)
-      if (isInterruptible)
-        interrupt()
-      true
-    }
&lt;p&gt; else&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;false&lt;br/&gt;
+    this.synchronized 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+      if (isRunning) {
+        info(&quot;Shutting down&quot;)
+        shutdownInitiated.countDown()
+        if (isInterruptible)
+          interrupt()
+        true
+      } else+        false+    }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;   }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/**&lt;br/&gt;
+  /**&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;After calling initiateShutdown(), use this API to wait until the shutdown is complete&lt;br/&gt;
    */&lt;br/&gt;
   def awaitShutdown(): Unit = 
{
-    shutdownLatch.await()
+    shutdownComplete.await()
     info(&quot;Shutdown completed&quot;)
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+  /**&lt;br/&gt;
+   *  Causes the current thread to wait until the shutdown is initiated,&lt;br/&gt;
+   *  or the specified waiting time elapses.&lt;br/&gt;
+   *&lt;br/&gt;
+   * @param timeout&lt;br/&gt;
+   * @param unit&lt;br/&gt;
+   */&lt;br/&gt;
+  def pause(timeout: Long, unit: TimeUnit): Unit = &lt;/p&gt;
{
+    if (shutdownInitiated.await(timeout, unit))
+      trace(&quot;shutdownInitiated latch count reached zero. Shutdown called.&quot;)
+  }
&lt;p&gt;+&lt;br/&gt;
   /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;This method is repeatedly invoked until the thread shuts down or this method throws an exception&lt;br/&gt;
    */&lt;br/&gt;
@@ -64,19 +78,24 @@ abstract class ShutdownableThread(val name: String, val isInterruptible: Boolean&lt;br/&gt;
   override def run(): Unit = {&lt;br/&gt;
     info(&quot;Starting&quot;)&lt;br/&gt;
     try 
{
-      while (isRunning.get)
+      while (isRunning)
         doWork()
     }
&lt;p&gt; catch &lt;/p&gt;
{
       case e: FatalExitError =&amp;gt;
-        isRunning.set(false)
-        shutdownLatch.countDown()
+        shutdownInitiated.countDown()
+        shutdownComplete.countDown()
         info(&quot;Stopped&quot;)
         Exit.exit(e.statusCode())
       case e: Throwable =&amp;gt;
-        if (isRunning.get())
+        if (isRunning)
           error(&quot;Error due to&quot;, e)
+    }
&lt;p&gt; finally &lt;/p&gt;
{
+       shutdownComplete.countDown()
     }&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;shutdownLatch.countDown()&lt;br/&gt;
     info(&quot;Stopped&quot;)&lt;br/&gt;
   }&lt;br/&gt;
+&lt;br/&gt;
+  def isRunning: Boolean = 
{
+    shutdownInitiated.getCount() != 0
+  }
&lt;p&gt; }&lt;br/&gt;
diff --git a/core/src/test/scala/integration/kafka/api/ConsumerBounceTest.scala b/core/src/test/scala/integration/kafka/api/ConsumerBounceTest.scala&lt;br/&gt;
index 8917921d85f..58d1be9ee5c 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/test/scala/integration/kafka/api/ConsumerBounceTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/integration/kafka/api/ConsumerBounceTest.scala&lt;br/&gt;
@@ -104,7 +104,7 @@ class ConsumerBounceTest extends IntegrationTestHarness with Logging {&lt;br/&gt;
     val scheduler = new BounceBrokerScheduler(numIters)&lt;br/&gt;
     scheduler.start()&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;while (scheduler.isRunning.get()) {&lt;br/&gt;
+    while (scheduler.isRunning) {&lt;br/&gt;
       val records = consumer.poll(100).asScala&lt;br/&gt;
       assertEquals(Set(tp), consumer.assignment.asScala)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -146,7 +146,7 @@ class ConsumerBounceTest extends IntegrationTestHarness with Logging {&lt;br/&gt;
     val scheduler = new BounceBrokerScheduler(numIters)&lt;br/&gt;
     scheduler.start()&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;while(scheduler.isRunning.get()) {&lt;br/&gt;
+    while(scheduler.isRunning) {&lt;br/&gt;
       val coin = TestUtils.random.nextInt(3)&lt;br/&gt;
       if (coin == 0) {&lt;br/&gt;
         info(&quot;Seeking to end of log&quot;)&lt;br/&gt;
diff --git a/core/src/test/scala/integration/kafka/server/DynamicBrokerReconfigurationTest.scala b/core/src/test/scala/integration/kafka/server/DynamicBrokerReconfigurationTest.scala&lt;br/&gt;
index fc06b731034..a760d7d1d06 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/test/scala/integration/kafka/server/DynamicBrokerReconfigurationTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/integration/kafka/server/DynamicBrokerReconfigurationTest.scala&lt;br/&gt;
@@ -439,7 +439,7 @@ class DynamicBrokerReconfigurationTest extends ZooKeeperTestHarness with SaslSet&lt;br/&gt;
     @volatile var sent = 0&lt;br/&gt;
     override def doWork(): Unit = {&lt;br/&gt;
         try {&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;while (isRunning.get) {&lt;br/&gt;
+            while (isRunning) {&lt;br/&gt;
                 sent += 1&lt;br/&gt;
                 val record = new ProducerRecord(topic, s&quot;key$sent&quot;, s&quot;value$sent&quot;)&lt;br/&gt;
                 producer.send(record).get(10, TimeUnit.SECONDS)&lt;br/&gt;
@@ -456,7 +456,7 @@ class DynamicBrokerReconfigurationTest extends ZooKeeperTestHarness with SaslSet&lt;br/&gt;
     var received = 0&lt;br/&gt;
     override def doWork(): Unit = {&lt;br/&gt;
       try {&lt;/li&gt;
	&lt;li&gt;while (isRunning.get || (received &amp;lt; producerThread.sent &amp;amp;&amp;amp; System.currentTimeMillis &amp;lt; endTimeMs)) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+        while (isRunning || (received &amp;lt; producerThread.sent &amp;amp;&amp;amp; System.currentTimeMillis &amp;lt; endTimeMs)) {
           received += consumer.poll(50).count
         }       }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt; finally {&lt;br/&gt;
diff --git a/gradle/findbugs-exclude.xml b/gradle/findbugs-exclude.xml&lt;br/&gt;
index 3bc3d39b339..66b4874e3f9 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/gradle/findbugs-exclude.xml&lt;br/&gt;
+++ b/gradle/findbugs-exclude.xml&lt;br/&gt;
@@ -88,21 +88,6 @@ For a detailed description of findbugs bug categories, see &lt;a href=&quot;http://findbugs.sourc&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://findbugs.sourc&lt;/a&gt;&lt;br/&gt;
         &amp;lt;/Or&amp;gt;&lt;br/&gt;
     &amp;lt;/Match&amp;gt;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;Match&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;!-- Add a suppression for &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-4897&quot; title=&quot;LogCleaner#cleanSegments should not ignore failures to delete files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-4897&quot;&gt;&lt;del&gt;KAFKA-4897&lt;/del&gt;&lt;/a&gt;: LogCleaner#cleanSegments should not ignore failures to delete files.&lt;/li&gt;
	&lt;li&gt;TODO: remove this suppression when &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-4897&quot; title=&quot;LogCleaner#cleanSegments should not ignore failures to delete files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-4897&quot;&gt;&lt;del&gt;KAFKA-4897&lt;/del&gt;&lt;/a&gt; is fixed. --&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;Package name=&quot;kafka.log&quot;/&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;Source name=&quot;LogCleaner.scala&quot;/&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;Bug pattern=&quot;RV_RETURN_VALUE_IGNORED,RV_RETURN_VALUE_IGNORED_BAD_PRACTICE&quot;/&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;/Match&amp;gt;&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;&amp;lt;Match&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;!-- Add a suppression for ignoring the return value of CountDownLatch#await. --&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;Class name=&quot;kafka.log.Cleaner&quot;/&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;Method name=&quot;cleanOrSleep&quot;/&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;Bug pattern=&quot;RV_RETURN_VALUE_IGNORED_BAD_PRACTICE&quot;/&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;/Match&amp;gt;&lt;br/&gt;
-&lt;br/&gt;
     &amp;lt;Match&amp;gt;&lt;br/&gt;
         &amp;lt;!-- Add a suppression for having the thread start in the constructor of the old, deprecated consumer. --&amp;gt;&lt;br/&gt;
         &amp;lt;Class name=&quot;kafka.producer.Producer&quot;/&amp;gt;&lt;/li&gt;
&lt;/ul&gt;





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16340560" author="ijuma" created="Fri, 26 Jan 2018 04:32:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt;, looks like the PR had the wrong Jira number.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13043734">KAFKA-4773</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 42 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3c9h3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>