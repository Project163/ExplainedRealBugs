<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:03:22 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-5747] Broker crashes on startup when trying to parse empty snapshot files</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-5747</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;A broker server crash can sometime result in empty snapshot files on disk (depending on FS, barrier setting etc), when Kafka tries to parse such files it crashes, gets restarted and crashes again, this happens until you remove empty snapshot files with:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;find /logs/dir -name \*.snapshot -size 0 -delete
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Log:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Aug 15 22:52:11 localhost kafka[23681]: INFO Recovering unflushed segment 0 in log __consumer_offsets-16. (kafka.log.Log)
Aug 15 22:52:11 localhost kafka[23681]: INFO Loading producer state from offset 1207 for partition __consumer_offsets-16 with message format version 0 (kafka.log.Log)
Aug 15 22:52:11 localhost kafka[23681]: INFO Completed load of log __consumer_offsets-16 with 1 log segments, log start offset 0 and log end offset 1207 in 15 ms (kafka.log.Log)
Aug 15 22:52:11 localhost kafka[23681]: WARN Found a corrupted index file due to requirement failed: Corrupt index found, index file (/disk/data/kafka/mycluster/mytopic-64/00000000300519800823.index) has non-zero size but the last offset is 300519800823 which is no larger than the base offset 300519800823.}. deleting /disk/data/kafka/mycluster/mytopic-64/00000000300519800823.timeindex, /disk/data/kafka/mycluster/mytopic-64/00000000300519800823.index, and /disk/data/kafka/mycluster/mytopic-64/00000000300519800823.txnindex and rebuilding index... (kafka.log.Log)
Aug 15 22:52:11 localhost kafka[23681]: INFO Loading producer state from snapshot file 00000000300519800823.snapshot for partition mytopic-64 (kafka.log.ProducerStateManager)
Aug 15 22:52:11 localhost kafka[23681]: ERROR There was an error in one of the threads during logs loading: org.apache.kafka.common.protocol.types.SchemaException: Error reading field &apos;version&apos;: java.nio.BufferUnderflowException (kafka.log.LogManager)
Aug 15 22:52:11 localhost kafka[23681]: FATAL [Kafka Server 10139], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
Aug 15 22:52:11 localhost kafka[23681]: org.apache.kafka.common.protocol.types.SchemaException: Error reading field &apos;version&apos;: java.nio.BufferUnderflowException
Aug 15 22:52:11 localhost kafka[23681]:         at org.apache.kafka.common.protocol.types.Schema.read(Schema.java:76)
Aug 15 22:52:11 localhost kafka[23681]:         at kafka.log.ProducerStateManager$.readSnapshot(ProducerStateManager.scala:289)
Aug 15 22:52:11 localhost kafka[23681]:         at kafka.log.ProducerStateManager.loadFromSnapshot(ProducerStateManager.scala:440)
Aug 15 22:52:11 localhost kafka[23681]:         at kafka.log.ProducerStateManager.truncateAndReload(ProducerStateManager.scala:499)
Aug 15 22:52:11 localhost kafka[23681]:         at kafka.log.Log.recoverSegment(Log.scala:327)
Aug 15 22:52:11 localhost kafka[23681]:         at kafka.log.Log.$anonfun$loadSegmentFiles$3(Log.scala:314)
Aug 15 22:52:11 localhost kafka[23681]:         at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789)
Aug 15 22:52:11 localhost kafka[23681]:         at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:32)
Aug 15 22:52:11 localhost kafka[23681]:         at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:29)
Aug 15 22:52:11 localhost kafka[23681]:         at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:191)
Aug 15 22:52:11 localhost kafka[23681]:         at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788)
Aug 15 22:52:11 localhost kafka[23681]:         at kafka.log.Log.loadSegmentFiles(Log.scala:272)
Aug 15 22:52:11 localhost kafka[23681]:         at kafka.log.Log.loadSegments(Log.scala:376)
Aug 15 22:52:11 localhost kafka[23681]:         at kafka.log.Log.&amp;lt;init&amp;gt;(Log.scala:179)
Aug 15 22:52:11 localhost kafka[23681]:         at kafka.log.Log$.apply(Log.scala:1581)
Aug 15 22:52:11 localhost kafka[23681]:         at kafka.log.LogManager.$anonfun$loadLogs$12(LogManager.scala:172)
Aug 15 22:52:11 localhost kafka[23681]:         at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:57)
Aug 15 22:52:11 localhost kafka[23681]:         at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
Aug 15 22:52:11 localhost kafka[23681]:         at java.util.concurrent.FutureTask.run(FutureTask.java:266)
Aug 15 22:52:11 localhost kafka[23681]:         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
Aug 15 22:52:11 localhost kafka[23681]:         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
Aug 15 22:52:11 localhost kafka[23681]:         at java.lang.Thread.run(Thread.java:748)
Aug 15 22:52:11 localhost kafka[23681]: INFO [Kafka Server 10139], shutting down (kafka.server.KafkaServer)
Aug 15 22:52:11 localhost kafka[23681]: INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
Aug 15 22:52:11 localhost kafka[23681]: INFO Session: 0x15de80e0a37004c closed (org.apache.zookeeper.ZooKeeper)
Aug 15 22:52:11 localhost kafka[23681]: INFO EventThread shut down for session: 0x15de80e0a37004c (org.apache.zookeeper.ClientCnxn)
Aug 15 22:52:11 localhost kafka[23681]: INFO [Kafka Server 10139], shut down completed (kafka.server.KafkaServer)
Aug 15 22:52:11 localhost kafka[23681]: FATAL Exiting Kafka. (kafka.server.KafkaServerStartable)
Aug 15 22:52:11 localhost kafka[23681]: INFO [Kafka Server 10139], shutting down (kafka.server.KafkaServer)
Aug 15 22:52:12 localhost systemd[1]: kafka.service: Main process exited, code=exited, status=1/FAILURE
Aug 15 22:52:12 localhost systemd[1]: kafka.service: Unit entered failed state.
Aug 15 22:52:12 localhost systemd[1]: kafka.service: Failed with result &apos;exit-code&apos;.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Happens with 0.10 &amp;amp; 0.11&lt;/p&gt;</description>
                <environment></environment>
        <key id="13095431">KAFKA-5747</key>
            <summary>Broker crashes on startup when trying to parse empty snapshot files</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hachikuji">Jason Gustafson</assignee>
                                    <reporter username="l.mierzwa">Lukasz Mierzwa</reporter>
                        <labels>
                    </labels>
                <created>Thu, 17 Aug 2017 19:01:24 +0000</created>
                <updated>Tue, 22 Aug 2017 10:33:51 +0000</updated>
                            <resolved>Mon, 21 Aug 2017 17:23:58 +0000</resolved>
                                    <version>0.11.0.0</version>
                                    <fixVersion>0.11.0.1</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16131021" author="bobrik" created="Thu, 17 Aug 2017 19:08:30 +0000"  >&lt;p&gt;This is especially bad, because Kafka starts the process from the beginning and it doesn&apos;t get any faster between iterations. It seems that recovery state is not written until recovery is fully complete. Imagine waiting for 1h to recover 1k partitions and then seeing this error when just 10 partitions remain.&lt;/p&gt;</comment>
                            <comment id="16131252" author="hachikuji" created="Thu, 17 Aug 2017 20:31:04 +0000"  >&lt;p&gt;Changed the affected version to 0.11.0.0 only since this producer snapshot file did not exist prior to this release.&lt;/p&gt;</comment>
                            <comment id="16131272" author="l.mierzwa" created="Thu, 17 Aug 2017 20:46:42 +0000"  >&lt;p&gt;Sorry, I though I hit this with 0.10 too, but I can only provide logs from 0.11, so might have been a different issue (or simply different empty files).&lt;/p&gt;</comment>
                            <comment id="16131335" author="githubbot" created="Thu, 17 Aug 2017 21:33:35 +0000"  >&lt;p&gt;GitHub user hachikuji opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/3688&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3688&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5747&quot; title=&quot;Broker crashes on startup when trying to parse empty snapshot files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5747&quot;&gt;&lt;del&gt;KAFKA-5747&lt;/del&gt;&lt;/a&gt;: Producer snapshot loading should cover schema and other errors&lt;/p&gt;



&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/hachikuji/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/hachikuji/kafka&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5747&quot; title=&quot;Broker crashes on startup when trying to parse empty snapshot files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5747&quot;&gt;&lt;del&gt;KAFKA-5747&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/3688.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3688.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #3688&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 21ea5414239206fdaacebb7a1304fd9fe598c68f&lt;br/&gt;
Author: Jason Gustafson &amp;lt;jason@confluent.io&amp;gt;&lt;br/&gt;
Date:   2017-08-17T21:27:43Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5747&quot; title=&quot;Broker crashes on startup when trying to parse empty snapshot files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5747&quot;&gt;&lt;del&gt;KAFKA-5747&lt;/del&gt;&lt;/a&gt;: Producer snapshot loading should cover schema and other errors&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="16135465" author="hachikuji" created="Mon, 21 Aug 2017 17:23:58 +0000"  >&lt;p&gt;Issue resolved by pull request 3688&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/pull/3688&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3688&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16135466" author="githubbot" created="Mon, 21 Aug 2017 17:25:02 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/3688&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3688&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="13096091">KAFKA-5751</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 13 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3ix6f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>