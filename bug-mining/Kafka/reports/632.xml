<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:42:46 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-1863] Exception categories / hierarchy in clients</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-1863</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;In the new clients package we introduces a new set of exceptions, but its hierarchy is not very clear as of today:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;RuntimeException -&amp;gt; KafkaException -&amp;gt; BufferExhastedException
                                                           -&amp;gt; ConfigException
                                                           -&amp;gt; SerializationException
                                                           -&amp;gt; QuotaViolationException
                                                           -&amp;gt; SchemaException

                                                           -&amp;gt; ApiException

ApiException -&amp;gt; InvalidTopicException
                     -&amp;gt; OffsetMetadataTooLarge (probabaly need to be renamed)
                     -&amp;gt; RecordBatchTooLargeException
                     -&amp;gt; RecordTooLargeException
                     -&amp;gt; UnknownServerException

                     -&amp;gt; RetriableException

RetriableException -&amp;gt; CorruptRecordException
                               -&amp;gt; InvalidMetadataException
                               -&amp;gt; NotEnoughtReplicasAfterAppendException
                               -&amp;gt; NotEnoughReplicasException
                               -&amp;gt; OffsetOutOfRangeException
                               -&amp;gt; TimeoutException
                               -&amp;gt; UnknownTopicOrPartitionException
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;KafkaProducer.send() may throw KafkaExceptions that are not ApiExceptions; other exceptions will be set in the returned future metadata.&lt;/p&gt;

&lt;p&gt;We need better to&lt;/p&gt;

&lt;p&gt;1. Re-examine the hierarchy. For example, for producers only exceptions that are thrown directly from the caller thread before it is appended to the batch buffer should be ApiExceptions; some exceptions could be renamed / merged.&lt;/p&gt;

&lt;p&gt;2. Clearly document the exception category / hierarchy as part of the release.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=criccomini&quot; class=&quot;user-hover&quot; rel=&quot;criccomini&quot;&gt;criccomini&lt;/a&gt; may have some more feedbacks for this issue from Samza&apos;s usage experience. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jkreps&quot; class=&quot;user-hover&quot; rel=&quot;jkreps&quot;&gt;jkreps&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12767525">KAFKA-1863</key>
            <summary>Exception categories / hierarchy in clients</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="guozhang">Guozhang Wang</assignee>
                                    <reporter username="guozhang">Guozhang Wang</reporter>
                        <labels>
                    </labels>
                <created>Wed, 14 Jan 2015 19:07:10 +0000</created>
                <updated>Tue, 17 May 2016 14:15:38 +0000</updated>
                            <resolved>Fri, 13 Mar 2015 22:18:14 +0000</resolved>
                                                    <fixVersion>0.9.0.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="14277814" author="navina" created="Wed, 14 Jan 2015 22:36:07 +0000"  >&lt;p&gt;Summarizing the issue we face in Samza:&lt;/p&gt;

&lt;p&gt;In Samza, we want to be able to retry producer.send when certain exceptions (mostly, RetriableException) occur, that can be mitigated over time with retries. This way, we can leverage the pipelining feature in the new API, while also making sure that a single send failure does not bring down the Samza container.&lt;/p&gt;

&lt;p&gt;The main point of concern is that the defined callback can get invoked in either the main thread or the IO thread from Kafka. This means we have to catch exceptions in more than one point in Samza producer code to ensure that we retry on the right exceptions and also, have to share states across the main thread and the IO thread (which executes the callback). &lt;/p&gt;

&lt;p&gt;A clearly defined hierarchy of exceptions will be a good starting point to ensure that our implementation logic is correct and deterministic.&lt;/p&gt;

&lt;p&gt;The patch for KafkaSystemProducer in Samza with the new producer API is available in this &lt;a href=&quot;https://reviews.apache.org/r/29899/diff/#&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;patch&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14277885" author="jkreps" created="Wed, 14 Jan 2015 23:30:58 +0000"  >&lt;p&gt;Hey guys, I put some thought into this but I agree it isn&apos;t very clearly documented. Let&apos;s see if it makes sense:&lt;/p&gt;

&lt;p&gt;ApiException denotes server-side exceptions and map to Kafka error codes. They indicate a server or network error.&lt;/p&gt;

&lt;p&gt;RetriableException are things that, if retried, might work. You want to avoid retrying things like RecordTooLargeException because it is not going to change.&lt;/p&gt;

&lt;p&gt;The next question is why do some exceptions get thrown by send() and some not? First, obviously not all exceptions can be thrown by send() since the error may occur asynchronously. So the choice is either to have all errors go to the callback or not. The rationale for throwing some exceptions directly is that these are things you should not ignore even if you don&apos;t wait on the future &amp;#8212; e.g. a serialization error. The rationale for handling api exceptions in the application thread was to simplify error handling. Some exceptions that can be thrown by the server can also be thrown by the client &amp;#8212; e.g. TimeoutException. It seems simpler to be able to say that timeout exceptions will ALWAYS go to the callback even if the timeout occurs waiting on a metadata update.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navina&quot; class=&quot;user-hover&quot; rel=&quot;navina&quot;&gt;navina&lt;/a&gt; I don&apos;t think I understand what you are saying. Is your objection that the error can be handled in two different threads? Is that a problem? Also, the producer has built in retries which will be a bit more efficient as they retry using the serialized data, do those not work?&lt;/p&gt;


</comment>
                            <comment id="14277973" author="criccomini" created="Thu, 15 Jan 2015 00:29:27 +0000"  >&lt;p&gt;Here&apos;s how Samza&apos;s KafkaSystemProducer currently works. We use a sync Kafka producer to send messages. We batch inside Samza&apos;s KafkaSystemProducer, so calling KafkaSystemProducer.send() prepends your message to a buffer inside the KafkaSystemProducer (we don&apos;t send it to the underlying Kafka producer at this point). When the buffer reaches some max (say, 200), the send() call will trigger a sync KafkaSystemProducer.flush() call, which will call send() on the underlying producer. Since the underlying kafka producer&apos;s send() call is blocking, any exception that occurs happens on the thread that&apos;s calling send(), so we just simply wrap the send() call in a try/catch. Flush is also called before Samza checkpoints its offsets, to make sure that any outstanding output is sent (so we don&apos;t lose data if there&apos;s a failure).&lt;/p&gt;

&lt;p&gt;Samza&apos;s KafkaSystemProducer is currently setup to retry forever, no matter what, when sends to Kafka fail. It waits 10s, and retries. This behavior has come in handy in scenarios where we have (un)expected downtime or cluster maintenance on a Kafka grid. When the grid&apos;s offline, we don&apos;t want 50 Samza jobs to kill themselves. We just want them to chill out until the grid&apos;s back.&lt;/p&gt;

&lt;p&gt;This strategy has some drawbacks, though. &lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;The KafkaSystemProducer.flush() call is blocking. This hurts throughput. Sometimes, quite severely.&lt;/li&gt;
	&lt;li&gt;Some exceptions are never going to get better. Retrying doesn&apos;t make sense in this case.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;When we upgrade to the new Producer, we want to address these issues. For (1), the new producer everything is async, so that gets fixed automatically. For (2), we&apos;d like to only retry with RetriableException, and fail for the rest.&lt;/p&gt;

&lt;p&gt;The trick is, if the sends are no longer sync, we have to have a mechanism by which we can verify that all outstanding messages have been successfully sent before we return.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;send()
send()
send()
flush() &lt;span class=&quot;code-comment&quot;&gt;// when &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; returns, all messages must be in Kafka.. inflight must be 0 and buffer must be 0&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The naive approach would be to just hold on to a future for each send() call, and stuff it in a list. When flush is invoked, simply iterate over the list, and call Future.get(). The confusing thing with this approach is what to do if Future.get() tells us that there was an exception when the message send was attempted. It seems that re-sending the message at this point would result in out of order messages. Is that correct?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;send() &lt;span class=&quot;code-comment&quot;&gt;// success
&lt;/span&gt;send() &lt;span class=&quot;code-comment&quot;&gt;// failed
&lt;/span&gt;send() &lt;span class=&quot;code-comment&quot;&gt;// enqueued
&lt;/span&gt;flush()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the above example, if we call Future.get() on the second send()&apos;s future, and we see it&apos;s a failure, the third send() could have already happened. In this case, if we re-send the failed message, then we get the third message before the second, right?&lt;/p&gt;

&lt;p&gt;Another oddity of this approach is that it seems we would have to double-buffer the messages in order to resend them, since RecordMetadata doesn&apos;t have the actual message that we sent. In order to re-send, we&apos;d have to keep the message in a buffer in KafkaSystemProducer, along with its future, until the Future.get() returns successfully.&lt;/p&gt;

&lt;p&gt;We then thought that we would set:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;retries=2000000000
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;At this point, we thought that the producer would re-send forever from the send thread, which is pretty much what we wanted in the case of a failure. But then we realized that if we had multiple in-flight requests, this could lead to out of order messages, so we forced:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;max.in.flight.requests.per.connection=1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So at this point, we believe that any message that gets into the send thread will be guaranteed to be sent, and in the right order, always.&lt;/p&gt;

&lt;p&gt;But, talking with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt;, it sounds like there are some cases where ApiExceptions are thrown from the main thread, not the send thread. In this case, it seems that our &lt;tt&gt;retries&lt;/tt&gt; setting has no effect, because the message hasn&apos;t even made it into the queue for the send thread yet. So, if an exception is thrown in the main thread, we seem to have to catch the RetriableException that&apos;s thrown, and re-send the message.&lt;/p&gt;

&lt;p&gt;This is the current implementation that &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=navina&quot; class=&quot;user-hover&quot; rel=&quot;navina&quot;&gt;navina&lt;/a&gt; is working on. Part of me is thinking, &quot;This can&apos;t be right. We must be misunderstanding something.&quot; So, I 1) want to confirm that we&apos;re not misunderstanding anything, and 2) see if there is a better way to accomplish what we want:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Async sends.&lt;/li&gt;
	&lt;li&gt;A &quot;flush&quot; mechanism that blocks until all messages have been sent to Kafka.&lt;/li&gt;
	&lt;li&gt;In-order retries when a RetriableFailure occurs.&lt;/li&gt;
	&lt;li&gt;Forward a non-RetriableException when it occurs.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;I&apos;m pretty confident that my mental model is broken, so any help correcting it would be appreciated. Also, any tips on a better way to accomplish what we want would be appreciated.&lt;/p&gt;</comment>
                            <comment id="14278024" author="guozhang" created="Thu, 15 Jan 2015 01:03:38 +0000"  >&lt;p&gt;My original motivation of this ticket is to make it more clear to the users about &quot;when&quot; does &quot;which&quot; exception can possibly be thrown, and upon catching them &quot;what&quot; could be done. With that in mind I was thinking the following things can be done here:&lt;/p&gt;

&lt;p&gt;1) rename OffsetMetadataTooLarge to OffsetMetadataTooLargeException.&lt;br/&gt;
2) document for each exception thrown from producer.send, are they retriable or fatal (today only BufferExhausted are retriable).&lt;br/&gt;
3) document for each exception thrown in future, user can tell what to do based on the exception type (extended from RetriableException or not).&lt;/p&gt;

&lt;p&gt;For concrete use cases like Chris/Navina&apos;s, we can also document about the semantics of the thrown exceptions such as 1) did the exception cause the whole batch to fail, 2) does it possibly cause out-of-order and how it is related to pipelining scheme / in-flight requests, 3) etc...&lt;/p&gt;</comment>
                            <comment id="14278104" author="jkreps" created="Thu, 15 Jan 2015 02:08:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt; Makes sense. You&apos;re correct that the docs on this suck, the send method doesn&apos;t even list the exceptions it throws so there is no way to figure this out except by reading the code.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=criccomini&quot; class=&quot;user-hover&quot; rel=&quot;criccomini&quot;&gt;criccomini&lt;/a&gt; Your understanding is correct. Setting max.in.flight.requests.per.connection=1 and retries=infinity should give you what you want.&lt;/p&gt;

&lt;p&gt;send() can throw exceptions in certain cases. Specifically if:&lt;br/&gt;
1. The serialization of the message fails.&lt;br/&gt;
2. You time out waiting for metadata about the cluster/topic on the very first request&lt;br/&gt;
3. You configure the client to fail rather than block if it&apos;s internal queue is full and the internal queue is full&lt;br/&gt;
4. You set a partition on the ProducerRecord which is invalid (i.e. larger than the largest) and various other IllegalArgumentExceptions&lt;/p&gt;

&lt;p&gt;I think none of these should be an issue since (1) is a bug, (2) should be configured to infinite for you, (3) you won&apos;t do, and (4) is a bug.&lt;/p&gt;

&lt;p&gt;The mental model here is that we throw the exception directly if we can&apos;t even enqueue the message. &lt;/p&gt;

&lt;p&gt;The next question is, great, you have given me information about each individual send but how can I know that all my stuff is sent correctly. The easiest thing here would be to hang on to all the futures and just call get on them as you suggest.&lt;/p&gt;

&lt;p&gt;So I think the take aways are:&lt;br/&gt;
1. We need to document the errors (and rename that one)&lt;br/&gt;
2. We need to document the retry behavior with multiple in-flight requests&lt;br/&gt;
3. It might be nice to add a flush() call that waits for all the currently buffered or in-flight requests to complete assuming this doesn&apos;t add inefficiency in the normal case.&lt;/p&gt;




</comment>
                            <comment id="14278107" author="criccomini" created="Thu, 15 Jan 2015 02:10:20 +0000"  >&lt;blockquote&gt;&lt;p&gt;It might be nice to add a flush() call that waits for all the currently buffered or in-flight requests to complete assuming this doesn&apos;t add inefficiency in the normal case.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1 This would be very helpful.&lt;/p&gt;</comment>
                            <comment id="14278113" author="criccomini" created="Thu, 15 Jan 2015 02:17:30 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jkreps&quot; class=&quot;user-hover&quot; rel=&quot;jkreps&quot;&gt;jkreps&lt;/a&gt;, so it sounds like we can fail our containers on all exceptions that we see, and rely on retries=2000000000 to handle all RetriableExceptions, correct?&lt;/p&gt;</comment>
                            <comment id="14278116" author="jkreps" created="Thu, 15 Jan 2015 02:17:35 +0000"  >&lt;p&gt;Cool, filed &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1865&quot; title=&quot;Add a flush() call to the new producer API&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1865&quot;&gt;&lt;del&gt;KAFKA-1865&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14288327" author="navina" created="Thu, 22 Jan 2015 22:19:23 +0000"  >&lt;p&gt;As a part of the documentation, can you also add a comparison table for the configuration variables between the old and new Kafka versions of the Kafka Producer? It can probably be part of a separate document which describes the differences between the old and new producer design. If such a document already exists, please let me know!&lt;/p&gt;</comment>
                            <comment id="14347338" author="guozhang" created="Wed, 4 Mar 2015 18:39:20 +0000"  >&lt;p&gt;Created reviewboard &lt;a href=&quot;https://reviews.apache.org/r/31735/diff/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.apache.org/r/31735/diff/&lt;/a&gt;&lt;br/&gt;
 against branch origin/trunk&lt;/p&gt;</comment>
                            <comment id="14347342" author="guozhang" created="Wed, 4 Mar 2015 18:40:57 +0000"  >&lt;p&gt;Add some more docs in the possible exception hierarchy, with this and Jay&apos;s modified throws exception in send() I think this ticket can be covered.&lt;/p&gt;</comment>
                            <comment id="14361191" author="guozhang" created="Fri, 13 Mar 2015 22:17:57 +0000"  >&lt;p&gt;Added the docs accordingly, closing this ticket for now.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12706818">SAMZA-227</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12767631">KAFKA-1865</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12702577" name="KAFKA-1863.patch" size="9280" author="guozhang" created="Wed, 4 Mar 2015 18:39:20 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 36 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i24djz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>