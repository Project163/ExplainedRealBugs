<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:02:25 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-5413] Log cleaner fails due to large offset in segment file</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-5413</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;The log cleaner thread in our brokers is failing with the trace below&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[2017-06-08 15:49:54,822] INFO {kafka-log-cleaner-thread-0} Cleaner 0: Cleaning segment 0 in log __consumer_offsets-12 (largest timestamp Thu Jun 08 15:48:59 PDT 2017) into 0, retaining deletes. (kafka.log.LogCleaner)
[2017-06-08 15:49:54,822] INFO {kafka-log-cleaner-thread-0} Cleaner 0: Cleaning segment 2147343575 in log __consumer_offsets-12 (largest timestamp Thu Jun 08 15:49:06 PDT 2017) into 0, retaining deletes. (kafka.log.LogCleaner)
[2017-06-08 15:49:54,834] ERROR {kafka-log-cleaner-thread-0} [kafka-log-cleaner-thread-0], Error due to  (kafka.log.LogCleaner)
java.lang.IllegalArgumentException: requirement failed: largest offset in message set can not be safely converted to relative offset.
        at scala.Predef$.require(Predef.scala:224)
        at kafka.log.LogSegment.append(LogSegment.scala:109)
        at kafka.log.Cleaner.cleanInto(LogCleaner.scala:478)
        at kafka.log.Cleaner$$anonfun$cleanSegments$1.apply(LogCleaner.scala:405)
        at kafka.log.Cleaner$$anonfun$cleanSegments$1.apply(LogCleaner.scala:401)
        at scala.collection.immutable.List.foreach(List.scala:381)
        at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:401)
        at kafka.log.Cleaner$$anonfun$clean$4.apply(LogCleaner.scala:363)
        at kafka.log.Cleaner$$anonfun$clean$4.apply(LogCleaner.scala:362)
        at scala.collection.immutable.List.foreach(List.scala:381)
        at kafka.log.Cleaner.clean(LogCleaner.scala:362)
        at kafka.log.LogCleaner$CleanerThread.cleanOrSleep(LogCleaner.scala:241)
        at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:220)
        at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)
[2017-06-08 15:49:54,835] INFO {kafka-log-cleaner-thread-0} [kafka-log-cleaner-thread-0], Stopped  (kafka.log.LogCleaner)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This seems to point at the specific line &lt;a href=&quot;https://github.com/apache/kafka/blob/0.11.0/core/src/main/scala/kafka/log/LogSegment.scala#L92&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt; in the kafka src where the difference is actually larger than MAXINT as both baseOffset and offset are of type long. It was introduced in this &lt;a href=&quot;https://github.com/apache/kafka/pull/2210/files/56d1f8196b77a47b176b7bbd1e4220a3be827631&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;pr&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;These were the outputs of dumping the first two log segments&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;:~$ /usr/bin/kafka-run-class kafka.tools.DumpLogSegments --deep-iteration --files /kafka-logs/__consumer_offsets-12/000
00000000000000000.log
Dumping /kafka-logs/__consumer_offsets-12/00000000000000000000.log
Starting offset: 0
offset: 1810054758 position: 0 NoTimestampType: -1 isvalid: true payloadsize: -1 magic: 0 compresscodec: NONE crc: 3127861909 keysize: 34

:~$ /usr/bin/kafka-run-class kafka.tools.DumpLogSegments --deep-iteration --files /kafka-logs/__consumer_offsets-12/000
00000002147343575.log
Dumping /kafka-logs/__consumer_offsets-12/00000000002147343575.log
Starting offset: 2147343575
offset: 2147539884 position: 0 NoTimestampType: -1 isvalid: true paylo
adsize: -1 magic: 0 compresscodec: NONE crc: 2282192097 keysize: 34
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;My guess is that since 2147539884 is larger than MAXINT, we are hitting this exception. Was there a specific reason, this check was added in 0.10.2?&lt;/p&gt;

&lt;p&gt;E.g. if the first offset is a key = &quot;key 0&quot; and then we have MAXINT + 1 of &quot;key 1&quot; following, wouldn&apos;t we run into this situation whenever the log cleaner runs?&lt;/p&gt;</description>
                <environment>Ubuntu 14.04 LTS, Oracle Java 8u92, kafka_2.11-0.10.2.0</environment>
        <key id="13078470">KAFKA-5413</key>
            <summary>Log cleaner fails due to large offset in segment file</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="Kelvinrutt">Kelvin Rutt</assignee>
                                    <reporter username="ny2ko">Nicholas Ngorok</reporter>
                        <labels>
                            <label>reliability</label>
                    </labels>
                <created>Thu, 8 Jun 2017 23:43:08 +0000</created>
                <updated>Tue, 8 Oct 2019 10:39:59 +0000</updated>
                            <resolved>Wed, 21 Jun 2017 01:03:10 +0000</resolved>
                                    <version>0.10.2.0</version>
                    <version>0.10.2.1</version>
                                    <fixVersion>0.10.2.2</fixVersion>
                    <fixVersion>0.11.0.0</fixVersion>
                                    <component>core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>22</watches>
                                                                                                                <comments>
                            <comment id="16044555" author="federico giraud" created="Fri, 9 Jun 2017 15:39:11 +0000"  >&lt;p&gt;More details (I&apos;m investigating the same issue in the same company): the problem seems to be exactly what is described in &lt;a href=&quot;https://github.com/apache/kafka/pull/2210/files/56d1f8196b77a47b176b7bbd1e4220a3be827631#r91192806&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;this comment on the PR&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Debugger output:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;kafka-log-cleaner-thread-0[7] where
  [7] kafka.log.Cleaner.cleanSegments (LogCleaner.scala:401)
  [8] kafka.log.Cleaner$$anonfun$clean$4.apply (LogCleaner.scala:363)
  [9] kafka.log.Cleaner$$anonfun$clean$4.apply (LogCleaner.scala:362)
  [10] scala.collection.immutable.List.foreach (List.scala:381)
  [11] kafka.log.Cleaner.clean (LogCleaner.scala:362)
  [12] kafka.log.LogCleaner$CleanerThread.cleanOrSleep (LogCleaner.scala:241)
  [13] kafka.log.LogCleaner$CleanerThread.doWork (LogCleaner.scala:220)
  [14] kafka.utils.ShutdownableThread.run (ShutdownableThread.scala:63)
kafka-log-cleaner-thread-0[7] print segments
 segments = &lt;span class=&quot;code-quote&quot;&gt;&quot;List(LogSegment(baseOffset=0, size=18527), LogSegment(baseOffset=2147343575, size=60))&quot;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16044637" author="ijuma" created="Fri, 9 Jun 2017 16:27:39 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16044669" author="junrao" created="Fri, 9 Jun 2017 16:49:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ny2ko&quot; class=&quot;user-hover&quot; rel=&quot;ny2ko&quot;&gt;ny2ko&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Federico+Giraud&quot; class=&quot;user-hover&quot; rel=&quot;Federico Giraud&quot;&gt;Federico Giraud&lt;/a&gt;, thanks for the reporting this issue. In LogCleaner.groupSegmentsBySize(), we try to groups segments with the following check.&lt;br/&gt;
   segs.head.index.lastOffset - group.last.index.baseOffset &amp;lt;= Int.MaxValue&lt;/p&gt;

&lt;p&gt;The intention is that if 2 segments&apos;s offset differ by more than Int.MaxValue, they will be put into different groups and therefore won&apos;t be writing to the same output segment. So, I am not sure why the grouping didn&apos;t happen.&lt;/p&gt;

&lt;p&gt;Do you think you could get the value of index.lastOffset and index.baseOffset of these 2 segments in the debugger? Alternatively, if you could upload the 2 log segments (with both the log and the index files) with base offset 0 and 2147343575 to the jira, we can take a look of that locally.&lt;/p&gt;</comment>
                            <comment id="16045572" author="junrao" created="Sat, 10 Jun 2017 15:22:22 +0000"  >&lt;p&gt;Could you attach the .index file of the 2 segments too?&lt;/p&gt;</comment>
                            <comment id="16046845" author="ny2ko" created="Mon, 12 Jun 2017 17:55:25 +0000"  >&lt;p&gt;I&apos;ve uploaded all files pertaining to the two segments. In both cases the .index files are zero bytes and couldn&apos;t be uploaded&lt;/p&gt;</comment>
                            <comment id="16046913" author="federico giraud" created="Mon, 12 Jun 2017 18:36:38 +0000"  >&lt;p&gt;Please let us know if you need any additional information that could help debugging the issue. We had to rollback the cluster to 0.9 but we would like to move to the new version.&lt;/p&gt;</comment>
                            <comment id="16046960" author="kelvinrutt" created="Mon, 12 Jun 2017 19:16:27 +0000"  >&lt;p&gt;I&apos;ve just had this issue myself. The problem is that when the index file size is 0 the actual last offset in the .log file is not reported. It uses the baseoffset.  This causes the group segments to incorrectly group the segments.&lt;br/&gt;
The log compaction uses the actual offsets from the log file which are often too large a range to fit into a single segment hitting the require statement.&lt;br/&gt;
The fix is to ensure that the correct last offset is always reported.&lt;/p&gt;

&lt;p&gt;This is more apparent with heavily compacted topics where the last offset can be much larger than the base offset.&lt;/p&gt;</comment>
                            <comment id="16048394" author="ny2ko" created="Tue, 13 Jun 2017 20:57:10 +0000"  >&lt;p&gt;This happened again today on another cluster we had upgraded ~3 weeks ago. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt; could you please suggest a workaround if it exists to tackle this issue? It is a high priority for us since log cleaner threads and in turn compaction have stopped.&lt;/p&gt;</comment>
                            <comment id="16048429" author="junrao" created="Tue, 13 Jun 2017 21:29:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Kelvinrutt&quot; class=&quot;user-hover&quot; rel=&quot;Kelvinrutt&quot;&gt;Kelvinrutt&lt;/a&gt;, yes, that seems to be the issue. segs.head.index.lastOffset doesn&apos;t give the precise last offset in the segment, especially in the case where the index is empty. The issue seems to be there even in 0.9.0.&lt;/p&gt;

&lt;p&gt;About the fix. LogSegment.nextOffset() gives the offset that we want, but can be expensive. Perhaps we could use the next segment&apos;s base offset instead. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Kelvinrutt&quot; class=&quot;user-hover&quot; rel=&quot;Kelvinrutt&quot;&gt;Kelvinrutt&lt;/a&gt;, do you think you could patch it?&lt;/p&gt;

&lt;p&gt;Until this is fixed, not sure if there is an easy way to get around the issue.&lt;/p&gt;</comment>
                            <comment id="16048547" author="kelvinrutt" created="Wed, 14 Jun 2017 00:18:31 +0000"  >&lt;p&gt;This is the patch I did.  It&apos;s basic but does the job.&lt;/p&gt;</comment>
                            <comment id="16049239" author="junrao" created="Wed, 14 Jun 2017 14:39:24 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Kelvinrutt&quot; class=&quot;user-hover&quot; rel=&quot;Kelvinrutt&quot;&gt;Kelvinrutt&lt;/a&gt;, thanks for the patch. We normally contribute code through git pull requests (see details &lt;a href=&quot;http://kafka.apache.org/contributing&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://kafka.apache.org/contributing&lt;/a&gt;) to make the review and testing easy. Do you think you could submit a git PR instead? Thanks,&lt;/p&gt;</comment>
                            <comment id="16049440" author="kelvinrutt" created="Wed, 14 Jun 2017 17:57:55 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt;, no problem. It might be a couple of days before I can do this. It seems my patch makes the symptoms less likely but doesn&apos;t fix the problem.  We need to ensure the last index is always written to the .index file because log.index.interval.bytes is preventing this. &lt;br/&gt;
I still see the issue even when the .index file is not zero length.&lt;/p&gt;</comment>
                            <comment id="16051273" author="junrao" created="Fri, 16 Jun 2017 01:35:34 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Kelvinrutt&quot; class=&quot;user-hover&quot; rel=&quot;Kelvinrutt&quot;&gt;Kelvinrutt&lt;/a&gt;, yes, getting the last offset from the index won&apos;t be reliable since the last offset is not guaranteed to be in the index. We can probably just use (the base offset of the next segment - 1) as the last Offset for the current segment. The next segment should always exist since the last segment will never be cleaned.&lt;/p&gt;</comment>
                            <comment id="16052247" author="githubbot" created="Fri, 16 Jun 2017 18:41:39 +0000"  >&lt;p&gt;GitHub user kelvinrutt opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/3357&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3357&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5413&quot; title=&quot;Log cleaner fails due to large offset in segment file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5413&quot;&gt;&lt;del&gt;KAFKA-5413&lt;/del&gt;&lt;/a&gt;: Log cleaner fails due to large offset in segment file&lt;/p&gt;

&lt;p&gt;    the contribution is my original work and I license the work to the project under the project&apos;s open source license.&lt;/p&gt;

&lt;p&gt;    @junrao , I had already made the code change before your last comment.  I&apos;ve done pretty much what you said, except that I&apos;ve not used the current segment because I wasn&apos;t sure if it will always be available.&lt;br/&gt;
    I&apos;m happy to change it if you prefer.&lt;br/&gt;
    I&apos;ve run all the unit and integration tests which all passed.&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/kelvinrutt/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/kelvinrutt/kafka&lt;/a&gt; kafka_5413_bugfix&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/3357.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3357.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #3357&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 85d7024ea6bc67328a59b5cae3078fd4138df33f&lt;br/&gt;
Author: Kelvin Rutt &amp;lt;ruttkelvin@gmail.com&amp;gt;&lt;br/&gt;
Date:   2017-06-15T14:34:04Z&lt;/p&gt;

&lt;p&gt;    Fix problem with log cleaner where index under reports&lt;/p&gt;

&lt;p&gt;commit 1adcc8a04af56a02efbeb90874e0545036c1a316&lt;br/&gt;
Author: Kelvin Rutt &amp;lt;ruttkelvin@gmail.com&amp;gt;&lt;br/&gt;
Date:   2017-06-15T15:34:28Z&lt;/p&gt;

&lt;p&gt;    Add comments and remove some unwanted code&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="16056761" author="githubbot" created="Wed, 21 Jun 2017 01:01:56 +0000"  >&lt;p&gt;Github user asfgit closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/3357&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3357&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16056764" author="junrao" created="Wed, 21 Jun 2017 01:03:10 +0000"  >&lt;p&gt;Issue resolved by pull request 3357&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/pull/3357&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3357&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16057900" author="githubbot" created="Wed, 21 Jun 2017 17:40:28 +0000"  >&lt;p&gt;GitHub user kelvinrutt opened a pull request:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/3397&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3397&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5413&quot; title=&quot;Log cleaner fails due to large offset in segment file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5413&quot;&gt;&lt;del&gt;KAFKA-5413&lt;/del&gt;&lt;/a&gt;: Port fix to 0.10.2 branch&lt;/p&gt;

&lt;p&gt;    Port &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5413&quot; title=&quot;Log cleaner fails due to large offset in segment file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5413&quot;&gt;&lt;del&gt;KAFKA-5413&lt;/del&gt;&lt;/a&gt; to the 0.10.2 branch&lt;/p&gt;

&lt;p&gt;You can merge this pull request into a Git repository by running:&lt;/p&gt;

&lt;p&gt;    $ git pull &lt;a href=&quot;https://github.com/kelvinrutt/kafka&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/kelvinrutt/kafka&lt;/a&gt; kafka_5413_port&lt;/p&gt;

&lt;p&gt;Alternatively you can review and apply these changes as the patch at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/3397.patch&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3397.patch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To close this pull request, make a commit to your master/trunk branch&lt;br/&gt;
with (at least) the following in the commit message:&lt;/p&gt;

&lt;p&gt;    This closes #3397&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;commit 82c7ce89f230bd08864d46abadbae0a2278c89dc&lt;br/&gt;
Author: Kelvin Rutt &amp;lt;ruttkelvin@gmail.com&amp;gt;&lt;br/&gt;
Date:   2017-06-21T17:34:18Z&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-5413&quot; title=&quot;Log cleaner fails due to large offset in segment file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-5413&quot;&gt;&lt;del&gt;KAFKA-5413&lt;/del&gt;&lt;/a&gt;: Port fix to 0.10.2 branch&lt;/p&gt;

&lt;hr /&gt;</comment>
                            <comment id="16063228" author="junrao" created="Mon, 26 Jun 2017 15:08:33 +0000"  >&lt;p&gt;Merged &lt;a href=&quot;https://github.com/apache/kafka/pull/3397&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3397&lt;/a&gt; to 0.10.2.&lt;/p&gt;</comment>
                            <comment id="16063514" author="ny2ko" created="Mon, 26 Jun 2017 17:57:40 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Kelvinrutt&quot; class=&quot;user-hover&quot; rel=&quot;Kelvinrutt&quot;&gt;Kelvinrutt&lt;/a&gt; for getting this solved very quickly! &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=junrao&quot; class=&quot;user-hover&quot; rel=&quot;junrao&quot;&gt;junrao&lt;/a&gt; is there a timeline/plans for the 0.10.2.2 release?&lt;/p&gt;</comment>
                            <comment id="16135218" author="mlesyk" created="Mon, 21 Aug 2017 14:18:26 +0000"  >&lt;p&gt;Also hit this issue, when could 0.10.2.2 expected to be released?&lt;/p&gt;</comment>
                            <comment id="16142103" author="githubbot" created="Fri, 25 Aug 2017 20:00:08 +0000"  >&lt;p&gt;Github user kelvinrutt closed the pull request at:&lt;/p&gt;

&lt;p&gt;    &lt;a href=&quot;https://github.com/apache/kafka/pull/3397&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/3397&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16250419" author="adamkeyser" created="Mon, 13 Nov 2017 22:42:52 +0000"  >&lt;p&gt;We are encountering this bug - Is 0.10.2.2 released? I don&apos;t see a link in the releases page.&lt;/p&gt;</comment>
                            <comment id="16263626" author="ijuma" created="Thu, 23 Nov 2017 00:46:12 +0000"  >&lt;p&gt;0.10.2.2 hasn&apos;t been released and there are no immediate plans to release it. Can you upgrade to 0.11.0.2 instead?&lt;/p&gt;</comment>
                            <comment id="16264945" author="plaflamme" created="Fri, 24 Nov 2017 05:49:54 +0000"  >&lt;p&gt;We&apos;re hitting the same problem and would like to upgrade to a 0.10.x version to reduce the workload and, more importantly, risks. According to &lt;a href=&quot;https://issues.apache.org/jira/projects/KAFKA/versions/12340570&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/projects/KAFKA/versions/12340570&lt;/a&gt; there are 19 bugs total, 2 of which are marked critical and 14 major.&lt;/p&gt;

&lt;p&gt;As far as I can tell, there is no workaround for this problem. Is this enough reason to go through a release cycle? I&apos;d like to provide some help, but obviously I can&apos;t do that for releasing. What are things that users like us can do to make a 0.10.2.2 release happen?&lt;/p&gt;</comment>
                            <comment id="16322759" author="noslowerdna" created="Thu, 11 Jan 2018 19:05:33 +0000"  >&lt;p&gt;We ran into this for a partition of the __consumer_offsets topic. The issue was discovered when we noticed that the open file count for a Kafka broker had been steadily growing for a couple months, and was about 2x higher than any other broker in the cluster. When we restarted this broker it seemed able to recover, deleting a large number of old log segments, with the open file count returning to a more normal value.&lt;/p&gt;</comment>
                            <comment id="16322832" author="plaflamme" created="Thu, 11 Jan 2018 19:40:16 +0000"  >&lt;p&gt;Yes, that&apos;s what happens when the log cleaner dies for any reason (the compacted logs are no longer compacted and will grow unbounded). The original issue has no workaround, meaning that the log cleaner will die again after restarting the broker...&lt;/p&gt;

&lt;p&gt;FWIW, we ended up upgrading to 0.11.x since there was clearly no intention on releasing 0.10.2.2.&lt;/p&gt;</comment>
                            <comment id="16322857" author="noslowerdna" created="Thu, 11 Jan 2018 19:58:32 +0000"  >&lt;p&gt;Thanks for the insight, we&apos;ll keep a watchful eye on it.&lt;/p&gt;</comment>
                            <comment id="16412346" author="brettrann" created="Sat, 24 Mar 2018 01:46:24 +0000"  >&lt;p&gt;Is this the same issue as was reported here? &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6056&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/KAFKA-6056&lt;/a&gt;&#160; (note the workaround we used, also)&lt;/p&gt;</comment>
                            <comment id="16413904" author="noslowerdna" created="Mon, 26 Mar 2018 14:12:47 +0000"  >&lt;blockquote&gt;&lt;p&gt;Is this the same issue as was reported here?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It sounds like a related issue, that may be more rare than what the correction for this one addressed, or a variant that eluded the bug fix here. The stack trace looks the same.&lt;/p&gt;</comment>
                            <comment id="16442121" author="davidpsv17" created="Wed, 18 Apr 2018 08:31:36 +0000"  >&lt;p&gt;Hi, I have the same problem and I&apos;m running 0.11.0.2.&lt;/p&gt;

&lt;p&gt;That is what appears in log-cleaner.log:&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;2018-04-18 10:00:32,918&amp;#93;&lt;/span&gt; INFO Cleaner 3: Cleaning log __consumer_offsets-13 (cleaning prior to Tue Mar 06 12:04:48 CET 2018, discarding tombstones prior to Tue Dec 19 19:33:28 CET 2017)... (kafka.log.LogCleaner)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2018-04-18 10:00:32,919&amp;#93;&lt;/span&gt; INFO Cleaner 3: Cleaning segment 0 in log __consumer_offsets-13 (largest timestamp Tue Dec 12 09:06:39 CET 2017) into 0, retaining deletes. (kafka.log.LogCleaner)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2018-04-18 10:00:32,954&amp;#93;&lt;/span&gt; ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-log-cleaner-thread-3&amp;#93;&lt;/span&gt;: Error due to (kafka.log.LogCleaner)&lt;br/&gt;
java.lang.IllegalArgumentException: requirement failed: largest offset in message set can not be safely converted to relative offset.&lt;br/&gt;
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at scala.Predef$.require(Predef.scala:224)&lt;br/&gt;
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at kafka.log.LogSegment.append(LogSegment.scala:121)&lt;br/&gt;
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at kafka.log.Cleaner.cleanInto(LogCleaner.scala:547)&lt;br/&gt;
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:443)&lt;br/&gt;
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:385)&lt;br/&gt;
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at kafka.log.Cleaner$$anonfun$doClean$4.apply(LogCleaner.scala:384)&lt;br/&gt;
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at scala.collection.immutable.List.foreach(List.scala:392)&lt;br/&gt;
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at kafka.log.Cleaner.doClean(LogCleaner.scala:384)&lt;br/&gt;
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at kafka.log.Cleaner.clean(LogCleaner.scala:361)&lt;br/&gt;
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at kafka.log.LogCleaner$CleanerThread.cleanOrSleep(LogCleaner.scala:256)&lt;br/&gt;
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:236)&lt;br/&gt;
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;2018-04-18 10:00:32,954&amp;#93;&lt;/span&gt; INFO &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-log-cleaner-thread-3&amp;#93;&lt;/span&gt;: Stopped (kafka.log.LogCleaner)&lt;/p&gt;

&lt;p&gt;Any suggestion?&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Thanks!!&lt;/p&gt;</comment>
                            <comment id="16444926" author="badai" created="Thu, 19 Apr 2018 22:43:21 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=davidpsv17&quot; class=&quot;user-hover&quot; rel=&quot;davidpsv17&quot;&gt;davidpsv17&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Did you just upgraded to 0.11.x when you hit this issue? If yes, it maybe related to &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6264&quot; title=&quot;Log cleaner thread may die on legacy segment containing messages whose offsets are too large&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6264&quot;&gt;&lt;del&gt;KAFKA-6264&lt;/del&gt;&lt;/a&gt;.&#160;&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;

&lt;p&gt;Badai&lt;/p&gt;</comment>
                            <comment id="16946698" author="navibrar" created="Tue, 8 Oct 2019 10:39:59 +0000"  >&lt;p&gt;Can we manually delete .index and .log files for that partition if we don&apos;t care about data loss as our consumer group is disbaled now, which was catered by the consumer offsets partition which is having this issue.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12872754" name="00000000000000000000.index.cleaned" size="10485760" author="ny2ko" created="Mon, 12 Jun 2017 17:53:59 +0000"/>
                            <attachment id="12872366" name="00000000000000000000.log" size="48894" author="ny2ko" created="Fri, 9 Jun 2017 22:32:27 +0000"/>
                            <attachment id="12872753" name="00000000000000000000.log.cleaned" size="48894" author="ny2ko" created="Mon, 12 Jun 2017 17:53:55 +0000"/>
                            <attachment id="12872752" name="00000000000000000000.timeindex.cleaned" size="10485756" author="ny2ko" created="Mon, 12 Jun 2017 17:53:58 +0000"/>
                            <attachment id="12872367" name="00000000002147422683.log" size="437" author="ny2ko" created="Fri, 9 Jun 2017 22:34:17 +0000"/>
                            <attachment id="12872912" name="kafka-5413.patch" size="1858" author="Kelvinrutt" created="Wed, 14 Jun 2017 00:17:10 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 6 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3g2c7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>