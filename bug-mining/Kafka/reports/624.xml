<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:42:41 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-1755] Improve error handling in log cleaner</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-1755</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;The log cleaner is a critical process when using compacted topics.&lt;br/&gt;
However, if there is any error in any topic (notably if a key is missing) then the cleaner exits and all other compacted topics will also be adversely affected - i.e., compaction stops across the board.&lt;/p&gt;

&lt;p&gt;This can be improved by just aborting compaction for a topic on any error and keep the thread from exiting.&lt;/p&gt;

&lt;p&gt;Another improvement would be to reject messages without keys that are sent to compacted topics although this is not enough by itself.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12753080">KAFKA-1755</key>
            <summary>Improve error handling in log cleaner</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jjkoshy">Joel Jacob Koshy</assignee>
                                    <reporter username="jjkoshy">Joel Jacob Koshy</reporter>
                        <labels>
                            <label>newbie++</label>
                    </labels>
                <created>Wed, 5 Nov 2014 16:15:38 +0000</created>
                <updated>Mon, 21 Dec 2015 19:22:47 +0000</updated>
                            <resolved>Mon, 21 Dec 2015 19:22:47 +0000</resolved>
                                                    <fixVersion>0.9.0.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="14198578" author="criccomini" created="Wed, 5 Nov 2014 16:20:56 +0000"  >&lt;p&gt;It might also be desirable to allow the log compaction to continue on the topic in question, and simply keep all messages without keys without doing any compaction on them.&lt;/p&gt;</comment>
                            <comment id="14216486" author="jjkoshy" created="Tue, 18 Nov 2014 17:42:52 +0000"  >&lt;p&gt;There are a couple of issues that I was thinking of in scope for this jira:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Log cleaner threads quitting on errors (which may be a non-issue as discussed further below).&lt;/li&gt;
	&lt;li&gt;Dealing with cleaner failures due to unkeyed messages.&lt;/li&gt;
	&lt;li&gt;Other cleaner failures are possible as well (for e.g., compressed message sets until &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1374&quot; title=&quot;LogCleaner (compaction) does not support compressed topics&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1374&quot;&gt;&lt;del&gt;KAFKA-1374&lt;/del&gt;&lt;/a&gt; is reviewed and checked-in)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The reason this jira was filed is because the log cleaner compacts all compacted topics so one topic should (ideally) not affect another. Any practical deployment would need to set up alerts on the cleaner thread dying. Right now, I think the most reliable way to alert (with the currently available metrics) would be to monitor the max-dirty-ratio. If we set up this alert, then allowing the cleaner to continue would in practice only delay an alert. So one can argue that it is better to fail fast - i.e., let the log cleaner die because a problematic topic is something that needs to be looked into immediately. However, I think there are further improvements with alternatives that can be made. It would be helpful if others can share their thoughts/preferences on these:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Introduce a new LogCleaningState: LogCleaningPausedDueToError&lt;/li&gt;
	&lt;li&gt;Introduce a metric for the number of live cleaner threads&lt;/li&gt;
	&lt;li&gt;If the log cleaner encounters any uncaught error, there are a couple of options:
	&lt;ul&gt;
		&lt;li&gt;Don&apos;t let the thread die, but move the partition to LogCleaningPausedDueToError. Other topics-partitions can still be compacted. Alerts can be set up on the number of partitions in state LogCleaningPausedDueToError.&lt;/li&gt;
		&lt;li&gt;Let the cleaner die and decrement live cleaner count. Alerts can be set up on the number of live cleaner threads.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;If the cleaner encounters un-keyed messages:
	&lt;ul&gt;
		&lt;li&gt;Delete those messages, and do nothing. i.e., ignore (or just log the count in log cleaner stats)&lt;/li&gt;
		&lt;li&gt;Keep the messages, move the partition to LogCleaningPausedDueToError.  The motivation for this is accidental misconfiguration. i.e., it may be important to not lose those messages. The error log cleaning state can be cleared only by deleting and then recreating the topic.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;Additionally, I think we should reject producer requests containing un-keyed messages to compacted topics.&lt;/li&gt;
	&lt;li&gt;With all of the above, a backup alert can also be set up on the max-dirty-ratio.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14234780" author="guozhang" created="Thu, 4 Dec 2014 23:23:41 +0000"  >&lt;p&gt;Here are my two cents:&lt;/p&gt;

&lt;p&gt;1. At the end of the day, Kafka will have two types of topics, one type only accepts keyed messages and log compaction is used; the other one accepts any message and log cleaning is used. Those two types of topics never exchange, i.e. once a topic is created with one of the two types, it will never change its type until deletion.&lt;/p&gt;

&lt;p&gt;2. Compressed message will be supported with log compaction, which will de-serialize the message set and re-serialize.&lt;/p&gt;

&lt;p&gt;3. With these two points in mind, I would suggest for now:&lt;br/&gt;
  a. Broker reject non-keyed messages for compacted topics.&lt;br/&gt;
  b. Broker reject compressed messages for compacted topics (this will be lifted after &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1374&quot; title=&quot;LogCleaner (compaction) does not support compressed topics&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1374&quot;&gt;&lt;del&gt;KAFKA-1374&lt;/del&gt;&lt;/a&gt; is checked in).&lt;br/&gt;
  c. With this, it should never happen that compactor thread encountering a non-keyed / compressed (this will be lifted after &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1374&quot; title=&quot;LogCleaner (compaction) does not support compressed topics&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1374&quot;&gt;&lt;del&gt;KAFKA-1374&lt;/del&gt;&lt;/a&gt;); if it happens, this would be a FATAL error and we should throw an exception and halt the server. It indicates some operations are needed and there are some code fixes before it can be restarted.&lt;/p&gt;</comment>
                            <comment id="14256890" author="jjkoshy" created="Tue, 23 Dec 2014 11:41:09 +0000"  >&lt;p&gt;Thanks for the comments. The issue with 3a is that once we do have compression support for compacted topics it will be very ugly to implement that check on message arrival. This is because we need to do a deep iteration on incoming messages to look at the key field. The only time we do that currently on the broker is when assigning offsets. However, this code is in ByteBufferMessageSet which is fairly low-level and has no log-config information associated with it. We would have to &quot;leak&quot; some flag indicating whether non-keyed messages are allowed or not which is ugly. That is why I prefer not doing that check on message arrival and just have the log cleaner drop/ignore non-keyed messages with a warning. Ultimately, the effect is the same. However, the benefit of rejecting is that the producer is made aware of it. So I guess I changed my mind with regard to my earlier comment - i.e., I would recommend against doing this unless we can think of an elegant implementation. 3b is easy to do and we can implement that until &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-1374&quot; title=&quot;LogCleaner (compaction) does not support compressed topics&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-1374&quot;&gt;&lt;del&gt;KAFKA-1374&lt;/del&gt;&lt;/a&gt; is in place.&lt;/p&gt;</comment>
                            <comment id="14257268" author="jkreps" created="Tue, 23 Dec 2014 17:52:49 +0000"  >&lt;p&gt;Rejecting messages without a key doesn&apos;t actually solve the problem, I think as you can change the retention setting of a topic to compaction later at which point there may already be null keys.&lt;/p&gt;

&lt;p&gt;Perhaps the most consistent thing to do would actually be to treat null as a key value. So the cleaner would retain a single null value and remove the others. &lt;/p&gt;</comment>
                            <comment id="14333360" author="jjkoshy" created="Mon, 23 Feb 2015 14:43:12 +0000"  >&lt;p&gt;Created reviewboard &lt;a href=&quot;https://reviews.apache.org/r/31306/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.apache.org/r/31306/&lt;/a&gt;&lt;br/&gt;
 against branch origin/trunk&lt;/p&gt;</comment>
                            <comment id="14333387" author="jjkoshy" created="Mon, 23 Feb 2015 15:23:37 +0000"  >&lt;p&gt;I thought a bit more about this and here is a patch that summarizes my thoughts.&lt;/p&gt;

&lt;p&gt;This patch does message validation on arrival, and drops unkeyed messages during log compaction.&lt;/p&gt;

&lt;p&gt;I actually think it is better to reject invalid messages (unkeyed and for now compressed) up front as opposed to accepting those messages and only dropping/warning during compaction. This way the producer is given early indication via a client-side error that it is doing something wrong which is better than just a broker-side warning/invalid metric. We still need to deal with unkeyed messages that may already be in the log but that is orthogonal I think - this includes the case when you change a non-compacted topic to be compacted. That  is perhaps an invalid operation - i.e., you should ideally delete the topic before doing that, but in any event this patch handles that case by deleting invalid messages during log compaction.&lt;/p&gt;

&lt;p&gt;Case in point: at LinkedIn we use Kafka-based offset management for some of our consumers. We recently discovered compressed messages in the offsets topic which caused the log cleaner to quit. We saw this issue in the past with Samza checkpoint topics and suspected that  Samza was doing something wrong. However, after seeing it in the __consumer_offsets topic it is more likely to be an actual bug in the broker - either in the log cleaner itself, or even at the lower level byte-buffer message set API level. We currently do not know. If we at least reject invalid messages on arrival we can rule out clients as being the issue.&lt;/p&gt;</comment>
                            <comment id="14333389" author="jjkoshy" created="Mon, 23 Feb 2015 15:25:20 +0000"  >&lt;p&gt;Also, I have an incremental patch that prevents the log cleaner from quitting due to uncaught errors while cleaning a specific partition. It basically moves that partition to a permanent failed state and allows the cleaner to continue compacting other partitions. It      continues to include the failed partition when computing the max dirty ratio so you can still accurately alert on that metric. We can discuss whether we want to add that or not.&lt;/p&gt;</comment>
                            <comment id="14334000" author="jjkoshy" created="Mon, 23 Feb 2015 22:30:03 +0000"  >&lt;p&gt;Updated reviewboard &lt;a href=&quot;https://reviews.apache.org/r/31306/diff/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.apache.org/r/31306/diff/&lt;/a&gt;&lt;br/&gt;
 against branch origin/trunk&lt;/p&gt;</comment>
                            <comment id="14338907" author="jjkoshy" created="Thu, 26 Feb 2015 18:54:58 +0000"  >&lt;p&gt;Updated reviewboard &lt;a href=&quot;https://reviews.apache.org/r/31306/diff/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.apache.org/r/31306/diff/&lt;/a&gt;&lt;br/&gt;
 against branch origin/trunk&lt;/p&gt;</comment>
                            <comment id="15066928" author="gwenshap" created="Mon, 21 Dec 2015 19:22:47 +0000"  >&lt;p&gt;This was in fact committed to trunk and is in 0.9.0.0:&lt;/p&gt;

&lt;p&gt;commit 1cd6ed9e2c07a63474ed80a8224bd431d5d4243c  Joel Koshy committed on Mar 3&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/commit/1cd6ed9e2c07a63474ed80a8224bd431d5d4243c#diff-d7330411812d23e8a34889bee42fedfe&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/commit/1cd6ed9e2c07a63474ed80a8224bd431d5d4243c#diff-d7330411812d23e8a34889bee42fedfe&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12732915">KAFKA-1581</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12700201" name="KAFKA-1755.patch" size="36660" author="jjkoshy" created="Mon, 23 Feb 2015 14:43:11 +0000"/>
                            <attachment id="12700276" name="KAFKA-1755_2015-02-23_14:29:54.patch" size="40160" author="jjkoshy" created="Mon, 23 Feb 2015 22:30:02 +0000"/>
                            <attachment id="12701143" name="KAFKA-1755_2015-02-26_10:54:50.patch" size="43610" author="jjkoshy" created="Thu, 26 Feb 2015 18:54:58 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 48 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22067:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Reviewer</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>jkreps</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>