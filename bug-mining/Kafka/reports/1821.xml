<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:06:46 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6529] Broker leaks memory and file descriptors after sudden client disconnects</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6529</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;If a producer forcefully disconnects from a broker while it has staged receives, that connection enters a limbo state where it is no longer processed by the SocketServer.Processor, leaking the file descriptor for the socket and the memory used for the staged recieve queue for that connection.&lt;/p&gt;

&lt;p&gt;We noticed this during an upgrade from 0.9.0.2 to 0.11.0.2. Immediately after the rolling restart to upgrade, open file descriptors on the brokers started climbing uncontrollably. In a few cases brokers reached our configured max open files limit of 100k and crashed before we rolled back.&lt;/p&gt;

&lt;p&gt;We tracked this down to a buildup of muted connections in the Selector.closingChannels list. If a client disconnects from the broker with multiple pending produce requests, when the broker attempts to send an ack to the client it recieves an IOException because the TCP socket has been closed. This triggers the Selector to close the channel, but because it still has pending requests, it adds it to Selector.closingChannels to process those requests. However, because that exception was triggered by trying to send a response, the SocketServer.Processor has marked the channel as muted and will no longer process it at all.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Reproduced by:&lt;/b&gt;&lt;br/&gt;
Starting a Kafka broker/cluster&lt;br/&gt;
Client produces several messages and then disconnects abruptly (eg. &lt;em&gt;./rdkafka_performance -P -x 100 -b broker:9092 -t test_topic&lt;/em&gt;)&lt;br/&gt;
Broker then leaks file descriptor previously used for TCP socket and memory for unprocessed messages&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Proposed solution (which we&apos;ve implemented internally)&lt;/b&gt;&lt;br/&gt;
Whenever an exception is encountered when writing to a socket in Selector.pollSelectionKeys(...) record that that connection failed a send by adding the KafkaChannel ID to Selector.failedSends. Then re-raise the exception to still trigger the socket disconnection logic. Since every exception raised in this function triggers a disconnect, we also treat any exception while writing to the socket as a failed send.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13135912">KAFKA-6529</key>
            <summary>Broker leaks memory and file descriptors after sudden client disconnects</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="gcampbell">Graham Campbell</reporter>
                        <labels>
                    </labels>
                <created>Fri, 2 Feb 2018 22:56:56 +0000</created>
                <updated>Sat, 4 Apr 2020 15:10:26 +0000</updated>
                            <resolved>Fri, 9 Feb 2018 15:14:59 +0000</resolved>
                                    <version>0.11.0.2</version>
                    <version>1.0.0</version>
                                    <fixVersion>0.11.0.3</fixVersion>
                    <fixVersion>1.0.1</fixVersion>
                    <fixVersion>1.1.0</fixVersion>
                                    <component>network</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>14</watches>
                                                                                                                <comments>
                            <comment id="16351042" author="githubbot" created="Fri, 2 Feb 2018 23:03:45 +0000"  >&lt;p&gt;parafiend opened a new pull request #4517: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6529&quot; title=&quot;Broker leaks memory and file descriptors after sudden client disconnects&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6529&quot;&gt;&lt;del&gt;KAFKA-6529&lt;/del&gt;&lt;/a&gt;: Stop file descriptor leak when client disconnects with staged receives&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4517&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4517&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   If an exception is encountered while sending data to a client&lt;br/&gt;
   connection, that connection is disconnected. If there are staged&lt;br/&gt;
   receives for that connection, it is tracked to process those records.&lt;br/&gt;
   However, if the exception was encountered during processing a&lt;br/&gt;
   `RequestChannel.Request`, the `KafkaChannel` for that connection is&lt;br/&gt;
   muted and won&apos;t be processed.&lt;/p&gt;

&lt;p&gt;   Add the channel to failed sends so the connection is cleaned up on those&lt;br/&gt;
   exceptions. This stops the leak of the memory for pending requests&lt;br/&gt;
   and the file descriptor of the TCP socket.&lt;/p&gt;

&lt;p&gt;   Only flag channel as failed send when an exception is encountered while&lt;br/&gt;
   actually attempting to send something. Other socket interactions don&apos;t&lt;br/&gt;
   count.&lt;/p&gt;

&lt;p&gt;   Test that a channel is closed when an exception is raised while writing to&lt;br/&gt;
   a socket that has been closed by the client. Since sending a response &lt;br/&gt;
   requires acks != 0, allow specifying the required acks for test requests&lt;br/&gt;
   in SocketServerTest.scala.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16357015" author="damianguy" created="Thu, 8 Feb 2018 14:47:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt; should this go in to 1.1?&lt;/p&gt;</comment>
                            <comment id="16357626" author="ijuma" created="Thu, 8 Feb 2018 21:50:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=damianguy&quot; class=&quot;user-hover&quot; rel=&quot;damianguy&quot;&gt;damianguy&lt;/a&gt; Yes, I think the PR should be merged today or tomorrow. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rsivaram&quot; class=&quot;user-hover&quot; rel=&quot;rsivaram&quot;&gt;rsivaram&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hachikuji&quot; class=&quot;user-hover&quot; rel=&quot;hachikuji&quot;&gt;hachikuji&lt;/a&gt; are on it.&lt;/p&gt;</comment>
                            <comment id="16358354" author="githubbot" created="Fri, 9 Feb 2018 12:59:21 +0000"  >&lt;p&gt;rajinisivaram closed pull request #4517: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6529&quot; title=&quot;Broker leaks memory and file descriptors after sudden client disconnects&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6529&quot;&gt;&lt;del&gt;KAFKA-6529&lt;/del&gt;&lt;/a&gt;: Stop file descriptor leak when client disconnects with staged receives&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4517&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4517&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/clients/src/main/java/org/apache/kafka/common/network/Selector.java b/clients/src/main/java/org/apache/kafka/common/network/Selector.java&lt;br/&gt;
index 6bfcfd21a90..ed037b3a8f7 100644&lt;br/&gt;
&amp;#8212; a/clients/src/main/java/org/apache/kafka/common/network/Selector.java&lt;br/&gt;
+++ b/clients/src/main/java/org/apache/kafka/common/network/Selector.java&lt;br/&gt;
@@ -325,9 +325,9 @@ public void send(Send send) {&lt;br/&gt;
             } catch (Exception e) {&lt;br/&gt;
                 // update the state for consistency, the channel will be discarded after `close`&lt;br/&gt;
                 channel.state(ChannelState.FAILED_SEND);&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// ensure notification via `disconnected`&lt;br/&gt;
+                // ensure notification via `disconnected` when `failedSends` are processed in the next poll&lt;br/&gt;
                 this.failedSends.add(connectionId);&lt;/li&gt;
	&lt;li&gt;close(channel, false);&lt;br/&gt;
+                close(channel, false, false);&lt;br/&gt;
                 if (!(e instanceof CancelledKeyException)) {&lt;br/&gt;
                     log.error(&quot;Unexpected exception during send, closing connection {} and rethrowing exception {}&quot;,&lt;br/&gt;
                             connectionId, e);&lt;br/&gt;
@@ -450,6 +450,7 @@ void pollSelectionKeys(Set&amp;lt;SelectionKey&amp;gt; selectionKeys,&lt;br/&gt;
             if (idleExpiryManager != null)&lt;br/&gt;
                 idleExpiryManager.update(channel.id(), currentTimeNanos);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+            boolean sendFailed = false;&lt;br/&gt;
             try {&lt;/p&gt;

&lt;p&gt;                 /* complete any connections that have finished their handshake (either normally or immediately) */&lt;br/&gt;
@@ -491,7 +492,13 @@ void pollSelectionKeys(Set&amp;lt;SelectionKey&amp;gt; selectionKeys,&lt;/p&gt;

&lt;p&gt;                 /* if channel is ready write to any sockets that have space in their buffer and for which we have data */&lt;br/&gt;
                 if (channel.ready() &amp;amp;&amp;amp; key.isWritable()) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Send send = channel.write();&lt;br/&gt;
+                    Send send = null;&lt;br/&gt;
+                    try 
{
+                        send = channel.write();
+                    }
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
+                        sendFailed = true;
+                        throw e;
+                    }
&lt;p&gt;                     if (send != null) &lt;/p&gt;
{
                         this.completedSends.add(send);
                         this.sensors.recordBytesSent(channel.id(), send.size());
@@ -500,7 +507,7 @@ void pollSelectionKeys(Set&amp;lt;SelectionKey&amp;gt; selectionKeys,
 
                 /* cancel any defunct sockets */
                 if (!key.isValid())
-                    close(channel, true);
+                    close(channel, true, true);
 
             }
&lt;p&gt; catch (Exception e) {&lt;br/&gt;
                 String desc = channel.socketDescription();&lt;br/&gt;
@@ -510,7 +517,7 @@ else if (e instanceof AuthenticationException) // will be logged later as error&lt;br/&gt;
                     log.debug(&quot;Connection with {} disconnected due to authentication exception&quot;, desc, e);&lt;br/&gt;
                 else&lt;br/&gt;
                     log.warn(&quot;Unexpected error from {}; closing connection&quot;, desc, e);&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;close(channel, true);&lt;br/&gt;
+                close(channel, !sendFailed, true);&lt;br/&gt;
             } finally 
{
                 maybeRecordTimePerConnection(channel, channelStartTimeNanos);
             }
&lt;p&gt;@@ -620,7 +627,7 @@ private void maybeCloseOldestConnection(long currentTimeNanos) {&lt;br/&gt;
                     log.trace(&quot;About to close the idle connection from {} due to being idle for {} millis&quot;,&lt;br/&gt;
                             connectionId, (currentTimeNanos - expiredConnection.getValue()) / 1000 / 1000);&lt;br/&gt;
                 channel.state(ChannelState.EXPIRED);&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;close(channel, true);&lt;br/&gt;
+                close(channel, true, true);&lt;br/&gt;
             }&lt;br/&gt;
         }&lt;br/&gt;
     }&lt;br/&gt;
@@ -674,7 +681,7 @@ public void close(String id) 
{
             // There is no disconnect notification for local close, but updating
             // channel state here anyway to avoid confusion.
             channel.state(ChannelState.LOCAL_CLOSE);
-            close(channel, false);
+            close(channel, false, false);
         }
&lt;p&gt; else {&lt;br/&gt;
             KafkaChannel closingChannel = this.closingChannels.remove(id);&lt;br/&gt;
             // Close any closing channel, leave the channel in the state in which closing was triggered&lt;br/&gt;
@@ -694,7 +701,10 @@ public void close(String id) {&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;closed immediately. The channel will not be added to disconnected list and it is the&lt;/li&gt;
	&lt;li&gt;responsibility of the caller to handle disconnect notifications.&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private void close(KafkaChannel channel, boolean processOutstanding) {&lt;br/&gt;
+    private void close(KafkaChannel channel, boolean processOutstanding, boolean notifyDisconnect) {&lt;br/&gt;
+&lt;br/&gt;
+        if (processOutstanding &amp;amp;&amp;amp; !notifyDisconnect)&lt;br/&gt;
+            throw new IllegalStateException(&quot;Disconnect notification required for remote disconnect after processing outstanding requests&quot;);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         channel.disconnect();&lt;/p&gt;

&lt;p&gt;@@ -712,8 +722,9 @@ private void close(KafkaChannel channel, boolean processOutstanding) {&lt;br/&gt;
         if (processOutstanding &amp;amp;&amp;amp; deque != null &amp;amp;&amp;amp; !deque.isEmpty()) {&lt;br/&gt;
             // stagedReceives will be moved to completedReceives later along with receives from other channels&lt;br/&gt;
             closingChannels.put(channel.id(), channel);&lt;br/&gt;
+            log.debug(&quot;Tracking closing connection {} to process outstanding requests&quot;, channel.id());&lt;br/&gt;
         } else&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;doClose(channel, processOutstanding);&lt;br/&gt;
+            doClose(channel, notifyDisconnect);&lt;br/&gt;
         this.channels.remove(channel.id());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         if (idleExpiryManager != null)&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/network/SocketServerTest.scala b/core/src/test/scala/unit/kafka/network/SocketServerTest.scala&lt;br/&gt;
index 13299c7cc29..8ee4c36ba44 100644&lt;br/&gt;
&amp;#8212; a/core/src/test/scala/unit/kafka/network/SocketServerTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/network/SocketServerTest.scala&lt;br/&gt;
@@ -148,7 +148,7 @@ class SocketServerTest extends JUnitSuite {&lt;br/&gt;
   }&lt;/p&gt;

&lt;p&gt;   def sendAndReceiveRequest(socket: Socket, server: SocketServer): RequestChannel.Request = &lt;/p&gt;
{
-    sendRequest(socket, producerRequestBytes)
+    sendRequest(socket, producerRequestBytes())
     receiveRequest(server.requestChannel)
   }

&lt;p&gt;@@ -157,11 +157,10 @@ class SocketServerTest extends JUnitSuite &lt;/p&gt;
{
     server.metrics.close()
   }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private def producerRequestBytes: Array&lt;span class=&quot;error&quot;&gt;&amp;#91;Byte&amp;#93;&lt;/span&gt; = {&lt;br/&gt;
+  private def producerRequestBytes(ack: Short = 0): Array&lt;span class=&quot;error&quot;&gt;&amp;#91;Byte&amp;#93;&lt;/span&gt; = {&lt;br/&gt;
     val correlationId = -1&lt;br/&gt;
     val clientId = &quot;&quot;&lt;br/&gt;
     val ackTimeoutMs = 10000&lt;/li&gt;
	&lt;li&gt;val ack = 0: Short&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val emptyRequest = ProduceRequest.Builder.forCurrentMagic(ack, ackTimeoutMs,&lt;br/&gt;
       new HashMap&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, MemoryRecords&amp;#93;&lt;/span&gt;()).build()&lt;br/&gt;
@@ -177,7 +176,7 @@ class SocketServerTest extends JUnitSuite {&lt;br/&gt;
   @Test&lt;br/&gt;
   def simpleRequest() {&lt;br/&gt;
     val plainSocket = connect(protocol = SecurityProtocol.PLAINTEXT)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val serializedBytes = producerRequestBytes&lt;br/&gt;
+    val serializedBytes = producerRequestBytes()&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // Test PLAINTEXT socket&lt;br/&gt;
     sendRequest(plainSocket, serializedBytes)&lt;br/&gt;
@@ -206,7 +205,7 @@ class SocketServerTest extends JUnitSuite {&lt;br/&gt;
   @Test&lt;br/&gt;
   def testGracefulClose() {&lt;br/&gt;
     val plainSocket = connect(protocol = SecurityProtocol.PLAINTEXT)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val serializedBytes = producerRequestBytes&lt;br/&gt;
+    val serializedBytes = producerRequestBytes()&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     for (_ &amp;lt;- 0 until 10)&lt;br/&gt;
       sendRequest(plainSocket, serializedBytes)&lt;br/&gt;
@@ -221,7 +220,7 @@ class SocketServerTest extends JUnitSuite {&lt;br/&gt;
   @Test&lt;br/&gt;
   def testNoOpAction(): Unit = {&lt;br/&gt;
     val plainSocket = connect(protocol = SecurityProtocol.PLAINTEXT)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val serializedBytes = producerRequestBytes&lt;br/&gt;
+    val serializedBytes = producerRequestBytes()&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     for (_ &amp;lt;- 0 until 3)&lt;br/&gt;
       sendRequest(plainSocket, serializedBytes)&lt;br/&gt;
@@ -235,7 +234,7 @@ class SocketServerTest extends JUnitSuite {&lt;br/&gt;
   @Test&lt;br/&gt;
   def testConnectionId() {&lt;br/&gt;
     val sockets = (1 to 5).map(_ =&amp;gt; connect(protocol = SecurityProtocol.PLAINTEXT))&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val serializedBytes = producerRequestBytes&lt;br/&gt;
+    val serializedBytes = producerRequestBytes()&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val requests = sockets.map{socket =&amp;gt;&lt;br/&gt;
       sendRequest(socket, serializedBytes)&lt;br/&gt;
@@ -264,7 +263,7 @@ class SocketServerTest extends JUnitSuite {&lt;/p&gt;

&lt;p&gt;     try {&lt;br/&gt;
       overrideServer.startup()&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val serializedBytes = producerRequestBytes&lt;br/&gt;
+      val serializedBytes = producerRequestBytes()&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;       // Connection with no staged receives&lt;br/&gt;
       val socket1 = connect(overrideServer, protocol = SecurityProtocol.PLAINTEXT)&lt;br/&gt;
@@ -347,7 +346,7 @@ class SocketServerTest extends JUnitSuite {&lt;/p&gt;

&lt;p&gt;       // Send requests to `channel1` until a receive is staged and advance time beyond idle time so that `channel1` is&lt;br/&gt;
       // closed with staged receives and is in Selector.closingChannels&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val serializedBytes = producerRequestBytes&lt;br/&gt;
+      val serializedBytes = producerRequestBytes()&lt;br/&gt;
       val request = sendRequestsUntilStagedReceive(overrideServer, socket1, serializedBytes)&lt;br/&gt;
       time.sleep(idleTimeMs + 1)&lt;br/&gt;
       TestUtils.waitUntilTrue(() =&amp;gt; openChannel.isEmpty, &quot;Idle channel not closed&quot;)&lt;br/&gt;
@@ -437,7 +436,7 @@ class SocketServerTest extends JUnitSuite {&lt;br/&gt;
     TestUtils.waitUntilTrue(() =&amp;gt; server.connectionCount(address) &amp;lt; conns.length,&lt;br/&gt;
       &quot;Failed to decrement connection count after close&quot;)&lt;br/&gt;
     val conn2 = connect()&lt;/li&gt;
	&lt;li&gt;val serializedBytes = producerRequestBytes&lt;br/&gt;
+    val serializedBytes = producerRequestBytes()&lt;br/&gt;
     sendRequest(conn2, serializedBytes)&lt;br/&gt;
     val request = server.requestChannel.receiveRequest(2000)&lt;br/&gt;
     assertNotNull(request)&lt;br/&gt;
@@ -456,7 +455,7 @@ class SocketServerTest extends JUnitSuite {&lt;br/&gt;
       val conns = (0 until overrideNum).map(_ =&amp;gt; connect(overrideServer))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;       // it should succeed&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val serializedBytes = producerRequestBytes&lt;br/&gt;
+      val serializedBytes = producerRequestBytes()&lt;br/&gt;
       sendRequest(conns.last, serializedBytes)&lt;br/&gt;
       val request = overrideServer.requestChannel.receiveRequest(2000)&lt;br/&gt;
       assertNotNull(request)&lt;br/&gt;
@@ -539,7 +538,7 @@ class SocketServerTest extends JUnitSuite {&lt;br/&gt;
     try {&lt;br/&gt;
       overrideServer.startup()&lt;br/&gt;
       conn = connect(overrideServer)&lt;/li&gt;
	&lt;li&gt;val serializedBytes = producerRequestBytes&lt;br/&gt;
+      val serializedBytes = producerRequestBytes()&lt;br/&gt;
       sendRequest(conn, serializedBytes)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;       val channel = overrideServer.requestChannel&lt;br/&gt;
@@ -564,6 +563,54 @@ class SocketServerTest extends JUnitSuite {&lt;br/&gt;
     }&lt;br/&gt;
   }&lt;/p&gt;

&lt;p&gt;+  @Test&lt;br/&gt;
+  def testClientDisconnectionWithStagedReceivesFullyProcessed() {&lt;br/&gt;
+    val serverMetrics = new Metrics&lt;br/&gt;
+    @volatile var selector: TestableSelector = null&lt;br/&gt;
+    val overrideConnectionId = &quot;127.0.0.1:1-127.0.0.1:2-0&quot;&lt;br/&gt;
+    val overrideServer = new SocketServer(KafkaConfig.fromProps(props), serverMetrics, Time.SYSTEM, credentialProvider) {&lt;br/&gt;
+      override def newProcessor(id: Int, connectionQuotas: ConnectionQuotas, listenerName: ListenerName,&lt;br/&gt;
+                                protocol: SecurityProtocol, memoryPool: MemoryPool): Processor = {&lt;br/&gt;
+        new Processor(id, time, config.socketRequestMaxBytes, requestChannel, connectionQuotas,&lt;br/&gt;
+          config.connectionsMaxIdleMs, listenerName, protocol, config, metrics, credentialProvider, memoryPool, new LogContext()) {&lt;br/&gt;
+          override protected&lt;span class=&quot;error&quot;&gt;&amp;#91;network&amp;#93;&lt;/span&gt; def connectionId(socket: Socket): String = overrideConnectionId&lt;br/&gt;
+          override protected&lt;span class=&quot;error&quot;&gt;&amp;#91;network&amp;#93;&lt;/span&gt; def createSelector(channelBuilder: ChannelBuilder): Selector = &lt;/p&gt;
{
+           val testableSelector = new TestableSelector(config, channelBuilder, time, metrics)
+           selector = testableSelector
+           testableSelector
+        }
&lt;p&gt;+        }&lt;br/&gt;
+      }&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    def openChannel: Option&lt;span class=&quot;error&quot;&gt;&amp;#91;KafkaChannel&amp;#93;&lt;/span&gt; = overrideServer.processor(0).channel(overrideConnectionId)&lt;br/&gt;
+    def openOrClosingChannel: Option&lt;span class=&quot;error&quot;&gt;&amp;#91;KafkaChannel&amp;#93;&lt;/span&gt; = overrideServer.processor(0).openOrClosingChannel(overrideConnectionId)&lt;br/&gt;
+&lt;br/&gt;
+    try &lt;/p&gt;
{
+      overrideServer.startup()
+      val socket = connect(overrideServer)
+
+      TestUtils.waitUntilTrue(() =&amp;gt; openChannel.nonEmpty, &quot;Channel not found&quot;)
+
+      // Setup channel to client with staged receives so when client disconnects
+      // it will be stored in Selector.closingChannels
+      val serializedBytes = producerRequestBytes(1)
+      val request = sendRequestsUntilStagedReceive(overrideServer, socket, serializedBytes)
+
+      // Set SoLinger to 0 to force a hard disconnect via TCP RST
+      socket.setSoLinger(true, 0)
+      socket.close()
+
+      // Complete request with socket exception so that the channel is removed from Selector.closingChannels
+      processRequest(overrideServer.requestChannel, request)
+      TestUtils.waitUntilTrue(() =&amp;gt; openOrClosingChannel.isEmpty, &quot;Channel not closed after failed send&quot;)
+      assertTrue(&quot;Unexpected completed send&quot;, selector.completedSends.isEmpty)
+    }
&lt;p&gt; finally &lt;/p&gt;
{
+      overrideServer.shutdown()
+      serverMetrics.close()
+    }
&lt;p&gt;+  }&lt;br/&gt;
+&lt;br/&gt;
   /*&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Test that we update request metrics if the channel has been removed from the selector when the broker calls&lt;/li&gt;
	&lt;li&gt;`selector.send` (selector closes old connections, for example).&lt;br/&gt;
@@ -578,7 +625,7 @@ class SocketServerTest extends JUnitSuite {&lt;br/&gt;
     try {&lt;br/&gt;
       overrideServer.startup()&lt;br/&gt;
       conn = connect(overrideServer)&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val serializedBytes = producerRequestBytes&lt;br/&gt;
+      val serializedBytes = producerRequestBytes()&lt;br/&gt;
       sendRequest(conn, serializedBytes)&lt;br/&gt;
       val channel = overrideServer.requestChannel&lt;br/&gt;
       val request = receiveRequest(channel)&lt;br/&gt;
@@ -697,7 +744,7 @@ class SocketServerTest extends JUnitSuite {&lt;br/&gt;
       testableSelector.updateMinWakeup(2)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;       val sockets = (1 to 2).map(_ =&amp;gt; connect(testableServer))&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;sockets.foreach(sendRequest(_, producerRequestBytes))&lt;br/&gt;
+      sockets.foreach(sendRequest(_, producerRequestBytes()))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;       testableServer.testableSelector.addFailure(SelectorOperation.Send)&lt;br/&gt;
       sockets.foreach(_ =&amp;gt; processRequest(testableServer.requestChannel))&lt;br/&gt;
@@ -720,7 +767,7 @@ class SocketServerTest extends JUnitSuite {&lt;br/&gt;
       testableSelector.updateMinWakeup(2)&lt;/p&gt;

&lt;p&gt;       val sockets = (1 to 2).map(_ =&amp;gt; connect(testableServer))&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;sockets.foreach(sendRequest(_, producerRequestBytes))&lt;br/&gt;
+      sockets.foreach(sendRequest(_, producerRequestBytes()))&lt;br/&gt;
       val requestChannel = testableServer.requestChannel&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;       val requests = sockets.map(_ =&amp;gt; receiveRequest(requestChannel))&lt;br/&gt;
@@ -748,7 +795,7 @@ class SocketServerTest extends JUnitSuite {&lt;br/&gt;
       testableSelector.updateMinWakeup(2)&lt;/p&gt;

&lt;p&gt;       val sockets = (1 to 2).map(_ =&amp;gt; connect(testableServer))&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val serializedBytes = producerRequestBytes&lt;br/&gt;
+      val serializedBytes = producerRequestBytes()&lt;br/&gt;
       val request = sendRequestsUntilStagedReceive(testableServer, sockets(0), serializedBytes)&lt;br/&gt;
       sendRequest(sockets(1), serializedBytes)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -782,7 +829,7 @@ class SocketServerTest extends JUnitSuite {&lt;/p&gt;

&lt;p&gt;       testableSelector.cachedCompletedReceives.minPerPoll = 2&lt;br/&gt;
       testableSelector.addFailure(SelectorOperation.Mute)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;sockets.foreach(sendRequest(_, producerRequestBytes))&lt;br/&gt;
+      sockets.foreach(sendRequest(_, producerRequestBytes()))&lt;br/&gt;
       val requests = sockets.map(_ =&amp;gt; receiveRequest(requestChannel))&lt;br/&gt;
       testableSelector.waitForOperations(SelectorOperation.Mute, 2)&lt;br/&gt;
       testableServer.waitForChannelClose(testableSelector.allFailedChannels.head, locallyClosed = true)&lt;br/&gt;
@@ -906,7 +953,7 @@ class SocketServerTest extends JUnitSuite {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // Check new channel behaves as expected&lt;br/&gt;
     val (socket, connectionId) = connectAndProcessRequest(testableServer)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertArrayEquals(producerRequestBytes, receiveResponse(socket))&lt;br/&gt;
+    assertArrayEquals(producerRequestBytes(), receiveResponse(socket))&lt;br/&gt;
     assertNotNull(&quot;Channel should not have been closed&quot;, selector.channel(connectionId))&lt;br/&gt;
     assertNull(&quot;Channel should not be closing&quot;, selector.closingChannel(connectionId))&lt;br/&gt;
     socket.close()&lt;/li&gt;
&lt;/ul&gt;





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="17072569" author="zzccctv" created="Wed, 1 Apr 2020 09:25:03 +0000"  >&lt;p&gt;I have this problem&#65292;but I don&apos;t know&#65292;How can we reproduce this problem or How to find this problem in production environment&#65311;Thank you very much.&lt;/p&gt;</comment>
                            <comment id="17074102" author="gcampbell" created="Thu, 2 Apr 2020 21:41:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zzccctv&quot; class=&quot;user-hover&quot; rel=&quot;zzccctv&quot;&gt;zzccctv&lt;/a&gt; I originally reproduced it in a test environment by running many instances of the librdkafka performance test client against a broker to trigger the bug. If you&apos;re hitting this bug, the open sockets and open file descriptors of the broker process should grow over time due to the leaked sockets when clients disconnect while their requests are being processed.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;./rdkafka_performance -P -x 100 -b broker:9092 -t test_topic&lt;/em&gt;&lt;/p&gt;</comment>
                            <comment id="17075166" author="zzccctv" created="Sat, 4 Apr 2020 15:03:59 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gcampbell&quot; class=&quot;user-hover&quot; rel=&quot;gcampbell&quot;&gt;gcampbell&lt;/a&gt;&#160; Thanks for your comments. When I run /usr/sbin/lsof -p on that process, I see a lot of &quot;can&apos;t identify protocol&quot;,Does it mean that there are many file description leaks in broker? If I don&apos;t use librdkafka, will it not trigger the problem&#65311;I used the Java version of Kafka client to test it many times and i didn&apos;t find this problem&#12290;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310250" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10430"><![CDATA[Patch]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 32 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3pqk7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>