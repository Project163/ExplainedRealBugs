<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:43:25 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-19427] The __consumer_offsets topic applies the broker configuration message.max.bytes, which may cause the coordinator broker to allocate too much memory and cause OOM</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-19427</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;h3&gt;&lt;a name=&quot;Kafkaclusterconfiguration&quot;&gt;&lt;/a&gt;Kafka cluster configuration&lt;/h3&gt;

&lt;p&gt;1.Kafka version&#65306;4.0&lt;br/&gt;
2.The cluster specifications are: 3 brokers and 3 controllers&lt;br/&gt;
3.JVM startup parameters:&lt;br/&gt;
&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13077168/13077168_image-2025-06-23-14-16-00-554.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;4.JDK version&#65306;&lt;br/&gt;
&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13077167/13077167_image-2025-06-23-14-17-34-767.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;&lt;a name=&quot;Stepstoreproducetheproblem&quot;&gt;&lt;/a&gt;Steps to reproduce the problem&lt;/h3&gt;

&lt;p&gt;1.In this new cluster, create a test topic: &lt;b&gt;test&lt;/b&gt;&#65292;and this cluster will eventually have &lt;b&gt;only this one topic&lt;/b&gt; tested by external users.&lt;/p&gt;

&lt;p&gt;topic config : NewTopic newTopic = new NewTopic(&quot;test&quot;, 3, (short) 1);&lt;br/&gt;
2.Start the producer and send 1,000 messages&lt;br/&gt;
3.Start the consumer and use the earliest strategy for consumption. The groupIds are rivenTest1/rivenTest2/.../rivenTest8&lt;/p&gt;

&lt;p&gt;4.During the process of starting the consumer, it was found that some consumer groups failed to start, and the coordinator brokers corresponding to these groups also had OOM exceptions&lt;/p&gt;

&lt;p&gt;client error logs&#65306;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[main] INFO org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector - initializing Kafka metrics collector
[main] INFO org.apache.kafka.common.security.authenticator.AbstractLogin - Successfully logged in.
[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750661985923
[main] INFO org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer - [Consumer clientId=consumer-rivenTest6-1, groupId=rivenTest6] Subscribed to topic(s): test
[main] INFO org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-rivenTest6-1, groupId=rivenTest6] Cluster ID: 3esGOWhETi-zo2uHq7NsFg
[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-rivenTest6-1, groupId=rivenTest6] Discovered group coordinator 18-97-25-88-k.mq.zoomdev.us:9889 (id: 2147483644 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)
[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-rivenTest6-1, groupId=rivenTest6] (Re-)joining group
[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-rivenTest6-1, groupId=rivenTest6] Request joining group due to: need to re-join with the given member-id: consumer-rivenTest6-1-38849218-32fa-430d-b14c-d3ce7ff402c4
[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-rivenTest6-1, groupId=rivenTest6] (Re-)joining group
[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-rivenTest6-1, groupId=rivenTest6] Successfully joined group with generation Generation{generationId=17, memberId=&lt;span class=&quot;code-quote&quot;&gt;&apos;consumer-rivenTest6-1-38849218-32fa-430d-b14c-d3ce7ff402c4&apos;&lt;/span&gt;, protocol=&lt;span class=&quot;code-quote&quot;&gt;&apos;roundrobin&apos;&lt;/span&gt;}
[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-rivenTest6-1, groupId=rivenTest6] Finished assignment &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; group at generation 17: {consumer-rivenTest6-1-38849218-32fa-430d-b14c-d3ce7ff402c4=Assignment(partitions=[test-0, test-1, test-2])}
[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-rivenTest6-1, groupId=rivenTest6] Request joining group due to: rebalance failed due to &lt;span class=&quot;code-quote&quot;&gt;&apos;Unexpected error from SyncGroup: The server experienced an unexpected error when processing the request.&apos;&lt;/span&gt; (KafkaException)
org.apache.kafka.common.KafkaException: Unexpected error from SyncGroup: The server experienced an unexpected error when processing the request.
&#160; &#160; at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler.handle(AbstractCoordinator.java:893)
&#160; &#160; at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler.handle(AbstractCoordinator.java:812)
&#160; &#160; at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:1311)
&#160; &#160; at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:1286)
&#160; &#160; at org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:206)
&#160; &#160; at org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:169)
&#160; &#160; at org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:129)
&#160; &#160; at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:617)
&#160; &#160; at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:429)
&#160; &#160; at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:314)
&#160; &#160; at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:253)
&#160; &#160; at org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer.pollForFetches(ClassicKafkaConsumer.java:692)
&#160; &#160; at org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer.poll(ClassicKafkaConsumer.java:623)
&#160; &#160; at org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer.poll(ClassicKafkaConsumer.java:596)
&#160; &#160; at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:874)
&#160; &#160; at us.zoom.mq.examples.ConsumerTest.startConsumer(ConsumerTest.java:233)
&#160; &#160; at us.zoom.mq.examples.ConsumerTest.main(ConsumerTest.java:149)
[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-rivenTest6-1, groupId=rivenTest6] Member consumer-rivenTest6-1-38849218-32fa-430d-b14c-d3ce7ff402c4 sending LeaveGroup request to coordinator 18-97-25-88-k.mq.zoomdev.us:9889 (id: 2147483644 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) due to the consumer is being closed
[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-rivenTest6-1, groupId=rivenTest6] Resetting generation and member id due to: consumer pro-actively leaving the group
[main] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-rivenTest6-1, groupId=rivenTest6] Request joining group due to: consumer pro-actively leaving the group
[main] ERROR org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-rivenTest6-1, groupId=rivenTest6] LeaveGroup request with Generation{generationId=17, memberId=&lt;span class=&quot;code-quote&quot;&gt;&apos;consumer-rivenTest6-1-38849218-32fa-430d-b14c-d3ce7ff402c4&apos;&lt;/span&gt;, protocol=&lt;span class=&quot;code-quote&quot;&gt;&apos;roundrobin&apos;&lt;/span&gt;} failed with error: The server experienced an unexpected error when processing the request.
[main] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[main] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[main] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
[main] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[main] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.consumer &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; consumer-rivenTest6-1 unregistered &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;coordinator broker error logs&#65306;&lt;br/&gt;
&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13077162/13077162_image-2025-06-23-15-04-26-598.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;h3&gt;&lt;a name=&quot;Analysis%3A&quot;&gt;&lt;/a&gt;Analysis:&lt;/h3&gt;

&lt;p&gt;This is a brand new Kafka4.0 cluster with only one topic created;&lt;br/&gt;
The JDK version is 17;&lt;br/&gt;
Why does the broker encounter OOM so quickly when it is just sending and consuming data? Is there a memory leak somewhere?&lt;br/&gt;
1 First, use the arthas tool to analyze the memory usage&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13077163/13077163_image-2025-06-23-15-04-15-708.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;We can see that most of the heap memory is &lt;b&gt;occupied by the old generation&lt;/b&gt;, and it is likely that the program will directly experience OOM of the heap memory when it needs to &lt;font color=&quot;#ff0000&quot;&gt;&lt;b&gt;apply for a large object. It should be noted that the maximum memory we allocate to the Kafka process is actually 3G, and there is also a lot of space left in the heap memory. Why does it directly trigger the Java heap space type OOM in this case?&lt;/b&gt;&lt;/font&gt;&lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;#172b4d&quot;&gt;2.Dump memory snapshots and use tools to analyze what is currently occupying a large amount of memory in the program&lt;br/&gt;
&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13077160/13077160_image-2025-06-23-15-33-06-851.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;br/&gt;
&lt;br/&gt;
&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13077159/13077159_image-2025-06-23-15-33-26-209.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;br/&gt;
After analyzing the memory usage, I found that it was basically all the &lt;b&gt;coordinators&lt;/b&gt; objects in the &lt;b&gt;CoordinatorRuntime&lt;/b&gt; class that occupied the memory and did not release it; coordinators is a ConcurrentHashMap structure, the key is the TopicPartition type, and the value is the CoordinatorContext type.&lt;br/&gt;
&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13077161/13077161_image-2025-06-23-15-11-13-026.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;br/&gt;
&lt;br/&gt;
Why does a broker machine simply start a consumer, the topic has only three partitions, and the consumer group uses no more than 10 partitions in total, and the &lt;b&gt;coordinators&lt;/b&gt; object in the broker process occupies such a large amount of memory and does not release it?&lt;br/&gt;
Is there a problem with the broker configuration or the JDK17 version or the jvm startup parameters, or is there a memory leak in the kafka 4.0 version code?&lt;/font&gt;&lt;font color=&quot;#172b4d&quot;&gt;Please help analyze and answer, looking forward to your reply.&lt;br/&gt;
Thank you very much!&lt;/font&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13621524">KAFKA-19427</key>
            <summary>The __consumer_offsets topic applies the broker configuration message.max.bytes, which may cause the coordinator broker to allocate too much memory and cause OOM</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mingyen066">Ming-Yen Chung</assignee>
                                    <reporter username="RivenSun">RivenSun</reporter>
                        <labels>
                    </labels>
                <created>Mon, 23 Jun 2025 07:35:07 +0000</created>
                <updated>Fri, 18 Jul 2025 07:21:05 +0000</updated>
                            <resolved>Wed, 16 Jul 2025 16:58:00 +0000</resolved>
                                    <version>4.0.0</version>
                                    <fixVersion>4.0.1</fixVersion>
                    <fixVersion>4.1.0</fixVersion>
                                    <component>consumer</component>
                    <component>group-coordinator</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>18</watches>
                                                                                                                <comments>
                            <comment id="17985258" author="rivensun" created="Mon, 23 Jun 2025 07:40:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=guozhang&quot; class=&quot;user-hover&quot; rel=&quot;guozhang&quot;&gt;guozhang&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dajac&quot; class=&quot;user-hover&quot; rel=&quot;dajac&quot;&gt;dajac&lt;/a&gt;&#160;&lt;br/&gt;
Could you please help me look into this issue? &lt;br/&gt;
Thank you very much!&lt;/p&gt;</comment>
                            <comment id="17985627" author="JIRAUSER304653" created="Mon, 23 Jun 2025 13:30:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=RivenSun&quot; class=&quot;user-hover&quot; rel=&quot;RivenSun&quot;&gt;RivenSun&lt;/a&gt; to help diagnose the issue, could you attach the broker logs and the output of &lt;tt&gt;kafka-topics --describe --topic __consumer_offsets&lt;/tt&gt;?&lt;/p&gt;</comment>
                            <comment id="17985753" author="rivensun" created="Tue, 24 Jun 2025 02:43:56 +0000"  >&lt;p&gt;The above document has posted the client log and coordinator broker log when the problem occurs.&lt;br/&gt;
The coordinator broker log is posted here in text form. We can see that two OOM exceptions occurred:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[2025-06-23 02:50:03,315] INFO [GroupCoordinator id=3 topic=__consumer_offsets partition=36] Dynamic member with unknown member id joins group rivenTest6 in Empty state. Created a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; member id consumer-rivenTest6-1-2863a8c0-c963-4a1e-96f0-c7036ff85f6d and requesting the member to rejoin with &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; id. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-06-23 02:50:03,738] WARN [GroupCoordinator id=3 topic=__consumer_offsets partition=36] Failed to write empty metadata &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; group rivenTest6: Java heap space (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-06-23 02:50:03,750] INFO [GroupCoordinator id=3 topic=__consumer_offsets partition=36] Pending dynamic member with id consumer-rivenTest6-1-2863a8c0-c963-4a1e-96f0-c7036ff85f6d joins group rivenTest6 in Empty state. Adding to the group now. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-06-23 02:50:03,750] INFO [GroupCoordinator id=3 topic=__consumer_offsets partition=36] Preparing to rebalance group rivenTest6 in state PreparingRebalance with old generation 0 (reason: Adding &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; member consumer-rivenTest6-1-2863a8c0-c963-4a1e-96f0-c7036ff85f6d with group instance id &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;; client reason: need to re-join with the given member-id: consumer-rivenTest6-1-2863a8c0-c963-4a1e-96f0-c7036ff85f6d). (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-06-23 02:50:06,751] INFO [GroupCoordinator id=3 topic=__consumer_offsets partition=36] Stabilized group rivenTest6 generation 1 with 1 members. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-06-23 02:50:07,056] INFO [GroupCoordinator id=3 topic=__consumer_offsets partition=36] Assignment received from leader consumer-rivenTest6-1-2863a8c0-c963-4a1e-96f0-c7036ff85f6d &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; group rivenTest6 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; generation 1. The group has 1 members, 0 of which are &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt;. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-06-23 02:50:07,314] INFO [GroupCoordinator id=3 topic=__consumer_offsets partition=36] Preparing to rebalance group rivenTest6 in state PreparingRebalance with old generation 1 (reason: Error UNKNOWN_SERVER_ERROR when storing group assignmentduring SyncGroup (member: consumer-rivenTest6-1-2863a8c0-c963-4a1e-96f0-c7036ff85f6d).). (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-06-23 02:50:07,707] INFO [GroupCoordinator id=3 topic=__consumer_offsets partition=36] [Group rivenTest6] Member consumer-rivenTest6-1-2863a8c0-c963-4a1e-96f0-c7036ff85f6d has left group through explicit `LeaveGroup` request; client reason: the consumer is being closed (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-06-23 02:50:07,709] INFO [GroupCoordinator id=3 topic=__consumer_offsets partition=36] Group rivenTest6 with generation 2 is now empty. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-06-23 02:50:08,069] WARN [GroupCoordinator id=3 topic=__consumer_offsets partition=36] Failed to write empty metadata &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; group rivenTest6: The server experienced an unexpected error when processing the request. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-06-23 02:50:08,090] ERROR [GroupCoordinator id=3] Operation classic-group-leave with LeaveGroupRequestData(groupId=&lt;span class=&quot;code-quote&quot;&gt;&apos;rivenTest6&apos;&lt;/span&gt;, memberId=&lt;span class=&quot;code-quote&quot;&gt;&apos;&apos;, members=[MemberIdentity(memberId=&apos;&lt;/span&gt;consumer-rivenTest6-1-2863a8c0-c963-4a1e-96f0-c7036ff85f6d&lt;span class=&quot;code-quote&quot;&gt;&apos;, groupInstanceId=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, reason=&apos;&lt;/span&gt;the consumer is being closed&apos;)]) hit an unexpected exception: Java heap space. (org.apache.kafka.coordinator.group.GroupCoordinatorService)
java.lang.OutOfMemoryError: Java heap space &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Today I used rivenTest6 to start the consumer again and found that this group can start consumption normally. The following is the coordinatorBroker log today:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
[2025-06-24 02:24:04,810] INFO [GroupCoordinator id=3 topic=__consumer_offsets partition=36] Dynamic member with unknown member id joins group rivenTest6 in Stable state. Created a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; member id consumer-rivenTest6-1-4fbe3e3c-fa31-45ce-a917-3ea7ea2f8026 and requesting the member to rejoin with &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; id. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-06-24 02:24:05,096] INFO [GroupCoordinator id=3 topic=__consumer_offsets partition=36] Pending dynamic member with id consumer-rivenTest6-1-4fbe3e3c-fa31-45ce-a917-3ea7ea2f8026 joins group rivenTest6 in Stable state. Adding to the group now. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-06-24 02:24:05,096] INFO [GroupCoordinator id=3 topic=__consumer_offsets partition=36] Preparing to rebalance group rivenTest6 in state PreparingRebalance with old generation 1 (reason: Adding &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; member consumer-rivenTest6-1-4fbe3e3c-fa31-45ce-a917-3ea7ea2f8026 with group instance id &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;; client reason: need to re-join with the given member-id: consumer-rivenTest6-1-4fbe3e3c-fa31-45ce-a917-3ea7ea2f8026). (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-06-24 02:24:27,863] INFO [GroupCoordinator id=3 topic=__consumer_offsets partition=36] Member consumer-rivenTest6-1-227a766a-90d2-4365-af17-117566bbbd58 in group rivenTest6 has failed, removing it from the group. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-06-24 02:24:27,863] INFO [GroupCoordinator id=3 topic=__consumer_offsets partition=36] Stabilized group rivenTest6 generation 2 with 1 members. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-06-24 02:24:28,160] INFO [GroupCoordinator id=3 topic=__consumer_offsets partition=36] Assignment received from leader consumer-rivenTest6-1-4fbe3e3c-fa31-45ce-a917-3ea7ea2f8026 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; group rivenTest6 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; generation 2. The group has 1 members, 0 of which are &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt;. (org.apache.kafka.coordinator.group.GroupMetadataManager) &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Then I immediately looked at the broker&apos;s memory usage at this time, as follows&#65306;&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13077191/13077191_image-2025-06-24-10-29-51-465.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;The kafka process was started on June 20th and has not been restarted so far.&lt;br/&gt;
Yesterday, the memory usage of g1_old_gen was 76.14%. When rivenTest6 groupId consumption was started, the coordinator broker would experience OOM.&lt;br/&gt;
Today, the memory usage of g1_old_gen was 42.62%. When rivenTest6 groupId consumption was started, the coordinator broker was normal and the client could consume data normally.&lt;br/&gt;
&lt;b&gt;So it was because the process had enough memory to support the use after the old generation heap memory was reclaimed by GC. But what I don&apos;t understand is why the coordinator broker needs to apply for such a large heap memory for a topic registration consumption with three partitions.&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;The partition status of __consumer_offsets is as follows:&lt;/b&gt;&lt;br/&gt;
&lt;b&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13077193/13077193_image-2025-06-24-10-43-46-826.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=squah-confluent&quot; class=&quot;user-hover&quot; rel=&quot;squah-confluent&quot;&gt;squah-confluent&lt;/a&gt; Looking forward to your reply. Thank you&#65281;&lt;/p&gt;</comment>
                            <comment id="17985754" author="rivensun" created="Tue, 24 Jun 2025 02:51:28 +0000"  >&lt;p&gt;Add additional information. When the consumer is not started, the broker&apos;s log is normal.&lt;/p&gt;

&lt;p&gt;There are only two topics in the cluster, details of the test topic.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13077194/13077194_image-2025-06-24-10-50-17-396.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;</comment>
                            <comment id="17985812" author="dajac" created="Tue, 24 Jun 2025 08:55:30 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=RivenSun&quot; class=&quot;user-hover&quot; rel=&quot;RivenSun&quot;&gt;RivenSun&lt;/a&gt; Thanks for the Jira. Could you please share a heap dump of the broker when the issue happens? It would help to diagnose what consumes a lot of memory. For the context, the byte buffers that you highlighted in the description are indeed kept by the group coordinator. It has one per __consumer_offsets partitions and they are 1MB each by default. In your case, you have 3 brokers and 50 partitions so ~16 buffers per broker. They should not take more than 16MB per broker. They should not be the source of any issues unless there is a bug somewhere. Having the heap dump and the full logs of the broker would help. I tried to reproduce it with a single broker but I could not.&lt;/p&gt;</comment>
                            <comment id="17985813" author="dajac" created="Tue, 24 Jun 2025 08:58:34 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=RivenSun&quot; class=&quot;user-hover&quot; rel=&quot;RivenSun&quot;&gt;RivenSun&lt;/a&gt; Could you also share your config? What do you use for `max.message.bytes`? Those buffers are actually allocated based on `max.message.bytes` so it may be the source of the issue.&lt;/p&gt;</comment>
                            <comment id="17985826" author="chia7712" created="Tue, 24 Jun 2025 09:53:10 +0000"  >&lt;p&gt;If `max.message.bytes` is too small to carry all records, the `MemoryRecordsBuilder` will create another buffer internally. The buffer recycled by `freeCurrentBatch` is the smaller one. That means the `GrowableBufferSupplier` always reuse the &quot;same&quot; buffer rather than &quot;growable&quot; buffer. &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
        &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; void freeCurrentBatch() {
            &lt;span class=&quot;code-comment&quot;&gt;// Cancel the linger timeout.
&lt;/span&gt;            currentBatch.lingerTimeoutTask.ifPresent(TimerTask::cancel);

            &lt;span class=&quot;code-comment&quot;&gt;// Release the buffer.
&lt;/span&gt;            &lt;span class=&quot;code-comment&quot;&gt;// bufferSupplier.release(currentBatch.buffer);
&lt;/span&gt;            bufferSupplier.release(currentBatch.builder.buffer());

            currentBatch = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
        }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;However, this seems to be unrelated to OOM, as the buffer should be GCable. &lt;/p&gt;</comment>
                            <comment id="17985998" author="rivensun" created="Wed, 25 Jun 2025 05:47:13 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dajac&quot; class=&quot;user-hover&quot; rel=&quot;dajac&quot;&gt;dajac&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chia7712&quot; class=&quot;user-hover&quot; rel=&quot;chia7712&quot;&gt;chia7712&lt;/a&gt; thanks for your reply!&lt;br/&gt;
As for why there is a `max.message.bytes` configuration in the config of __consumer_offsets, it is because it was created using the default configuration of broker &#8216;message.max.bytes=1073741824&#8217;. I made the same configuration for the cluster below version 4.0, but there was no problem.&lt;br/&gt;
Below is the complete configuration file of my broker machine. I replaced sensitive information with ***&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
process.roles=broker
node.id=2
controller.quorum.voters=***
controller.listener.names=CONTROLLER

broker.rack=us-east-1b
log.dirs=/asyncmq/kafka/data1
listeners=CLIENT_PRIVATE:&lt;span class=&quot;code-comment&quot;&gt;//:9449,SASL_SSL://:9889,INTERNAL_SSL://:9559,PLAIN_PLUGIN_SSL://:9669
&lt;/span&gt;advertised.listeners=***
listener.security.protocol.map=INTERNAL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL,PLAIN_PLUGIN_SSL:SASL_SSL,CLIENT_PRIVATE:SASL_SSL,CONTROLLER:SASL_SSL

#ssl config
ssl.keystore.password=***
ssl.key.password=***
ssl.keystore.location=/etc/kafka/keystore.jks
ssl.client.auth=none
ssl.endpoint.identification.algorithm=https
ssl.allow.dn.changes=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
ssl.allow.san.changes=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;

#controller communicate config
sasl.mechanism.controller.protocol=PLAIN

#broker communicate config
#security.inter.broker.protocol=SASL_PLAINTEXT
inter.broker.listener.name=INTERNAL_SSL
sasl.mechanism.inter.broker.protocol=PLAIN
broker.heartbeat.interval.ms=2000
broker.session.timeout.ms=9000

#acl authorization config
authorizer.&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;name=org.apache.kafka.metadata.authorizer.StandardAuthorizer
allow.everyone.&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;.no.acl.found=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
&lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;.users=***

num.partitions=8
&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;.replication.factor=3
message.max.bytes=1073741824
min.insync.replicas=1

auto.create.topics.enable=False
delete.topic.enable=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
auto.leader.rebalance.enable=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
log.segment.bytes=1073741824
log.retention.hours=168
log.retention.check.interval.ms=300000
log.index.size.max.bytes=10485760
segment.index.bytes=10485760

replica.lag.time.max.ms=30000
fetch.max.bytes=57671680
log.preallocate=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;

num.network.threads=200
listener.name.internal_ssl.num.network.threads=50
listener.name.plain_plugin_ssl.num.network.threads=50
num.io.threads=64
queued.max.requests=4000
num.replica.fetchers=8
background.threads=10
num.recovery.threads.per.data.dir=1

connections.max.idle.ms=300000
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600

offsets.topic.num.partitions=50
offsets.topic.replication.factor=3
offsets.retention.minutes=10080
group.max.session.timeout.ms=1800000
group.min.session.timeout.ms=6000

transaction.state.log.num.partitions=50
transaction.state.log.replication.factor=3
transaction.state.log.min.isr=2
transaction.max.timeout.ms=900000 &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The attached file contains the broker memory dump package when the problem occurs.&lt;br/&gt;
...&lt;br/&gt;
Size limit encountered when uploading an attachment. Is there any other way for us to send you the dump package?&lt;br/&gt;
After compression, my dump package is still 106MB in size&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13077208/13077208_image-2025-06-25-13-46-30-388.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17986007" author="showuon" created="Wed, 25 Jun 2025 06:03:33 +0000"  >&lt;p&gt;So the root cause should be this config: `message.max.bytes=1073741824` (1GB). And like you said, you have 8 consumers, which might use 8GB of memory if all 8 consumers are fetching from the same broker with 1GB message size each. This &lt;a href=&quot;https://kafka.apache.org/documentation/#consumerconfigs_fetch.max.bytes&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;config description&lt;/a&gt; has clear explanation:&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;cite&gt;The maximum amount of data the server should return for a fetch request. Records are fetched in batches by the consumer, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that the consumer can make progress. As such, this is not a absolute maximum. The maximum record batch size accepted by the broker is defined via &lt;tt&gt;message.max.bytes&lt;/tt&gt; (broker config) or &lt;tt&gt;max.message.bytes&lt;/tt&gt; (topic config). Note that the consumer performs multiple fetches in parallel.&lt;/cite&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Even though you said this OOM won&apos;t happen in versions &amp;lt; 4.0, this is not a bug in kafka broker in my opinion. Let&apos;s see if David/ Chia-Ping has different opinions.&lt;/p&gt;</comment>
                            <comment id="17986016" author="rivensun" created="Wed, 25 Jun 2025 06:29:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=showuon&quot; class=&quot;user-hover&quot; rel=&quot;showuon&quot;&gt;showuon&lt;/a&gt; thanks for your apply!&lt;br/&gt;
After your reply, I confirmed the normal Kafka cluster running on the production line again.&lt;br/&gt;
The kafka version is 3.9.0, and the configuration of __consumer_offsets &lt;b&gt;does not set&lt;/b&gt; `message.max.bytes=1073741824` (1GB)&lt;/p&gt;

&lt;p&gt;As for why I mistakenly thought that the __consumer_offsets of my production cluster would make this setting, it is because my local test cluster and the production cluster use the same deployment script, and &lt;b&gt;the broker configuration file will have the setting `message.max.bytes=1073741824`&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;I now believe that the OOM of my local broker is due to the max.message.bytes configuration of __consumer_offsets, but the timing and parameters of the creation of this internal topic are automatically performed by the broker.&lt;br/&gt;
So why in the 4.0 version code, the creation of __consumer_offsets will read the message.max.bytes (broker config) on &#8203;&#8203;the broker, and then apply it to the max.message.bytes (topic config).&lt;/p&gt;

&lt;p&gt;I also look forward to responses from other relevant experts.&lt;br/&gt;
Thanks.&lt;/p&gt;</comment>
                            <comment id="17986045" author="dajac" created="Wed, 25 Jun 2025 09:00:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=RivenSun&quot; class=&quot;user-hover&quot; rel=&quot;RivenSun&quot;&gt;RivenSun&lt;/a&gt; Thanks for confirming. The root cause is indeed `message.max.bytes=1073741824` (1GB). The group coordinator basically allocate a 1GB buffer for each __consumer_offsets partitions assigned to it. The coordinator uses the topic level config or the broker config to determine the max message size. As a workaround, you can dynamically set the property to the topic (e.g. 1MB) and restart.&lt;/p&gt;

&lt;p&gt;I think that we should do two things here to improve the situation:&#160;&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;We could introduce a new config to drive the value used by the group coordinator &#8211; e.g group.coordinator.append.max.bytes &#8211; instead of relying on the broker message.max.bytes. This would be used to set the max bytes at the topic level when the topic is created.&lt;/li&gt;
	&lt;li&gt;We could change the allocation logic to start with a smaller buffer. For instance, we could start with 512KB and let it grow up to message.max.bytes if there is a need for it. This would avoid the large allocation.&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="17986046" author="rivensun" created="Wed, 25 Jun 2025 09:01:50 +0000"  >&lt;p&gt;The configuration of the production line health cluster __consumer_offsets is:&lt;br/&gt;
cleanup.policy=compact&lt;br/&gt;
compression.type=producer&lt;br/&gt;
segment.bytes=104857600&lt;/p&gt;

&lt;p&gt;The configuration of __consumer_offsets in the local 4.0 version test cluster is:&lt;br/&gt;
cleanup.policy=compact&lt;br/&gt;
compression.type=producer&lt;br/&gt;
segment.bytes=104857600&lt;br/&gt;
&lt;b&gt;min.insync.replicas=1&lt;/b&gt;&lt;br/&gt;
&lt;b&gt;max.message.bytes=1073741824&lt;/b&gt;&lt;br/&gt;
&lt;b&gt;preallocate=false&lt;/b&gt;&lt;br/&gt;
&lt;b&gt;segment.index.bytes=10485760&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;After looking at the latest code, I did not find any code to add redundant configuration in the `AutoTopicCreationManager#creatableTopic` method. Maybe it is caused by other code.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17986047" author="rivensun" created="Wed, 25 Jun 2025 09:07:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dajac&quot; class=&quot;user-hover&quot; rel=&quot;dajac&quot;&gt;dajac&lt;/a&gt;&#160;&lt;br/&gt;
Thanks for your reply, which helped me to finalize the RC.&lt;br/&gt;
I will solve this problem according to your suggestion.&lt;br/&gt;
Does this mean that it is caused by the 4.0 code? Because before the 4.0 version, as mentioned in my latest reply, the creation of __consumer_offsets seems to only apply the following three configurations, and will not perceive the default configuration set for ordinary topics on the broker.&lt;br/&gt;
&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13077213/13077213_image-2025-06-25-17-06-54-449.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;</comment>
                            <comment id="17986108" author="chia7712" created="Wed, 25 Jun 2025 11:08:08 +0000"  >&lt;p&gt;hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=RivenSun&quot; class=&quot;user-hover&quot; rel=&quot;RivenSun&quot;&gt;RivenSun&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;there is a big change in the coordinator after 4.0, and the (topic-level) max.message.bytes and (broker-level) message.max.bytes of offset topic is used to create a buffer in the new coordinator. Hence, a 1G size could cause issue in the 4.0 and later version. The following link shows the usage of message size in 4.0+&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/kafka/blob/33a1648c44acf5021138f8cf5e8117ad0071f317/coordinator-common/src/main/java/org/apache/kafka/coordinator/common/runtime/CoordinatorRuntime.java#L862&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/33a1648c44acf5021138f8cf5e8117ad0071f317/coordinator-common/src/main/java/org/apache/kafka/coordinator/common/runtime/CoordinatorRuntime.java#L862&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dajac&quot; class=&quot;user-hover&quot; rel=&quot;dajac&quot;&gt;dajac&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;    We could introduce a new config to drive the value used by the group coordinator &#8211; e.g group.coordinator.append.max.bytes &#8211; instead of relying on the broker message.max.bytes. This would be used to set the max bytes at the topic level when the topic is created.&lt;br/&gt;
    We could change the allocation logic to start with a smaller buffer. For instance, we could start with 512KB and let it grow up to message.max.bytes if there is a need for it. This would avoid the large allocation.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It seems the second approach is good enough? Introducing `group.coordinator.append.max.bytes` would require a KIP and the new config seems to be similar to (topic-level) max.message.bytes`?&lt;/p&gt;


</comment>
                            <comment id="17986109" author="rivensun" created="Wed, 25 Jun 2025 11:12:39 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dajac&quot; class=&quot;user-hover&quot; rel=&quot;dajac&quot;&gt;dajac&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=showuon&quot; class=&quot;user-hover&quot; rel=&quot;showuon&quot;&gt;showuon&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chia7712&quot; class=&quot;user-hover&quot; rel=&quot;chia7712&quot;&gt;chia7712&lt;/a&gt;&#160;&lt;/p&gt;

&lt;p&gt;I reviewed the code for creating the &lt;b&gt;test&lt;/b&gt; topic. I did not set any topicConfigs configuration, only numPartitions and replicationFactor.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
NewTopic newTopic = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; NewTopic(&lt;span class=&quot;code-quote&quot;&gt;&quot;test&quot;&lt;/span&gt;, 3, (&lt;span class=&quot;code-object&quot;&gt;short&lt;/span&gt;) 1);
adminClient.createTopics(Collections.singleton(newTopic)).all().get(); &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;However, as shown in the following command, the broker automatically appended some additional configurations when creating the &lt;b&gt;test&lt;/b&gt; topic. &lt;b&gt;I think this is not what I expected.&lt;/b&gt;&lt;br/&gt;
&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13077215/13077215_image-2025-06-25-19-10-49-177.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Looking forward to your reply.&#160;&lt;br/&gt;
Thanks!&lt;/p&gt;</comment>
                            <comment id="17986111" author="chia7712" created="Wed, 25 Jun 2025 11:18:28 +0000"  >&lt;blockquote&gt;
&lt;p&gt;However, as shown in the following command, the broker automatically appended some additional configurations when creating the test topic.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;some broker-level configs will be added to a topic if they are absent. For example, broker-level message.max.bytes will be applied to a topic if its topic-level max.message.bytes is absent.&lt;/p&gt;</comment>
                            <comment id="17986114" author="rivensun" created="Wed, 25 Jun 2025 11:29:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chia7712&quot; class=&quot;user-hover&quot; rel=&quot;chia7712&quot;&gt;chia7712&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dajac&quot; class=&quot;user-hover&quot; rel=&quot;dajac&quot;&gt;dajac&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=showuon&quot; class=&quot;user-hover&quot; rel=&quot;showuon&quot;&gt;showuon&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=squah-confluent&quot; class=&quot;user-hover&quot; rel=&quot;squah-confluent&quot;&gt;squah-confluent&lt;/a&gt; Thank you for your reply.&lt;br/&gt;
Because my own Kafka control management console only displays the user display setting level configuration when displaying topic details, which caused some misunderstandings for me.&lt;/p&gt;

&lt;p&gt;I will check the PR code changes of the 4.0 version of the coordinator.&lt;br/&gt;
Thanks very much!&lt;/p&gt;</comment>
                            <comment id="17986122" author="rivensun" created="Wed, 25 Jun 2025 11:54:19 +0000"  >&lt;p&gt;So can this jira be considered a bug introduced by the coordinator code change in version 4.0? Because even in 3.9.0, this problem does not occur under the same configuration.&lt;br/&gt;
As mentioned in the PR:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/kafka/blob/33a1648c44acf5021138f8cf5e8117ad0071f317/coordinator-common/src/main/java/org/apache/kafka/coordinator/common/runtime/CoordinatorRuntime.java#L862&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/blob/33a1648c44acf5021138f8cf5e8117ad0071f317/coordinator-common/src/main/java/org/apache/kafka/coordinator/common/runtime/CoordinatorRuntime.java#L862&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17986127" author="chia7712" created="Wed, 25 Jun 2025 12:08:43 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=RivenSun&quot; class=&quot;user-hover&quot; rel=&quot;RivenSun&quot;&gt;RivenSun&lt;/a&gt; 4.0 is a major release, so it seems to me that this is a kind of behavior change for a specific config. However, the scenario you encountered is worth fixing. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dajac&quot; class=&quot;user-hover&quot; rel=&quot;dajac&quot;&gt;dajac&lt;/a&gt; had provided two approaches. I can address them soon and then backport them into 4.0.1&lt;/p&gt;</comment>
                            <comment id="17986129" author="rivensun" created="Wed, 25 Jun 2025 12:15:24 +0000"  >&lt;p&gt;OK, I will solve this problem according to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dajac&quot; class=&quot;user-hover&quot; rel=&quot;dajac&quot;&gt;dajac&lt;/a&gt; his suggestion. You can link the new PR you submit to this jira.&lt;br/&gt;
Thanks.&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chia7712&quot; class=&quot;user-hover&quot; rel=&quot;chia7712&quot;&gt;chia7712&lt;/a&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17986133" author="rivensun" created="Wed, 25 Jun 2025 13:06:07 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chia7712&quot; class=&quot;user-hover&quot; rel=&quot;chia7712&quot;&gt;chia7712&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dajac&quot; class=&quot;user-hover&quot; rel=&quot;dajac&quot;&gt;dajac&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=showuon&quot; class=&quot;user-hover&quot; rel=&quot;showuon&quot;&gt;showuon&lt;/a&gt;&#160;&lt;/p&gt;

&lt;p&gt;Finally, I would like to explain why my broker configuration message.max.bytes is set to 1G&lt;/p&gt;

&lt;p&gt;Because we have an application scenario, a group will subscribe to all topics under this cluster with a regular expression; this causes this group to subscribe to many topicPartitions; and then the number of consumer clients in this group is also large.&lt;/p&gt;

&lt;p&gt;When this group is rebalanced, we found that when the coordinator broker stores the assignment of this group to __consumer_offsets, it will throw an error RecordTooLargeException in server.log. As a result, this group will never be able to be stable successfully.&lt;br/&gt;
Finally, we increased the configuration max.message.bytes of __consumer_offsets to 1G, and this problem was solved.&lt;/p&gt;

&lt;p&gt;Therefore, we adjusted the broker deployment script afterwards, &lt;b&gt;because the creation of __consumer_offsets is automatically performed by the broker. In order to avoid this problem, we can only set the broker configuration to `message.max.bytes=1073741824` (1GB)&lt;/b&gt;&lt;br/&gt;
Thanks.&lt;/p&gt;</comment>
                            <comment id="17986136" author="ijuma" created="Wed, 25 Jun 2025 13:15:52 +0000"  >&lt;p&gt;I agree that this is a bug. Generally speaking, we shouldn&apos;t blindly allocate very large buffers based on a &quot;max&quot; config. In addition, we should be careful not to retain very large buffers if there is an occasional very large message (to avoid issues similar to &lt;a href=&quot;https://www.evanjones.ca/java-bytebuffer-leak.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://www.evanjones.ca/java-bytebuffer-leak.html&lt;/a&gt;).&lt;/p&gt;</comment>
                            <comment id="17986141" author="rivensun" created="Wed, 25 Jun 2025 13:40:31 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt; Thanks for your apply.&lt;/p&gt;

&lt;p&gt;I agree with your point of view. Combined with the scenario I mentioned above:&lt;br/&gt;
When storing a huge group assignment, RecordTooLargeException may occur, and then I have to increase the `max.message.bytes` of __consumer_offsets.&lt;/p&gt;

&lt;p&gt;I suggest that the solution to this problem is to i&lt;b&gt;ntroduce a new parameter&lt;/b&gt; to set the `byteBuffer` here, as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dajac&quot; class=&quot;user-hover&quot; rel=&quot;dajac&quot;&gt;dajac&lt;/a&gt;&#160; said, instead of using maxMessageSize, and this `byteBuffer` can slowly grow from a smaller value to the configured maximum value.&lt;/p&gt;

&lt;p&gt;By the way, I will modify the title of this jira to better track a more specific problem.&lt;br/&gt;
Thanks.&lt;/p&gt;</comment>
                            <comment id="17986143" author="chia7712" created="Wed, 25 Jun 2025 13:46:05 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt; yes, If &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dajac&quot; class=&quot;user-hover&quot; rel=&quot;dajac&quot;&gt;dajac&lt;/a&gt; has no objections, we will file a PR according to DJ second suggestion.&lt;/p&gt;</comment>
                            <comment id="17986144" author="JIRAUSER300229" created="Wed, 25 Jun 2025 13:52:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=RivenSun&quot; class=&quot;user-hover&quot; rel=&quot;RivenSun&quot;&gt;RivenSun&lt;/a&gt;, could you share which record will cause RecordTooLargeException? If it&apos;s about subscription metadata, probably it can be solved by KIP-1101 in 4.1.&lt;/p&gt;</comment>
                            <comment id="17986148" author="dajac" created="Wed, 25 Jun 2025 14:07:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt; Yeah, it is definitely a bug.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chia7712&quot; class=&quot;user-hover&quot; rel=&quot;chia7712&quot;&gt;chia7712&lt;/a&gt; I agree that we should do my second suggestion. Start with a small buffer and grow it based on needs up to max.message.bytes. In practice, max.message.bytes will never be reached because we flush the records based on the linger time (5ms by default).&lt;/p&gt;</comment>
                            <comment id="17986150" author="rivensun" created="Wed, 25 Jun 2025 14:10:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yangpoan&quot; class=&quot;user-hover&quot; rel=&quot;yangpoan&quot;&gt;yangpoan&lt;/a&gt; Thank you very much for your suggestions and reply!&lt;br/&gt;
Previously, I encountered a RecordTooLargeException when storing group assignments in __consumer_offsets. It was indeed as described in the KIP-1101 . There were many topic partitions, many consumer client machines, and rack information was also enabled.&lt;br/&gt;
I hope Kafka4.1 can solve this problem.&lt;br/&gt;
Thanks.&lt;/p&gt;</comment>
                            <comment id="17986153" author="ijuma" created="Wed, 25 Jun 2025 14:16:33 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dajac&quot; class=&quot;user-hover&quot; rel=&quot;dajac&quot;&gt;dajac&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chia7712&quot; class=&quot;user-hover&quot; rel=&quot;chia7712&quot;&gt;chia7712&lt;/a&gt; The proposed approach won&apos;t retain large buffers if an occasional large message is found? From David&apos;s message, it sounds like it won&apos;t, but I want to double-check.&lt;/p&gt;</comment>
                            <comment id="17986184" author="chia7712" created="Wed, 25 Jun 2025 15:55:22 +0000"  >&lt;blockquote&gt;
&lt;p&gt;The proposed approach won&apos;t retain large buffers if an occasional large message is found? From David&apos;s message, it sounds like it won&apos;t, but I want to double-check.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think the maximum size of the retaining buffer is controlled by the maximum message size. The large buffer created by a single large record should not be recycled&lt;/p&gt;</comment>
                            <comment id="17986311" author="dajac" created="Thu, 26 Jun 2025 08:54:03 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ijuma&quot; class=&quot;user-hover&quot; rel=&quot;ijuma&quot;&gt;ijuma&lt;/a&gt; The buffer is used to accumulate records when a batch is built so we don&apos;t really know whether the buffer got large due to a one off. If we want to do this, we could keep some statistics about the amount of bytes used by the last X batches and reduce the capacity of the buffer based on it. For instance, we could reduce the buffer if its size is 2 times larger than the max or something along those lines. I haven&apos;t really thought it through. This is just a high level idea.&lt;/p&gt;</comment>
                            <comment id="17986386" author="ijuma" created="Thu, 26 Jun 2025 14:21:01 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dajac&quot; class=&quot;user-hover&quot; rel=&quot;dajac&quot;&gt;dajac&lt;/a&gt; A simple approach is to simply not cache beyond the current request if the size is beyond X (similar to &lt;a href=&quot;https://www.evanjones.ca/java-bytebuffer-leak.html).&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://www.evanjones.ca/java-bytebuffer-leak.html).&lt;/a&gt; If we don&apos;t cache beyond the current request already, then there is nothing to do.&lt;/p&gt;</comment>
                            <comment id="18007579" author="chia7712" created="Wed, 16 Jul 2025 14:22:03 +0000"  >&lt;p&gt;trunk: &lt;a href=&quot;https://github.com/apache/kafka/commit/e3276ae029b6475421c67053096f8f86616b67f6&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/commit/e3276ae029b6475421c67053096f8f86616b67f6&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;4.1: &lt;a href=&quot;https://github.com/apache/kafka/commit/05f012c7f182c2308ff96960fb7cae53f62b24a7&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/commit/05f012c7f182c2308ff96960fb7cae53f62b24a7&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;4.0: &lt;a href=&quot;https://github.com/apache/kafka/commit/eefee6d58d8bc426ab54d4bc05d49ddb5566c025&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/commit/eefee6d58d8bc426ab54d4bc05d49ddb5566c025&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="18007802" author="fvaleri" created="Thu, 17 Jul 2025 12:18:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=RivenSun&quot; class=&quot;user-hover&quot; rel=&quot;RivenSun&quot;&gt;RivenSun&lt;/a&gt; thanks for reporting this.&lt;/p&gt;

&lt;p&gt;Out of curiosity, how many subscribed partitions for a single consumer are we talking about here?&lt;br/&gt;
Did you set message.max.bytes to 1GB arbitrarily or based on the actual __consumer_offsets record size?&lt;/p&gt;</comment>
                            <comment id="18007994" author="showuon" created="Fri, 18 Jul 2025 07:21:05 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-19519&quot; title=&quot;Introduce a new config for group coordinator max record size&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-19519&quot;&gt;KAFKA-19519&lt;/a&gt; is created for the solution (1): introducing a new config to drive the max record size used by the group coordinator to allow users to increase the record size for group coordinator only.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13623829">KAFKA-19519</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="13077168" name="image-2025-06-23-14-16-00-554.png" size="331919" author="RivenSun" created="Mon, 23 Jun 2025 06:16:04 +0000"/>
                            <attachment id="13077167" name="image-2025-06-23-14-17-34-767.png" size="80799" author="RivenSun" created="Mon, 23 Jun 2025 06:17:38 +0000"/>
                            <attachment id="13077166" name="image-2025-06-23-14-28-51-524.png" size="823290" author="RivenSun" created="Mon, 23 Jun 2025 06:28:56 +0000"/>
                            <attachment id="13077165" name="image-2025-06-23-14-31-47-453.png" size="271386" author="RivenSun" created="Mon, 23 Jun 2025 06:31:51 +0000"/>
                            <attachment id="13077164" name="image-2025-06-23-15-01-32-074.png" size="743989" author="RivenSun" created="Mon, 23 Jun 2025 07:01:37 +0000"/>
                            <attachment id="13077163" name="image-2025-06-23-15-04-15-708.png" size="291859" author="RivenSun" created="Mon, 23 Jun 2025 07:04:20 +0000"/>
                            <attachment id="13077162" name="image-2025-06-23-15-04-26-598.png" size="743989" author="RivenSun" created="Mon, 23 Jun 2025 07:04:32 +0000"/>
                            <attachment id="13077161" name="image-2025-06-23-15-11-13-026.png" size="75420" author="RivenSun" created="Mon, 23 Jun 2025 07:11:16 +0000"/>
                            <attachment id="13077160" name="image-2025-06-23-15-33-06-851.png" size="99891" author="RivenSun" created="Mon, 23 Jun 2025 07:33:11 +0000"/>
                            <attachment id="13077159" name="image-2025-06-23-15-33-26-209.png" size="370268" author="RivenSun" created="Mon, 23 Jun 2025 07:33:31 +0000"/>
                            <attachment id="13077190" name="image-2025-06-24-10-27-52-116.png" size="381896" author="RivenSun" created="Tue, 24 Jun 2025 02:27:55 +0000"/>
                            <attachment id="13077191" name="image-2025-06-24-10-29-51-465.png" size="290483" author="RivenSun" created="Tue, 24 Jun 2025 02:29:55 +0000"/>
                            <attachment id="13077192" name="image-2025-06-24-10-41-40-027.png" size="983715" author="RivenSun" created="Tue, 24 Jun 2025 02:41:44 +0000"/>
                            <attachment id="13077193" name="image-2025-06-24-10-43-46-826.png" size="973141" author="RivenSun" created="Tue, 24 Jun 2025 02:43:51 +0000"/>
                            <attachment id="13077194" name="image-2025-06-24-10-50-17-396.png" size="401998" author="RivenSun" created="Tue, 24 Jun 2025 02:50:20 +0000"/>
                            <attachment id="13077208" name="image-2025-06-25-13-46-30-388.png" size="53673" author="RivenSun" created="Wed, 25 Jun 2025 05:46:34 +0000"/>
                            <attachment id="13077213" name="image-2025-06-25-17-06-54-449.png" size="255187" author="RivenSun" created="Wed, 25 Jun 2025 09:06:58 +0000"/>
                            <attachment id="13077215" name="image-2025-06-25-19-10-49-177.png" size="147130" author="RivenSun" created="Wed, 25 Jun 2025 11:10:52 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>18.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            16 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1wfps:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>