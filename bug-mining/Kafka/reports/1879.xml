<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 17:09:25 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-6773] Kafka consumer without group.id crashes when requesting offset on a topic-partition</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-6773</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;After recent changes, when a KafkaConsumer requests the current offset on a topic partition (e.g. via a call to &lt;tt&gt;position&lt;/tt&gt;), the following exception is thrown if the consumer doesn&apos;t belong to a consumer group ( &lt;tt&gt;group.id&lt;/tt&gt;&#160;is unset):&#160;&lt;/p&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
org.apache.kafka.common.KafkaException: Unexpected error in fetch offset response: The configured groupId is invalid &#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler.handle(ConsumerCoordinator.java:835) &#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler.handle(ConsumerCoordinator.java:818) &#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:822) &#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:802) &#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:204) &#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:167) &#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:127) &#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:574) &#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:389) &#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:292) &#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:232) &#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:192) &#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.fetchCommittedOffsets(ConsumerCoordinator.java:469) &#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded(ConsumerCoordinator.java:446) &#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:1788) &#160; &#160; &#160; &#160; at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1429)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13151498">KAFKA-6773</key>
            <summary>Kafka consumer without group.id crashes when requesting offset on a topic-partition</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hachikuji">Jason Gustafson</assignee>
                                    <reporter username="kkonstantine">Konstantine Karantasis</reporter>
                        <labels>
                    </labels>
                <created>Tue, 10 Apr 2018 22:19:11 +0000</created>
                <updated>Thu, 12 Apr 2018 01:22:55 +0000</updated>
                            <resolved>Thu, 12 Apr 2018 01:22:55 +0000</resolved>
                                                                    <component>core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="16433134" author="githubbot" created="Tue, 10 Apr 2018 22:59:18 +0000"  >&lt;p&gt;hachikuji opened a new pull request #4851: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6773&quot; title=&quot;Kafka consumer without group.id crashes when requesting offset on a topic-partition&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6773&quot;&gt;&lt;del&gt;KAFKA-6773&lt;/del&gt;&lt;/a&gt;; Allow offset commit/fetch/describe with empty groupId&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4851&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4851&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   We had a regression in #4788 which caused the offset commit/fetch/describe APIs to fail if the groupId was empty. This should be allowed for backwards compatibility. I&apos;ve added a test case to ensure that we do not miss this again in the future.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Committer Checklist (excluded from commit message)&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Verify design and implementation&lt;/li&gt;
	&lt;li&gt;[ ] Verify test coverage and CI build status&lt;/li&gt;
	&lt;li&gt;[ ] Verify documentation (including upgrade notes)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16434735" author="githubbot" created="Wed, 11 Apr 2018 23:47:15 +0000"  >&lt;p&gt;hachikuji closed pull request #4851: &lt;a href=&quot;https://issues.apache.org/jira/browse/KAFKA-6773&quot; title=&quot;Kafka consumer without group.id crashes when requesting offset on a topic-partition&quot; class=&quot;issue-link&quot; data-issue-key=&quot;KAFKA-6773&quot;&gt;&lt;del&gt;KAFKA-6773&lt;/del&gt;&lt;/a&gt;; Allow offset commit/fetch/describe with empty groupId&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/kafka/pull/4851&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/kafka/pull/4851&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/core/src/main/scala/kafka/coordinator/group/GroupCoordinator.scala b/core/src/main/scala/kafka/coordinator/group/GroupCoordinator.scala&lt;br/&gt;
index 225b7090761..cbbd91396b2 100644&lt;br/&gt;
&amp;#8212; a/core/src/main/scala/kafka/coordinator/group/GroupCoordinator.scala&lt;br/&gt;
+++ b/core/src/main/scala/kafka/coordinator/group/GroupCoordinator.scala&lt;br/&gt;
@@ -27,7 +27,7 @@ import kafka.utils.Logging&lt;br/&gt;
 import kafka.zk.KafkaZkClient&lt;br/&gt;
 import org.apache.kafka.common.TopicPartition&lt;br/&gt;
 import org.apache.kafka.common.internals.Topic&lt;br/&gt;
-import org.apache.kafka.common.protocol.Errors&lt;br/&gt;
+import org.apache.kafka.common.protocol.&lt;/p&gt;
{ApiKeys, Errors}
&lt;p&gt; import org.apache.kafka.common.record.RecordBatch.&lt;/p&gt;
{NO_PRODUCER_EPOCH, NO_PRODUCER_ID}
&lt;p&gt; import org.apache.kafka.common.requests._&lt;br/&gt;
 import org.apache.kafka.common.utils.Time&lt;br/&gt;
@@ -109,7 +109,7 @@ class GroupCoordinator(val brokerId: Int,&lt;br/&gt;
                       protocolType: String,&lt;br/&gt;
                       protocols: List[(String, Array&lt;span class=&quot;error&quot;&gt;&amp;#91;Byte&amp;#93;&lt;/span&gt;)],&lt;br/&gt;
                       responseCallback: JoinCallback): Unit = {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;validateGroup(groupId).foreach { error =&amp;gt;&lt;br/&gt;
+    validateGroupStatus(groupId, ApiKeys.JOIN_GROUP).foreach 
{ error =&amp;gt;
       responseCallback(joinError(memberId, error))
       return
     }
&lt;p&gt;@@ -237,7 +237,7 @@ class GroupCoordinator(val brokerId: Int,&lt;br/&gt;
                       memberId: String,&lt;br/&gt;
                       groupAssignment: Map[String, Array&lt;span class=&quot;error&quot;&gt;&amp;#91;Byte&amp;#93;&lt;/span&gt;],&lt;br/&gt;
                       responseCallback: SyncCallback): Unit = {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;validateGroup(groupId) match {&lt;br/&gt;
+    validateGroupStatus(groupId, ApiKeys.SYNC_GROUP) match 
{
       case Some(error) if error == Errors.COORDINATOR_LOAD_IN_PROGRESS =&amp;gt;
         // The coordinator is loading, which means we&apos;ve lost the state of the active rebalance and the
         // group will need to start over at JoinGroup. By returning rebalance in progress, the consumer
@@ -313,7 +313,7 @@ class GroupCoordinator(val brokerId: Int,
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def handleLeaveGroup(groupId: String, memberId: String, responseCallback: Errors =&amp;gt; Unit): Unit = {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;validateGroup(groupId).foreach { error =&amp;gt;&lt;br/&gt;
+    validateGroupStatus(groupId, ApiKeys.LEAVE_GROUP).foreach 
{ error =&amp;gt;
       responseCallback(error)
       return
     }
&lt;p&gt;@@ -346,7 +346,7 @@ class GroupCoordinator(val brokerId: Int,&lt;br/&gt;
     var groupsEligibleForDeletion: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;GroupMetadata&amp;#93;&lt;/span&gt; = Seq()&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     groupIds.foreach { groupId =&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;validateGroup(groupId) match {&lt;br/&gt;
+      validateGroupStatus(groupId, ApiKeys.DELETE_GROUPS) match {&lt;br/&gt;
         case Some(error) =&amp;gt;&lt;br/&gt;
           groupErrors += groupId -&amp;gt; error&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -386,7 +386,7 @@ class GroupCoordinator(val brokerId: Int,&lt;br/&gt;
                       memberId: String,&lt;br/&gt;
                       generationId: Int,&lt;br/&gt;
                       responseCallback: Errors =&amp;gt; Unit) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;validateGroup(groupId).foreach { error =&amp;gt;&lt;br/&gt;
+    validateGroupStatus(groupId, ApiKeys.HEARTBEAT).foreach { error =&amp;gt;&lt;br/&gt;
       if (error == Errors.COORDINATOR_LOAD_IN_PROGRESS)&lt;br/&gt;
         // the group is still loading, so respond just blindly&lt;br/&gt;
         responseCallback(Errors.NONE)&lt;br/&gt;
@@ -448,7 +448,7 @@ class GroupCoordinator(val brokerId: Int,&lt;br/&gt;
                              producerEpoch: Short,&lt;br/&gt;
                              offsetMetadata: immutable.Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, OffsetAndMetadata&amp;#93;&lt;/span&gt;,&lt;br/&gt;
                              responseCallback: immutable.Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, Errors&amp;#93;&lt;/span&gt; =&amp;gt; Unit): Unit = {&lt;/li&gt;
	&lt;li&gt;validateGroup(groupId) match {&lt;br/&gt;
+    validateGroupStatus(groupId, ApiKeys.TXN_OFFSET_COMMIT) match {&lt;br/&gt;
       case Some(error) =&amp;gt; responseCallback(offsetMetadata.mapValues(_ =&amp;gt; error))&lt;br/&gt;
       case None =&amp;gt;&lt;br/&gt;
         val group = groupManager.getGroup(groupId).getOrElse {&lt;br/&gt;
@@ -463,7 +463,7 @@ class GroupCoordinator(val brokerId: Int,&lt;br/&gt;
                           generationId: Int,&lt;br/&gt;
                           offsetMetadata: immutable.Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, OffsetAndMetadata&amp;#93;&lt;/span&gt;,&lt;br/&gt;
                           responseCallback: immutable.Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, Errors&amp;#93;&lt;/span&gt; =&amp;gt; Unit) {&lt;/li&gt;
	&lt;li&gt;validateGroup(groupId) match {&lt;br/&gt;
+    validateGroupStatus(groupId, ApiKeys.OFFSET_COMMIT) match {&lt;br/&gt;
       case Some(error) =&amp;gt; responseCallback(offsetMetadata.mapValues(_ =&amp;gt; error))&lt;br/&gt;
       case None =&amp;gt;&lt;br/&gt;
         groupManager.getGroup(groupId) match {&lt;br/&gt;
@@ -524,7 +524,7 @@ class GroupCoordinator(val brokerId: Int,&lt;br/&gt;
   def handleFetchOffsets(groupId: String, partitions: Option[Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition&amp;#93;&lt;/span&gt;] = None):&lt;br/&gt;
   (Errors, Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, OffsetFetchResponse.PartitionData&amp;#93;&lt;/span&gt;) = {&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;validateGroup(groupId) match {&lt;br/&gt;
+    validateGroupStatus(groupId, ApiKeys.OFFSET_FETCH) match 
{
       case Some(error) =&amp;gt; error -&amp;gt; Map.empty
       case None =&amp;gt;
         // return offsets blindly regardless the current group state since the group may be using
@@ -543,7 +543,7 @@ class GroupCoordinator(val brokerId: Int,
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def handleDescribeGroup(groupId: String): (Errors, GroupSummary) = {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;validateGroup(groupId) match {&lt;br/&gt;
+    validateGroupStatus(groupId, ApiKeys.DESCRIBE_GROUPS) match {&lt;br/&gt;
       case Some(error) =&amp;gt; (error, GroupCoordinator.EmptyGroup)&lt;br/&gt;
       case None =&amp;gt;&lt;br/&gt;
         groupManager.getGroup(groupId) match {&lt;br/&gt;
@@ -563,8 +563,23 @@ class GroupCoordinator(val brokerId: Int,&lt;br/&gt;
     info(s&quot;Removed $offsetsRemoved offsets associated with deleted partitions: ${topicPartitions.mkString(&quot;, &quot;)}.&quot;)&lt;br/&gt;
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private def validateGroup(groupId: String): Option&lt;span class=&quot;error&quot;&gt;&amp;#91;Errors&amp;#93;&lt;/span&gt; = {&lt;/li&gt;
	&lt;li&gt;if (!validGroupId(groupId))&lt;br/&gt;
+  private def isValidGroupId(groupId: String, api: ApiKeys): Boolean = 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+    api match {
+      case ApiKeys.OFFSET_COMMIT | ApiKeys.OFFSET_FETCH | ApiKeys.DESCRIBE_GROUPS | ApiKeys.DELETE_GROUPS =&amp;gt;
+        // For backwards compatibility, we support the offset commit APIs for the empty groupId, and also
+        // in DescribeGroups and DeleteGroups so that users can view and delete state of all groups.
+        groupId != null
+      case _ =&amp;gt;
+        // The remaining APIs are groups using Kafka for group coordination and must have a non-empty groupId
+        groupId != null &amp;amp;&amp;amp; !groupId.isEmpty
+    }+  }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;+&lt;br/&gt;
+  /**&lt;br/&gt;
+   * Check that the groupId is valid, assigned to this coordinator and that the group has been loaded.&lt;br/&gt;
+   */&lt;br/&gt;
+  private def validateGroupStatus(groupId: String, api: ApiKeys): Option&lt;span class=&quot;error&quot;&gt;&amp;#91;Errors&amp;#93;&lt;/span&gt; = &lt;/p&gt;
{
+    if (!isValidGroupId(groupId, api))
       Some(Errors.INVALID_GROUP_ID)
     else if (!isActive.get)
       Some(Errors.COORDINATOR_NOT_AVAILABLE)
@@ -648,10 +663,6 @@ class GroupCoordinator(val brokerId: Int,
     }
&lt;p&gt;   }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private def validGroupId(groupId: String): Boolean = 
{
-    groupId != null &amp;amp;&amp;amp; !groupId.isEmpty
-  }
&lt;p&gt;-&lt;br/&gt;
   private def joinError(memberId: String, error: Errors): JoinGroupResult = {&lt;br/&gt;
     JoinGroupResult(&lt;br/&gt;
       members = Map.empty,&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/admin/DeleteConsumerGroupsTest.scala b/core/src/test/scala/unit/kafka/admin/DeleteConsumerGroupsTest.scala&lt;br/&gt;
index effa55d1b2f..4cc28372449 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/test/scala/unit/kafka/admin/DeleteConsumerGroupsTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/admin/DeleteConsumerGroupsTest.scala&lt;br/&gt;
@@ -59,32 +59,6 @@ class DeleteConsumerGroupTest extends ConsumerGroupCommandTest 
{
       result.size == 1 &amp;amp;&amp;amp; result.keySet.contains(missingGroup) &amp;amp;&amp;amp; result.get(missingGroup).contains(Errors.GROUP_ID_NOT_FOUND))
   }&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test&lt;/li&gt;
	&lt;li&gt;def testDeleteCmdInvalidGroupId() {&lt;/li&gt;
	&lt;li&gt;TestUtils.createOffsetsTopic(zkClient, servers)&lt;/li&gt;
	&lt;li&gt;val invalidGroupId = &quot;&quot;&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;val cgcArgs = Array(&quot;-&lt;del&gt;bootstrap-server&quot;, brokerList, &quot;&lt;/del&gt;&lt;del&gt;delete&quot;, &quot;&lt;/del&gt;-group&quot;, invalidGroupId)&lt;/li&gt;
	&lt;li&gt;val service = getConsumerGroupService(cgcArgs)&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;val output = TestUtils.grabConsoleOutput(service.deleteGroups())&lt;/li&gt;
	&lt;li&gt;assertTrue(s&quot;The expected error (${Errors.INVALID_GROUP_ID}) was not detected while deleting consumer group&quot;,&lt;/li&gt;
	&lt;li&gt;output.contains(s&quot;Group &apos;$invalidGroupId&apos; could not be deleted due to: ${Errors.INVALID_GROUP_ID.toString}&quot;))&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;@Test&lt;/li&gt;
	&lt;li&gt;def testDeleteInvalidGroupId() {&lt;/li&gt;
	&lt;li&gt;TestUtils.createOffsetsTopic(zkClient, servers)&lt;/li&gt;
	&lt;li&gt;val invalidGroupId = &quot;&quot;&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;val cgcArgs = Array(&quot;-&lt;del&gt;bootstrap-server&quot;, brokerList, &quot;&lt;/del&gt;&lt;del&gt;delete&quot;, &quot;&lt;/del&gt;-group&quot;, invalidGroupId)&lt;/li&gt;
	&lt;li&gt;val service = getConsumerGroupService(cgcArgs)&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;val result = service.deleteGroups()&lt;/li&gt;
	&lt;li&gt;assertTrue(s&quot;The expected error (${Errors.INVALID_GROUP_ID}) was not detected while deleting consumer group&quot;,&lt;/li&gt;
	&lt;li&gt;result.size == 1 &amp;amp;&amp;amp; result.keySet.contains(invalidGroupId) &amp;amp;&amp;amp; result.get(invalidGroupId).contains(Errors.INVALID_GROUP_ID))&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;br/&gt;
   @Test&lt;br/&gt;
   def testDeleteCmdNonEmptyGroup() {&lt;br/&gt;
     TestUtils.createOffsetsTopic(zkClient, servers)&lt;br/&gt;
diff --git a/core/src/test/scala/unit/kafka/coordinator/group/GroupCoordinatorTest.scala b/core/src/test/scala/unit/kafka/coordinator/group/GroupCoordinatorTest.scala&lt;br/&gt;
index 08c13eb9195..933e91bfcec 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/core/src/test/scala/unit/kafka/coordinator/group/GroupCoordinatorTest.scala&lt;br/&gt;
+++ b/core/src/test/scala/unit/kafka/coordinator/group/GroupCoordinatorTest.scala&lt;br/&gt;
@@ -37,7 +37,7 @@ import org.junit.Assert._&lt;br/&gt;
 import org.junit.
{After, Assert, Before, Test}
&lt;p&gt; import org.scalatest.junit.JUnitSuite&lt;/p&gt;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;-import scala.collection._&lt;br/&gt;
+import scala.collection.mutable&lt;br/&gt;
 import scala.concurrent.duration.Duration&lt;br/&gt;
 import scala.concurrent.&lt;/p&gt;
{Await, Future, Promise, TimeoutException}

&lt;p&gt;@@ -138,7 +138,7 @@ class GroupCoordinatorTest extends JUnitSuite {&lt;br/&gt;
     val topicPartition = new TopicPartition(&quot;foo&quot;, 0)&lt;br/&gt;
     var offsetCommitErrors = Map.empty&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, Errors&amp;#93;&lt;/span&gt;&lt;br/&gt;
     groupCoordinator.handleCommitOffsets(otherGroupId, memberId, 1,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;immutable.Map(topicPartition -&amp;gt; OffsetAndMetadata(15L)), result =&amp;gt; 
{ offsetCommitErrors = result })&lt;br/&gt;
+      Map(topicPartition -&amp;gt; OffsetAndMetadata(15L)), result =&amp;gt; { offsetCommitErrors = result }
&lt;p&gt;)&lt;br/&gt;
     assertEquals(Some(Errors.COORDINATOR_LOAD_IN_PROGRESS), offsetCommitErrors.get(topicPartition))&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // Heartbeat&lt;br/&gt;
@@ -155,7 +155,7 @@ class GroupCoordinatorTest extends JUnitSuite {&lt;br/&gt;
     assertEquals(Errors.COORDINATOR_LOAD_IN_PROGRESS, listGroupsError)&lt;/p&gt;

&lt;p&gt;     // DeleteGroups&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val deleteGroupsErrors = groupCoordinator.handleDeleteGroups(immutable.Set(otherGroupId))&lt;br/&gt;
+    val deleteGroupsErrors = groupCoordinator.handleDeleteGroups(Set(otherGroupId))&lt;br/&gt;
     assertEquals(Some(Errors.COORDINATOR_LOAD_IN_PROGRESS), deleteGroupsErrors.get(otherGroupId))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // Check that non-loading groups are still accessible&lt;br/&gt;
@@ -452,7 +452,7 @@ class GroupCoordinatorTest extends JUnitSuite {&lt;br/&gt;
     timer.advanceClock(sessionTimeout / 2)&lt;/p&gt;

&lt;p&gt;     EasyMock.reset(replicaManager)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val commitOffsetResult = commitOffsets(groupId, assignedConsumerId, generationId, immutable.Map(tp -&amp;gt; offset))&lt;br/&gt;
+    val commitOffsetResult = commitOffsets(groupId, assignedConsumerId, generationId, Map(tp -&amp;gt; offset))&lt;br/&gt;
     assertEquals(Errors.NONE, commitOffsetResult(tp))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     timer.advanceClock(sessionTimeout / 2 + 100)&lt;br/&gt;
@@ -820,7 +820,7 @@ class GroupCoordinatorTest extends JUnitSuite &lt;/p&gt;
{
     val tp = new TopicPartition(&quot;topic&quot;, 0)
     val offset = OffsetAndMetadata(0)
 
-    val commitOffsetResult = commitOffsets(groupId, memberId, generationId, immutable.Map(tp -&amp;gt; offset))
+    val commitOffsetResult = commitOffsets(groupId, memberId, generationId, Map(tp -&amp;gt; offset))
     assertEquals(Errors.ILLEGAL_GENERATION, commitOffsetResult(tp))
   }

&lt;p&gt;@@ -830,7 +830,7 @@ class GroupCoordinatorTest extends JUnitSuite &lt;/p&gt;
{
     val offset = OffsetAndMetadata(0)
 
     val commitOffsetResult = commitOffsets(groupId, OffsetCommitRequest.DEFAULT_MEMBER_ID,
-      OffsetCommitRequest.DEFAULT_GENERATION_ID, immutable.Map(tp -&amp;gt; offset))
+      OffsetCommitRequest.DEFAULT_GENERATION_ID, Map(tp -&amp;gt; offset))
     assertEquals(Errors.NONE, commitOffsetResult(tp))
   }

&lt;p&gt;@@ -856,7 +856,7 @@ class GroupCoordinatorTest extends JUnitSuite {&lt;br/&gt;
     val tp = new TopicPartition(&quot;topic&quot;, 0)&lt;br/&gt;
     val offset = OffsetAndMetadata(0)&lt;br/&gt;
     val commitOffsetResult = commitOffsets(groupId, OffsetCommitRequest.DEFAULT_MEMBER_ID,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;OffsetCommitRequest.DEFAULT_GENERATION_ID, immutable.Map(tp -&amp;gt; offset))&lt;br/&gt;
+      OffsetCommitRequest.DEFAULT_GENERATION_ID, Map(tp -&amp;gt; offset))&lt;br/&gt;
     assertEquals(Errors.NONE, commitOffsetResult(tp))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val (error, partitionData) = groupCoordinator.handleFetchOffsets(groupId, Some(Seq(tp)))&lt;br/&gt;
@@ -870,7 +870,7 @@ class GroupCoordinatorTest extends JUnitSuite {&lt;br/&gt;
     val offset = OffsetAndMetadata(0)&lt;/p&gt;

&lt;p&gt;     val commitOffsetResult = commitOffsets(groupId, OffsetCommitRequest.DEFAULT_MEMBER_ID,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;OffsetCommitRequest.DEFAULT_GENERATION_ID, immutable.Map(tp -&amp;gt; offset))&lt;br/&gt;
+      OffsetCommitRequest.DEFAULT_GENERATION_ID, Map(tp -&amp;gt; offset))&lt;br/&gt;
     assertEquals(Errors.NONE, commitOffsetResult(tp))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val (error, partitionData) = groupCoordinator.handleFetchOffsets(groupId, Some(Seq(tp)))&lt;br/&gt;
@@ -878,6 +878,44 @@ class GroupCoordinatorTest extends JUnitSuite &lt;/p&gt;
{
     assertEquals(Some(0), partitionData.get(tp).map(_.offset))
   }

&lt;p&gt;+  @Test&lt;br/&gt;
+  def testCommitAndFetchOffsetsWithEmptyGroup() &lt;/p&gt;
{
+    // For backwards compatibility, the coordinator supports committing/fetching offsets with an empty groupId.
+    // To allow inspection and removal of the empty group, we must also support DescribeGroups and DeleteGroups
+
+    val tp = new TopicPartition(&quot;topic&quot;, 0)
+    val offset = OffsetAndMetadata(0)
+    val groupId = &quot;&quot;
+
+    val commitOffsetResult = commitOffsets(groupId, OffsetCommitRequest.DEFAULT_MEMBER_ID,
+      OffsetCommitRequest.DEFAULT_GENERATION_ID, Map(tp -&amp;gt; offset))
+    assertEquals(Errors.NONE, commitOffsetResult(tp))
+
+    val (fetchError, partitionData) = groupCoordinator.handleFetchOffsets(groupId, Some(Seq(tp)))
+    assertEquals(Errors.NONE, fetchError)
+    assertEquals(Some(0), partitionData.get(tp).map(_.offset))
+
+    val (describeError, summary) = groupCoordinator.handleDescribeGroup(groupId)
+    assertEquals(Errors.NONE, describeError)
+    assertEquals(Empty.toString, summary.state)
+
+    val groupTopicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, groupPartitionId)
+    val partition = EasyMock.niceMock(classOf[Partition])
+
+    EasyMock.reset(replicaManager)
+    EasyMock.expect(replicaManager.getMagic(EasyMock.anyObject())).andStubReturn(Some(RecordBatch.CURRENT_MAGIC_VALUE))
+    EasyMock.expect(replicaManager.getPartition(groupTopicPartition)).andStubReturn(Some(partition))
+    EasyMock.expect(replicaManager.nonOfflinePartition(groupTopicPartition)).andStubReturn(Some(partition))
+    EasyMock.replay(replicaManager, partition)
+
+    val deleteErrors = groupCoordinator.handleDeleteGroups(Set(groupId))
+    assertEquals(Errors.NONE, deleteErrors(groupId))
+
+    val (err, data) = groupCoordinator.handleFetchOffsets(groupId, Some(Seq(tp)))
+    assertEquals(Errors.NONE, err)
+    assertEquals(Some(OffsetFetchResponse.INVALID_OFFSET), data.get(tp).map(_.offset))
+  }
&lt;p&gt;+&lt;br/&gt;
   @Test&lt;br/&gt;
   def testBasicFetchTxnOffsets() {&lt;br/&gt;
     val tp = new TopicPartition(&quot;topic&quot;, 0)&lt;br/&gt;
@@ -885,7 +923,7 @@ class GroupCoordinatorTest extends JUnitSuite {&lt;br/&gt;
     val producerId = 1000L&lt;br/&gt;
     val producerEpoch : Short = 2&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val commitOffsetResult = commitTransactionalOffsets(groupId, producerId, producerEpoch, immutable.Map(tp -&amp;gt; offset))&lt;br/&gt;
+    val commitOffsetResult = commitTransactionalOffsets(groupId, producerId, producerEpoch, Map(tp -&amp;gt; offset))&lt;br/&gt;
     assertEquals(Errors.NONE, commitOffsetResult(tp))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val (error, partitionData) = groupCoordinator.handleFetchOffsets(groupId, Some(Seq(tp)))&lt;br/&gt;
@@ -912,7 +950,7 @@ class GroupCoordinatorTest extends JUnitSuite {&lt;br/&gt;
     val producerId = 1000L&lt;br/&gt;
     val producerEpoch : Short = 2&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val commitOffsetResult = commitTransactionalOffsets(groupId, producerId, producerEpoch, immutable.Map(tp -&amp;gt; offset))&lt;br/&gt;
+    val commitOffsetResult = commitTransactionalOffsets(groupId, producerId, producerEpoch, Map(tp -&amp;gt; offset))&lt;br/&gt;
     assertEquals(Errors.NONE, commitOffsetResult(tp))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val (error, partitionData) = groupCoordinator.handleFetchOffsets(groupId, Some(Seq(tp)))&lt;br/&gt;
@@ -936,7 +974,7 @@ class GroupCoordinatorTest extends JUnitSuite {&lt;br/&gt;
     val producerId = 1000L&lt;br/&gt;
     val producerEpoch : Short = 2&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val commitOffsetResult = commitTransactionalOffsets(groupId, producerId, producerEpoch, immutable.Map(tp -&amp;gt; offset))&lt;br/&gt;
+    val commitOffsetResult = commitTransactionalOffsets(groupId, producerId, producerEpoch, Map(tp -&amp;gt; offset))&lt;br/&gt;
     assertEquals(Errors.NONE, commitOffsetResult(tp))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val (error, partitionData) = groupCoordinator.handleFetchOffsets(groupId, Some(Seq(tp)))&lt;br/&gt;
@@ -975,16 +1013,16 @@ class GroupCoordinatorTest extends JUnitSuite {&lt;/p&gt;

&lt;p&gt;     groupCoordinator.groupManager.addPartitionOwnership(offsetTopicPartitions(1).partition)&lt;br/&gt;
     val errors = mutable.ArrayBuffer&lt;span class=&quot;error&quot;&gt;&amp;#91;Errors&amp;#93;&lt;/span&gt;()&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val partitionData = mutable.ArrayBuffer[Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, OffsetFetchResponse.PartitionData&amp;#93;&lt;/span&gt;]()&lt;br/&gt;
+    val partitionData = mutable.ArrayBuffer[scala.collection.Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, OffsetFetchResponse.PartitionData&amp;#93;&lt;/span&gt;]()&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val commitOffsetResults = mutable.ArrayBuffer&lt;span class=&quot;error&quot;&gt;&amp;#91;CommitOffsetCallbackParams&amp;#93;&lt;/span&gt;()&lt;/p&gt;

&lt;p&gt;     // Ensure that the two groups map to different partitions.&lt;br/&gt;
     assertNotEquals(offsetTopicPartitions(0), offsetTopicPartitions(1))&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;commitOffsetResults.append(commitTransactionalOffsets(groupId, producerId, producerEpoch, immutable.Map(partitions(0) -&amp;gt; offsets(0))))&lt;br/&gt;
+    commitOffsetResults.append(commitTransactionalOffsets(groupId, producerId, producerEpoch, Map(partitions(0) -&amp;gt; offsets(0))))&lt;br/&gt;
     assertEquals(Errors.NONE, commitOffsetResults(0)(partitions(0)))&lt;/li&gt;
	&lt;li&gt;commitOffsetResults.append(commitTransactionalOffsets(otherGroupId, producerId, producerEpoch, immutable.Map(partitions(1) -&amp;gt; offsets(1))))&lt;br/&gt;
+    commitOffsetResults.append(commitTransactionalOffsets(otherGroupId, producerId, producerEpoch, Map(partitions(1) -&amp;gt; offsets(1))))&lt;br/&gt;
     assertEquals(Errors.NONE, commitOffsetResults(1)(partitions(1)))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // We got a commit for only one __consumer_offsets partition. We should only materialize it&apos;s group offsets.&lt;br/&gt;
@@ -1051,16 +1089,16 @@ class GroupCoordinatorTest extends JUnitSuite {&lt;br/&gt;
     val offsetTopicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, groupCoordinator.partitionFor(groupId))&lt;/p&gt;

&lt;p&gt;     val errors = mutable.ArrayBuffer&lt;span class=&quot;error&quot;&gt;&amp;#91;Errors&amp;#93;&lt;/span&gt;()&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val partitionData = mutable.ArrayBuffer[Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, OffsetFetchResponse.PartitionData&amp;#93;&lt;/span&gt;]()&lt;br/&gt;
+    val partitionData = mutable.ArrayBuffer[scala.collection.Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, OffsetFetchResponse.PartitionData&amp;#93;&lt;/span&gt;]()&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val commitOffsetResults = mutable.ArrayBuffer&lt;span class=&quot;error&quot;&gt;&amp;#91;CommitOffsetCallbackParams&amp;#93;&lt;/span&gt;()&lt;/p&gt;

&lt;p&gt;     // producer0 commits the offsets for partition0&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;commitOffsetResults.append(commitTransactionalOffsets(groupId, producerIds(0), producerEpochs(0), immutable.Map(partitions(0) -&amp;gt; offsets(0))))&lt;br/&gt;
+    commitOffsetResults.append(commitTransactionalOffsets(groupId, producerIds(0), producerEpochs(0), Map(partitions(0) -&amp;gt; offsets(0))))&lt;br/&gt;
     assertEquals(Errors.NONE, commitOffsetResults(0)(partitions(0)))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // producer1 commits the offsets for partition1&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;commitOffsetResults.append(commitTransactionalOffsets(groupId, producerIds(1), producerEpochs(1), immutable.Map(partitions(1) -&amp;gt; offsets(1))))&lt;br/&gt;
+    commitOffsetResults.append(commitTransactionalOffsets(groupId, producerIds(1), producerEpochs(1), Map(partitions(1) -&amp;gt; offsets(1))))&lt;br/&gt;
     assertEquals(Errors.NONE, commitOffsetResults(1)(partitions(1)))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // producer0 commits its transaction.&lt;br/&gt;
@@ -1123,7 +1161,7 @@ class GroupCoordinatorTest extends JUnitSuite {&lt;br/&gt;
     assertEquals((Errors.NONE, Map.empty), groupCoordinator.handleFetchOffsets(groupId))&lt;/p&gt;

&lt;p&gt;     val commitOffsetResult = commitOffsets(groupId, OffsetCommitRequest.DEFAULT_MEMBER_ID,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;OffsetCommitRequest.DEFAULT_GENERATION_ID, immutable.Map(tp1 -&amp;gt; offset1, tp2 -&amp;gt; offset2, tp3 -&amp;gt; offset3))&lt;br/&gt;
+      OffsetCommitRequest.DEFAULT_GENERATION_ID, Map(tp1 -&amp;gt; offset1, tp2 -&amp;gt; offset2, tp3 -&amp;gt; offset3))&lt;br/&gt;
     assertEquals(Errors.NONE, commitOffsetResult(tp1))&lt;br/&gt;
     assertEquals(Errors.NONE, commitOffsetResult(tp2))&lt;br/&gt;
     assertEquals(Errors.NONE, commitOffsetResult(tp3))&lt;br/&gt;
@@ -1150,7 +1188,7 @@ class GroupCoordinatorTest extends JUnitSuite 
{
     assertEquals(Errors.NONE, joinGroupError)
 
     EasyMock.reset(replicaManager)
-    val commitOffsetResult = commitOffsets(groupId, assignedMemberId, generationId, immutable.Map(tp -&amp;gt; offset))
+    val commitOffsetResult = commitOffsets(groupId, assignedMemberId, generationId, Map(tp -&amp;gt; offset))
     assertEquals(Errors.REBALANCE_IN_PROGRESS, commitOffsetResult(tp))
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -1332,20 +1370,20 @@ class GroupCoordinatorTest extends JUnitSuite &lt;/p&gt;
{
     val memberId = JoinGroupRequest.UNKNOWN_MEMBER_ID
     joinGroup(groupId, memberId, protocolType, protocols)
 
-    val result = groupCoordinator.handleDeleteGroups(Set(groupId).toSet)
+    val result = groupCoordinator.handleDeleteGroups(Set(groupId))
     assert(result.size == 1 &amp;amp;&amp;amp; result.contains(groupId) &amp;amp;&amp;amp; result.get(groupId).contains(Errors.NON_EMPTY_GROUP))
   }

&lt;p&gt;   @Test&lt;br/&gt;
   def testDeleteGroupWithInvalidGroupId() &lt;/p&gt;
{
-    val invalidGroupId = &quot;&quot;
-    val result = groupCoordinator.handleDeleteGroups(Set(invalidGroupId).toSet)
+    val invalidGroupId = null
+    val result = groupCoordinator.handleDeleteGroups(Set(invalidGroupId))
     assert(result.size == 1 &amp;amp;&amp;amp; result.contains(invalidGroupId) &amp;amp;&amp;amp; result.get(invalidGroupId).contains(Errors.INVALID_GROUP_ID))
   }

&lt;p&gt;   @Test&lt;br/&gt;
   def testDeleteGroupWithWrongCoordinator() &lt;/p&gt;
{
-    val result = groupCoordinator.handleDeleteGroups(Set(otherGroupId).toSet)
+    val result = groupCoordinator.handleDeleteGroups(Set(otherGroupId))
     assert(result.size == 1 &amp;amp;&amp;amp; result.contains(otherGroupId) &amp;amp;&amp;amp; result.get(otherGroupId).contains(Errors.NOT_COORDINATOR))
   }

&lt;p&gt;@@ -1367,7 +1405,7 @@ class GroupCoordinatorTest extends JUnitSuite &lt;/p&gt;
{
     EasyMock.expect(replicaManager.nonOfflinePartition(groupTopicPartition)).andStubReturn(Some(partition))
     EasyMock.replay(replicaManager, partition)
 
-    val result = groupCoordinator.handleDeleteGroups(Set(groupId).toSet)
+    val result = groupCoordinator.handleDeleteGroups(Set(groupId))
     assert(result.size == 1 &amp;amp;&amp;amp; result.contains(groupId) &amp;amp;&amp;amp; result.get(groupId).contains(Errors.NONE))
   }

&lt;p&gt;@@ -1388,7 +1426,7 @@ class GroupCoordinatorTest extends JUnitSuite {&lt;br/&gt;
     EasyMock.reset(replicaManager)&lt;br/&gt;
     val tp = new TopicPartition(&quot;topic&quot;, 0)&lt;br/&gt;
     val offset = OffsetAndMetadata(0)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val commitOffsetResult = commitOffsets(groupId, assignedMemberId, joinGroupResult.generationId, immutable.Map(tp -&amp;gt; offset))&lt;br/&gt;
+    val commitOffsetResult = commitOffsets(groupId, assignedMemberId, joinGroupResult.generationId, Map(tp -&amp;gt; offset))&lt;br/&gt;
     assertEquals(Errors.NONE, commitOffsetResult(tp))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     val describeGroupResult = groupCoordinator.handleDescribeGroup(groupId)&lt;br/&gt;
@@ -1408,7 +1446,7 @@ class GroupCoordinatorTest extends JUnitSuite {&lt;br/&gt;
     EasyMock.expect(replicaManager.nonOfflinePartition(groupTopicPartition)).andStubReturn(Some(partition))&lt;br/&gt;
     EasyMock.replay(replicaManager, partition)&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val result = groupCoordinator.handleDeleteGroups(Set(groupId).toSet)&lt;br/&gt;
+    val result = groupCoordinator.handleDeleteGroups(Set(groupId))&lt;br/&gt;
     assert(result.size == 1 &amp;amp;&amp;amp; result.contains(groupId) &amp;amp;&amp;amp; result.get(groupId).contains(Errors.NONE))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     assertEquals(Dead.toString, groupCoordinator.handleDescribeGroup(groupId)._2.state)&lt;br/&gt;
@@ -1535,7 +1573,7 @@ class GroupCoordinatorTest extends JUnitSuite {&lt;br/&gt;
                                   assignment: Map[String, Array&lt;span class=&quot;error&quot;&gt;&amp;#91;Byte&amp;#93;&lt;/span&gt;]): Future&lt;span class=&quot;error&quot;&gt;&amp;#91;SyncGroupCallbackParams&amp;#93;&lt;/span&gt; = {&lt;br/&gt;
     val (responseFuture, responseCallback) = setupSyncGroupCallback&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val capturedArgument: Capture[Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, PartitionResponse&amp;#93;&lt;/span&gt; =&amp;gt; Unit] = EasyMock.newCapture()&lt;br/&gt;
+    val capturedArgument: Capture[scala.collection.Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, PartitionResponse&amp;#93;&lt;/span&gt; =&amp;gt; Unit] = EasyMock.newCapture()&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     EasyMock.expect(replicaManager.appendRecords(EasyMock.anyLong(),&lt;br/&gt;
       EasyMock.anyShort(),&lt;br/&gt;
@@ -1616,10 +1654,10 @@ class GroupCoordinatorTest extends JUnitSuite {&lt;br/&gt;
   private def commitOffsets(groupId: String,&lt;br/&gt;
                             consumerId: String,&lt;br/&gt;
                             generationId: Int,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;offsets: immutable.Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, OffsetAndMetadata&amp;#93;&lt;/span&gt;): CommitOffsetCallbackParams = {&lt;br/&gt;
+                            offsets: Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, OffsetAndMetadata&amp;#93;&lt;/span&gt;): CommitOffsetCallbackParams = {&lt;br/&gt;
     val (responseFuture, responseCallback) = setupCommitOffsetsCallback&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val capturedArgument: Capture[Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, PartitionResponse&amp;#93;&lt;/span&gt; =&amp;gt; Unit] = EasyMock.newCapture()&lt;br/&gt;
+    val capturedArgument: Capture[scala.collection.Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, PartitionResponse&amp;#93;&lt;/span&gt; =&amp;gt; Unit] = EasyMock.newCapture()&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     EasyMock.expect(replicaManager.appendRecords(EasyMock.anyLong(),&lt;br/&gt;
       EasyMock.anyShort(),&lt;br/&gt;
@@ -1646,10 +1684,10 @@ class GroupCoordinatorTest extends JUnitSuite {&lt;br/&gt;
   private def commitTransactionalOffsets(groupId: String,&lt;br/&gt;
                                          producerId: Long,&lt;br/&gt;
                                          producerEpoch: Short,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;offsets: immutable.Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, OffsetAndMetadata&amp;#93;&lt;/span&gt;): CommitOffsetCallbackParams = {&lt;br/&gt;
+                                         offsets: Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, OffsetAndMetadata&amp;#93;&lt;/span&gt;): CommitOffsetCallbackParams = {&lt;br/&gt;
     val (responseFuture, responseCallback) = setupCommitOffsetsCallback&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;val capturedArgument: Capture[Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, PartitionResponse&amp;#93;&lt;/span&gt; =&amp;gt; Unit] = EasyMock.newCapture()&lt;br/&gt;
+    val capturedArgument: Capture[scala.collection.Map&lt;span class=&quot;error&quot;&gt;&amp;#91;TopicPartition, PartitionResponse&amp;#93;&lt;/span&gt; =&amp;gt; Unit] = EasyMock.newCapture()&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     EasyMock.expect(replicaManager.appendRecords(EasyMock.anyLong(),&lt;br/&gt;
       EasyMock.anyShort(),&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 31 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3se2v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>