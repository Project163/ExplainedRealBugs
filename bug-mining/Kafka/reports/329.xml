<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 16:38:53 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[KAFKA-955] After a leader change, messages sent with ack=0 are lost</title>
                <link>https://issues.apache.org/jira/browse/KAFKA-955</link>
                <project id="12311720" key="KAFKA">Kafka</project>
                    <description>&lt;p&gt;If the leader changes for a partition, and a producer is sending messages with ack=0, then messages will be lost, since the producer has no active way of knowing that the leader has changed, until it&apos;s next metadata refresh update.&lt;/p&gt;

&lt;p&gt;The broker receiving the message, which is no longer the leader, logs a message like this:&lt;/p&gt;

&lt;p&gt;Produce request with correlation id 7136261 from client  on partition &lt;span class=&quot;error&quot;&gt;&amp;#91;mytopic,0&amp;#93;&lt;/span&gt; failed due to Leader not local for partition &lt;span class=&quot;error&quot;&gt;&amp;#91;mytopic,0&amp;#93;&lt;/span&gt; on broker 508818741&lt;/p&gt;

&lt;p&gt;This is exacerbated by the controlled shutdown mechanism, which forces an immediate leader change.&lt;/p&gt;

&lt;p&gt;A possible solution to this would be for a broker which receives a message, for a topic that it is no longer the leader for (and if the ack level is 0), then the broker could just silently forward the message over to the current leader.&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12654664">KAFKA-955</key>
            <summary>After a leader change, messages sent with ack=0 are lost</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="guozhang">Guozhang Wang</assignee>
                                    <reporter username="jbrosenberg">Jason Rosenberg</reporter>
                        <labels>
                    </labels>
                <created>Tue, 25 Jun 2013 05:24:34 +0000</created>
                <updated>Thu, 3 Nov 2016 07:12:34 +0000</updated>
                            <resolved>Wed, 28 Aug 2013 17:17:44 +0000</resolved>
                                    <version>0.8.0</version>
                                    <fixVersion>0.8.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>9</watches>
                                                                                                                <comments>
                            <comment id="13696123" author="jbrosenberg" created="Sat, 29 Jun 2013 13:14:35 +0000"  >&lt;p&gt;Here&apos;s a related scenario, that I see after a rolling restart of my brokers (using ack=0).&lt;/p&gt;

&lt;p&gt;looking back at my logs, I&apos;m wondering if a producer will reuse the same socket to send data to the same broker, for multiple topics (I&apos;m guessing yes).  In which case, it looks like I&apos;m seeing this scenario:&lt;/p&gt;

&lt;p&gt;1. producer1 is happily sending messages for topicX and topicY to serverA (serverA is the leader for both topics, only 1 partition for each topic for simplicity).&lt;br/&gt;
2. serverA is restarted, and in the process, serverB becomes the new leader for both topicX and topicY.&lt;br/&gt;
3. producer1 decides to send a new message to topicX to serverA.&lt;br/&gt;
3a. this results in an exception (&quot;Connection reset by peer&quot;).  producer1&apos;s connection to serverA is invalidated.&lt;br/&gt;
3b. producer1 makes a new metadata request for topicX, and learns that serverB is now the leader for topicX.&lt;br/&gt;
3c. producer1 resends the message to topicX, on serverB.&lt;br/&gt;
4. producer1 decides to send a new message to topicY to serverA.&lt;br/&gt;
4a. producer1 notes that it&apos;s socket to serverA is invalid, so it creates a new connection to serverA.&lt;br/&gt;
4b. producer1 successfully sends it&apos;s message to serverA (without realizing that serverA is no longer the leader for topicY).&lt;br/&gt;
4c. serverA logs to it&apos;s console:  &lt;br/&gt;
2013-06-23 08:28:46,770  WARN &lt;span class=&quot;error&quot;&gt;&amp;#91;kafka-request-handler-2&amp;#93;&lt;/span&gt; server.KafkaApis - &lt;span class=&quot;error&quot;&gt;&amp;#91;KafkaApi-508818741&amp;#93;&lt;/span&gt; Produce request with correlation id 7136261 from client  on partition &lt;span class=&quot;error&quot;&gt;&amp;#91;mytopic,0&amp;#93;&lt;/span&gt; failed due to Leader not local for partition &lt;span class=&quot;error&quot;&gt;&amp;#91;mytopic,0&amp;#93;&lt;/span&gt; on broker 508818741&lt;br/&gt;
5. producer1 continues to send messages for topicY to serverA, and serverA continues to log the same messages.&lt;br/&gt;
6. 10 minutes later, producer1 decides to update it&apos;s metadata for topicY, and learns that serverB is now the leader for topidY.&lt;br/&gt;
7. the warning messages finally stop in the console for serverA.&lt;/p&gt;

&lt;p&gt;I am pretty sure this scenario, or one very close to it, is what I&apos;m seeing in my logs, after doing a rolling restart, with controlled shutdown.&lt;/p&gt;

&lt;p&gt;I think this scenario makes the issue more severe than just a problem with controlled restart and ack=0.&lt;/p&gt;
</comment>
                            <comment id="13696464" author="junrao" created="Mon, 1 Jul 2013 04:20:20 +0000"  >&lt;p&gt;It seems there are various ways that can cause this to happen. (a) In the above scenario, after the leaders fail over, topicX causes new sockets to be established. Then topicY uses the newly established socket without realizing that the leader for topic Y has changed. (b) When we fetch the metadata for a topic, we fetch the metadata for all partitions. Let&apos;s say that we never get to send any data to a particular partition. The socket for this partition is not established since  SyncProducer make socket connections lazily on first send. Then the leader for the partition changes. Finally, the producer sends a message to that partition. Now a socket is established to the wrong leader without the producer realizing it.&lt;/p&gt;

&lt;p&gt;In general, if we hit any error for produce requests with ack=0, currently the producer won&apos;t notice it. For example, if the broker hits a MessageTooLargeException or if the broker hits any other unexpected exceptions. In those cases, forwarding the requests will not help. Also, forwarding requests will complicate the logic in the broker since we have to figure out the broker&apos;s host and port, and potentially cache the socket connection to other brokers.&lt;/p&gt;

&lt;p&gt;An alternative solution is to simply close the socket connection when we hit any error for produce requests with ack=0. This way, the producer will realize the error on next send.&lt;/p&gt;</comment>
                            <comment id="13720260" author="guozhang" created="Thu, 25 Jul 2013 23:50:26 +0000"  >&lt;p&gt;Following the close-socket approach, I propose the following change:&lt;/p&gt;

&lt;p&gt;1. Add a closeSocket: Boolean field in Response class.&lt;/p&gt;

&lt;p&gt;2. In KafkaApi.handleProducerRequest, if requireAck == 0 check if numPartitionsInError != 0. If yes set closeSocket to true in the returning response.&lt;/p&gt;

&lt;p&gt;3. SocketServer.Processor.processNewResponses, if curr.responseSend == null, check if closeSocket == true. If yes, log the closing socket info and close the key.&lt;/p&gt;
</comment>
                            <comment id="13720311" author="guozhang" created="Fri, 26 Jul 2013 00:55:19 +0000"  >&lt;p&gt;Add one case for ack=0 in testSendWithDeadBroker, passed.&lt;/p&gt;</comment>
                            <comment id="13725324" author="junrao" created="Wed, 31 Jul 2013 15:13:52 +0000"  >&lt;p&gt;Thanks for the patch. Some comments:&lt;/p&gt;

&lt;p&gt;1. SocketServer: We should call updateRequestMetrics even when we close the socket. Otherwise, total time will be broken for that request.&lt;/p&gt;

&lt;p&gt;2. ProducerTest: Let&apos;s add a new unit test instead of piggybacking on the existing one. What we can do is to create a sync producer and send a produce request with ack=0 that will introduce an error (e.g., a message larger than max size). After that, we can verified that the underlying socket is closed.&lt;/p&gt;

&lt;p&gt;3. KafkaApi: In the debug logging, why not log the whole producer request? &lt;/p&gt;</comment>
                            <comment id="13725452" author="guozhang" created="Wed, 31 Jul 2013 17:23:40 +0000"  >&lt;p&gt;Thanks for the comments Jun.&lt;/p&gt;

&lt;p&gt;1,2,3. Done.&lt;/p&gt;</comment>
                            <comment id="13727824" author="junrao" created="Fri, 2 Aug 2013 17:20:35 +0000"  >&lt;p&gt;Thanks for patch v2. Some more comments.&lt;/p&gt;

&lt;p&gt;20. testSendWithAckZeroDeadBroker(): I am not sure if the unit test does what you want. First of all, setup() will always start brokers for each test unless you explicitly shut them down. So, in this test, the brokers are not dead. Second, the test doesn&apos;t really test that the socket is closed after error. I suggest that we add a new test in SyncProducerTest. We send a request with ack=0 with a large message. After that, we can try to send a new request again and we should hit a socket I/O exception. We may have to wait for some time between the two requests.&lt;/p&gt;</comment>
                            <comment id="13727910" author="guozhang" created="Fri, 2 Aug 2013 18:13:57 +0000"  >&lt;p&gt;Sorry for the name misleading, I did not shut down the broker but instead send a large message to it to trigger the MessageSizeTooLargeException. The name of the test should be testSendTooLargeMessageWithAckZero.&lt;/p&gt;

&lt;p&gt;I will use SyncProducer instead of Producer in this test, and send a normal message to the broker after this message, and expecting it to fail due to socket IO exception.&lt;/p&gt;</comment>
                            <comment id="13728211" author="guozhang" created="Fri, 2 Aug 2013 22:35:20 +0000"  >&lt;p&gt;Add the testMessageSizeTooLargeWithAckZero to syncProducerTest, which:&lt;/p&gt;

&lt;p&gt;1. First send a large message that will cause the MessageSizeTooLarge exception, and hence close the socket. But this message will be silently dropped and lost.&lt;/p&gt;

&lt;p&gt;2. Then send another large message, but just to make sure its size exceeds the buffer size so the socket buffer will be flushed immediately; this send should fail since the socket has been closed.&lt;/p&gt;</comment>
                            <comment id="13746561" author="edenhill" created="Wed, 21 Aug 2013 16:57:52 +0000"  >
&lt;p&gt;If the producer is sending messages through the same broker for other topic+partitions that did not have a leader change they will also be affected by the close of the socket, resulting in lost messages.&lt;/p&gt;

&lt;p&gt;It would be better if the broker would notify all connected clients of broker changes (leader change, broker add/delete, topic add/delete)&lt;br/&gt;
by sending an unsolicited MetadataResponse message (with corrid 0) (or by some other mean).&lt;/p&gt;

&lt;p&gt;This would propogate topology changes in a faster and less intrusive way.&lt;/p&gt;</comment>
                            <comment id="13746791" author="guozhang" created="Wed, 21 Aug 2013 20:13:59 +0000"  >&lt;p&gt;Hello Magnus,&lt;/p&gt;

&lt;p&gt;1. Under Ack=0, the producer does not expect any responses for produce request, and it does not listen to any possible connections from the producer either. So actively sending MetadataResponse would not work: producers are only expecting MetadataResponse when they send MetadataRequest.&lt;/p&gt;

&lt;p&gt;2. When we close the socket, producer would be notified and try to refresh their Metadata and retry. Since by default each produce request will be retried multiple times before it is got dropped, the current approach would not cause lost messages.&lt;/p&gt;</comment>
                            <comment id="13746810" author="edenhill" created="Wed, 21 Aug 2013 20:33:29 +0000"  >&lt;p&gt;Hi Guozhang,&lt;/p&gt;

&lt;p&gt;I understand that you might not want to introduce a new message semantic at this point of the 0.8 beta, but it wont get easier after the release.&lt;/p&gt;

&lt;p&gt;My proposal is a change of the protocol definition to allow unsolicited metadata response messages to be sent from the broker, this would of course require changes in most clients, but a very small one for those that are not interested in keeping their leader cache up to date.&lt;/p&gt;

&lt;p&gt;Consider a producer forwarding &amp;gt;100kmsgs/s for a number of topics to a broker that suddenly drops the connection because one of those topics changed leader, the producer message queue will quickly build up and might start dropping messages (for topics that didnt loose their leader) due to local queue thresholds or very slowly recover if the current rate of messages is close to the maximum thruput.&lt;/p&gt;


&lt;p&gt;In my mind closing the socket because one top+par changed leader is a very intrusive way to signal an event for sub-set of the communication, and it should instead be fixed properly with an unsoliticed metadata response message.&lt;/p&gt;

&lt;p&gt;The unsolicited metadata response message is useful for other scenarios aswell, new brokers and topics being added, for instance.&lt;/p&gt;

&lt;p&gt;My two cents on the topic, thank you.&lt;/p&gt;</comment>
                            <comment id="13747692" author="junrao" created="Thu, 22 Aug 2013 17:32:22 +0000"  >&lt;p&gt;Magnus, thanks for your comment. What you suggested is interesting and could be a more effective way of communicating between the producer and the broker. It does require that the producer be able to receive requests initiated at the broker. We do plan to make the producer side processing selector based for efficiency reason. However, this will be a post 0.8 item. We could consider your suggestion then. Regarding your concern about dropped messages, my take is the following. If a client chooses not to receive an ack, it probably means that losing a few batch of messages is not that important. If a client does care about data loss, it can choose ack with 1 or -1. The throughout will be less. However, there are other ways to improve the throughput (e.g., using a larger batch size and/or more instances of producers).&lt;/p&gt;

&lt;p&gt;Guozhang, patch v3 looks good to me overall. A few more comments:&lt;/p&gt;

&lt;p&gt;30. SyncProducerTest.testMessagesizeTooLargeWithAckZero(): You hardcoded the sleep to 500ms. Could you change it to the waitUntil style wait such that the test can finish early if the conditions have been met?&lt;/p&gt;

&lt;p&gt;31. KafkaApi.handleProducerRequest(): The logging should probably be at debug level since this doesn&apos;t indicate an error at the broker. It&apos;s really an error for the client.&lt;/p&gt;


</comment>
                            <comment id="13747724" author="guozhang" created="Thu, 22 Aug 2013 17:58:39 +0000"  >&lt;p&gt;Thanks for the comments Jun.&lt;/p&gt;

&lt;p&gt;30. Done.&lt;br/&gt;
31. After a second thought I realized that we do not need to sleep since the second message size is large enough to cause the socket buffer to flush immediately, and by then the socket close should have been triggered by the server. This has been verified in the unit test.&lt;/p&gt;

&lt;p&gt;Made some minor changes on comments and rebased on 0.8&lt;/p&gt;</comment>
                            <comment id="13748671" author="nehanarkhede" created="Fri, 23 Aug 2013 16:15:44 +0000"  >&lt;p&gt;Thanks for the patches, Guozhang. I reviewed patch v4 and here are some comments -&lt;/p&gt;

&lt;p&gt;KafkaApis and SocketServer&lt;br/&gt;
1.1 One way to allow the socket server to close the channel is to just mark the request&apos;s key cancelled in the Response object. This way when the socket server is handling the response, it will throw a CancelledKeyException and we close the key in this case. One advantage of this approach is we can avoid introducing the close socket flag, just to handle this case. To make sure the request metrics are always updated, we can move curr.request.updateRequestMetrics to the first statement in the (curr.responseSend == null) block.&lt;/p&gt;

&lt;p&gt;1.2 I think the below warn message can be improved -&lt;br/&gt;
Sending the close socket signal due to error handling produce request &lt;span class=&quot;error&quot;&gt;&amp;#91;%s&amp;#93;&lt;/span&gt; with Ack=0&lt;/p&gt;

&lt;p&gt;Let&apos;s include the client id, correlation id and list of topics and partitions that this request had. This is probably more useful than printing the entire produce request as is, since that attempts to print things like ByteBufferMessageSet and is unreadable.&lt;/p&gt;</comment>
                            <comment id="13748708" author="guozhang" created="Fri, 23 Aug 2013 16:59:40 +0000"  >&lt;p&gt;Thanks for the comments Neha.&lt;/p&gt;

&lt;p&gt;1.1. Great point. The only concern is that now KafkaApis need to know that requestKey is actually java.nio.channels.SelectionKey. But I think this is fine.&lt;/p&gt;

&lt;p&gt;1.2. Done.&lt;/p&gt;</comment>
                            <comment id="13749038" author="guozhang" created="Fri, 23 Aug 2013 21:50:34 +0000"  >&lt;p&gt;After talking around with people I now proposed an approach similar to v4 but generalized with a responseCode instead of just a close socket flag. And on SocketServer the processor would act based on the code instead of checking if the responseSend is null or not.&lt;/p&gt;

&lt;p&gt;Also change aliveBrokers in KafkaApis from var to val since it is not overwritten in lifetime.&lt;/p&gt;</comment>
                            <comment id="13749410" author="nehanarkhede" created="Sat, 24 Aug 2013 15:23:34 +0000"  >&lt;p&gt;I like the way the responseCode is generalized. Patch v6 looks good, few minor comments before checkin -&lt;/p&gt;

&lt;p&gt;1. Remove unused variable allBrokers from KafkaApis&lt;br/&gt;
2. This comment needs to be changed according to the new response code logic - &lt;br/&gt;
// a null response send object indicates&lt;/p&gt;

&lt;p&gt;Maybe we should wait for review from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jkreps&quot; class=&quot;user-hover&quot; rel=&quot;jkreps&quot;&gt;jkreps&lt;/a&gt; since he has most context on the socket server.&lt;/p&gt;</comment>
                            <comment id="13750375" author="jkreps" created="Mon, 26 Aug 2013 18:32:39 +0000"  >&lt;p&gt;Great fix. A few minor comments, mostly stylistic.&lt;/p&gt;

&lt;p&gt;RequestChannel.scala:&lt;br/&gt;
1. This usage exposes a bit much:&lt;br/&gt;
   requestChannel.sendResponse(new RequestChannel.Response(request.processor, request, null, RequestChannel.CloseSocket))&lt;br/&gt;
I think it might be nicer to have this instead:&lt;br/&gt;
   requestChannel.close(request.processor, request)&lt;br/&gt;
and&lt;br/&gt;
   requestChannel.noResponse(req.processor, request)&lt;br/&gt;
Implementation would be the same, it just would just be a little more clear for the user and the response codes can be private.&lt;/p&gt;

&lt;p&gt;Likewise in the response object I should be able to &lt;/p&gt;

&lt;p&gt;2. These are a little confusing:&lt;br/&gt;
val SendResponse: Short = 0&lt;br/&gt;
val NoResponse: Short = 1&lt;br/&gt;
val CloseSocket: Short = 9&lt;br/&gt;
Why is it 0, 1, and 9?&lt;/p&gt;

&lt;p&gt;What is the relationship between these and ErrorMapping? It should be clear from reading.&lt;/p&gt;

&lt;p&gt;Is there a reason we can&apos;t use a case class&lt;br/&gt;
  case class ResponseAction&lt;br/&gt;
  case object SendAction extends ResponseAction&lt;br/&gt;
  case object NoOpAction extends ResponseAction&lt;br/&gt;
  case object CloseConnectionAction extends ResponseAction&lt;/p&gt;

&lt;p&gt;Then to use it&lt;/p&gt;

&lt;p&gt;response.action match {&lt;br/&gt;
  case SendAction =&amp;gt; do send&lt;br/&gt;
  case NoOpAction =&amp;gt; read more&lt;br/&gt;
  case CloseConnectionAction =&amp;gt; something&lt;br/&gt;
}&lt;/p&gt;

&lt;p&gt;This seems clearer to me and I don&apos;t think it is significantly more expensive.&lt;/p&gt;

&lt;p&gt;Can we also standardize the usage so that we no longer have the user EITHER give null or NoResponse? It should be one or the other.&lt;/p&gt;

&lt;p&gt;3. This logging &quot;Cancelling the request key to notify socket server close the connection due to error handling produce request &quot; is not informative to the user. What does it mean to cancel a key? What broke? What should they do? I also think this should be info unless we want the server admin to take some action (I don&apos;t think so, right? This is a normal occurance).&lt;/p&gt;

&lt;p&gt;SocketServer.scala&lt;br/&gt;
4. The comment &quot;a null response send object&quot; is retained but we are no longer using null to indicate this we are using RequestChannel.NoResponse. I think this comment is actually a little verbose given that we now have a nicely named response action.&lt;/p&gt;

&lt;p&gt;ProducerTest.scala:&lt;br/&gt;
5. org.scalatest.TestFailedException: Is there a reason you are giving the full path here instead of importing it&lt;/p&gt;

&lt;p&gt;Question on testing, what is the message loss rate with acks=0 under moderate load if we do something like a controlled shutdown with other replicas available?&lt;/p&gt;</comment>
                            <comment id="13750735" author="guozhang" created="Mon, 26 Aug 2013 23:28:30 +0000"  >&lt;p&gt;Thanks for the comments, Neha, Jay.&lt;/p&gt;

&lt;p&gt;Neha:&lt;/p&gt;

&lt;p&gt;1. Done.&lt;br/&gt;
2. Incorporated with Jay&apos;s comments.&lt;/p&gt;

&lt;p&gt;Jay:&lt;/p&gt;

&lt;p&gt;1. Done.&lt;br/&gt;
2. Done. I ended up using trait and objects, and let requestChannel.close and requestChannel.noOperation (I changed the name from noResponse here since it matches the noOpAction better) create new responses themselves.&lt;br/&gt;
3. Done.&lt;br/&gt;
4. Done.&lt;br/&gt;
5. Done.&lt;/p&gt;

&lt;p&gt;Regarding your question, the message loss is depending on the producer throughput and queue size. Since the first message will always be silently dropped, and once the producer noticed the socket closure, it will stop producing and refresh new metadata, and if during this time the producer queue is full then it will drop more messages. So the answer would be the range between &lt;span class=&quot;error&quot;&gt;&amp;#91;1, produce-throughput / time-taken-to-refresh-metadata - queue-size&amp;#93;&lt;/span&gt;.&lt;/p&gt;</comment>
                            <comment id="13752583" author="jkreps" created="Wed, 28 Aug 2013 17:06:13 +0000"  >&lt;p&gt;+1 Gorgeous.&lt;/p&gt;</comment>
                            <comment id="13752590" author="nehanarkhede" created="Wed, 28 Aug 2013 17:14:38 +0000"  >&lt;p&gt;This is great. +1. One improvement on logging -&lt;/p&gt;

&lt;p&gt;        info((&quot;Send the close connection response due to error handling produce request &quot; +&lt;br/&gt;
          &quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;clientId = %s, correlationId = %s, topicAndPartition = %s&amp;#93;&lt;/span&gt; with Ack=0&quot;)&lt;br/&gt;
          .format(produceRequest.clientId, produceRequest.correlationId, produceRequest.topicPartitionMessageSizeMap.mkString(&quot;&lt;span class=&quot;error&quot;&gt;&amp;#91;&amp;quot;,&amp;quot;,&amp;quot;,&amp;quot;&amp;#93;&lt;/span&gt;&quot;)))&lt;/p&gt;

&lt;p&gt;Here we only want to print the topic and partition, so it seems that we should be printing the keys of the map, not the entire map ?&lt;br/&gt;
produceRequest.topicPartitionMessageSizeMap.keySet.mkString(&quot;,&quot;)&lt;/p&gt;

&lt;p&gt;I can make this change on checkin.&lt;/p&gt;</comment>
                            <comment id="13752596" author="nehanarkhede" created="Wed, 28 Aug 2013 17:17:44 +0000"  >&lt;p&gt;Committed patch v7 to 0.8 after making the logging fix described above&lt;/p&gt;</comment>
                            <comment id="13756692" author="junrao" created="Tue, 3 Sep 2013 15:14:41 +0000"  >&lt;p&gt;Thanks for patch v7. A couple of more comments.&lt;/p&gt;

&lt;p&gt;70. There is a long standing bug in ProducerRequest.handleError(). If ack=0, we shouldn&apos;t send a response when the broker hits an unexpected error. We should either close the socket connection or send no response. Not sure which one is better.&lt;/p&gt;

&lt;p&gt;71. A minor issue. The following comment in RequestChannel is a bit confusing. It sounds like that it needs to read more data from network to complete this request, but it is not.&lt;br/&gt;
  /** No operation to take for the request, need to read more over the network */&lt;br/&gt;
  def noOperation(processor: Int, request: RequestChannel.Request) {&lt;/p&gt;</comment>
                            <comment id="13767054" author="guozhang" created="Fri, 13 Sep 2013 22:17:48 +0000"  >&lt;p&gt;Created reviewboard &lt;a href=&quot;https://reviews.apache.org/r/14140/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://reviews.apache.org/r/14140/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13767147" author="junrao" created="Fri, 13 Sep 2013 23:18:30 +0000"  >&lt;p&gt;Thanks for the followup patch. +1 and committed to 0.8.&lt;/p&gt;</comment>
                            <comment id="15436999" author="mazhar.shaikh.in" created="Thu, 25 Aug 2016 14:37:15 +0000"  >&lt;p&gt;Hi All,&lt;/p&gt;

&lt;p&gt;affected version &amp;amp; fixed version is same, just want to know if this fix is available in &quot;0.8.2&quot;&lt;/p&gt;

&lt;p&gt;I&apos;m facing similar issue in &quot;0.8.2&quot;.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15631889" author="bill zhang" created="Thu, 3 Nov 2016 07:12:34 +0000"  >&lt;p&gt;I am using Flume with Kafka Channel &amp;amp; facing below issues. &lt;/p&gt;

&lt;p&gt;Kafka Version: kafka_2.9.1-0.8.2.0&lt;br/&gt;
Flume Version: apache-flume-1.6.0&lt;/p&gt;

&lt;p&gt;It seems was resolved from below :&lt;br/&gt;
Step 1: copy zookeeper Jar file to Flume classpath&lt;br/&gt;
Step 2: a1.channels.c1.kafka.producer.type = async&lt;/p&gt;

&lt;p&gt;Note:&lt;br/&gt;
i didn&apos;t change default value of request.required.acks. It seems works, it is still in testing...&lt;/p&gt;


&lt;p&gt;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~&lt;br/&gt;
Issue 1:&lt;br/&gt;
02 Nov 2016 22:20:06,201 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume_tbox-topic_SATL2036-1478087994030-54387da2-0-2&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.warn:83)  - Reconnect due to socket error: null&lt;br/&gt;
02 Nov 2016 22:20:06,203 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume_tbox-topic_SATL2036-1478087994030-54387da2-0-2&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume_tbox-topic_SATL2036-1478087994030-54387da2-0-2&amp;#93;&lt;/span&gt;, Stopped &lt;br/&gt;
02 Nov 2016 22:20:06,203 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume_tbox-topic_SATL2036-1478087994030-54387da2-0-2&amp;#93;&lt;/span&gt;, Shutdown completed&lt;br/&gt;
02 Nov 2016 22:20:06,203 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume_tbox-topic_SATL2036-1478087994030-54387da2-0-1&amp;#93;&lt;/span&gt;, Shutting down&lt;br/&gt;
02 Nov 2016 22:20:06,204 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume_tbox-topic_SATL2036-1478087994030-54387da2-0-1&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.warn:83)  - Reconnect due to socket error: null&lt;br/&gt;
02 Nov 2016 22:20:06,204 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume_tbox-topic_SATL2036-1478087994030-54387da2-0-1&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume_tbox-topic_SATL2036-1478087994030-54387da2-0-1&amp;#93;&lt;/span&gt;, Stopped &lt;br/&gt;
02 Nov 2016 22:20:06,204 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume_tbox-topic_SATL2036-1478087994030-54387da2-0-1&amp;#93;&lt;/span&gt;, Shutdown completed&lt;br/&gt;
02 Nov 2016 22:20:06,205 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherManager-1478087994042&amp;#93;&lt;/span&gt; All connections stopped&lt;br/&gt;
02 Nov 2016 22:20:06,207 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;ZkClient-EventThread-58-SATL2036:2181,SATL2037:2181,SATL2038:2181/kafka&amp;#93;&lt;/span&gt; (org.I0Itec.zkclient.ZkEventThread.run:82)  - Terminate ZkClient event thread.&lt;br/&gt;
02 Nov 2016 22:20:06,212 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;PollableSourceRunner-KafkaSource-r1&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.warn:89)  - Failed to send producer request with correlation id 34198503 to broker 1 with data for partitions &lt;span class=&quot;error&quot;&gt;&amp;#91;channel-tbox-parsed-topic,3&amp;#93;&lt;/span&gt;&lt;br/&gt;
java.nio.channels.ClosedByInterruptException&lt;br/&gt;
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)&lt;br/&gt;
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:511)&lt;br/&gt;
	at java.nio.channels.SocketChannel.write(SocketChannel.java:502)&lt;br/&gt;
	at kafka.network.BoundedByteBufferSend.writeTo(BoundedByteBufferSend.scala:56)&lt;br/&gt;
	at kafka.network.Send$class.writeCompletely(Transmission.scala:75)&lt;br/&gt;
	at kafka.network.BoundedByteBufferSend.writeCompletely(BoundedByteBufferSend.scala:26)&lt;br/&gt;
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:92)&lt;br/&gt;
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:72)&lt;br/&gt;
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:71)&lt;br/&gt;
	at kafka.producer.SyncProducer$$anonfun$send$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(SyncProducer.scala:102)&lt;br/&gt;
	at kafka.producer.SyncProducer$$anonfun$send$1$$anonfun$apply$mcV$sp$1.apply(SyncProducer.scala:102)&lt;br/&gt;
	at kafka.producer.SyncProducer$$anonfun$send$1$$anonfun$apply$mcV$sp$1.apply(SyncProducer.scala:102)&lt;br/&gt;
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)&lt;br/&gt;
	at kafka.producer.SyncProducer$$anonfun$send$1.apply$mcV$sp(SyncProducer.scala:101)&lt;br/&gt;
	at kafka.producer.SyncProducer$$anonfun$send$1.apply(SyncProducer.scala:101)&lt;br/&gt;
	at kafka.producer.SyncProducer$$anonfun$send$1.apply(SyncProducer.scala:101)&lt;br/&gt;
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)&lt;br/&gt;
	at kafka.producer.SyncProducer.send(SyncProducer.scala:100)&lt;br/&gt;
	at kafka.producer.async.DefaultEventHandler.kafka$producer$async$DefaultEventHandler$$send(DefaultEventHandler.scala:255)&lt;br/&gt;
	at kafka.producer.async.DefaultEventHandler$$anonfun$dispatchSerializedData$2.apply(DefaultEventHandler.scala:106)&lt;br/&gt;
	at kafka.producer.async.DefaultEventHandler$$anonfun$dispatchSerializedData$2.apply(DefaultEventHandler.scala:100)&lt;br/&gt;
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)&lt;br/&gt;
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)&lt;br/&gt;
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)&lt;br/&gt;
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:226)&lt;br/&gt;
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)&lt;br/&gt;
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:98)&lt;br/&gt;
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)&lt;br/&gt;
	at kafka.producer.async.DefaultEventHandler.dispatchSerializedData(DefaultEventHandler.scala:100)&lt;br/&gt;
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:72)&lt;br/&gt;
	at kafka.producer.Producer.send(Producer.scala:76)&lt;br/&gt;
	at kafka.javaapi.producer.Producer.send(Producer.scala:42)&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doCommit(KafkaChannel.java:357)&lt;br/&gt;
	at org.apache.flume.channel.BasicTransactionSemantics.commit(BasicTransactionSemantics.java:151)&lt;br/&gt;
	at org.apache.flume.channel.ChannelProcessor.processEventBatch(ChannelProcessor.java:192)&lt;br/&gt;
	at org.apache.flume.source.kafka.KafkaSource.process(KafkaSource.java:130)&lt;br/&gt;
	at org.apache.flume.source.PollableSourceRunner$PollingRunner.run(PollableSourceRunner.java:139)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
02 Nov 2016 22:20:06,214 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;PollableSourceRunner-KafkaSource-r1&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - Back off for 100 ms before retrying send. Remaining retries = 3&lt;br/&gt;
02 Nov 2016 22:20:06,214 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;PollableSourceRunner-KafkaSource-r1&amp;#93;&lt;/span&gt; (org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doCommit:363)  - Sending events to Kafka failed&lt;br/&gt;
java.lang.InterruptedException: sleep interrupted&lt;br/&gt;
	at java.lang.Thread.sleep(Native Method)&lt;br/&gt;
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:76)&lt;br/&gt;
	at kafka.producer.Producer.send(Producer.scala:76)&lt;br/&gt;
	at kafka.javaapi.producer.Producer.send(Producer.scala:42)&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doCommit(KafkaChannel.java:357)&lt;br/&gt;
	at org.apache.flume.channel.BasicTransactionSemantics.commit(BasicTransactionSemantics.java:151)&lt;br/&gt;
	at org.apache.flume.channel.ChannelProcessor.processEventBatch(ChannelProcessor.java:192)&lt;br/&gt;
	at org.apache.flume.source.kafka.KafkaSource.process(KafkaSource.java:130)&lt;br/&gt;
	at org.apache.flume.source.PollableSourceRunner$PollingRunner.run(PollableSourceRunner.java:139)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
02 Nov 2016 22:20:06,215 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;PollableSourceRunner-KafkaSource-r1&amp;#93;&lt;/span&gt; (org.apache.flume.source.kafka.KafkaSource.process:153)  - KafkaSource EXCEPTION, {}&lt;br/&gt;
org.apache.flume.ChannelException: Unable to put batch on required channel: org.apache.flume.channel.kafka.KafkaChannel&lt;/p&gt;
{name: c1}
&lt;p&gt;	at org.apache.flume.channel.ChannelProcessor.processEventBatch(ChannelProcessor.java:200)&lt;br/&gt;
	at org.apache.flume.source.kafka.KafkaSource.process(KafkaSource.java:130)&lt;br/&gt;
	at org.apache.flume.source.PollableSourceRunner$PollingRunner.run(PollableSourceRunner.java:139)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
Caused by: org.apache.flume.ChannelException: Commit failed as send to Kafka failed&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doCommit(KafkaChannel.java:364)&lt;br/&gt;
	at org.apache.flume.channel.BasicTransactionSemantics.commit(BasicTransactionSemantics.java:151)&lt;br/&gt;
	at org.apache.flume.channel.ChannelProcessor.processEventBatch(ChannelProcessor.java:192)&lt;br/&gt;
	... 3 more&lt;br/&gt;
Caused by: java.lang.InterruptedException: sleep interrupted&lt;br/&gt;
	at java.lang.Thread.sleep(Native Method)&lt;br/&gt;
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:76)&lt;br/&gt;
	at kafka.producer.Producer.send(Producer.scala:76)&lt;br/&gt;
	at kafka.javaapi.producer.Producer.send(Producer.scala:42)&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doCommit(KafkaChannel.java:357)&lt;br/&gt;
	... 5 more&lt;br/&gt;
02 Nov 2016 22:20:06,233 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.zookeeper.ZooKeeper.close:684)  - Session: 0x2581dc726ab01ad closed&lt;br/&gt;
02 Nov 2016 22:20:06,233 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;lifecycleSupervisor-1-1-EventThread&amp;#93;&lt;/span&gt; (org.apache.zookeeper.ClientCnxn$EventThread.run:512)  - EventThread shut down&lt;br/&gt;
02 Nov 2016 22:20:06,239 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;flume_tbox-topic_SATL2036-1478087994030-54387da2&amp;#93;&lt;/span&gt;, ZKConsumerConnector shut down completed&lt;br/&gt;
02 Nov 2016 22:20:06,239 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: SOURCE, name: r1 stopped&lt;br/&gt;
02 Nov 2016 22:20:06,239 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: SOURCE, name: r1. source.start.time == 1478087994119&lt;br/&gt;
02 Nov 2016 22:20:06,239 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: SOURCE, name: r1. source.stop.time == 1478096406239&lt;br/&gt;
02 Nov 2016 22:20:06,239 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SOURCE, name: r1. source.kafka.commit.time == 555&lt;br/&gt;
02 Nov 2016 22:20:06,239 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SOURCE, name: r1. source.kafka.event.get.time == 1409513&lt;br/&gt;
02 Nov 2016 22:20:06,239 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SOURCE, name: r1. src.append-batch.accepted == 0&lt;br/&gt;
02 Nov 2016 22:20:06,240 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SOURCE, name: r1. src.append-batch.received == 0&lt;br/&gt;
02 Nov 2016 22:20:06,240 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SOURCE, name: r1. src.append.accepted == 0&lt;br/&gt;
02 Nov 2016 22:20:06,240 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SOURCE, name: r1. src.append.received == 0&lt;br/&gt;
02 Nov 2016 22:20:06,240 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SOURCE, name: r1. src.events.accepted == 343&lt;br/&gt;
02 Nov 2016 22:20:06,240 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SOURCE, name: r1. src.events.received == 343&lt;br/&gt;
02 Nov 2016 22:20:06,240 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SOURCE, name: r1. src.open-connection.count == 0&lt;br/&gt;
02 Nov 2016 22:20:06,240 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.source.kafka.KafkaSource.stop:237)  - Kafka Source r1 stopped. Metrics: SOURCE:r1&lt;/p&gt;
{src.events.accepted=343, src.open-connection.count=0, src.append.received=0, source.kafka.event.get.time=1409513, src.append-batch.received=0, src.append-batch.accepted=0, src.append.accepted=0, src.events.received=343, source.kafka.commit.time=555}
&lt;p&gt;02 Nov 2016 22:20:06,240 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21&amp;#93;&lt;/span&gt;, ZKConsumerConnector shutting down&lt;br/&gt;
02 Nov 2016 22:20:06,241 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherManager-1478087993018&amp;#93;&lt;/span&gt; Stopping leader finder thread&lt;br/&gt;
02 Nov 2016 22:20:06,241 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21-leader-finder-thread&amp;#93;&lt;/span&gt;, Shutting down&lt;br/&gt;
02 Nov 2016 22:20:06,241 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21-leader-finder-thread&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21-leader-finder-thread&amp;#93;&lt;/span&gt;, Stopped &lt;br/&gt;
02 Nov 2016 22:20:06,241 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21-leader-finder-thread&amp;#93;&lt;/span&gt;, Shutdown completed&lt;br/&gt;
02 Nov 2016 22:20:06,241 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherManager-1478087993018&amp;#93;&lt;/span&gt; Stopping all fetchers&lt;br/&gt;
02 Nov 2016 22:20:06,241 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21-0-1&amp;#93;&lt;/span&gt;, Shutting down&lt;br/&gt;
02 Nov 2016 22:20:06,242 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21-0-1&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.warn:83)  - Reconnect due to socket error: null&lt;br/&gt;
02 Nov 2016 22:20:06,242 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21-0-1&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21-0-1&amp;#93;&lt;/span&gt;, Stopped &lt;br/&gt;
02 Nov 2016 22:20:06,242 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21-0-1&amp;#93;&lt;/span&gt;, Shutdown completed&lt;br/&gt;
02 Nov 2016 22:20:06,242 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherManager-1478087993018&amp;#93;&lt;/span&gt; All connections stopped&lt;br/&gt;
02 Nov 2016 22:20:06,243 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;ZkClient-EventThread-42-SATL2036:2181,SATL2037:2181,SATL2038:2181/kafka&amp;#93;&lt;/span&gt; (org.I0Itec.zkclient.ZkEventThread.run:82)  - Terminate ZkClient event thread.&lt;br/&gt;
02 Nov 2016 22:20:06,244 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.zookeeper.ZooKeeper.close:684)  - Session: 0x356eb2d4b833fab closed&lt;br/&gt;
02 Nov 2016 22:20:06,244 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21&amp;#93;&lt;/span&gt;, ZKConsumerConnector shut down completed&lt;br/&gt;
02 Nov 2016 22:20:06,244 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;SinkRunner-PollingRunner-FailoverSinkProcessor-EventThread&amp;#93;&lt;/span&gt; (org.apache.zookeeper.ClientCnxn$EventThread.run:512)  - EventThread shut down&lt;br/&gt;
02 Nov 2016 22:20:06,246 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - Shutting down producer&lt;br/&gt;
02 Nov 2016 22:20:06,247 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - Closing all sync producers&lt;br/&gt;
02 Nov 2016 22:20:06,256 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - Disconnecting from 10.25.20.36:9092&lt;br/&gt;
02 Nov 2016 22:20:06,256 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: CHANNEL, name: c1 stopped&lt;br/&gt;
02 Nov 2016 22:20:06,256 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: CHANNEL, name: c1. channel.start.time == 1478087992836&lt;br/&gt;
02 Nov 2016 22:20:06,256 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: CHANNEL, name: c1. channel.stop.time == 1478096406256&lt;br/&gt;
02 Nov 2016 22:20:06,257 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: c1. channel.capacity == 0&lt;br/&gt;
02 Nov 2016 22:20:06,257 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: c1. channel.current.size == 0&lt;br/&gt;
02 Nov 2016 22:20:06,257 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: c1. channel.event.put.attempt == 0&lt;br/&gt;
02 Nov 2016 22:20:06,257 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: c1. channel.event.put.success == 343&lt;br/&gt;
02 Nov 2016 22:20:06,257 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: c1. channel.event.take.attempt == 0&lt;br/&gt;
02 Nov 2016 22:20:06,257 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: c1. channel.event.take.success == 342&lt;br/&gt;
02 Nov 2016 22:20:06,257 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: c1. channel.kafka.commit.time == 201&lt;br/&gt;
02 Nov 2016 22:20:06,258 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: c1. channel.kafka.event.get.time == 531&lt;br/&gt;
02 Nov 2016 22:20:06,258 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: c1. channel.kafka.event.send.time == 1789&lt;br/&gt;
02 Nov 2016 22:20:06,258 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: c1. channel.rollback.count == 0&lt;br/&gt;
02 Nov 2016 22:20:06,258 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.flume.channel.kafka.KafkaChannel.stop:123)  - Kafka channel c1 stopped. Metrics: CHANNEL:c1&lt;/p&gt;
{channel.event.put.attempt=0, channel.event.put.success=343, channel.kafka.event.get.time=531, channel.current.size=0, channel.event.take.attempt=0, channel.event.take.success=342, channel.kafka.event.send.time=1789, channel.capacity=0, channel.kafka.commit.time=201, channel.rollback.count=0}
&lt;p&gt;02 Nov 2016 22:20:06,264 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;SinkRunner-PollingRunner-DefaultSinkProcessor&amp;#93;&lt;/span&gt; (org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake:332)  - Error while getting events from Kafka&lt;br/&gt;
java.lang.InterruptedException&lt;br/&gt;
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)&lt;br/&gt;
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)&lt;br/&gt;
	at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)&lt;br/&gt;
	at kafka.consumer.ConsumerIterator.makeNext(ConsumerIterator.scala:65)&lt;br/&gt;
	at kafka.consumer.ConsumerIterator.makeNext(ConsumerIterator.scala:33)&lt;br/&gt;
	at kafka.utils.IteratorTemplate.maybeComputeNext(IteratorTemplate.scala:66)&lt;br/&gt;
	at kafka.utils.IteratorTemplate.hasNext(IteratorTemplate.scala:58)&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:306)&lt;br/&gt;
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)&lt;br/&gt;
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)&lt;br/&gt;
	at org.apache.flume.sink.kafka.KafkaSink.process(KafkaSink.java:97)&lt;br/&gt;
	at org.apache.flume.sink.DefaultSinkProcessor.process(DefaultSinkProcessor.java:68)&lt;br/&gt;
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
02 Nov 2016 22:20:06,274 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;SinkRunner-PollingRunner-DefaultSinkProcessor&amp;#93;&lt;/span&gt; (org.apache.flume.sink.kafka.KafkaSink.process:139)  - Failed to publish events&lt;br/&gt;
org.apache.flume.ChannelException: Error while getting events from Kafka&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:333)&lt;br/&gt;
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)&lt;br/&gt;
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)&lt;br/&gt;
	at org.apache.flume.sink.kafka.KafkaSink.process(KafkaSink.java:97)&lt;br/&gt;
	at org.apache.flume.sink.DefaultSinkProcessor.process(DefaultSinkProcessor.java:68)&lt;br/&gt;
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
Caused by: java.lang.InterruptedException&lt;br/&gt;
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)&lt;br/&gt;
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)&lt;br/&gt;
	at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)&lt;br/&gt;
	at kafka.consumer.ConsumerIterator.makeNext(ConsumerIterator.scala:65)&lt;br/&gt;
	at kafka.consumer.ConsumerIterator.makeNext(ConsumerIterator.scala:33)&lt;br/&gt;
	at kafka.utils.IteratorTemplate.maybeComputeNext(IteratorTemplate.scala:66)&lt;br/&gt;
	at kafka.utils.IteratorTemplate.hasNext(IteratorTemplate.scala:58)&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:306)&lt;br/&gt;
	... 6 more&lt;br/&gt;
02 Nov 2016 22:20:06,275 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;SinkRunner-PollingRunner-DefaultSinkProcessor&amp;#93;&lt;/span&gt; (org.apache.flume.SinkRunner$PollingRunner.run:160)  - Unable to deliver event. Exception follows.&lt;br/&gt;
org.apache.flume.EventDeliveryException: Failed to publish events&lt;br/&gt;
	at org.apache.flume.sink.kafka.KafkaSink.process(KafkaSink.java:150)&lt;br/&gt;
	at org.apache.flume.sink.DefaultSinkProcessor.process(DefaultSinkProcessor.java:68)&lt;br/&gt;
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
Caused by: org.apache.flume.ChannelException: Error while getting events from Kafka&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:333)&lt;br/&gt;
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)&lt;br/&gt;
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)&lt;br/&gt;
	at org.apache.flume.sink.kafka.KafkaSink.process(KafkaSink.java:97)&lt;br/&gt;
	... 3 more&lt;br/&gt;
Caused by: java.lang.InterruptedException&lt;br/&gt;
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)&lt;br/&gt;
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)&lt;br/&gt;
	at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)&lt;br/&gt;
	at kafka.consumer.ConsumerIterator.makeNext(ConsumerIterator.scala:65)&lt;br/&gt;
	at kafka.consumer.ConsumerIterator.makeNext(ConsumerIterator.scala:33)&lt;br/&gt;
	at kafka.utils.IteratorTemplate.maybeComputeNext(IteratorTemplate.scala:66)&lt;br/&gt;
	at kafka.utils.IteratorTemplate.hasNext(IteratorTemplate.scala:58)&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:306)&lt;br/&gt;
	... 6 more&lt;br/&gt;
02 Nov 2016 22:20:06,794 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;flume_tbox-topic_SATL2036-1478087994030-54387da2_watcher_executor&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;flume_tbox-topic_SATL2036-1478087994030-54387da2&amp;#93;&lt;/span&gt;, stopping watcher executor thread for consumer flume_tbox-topic_SATL2036-1478087994030-54387da2&lt;br/&gt;
02 Nov 2016 22:20:06,816 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21_watcher_executor&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21&amp;#93;&lt;/span&gt;, stopping watcher executor thread for consumer flume-channel-tbox-topic_SATL2036-1478087992871-1a60fb21&lt;br/&gt;
02 Nov 2016 22:20:06,887 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;SinkRunner-PollingRunner-FailoverSinkProcessor&amp;#93;&lt;/span&gt; (org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake:332)  - Error while getting events from Kafka&lt;br/&gt;
java.util.NoSuchElementException&lt;br/&gt;
	at kafka.utils.IteratorTemplate.next(IteratorTemplate.scala:39)&lt;br/&gt;
	at kafka.consumer.ConsumerIterator.next(ConsumerIterator.scala:46)&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:310)&lt;br/&gt;
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)&lt;br/&gt;
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)&lt;br/&gt;
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:374)&lt;br/&gt;
	at org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:182)&lt;br/&gt;
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
02 Nov 2016 22:20:06,888 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;SinkRunner-PollingRunner-FailoverSinkProcessor&amp;#93;&lt;/span&gt; (org.apache.flume.sink.hdfs.HDFSEventSink.process:459)  - process failed&lt;br/&gt;
org.apache.flume.ChannelException: Error while getting events from Kafka&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:333)&lt;br/&gt;
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)&lt;br/&gt;
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)&lt;br/&gt;
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:374)&lt;br/&gt;
	at org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:182)&lt;br/&gt;
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
Caused by: java.util.NoSuchElementException&lt;br/&gt;
	at kafka.utils.IteratorTemplate.next(IteratorTemplate.scala:39)&lt;br/&gt;
	at kafka.consumer.ConsumerIterator.next(ConsumerIterator.scala:46)&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:310)&lt;br/&gt;
	... 6 more&lt;br/&gt;
02 Nov 2016 22:20:06,889 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;SinkRunner-PollingRunner-FailoverSinkProcessor&amp;#93;&lt;/span&gt; (org.apache.flume.sink.FailoverSinkProcessor.process:185)  - Sink k1 failed and has been sent to failover list&lt;br/&gt;
org.apache.flume.EventDeliveryException: org.apache.flume.ChannelException: Error while getting events from Kafka&lt;br/&gt;
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:463)&lt;br/&gt;
	at org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:182)&lt;br/&gt;
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
Caused by: org.apache.flume.ChannelException: Error while getting events from Kafka&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:333)&lt;br/&gt;
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)&lt;br/&gt;
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)&lt;br/&gt;
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:374)&lt;br/&gt;
	... 3 more&lt;br/&gt;
Caused by: java.util.NoSuchElementException&lt;br/&gt;
	at kafka.utils.IteratorTemplate.next(IteratorTemplate.scala:39)&lt;br/&gt;
	at kafka.consumer.ConsumerIterator.next(ConsumerIterator.scala:46)&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:310)&lt;br/&gt;
	... 6 more&lt;br/&gt;
02 Nov 2016 22:20:06,896 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;SinkRunner-PollingRunner-FailoverSinkProcessor&amp;#93;&lt;/span&gt; (org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake:332)  - Error while getting events from Kafka&lt;br/&gt;
java.util.NoSuchElementException&lt;br/&gt;
	at kafka.utils.IteratorTemplate.next(IteratorTemplate.scala:39)&lt;br/&gt;
	at kafka.consumer.ConsumerIterator.next(ConsumerIterator.scala:46)&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:310)&lt;br/&gt;
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)&lt;br/&gt;
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)&lt;br/&gt;
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:374)&lt;br/&gt;
	at org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:182)&lt;br/&gt;
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
02 Nov 2016 22:20:06,897 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;SinkRunner-PollingRunner-FailoverSinkProcessor&amp;#93;&lt;/span&gt; (org.apache.flume.sink.hdfs.HDFSEventSink.process:459)  - process failed&lt;br/&gt;
org.apache.flume.ChannelException: Error while getting events from Kafka&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:333)&lt;br/&gt;
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)&lt;br/&gt;
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)&lt;br/&gt;
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:374)&lt;br/&gt;
	at org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:182)&lt;br/&gt;
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
Caused by: java.util.NoSuchElementException&lt;br/&gt;
	at kafka.utils.IteratorTemplate.next(IteratorTemplate.scala:39)&lt;br/&gt;
	at kafka.consumer.ConsumerIterator.next(ConsumerIterator.scala:46)&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:310)&lt;br/&gt;
	... 6 more&lt;br/&gt;
02 Nov 2016 22:20:06,898 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;SinkRunner-PollingRunner-FailoverSinkProcessor&amp;#93;&lt;/span&gt; (org.apache.flume.sink.FailoverSinkProcessor.process:185)  - Sink k2 failed and has been sent to failover list&lt;br/&gt;
org.apache.flume.EventDeliveryException: org.apache.flume.ChannelException: Error while getting events from Kafka&lt;br/&gt;
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:463)&lt;br/&gt;
	at org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:182)&lt;br/&gt;
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
Caused by: org.apache.flume.ChannelException: Error while getting events from Kafka&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:333)&lt;br/&gt;
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)&lt;br/&gt;
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)&lt;br/&gt;
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:374)&lt;br/&gt;
	... 3 more&lt;br/&gt;
Caused by: java.util.NoSuchElementException&lt;br/&gt;
	at kafka.utils.IteratorTemplate.next(IteratorTemplate.scala:39)&lt;br/&gt;
	at kafka.consumer.ConsumerIterator.next(ConsumerIterator.scala:46)&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:310)&lt;br/&gt;
	... 6 more&lt;br/&gt;
02 Nov 2016 22:20:06,898 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;SinkRunner-PollingRunner-FailoverSinkProcessor&amp;#93;&lt;/span&gt; (org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake:332)  - Error while getting events from Kafka&lt;br/&gt;
java.util.NoSuchElementException&lt;br/&gt;
	at kafka.utils.IteratorTemplate.next(IteratorTemplate.scala:39)&lt;br/&gt;
	at kafka.consumer.ConsumerIterator.next(ConsumerIterator.scala:46)&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:310)&lt;br/&gt;
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)&lt;br/&gt;
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)&lt;br/&gt;
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:374)&lt;br/&gt;
	at org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:182)&lt;br/&gt;
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
02 Nov 2016 22:20:06,898 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;SinkRunner-PollingRunner-FailoverSinkProcessor&amp;#93;&lt;/span&gt; (org.apache.flume.sink.hdfs.HDFSEventSink.process:459)  - process failed&lt;br/&gt;
org.apache.flume.ChannelException: Error while getting events from Kafka&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:333)&lt;br/&gt;
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)&lt;br/&gt;
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)&lt;br/&gt;
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:374)&lt;br/&gt;
	at org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:182)&lt;br/&gt;
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
Caused by: java.util.NoSuchElementException&lt;br/&gt;
	at kafka.utils.IteratorTemplate.next(IteratorTemplate.scala:39)&lt;br/&gt;
	at kafka.consumer.ConsumerIterator.next(ConsumerIterator.scala:46)&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:310)&lt;br/&gt;
	... 6 more&lt;br/&gt;
02 Nov 2016 22:20:06,899 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;SinkRunner-PollingRunner-FailoverSinkProcessor&amp;#93;&lt;/span&gt; (org.apache.flume.sink.FailoverSinkProcessor.process:185)  - Sink k3 failed and has been sent to failover list&lt;br/&gt;
org.apache.flume.EventDeliveryException: org.apache.flume.ChannelException: Error while getting events from Kafka&lt;br/&gt;
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:463)&lt;br/&gt;
	at org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:182)&lt;br/&gt;
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
Caused by: org.apache.flume.ChannelException: Error while getting events from Kafka&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:333)&lt;br/&gt;
	at org.apache.flume.channel.BasicTransactionSemantics.take(BasicTransactionSemantics.java:113)&lt;br/&gt;
	at org.apache.flume.channel.BasicChannelSemantics.take(BasicChannelSemantics.java:95)&lt;br/&gt;
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:374)&lt;br/&gt;
	... 3 more&lt;br/&gt;
Caused by: java.util.NoSuchElementException&lt;br/&gt;
	at kafka.utils.IteratorTemplate.next(IteratorTemplate.scala:39)&lt;br/&gt;
	at kafka.consumer.ConsumerIterator.next(ConsumerIterator.scala:46)&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doTake(KafkaChannel.java:310)&lt;br/&gt;
	... 6 more&lt;br/&gt;
02 Nov 2016 22:20:06,899 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;SinkRunner-PollingRunner-FailoverSinkProcessor&amp;#93;&lt;/span&gt; (org.apache.flume.SinkRunner$PollingRunner.run:160)  - Unable to deliver event. Exception follows.&lt;br/&gt;
org.apache.flume.EventDeliveryException: All sinks failed to process, nothing left to failover to&lt;br/&gt;
	at org.apache.flume.sink.FailoverSinkProcessor.process(FailoverSinkProcessor.java:191)&lt;br/&gt;
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
02 Nov 2016 22:20:07,216 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;flume_tbox_parsed_SATL2036-1478088061094-7badc6c0&amp;#93;&lt;/span&gt;, ZKConsumerConnector shutting down&lt;br/&gt;
02 Nov 2016 22:20:07,217 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherManager-1478088061100&amp;#93;&lt;/span&gt; Stopping leader finder thread&lt;br/&gt;
02 Nov 2016 22:20:07,217 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-leader-finder-thread&amp;#93;&lt;/span&gt;, Shutting down&lt;br/&gt;
02 Nov 2016 22:20:07,218 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-leader-finder-thread&amp;#93;&lt;/span&gt;, Shutdown completed&lt;br/&gt;
02 Nov 2016 22:20:07,218 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-leader-finder-thread&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-leader-finder-thread&amp;#93;&lt;/span&gt;, Stopped &lt;br/&gt;
02 Nov 2016 22:20:07,218 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherManager-1478088061100&amp;#93;&lt;/span&gt; Stopping all fetchers&lt;br/&gt;
02 Nov 2016 22:20:07,218 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-0-2&amp;#93;&lt;/span&gt;, Shutting down&lt;br/&gt;
02 Nov 2016 22:20:07,219 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-0-2&amp;#93;&lt;/span&gt;, Shutdown completed&lt;br/&gt;
02 Nov 2016 22:20:07,219 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-0-2&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-0-2&amp;#93;&lt;/span&gt;, Stopped &lt;br/&gt;
02 Nov 2016 22:20:07,220 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-0-1&amp;#93;&lt;/span&gt;, Shutting down&lt;br/&gt;
02 Nov 2016 22:20:07,220 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-0-1&amp;#93;&lt;/span&gt;, Shutdown completed&lt;br/&gt;
02 Nov 2016 22:20:07,220 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-0-1&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherThread-flume_tbox_parsed_SATL2036-1478088061094-7badc6c0-0-1&amp;#93;&lt;/span&gt;, Stopped &lt;br/&gt;
02 Nov 2016 22:20:07,221 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;ConsumerFetcherManager-1478088061100&amp;#93;&lt;/span&gt; All connections stopped&lt;br/&gt;
02 Nov 2016 22:20:07,223 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;ZkClient-EventThread-48-SATL2036:2181,SATL2037:2181,SATL2038:2181/kafka&amp;#93;&lt;/span&gt; (org.I0Itec.zkclient.ZkEventThread.run:82)  - Terminate ZkClient event thread.&lt;br/&gt;
02 Nov 2016 22:20:07,226 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;flume_tbox_parsed_SATL2036-1478088061094-7badc6c0_watcher_executor&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;flume_tbox_parsed_SATL2036-1478088061094-7badc6c0&amp;#93;&lt;/span&gt;, stopping watcher executor thread for consumer flume_tbox_parsed_SATL2036-1478088061094-7badc6c0&lt;br/&gt;
02 Nov 2016 22:20:07,226 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (org.apache.zookeeper.ZooKeeper.close:684)  - Session: 0x156eb2d4a70421e closed&lt;br/&gt;
02 Nov 2016 22:20:07,226 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;lifecycleSupervisor-1-0-EventThread&amp;#93;&lt;/span&gt; (org.apache.zookeeper.ClientCnxn$EventThread.run:512)  - EventThread shut down&lt;br/&gt;
02 Nov 2016 22:20:07,227 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;agent-shutdown-hook&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - &lt;span class=&quot;error&quot;&gt;&amp;#91;flume_tbox_parsed_SATL2036-1478088061094-7badc6c0&amp;#93;&lt;/span&gt;, ZKConsumerConnector shut down completed&lt;/p&gt;



&lt;p&gt;Issue 2:&lt;br/&gt;
03 Nov 2016 13:31:29,287 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;PollableSourceRunner-KafkaSource-r1&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - Back off for 100 ms before retrying send. Remaining retries = 1&lt;br/&gt;
03 Nov 2016 13:31:29,388 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;PollableSourceRunner-KafkaSource-r1&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - Fetching metadata from broker id:1,host:SATL2037,port:9092 with correlation id 2307612 for 1 topic(s) Set(channel-tbox-topic)&lt;br/&gt;
03 Nov 2016 13:31:29,388 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;PollableSourceRunner-KafkaSource-r1&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - Connected to SATL2037:9092 for producing&lt;br/&gt;
03 Nov 2016 13:31:29,389 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;PollableSourceRunner-KafkaSource-r1&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - Disconnecting from SATL2037:9092&lt;br/&gt;
03 Nov 2016 13:31:29,443 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;PollableSourceRunner-KafkaSource-r1&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - Connected to SATL2037:9092 for producing&lt;br/&gt;
03 Nov 2016 13:31:29,549 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;PollableSourceRunner-KafkaSource-r1&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - Disconnecting from SATL2037:9092&lt;br/&gt;
03 Nov 2016 13:31:29,550 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;PollableSourceRunner-KafkaSource-r1&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.warn:89)  - Failed to send producer request with correlation id 2308613 to broker 2 with data for partitions &lt;span class=&quot;error&quot;&gt;&amp;#91;channel-tbox-topic,4&amp;#93;&lt;/span&gt;&lt;br/&gt;
java.io.IOException: Connection reset by peer&lt;br/&gt;
	at sun.nio.ch.FileDispatcherImpl.writev0(Native Method)&lt;br/&gt;
	at sun.nio.ch.SocketDispatcher.writev(SocketDispatcher.java:51)&lt;br/&gt;
	at sun.nio.ch.IOUtil.write(IOUtil.java:148)&lt;br/&gt;
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:504)&lt;br/&gt;
	at java.nio.channels.SocketChannel.write(SocketChannel.java:502)&lt;br/&gt;
	at kafka.network.BoundedByteBufferSend.writeTo(BoundedByteBufferSend.scala:56)&lt;br/&gt;
	at kafka.network.Send$class.writeCompletely(Transmission.scala:75)&lt;br/&gt;
	at kafka.network.BoundedByteBufferSend.writeCompletely(BoundedByteBufferSend.scala:26)&lt;br/&gt;
	at kafka.network.BlockingChannel.send(BlockingChannel.scala:92)&lt;br/&gt;
	at kafka.producer.SyncProducer.liftedTree1$1(SyncProducer.scala:72)&lt;br/&gt;
	at kafka.producer.SyncProducer.kafka$producer$SyncProducer$$doSend(SyncProducer.scala:71)&lt;br/&gt;
	at kafka.producer.SyncProducer$$anonfun$send$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(SyncProducer.scala:102)&lt;br/&gt;
	at kafka.producer.SyncProducer$$anonfun$send$1$$anonfun$apply$mcV$sp$1.apply(SyncProducer.scala:102)&lt;br/&gt;
	at kafka.producer.SyncProducer$$anonfun$send$1$$anonfun$apply$mcV$sp$1.apply(SyncProducer.scala:102)&lt;br/&gt;
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)&lt;br/&gt;
	at kafka.producer.SyncProducer$$anonfun$send$1.apply$mcV$sp(SyncProducer.scala:101)&lt;br/&gt;
	at kafka.producer.SyncProducer$$anonfun$send$1.apply(SyncProducer.scala:101)&lt;br/&gt;
	at kafka.producer.SyncProducer$$anonfun$send$1.apply(SyncProducer.scala:101)&lt;br/&gt;
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)&lt;br/&gt;
	at kafka.producer.SyncProducer.send(SyncProducer.scala:100)&lt;br/&gt;
	at kafka.producer.async.DefaultEventHandler.kafka$producer$async$DefaultEventHandler$$send(DefaultEventHandler.scala:255)&lt;br/&gt;
	at kafka.producer.async.DefaultEventHandler$$anonfun$dispatchSerializedData$2.apply(DefaultEventHandler.scala:106)&lt;br/&gt;
	at kafka.producer.async.DefaultEventHandler$$anonfun$dispatchSerializedData$2.apply(DefaultEventHandler.scala:100)&lt;br/&gt;
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)&lt;br/&gt;
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)&lt;br/&gt;
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)&lt;br/&gt;
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:226)&lt;br/&gt;
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)&lt;br/&gt;
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:98)&lt;br/&gt;
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)&lt;br/&gt;
	at kafka.producer.async.DefaultEventHandler.dispatchSerializedData(DefaultEventHandler.scala:100)&lt;br/&gt;
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:72)&lt;br/&gt;
	at kafka.producer.Producer.send(Producer.scala:76)&lt;br/&gt;
	at kafka.javaapi.producer.Producer.send(Producer.scala:42)&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doCommit(KafkaChannel.java:357)&lt;br/&gt;
	at org.apache.flume.channel.BasicTransactionSemantics.commit(BasicTransactionSemantics.java:151)&lt;br/&gt;
	at org.apache.flume.channel.ChannelProcessor.processEventBatch(ChannelProcessor.java:192)&lt;br/&gt;
	at org.apache.flume.source.kafka.KafkaSource.process(KafkaSource.java:130)&lt;br/&gt;
	at org.apache.flume.source.PollableSourceRunner$PollingRunner.run(PollableSourceRunner.java:139)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
03 Nov 2016 13:31:29,550 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;PollableSourceRunner-KafkaSource-r1&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - Back off for 100 ms before retrying send. Remaining retries = 0&lt;br/&gt;
03 Nov 2016 13:31:29,651 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;PollableSourceRunner-KafkaSource-r1&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - Fetching metadata from broker id:0,host:SATL2036,port:9092 with correlation id 2308614 for 1 topic(s) Set(channel-tbox-topic)&lt;br/&gt;
03 Nov 2016 13:31:29,651 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;PollableSourceRunner-KafkaSource-r1&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - Connected to SATL2036:9092 for producing&lt;br/&gt;
03 Nov 2016 13:31:29,652 INFO  &lt;span class=&quot;error&quot;&gt;&amp;#91;PollableSourceRunner-KafkaSource-r1&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.info:68)  - Disconnecting from SATL2036:9092&lt;br/&gt;
03 Nov 2016 13:31:29,653 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;PollableSourceRunner-KafkaSource-r1&amp;#93;&lt;/span&gt; (kafka.utils.Logging$class.error:97)  - Failed to send requests for topics channel-tbox-topic with correlation ids in &lt;span class=&quot;error&quot;&gt;&amp;#91;2304607,2308614&amp;#93;&lt;/span&gt;&lt;br/&gt;
03 Nov 2016 13:31:29,653 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;PollableSourceRunner-KafkaSource-r1&amp;#93;&lt;/span&gt; (org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doCommit:363)  - Sending events to Kafka failed&lt;br/&gt;
kafka.common.FailedToSendMessageException: Failed to send messages after 3 tries.&lt;br/&gt;
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:90)&lt;br/&gt;
	at kafka.producer.Producer.send(Producer.scala:76)&lt;br/&gt;
	at kafka.javaapi.producer.Producer.send(Producer.scala:42)&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doCommit(KafkaChannel.java:357)&lt;br/&gt;
	at org.apache.flume.channel.BasicTransactionSemantics.commit(BasicTransactionSemantics.java:151)&lt;br/&gt;
	at org.apache.flume.channel.ChannelProcessor.processEventBatch(ChannelProcessor.java:192)&lt;br/&gt;
	at org.apache.flume.source.kafka.KafkaSource.process(KafkaSource.java:130)&lt;br/&gt;
	at org.apache.flume.source.PollableSourceRunner$PollingRunner.run(PollableSourceRunner.java:139)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
03 Nov 2016 13:31:29,653 ERROR &lt;span class=&quot;error&quot;&gt;&amp;#91;PollableSourceRunner-KafkaSource-r1&amp;#93;&lt;/span&gt; (org.apache.flume.source.kafka.KafkaSource.process:153)  - KafkaSource EXCEPTION, {}&lt;br/&gt;
org.apache.flume.ChannelException: Unable to put batch on required channel: org.apache.flume.channel.kafka.KafkaChannel&lt;/p&gt;
{name: c1}
&lt;p&gt;	at org.apache.flume.channel.ChannelProcessor.processEventBatch(ChannelProcessor.java:200)&lt;br/&gt;
	at org.apache.flume.source.kafka.KafkaSource.process(KafkaSource.java:130)&lt;br/&gt;
	at org.apache.flume.source.PollableSourceRunner$PollingRunner.run(PollableSourceRunner.java:139)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
Caused by: org.apache.flume.ChannelException: Commit failed as send to Kafka failed&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doCommit(KafkaChannel.java:364)&lt;br/&gt;
	at org.apache.flume.channel.BasicTransactionSemantics.commit(BasicTransactionSemantics.java:151)&lt;br/&gt;
	at org.apache.flume.channel.ChannelProcessor.processEventBatch(ChannelProcessor.java:192)&lt;br/&gt;
	... 3 more&lt;br/&gt;
Caused by: kafka.common.FailedToSendMessageException: Failed to send messages after 3 tries.&lt;br/&gt;
	at kafka.producer.async.DefaultEventHandler.handle(DefaultEventHandler.scala:90)&lt;br/&gt;
	at kafka.producer.Producer.send(Producer.scala:76)&lt;br/&gt;
	at kafka.javaapi.producer.Producer.send(Producer.scala:42)&lt;br/&gt;
	at org.apache.flume.channel.kafka.KafkaChannel$KafkaTransaction.doCommit(KafkaChannel.java:357)&lt;br/&gt;
	... 5 more&lt;/p&gt;




</comment>
                    </comments>
                    <attachments>
                            <attachment id="12603129" name="KAFKA-955-followup.v1.patch" size="1484" author="guozhang" created="Fri, 13 Sep 2013 22:17:42 +0000"/>
                            <attachment id="12594303" name="KAFKA-955.v1.patch" size="5829" author="guozhang" created="Fri, 26 Jul 2013 00:55:19 +0000"/>
                            <attachment id="12594296" name="KAFKA-955.v1.patch" size="3551" author="guozhang" created="Thu, 25 Jul 2013 23:51:12 +0000"/>
                            <attachment id="12595217" name="KAFKA-955.v2.patch" size="6431" author="guozhang" created="Wed, 31 Jul 2013 17:23:52 +0000"/>
                            <attachment id="12595686" name="KAFKA-955.v3.patch" size="6162" author="guozhang" created="Fri, 2 Aug 2013 22:35:20 +0000"/>
                            <attachment id="12599462" name="KAFKA-955.v4.patch" size="6297" author="guozhang" created="Thu, 22 Aug 2013 17:58:39 +0000"/>
                            <attachment id="12599655" name="KAFKA-955.v5.patch" size="5507" author="guozhang" created="Fri, 23 Aug 2013 16:59:40 +0000"/>
                            <attachment id="12599718" name="KAFKA-955.v6.patch" size="9050" author="guozhang" created="Fri, 23 Aug 2013 21:50:34 +0000"/>
                            <attachment id="12600049" name="KAFKA-955.v7.patch" size="9832" author="guozhang" created="Mon, 26 Aug 2013 23:28:30 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>334941</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 2 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1lryf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>335265</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>