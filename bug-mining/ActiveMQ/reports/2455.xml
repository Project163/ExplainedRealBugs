<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 06:08:01 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[AMQ-5542] KahaDB data files containing acknowledgements are deleted during cleanup</title>
                <link>https://issues.apache.org/jira/browse/AMQ-5542</link>
                <project id="12311210" key="AMQ">ActiveMQ Classic</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/AMQ-2832&quot; title=&quot;Possible replay of old messages post index recovery from journal - data files containing acks reclaimed/cleaned up in error&quot; class=&quot;issue-link&quot; data-issue-key=&quot;AMQ-2832&quot;&gt;&lt;del&gt;AMQ-2832&lt;/del&gt;&lt;/a&gt; was not fixed cleanly.&lt;br/&gt;
The commit dd68c61e65f24b7dc498b36e34960a4bc46ded4b by Gary from 8.10.2010 introduced a problem by deleting too many files.&lt;/p&gt;

&lt;p&gt;Scenarios we are facing currently in production:&lt;br/&gt;
Data file #1 contains unconsumed messages sitting in a DLQ. So this file is not a cleanup candidate.&lt;br/&gt;
The next file #2 contains acks of some messages from file #1. This file is not a cleanup candidate (because of ackMessageFileMap logic).&lt;br/&gt;
The next file #3 contains acks of some messages from file #2. And this file is deleted during the cleanup procedure. So on Broker restart all messages from #2, whose acks were from the deleted file #3, are replayed!&lt;br/&gt;
The reason is gcCandidates variable, which is a copy of gcCandidateSet (see MessageDatabase#checkpointUpdate at the end of the method - org/apache/activemq/store/kahadb/MessageDatabase.java:1659 on 5.10.0 tag). So when a candidate is deleted from gcCandidateSet (org/apache/activemq/store/kahadb/MessageDatabase.java:1668 on 5.10.0 tag), gcCandidates still contains that candidate and the comparison on org/apache/activemq/store/kahadb/MessageDatabase.java:1666 works wrong!&lt;br/&gt;
I will try to adjust AMQ2832Test.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12770461">AMQ-5542</key>
            <summary>KahaDB data files containing acknowledgements are deleted during cleanup</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gtully">Gary Tully</assignee>
                                    <reporter username="barlabanov">Sergiy Barlabanov</reporter>
                        <labels>
                    </labels>
                <created>Tue, 27 Jan 2015 20:40:33 +0000</created>
                <updated>Thu, 18 Jun 2015 17:50:58 +0000</updated>
                            <resolved>Mon, 2 Feb 2015 13:07:37 +0000</resolved>
                                    <version>5.10.0</version>
                    <version>5.10.1</version>
                                    <fixVersion>5.11.1</fixVersion>
                    <fixVersion>5.12.0</fixVersion>
                                    <component>Message Store</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="14294232" author="tbain98" created="Tue, 27 Jan 2015 21:35:24 +0000"  >&lt;p&gt;Doesn&apos;t the logic described here imply that we&apos;re almost never going to be able to delete data files that follow the first unconsumed message?  Won&apos;t it usually be true that there&apos;s at least one ack in file N+1 of a message in file N, for all values of N, so file N+1 will always need to stick around for as long as N does?&lt;/p&gt;</comment>
                            <comment id="14294326" author="barlabanov" created="Tue, 27 Jan 2015 22:38:12 +0000"  >&lt;p&gt;This is an adjustment test for AMQ2832Test.java which fails currently on trunk, 5.10.1, and 5.10.0.&lt;br/&gt;
The adjustment is relative to the trunk version of AMQ2832Test.java.&lt;/p&gt;</comment>
                            <comment id="14294329" author="barlabanov" created="Tue, 27 Jan 2015 22:39:44 +0000"  >&lt;p&gt;This is the possible patch.&lt;br/&gt;
Just removed the copy of gcCandidateSet. It is unclear to me what was the purpose of this copy.&lt;/p&gt;</comment>
                            <comment id="14294333" author="barlabanov" created="Tue, 27 Jan 2015 22:42:36 +0000"  >&lt;p&gt;The consequence of the fix is that if you are really unlucky you will get all files blocked beginning from the one with unconsumed message/messages through all next files containing acks pointing to the files before them.&lt;br/&gt;
So having some unconsumed messages for a long term (like messages in a DLQ) in such an unlucky case will eat quite a lot of space.&lt;/p&gt;</comment>
                            <comment id="14294349" author="barlabanov" created="Tue, 27 Jan 2015 22:48:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/AMQ-2736&quot; title=&quot;KahaDB doesn&amp;#39;t clean up old files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;AMQ-2736&quot;&gt;&lt;del&gt;AMQ-2736&lt;/del&gt;&lt;/a&gt; actually introduced the problem. See the comment of Gary &lt;a href=&quot;https://issues.apache.org/jira/browse/AMQ-2736#comment-12942986&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/AMQ-2736#comment-12942986&lt;/a&gt;.&lt;br/&gt;
It was thought to be a logical error, but it was not. It is not possible just to drop the files, when they contain acks pointing to other files, which are blocked.&lt;/p&gt;</comment>
                            <comment id="14294463" author="barlabanov" created="Wed, 28 Jan 2015 00:18:20 +0000"  >&lt;p&gt;Tim, I think, you are right. Otherwise KahaDB will loose acks and replay messages.&lt;br/&gt;
If this is true, than the current cleanup mechanism have to be reconsidered. It will not work well for scenarios, where messages may stay unconsumed for some time. Some sort of compaction has to be done.&lt;br/&gt;
In the current project we have nearly always some messages in DLQs sitting there for maximum 2 days. This means that we would always have nearly all data files for the last two days.&lt;br/&gt;
Currently it is ok, we have enough of place on the SAN. But what if that would be 2 weeks instead of 2 days?&lt;br/&gt;
I think in this case we would use JDBC storage.&lt;br/&gt;
Another possibility would be to use mKahaDB and put DLQs to a separate storage. That storage would not grow fast since there would not be much traffic.&lt;/p&gt;</comment>
                            <comment id="14295309" author="gtully" created="Wed, 28 Jan 2015 15:45:09 +0000"  >&lt;p&gt;mKahaDB is the current answer to the need for compaction/rewrite problem. that is why it emerged. Partition based on the average length of time a message spends in a queue.&lt;/p&gt;</comment>
                            <comment id="14295399" author="artnaseef" created="Wed, 28 Jan 2015 17:04:52 +0000"  >&lt;p&gt;To Tim&apos;s point &amp;#8211; if there is &lt;b&gt;any&lt;/b&gt; content in the data file that means it is needed, then the file must not be removed.  That problem exists even for messages - one, small message can hold an entire data file.&lt;/p&gt;

&lt;p&gt;Therefore, if there is an acknowledgement in the data file that still needs to be processed, the data file must not be removed.&lt;/p&gt;

&lt;p&gt;As Gary mentioned, multi-kahadb can be used to better prevent the scenario of large holes in data files.&lt;/p&gt;

&lt;p&gt;Keep in mind - it&apos;s in the JMS specification that consumers are expected to be &quot;timely&quot; (I forget the exact wording).  ActiveMQ (and other JMS solutions) are not &quot;message stores&quot; - using them as such leads to many issues.  If messages need to be stored for a length of time, I generally recommend adding a store to the architecture and moving those messages out of ActiveMQ and into the store as-needed.&lt;/p&gt;

&lt;p&gt;With that said, a solution to the compaction problem would be quite welcome.&lt;/p&gt;</comment>
                            <comment id="14295447" author="tbain98" created="Wed, 28 Jan 2015 17:34:09 +0000"  >&lt;p&gt;Consumers can be timely but unsuccessful, leading to messages going to the DLQ, where they can cause exactly this kind of behavior.  So as ActiveMQ is currently implemented the expectation Art referenced (that consumers be timely) needs to be applied to the DLQ as well, which isn&apos;t how I&apos;d expect to need to interact with a DLQ.  I would assume that I could come in the next morning, see that there were messages in the DLQ that failed for some reason, and decide what to do about them.  But even if we simply fix this bug by not deleting the KahaDB files that are still needed (potentially all of them), then the consequence of that is going to be potentially large KahaDB disk usage for just a few messages, which I think most developers/admins won&apos;t be expecting.&lt;/p&gt;

&lt;p&gt;The way I just described interacting with the DLQ does in fact use it as a message store, and I think that&apos;s a valid use case.&lt;/p&gt;

&lt;p&gt;I think that fixing this specific bug is better than not (high disk usage is better than invalid message redelivery, IMO), but I think another solution (which could be mKahaDB, or something else such as having a separate KahaDB for the DLQ) is still needed (in a separate JIRA enhancement).  I submitted &lt;a href=&quot;https://issues.apache.org/jira/browse/AMQ-5547&quot; title=&quot;Provide a means to compact sparsely-populated KahaDB data files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;AMQ-5547&quot;&gt;&lt;del&gt;AMQ-5547&lt;/del&gt;&lt;/a&gt; to capture that need.&lt;/p&gt;</comment>
                            <comment id="14296173" author="barlabanov" created="Thu, 29 Jan 2015 00:52:44 +0000"  >&lt;p&gt;This is correct. This is what we have in production. We have some messages in DLQs. They stay there for max 2 days. After that a special job removes messages older than 2 days from the DLQs.&lt;br/&gt;
Now we expect that ActiveMQ will always retain nearly all data files for the last two days because of those messages in the DLQs. So this would take quite a lot of space I think and we did not expect that when we set up the servers - may be we will have to get a larger SAN volume for that.&lt;/p&gt;

&lt;p&gt;Another consideration is that this is not only the space which will be eaten by KahaDB but also the time ActiveMQ needs to recover after the crash. ActiveMQ will need quite a lot of time to replay all the data files which are sitting there just because of several DLQ messages.&lt;br/&gt;
And the periodic cleanup may take more time to check all the data files (and KahaDB cleanup is a single threaded storage blocking operation).&lt;/p&gt;</comment>
                            <comment id="14296281" author="tbain98" created="Thu, 29 Jan 2015 02:28:34 +0000"  >&lt;p&gt;One option to work around this problem might be to have a job that periodically consumes all DLQ messages and re-sends them to the DLQ as a new message.  That way the dead messages are always near the newest messages in KahaDB and it can delete the old files.  You&apos;ll lose metadata about when the original message was sent/received/etc., but that may be better than what you have now.  (And you could always wrap the original message, with all its metadata, in a wrapper message if you wanted to keep that info.)  This should still get fixed and the improvement I submitted should still get implemented, but that workaround might get you by until the improvement gets implemented.&lt;/p&gt;</comment>
                            <comment id="14296330" author="artnaseef" created="Thu, 29 Jan 2015 03:31:07 +0000"  >&lt;p&gt;DLQs are a common cause of this problem.  My recommendation when using DLQs is &lt;b&gt;always&lt;/b&gt; have a plan for handling them and consume them in a timely manner.&lt;/p&gt;

&lt;p&gt;Again, if the messages need to be stored for a period of time (like 2 days), the best approach is to get them out of ActiveMQ and put them in some type of message store.  Another consideration of this use-case: keeping the messages for this period means some manual action is expected.  ActiveMQ is not designed to give &quot;random access&quot; to messages, which would typically be needed for manual intervention, but instead to produce and consume as a queue.  This use-case would be better served with a database in which individual messages could be referenced.&lt;/p&gt;

&lt;p&gt;Regardless, this is how ActiveMQ currently functions.  Until something better is implemented, these data files must not be deleted until they are no longer used.&lt;/p&gt;</comment>
                            <comment id="14296645" author="gtully" created="Thu, 29 Jan 2015 09:49:54 +0000"  >&lt;p&gt;i will review and try and recall the need for the copy. great find. patch with test case is always much appreciated &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14301245" author="gtully" created="Mon, 2 Feb 2015 13:07:37 +0000"  >&lt;p&gt;test and fix applied (reverted the change from &lt;a href=&quot;https://issues.apache.org/jira/browse/AMQ-2736&quot; title=&quot;KahaDB doesn&amp;#39;t clean up old files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;AMQ-2736&quot;&gt;&lt;del&gt;AMQ-2736&lt;/del&gt;&lt;/a&gt;) with thanks. all tests look good. The copy looks plain wrong to me.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12786968">AMQ-5695</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                                                <inwardlinks description="is broken by">
                                        <issuelink>
            <issuekey id="12483957">AMQ-2736</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12694867" name="AMQ-5542.patch" size="1554" author="barlabanov" created="Tue, 27 Jan 2015 22:39:44 +0000"/>
                            <attachment id="12694864" name="AdjustedAMQ2832Test.patch" size="3474" author="barlabanov" created="Tue, 27 Jan 2015 22:38:12 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 42 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i24v0f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>