<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 06:09:51 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[AMQ-5762] Severe memory leak in the MQTT connector</title>
                <link>https://issues.apache.org/jira/browse/AMQ-5762</link>
                <project id="12311210" key="AMQ">ActiveMQ Classic</project>
                    <description>&lt;p&gt;When an MQTT connection is closed some memory is not released. In case of the soft close (calling connection close on the client) memory leaks at the rate of 70K per connection close. In case of the hard close (pulling the wire, or cutting off the network connection) the leak goes at the rate of 300K per close. we also checked it on version 5.11 - same problem&lt;/p&gt;</description>
                <environment></environment>
        <key id="12827045">AMQ-5762</key>
            <summary>Severe memory leak in the MQTT connector</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="10001">Pending Closed</resolution>
                                        <assignee username="tabish">Timothy A. Bish</assignee>
                                    <reporter username="mfeingold">Michael Feingold</reporter>
                        <labels>
                    </labels>
                <created>Mon, 4 May 2015 20:43:04 +0000</created>
                <updated>Fri, 15 May 2015 20:30:12 +0000</updated>
                            <resolved>Thu, 14 May 2015 21:13:22 +0000</resolved>
                                    <version>5.10.1</version>
                    <version>5.10.2</version>
                    <version>5.11.0</version>
                    <version>5.11.1</version>
                                    <fixVersion>5.12.0</fixVersion>
                                    <component>MQTT</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="14528492" author="tabish121" created="Tue, 5 May 2015 14:17:42 +0000"  >&lt;p&gt;Have you done any profiling to narrow down what the leak is?  &lt;/p&gt;</comment>
                            <comment id="14528623" author="mfeingold" created="Tue, 5 May 2015 15:15:40 +0000"  >&lt;p&gt;Yep. We built a test harness off of the example based on the fusesource client. It is really straightforward - it creates a thousand connections and then cycles through closing them and opening them. We ran this test overnight several times on different versions of AMQ. After a 100 of cycles the memory heap was at 7Gb after the manually triggered GC. We also tested the hard close by killing the client app and restarting it as well as cutting off network by playing with firewall settings. This is where we got the 300K per close. We ran all of this on the out of the box AMQ config. The only change was we turned on thread pooling and configure nio. The same tests did not show any memory leaks on the openwire connections&lt;/p&gt;

&lt;p&gt;I would be happy to share the test harness if it would help any.&lt;/p&gt;</comment>
                            <comment id="14528641" author="tabish121" created="Tue, 5 May 2015 15:27:30 +0000"  >&lt;p&gt;Thanks, it helps to know what client you are using.  I can probably whip up a test but if you want to contribute a unit test based reproducer we love contributions &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  Did you happen to look at the JVM with a tool like VisualVM or Yourkit to see what was holding the memory?  &lt;/p&gt;</comment>
                            <comment id="14528699" author="mfeingold" created="Tue, 5 May 2015 15:53:19 +0000"  >&lt;p&gt;Yep. We used JConsole (and VisualVM) I have a capture of the memory graph - it shows a steady growth. &lt;/p&gt;</comment>
                            <comment id="14528711" author="mfeingold" created="Tue, 5 May 2015 15:57:31 +0000"  >&lt;p&gt;Oh one more clarification - the test consists of connect with a certain clientID, subscribe to a topic with the name based on the clientID and then disconnect. I have the testharness to be placed here: &lt;a href=&quot;https://github.com/Hill30/amq-tests&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/Hill30/amq-tests&lt;/a&gt;. Currently the repo is a mess - there are several versions of the test harness all mashed together, but I have a guy bring some order to it.&lt;/p&gt;</comment>
                            <comment id="14528712" author="tabish121" created="Tue, 5 May 2015 15:57:32 +0000"  >&lt;p&gt;Was curious about which objects were taking up the memory, I will try and reproduce later on today and see what I can observe.  &lt;/p&gt;</comment>
                            <comment id="14528745" author="mfeingold" created="Tue, 5 May 2015 16:21:25 +0000"  >&lt;p&gt;I appreciate your involvement. This is really important for us. For now we can work around this problem by restarting AMQ overnight, but as the traffic and number of the clients grows...&lt;/p&gt;</comment>
                            <comment id="14528788" author="tabish121" created="Tue, 5 May 2015 16:56:54 +0000"  >&lt;p&gt;The github links isn&apos;t working.  If you want to look at the ActiveMQ unit tests for MQTT we have bunch that use the FuseSource MQTT client that you can work off of to create a small unit test that captures your specific scenario.  Does the client connect to a Topic with an active producer or is everything pretty much idle at the time of connect / disconnect ?&lt;/p&gt;</comment>
                            <comment id="14528950" author="mfeingold" created="Tue, 5 May 2015 18:05:34 +0000"  >&lt;p&gt;My apologies - the repo was private, I just turned it into public. It is still messy though. And to answer your question - yes, it is idle, no messages are sent in or out. connect, subscribe, disconnect, that&apos;s it&lt;/p&gt;</comment>
                            <comment id="14529324" author="tabish121" created="Tue, 5 May 2015 21:31:13 +0000"  >&lt;p&gt;So having looked at the tests you have so far I see some things right off that can account for memory climb.  The test is creating durable subscriptions to Topics, meaning that some data is going to be created for each that will be held until the durable subscription is removed.  Next the test creates a client that subscribes to a unique Topic on each iteration meaning that a new Topic is created for every client connection which will not go away on disconnect.  Given that I am not surprised with the results you are seeing.  &lt;/p&gt;</comment>
                            <comment id="14529385" author="mfeingold" created="Tue, 5 May 2015 22:10:05 +0000"  >&lt;p&gt;What you are saying is that the redundant subscribe creates the memory leak? I would expect that when the same client tries to subscribe once more to the same topic the subscription should be considered redundant and ignored. Anyway this is important info and we will run the test without the subscribe to confirm that this is the case. &lt;/p&gt;

&lt;p&gt;I also think that the extra 230K per hard close is still a concern. We will run a few more tests and I will keep you posted&lt;/p&gt;</comment>
                            <comment id="14529407" author="tabish121" created="Tue, 5 May 2015 22:19:34 +0000"  >&lt;p&gt;Just sharing some thoughts based on initial look at the repo which is a little cluttered so I wasn&apos;t 100% sure what all was under test.  Would be nice to reduce the test to the simplest possible reproducer.  I created a simple unit test based on what I thought the code was attempting to do and did some profiling and didn&apos;t see anything that was surprising.  For a test case where the subscriptions are not durable and the broker had been configured to GC inactive destinations my memory remained fairly stable although it did look as though the MQTT FuseSource client was retaining memory for closed connections.  You might want to give the Paho MQTT client a shot in your testing.  &lt;/p&gt;</comment>
                            <comment id="14530797" author="mfeingold" created="Wed, 6 May 2015 16:13:14 +0000"  >&lt;p&gt;Unfortunately our use case requires durable subscriptions. &lt;/p&gt;

&lt;p&gt;We use MQTT to synchronize the data between our servers and multiple (up to 4000 at this time) mobile devices. We create a topic per device and every device connects to this topic with the clientID specific for the device. The specifics of the mobile connectivity demands to account for multiple disconnects and connection drops. &lt;/p&gt;

&lt;p&gt;I asked the code to be pared down to bare bones and will share it with you shortly. &lt;/p&gt;

&lt;p&gt;Also we ran another test overnight - no subscribe at all, just connect/disconnect on durable subscription, and the heap seems to be growing. I will keep you posted&lt;/p&gt;</comment>
                            <comment id="14530860" author="tabish121" created="Wed, 6 May 2015 16:46:19 +0000"  >&lt;p&gt;Using durable subscriptions is of course perfectly valid.  We just need to narrow down the testing to determine if the behaviour you are seeing is just normal resource utilization or an actual problem.  &lt;/p&gt;</comment>
                            <comment id="14531425" author="mfeingold" created="Wed, 6 May 2015 21:12:17 +0000"  >&lt;p&gt;Here is the memory consumption chart from our latest test run &lt;a href=&quot;https://github.com/Hill30/amq-tests/blob/master/mqtt_conncect-disconnect/memory_leak_example.png&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/Hill30/amq-tests/blob/master/mqtt_conncect-disconnect/memory_leak_example.png&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The code for this particular run is here: &lt;a href=&quot;https://github.com/Hill30/amq-tests/tree/master/mqtt_conncect-disconnect&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/Hill30/amq-tests/tree/master/mqtt_conncect-disconnect&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As you can see the memory leak seems to be present, even though nothing is happening except connect/disconnect. Keep in mind that this test was ran on the same instance of ActiveMQ as our previous tests which did include subscribe to the topic, and the subscribe was done with QoS=2.&lt;/p&gt;

&lt;p&gt;My guess for why we see the same result even though there is no subscribe is that it is because the session connect is attaching to is already there (clean session=false) and it has a reference to a durable topic created during previous test runs (when a topic was created in response to a subscribe with QoS=2)&lt;/p&gt;

&lt;p&gt;We will re-run the test over a clean ActiveMQ installation and I will share the results&lt;/p&gt;</comment>
                            <comment id="14531600" author="tabish121" created="Wed, 6 May 2015 22:50:52 +0000"  >&lt;p&gt;Please also share the broker configuration you are using to help match up your environment.&lt;/p&gt;</comment>
                            <comment id="14531630" author="tabish121" created="Wed, 6 May 2015 23:01:52 +0000"  >&lt;p&gt;Also, I&apos;d recommend trying against the latest ActiveMQ 5.12-SNAPSHOT as that has a bunch of fixes.  &lt;/p&gt;</comment>
                            <comment id="14532564" author="mfeingold" created="Thu, 7 May 2015 12:54:40 +0000"  >&lt;p&gt;ok. It is official. We re-ran the same test over a clean instance of AMQ - no memory leak. &lt;a href=&quot;https://github.com/Hill30/amq-tests/blob/master/mqtt_conncect-disconnect/no-leak.png&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/Hill30/amq-tests/blob/master/mqtt_conncect-disconnect/no-leak.png&lt;/a&gt;. We will modify the test as follows:&lt;/p&gt;

&lt;p&gt;1. connect&lt;br/&gt;
2. subscribe to a topic with QoS 2&lt;br/&gt;
3. disconnect&lt;br/&gt;
4. repeat&lt;br/&gt;
4.1 connect&lt;br/&gt;
4.2 disconnect&lt;/p&gt;

&lt;p&gt;will keep you posted&lt;/p&gt;

</comment>
                            <comment id="14536787" author="mfeingold" created="Sat, 9 May 2015 17:33:58 +0000"  >&lt;p&gt;Alright. I can share some results.&lt;/p&gt;

&lt;p&gt;I created 2 versions of test harness a single file version and batch version. &lt;/p&gt;

&lt;p&gt;The single version (&lt;a href=&quot;https://github.com/Hill30/amq-tests/tree/master/MQTTDisconnect&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/Hill30/amq-tests/tree/master/MQTTDisconnect&lt;/a&gt;) runs against a single topic repeats the following operations: connect to the topic, wait for connection, subscribe to the topic QoS=2, disconnect, wait for the disconnect.&lt;/p&gt;

&lt;p&gt;The batch version (&lt;a href=&quot;https://github.com/Hill30/amq-tests/tree/master/MQTTBatchDisconnect&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/Hill30/amq-tests/tree/master/MQTTBatchDisconnect&lt;/a&gt;) for every connection on the list of 500 connections it creates a connection, and once it connects successfully it subscribes to the topic. After the process of creating connections is completed, it disconnects all of them. Then the process is repeated. &lt;/p&gt;

&lt;p&gt;Here is what I have discovered&lt;/p&gt;

&lt;p&gt;1. The single file test did not reliably show any memory leaks. Several test runs of 100000 connect/subscribe/disconnect cycles show memory increase of 200 bytes per cycle, which may be just an inconsistency in the way heap size is measured.&lt;/p&gt;

&lt;p&gt;2. The batch test shows memory leak of ~75K per connect/disconnect on 5.10.2 and ~35K per on 5.12 SNAPSHOT. The most puzzling part is that after the batch test has been run, all other tests (including the single file) start leaking at the same rate. This behavior continues even after broker restart.&lt;/p&gt;

&lt;p&gt;On the side note, repeating subscribe for the session has no impact on the memory leak&lt;/p&gt;

&lt;p&gt;You can examine the results of the test runs here: &lt;a href=&quot;https://github.com/Hill30/amq-tests/blob/master/MQTTBatchDisconnect/src/com/hill30/AMQTests/runs.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/Hill30/amq-tests/blob/master/MQTTBatchDisconnect/src/com/hill30/AMQTests/runs.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;AMQ configuration is taken out of the box - just unzipped and started&lt;/p&gt;</comment>
                            <comment id="14538279" author="tabish121" created="Mon, 11 May 2015 17:54:26 +0000"  >&lt;p&gt;I tried your test cases against both a 5.12-SNAPSHOT and 5.11.2 build and see no leaks.  I believe that what you are seeing is the typical rise in heap usage that will continue until a GC cycle is run.  You can see this in action if you run your broker with a profiler attached such as VisualVM or YourKit and force a full GC, the memory will drop back to near your initial starting point each time.&lt;/p&gt;

&lt;p&gt;I modified your batch connect client to run for 30 minutes for so and then on completion forced a GC and ended up back down around my starting usage point and each version.  &lt;/p&gt;</comment>
                            <comment id="14538543" author="mfeingold" created="Mon, 11 May 2015 19:55:22 +0000"  >&lt;p&gt;Well I am not sure what to tell you. In my case it is clearly a leak - every measure of the heap level I take I do so after forcing GC manually through the JConsole - several times. What platform you are running this on? I ran my tests on Mac OS. I will re run them on the Windows. &lt;/p&gt;

&lt;p&gt;Any chance we can do a webex so that I would share my setup with you?&lt;/p&gt;

&lt;p&gt;I really need to get to the bottom of this. We do have a memory leak in our prod - that&apos;s why we started &lt;/p&gt;</comment>
                            <comment id="14540459" author="mzevin" created="Tue, 12 May 2015 18:47:56 +0000"  >&lt;p&gt;Michael Feingold asked me to try MQTTBatchDisconnect program against ActiveMQ broker installed on a Windows Server. Broker version number installed on our test server is 5.10.2. I have used jconsole tool from JDK to look at heap during the the test. I ran application 5th times (each run creates 500x10=5000 MQTT connections with QOS subscription level 2). After each application run and manual GC (&apos;Perform GC&apos; button in jconsole) I can see that some amount of memory leaked (~150-200 MB per application run). I am going to attach ActiveMQ configuration files from the server and screenshot that was taken from jconsole. &lt;/p&gt;</comment>
                            <comment id="14540489" author="mfeingold" created="Tue, 12 May 2015 19:00:44 +0000"  >&lt;p&gt;I looks like we can consistently reproduce the memory leak in a variety of environments AMQ versions and configuration options.&lt;/p&gt;

&lt;p&gt;A stupid though just occurred to me - when you were running my MQTTBatchDisconnect test - did you take it from github as is? If it so, the test was only running connect/disconnect scenario. On clean install thus scenario does not leak. &lt;/p&gt;

&lt;p&gt;My initial intent was to run the test from a command line with parameters, but then I grew lazy and set parameters directly in the code, currently in line 12. The checked in version of the test sets the QoS to &quot;none&quot;, so there is no call to subscribe during the test. The test runs with the leak have the second parameter set to &quot;2&quot;. I will modify the code in the repo for your convinience&lt;/p&gt;</comment>
                            <comment id="14544259" author="mfeingold" created="Thu, 14 May 2015 19:54:26 +0000"  >&lt;p&gt;heapdumps comparison&lt;/p&gt;</comment>
                            <comment id="14544265" author="mfeingold" created="Thu, 14 May 2015 20:00:54 +0000"  >&lt;p&gt;I believe I know what&apos;s going on. It looks like every time a connection to any topic is closed, some memory is leaked. The amount of memory leaked is ~100b times number of currently existing durable topics. Therefore if the number of durable topics is low, the leak us so slow you can hardly see it. Also if connect/disconnect is happening only once in a blue moon - same thing. In my use case both are pretty high, so here we are.&lt;/p&gt;

&lt;p&gt;I captured a few memory dumps while I was running my tests and they show that every time a connection is disconnected, for every durable topic there are 2 objects leaking - a hashmap and a linkedlist Node. You  can clearly see it in the heapdump compare screenshot (attached &lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12732941/Screen%20Shot%202015-05-14%20at%202.06.02%20PM.png&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12732941/Screen%20Shot%202015-05-14%20at%202.06.02%20PM.png&lt;/a&gt;). Here is what I did:&lt;/p&gt;

&lt;p&gt;1. on a clean install I created 2 durable topics via console&lt;br/&gt;
2. created a heapdump1&lt;br/&gt;
3. I ran a test connecting to the same topic and immediately disconnecting from it. The connect/dosconnect cyscle was repeated 50000 times.&lt;br/&gt;
4. another heapdump created&lt;/p&gt;

&lt;p&gt;What you see in the picture is a comparison between the two. You can clearly see the 2 culprits.&lt;/p&gt;</comment>
                            <comment id="14544306" author="tabish121" created="Thu, 14 May 2015 20:24:34 +0000"  >&lt;p&gt;I&apos;ve found the issue already, and have a patch going in soon.  I will let you know once I&apos;ve finished testing and added committed the fix, you can then pull down the latest source from github and build or you can wait until a new SNAPSHOT build is done and run against that.  &lt;/p&gt;</comment>
                            <comment id="14544372" author="mfeingold" created="Thu, 14 May 2015 21:11:47 +0000"  >&lt;p&gt;That&apos;s great news, thank you. Let me know when it is ready&lt;/p&gt;</comment>
                            <comment id="14544373" author="tabish121" created="Thu, 14 May 2015 21:13:22 +0000"  >&lt;p&gt;Added a fix to workaround the leak in KahaDB from the lookup of Durable subscriptions from an MQTT connection. &lt;/p&gt;</comment>
                            <comment id="14544419" author="tabish121" created="Thu, 14 May 2015 21:49:43 +0000"  >&lt;p&gt;The 5.12-SNAPSHOT builds are available here but it will take a day or so for one that includes the fix to be run.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://repository.apache.org/content/repositories/snapshots/org/apache/activemq/apache-activemq/5.12-SNAPSHOT/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://repository.apache.org/content/repositories/snapshots/org/apache/activemq/apache-activemq/5.12-SNAPSHOT/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14545617" author="mfeingold" created="Fri, 15 May 2015 14:58:22 +0000"  >&lt;p&gt;Our tests confirm that there is no memory leaks on the patched version. Thank you. &lt;/p&gt;

&lt;p&gt;Do you know when we can expect the 5.12.0 release? Will the fix be rolled in the 5.10.x and/or 5.11.x?&lt;/p&gt;</comment>
                            <comment id="14546134" author="tabish121" created="Fri, 15 May 2015 20:30:12 +0000"  >&lt;p&gt;I don&apos;t know of any firm plans for releases at this point, I think a 5.12 is worth considering soon given all the work we&apos;ve done to harden it.  I did a merge back to 5.11.x for this fix in case you want to build your own version of 5.11.  It could go back to 5.10.x if someone wanted to do that also.  &lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12732328" name="Screen Shot 2015-05-12 at 20.06.47.png" size="73326" author="mzevin" created="Tue, 12 May 2015 18:49:54 +0000"/>
                            <attachment id="12732941" name="Screen Shot 2015-05-14 at 2.06.02 PM.png" size="397263" author="mfeingold" created="Thu, 14 May 2015 19:54:26 +0000"/>
                            <attachment id="12732326" name="activemq.xml" size="6297" author="mzevin" created="Tue, 12 May 2015 18:49:54 +0000"/>
                            <attachment id="12732327" name="wrapper.conf" size="10395" author="mzevin" created="Tue, 12 May 2015 18:49:54 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 27 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2e9l3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>