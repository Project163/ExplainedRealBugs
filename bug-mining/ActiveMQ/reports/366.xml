<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 05:37:04 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[AMQ-1739] ActiveMQ 5.1.0 runs out of file descriptors with lots of &apos;CLOSE_WAIT&apos; sockets</title>
                <link>https://issues.apache.org/jira/browse/AMQ-1739</link>
                <project id="12311210" key="AMQ">ActiveMQ Classic</project>
                    <description>&lt;p&gt;We have no idea why or when, but within a few days after start-up, ActiveMQ suddenly runs out of file descriptors (we&apos;ve raised the limit to 10240). According to lsof it has lots of sockets which are in CLOSE_WAIT when that happens. As soon as that happened once, it would re-occur within a few hours. This behavior did not happen with ActiveMQ 5.0.&lt;/p&gt;

&lt;p&gt;We have five queues, all with only one consumer. All consumption and production is via the Stomp-interface using PHP-clients. Three of those queues get up to 50-100 messages/second in peak moments, while the consumers adjust their own consumption rate to the systems load (normally its maxed to about 50-150/sec). So in high-load moments on the consumers, the queues can grow to a few thousand messages, normally the queues are emptied as soon as a message occurs. Those five consumers stay connected indefinitely.&lt;/p&gt;

&lt;p&gt;The messages are all quite small (at most 1 KB or so) and come from 5 web servers. For each web page-request (about 2-3M/day) a connection is made to ActiveMQ via Stomp and at least one message is sent to ActiveMQ, for most requests two are sent to the two most active queues. For all request a new connection is made and at most 4 stomp-messages are sent to ActiveMQ (connect, two messages, disconnect), since apache+php does not allow useful reuse of sockets and similar resources.So &lt;br/&gt;
So the connection-rate is about the same as the highest message rate on any of the queues (so 50-100connects/second).&lt;/p&gt;

&lt;p&gt;When the high amount of sockets in CLOSE_WAIT occurs, we manually disable the producers and the sockets disappear gradually. After that the amount of sockets stays around 180-190 (mostly opened jars), but seams to re-increase more easily than when ActiveMQ is restarted. I have not checked if anything special happens on the web servers or databases, since their producer and consumer implementation has not changed since 5.0.&lt;/p&gt;

&lt;p&gt;What I did notice is that the memory-consumption increases heavily prior to running out of descriptors, and the consumption re-increases way to fast compared to before 11:45u:&lt;br/&gt;
&lt;a href=&quot;http://achelois.tweakers.net/~acm/tnet/activemq-5.1-memory-consumption.png&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://achelois.tweakers.net/~acm/tnet/activemq-5.1-memory-consumption.png&lt;/a&gt;&lt;/p&gt;</description>
                <environment>&lt;p&gt;We have a single broker with no special network-stuff. Our broker-system has two single core Opterons, 8GB of memory, plenty of I/O and runs a recent 64bit debian with 2.6.21 kernel.&lt;/p&gt;

&lt;p&gt;Java(TM) SE Runtime Environment (build 1.6.0_06-b02)&lt;br/&gt;
Java HotSpot(TM) 64-Bit Server VM (build 10.0-b22, mixed mode)&lt;/p&gt;

&lt;p&gt;We left most of the activemq.xml-configuration as-is and adjusted the start-up script to run with 2GB heap size and parallel garbage collector, which was more or less needed for 5.0 and left for 5.1 in the start-up script.&lt;/p&gt;</environment>
        <key id="12482579">AMQ-1739</key>
            <summary>ActiveMQ 5.1.0 runs out of file descriptors with lots of &apos;CLOSE_WAIT&apos; sockets</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rajdavies">Robert Davies</assignee>
                                    <reporter username="acm">Arjen</reporter>
                        <labels>
                    </labels>
                <created>Wed, 21 May 2008 10:59:28 +0000</created>
                <updated>Mon, 28 Jul 2014 13:44:56 +0000</updated>
                            <resolved>Tue, 2 Sep 2008 06:57:36 +0000</resolved>
                                    <version>5.1.0</version>
                                    <fixVersion>5.2.0</fixVersion>
                                    <component>Broker</component>
                        <due></due>
                            <votes>6</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="12939718" author="rajdavies" created="Wed, 21 May 2008 11:52:59 +0000"  >&lt;p&gt;SVN revision 658637 makes closing a socket in a separate thread optional.&lt;br/&gt;
The property to set is closeAsync which is true by default.&lt;/p&gt;

&lt;p&gt;To disable this in a broker add it as a transport option to the transport connector address &lt;br/&gt;
e.g.  &lt;/p&gt;

&lt;p&gt;&amp;lt;transportConnectors&amp;gt;&lt;br/&gt;
            &amp;lt;transportConnector name=&quot;openwire&quot; uri=&quot;tcp://localhost:61616?transport.closeAsync=false&quot;/&amp;gt;&lt;br/&gt;
&amp;lt;/transportConnectors&amp;gt;&lt;/p&gt;</comment>
                            <comment id="12939687" author="ammulder" created="Wed, 21 May 2008 12:22:53 +0000"  >&lt;p&gt;For what it&apos;s worth, we saw this (problems with lots of CLOSE_WAIT sockets) only when testing with client with a tight loop that opened and closed lots of connections (instead of pooling), and only on Windows (where it would fail unable to get an available port after 4000-5000 connections).&lt;/p&gt;

&lt;p&gt;Another solution seemed to be to alter the Transport to set SO_LINGER to any positive value.&lt;/p&gt;</comment>
                            <comment id="12939712" author="fhanik" created="Wed, 21 May 2008 21:39:17 +0000"  >&lt;p&gt;CLOSE_WAIT is a kernel tuning parameter, how long the connection stays there depends on your OS.&lt;br/&gt;
On linux I don&apos;t even know if you can control it, but I know you can on windows and solaris.&lt;br/&gt;
problem with it being a kernel parameter, is that it then affects all the system, any program using TCP connections&lt;/p&gt;</comment>
                            <comment id="12939724" author="fhanik" created="Thu, 22 May 2008 14:17:37 +0000"  >&lt;p&gt;I stand corrected, it is just that solaris used to misname the parameter &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.sean.de/Solaris/soltune.html#tcp_close_wait_interval&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.sean.de/Solaris/soltune.html#tcp_close_wait_interval&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;close_Wait on a busy system can stick around if the application hasn&apos;t called close (server too busy, or a bug)&lt;/p&gt;

&lt;p&gt;here is a good summary&lt;br/&gt;
&lt;a href=&quot;http://www.sunmanagers.org/pipermail/sunmanagers/2006-January/039225.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.sunmanagers.org/pipermail/sunmanagers/2006-January/039225.html&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="12939716" author="acm" created="Mon, 26 May 2008 07:57:35 +0000"  >&lt;p&gt;The transport.closeAsync=false seems to work. We haven&apos;t had ActiveMQ running out of file descriptors for a few days now.&lt;/p&gt;

&lt;p&gt;I did see the systemload spike to 3+ a few times though, so the original issue which started the whole running-out-of-descriptors thingy still seem to exist. With a maximum heap of 512MB it ran out of memory and started doing full GC&apos;s every few seconds. With 1024MB heap it had less trouble with the increased load, but ran to gc&apos;s where it ran had 900MB consumed and reduced it to only 500MB rather than 300MB -&amp;gt; 30MB.&lt;/p&gt;

&lt;p&gt;I guess that&apos;s a different issue?&lt;/p&gt;</comment>
                            <comment id="12939731" author="acm" created="Tue, 27 May 2008 11:41:41 +0000"  >&lt;p&gt;The issue - or a similar one - reoccured yesterday.&lt;/p&gt;

&lt;p&gt;It appears ActiveMQ 5.1/5.2-snapshot copes much worse with queues that are filled faster than consumed (or not consumed at all) than 5.0.&lt;/p&gt;

&lt;p&gt;With 5.0 I could fill up two queues to over 80k small messages, but 5.2-snapshot refused to accept connections after about 5120 message on one queue and 3690 on the other.&lt;/p&gt;

&lt;p&gt;The attached tgz is a set of two php5 scripts. Just extract it somewhere and adjust the $brokerUri in &apos;producerserver.php&apos; to fit your needs. Then you should be able to run it and get an overloaded activemq within a minute or so.&lt;/p&gt;

&lt;p&gt;Running is simple, make sure you have a CLI-version of php 5 (in debian that is &apos;apt-get install php5-cli&apos;) and run: &apos;php producerserver.php&apos;&lt;/p&gt;

&lt;p&gt;That script will then include the default Stomp-implementation for php and connect to ActiveMQ using Stomp. It forks off $max child-processes, until you stop the script, which send two messages to two seperate queues.  If you need any special connection-parameters, have a look at the Stomp.php StompConnection&apos;s &apos;getInstance&apos;-method, but the above should work with a default ActiveMQ-install.&lt;/p&gt;

&lt;p&gt;Our ActiveMQ is started with a slightly adjusted activemq.xml (ssl and xmmp connections are not started, camel-section is empty, resource management is commented out) but mostly left to the defaults. Our ACTIVEMQ_OPTS = &quot;-XX:+UseParallelOldGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xms1024M -Xmx1024M -Dorg.apache.activemq.UseDedicatedTaskRunner=true&quot;&lt;/p&gt;

&lt;p&gt;Although normally you&apos;d have at least one consumer for those queue&apos;s, its easier and faster to reproduce the issue without one. That way you should get &apos;ERROR TransportConnector             - Could not accept connection : Too many open files&apos; pretty fast.&lt;/p&gt;</comment>
                            <comment id="12939750" author="comdivisionys" created="Tue, 3 Jun 2008 07:21:19 +0000"  >&lt;p&gt;I can only support what Arien said, we moved from 5.0 to 5.1 because of several smaller issues which are fixed, however there is something completly problematic going on...&lt;/p&gt;

&lt;p&gt;We have data collectors for network traffic/disk/cpu usage spread cross the datacenter which will all report into an ActiveMQ instance, each collector has its own queue, so being it approx. 15K queus and on each queue about 3-10 messages per minute coming in. that sounds not much, but in certain scenarios the Apps/DB Server picking up the data is not fast enough to pick them in a timely fashion, so they might queue up for up to 2 days. &lt;/p&gt;

&lt;p&gt;We had issues with 5.0 that it died from time to time (approx. once a week), but with 5.1 it does not even stand for 12 hours. &lt;/p&gt;

&lt;p&gt;As it is run in a VM, we extend the original setup of 1 GB Memory already to 4 GB, but even that didn&apos;t help, we always run either out of File Descriptors or out of memory.&lt;/p&gt;

&lt;p&gt;This is really a serious issue, because we need to decide whether we switch back to 5.0 or even back to a BEA or IBM tool, as the instabilities are going on for a few months now...&lt;/p&gt;</comment>
                            <comment id="12939764" author="vikdhawan" created="Tue, 3 Jun 2008 14:42:14 +0000"  >&lt;p&gt;Guys, &lt;/p&gt;

&lt;p&gt;i had the similar issue with 5.0 and 5.0 to resolve the File Descriptors and CLOSE_WAIT sockets. i tuned the JVM parameters and Solaris parmeter. &lt;/p&gt;

&lt;p&gt;1. i changed the ulimit -n to 1024 for the separate activemq user account we created to run AMQ. that basically changes the maximum file handles allowed per user. &lt;/p&gt;

&lt;p&gt;2. we are using these JVM parameters  -Xmx2048M -XX:SurvivorRatio=4 -XX:+UseParallelGC -Xms2048M -Xss512k. This configuration works and we don&apos;t get any out of File Descriptors problem any more. &lt;/p&gt;

&lt;p&gt;There are reasons behind why we chose this route, if you want to know the details let me know. &lt;/p&gt;

&lt;p&gt;BTW: Out-of-Memory is because a major bug in AMQ versions related to how they remove the old messages. The Old Gen memory pool keeps on growing because AMQ does not release the memory for the messages when the life cycle is complete for those messages (produced /consumed and removed from the queue). &lt;/p&gt;

&lt;p&gt;Hope this helps.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;</comment>
                            <comment id="12939872" author="acm" created="Sun, 29 Jun 2008 12:11:25 +0000"  >&lt;p&gt;I figured out why the CLOSE_WAIT&apos;s reoccured.&lt;/p&gt;

&lt;p&gt;It is caused by the default memory limit of 5MB per queue, which is configured in the default activemq.xml. As soon as the limit is hit, activemq just has the producers wait untill space frees up.&lt;br/&gt;
But if there is no consumption, or the consumption isn&apos;t fast enough, ActiveMQ will eventually have more producers than available file descriptors. In my case I got 930 CLOSE_WAIT&apos;s for 1024 available descriptors in total. I also had 930 stacks ending like this:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;java.lang.Object.wait(long) @bci=0 (Compiled frame; information may be imprecise)&lt;/li&gt;
	&lt;li&gt;org.apache.activemq.usage.MemoryUsage.waitForSpace(long) @bci=44, line=85 (Compiled frame)&lt;/li&gt;
	&lt;li&gt;org.apache.activemq.broker.region.Queue.send(org.apache.activemq.broker.ProducerBrokerExchange, org.apache.activemq.command.Message) @bci=259, line=395 (Interpreted frame)&lt;/li&gt;
	&lt;li&gt;org.apache.activemq.broker.region.AbstractRegion.send(org.apache.activemq.broker.ProducerBrokerExchange, org.apache.activemq.command.Message) @bci=42, line=350 (Compiled frame)&lt;/li&gt;
	&lt;li&gt;org.apache.activemq.broker.region.RegionBroker.send(org.apache.activemq.broker.ProducerBrokerExchange, org.apache.activemq.command.Message) @bci=142, line=437 (Compiled frame)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;So each of the 930 threads is waiting for someone to make some room, but since they prevent any other connection from entering the system, the memory will never be freed again. Possibly, even if there is a consumer which picks up consumption after a while, the fact that it ran out of file descriptors might cause it to a unpredictable and dangerous situation.&lt;/p&gt;

&lt;p&gt;After removing the memory limit for seperate queues, I reran my &quot;overload producer&quot; and was able to produce several tens of thousands of messages. But it wasn&apos;t really gone after that. Similar behaviour seems to occur as soon as you run out of the systemUsage&apos;s memoryUsage and/or when the disk or temporary spaces fill up, even though it by no means had reached the disk limit yet, but possibly the temporary limit.&lt;/p&gt;

&lt;p&gt;The problem here is of course that there might not be a solution to it. But it may help if the logfile gets error messages about hitting memory limits, rather than just leaving the user in the dark?&lt;/p&gt;</comment>
                            <comment id="12940016" author="jpoloney" created="Thu, 31 Jul 2008 20:12:43 +0000"  >&lt;p&gt;Arjen,&lt;/p&gt;

&lt;p&gt;I have also been experiencing the same problems. I am running a near identical setup to yours with ActiveMQ 5.0.0. I switched to 5.1.0 temporarily, but it had so many more problems, that I had to revert back.&lt;/p&gt;

&lt;p&gt;I believe the problem is actually within the Stomp client itself. I&apos;ve been searching around about the CLOSE_WAIT socket issue (in general) and it appears to be a problem caused by the code, not the server. Basically, some where in your code, the socket never gets closed. It can theoretically remain in a CLOSE_WAIT state forever if this happens.&lt;/p&gt;

&lt;p&gt;We monitor our ActiveMQ sockets every minute (using lsof) and about once every few hours, we see it spike from around 220 open connections to numbers like 7,000 or 8,000. It doesn&apos;t build up or anything, just spikes to extremely high numbers.&lt;/p&gt;

&lt;p&gt;In some cases, the queue actually dies (overloaded from too many sockets) and in some cases it actually recovers and flushes everything out. &lt;/p&gt;

&lt;p&gt;So, I think the problem lies somewhere inside the Stomp client rather than in ActiveMQ itself. Have you gotten anywhere else with this lately?&lt;/p&gt;</comment>
                            <comment id="12940020" author="acm" created="Mon, 4 Aug 2008 11:20:22 +0000"  >&lt;p&gt;Joel,&lt;/p&gt;

&lt;p&gt;The clients close their connection, as they should. If not, the sockets would not be in &apos;CLOSE_WAIT&apos; but in some other state (TIME_WAIT?).&lt;/p&gt;

&lt;p&gt;Switching to the 5.2 development build with the non-asynchronously closing sockets works fine once I had removed the limits on memory usage.&lt;/p&gt;</comment>
                            <comment id="12940027" author="jpoloney" created="Mon, 4 Aug 2008 19:50:51 +0000"  >&lt;p&gt;Arjen,&lt;/p&gt;

&lt;p&gt;I rewrote my activemq.xml from scratch and modified a lot of the memory usage parameters (like you said) and I&apos;m no longer having these issues. &lt;/p&gt;

&lt;p&gt;I don&apos;t really want to switch to a dev build of 5.2, I&apos;ll wait for it come out out officially (unless you strongly feel it&apos;s much better &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/biggrin.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;)&lt;/p&gt;</comment>
                            <comment id="12940154" author="rajdavies" created="Tue, 2 Sep 2008 06:57:35 +0000"  >&lt;p&gt;Going to mark this issue as resolved&lt;/p&gt;</comment>
                            <comment id="12940155" author="linusl" created="Thu, 4 Sep 2008 18:27:51 +0000"  >&lt;p&gt;Calling PHP &apos;socket_shutdown&apos; and &apos;socket_close&apos; functions to disconnect rather than using &apos;fclose&apos; which might leaving linger sockets on the ActiveMQ server. Try an older version of &lt;a href=&quot;http://stomp.codehaus.org/Stomp+JMS&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://stomp.codehaus.org/Stomp+JMS&lt;/a&gt; using fclose.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12461088" name="stomp-overload-producer.tgz" size="4400" author="acm" created="Tue, 27 May 2008 11:41:41 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>84784</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            17 years, 12 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0rzmn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>161416</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>