diff --git a/changes/1064-samuelcolvin.md b/changes/1064-samuelcolvin.md
new file mode 100644
index 000000000..7f81073d9
--- /dev/null
+++ b/changes/1064-samuelcolvin.md
@@ -0,0 +1 @@
+Prevent type attributes being added to schema unless the attribute `__schema_attributes__` is `True` 
diff --git a/docs/examples/types_custom_type.py b/docs/examples/types_custom_type.py
index 165b42b50..5e99d9689 100644
--- a/docs/examples/types_custom_type.py
+++ b/docs/examples/types_custom_type.py
@@ -1,21 +1,64 @@
-from pydantic import BaseModel, ValidationError
+import re
+from pydantic import BaseModel
 
-class StrictStr(str):
+# https://en.wikipedia.org/wiki/Postcodes_in_the_United_Kingdom#Validation
+post_code_regex = re.compile(
+    r'(?:'
+    r'([A-Z]{1,2}[0-9][A-Z0-9]?|ASCN|STHL|TDCU|BBND|[BFS]IQQ|PCRN|TKCA) ?'
+    r'([0-9][A-Z]{2})|'
+    r'(BFPO) ?([0-9]{1,4})|'
+    r'(KY[0-9]|MSR|VG|AI)[ -]?[0-9]{4}|'
+    r'([A-Z]{2}) ?([0-9]{2})|'
+    r'(GE) ?(CX)|'
+    r'(GIR) ?(0A{2})|'
+    r'(SAN) ?(TA1)'
+    r')'
+)
+
+class PostCode(str):
+    """
+    Partial UK postcode validation. Note: this is just an example, and is not
+    intended for use in production; in particular this does NOT guarantee
+    a postcode exists, just that it has a valid format.
+    """
     @classmethod
     def __get_validators__(cls):
+        # one or more validators may be yielded which will be called in the
+        # order to validate the input, each validator will receive as an input
+        # the value returned from the previous validator
         yield cls.validate
 
+    @classmethod
+    def __modify_schema__(cls, field_schema):
+        # __modify_schema__ should mutate the dict it receives in place,
+        # the returned value will be ignored
+        field_schema.update(
+            # simplified regex here for brevity, see the wikipedia link above
+            pattern='^[A-Z]{1,2}[0-9][A-Z0-9]? ?[0-9][A-Z]{2}$',
+            # some example postcodes
+            examples=['SP11 9DG', 'w1j7bu'],
+        )
+
     @classmethod
     def validate(cls, v):
         if not isinstance(v, str):
-            raise ValueError(f'strict string: str expected not {type(v)}')
-        return v
+            raise TypeError('string required')
+        m = post_code_regex.fullmatch(v.upper())
+        if not m:
+            raise ValueError('invalid postcode format')
+        # you could also return a string here which would mean model.post_code
+        # would be a string, pydantic won't care but you could end up with some
+        # confusion since the value's type won't match the type annotation
+        # exactly
+        return cls(f'{m.group(1)} {m.group(2)}')
+
+    def __repr__(self):
+        return f'PostCode({super().__repr__()})'
 
 class Model(BaseModel):
-    s: StrictStr
+    post_code: PostCode
 
-print(Model(s='hello'))
-try:
-    print(Model(s=123))
-except ValidationError as e:
-    print(e.json())
+model = Model(post_code='sw8 5el')
+print(model)
+print(model.post_code)
+print(Model.schema())
diff --git a/docs/usage/schema.md b/docs/usage/schema.md
index 804929ee8..a02cdde97 100644
--- a/docs/usage/schema.md
+++ b/docs/usage/schema.md
@@ -73,7 +73,7 @@ to set all of the arguments above except `default`.
 
 ### Unenforced Field constraints
 
-If *pydantic* finds constraints which are not being enforced, an error will be raised. If you want to force the 
+If *pydantic* finds constraints which are not being enforced, an error will be raised. If you want to force the
 constraint to appear in the schema, even though it's not being checked upon parsing, you can use variadic arguments
 to `Field()` with the raw schema attribute name:
 
@@ -82,6 +82,11 @@ to `Field()` with the raw schema attribute name:
 ```
 _(This script is complete, it should run "as is")_
 
+## Modifying schema in custom fields
+
+Custom field types can customise the schema generated for them using the `__modify_schema__` class method;
+see [Custom Data Types](types.md#custom-data-types) for more details.
+
 ## JSON Schema Types
 
 Types, custom field types, and constraints (like `max_length`) are mapped to the corresponding spec formats in the
diff --git a/docs/usage/types.md b/docs/usage/types.md
index a939b7966..3a92b7e62 100644
--- a/docs/usage/types.md
+++ b/docs/usage/types.md
@@ -1,5 +1,5 @@
-Where possible *pydantic* uses [standard library types](#standard-library-types) to define fields, thus smoothing 
-the learning curve. For many useful applications, however, no standard library type exists, 
+Where possible *pydantic* uses [standard library types](#standard-library-types) to define fields, thus smoothing
+the learning curve. For many useful applications, however, no standard library type exists,
 so *pydantic* implements [many commonly used types](#pydantic-types).
 
 If no existing type suits your purpose you can also implement your [own pydantic-compatible types](#custom-data-types)
@@ -7,7 +7,7 @@ with custom properties and validation.
 
 ## Standard Library Types
 
-*pydantic* supports many common types from the python standard library. If you need stricter processing see 
+*pydantic* supports many common types from the python standard library. If you need stricter processing see
 [Strict Types](#strict-types); if you need to constrain the values allowed (e.g. to require a positive int) see
 [Constrained Types](#constrained-types).
 
@@ -18,12 +18,12 @@ with custom properties and validation.
 : *pydantic* uses `int(v)` to coerce types to an `int`;
   see [this](models.md#data-conversion) warning on loss of information during data conversion
 
-`float` 
+`float`
 : similarly, `float(v)` is used to coerce values to floats
 
 `str`
 : strings are accepted as-is, `int` `float` and `Decimal` are coerced using `str(v)`, `bytes` and `bytearray` are
-  converted using `v.decode()`, enums inheriting from `str` are converted using `v.value`, 
+  converted using `v.decode()`, enums inheriting from `str` are converted using `v.value`,
   and all other types cause an error
 
 `bytes`
@@ -103,23 +103,23 @@ with custom properties and validation.
 : will cause the input value to be passed to `re.compile(v)` to create a regex pattern
 
 `ipaddress.IPv4Address`
-: simply uses the type itself for validation by passing the value to `IPv4Address(v)`; 
+: simply uses the type itself for validation by passing the value to `IPv4Address(v)`;
   see [Pydantic Types](#pydantic-types) for other custom IP address types
 
 `ipaddress.IPv4Interface`
-: simply uses the type itself for validation by passing the value to `IPv4Address(v)`; 
+: simply uses the type itself for validation by passing the value to `IPv4Address(v)`;
   see [Pydantic Types](#pydantic-types) for other custom IP address types
 
 `ipaddress.IPv4Network`
-: simply uses the type itself for validation by passing the value to `IPv4Network(v)`; 
+: simply uses the type itself for validation by passing the value to `IPv4Network(v)`;
   see [Pydantic Types](#pydantic-types) for other custom IP address types
 
 `ipaddress.IPv6Address`
-: simply uses the type itself for validation by passing the value to `IPv6Address(v)`; 
+: simply uses the type itself for validation by passing the value to `IPv6Address(v)`;
   see [Pydantic Types](#pydantic-types) for other custom IP address types
 
 `ipaddress.IPv6Interface`
-: simply uses the type itself for validation by passing the value to `IPv6Interface(v)`; 
+: simply uses the type itself for validation by passing the value to `IPv6Interface(v)`;
   see [Pydantic Types](#pydantic-types) for other custom IP address types
 
 `ipaddress.IPv6Network`
@@ -138,7 +138,7 @@ with custom properties and validation.
 : *pydantic* attempts to convert the value to a string, then passes the string to `Decimal(v)`
 
 `pathlib.Path`
-: simply uses the type itself for validation by passing the value to `Path(v)`; 
+: simply uses the type itself for validation by passing the value to `Path(v)`;
   see [Pydantic Types](#pydantic-types) for other more strict path types
 
 `uuid.UUID`
@@ -312,7 +312,7 @@ _(This script is complete, it should run "as is")_
 ## Literal Type
 
 !!! note
-    This is a new feature of the python standard library as of python 3.8; 
+    This is a new feature of the python standard library as of python 3.8;
     prior to python 3.8, it requires the [typing-extensions](https://pypi.org/project/typing-extensions/) package.
 
 *pydantic* supports the use of `typing.Literal` (or `typing_extensions.Literal` prior to python 3.8)
@@ -351,8 +351,8 @@ _(This script is complete, it should run "as is")_
 `EmailStr`
 : requires [email-validator](https://github.com/JoshData/python-email-validator) to be installed;
   the input string must be a valid email address, and the output is a simple string
-  
-  
+
+
 
 `NameEmail`
 : requires [email-validator](https://github.com/JoshData/python-email-validator) to be installed;
@@ -360,7 +360,7 @@ _(This script is complete, it should run "as is")_
   and the output is a `NameEmail` object which has two properties: `name` and `email`.
   For `Fred Bloggs <fred.bloggs@example.com>` the name would be `"Fred Bloggs"`;
   for `fred.bloggs@example.com` it would be `"fred.bloggs"`.
-  
+
 
 `PyObject`
 : expects a string and loads the python object importable at that dotted path;
@@ -406,7 +406,7 @@ _(This script is complete, it should run "as is")_
 : requires a valid UUID of type 5; see `UUID` [above](#standard-library-types)
 
 `SecretBytes`
-: bytes where the value is kept partially secret; see [Secrets](#secret-types) 
+: bytes where the value is kept partially secret; see [Secrets](#secret-types)
 
 `SecretStr`
 : string where the value is kept partially secret; see [Secrets](#secret-types)
@@ -616,7 +616,7 @@ _(This script is complete, it should run "as is")_
 ### Json Type
 
 You can use `Json` data type to make *pydantic* first load a raw JSON string.
-It can also optionally be used to parse the loaded object into another type base on 
+It can also optionally be used to parse the loaded object into another type base on
 the type `Json` is parameterised with:
 
 ```py
@@ -683,7 +683,7 @@ _(This script is complete, it should run "as is")_
 You can use the `ByteSize` data type to convert byte string representation to
 raw bytes and print out human readable versions of the bytes as well.
 
-!!! info 
+!!! info
     Note that `1b` will be parsed as "1 byte" and not "1 bit".
 
 ```py
@@ -702,3 +702,8 @@ to get validators to parse and validate the input data.
 {!.tmp_examples/types_custom_type.py!}
 ```
 _(This script is complete, it should run "as is")_
+
+Similar validation could be achieved using [`constr(regex=...)`](#constrained-types) except the value won't be
+formatted with a space, the schema would just include the full pattern and the returned value would be a vanilla string.
+
+See [Schema](schema.md) for more details on how the model's schema is generated.
diff --git a/pydantic/networks.py b/pydantic/networks.py
index d256f5f14..c34d90316 100644
--- a/pydantic/networks.py
+++ b/pydantic/networks.py
@@ -12,7 +12,7 @@ from ipaddress import (
 from typing import TYPE_CHECKING, Any, Dict, Generator, Optional, Set, Tuple, Type, Union, cast, no_type_check
 
 from . import errors
-from .utils import Representation
+from .utils import Representation, update_not_none
 from .validators import constr_length_validator, str_validator
 
 if TYPE_CHECKING:
@@ -139,6 +139,10 @@ class AnyUrl(str):
             url += '#' + fragment
         return url
 
+    @classmethod
+    def __modify_schema__(cls, field_schema: Dict[str, Any]) -> None:
+        update_not_none(field_schema, minLength=cls.min_length, maxLength=cls.max_length)
+
     @classmethod
     def __get_validators__(cls) -> 'CallableGenerator':
         yield cls.validate
diff --git a/pydantic/schema.py b/pydantic/schema.py
index 7672cf7ab..523c4a2f1 100644
--- a/pydantic/schema.py
+++ b/pydantic/schema.py
@@ -573,17 +573,6 @@ def field_singleton_sub_fields_schema(
         return {'anyOf': sub_field_schemas}, definitions, nested_models
 
 
-validation_attribute_to_schema_keyword = {
-    'min_length': 'minLength',
-    'max_length': 'maxLength',
-    'regex': 'pattern',
-    'gt': 'exclusiveMinimum',
-    'lt': 'exclusiveMaximum',
-    'ge': 'minimum',
-    'le': 'maximum',
-    'multiple_of': 'multipleOf',
-}
-
 # Order is important, subclasses of str must go before str, etc
 field_class_to_schema_enum_enabled: Tuple[Tuple[Any, Dict[str, Any]], ...] = (
     (EmailStr, {'type': 'string', 'format': 'email'}),
@@ -691,19 +680,20 @@ def field_singleton_schema(  # noqa: C901 (ignore complexity)
     if issubclass(field_type, Enum):
         f_schema.update({'enum': [item.value for item in field_type]})
         # Don't return immediately, to allow adding specific types
-    for field_name, schema_name in validation_attribute_to_schema_keyword.items():
-        field_value = getattr(field_type, field_name, None)
-        if field_value is not None:
-            if field_name == 'regex':
-                field_value = field_value.pattern
-            f_schema[schema_name] = field_value
+
     for type_, t_schema in field_class_to_schema_enum_enabled:
         if issubclass(field_type, type_):
             f_schema.update(t_schema)
             break
+
+    modify_schema = getattr(field_type, '__modify_schema__', None)
+    if modify_schema:
+        modify_schema(f_schema)
+
     # Return schema, with or without enum definitions
     if f_schema:
         return f_schema, definitions, nested_models
+
     for type_, t_schema in field_class_to_schema_enum_disabled:
         if issubclass(field_type, type_):
             return t_schema, definitions, nested_models
diff --git a/pydantic/types.py b/pydantic/types.py
index d8e20dff1..90e00fc2d 100644
--- a/pydantic/types.py
+++ b/pydantic/types.py
@@ -9,7 +9,7 @@ from uuid import UUID
 
 from . import errors
 from .typing import AnyType
-from .utils import import_string
+from .utils import import_string, update_not_none
 from .validators import (
     bytes_validator,
     constr_length_validator,
@@ -90,6 +90,12 @@ class ConstrainedBytes(bytes):
     min_length: OptionalInt = None
     max_length: OptionalInt = None
 
+    @classmethod
+    def __modify_schema__(cls, field_schema: Dict[str, Any]) -> None:
+        update_not_none(
+            field_schema, minLength=cls.min_length, maxLength=cls.max_length,
+        )
+
     @classmethod
     def __get_validators__(cls) -> 'CallableGenerator':
         yield bytes_validator
@@ -121,6 +127,12 @@ class ConstrainedList(list):  # type: ignore
         yield list_validator
         yield cls.list_length_validator
 
+    @classmethod
+    def __modify_schema__(cls, field_schema: Dict[str, Any]) -> None:
+        update_not_none(
+            field_schema, minLength=cls.min_items, maxLength=cls.max_items,
+        )
+
     @classmethod
     def list_length_validator(cls, v: 'List[T]') -> 'List[T]':
         v_len = len(v)
@@ -149,6 +161,12 @@ class ConstrainedStr(str):
     regex: Optional[Pattern[str]] = None
     strict = False
 
+    @classmethod
+    def __modify_schema__(cls, field_schema: Dict[str, Any]) -> None:
+        update_not_none(
+            field_schema, minLength=cls.min_length, maxLength=cls.max_length, pattern=cls.regex and cls.regex.pattern
+        )
+
     @classmethod
     def __get_validators__(cls) -> 'CallableGenerator':
         yield strict_str_validator if cls.strict else str_validator
@@ -260,6 +278,17 @@ class ConstrainedInt(int, metaclass=ConstrainedNumberMeta):
     le: OptionalInt = None
     multiple_of: OptionalInt = None
 
+    @classmethod
+    def __modify_schema__(cls, field_schema: Dict[str, Any]) -> None:
+        update_not_none(
+            field_schema,
+            exclusiveMinimum=cls.gt,
+            exclusiveMaximum=cls.lt,
+            minimum=cls.ge,
+            maximum=cls.le,
+            multipleOf=cls.multiple_of,
+        )
+
     @classmethod
     def __get_validators__(cls) -> 'CallableGenerator':
 
@@ -296,6 +325,17 @@ class ConstrainedFloat(float, metaclass=ConstrainedNumberMeta):
     le: OptionalIntFloat = None
     multiple_of: OptionalIntFloat = None
 
+    @classmethod
+    def __modify_schema__(cls, field_schema: Dict[str, Any]) -> None:
+        update_not_none(
+            field_schema,
+            exclusiveMinimum=cls.gt,
+            exclusiveMaximum=cls.lt,
+            minimum=cls.ge,
+            maximum=cls.le,
+            multipleOf=cls.multiple_of,
+        )
+
     @classmethod
     def __get_validators__(cls) -> 'CallableGenerator':
         yield strict_float_validator if cls.strict else float_validator
@@ -338,6 +378,17 @@ class ConstrainedDecimal(Decimal, metaclass=ConstrainedNumberMeta):
     decimal_places: OptionalInt = None
     multiple_of: OptionalIntFloatDecimal = None
 
+    @classmethod
+    def __modify_schema__(cls, field_schema: Dict[str, Any]) -> None:
+        update_not_none(
+            field_schema,
+            exclusiveMinimum=cls.gt,
+            exclusiveMaximum=cls.lt,
+            minimum=cls.ge,
+            maximum=cls.le,
+            multipleOf=cls.multiple_of,
+        )
+
     @classmethod
     def __get_validators__(cls) -> 'CallableGenerator':
         yield decimal_validator
diff --git a/pydantic/utils.py b/pydantic/utils.py
index 465a0ddaf..200cdaa2c 100644
--- a/pydantic/utils.py
+++ b/pydantic/utils.py
@@ -111,6 +111,10 @@ def deep_update(mapping: Dict[KeyType, Any], updating_mapping: Dict[KeyType, Any
     return updated_mapping
 
 
+def update_not_none(mapping: Dict[Any, Any], **update: Any) -> None:
+    mapping.update({k: v for k, v in update.items() if v is not None})
+
+
 def almost_equal_floats(value_1: float, value_2: float, *, delta: float = 1e-8) -> bool:
     """
     Return True if two floats are almost equal
diff --git a/tests/test_schema.py b/tests/test_schema.py
index ecdf824d5..3139309bc 100644
--- a/tests/test_schema.py
+++ b/tests/test_schema.py
@@ -513,10 +513,13 @@ def test_str_constrained_types(field_type, expected_schema):
     class Model(BaseModel):
         a: field_type
 
+    model_schema = Model.schema()
+    assert model_schema['properties']['a'] == expected_schema
+
     base_schema = {'title': 'Model', 'type': 'object', 'properties': {'a': {}}, 'required': ['a']}
     base_schema['properties']['a'] = expected_schema
 
-    assert Model.schema() == base_schema
+    assert model_schema == base_schema
 
 
 @pytest.mark.parametrize(
@@ -1680,3 +1683,24 @@ def test_dataclass():
         'properties': {'a': {'title': 'A', 'type': 'boolean'}},
         'required': ['a'],
     }
+
+
+def test_schema_attributes():
+    class ExampleEnum(Enum):
+        gt = 'GT'
+        lt = 'LT'
+        ge = 'GE'
+        le = 'LE'
+        max_length = 'ML'
+        multiple_of = 'MO'
+        regex = 'RE'
+
+    class Example(BaseModel):
+        example: ExampleEnum
+
+    assert Example.schema() == {
+        'title': 'Example',
+        'type': 'object',
+        'properties': {'example': {'title': 'Example', 'enum': ['GT', 'LT', 'GE', 'LE', 'ML', 'MO', 'RE']}},
+        'required': ['example'],
+    }
