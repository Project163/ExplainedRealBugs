diff --git a/docs/plugins/main.py b/docs/plugins/main.py
index 6411105ff..6a9776255 100644
--- a/docs/plugins/main.py
+++ b/docs/plugins/main.py
@@ -37,6 +37,7 @@ def on_page_markdown(markdown: str, page: Page, config: Config, files: Files) ->
     Called on each file after it is read and before it is converted to HTML.
     """
     markdown = upgrade_python(markdown)
+    markdown = insert_json_output(markdown)
     markdown = remove_code_fence_attributes(markdown)
     if md := add_version(markdown, page):
         return md
@@ -115,6 +116,26 @@ def _upgrade_code(code: str, min_version: int) -> str:
     return autoflake.fix_code(upgraded, remove_all_unused_imports=True)
 
 
+def insert_json_output(markdown: str) -> str:
+    """
+    Find `output="json"` code fence tags and replace with a separate JSON section
+    """
+
+    def replace_json(m: re.Match[str]) -> str:
+        start, attrs, code = m.groups()
+
+        def replace_last_print(m2: re.Match[str]) -> str:
+            ind, json_text = m2.groups()
+            json_text = indent(json.dumps(json.loads(json_text), indent=2), ind)
+            # no trailing fence as that's not part of code
+            return f'\n{ind}```\n\n{ind}JSON output:\n\n{ind}```json\n{json_text}\n'
+
+        code = re.sub(r'\n( *)"""(.*?)\1"""\n$', replace_last_print, code, flags=re.S)
+        return f'{start}{attrs}{code}{start}\n'
+
+    return re.sub(r'(^ *```)([^\n]*?output="json"[^\n]*?\n)(.+?)\1', replace_json, markdown, flags=re.M | re.S)
+
+
 def remove_code_fence_attributes(markdown: str) -> str:
     """
     There's no way to add attributes to code fences that works with both pycharm and mkdocs, hence we use
@@ -124,7 +145,7 @@ def remove_code_fence_attributes(markdown: str) -> str:
     """
 
     def remove_attrs(match: re.Match[str]) -> str:
-        suffix = re.sub(r' (?:test|lint|upgrade|group|requires)=".+?"', '', match.group(2), flags=re.M)
+        suffix = re.sub(r' (?:test|lint|upgrade|group|requires|output)=".+?"', '', match.group(2), flags=re.M)
         return f'{match.group(1)}{suffix}'
 
     return re.sub(r'^( *``` *py)(.*)', remove_attrs, markdown, flags=re.M)
diff --git a/docs/usage/models.md b/docs/usage/models.md
index 9500c592c..5f2d83b6c 100644
--- a/docs/usage/models.md
+++ b/docs/usage/models.md
@@ -323,48 +323,46 @@ The `GetterDict` instance will be called for each field with a sentinel as a fal
 value is set). Returning this sentinel means that the field is missing. Any other value will
 be interpreted as the value of the field.
 
-```py test="xfail - GetterDict is removed, replace with a custom root_validator"
-from typing import Any, Optional
+```py
+from collections.abc import Mapping
+from typing import Optional
 from xml.etree.ElementTree import fromstring
 
-from pydantic import BaseModel
-from pydantic.utils import GetterDict
+from pydantic import BaseModel, Field
 
 xmlstring = """
 <User Id="2138">
-    <FirstName />
-    <LoggedIn Value="true" />
+    <FirstName>John</FirstName>
+    <LastName>Foobar</LastName>
 </User>
 """
 
 
-class UserGetter(GetterDict):
-    def get(self, key: str, default: Any) -> Any:
-        # element attributes
-        if key in {'Id', 'Status'}:
-            return self._obj.attrib.get(key, default)
+class XmlMapping(Mapping):
+    def __init__(self, xmlstring):
+        self._xml = fromstring(xmlstring)
 
-        # element children
+    def __getitem__(self, key):
+        if key in {'Id', 'Status'}:
+            return self._xml.attrib.get(key)
         else:
-            try:
-                return self._obj.find(key).attrib['Value']
-            except (AttributeError, KeyError):
-                return default
+            return self._xml.find(key).text
 
+    def __len__(self):
+        return len(self._xml.attrib) + len(self._xml)
 
-class User(BaseModel):
-    Id: int
-    Status: Optional[str]
-    FirstName: Optional[str]
-    LastName: Optional[str]
-    LoggedIn: bool
+    def __iter__(self):
+        ...
 
-    class Config:
-        from_attributes = True
-        getter_dict = UserGetter
 
+class User(BaseModel):
+    id: int = Field(alias='Id')
+    first_name: Optional[str] = Field(None, alias='FirstName')
+    last_name: Optional[str] = Field(None, alias='LastName')
 
-user = User.from_orm(fromstring(xmlstring))
+
+print(User.model_validate(XmlMapping(xmlstring)))
+#> id=2138 first_name='John' last_name='Foobar'
 ```
 
 
@@ -695,10 +693,10 @@ In order to declare a generic model, you perform the following steps:
 
 Here is an example using `GenericModel` to create an easily-reused HTTP response payload wrapper:
 
-```py test="xfail - needs always/validate default support"
+```py test="xfail looks like an error with generics!"
 from typing import Generic, List, Optional, TypeVar
 
-from pydantic import BaseModel, ValidationError, validator_function
+from pydantic import BaseModel, Field, ValidationError, field_validator
 
 DataT = TypeVar('DataT')
 
@@ -714,14 +712,14 @@ class DataModel(BaseModel):
 
 
 class Response(BaseModel, Generic[DataT]):
-    data: Optional[DataT]
-    error: Optional[Error]
+    data: Optional[DataT] = None
+    error: Optional[Error] = Field(validate_default=True)
 
-    @validator_function('error', always=True)
-    def check_consistency(cls, v, values):
-        if v is not None and values['data'] is not None:
+    @field_validator('error')
+    def check_consistency(cls, v, info):
+        if v is not None and info.data['data'] is not None:
             raise ValueError('must not provide both data and error')
-        if v is None and values.get('data') is None:
+        if v is None and info.data.get('data') is None:
             raise ValueError('must provide data or error')
         return v
 
@@ -959,8 +957,8 @@ print(BarModel.model_fields.keys())
 
 You can also add validators by passing a dict to the `__validators__` argument.
 
-```py test="xfail create_model validators"
-from pydantic import ValidationError, create_model, validator
+```py rewrite_assert="false"
+from pydantic import ValidationError, create_model, field_validator
 
 
 def username_alphanumeric(cls, v):
@@ -968,17 +966,23 @@ def username_alphanumeric(cls, v):
     return v
 
 
-validators = {'username_validator': validator('username')(username_alphanumeric)}
+validators = {'username_validator': field_validator('username')(username_alphanumeric)}
 
 UserModel = create_model('UserModel', username=(str, ...), __validators__=validators)
 
 user = UserModel(username='scolvin')
 print(user)
+#> username='scolvin'
 
 try:
     UserModel(username='scolvi%n')
 except ValidationError as e:
     print(e)
+    """
+    1 validation error for UserModel
+    username
+      Assertion failed, must be alphanumeric [type=assertion_error, input_value='scolvi%n', input_type=str]
+    """
 ```
 
 ## Model creation from `NamedTuple` or `TypedDict`
@@ -989,10 +993,10 @@ For this _pydantic_ provides `create_model_from_namedtuple` and `create_model_fr
 Those methods have the exact same keyword arguments as `create_model`.
 
 
-```py test="xfail need Validator to replace create_model_from_typeddict"
+```py
 from typing_extensions import TypedDict
 
-from pydantic import ValidationError, create_model_from_typeddict
+from pydantic import ValidationError, Validator
 
 
 class User(TypedDict):
@@ -1000,17 +1004,21 @@ class User(TypedDict):
     id: int
 
 
-class Config:
-    extra = 'forbid'
-
-
-UserM = create_model_from_typeddict(User, __config__=Config)
-print(repr(UserM(name=123, id='3')))
+UserValdiator = Validator(User)
+print(repr(UserValdiator(dict(name='Fred', id='3'))))
+#> {'name': 'Fred', 'id': 3}
 
 try:
-    UserM(name=123, id='3', other='no')
+    UserValdiator(dict(name='Fred', id='wrong', other='no'))
 except ValidationError as e:
     print(e)
+    """
+    2 validation errors for typed-dict
+    id
+      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='wrong', input_type=str]
+    other
+      Extra inputs are not permitted [type=extra_forbidden, input_value='no', input_type=str]
+    """
 ```
 
 ## Custom Root Types
@@ -1402,7 +1410,7 @@ which are analogous to `BaseModel.parse_file` and `BaseModel.parse_raw`.
 and in some cases this may result in a loss of information.
 For example:
 
-```py test="xfail this logic has failed"
+```py
 from pydantic import BaseModel
 
 
@@ -1412,7 +1420,8 @@ class Model(BaseModel):
     c: str
 
 
-print(Model(a=3.1415, b=' 2.72 ', c=123).model_dump())
+print(Model(a=3.000, b='2.72', c=b'binary data').model_dump())
+#> {'a': 3, 'b': 2.72, 'c': 'binary data'}
 ```
 
 This is a deliberate decision of *pydantic*, and in general it's the most useful approach. See
diff --git a/docs/usage/schema.md b/docs/usage/schema.md
index cc0b26f9e..400cb9dd4 100644
--- a/docs/usage/schema.md
+++ b/docs/usage/schema.md
@@ -136,7 +136,7 @@ apply the schema generation logic used for _pydantic_ models in a more ad-hoc wa
 These functions behave similarly to `BaseModel.model_json_schema` and `BaseModel.schema_json`,
 but work with arbitrary pydantic-compatible types.
 
-```py requires="3.8"
+```py requires="3.8" output="json"
 from typing import Literal, Union
 
 from typing_extensions import Annotated
diff --git a/docs/usage/types.md b/docs/usage/types.md
index 12720b75a..afd86d629 100644
--- a/docs/usage/types.md
+++ b/docs/usage/types.md
@@ -305,59 +305,6 @@ for i in m.infinite:
     pydantic can't validate the values automatically for you because it would require
     consuming the infinite generator.
 
-#### Validating the first value
-
-You can create a [validator](validators.md) to validate the first value in an infinite generator and still not consume it entirely.
-
-```py test="xfail - what's going on here?"
-import itertools
-from typing import Iterable
-
-from pydantic import BaseModel, ValidationError, field_validator
-
-
-class Model(BaseModel):
-    infinite: Iterable[int]
-
-    @field_validator('infinite')
-    # You don't need to add the "ModelField", but it will help your
-    # editor give you completion and catch errors
-    def infinite_first_int(cls, iterable, field):
-        first_value = next(iterable)
-        if field.sub_fields:
-            # The Iterable had a parameter type, in this case it's int
-            # We use it to validate the first value
-            sub_field = field.sub_fields[0]
-            v, error = sub_field.validate(first_value, {}, loc='first_value')
-            if error:
-                raise ValidationError([error], cls)
-        # This creates a new generator that returns the first value and then
-        # the rest of the values from the (already started) iterable
-        return itertools.chain([first_value], iterable)
-
-
-def infinite_ints():
-    i = 0
-    while True:
-        yield i
-        i += 1
-
-
-m = Model(infinite=infinite_ints())
-print(m)
-
-
-def infinite_strs():
-    while True:
-        yield from 'allthesingleladies'
-
-
-try:
-    Model(infinite=infinite_strs())
-except ValidationError as e:
-    print(e)
-```
-
 ### Unions
 
 The `Union` type allows a model attribute to accept different types, e.g.:
@@ -1288,49 +1235,25 @@ my_cos_2 = ImportThings(obj='math.cos')
 assert my_cos == my_cos_2
 ```
 
-**Serializing an `ImportString` type to json is possible with a
-[custom encoder](exporting_models.md#json_encoders) which accounts for
-the evaluated object:**
-```py test="xfail - replace json_encoders"
-from types import BuiltinFunctionType
+**Serializing an `ImportString` type to json is possible with a`serializer` (TODO link).
 
-from pydantic import BaseModel, ImportString
+```py output="json"
+from pydantic import BaseModel, ImportString, serializer
 
 
-# The following class will not successfully serialize to JSON
-# Since "obj" is evaluated to an object, not a pydantic `ImportString`
-class WithCustomEncodersBad(BaseModel):
-    obj: ImportString
-
-    class Config:
-        json_encoders = {ImportString: lambda x: str(x)}
-
-
-# Create an instance
-m = WithCustomEncodersBad(obj='math.cos')
-
-try:
-    m.json()
-except TypeError as e:
-    print(e)
-
-# Let's do some sanity checks to verify that m.obj is not an "ImportString"
-print(isinstance(m.obj, ImportString))
-print(isinstance(m.obj, BuiltinFunctionType))
-
-
-# So now that we know that after an ImportString is evaluated by Pydantic
-# it results in its underlying object, we can configure our json encoder
-# to account for those specific types
 class WithCustomEncodersGood(BaseModel):
     obj: ImportString
 
-    class Config:
-        json_encoders = {BuiltinFunctionType: lambda x: str(x)}
+    @serializer('obj')
+    def serialize_obj(cls, v):
+        return str(v)
 
 
 m = WithCustomEncodersGood(obj='math.cos')
-print(m.json())
+print(m.model_dump_json())
+"""
+{"obj":"SerializationInfo(include=None, exclude=None, mode='json', by_alias=False, exclude_unset=False, exclude_defaults=False, exclude_none=False, round_trip=False)"}
+"""
 ```
 
 ### URLs
@@ -1628,8 +1551,8 @@ that you do not want to be visible in logging or tracebacks.
 `SecretStr` and `SecretBytes` can be initialized idempotently or by using `str` or `bytes` literals respectively.
 The `SecretStr` and `SecretBytes` will be formatted as either `'**********'` or `''` on conversion to json.
 
-```py test="xfail - replace json_encoders"
-from pydantic import BaseModel, SecretBytes, SecretStr, ValidationError
+```py
+from pydantic import BaseModel, SecretBytes, SecretStr, ValidationError, serializer
 
 
 class SimpleModel(BaseModel):
@@ -1641,18 +1564,31 @@ sm = SimpleModel(password='IAmSensitive', password_bytes=b'IAmSensitiveBytes')
 
 # Standard access methods will not display the secret
 print(sm)
+#> password=SecretStr('**********') password_bytes=SecretBytes(b'**********')
 print(sm.password)
+#> **********
 print(sm.model_dump())
+#> {'password': SecretStr('**********'), 'password_bytes': SecretBytes(b'**********')}
 print(sm.model_dump_json())
+#> {"password":"**********","password_bytes":"**********"}
 
 # Use get_secret_value method to see the secret's content.
 print(sm.password.get_secret_value())
+#> IAmSensitive
 print(sm.password_bytes.get_secret_value())
+#> b'IAmSensitiveBytes'
 
 try:
     SimpleModel(password=[1, 2, 3], password_bytes=[1, 2, 3])
 except ValidationError as e:
     print(e)
+    """
+    2 validation errors for SimpleModel
+    password
+      Input should be a valid string [type=string_type, input_value=[1, 2, 3], input_type=list]
+    password_bytes
+      Input should be a valid bytes [type=bytes_type, input_value=[1, 2, 3], input_type=list]
+    """
 
 
 # If you want the secret to be dumped as plain-text using the json method,
@@ -1661,22 +1597,24 @@ class SimpleModelDumpable(BaseModel):
     password: SecretStr
     password_bytes: SecretBytes
 
-    class Config:
-        json_encoders = {
-            SecretStr: lambda v: v.get_secret_value() if v else None,
-            SecretBytes: lambda v: v.get_secret_value() if v else None,
-        }
+    @serializer('password', 'password_bytes')
+    def serialize_secret(v):
+        return v.get_secret_value() if v else None
 
 
 sm2 = SimpleModelDumpable(password='IAmSensitive', password_bytes=b'IAmSensitiveBytes')
 
 # Standard access methods will not display the secret
 print(sm2)
+#> password=SecretStr('**********') password_bytes=SecretBytes(b'**********')
 print(sm2.password)
+#> **********
 print(sm2.model_dump())
+#> {'password': 'IAmSensitive', 'password_bytes': b'IAmSensitiveBytes'}
 
 # But the json method will
 print(sm2.model_dump_json())
+#> {"password":"IAmSensitive","password_bytes":"IAmSensitiveBytes"}
 ```
 
 ### Json Type
diff --git a/tests/test_docs.py b/tests/test_docs.py
index 8d793507b..9f6c445fc 100644
--- a/tests/test_docs.py
+++ b/tests/test_docs.py
@@ -123,18 +123,20 @@ def test_docs_examples(example: CodeExample, eval_example: EvalExample, tmp_path
 
     xfail = None
     if test_settings and test_settings.startswith('xfail'):
-        xfail = test_settings[5:]
+        xfail = test_settings[5:].lstrip(' -')
+
+    rewrite_assertions = prefix_settings.get('rewrite_assert', 'true') == 'true'
 
     try:
         if test_settings == 'no-print-intercept':
-            d2 = eval_example.run(example, module_globals=d)
+            d2 = eval_example.run(example, module_globals=d, rewrite_assertions=rewrite_assertions)
         elif eval_example.update_examples:
-            d2 = eval_example.run_print_update(example, module_globals=d)
+            d2 = eval_example.run_print_update(example, module_globals=d, rewrite_assertions=rewrite_assertions)
         else:
-            d2 = eval_example.run_print_check(example, module_globals=d)
+            d2 = eval_example.run_print_check(example, module_globals=d, rewrite_assertions=rewrite_assertions)
     except BaseException as e:  # run_print_check raises a BaseException
         if xfail:
-            pytest.xfail(str(e))
+            pytest.xfail(f'{xfail}, {type(e).__name__}: {e}')
         raise
     else:
         if xfail:
